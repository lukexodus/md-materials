# Syllabus

## Kali Linux Environment

---

## **Module 1: Reconnaissance & Information Gathering**

- Target ML model identification
- API endpoint enumeration
- Model architecture fingerprinting
- Training data inference techniques
- Framework detection (TensorFlow, PyTorch, scikit-learn)
- Version detection and CVE mapping
- OSINT for AI systems
- Model card and documentation analysis

---

## **Module 2: Model Extraction & Theft**

- Query-based model extraction
- API abuse for model replication
- Equation-solving attacks
- Functionally equivalent model creation
- Transfer learning exploitation
- Model distillation attacks
- Watermark detection bypass
- Intellectual property theft vectors

---

## **Module 3: Adversarial Machine Learning**

- Adversarial example generation (FGSM, PGD, C&W)
- Evasion attacks
- Perturbation techniques
- Gradient-based attacks
- Black-box attack methods
- Transferability exploitation
- Physical adversarial examples
- Universal adversarial perturbations

---

## **Module 4: Data Poisoning Attacks**

- Training data poisoning
- Backdoor injection
- Trigger-based attacks
- Label flipping
- Clean-label poisoning
- Federated learning poisoning
- Supply chain data contamination
- Dataset manipulation techniques

---

## **Module 5: Model Inversion & Privacy Attacks**

- Membership inference attacks
- Model inversion attacks
- Training data extraction
- Attribute inference
- Privacy leakage detection
- Gradient leakage exploitation
- Reconstruction attacks
- Differential privacy bypass

---

## **Module 6: Prompt Injection & LLM Exploitation**

- Direct prompt injection
- Indirect prompt injection
- Jailbreaking techniques
- System prompt extraction
- Context manipulation
- Instruction override attacks
- Multi-turn exploitation
- Role-playing bypass methods

---

## **Module 7: AI API Security Testing**

- Rate limiting bypass
- Authentication weaknesses
- API key extraction
- Cost amplification attacks
- Resource exhaustion
- Input validation bypass
- Response manipulation
- Token smuggling

---

## **Module 8: Model Behavioral Exploitation**

- Misclassification forcing
- Confidence manipulation
- Decision boundary exploration
- Class imbalance exploitation
- Overfitting abuse
- Underfitting detection
- Bias exploitation
- Fairness attack vectors

---

## **Module 9: Neural Network Backdoors**

- Trojan detection
- Activation pattern analysis
- Neuron-level backdoors
- Weight manipulation
- Trigger reverse engineering
- Stealth backdoor techniques
- Runtime backdoor injection
- Hardware-based neural trojans

---

## **Module 10: Automated ML Security Tools**

- Adversarial Robustness Toolbox (ART)
- CleverHans
- Foolbox
- TextAttack
- AutoAttack
- RobustBench
- SecML
- Custom automation scripts

---

## **Module 11: Defense Evasion**

- Detection bypass techniques
- Adversarial training circumvention
- Input transformation evasion
- Defensive distillation bypass
- Gradient masking exploitation
- Ensemble model attacks
- Certified defense attacks
- Randomization bypass

---

## **Module 12: MLOps & Pipeline Exploitation**

- CI/CD pipeline attacks
- Model registry manipulation
- Container escape techniques
- Dependency confusion
- Model versioning abuse
- Deployment configuration exploitation
- Monitoring system bypass
- A/B testing manipulation

---

## **Module 13: Federated Learning Attacks**

- Gradient poisoning
- Model update manipulation
- Byzantine attacks
- Inference attacks on aggregation
- Sybil attacks
- Free-riding detection
- Privacy budget exhaustion
- Aggregation protocol exploitation

---

## **Module 14: AutoML & NAS Exploitation**

- Hyperparameter manipulation
- Architecture search poisoning
- Automated feature engineering abuse
- Meta-learning exploitation
- Neural architecture backdoors
- Search space manipulation
- Resource consumption attacks
- Automated model stealing

---

## **Module 15: Reinforcement Learning Attacks**

- Reward hacking
- Policy manipulation
- Environment poisoning
- Action space exploitation
- State observation tampering
- Multi-agent exploitation
- Transfer learning attacks
- Adversarial policies

---

## **Module 16: Computer Vision Exploits**

- Image classification attacks
- Object detection bypass
- Segmentation manipulation
- Facial recognition evasion
- Patch attacks
- 3D adversarial objects
- Video manipulation
- Multi-modal attacks

---

## **Module 17: NLP & Text-Based Attacks**

- Sentiment manipulation
- Text classification evasion
- Named entity recognition bypass
- Machine translation attacks
- Text generation exploitation
- Semantic similarity abuse
- Character-level perturbations
- Token smuggling

---

## **Module 18: Audio & Speech Security**

- Speech recognition attacks
- Audio adversarial examples
- Voice cloning exploitation
- Speaker verification bypass
- Acoustic environment manipulation
- Ultrasonic attacks
- Noise injection techniques
- Deepfake audio generation

---

## **Module 19: Explainability Exploitation**

- LIME manipulation
- SHAP value attacks
- Attention mechanism exploitation
- Saliency map manipulation
- Feature importance poisoning
- Explanation backdoors
- Interpretability bypass
- Attribution attack vectors

---

## **Module 20: Hardware-Accelerated ML Attacks**

- GPU memory exploitation
- TPU-specific attacks
- Side-channel attacks on accelerators
- Timing attacks
- Power analysis
- Rowhammer for ML systems
- Cache-based attacks
- Hardware trojan injection

---

## **Module 21: Post-Exploitation & Persistence**

- Model backdoor maintenance
- Covert channel establishment
- Long-term data exfiltration
- Stealthy model updates
- Logging evasion
- Audit trail manipulation
- Shadow model deployment
- Recovery prevention

---

## **Module 22: Red Team Automation**

- Attack orchestration frameworks
- Payload generation automation
- Multi-stage attack chains
- Continuous testing pipelines
- Result analysis automation
- Report generation
- Exploit database integration
- Custom tool development

---

## **Module 23: Capture The Flag Strategies**

- Challenge reconnaissance
- Point optimization
- Time management
- Tool chain selection
- Documentation practices
- Team collaboration
- Hint utilization
- Write-up preparation

---

## **Module 24: Kali Linux Tooling Integration**

- Python ML library setup
- GPU configuration
- Docker container deployment
- Network traffic analysis tools
- Packet manipulation utilities
- Scripting environment setup
- Remote attack infrastructure
- Post-exploitation frameworks

---

## **Module 25: Documentation & Reporting**

- Attack chain documentation
- Proof-of-concept development
- Impact assessment
- Remediation recommendations
- CTF write-up structure
- Technical reporting
- Evidence preservation
- Knowledge base creation