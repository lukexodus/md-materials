# Request Options

## [[#Mode Options in Fetch API]]

## Credentials Option: omit, same-origin, include

### Overview

The `credentials` option in the Fetch API controls whether user credentials (cookies, HTTP authentication, TLS client certificates) are included in the request and whether credentials from the response are processed by the browser.

### The Three Credential Modes

#### `omit`

Explicitly excludes credentials from both the request and response processing.

```javascript
fetch('https://api.example.com/data', {
  credentials: 'omit'
});
```

**Request Behavior:**

- No cookies sent, even for same-origin requests
- No Authorization headers sent
- No TLS client certificates used

**Response Behavior:**

- `Set-Cookie` headers ignored by browser
- WWW-Authenticate challenges ignored
- No credential storage occurs

**Use Cases:**

- Public API endpoints that don't require authentication
- Preventing credential leakage to untrusted origins
- Anonymous requests where you want to ensure no identifying information is sent
- Stateless requests that should not create sessions

**Example - Public Data Fetch:**

```javascript
// Fetch public weather data without any credentials
const response = await fetch('https://api.weather.gov/forecast', {
  credentials: 'omit'
});
const weatherData = await response.json();
```

**Example - Preventing Credential Leakage:**

```javascript
// Ensure no cookies are sent to third-party analytics
fetch('https://analytics.example.com/track', {
  method: 'POST',
  credentials: 'omit',
  body: JSON.stringify({ event: 'page_view' })
});
```

#### `same-origin` (default)

Includes credentials only for requests to the same origin as the calling script.

```javascript
fetch('https://api.example.com/data', {
  credentials: 'same-origin'
});

// Equivalent to:
fetch('https://api.example.com/data');
```

**Request Behavior:**

- Same-origin: All cookies, auth headers, and certificates sent
- Cross-origin: No credentials sent
- Subdomains count as cross-origin (e.g., `app.example.com` vs `api.example.com`)

**Response Behavior:**

- Same-origin: `Set-Cookie` and authentication responses processed
- Cross-origin: Credential-setting headers ignored

**Origin Matching Rules:** An origin is "same" only when protocol, domain, and port all match exactly:

```javascript
// Current page: https://example.com:443

// Same-origin (credentials sent):
fetch('/api/data');
fetch('https://example.com/api/data');
fetch('https://example.com:443/api/data');

// Cross-origin (credentials NOT sent):
fetch('http://example.com/api/data');        // Different protocol
fetch('https://api.example.com/data');       // Different subdomain
fetch('https://example.com:8080/data');      // Different port
fetch('https://example.org/data');           // Different domain
```

**Use Cases:**

- Default secure behavior for most applications
- Internal API calls within the same domain
- When you want automatic credential inclusion for your own resources
- Preventing cross-origin credential exposure by default

**Example - Same-Origin API Calls:**

```javascript
// On https://example.com, calling own API
async function getUserProfile() {
  const response = await fetch('/api/user/profile', {
    credentials: 'same-origin' // explicit, but this is default
  });
  
  if (!response.ok) {
    throw new Error('Failed to fetch profile');
  }
  
  return response.json();
}
```

**Example - Mixed Origin Requests:**

```javascript
// On https://example.com
async function loadData() {
  // Credentials included (same-origin)
  const userResponse = await fetch('/api/user', {
    credentials: 'same-origin'
  });
  
  // Credentials NOT included (cross-origin)
  const publicResponse = await fetch('https://cdn.example.com/data.json', {
    credentials: 'same-origin'
  });
}
```

#### `include`

Includes credentials for all requests, regardless of origin.

```javascript
fetch('https://api.example.com/data', {
  credentials: 'include'
});
```

**Request Behavior:**

- Same-origin: All credentials sent (same as `same-origin`)
- Cross-origin: All credentials sent (requires CORS approval)

**Response Behavior:**

- Same-origin: All credential-setting headers processed
- Cross-origin: Credential-setting headers processed only if CORS headers allow

**CORS Requirements:**

For cross-origin requests with `credentials: 'include'`, the server must send:

```http
Access-Control-Allow-Origin: https://example.com
Access-Control-Allow-Credentials: true
```

**Restrictions:**

- `Access-Control-Allow-Origin` cannot be `*`
- `Access-Control-Allow-Headers` cannot be `*`
- `Access-Control-Allow-Methods` cannot be `*`
- Must specify exact origin or use dynamic origin reflection

**Use Cases:**

- Authenticated cross-origin API requests
- Single sign-on (SSO) implementations
- Microservices architectures with authentication
- Cross-subdomain authenticated requests

**Example - Cross-Origin Authenticated Request:**

```javascript
// From https://app.example.com to https://api.example.com
async function fetchUserData() {
  try {
    const response = await fetch('https://api.example.com/user', {
      credentials: 'include',
      headers: {
        'Content-Type': 'application/json'
      }
    });
    
    if (response.status === 401) {
      // Redirect to login
      window.location.href = '/login';
      return;
    }
    
    return await response.json();
  } catch (error) {
    console.error('Failed to fetch user data:', error);
    throw error;
  }
}
```

**Example - Cross-Subdomain Session Sharing:**

```javascript
// From https://shop.example.com accessing https://api.example.com
async function addToCart(productId, quantity) {
  const response = await fetch('https://api.example.com/cart/add', {
    method: 'POST',
    credentials: 'include', // Send session cookie cross-subdomain
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ productId, quantity })
  });
  
  return response.json();
}
```

### Credential Types Affected

#### HTTP Cookies

**Sent in Request:**

```http
GET /api/data HTTP/1.1
Host: api.example.com
Cookie: sessionId=abc123; userId=456
```

**Set in Response:**

```http
HTTP/1.1 200 OK
Set-Cookie: sessionId=xyz789; Path=/; HttpOnly; Secure
```

**Behavior by Mode:**

- `omit`: Never sends cookies, ignores Set-Cookie
- `same-origin`: Sends/receives cookies for same origin only
- `include`: Sends/receives cookies for all origins (if allowed)

#### HTTP Authentication

**Basic Authentication Example:**

```javascript
// Browser previously authenticated via WWW-Authenticate challenge
fetch('https://api.example.com/protected', {
  credentials: 'include' // Includes Authorization header
});
```

**Request with stored credentials:**

```http
GET /protected HTTP/1.1
Host: api.example.com
Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=
```

#### TLS Client Certificates

When the browser has client certificates installed:

```javascript
fetch('https://secure-api.example.com/data', {
  credentials: 'include' // Uses client certificate if available
});
```

[Inference] The browser automatically selects and presents the appropriate client certificate during the TLS handshake when credentials are included.

### Comparison Matrix

|Aspect|`omit`|`same-origin`|`include`|
|---|---|---|---|
|Same-origin cookies|❌ Not sent|✅ Sent|✅ Sent|
|Cross-origin cookies|❌ Not sent|❌ Not sent|✅ Sent (if CORS allows)|
|Set-Cookie processing (same-origin)|❌ Ignored|✅ Processed|✅ Processed|
|Set-Cookie processing (cross-origin)|❌ Ignored|❌ Ignored|✅ Processed (if CORS allows)|
|HTTP Auth headers|❌ Not sent|✅ Same-origin only|✅ Always sent|
|TLS client certificates|❌ Not used|✅ Same-origin only|✅ Always used|
|Default behavior|No|Yes|No|
|Requires CORS headers|No|No|Yes (cross-origin)|

### Practical Decision Tree

**Choose `omit` when:**

- Accessing public APIs that don't require authentication
- You want to guarantee no credentials are leaked
- Making requests to untrusted origins
- Implementing anonymous tracking or analytics

**Choose `same-origin` when:**

- Building a traditional web application with backend on same origin
- You want the default secure behavior
- Not making authenticated cross-origin requests
- Working with internal APIs only

**Choose `include` when:**

- Making authenticated requests to a different origin
- Implementing cross-subdomain authentication
- Using cookie-based SSO systems
- Building microservices with shared authentication
- Accessing APIs that require session cookies from a different domain

### Security Implications

#### With `omit`

**Security Benefits:**

- No risk of CSRF attacks (no credentials to steal)
- No credential leakage to third parties
- Prevents session fixation attacks

**Limitations:**

- Cannot implement authentication with this mode
- Cannot track users across requests

#### With `same-origin`

**Security Benefits:**

- Prevents cross-origin credential exposure by default
- Reduces CSRF attack surface
- No risk of sending cookies to third-party origins

**Limitations:**

- Cannot share authentication across subdomains
- Microservices on different subdomains need token-based auth

**CSRF Considerations:** [Inference] Same-origin requests with credentials are potentially vulnerable to CSRF if the server doesn't implement additional protections like CSRF tokens or SameSite cookie attributes.

#### With `include`

**Security Risks:**

- Increased CSRF attack surface
- Credentials sent to cross-origin destinations
- Requires careful CORS configuration
- Cookie leakage if CORS misconfigured

**Required Protections:**

- CSRF tokens for state-changing operations
- Strict CORS origin validation
- SameSite cookie attributes
- Origin header verification server-side

**Example - CSRF Protection with `include`:**

```javascript
// Step 1: Get CSRF token
const tokenResponse = await fetch('https://api.example.com/csrf-token', {
  credentials: 'include'
});
const { token } = await tokenResponse.json();

// Step 2: Include token in state-changing request
await fetch('https://api.example.com/update', {
  method: 'POST',
  credentials: 'include',
  headers: {
    'Content-Type': 'application/json',
    'X-CSRF-Token': token
  },
  body: JSON.stringify({ data: 'value' })
});
```

### Cookie Attributes Interaction

The `credentials` mode works in conjunction with cookie attributes:

#### SameSite Attribute

```http
Set-Cookie: sessionId=abc; SameSite=Strict
Set-Cookie: sessionId=abc; SameSite=Lax
Set-Cookie: sessionId=abc; SameSite=None; Secure
```

**Interaction with `credentials`:**

|credentials|SameSite=Strict|SameSite=Lax|SameSite=None|
|---|---|---|---|
|`omit`|Not sent|Not sent|Not sent|
|`same-origin`|Sent same-origin|Sent same-origin|Sent same-origin|
|`include`|Sent same-site only|Sent cross-site (top-level nav)|Sent cross-origin|

**Example - Cross-Origin Cookie Setup:**

```javascript
// Server must set cookie with proper attributes for cross-origin use
// Server response:
// Set-Cookie: sessionId=abc123; SameSite=None; Secure; HttpOnly

// Client request:
fetch('https://api.example.com/data', {
  credentials: 'include' // Cookie will be sent
});
```

### Error Handling Patterns

#### Detecting Missing Credentials

```javascript
async function authenticatedFetch(url, options = {}) {
  const response = await fetch(url, {
    ...options,
    credentials: 'include'
  });
  
  if (response.status === 401) {
    console.error('Authentication required - credentials missing or invalid');
    // Redirect to login or refresh token
    throw new Error('Unauthorized');
  }
  
  if (response.status === 403) {
    console.error('Forbidden - valid credentials but insufficient permissions');
    throw new Error('Forbidden');
  }
  
  return response;
}
```

#### Handling CORS Credential Errors

```javascript
async function crossOriginAuthFetch(url) {
  try {
    const response = await fetch(url, {
      credentials: 'include'
    });
    return response;
  } catch (error) {
    // CORS errors typically manifest as TypeError
    if (error instanceof TypeError) {
      console.error('CORS error - possible causes:');
      console.error('- Server missing Access-Control-Allow-Credentials header');
      console.error('- Server using wildcard (*) for Access-Control-Allow-Origin');
      console.error('- Network failure');
    }
    throw error;
  }
}
```

### Mode Switching Patterns

#### Dynamic Credential Mode

```javascript
function fetchWithDynamicCredentials(url, requireAuth = false) {
  const isLocalhost = url.startsWith('http://localhost') || 
                      url.startsWith('http://127.0.0.1');
  
  let credentialsMode;
  
  if (isLocalhost) {
    credentialsMode = 'same-origin';
  } else if (requireAuth) {
    credentialsMode = 'include';
  } else {
    credentialsMode = 'omit';
  }
  
  return fetch(url, {
    credentials: credentialsMode
  });
}
```

#### Environment-Based Configuration

```javascript
class APIClient {
  constructor(baseURL, environment = 'production') {
    this.baseURL = baseURL;
    this.credentials = this.getCredentialsMode(environment);
  }
  
  getCredentialsMode(environment) {
    switch (environment) {
      case 'development':
        return 'same-origin';
      case 'staging':
      case 'production':
        return 'include';
      default:
        return 'omit';
    }
  }
  
  async request(endpoint, options = {}) {
    return fetch(`${this.baseURL}${endpoint}`, {
      ...options,
      credentials: this.credentials
    });
  }
}

const api = new APIClient('https://api.example.com', process.env.NODE_ENV);
```

### Performance Considerations

#### Credential Mode Impact

[Inference] Different credential modes may have performance implications:

**`omit`:**

- Fastest - no credential lookup or transmission
- Smallest request size
- No cookie parsing overhead

**`same-origin`:**

- Moderate - conditional credential lookup
- Server must parse cookies for same-origin requests

**`include`:**

- Potential preflight overhead for cross-origin requests
- Larger request headers (cookies included)
- Server-side origin validation overhead

#### Preflight Caching

```javascript
// Preflight responses can be cached to reduce overhead
// Server sends:
// Access-Control-Max-Age: 86400

// Subsequent requests within 24 hours skip preflight
fetch('https://api.example.com/data', {
  credentials: 'include'
});
```

### Browser DevTools Debugging

#### Inspecting Credential Inclusion

**Network Tab:**

1. Look for `Cookie` header in Request Headers
2. Check `Set-Cookie` in Response Headers
3. Examine preflight OPTIONS request

**Console Errors:**

```
Access to fetch at 'https://api.example.com/data' from origin 
'https://example.com' has been blocked by CORS policy: 
The value of the 'Access-Control-Allow-Credentials' header in 
the response is '' which must be 'true' when the request's 
credentials mode is 'include'.
```

**Application Tab:**

1. Check Cookies section for domain and path
2. Verify SameSite and Secure attributes
3. Confirm cookie is not expired

### Real-World Implementation Examples

#### Multi-Tenant SaaS Application

```javascript
class TenantAPI {
  constructor(tenantSubdomain) {
    this.baseURL = `https://${tenantSubdomain}.saas-app.com`;
  }
  
  async authenticatedRequest(endpoint, options = {}) {
    return fetch(`${this.baseURL}${endpoint}`, {
      ...options,
      credentials: 'include', // Share auth across tenant subdomains
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      }
    });
  }
  
  async publicRequest(endpoint) {
    return fetch(`${this.baseURL}${endpoint}`, {
      credentials: 'omit' // No auth needed for public endpoints
    });
  }
}
```

#### Mixed Content Types

```javascript
async function loadDashboard() {
  // Authenticated user data - same origin
  const userPromise = fetch('/api/user', {
    credentials: 'same-origin'
  });
  
  // Public market data - cross origin, no auth needed
  const marketPromise = fetch('https://api.market-data.com/rates', {
    credentials: 'omit'
  });
  
  // Cross-origin authenticated analytics
  const analyticsPromise = fetch('https://analytics.company.com/stats', {
    credentials: 'include'
  });
  
  const [user, market, analytics] = await Promise.all([
    userPromise.then(r => r.json()),
    marketPromise.then(r => r.json()),
    analyticsPromise.then(r => r.json())
  ]);
  
  return { user, market, analytics };
}
```

### Testing Different Credential Modes

#### Unit Testing Pattern

```javascript
// Mock fetch for testing
global.fetch = jest.fn();

test('uses correct credentials mode for public API', async () => {
  fetch.mockResolvedValue({
    ok: true,
    json: async () => ({ data: 'public' })
  });
  
  await fetchPublicData();
  
  expect(fetch).toHaveBeenCalledWith(
    expect.any(String),
    expect.objectContaining({
      credentials: 'omit'
    })
  );
});

test('uses include mode for cross-origin auth', async () => {
  fetch.mockResolvedValue({
    ok: true,
    json: async () => ({ user: 'data' })
  });
  
  await fetchUserFromAuthAPI();
  
  expect(fetch).toHaveBeenCalledWith(
    expect.stringContaining('auth-api.example.com'),
    expect.objectContaining({
      credentials: 'include'
    })
  );
});
```

---

## Cache Control Options

The `cache` option in the Fetch API controls how the request interacts with the browser's HTTP cache, determining whether to use cached responses, when to validate them, and how to store new responses.

### `default` Mode

Standard browser caching behavior following HTTP cache semantics.

**Behavior:**

- Checks HTTP cache first for valid cached response
- If fresh cache entry exists (within `max-age` or not expired), returns it immediately without network request
- If stale cache entry exists, performs conditional request (with `If-None-Match` or `If-Modified-Since`)
- If no cache entry, performs normal network request
- Stores response according to cache headers (`Cache-Control`, `Expires`, `ETag`, etc.)

**Cache decision logic:**

```
1. Check cache for entry
2. If found and fresh → Return cached response
3. If found and stale → Send conditional request (304 possible)
4. If not found → Send normal request
5. Store response if cacheable
```

**Use cases:**

- Standard web requests where normal caching is desired
- Performance optimization through standard HTTP caching
- Most API calls where caching semantics are appropriate
- Default behavior for most applications

**Example:**

```javascript
fetch('/api/data', {
  cache: 'default'
})
// Respects Cache-Control: max-age=3600
// Will use cached response if less than 1 hour old
```

**Server header interaction:**

```javascript
// Server response:
// Cache-Control: max-age=300
// ETag: "abc123"

// First request - cache miss
fetch('/api/profile', {cache: 'default'}) // Network request

// Second request within 5 minutes - cache hit
fetch('/api/profile', {cache: 'default'}) // Returns cached, no network

// Third request after 5 minutes - conditional
fetch('/api/profile', {cache: 'default'}) 
// Sends: If-None-Match: "abc123"
// Gets: 304 Not Modified (or 200 with new content)
```

### `no-store` Mode

Completely bypasses cache for both reading and writing.

**Behavior:**

- Never checks cache for existing entries
- Always performs network request
- Never stores response in cache
- Behaves as if cache doesn't exist
- Most aggressive "always fresh" option

**Use cases:**

- Highly sensitive data that should never be cached (passwords, tokens, PII)
- Real-time data where even brief caching is unacceptable
- One-time use responses (password reset tokens, nonces)
- Financial transactions or time-sensitive operations
- Compliance requirements against caching

**Example:**

```javascript
fetch('/api/account/balance', {
  cache: 'no-store'
})
// Always hits network
// Response never stored in cache
// No trace in cache after request
```

**Security-critical usage:**

```javascript
async function loginUser(credentials) {
  return fetch('/auth/login', {
    method: 'POST',
    cache: 'no-store', // Never cache credentials or tokens
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify(credentials)
  });
}

async function getAccountDetails() {
  return fetch('/api/account/sensitive', {
    cache: 'no-store', // Fresh data always, no caching
    headers: {'Authorization': `Bearer ${token}`}
  });
}
```

**Comparison with server headers:**

- `cache: 'no-store'` in fetch → Client-side enforcement
- `Cache-Control: no-store` from server → Server instruction
- Using both provides defense in depth

### `reload` Mode

Bypasses cache on read but allows writing to cache.

**Behavior:**

- Ignores any cached entries, always performs network request
- Does not send conditional headers (`If-None-Match`, `If-Modified-Since`)
- Unconditional network request (cannot receive 304)
- Stores response in cache according to cache headers
- Similar to "hard refresh" or Ctrl+Shift+R in browsers

**Use cases:**

- Force refresh of potentially stale data
- User-initiated refresh actions
- Cache invalidation scenarios
- Ensuring absolutely latest version is retrieved
- Debugging cache issues

**Example:**

```javascript
fetch('/api/news', {
  cache: 'reload'
})
// Ignores cached response (even if fresh)
// Performs unconditional GET
// Server must send full response (no 304)
// New response stored in cache
```

**User-initiated refresh:**

```javascript
document.getElementById('refreshButton').addEventListener('click', async () => {
  const data = await fetch('/api/dashboard', {
    cache: 'reload' // Force fresh data
  }).then(r => r.json());
  
  updateUI(data);
});
```

**Cache invalidation pattern:**

```javascript
async function updateAndRefresh() {
  // 1. Update data on server
  await fetch('/api/data', {
    method: 'PUT',
    body: JSON.stringify(newData)
  });
  
  // 2. Force reload to get updated version
  const fresh = await fetch('/api/data', {
    cache: 'reload' // Bypass stale cache
  }).then(r => r.json());
  
  return fresh;
}
```

### `no-cache` Mode

Validates cached entries before using them.

**Behavior:**

- Checks cache for entries
- If entry exists, performs conditional request with validation headers
- Sends `If-None-Match` (with ETag) or `If-Modified-Since` (with Last-Modified)
- Can receive 304 Not Modified if content unchanged
- Always contacts server but may save bandwidth with 304
- Stores response according to cache headers

**Difference from `reload`:**

- `no-cache`: Always validates, but can use cached content if server confirms freshness (304)
- `reload`: Never validates, always gets full response

**Use cases:**

- Ensuring data freshness while allowing bandwidth optimization
- Situations where validation is required but 304 responses are acceptable
- Balance between freshness and performance
- APIs with good ETag support

**Example:**

```javascript
fetch('/api/content', {
  cache: 'no-cache'
})
// Has cached entry with ETag: "xyz789"
// Sends: If-None-Match: "xyz789"
// Receives: 304 Not Modified → Uses cached response
// OR: 200 OK with new content → Uses and caches new response
```

**Conditional request flow:**

```javascript
// Cached response metadata:
// ETag: "v1.2.3"
// Last-Modified: Wed, 21 Oct 2024 07:28:00 GMT

fetch('/api/resource', {
  cache: 'no-cache'
})
// Request includes:
// If-None-Match: "v1.2.3"
// If-Modified-Since: Wed, 21 Oct 2024 07:28:00 GMT

// Server response A (unchanged):
// 304 Not Modified
// → Browser uses cached response body

// Server response B (changed):
// 200 OK
// ETag: "v1.2.4"
// → Browser uses new response and updates cache
```

**Practical comparison:**

```javascript
// Scenario: Cached entry exists, content unchanged on server

// With 'no-cache': 
// - Small request with validation headers
// - 304 response (no body)
// - Uses cached response
// - Bandwidth: ~1-2 KB

// With 'reload':
// - Full request
// - 200 response with complete body
// - Replaces cached response with identical content
// - Bandwidth: Full response size (could be MBs)
```

### `force-cache` Mode

Prefers cached entries regardless of staleness.

**Behavior:**

- Checks cache for any entry (fresh or stale)
- If any cached entry exists, uses it immediately without validation
- Ignores cache expiration (`max-age`, `Expires`)
- Only performs network request if no cache entry exists
- Does not send conditional headers
- Stores new responses according to cache headers

**Use cases:**

- Performance-critical scenarios where staleness is acceptable
- Offline-first applications
- Reducing server load when approximate data is sufficient
- Resource-constrained environments (limited bandwidth)
- Non-critical or slow-changing data

**Example:**

```javascript
fetch('/api/config', {
  cache: 'force-cache'
})
// Cached entry expired 2 hours ago → Still uses it
// No network request unless cache is completely empty
```

**Offline-first pattern:**

```javascript
async function getDataOfflineFirst(url) {
  try {
    // Try cache first, even if stale
    const response = await fetch(url, {
      cache: 'force-cache'
    });
    return await response.json();
  } catch (error) {
    // If cache miss and network fails
    throw new Error('No cached data and network unavailable');
  }
}
```

**Performance optimization:**

```javascript
// Load non-critical resources from cache
async function loadStaticAssets() {
  const assets = [
    '/static/logo.png',
    '/static/footer-content.json',
    '/static/translations.json'
  ];
  
  return Promise.all(
    assets.map(url => 
      fetch(url, {cache: 'force-cache'}) // Use stale cache if available
    )
  );
}
```

**Staleness trade-off:**

```javascript
// User profile that changes infrequently
fetch('/api/user/preferences', {
  cache: 'force-cache' // Acceptable if stale
})

// vs.

// Stock price that must be current
fetch('/api/stocks/current-price', {
  cache: 'no-store' // Staleness unacceptable
})
```

### `only-if-cached` Mode

Only succeeds if valid cache entry exists.

**Behavior:**

- Only checks cache, never performs network request
- Returns cached entry if it exists and is valid (not expired)
- Fails with network error if no valid cache entry
- Must be used with `mode: 'same-origin'`
- Designed for offline scenarios

**Restriction:** Can only be used with `mode: 'same-origin'`. Using it with other modes causes TypeError.

**Use cases:**

- Checking if resource is available offline
- Guaranteed offline-only operations
- Performance-critical scenarios where network latency is unacceptable
- Testing cache state
- Progressive web apps in offline mode

**Example:**

```javascript
fetch('/api/data', {
  cache: 'only-if-cached',
  mode: 'same-origin'
})
.then(response => {
  // Cache hit - data available offline
  return response.json();
})
.catch(error => {
  // Cache miss - no network attempted
  console.log('Not available offline');
});
```

**Offline availability check:**

```javascript
async function isAvailableOffline(url) {
  try {
    await fetch(url, {
      cache: 'only-if-cached',
      mode: 'same-origin'
    });
    return true; // Cache hit
  } catch {
    return false; // Cache miss
  }
}

// Usage
if (await isAvailableOffline('/api/data')) {
  console.log('Can work offline');
} else {
  console.log('Requires network connection');
}
```

**PWA offline mode:**

```javascript
async function getDataOfflineOnly(url) {
  try {
    const response = await fetch(url, {
      cache: 'only-if-cached',
      mode: 'same-origin'
    });
    
    if (!response.ok) {
      throw new Error('Cached response not OK');
    }
    
    return await response.json();
  } catch (error) {
    throw new Error('Data not available offline');
  }
}
```

**Invalid usage [Unverified - exact error message may vary]:**

```javascript
// This will throw TypeError
fetch('https://api.example.com/data', {
  cache: 'only-if-cached',
  mode: 'cors' // Invalid combination
})
// TypeError: Failed to fetch
```

### Cache Mode Comparison Table

|Mode|Checks Cache|Uses Stale|Validates|Network if No Cache|Writes Cache|
|---|---|---|---|---|---|
|`default`|Yes|No|If stale|Yes|Yes|
|`no-store`|No|N/A|No|Always|No|
|`reload`|No|N/A|No|Always|Yes|
|`no-cache`|Yes|No|Always|Yes|Yes|
|`force-cache`|Yes|Yes|No|Yes|Yes|
|`only-if-cached`|Yes|No|No|Never|No|

### Cache Mode Selection Decision Tree

**Need guaranteed fresh data?**

- Critical freshness (sensitive/real-time) → `no-store`
- Important freshness (willing to validate) → `no-cache`
- Standard freshness (trust HTTP semantics) → `default`

**Performance priority over freshness?**

- Acceptable to use stale → `force-cache`
- Must be offline-capable → `only-if-cached` + `same-origin`

**User-initiated action?**

- Hard refresh / force reload → `reload`

**Never cache this data?**

- Security/privacy/compliance → `no-store`

### Interaction with HTTP Cache Headers

**Server `Cache-Control` headers affecting fetch `cache` option:**

```javascript
// Server sends: Cache-Control: no-store
fetch('/api/data', {cache: 'default'})
// Browser respects server directive, won't cache even though 'default'

// Server sends: Cache-Control: max-age=3600
fetch('/api/data', {cache: 'default'})
// Cached for 1 hour

fetch('/api/data', {cache: 'force-cache'})
// Uses cache even after 1 hour expires

fetch('/api/data', {cache: 'no-cache'})
// Ignores max-age, always validates
```

**Client `cache` option overriding server headers [Inference - browser-side control]:**

```javascript
// Server says: Cache-Control: max-age=86400 (cache for 1 day)

fetch('/api/data', {cache: 'no-store'})
// Client overrides, doesn't cache despite server instruction

fetch('/api/data', {cache: 'reload'})
// Client overrides, bypasses existing cache despite fresh entry
```

### Common Patterns and Best Practices

**API data freshness levels:**

```javascript
// Real-time critical data
const stockPrice = await fetch('/api/stock-price', {
  cache: 'no-store'
});

// Important but validates OK
const userProfile = await fetch('/api/profile', {
  cache: 'no-cache'
});

// Standard resources
const config = await fetch('/api/config', {
  cache: 'default'
});

// Static/slow-changing
const translations = await fetch('/i18n/en.json', {
  cache: 'force-cache'
});
```

**User-triggered refresh:**

```javascript
let lastFetchMode = 'default';

async function fetchData(userTriggered = false) {
  const mode = userTriggered ? 'reload' : 'default';
  lastFetchMode = mode;
  
  return fetch('/api/data', {
    cache: mode
  }).then(r => r.json());
}

// Auto-refresh
setInterval(() => fetchData(false), 60000); // Uses cache if fresh

// Manual refresh button
refreshBtn.onclick = () => fetchData(true); // Forces new data
```

**Offline-first with fallback:**

```javascript
async function fetchWithOfflineFallback(url) {
  try {
    // Try network first (default caching)
    return await fetch(url, {
      cache: 'default'
    });
  } catch (networkError) {
    // Network failed, try cache only
    try {
      return await fetch(url, {
        cache: 'only-if-cached',
        mode: 'same-origin'
      });
    } catch (cacheError) {
      throw new Error('Unavailable online and offline');
    }
  }
}
```

**Cache invalidation after mutation:**

```javascript
async function updateResource(id, data) {
  // 1. Send update
  await fetch(`/api/resource/${id}`, {
    method: 'PUT',
    cache: 'no-store', // Don't cache mutation
    body: JSON.stringify(data)
  });
  
  // 2. Fetch updated version, bypassing stale cache
  return fetch(`/api/resource/${id}`, {
    cache: 'reload' // Force fresh data
  }).then(r => r.json());
}
```

**Conditional caching based on network:**

```javascript
async function smartFetch(url) {
  const connection = navigator.connection;
  
  // On slow connection, prefer cache
  if (connection && connection.effectiveType === '2g') {
    return fetch(url, {cache: 'force-cache'});
  }
  
  // On fast connection, validate
  if (connection && connection.effectiveType === '4g') {
    return fetch(url, {cache: 'no-cache'});
  }
  
  // Default behavior
  return fetch(url, {cache: 'default'});
}
```

**Privacy-sensitive requests:**

```javascript
async function handleSensitiveData() {
  // Never cache auth tokens
  const authResponse = await fetch('/auth/token', {
    cache: 'no-store'
  });
  
  // Never cache PII
  const userData = await fetch('/api/user/private-data', {
    cache: 'no-store',
    credentials: 'include'
  });
  
  // Never cache payment info
  const paymentData = await fetch('/api/payment-methods', {
    cache: 'no-store'
  });
  
  return {authResponse, userData, paymentData};
}
```

### Cache Behavior with Different Request Methods

**GET requests:** All cache modes fully applicable. GET is the only method that typically interacts meaningfully with HTTP cache.

**POST/PUT/DELETE requests:**

```javascript
// POST with cache option
fetch('/api/data', {
  method: 'POST',
  cache: 'no-store', // Common for mutations
  body: JSON.stringify(data)
})
// Cache modes apply to response, but mutations rarely cached by browsers
```

[Inference] Most browsers don't cache POST/PUT/DELETE responses by default regardless of cache headers, though `no-store` provides explicit guarantee.

### Service Worker Cache vs Fetch Cache Option

These are separate caching layers:

**Fetch `cache` option:**

- Controls browser's HTTP cache
- Automatic based on HTTP headers
- Shared across tabs/windows
- Cleared by browser cache clearing

**Service Worker caches:**

```javascript
// Service Worker Cache API (separate from fetch cache option)
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      return cached || fetch(event.request, {
        cache: 'default' // Still uses HTTP cache
      }).then(response => {
        return caches.open('v1').then(cache => {
          cache.put(event.request, response.clone());
          return response;
        });
      });
    })
  );
});
```

**Both can be used together:**

- Service Worker intercepts first
- Can check Service Worker cache
- Falls back to fetch with cache option
- Fetch uses HTTP cache
- Response can be stored in both caches

---

## Redirect Handling

### Redirect Types and Fetch Behavior

Fetch API handles HTTP redirects automatically but with specific rules based on status codes:

**3xx Status Codes:**

- **301 Moved Permanently** - Followed automatically, method may change to GET
- **302 Found** - Followed automatically, method may change to GET
- **303 See Other** - Followed automatically, always changes to GET
- **307 Temporary Redirect** - Followed automatically, preserves method and body
- **308 Permanent Redirect** - Followed automatically, preserves method and body

```javascript
fetch('https://api.example.com/redirect')
// Automatically follows to final destination
// Returns response from final location
```

### Redirect Mode Control

```javascript
fetch('https://api.example.com/data', {
  redirect: 'follow'  // default behavior
});

fetch('https://api.example.com/data', {
  redirect: 'error'   // reject on any redirect
});

fetch('https://api.example.com/data', {
  redirect: 'manual'  // return opaque redirect response
});
```

**`redirect: 'follow'`** (default)

- Automatically follows up to a browser-specific limit (typically 20 redirects)
- Returns final response after all redirects complete
- Transparent to application code

**`redirect: 'error'`**

- Rejects promise if server returns any 3xx status
- Useful when redirects indicate misconfiguration or security issues

```javascript
fetch('https://api.example.com/data', {
  redirect: 'error'
})
.catch(error => {
  // Catches any redirect attempt
  console.error('Unexpected redirect:', error);
});
```

**`redirect: 'manual'`**

- Returns opaque response (type: 'opaqueredirect')
- Cannot access response body, headers, or status
- Primarily for Service Workers

```javascript
fetch('https://api.example.com/data', {
  redirect: 'manual'
})
.then(response => {
  console.log(response.type);  // 'opaqueredirect'
  console.log(response.status); // 0
  console.log(response.url);    // empty string
});
```

### Method Preservation Across Redirects

**301/302 redirect behavior:**

```javascript
// Original POST request
fetch('https://api.example.com/old-endpoint', {
  method: 'POST',
  body: JSON.stringify({ data: 'value' })
});

// Server responds: 301 → https://api.example.com/new-endpoint
// Browser converts to GET request (body discarded)
```

Historical behavior causes POST/PUT/PATCH/DELETE to become GET on 301/302 redirects. This follows legacy browser behavior for compatibility.

**307/308 redirect behavior:**

```javascript
// Original POST request
fetch('https://api.example.com/old-endpoint', {
  method: 'POST',
  body: JSON.stringify({ data: 'value' })
});

// Server responds: 307 → https://api.example.com/new-endpoint
// Browser preserves POST method and re-sends body
```

307 and 308 guarantee method and body preservation. Use these for redirecting non-GET requests.

### URL Access After Redirects

```javascript
fetch('https://api.example.com/redirect-chain')
  .then(response => {
    console.log(response.url);  // Final URL after all redirects
    // Cannot access intermediate URLs in redirect chain
  });
```

`response.url` contains the final destination URL only. The fetch API does not expose intermediate redirect URLs in the chain.

### CORS Requirements for Redirects

**Each redirect must include CORS headers:**

```javascript
// From https://myapp.com
fetch('https://api1.example.com/redirect')
```

Required headers at each step:

1. **Initial response (redirect):**
    
    ```
    HTTP/1.1 302 Found
    Location: https://api2.example.com/data
    Access-Control-Allow-Origin: https://myapp.com
    ```
    
2. **Final response:**
    
    ```
    HTTP/1.1 200 OK
    Access-Control-Allow-Origin: https://myapp.com
    ```
    

Missing CORS headers on any redirect response causes the entire request to fail.

### Cross-Origin Redirect Limitations

**Same-origin redirects:**

```javascript
// From https://myapp.com
fetch('https://myapp.com/redirect')
// Can redirect anywhere without CORS restrictions on redirect response
```

**Cross-origin redirects:**

```javascript
// From https://myapp.com
fetch('https://api.example.com/redirect')
// All redirect responses need CORS headers
// Final destination needs CORS headers
```

[Inference] Same-origin initial requests can redirect to cross-origin destinations, but the redirect response itself doesn't require CORS headers in this case—only the final destination does.

### Redirect Loops and Limits

```javascript
fetch('https://api.example.com/infinite-redirect')
// Browser enforces maximum redirect count
```

Browsers typically limit redirects to 20 hops. Exceeding this causes:

```
TypeError: Failed to fetch
```

The exact limit varies by browser. [Unverified] Chrome, Firefox, and Safari use 20 as the default limit, but this may have changed.

### Body Consumption in Redirect Chains

```javascript
fetch('https://api.example.com/redirect', {
  method: 'POST',
  body: JSON.stringify({ data: 'value' })
});
```

**For 307/308 redirects:**

- Body must be re-transmitted to each redirected location
- Body must be replayable (string, ArrayBuffer, or Blob)
- Streams cannot be replayed across redirects

```javascript
// This will fail on 307/308 redirects
const stream = new ReadableStream({...});
fetch('https://api.example.com/redirect', {
  method: 'POST',
  body: stream  // Non-replayable
});
// Error: Body stream already consumed
```

### Credentials Across Redirect Boundaries

```javascript
fetch('https://api.example.com/redirect', {
  credentials: 'include'
});
```

**Same-origin redirects:**

- Credentials (cookies, auth headers) preserved automatically

**Cross-origin redirects:**

- Credentials handling depends on final destination
- `credentials: 'include'` sends credentials to final cross-origin destination if CORS allows
- `credentials: 'same-origin'` strips credentials when redirecting cross-origin

```javascript
// From https://myapp.com
fetch('https://api1.example.com/redirect', {
  credentials: 'same-origin'
});
// Redirects to https://api2.example.com/data
// Credentials NOT sent to api2.example.com
```

### Header Preservation

**Standard headers:** Most standard request headers are preserved across redirects:

- `Accept`
- `Accept-Language`
- `Content-Type` (when method preserved)
- `User-Agent`

**Custom headers:**

```javascript
fetch('https://api.example.com/redirect', {
  headers: {
    'X-Custom-Header': 'value',
    'Authorization': 'Bearer token'
  }
});
```

Custom headers are preserved on same-origin redirects. Cross-origin redirect behavior for custom headers varies by browser and [Unverified] may be stripped for security reasons in some implementations.

**Authorization header specific behavior:**

```javascript
fetch('https://api.example.com/redirect', {
  headers: { 'Authorization': 'Bearer token' }
});
// Redirects to https://different-domain.com/data
```

[Inference] Browsers typically strip `Authorization` headers when redirecting to a different origin to prevent credential leakage, even if the redirect is followed automatically.

### Referrer Policy and Redirects

```javascript
fetch('https://api.example.com/redirect', {
  referrerPolicy: 'no-referrer'
});
```

Referrer policy affects what information is sent in the `Referer` header across redirects:

- `no-referrer` - No referer sent at any step
- `origin` - Only origin sent
- `same-origin` - Referer only for same-origin redirects
- `strict-origin-when-cross-origin` - Full URL for same-origin, origin only for cross-origin HTTPS

The policy applies to each redirect hop individually.

### Timing Information

```javascript
fetch('https://api.example.com/redirect')
  .then(response => {
    // Response received after all redirects complete
    // No way to measure individual redirect timing via fetch API
  });
```

Performance API provides redirect timing:

```javascript
performance.getEntriesByType('navigation').forEach(entry => {
  console.log('Redirect time:', entry.redirectEnd - entry.redirectStart);
  console.log('Redirect count:', entry.redirectCount);
});
```

This only works for navigation requests, not fetch() calls. [Unverified] Resource Timing API may provide redirect information for fetch requests in some browsers.

### Protocol Downgrades

```javascript
// From HTTPS page
fetch('https://api.example.com/redirect')
// Redirects to http://insecure.example.com/data
```

**HTTPS to HTTP redirects are blocked:**

- Mixed content policy prevents following redirect
- Fetch promise rejects
- Error appears similar to CORS failure

**HTTP to HTTPS redirects are allowed:**

```javascript
// From HTTP page
fetch('http://api.example.com/redirect')
// Can redirect to https://secure.example.com/data
```

This follows standard mixed content rules where downgrading security is blocked but upgrading is permitted.

### Redirect with Fragment Identifiers

```javascript
fetch('https://api.example.com/redirect')
// Server responds: 302 → https://example.com/data#section
```

Fragment identifiers (`#section`) in redirect `Location` headers are preserved in `response.url` but are not sent to the server. The browser handles fragments client-side.

```javascript
fetch('https://api.example.com/data#section')
  .then(response => {
    console.log(response.url);  // Includes #section
  });
```

The fragment is never transmitted in the HTTP request; it's purely for client-side processing.

### Conditional Redirects Based on Request Headers

Servers may redirect based on request headers:

```javascript
// Request with Accept: application/json
fetch('https://api.example.com/resource', {
  headers: { 'Accept': 'application/json' }
});
// May redirect to JSON-specific endpoint

// Request with Accept: text/html
fetch('https://api.example.com/resource', {
  headers: { 'Accept': 'text/html' }
});
// May redirect to HTML-specific endpoint
```

This is content negotiation via redirects. Headers are preserved and influence redirect destination.

### POST to GET Conversion Workarounds

When 307/308 are unavailable but POST must be preserved:

```javascript
fetch('https://api.example.com/old-endpoint', {
  method: 'POST',
  redirect: 'manual'
})
.then(response => {
  if (response.type === 'opaqueredirect') {
    // Handle redirect manually
    // Note: Cannot access Location header directly
  }
});
```

[Inference] Manual redirect handling with fetch API is severely limited due to opaque response restrictions. Alternative approaches like server-side proxy or client-side logic to construct new URL are typically more practical.

### Redirect Security Considerations

**Open redirect vulnerabilities:**

```javascript
// Server redirects to user-supplied URL
fetch('https://api.example.com/redirect?url=https://evil.com')
```

Fetch API follows these redirects automatically. Applications should validate redirect destinations when dealing with user-controlled redirect targets.

**Redirect-based timing attacks:**

```javascript
const start = performance.now();
fetch('https://api.example.com/check-resource')
  .then(() => {
    const duration = performance.now() - start;
    // Duration may reveal information about intermediate redirects
  });
```

[Inference] Timing differences in redirect chains could potentially leak information about server-side logic or resource existence, though practical exploitation depends on network variance.

### Service Worker Redirect Interception

```javascript
// In service worker
self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request, { redirect: 'manual' })
      .then(response => {
        if (response.type === 'opaqueredirect') {
          // Service worker can inspect and modify redirect behavior
          // Has access to Location header
          const location = response.headers.get('Location');
          return fetch(location);
        }
        return response;
      })
  );
});
```

Service Workers have special permissions with `redirect: 'manual'` that regular page contexts lack, including access to redirect headers.

### Relative vs Absolute Redirect Locations

```javascript
fetch('https://api.example.com/old/path/endpoint')
// Server responds with relative Location
// Location: ../new/endpoint
```

Browsers resolve relative `Location` headers based on the current request URL:

- `../new/endpoint` resolves to `https://api.example.com/new/endpoint`
- `/absolute/path` resolves to `https://api.example.com/absolute/path`
- `//other.example.com/path` resolves to `https://other.example.com/path`

Full URL resolution rules follow RFC 3986.

### Cached Redirect Handling

**301 and 308 (permanent redirects):**

```javascript
fetch('https://api.example.com/old-endpoint')
// First request: 301 → https://api.example.com/new-endpoint
// Subsequent requests may go directly to new-endpoint
```

Browsers cache permanent redirects. Future requests to the original URL may skip it entirely and go directly to the redirect target. This caching behavior varies by browser and `Cache-Control` headers.

**302, 303, 307 (temporary redirects):** Not typically cached without explicit `Cache-Control` directives. Each request follows the redirect chain.

### Redirect Count Access

```javascript
fetch('https://api.example.com/redirect-chain')
  .then(response => {
    // No direct way to get redirect count from response object
  });
```

Fetch API does not expose redirect count. For navigation requests, use Performance API:

```javascript
performance.getEntriesByType('navigation')[0].redirectCount
```

For fetch requests, [Unverified] redirect count is not accessible through standard APIs.

### Query Parameter Preservation

```javascript
fetch('https://api.example.com/redirect?key=value&token=abc123')
// Server responds: 302 → Location: /new-endpoint
```

**Relative redirects without query string:** Query parameters from original request are NOT automatically carried to redirect destination. The redirect `Location` must explicitly include them.

**Absolute redirects:**

```
Location: https://api.example.com/new-endpoint?key=value&token=abc123
```

Server must construct complete URL with any necessary query parameters.

### Multiple Consecutive Same-Origin Redirects

```javascript
fetch('https://api.example.com/redirect1')
// → https://api.example.com/redirect2
// → https://api.example.com/redirect3
// → https://api.example.com/final
```

Each redirect is treated independently. Headers, CORS checks (if cross-origin mid-chain), and method preservation rules apply at each step. Performance implications increase with chain length.

### Integrity Attribute and Redirects

```javascript
fetch('https://cdn.example.com/library.js', {
  integrity: 'sha384-abc123...'
})
// Redirects to https://cdn2.example.com/library.js
```

Subresource integrity verification occurs on the final resource after all redirects. The integrity hash must match the final response content, not intermediate redirect responses.

### Redirect with Authentication Challenges

```javascript
fetch('https://api.example.com/protected', {
  headers: { 'Authorization': 'Bearer token' }
})
// Server responds: 302 → /login
```

[Inference] If authentication fails, servers may redirect to login pages. For API contexts, returning 401 with appropriate headers is typically preferred over redirects, as redirect chains can complicate error handling in application code.

---

## Referrer and ReferrerPolicy

### Referrer Header Mechanics

#### Default Referrer Behavior

When making fetch requests, browsers automatically include a `Referer` header (note the historical misspelling) containing the URL of the page making the request. This allows servers to track navigation patterns and implement security measures.

```javascript
// Default behavior - browser sends current page URL as referrer
fetch('https://api.example.com/data')
  .then(response => response.json());
// Referer header: https://yoursite.com/page
```

#### Custom Referrer Values

The `referrer` option explicitly controls what referrer information is sent:

```javascript
// Send specific URL as referrer
fetch('https://api.example.com/data', {
  referrer: 'https://custom-referrer.com/source'
});

// Send no referrer
fetch('https://api.example.com/data', {
  referrer: ''
});

// Use client/document (default browser behavior)
fetch('https://api.example.com/data', {
  referrer: 'about:client'
});
```

Accepted values:

- Empty string `''`: Omit the Referer header entirely
- `'about:client'`: Use the default referrer (current page URL)
- Absolute URL string: Send specific URL as referrer (must be same-origin or fail)

### ReferrerPolicy Configuration

#### Policy Directives

The `referrerPolicy` option controls how much referrer information is sent under different conditions:

```javascript
// Strict: never send referrer
fetch('https://api.example.com/data', {
  referrerPolicy: 'no-referrer'
});

// Send full URL for same-origin, nothing for cross-origin
fetch('https://api.example.com/data', {
  referrerPolicy: 'same-origin'
});

// Send origin only (no path/query) for cross-origin
fetch('https://api.example.com/data', {
  referrerPolicy: 'strict-origin'
});
```

#### Complete Policy Options

**`no-referrer`** Never send referrer information under any circumstances.

```javascript
fetch('/api/sensitive', { referrerPolicy: 'no-referrer' });
// Referer header: (not sent)
```

**`no-referrer-when-downgrade`** (default) Send full referrer to same or more secure destinations (HTTPS→HTTPS, HTTP→HTTP, HTTP→HTTPS), but not when downgrading security (HTTPS→HTTP).

```javascript
// From https://site.com/page
fetch('https://api.example.com/data', { 
  referrerPolicy: 'no-referrer-when-downgrade' 
});
// Referer: https://site.com/page

fetch('http://api.example.com/data', { 
  referrerPolicy: 'no-referrer-when-downgrade' 
});
// Referer: (not sent - downgrade from HTTPS to HTTP)
```

**`origin`** Send only the origin (protocol, domain, port), stripping path and query parameters.

```javascript
// From https://site.com/admin/users?id=123
fetch('https://api.example.com/data', { 
  referrerPolicy: 'origin' 
});
// Referer: https://site.com
```

**`origin-when-cross-origin`** Send full URL for same-origin requests, but only origin for cross-origin requests.

```javascript
// From https://site.com/page/detail
fetch('https://site.com/api/data', { 
  referrerPolicy: 'origin-when-cross-origin' 
});
// Referer: https://site.com/page/detail

fetch('https://other.com/api/data', { 
  referrerPolicy: 'origin-when-cross-origin' 
});
// Referer: https://site.com
```

**`same-origin`** Send full referrer for same-origin requests, no referrer for cross-origin.

```javascript
// From https://site.com/page
fetch('https://site.com/api/data', { 
  referrerPolicy: 'same-origin' 
});
// Referer: https://site.com/page

fetch('https://other.com/api/data', { 
  referrerPolicy: 'same-origin' 
});
// Referer: (not sent)
```

**`strict-origin`** Send only origin to same-or-more-secure destinations, nothing when downgrading.

```javascript
// From https://site.com/admin
fetch('https://api.example.com/data', { 
  referrerPolicy: 'strict-origin' 
});
// Referer: https://site.com

fetch('http://api.example.com/data', { 
  referrerPolicy: 'strict-origin' 
});
// Referer: (not sent - downgrade)
```

**`strict-origin-when-cross-origin`** Send full URL for same-origin, only origin for cross-origin to same-or-more-secure destinations, nothing when downgrading.

```javascript
// From https://site.com/page
fetch('https://site.com/api/data', { 
  referrerPolicy: 'strict-origin-when-cross-origin' 
});
// Referer: https://site.com/page

fetch('https://other.com/api/data', { 
  referrerPolicy: 'strict-origin-when-cross-origin' 
});
// Referer: https://site.com

fetch('http://other.com/api/data', { 
  referrerPolicy: 'strict-origin-when-cross-origin' 
});
// Referer: (not sent - downgrade)
```

**`unsafe-url`** Always send the full URL as referrer, regardless of security. [Unverified: This exposes potentially sensitive URL information in all contexts].

```javascript
// From https://site.com/user/profile?token=secret
fetch('http://third-party.com/tracking', { 
  referrerPolicy: 'unsafe-url' 
});
// Referer: https://site.com/user/profile?token=secret
// Warning: Exposes query parameters even on downgrade
```

### Policy Hierarchy and Precedence

#### Multiple Policy Sources

Referrer policies can be set at multiple levels with specific precedence:

1. Fetch request `referrerPolicy` option (highest priority)
2. `<meta name="referrer">` tag
3. `Referrer-Policy` HTTP response header
4. Browser default (usually `no-referrer-when-downgrade`)

```javascript
// Request-level policy overrides all others
fetch('/api/data', { 
  referrerPolicy: 'no-referrer' 
});
// Uses no-referrer regardless of meta tag or headers
```

#### Document-Level Policies

```html
<!-- Set default for all requests from this page -->
<meta name="referrer" content="strict-origin-when-cross-origin">
```

```javascript
// This request inherits the meta tag policy
fetch('/api/data');

// This request overrides it
fetch('/api/sensitive', { referrerPolicy: 'no-referrer' });
```

### Security Considerations

#### Privacy Protection Patterns

Preventing referrer leakage for sensitive URLs:

```javascript
// Admin panel requests - hide referrer completely
fetch('/api/admin/users', {
  referrerPolicy: 'no-referrer',
  credentials: 'include'
});

// Public API with sensitive query params
const url = new URL('/search', window.location.origin);
url.searchParams.set('query', sensitiveSearchTerm);

fetch(url, {
  referrerPolicy: 'origin' // Strip query params from referrer
});
```

#### Third-Party API Integration

Controlling information exposure to external services:

```javascript
// Analytics or tracking - minimal exposure
fetch('https://analytics.third-party.com/event', {
  method: 'POST',
  referrerPolicy: 'strict-origin', // Only send domain, not path
  body: JSON.stringify({ event: 'page_view' })
});

// Payment processor - no referrer leakage
fetch('https://payment-gateway.com/checkout', {
  method: 'POST',
  referrerPolicy: 'no-referrer',
  body: JSON.stringify(paymentData)
});
```

#### HTTPS to HTTP Downgrade Protection

[Inference: Browsers typically block or warn about HTTPS→HTTP downgrades]:

```javascript
// From HTTPS page
fetch('http://insecure-api.com/data', {
  referrerPolicy: 'strict-origin'
});
// Referer: (not sent due to downgrade protection)

// Explicitly allow (not recommended)
fetch('http://insecure-api.com/data', {
  referrerPolicy: 'unsafe-url'
});
// Referer: https://yoursite.com/page (sent despite downgrade)
```

### Cross-Origin Resource Sharing (CORS) Interaction

#### Preflight Request Referrers

CORS preflight OPTIONS requests include referrer information based on the specified policy:

```javascript
fetch('https://api.other-domain.com/data', {
  method: 'POST',
  referrerPolicy: 'origin',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ data: 'value' })
});
// Preflight OPTIONS request:
// Referer: https://yoursite.com

// Actual POST request:
// Referer: https://yoursite.com
```

#### Conditional Referrer for CORS

Adjusting referrer policy based on destination:

```javascript
function fetchWithAdaptiveReferrer(url, options = {}) {
  const targetOrigin = new URL(url).origin;
  const currentOrigin = window.location.origin;
  
  const referrerPolicy = targetOrigin === currentOrigin
    ? 'same-origin'  // Full referrer for same-origin
    : 'strict-origin'; // Origin only for cross-origin
  
  return fetch(url, {
    ...options,
    referrerPolicy
  });
}

fetchWithAdaptiveReferrer('https://api.example.com/data');
```

### Debugging and Inspection

#### Verifying Sent Referrers

Inspect actual referrer headers in browser DevTools:

```javascript
// Server endpoint to echo headers back
fetch('/api/echo-headers', {
  referrerPolicy: 'strict-origin'
})
  .then(r => r.json())
  .then(headers => {
    console.log('Referer sent:', headers.referer);
  });
```

#### Testing Different Policies

Utility function for testing policy effects:

```javascript
async function testReferrerPolicy(url, policy) {
  const response = await fetch(url, {
    referrerPolicy: policy,
    method: 'GET'
  });
  
  // Some APIs echo back the received headers
  const headers = await response.json();
  console.log(`Policy: ${policy}`);
  console.log(`Referrer received by server: ${headers.referer || '(none)'}`);
  console.log(`Current page: ${window.location.href}`);
  console.log('---');
}

// Test suite
const policies = [
  'no-referrer',
  'origin',
  'strict-origin',
  'strict-origin-when-cross-origin'
];

policies.forEach(policy => 
  testReferrerPolicy('https://httpbin.org/headers', policy)
);
```

### Common Patterns and Use Cases

#### API Key Protection

Preventing API keys in URLs from leaking via referrer:

```javascript
// Bad: API key in URL could leak via referrer
const badUrl = 'https://api.service.com/data?key=secret123';
fetch(badUrl);
// Potential leak if referrer is sent elsewhere

// Good: Use headers + strict referrer policy
fetch('https://api.service.com/data', {
  referrerPolicy: 'no-referrer',
  headers: {
    'Authorization': 'Bearer secret123'
  }
});
```

#### Single Page Application (SPA) Navigation

Managing referrers during client-side routing:

```javascript
// SPA route change handler
function navigateToRoute(path, apiEndpoint) {
  // Update URL without page reload
  window.history.pushState({}, '', path);
  
  // Fetch data with appropriate referrer
  fetch(apiEndpoint, {
    // Use origin-when-cross-origin to send full URL to same-origin
    // but only origin to external APIs
    referrerPolicy: 'origin-when-cross-origin'
  })
    .then(r => r.json())
    .then(data => updateView(data));
}
```

#### Progressive Enhancement

Fallback for browsers without referrerPolicy support:

```javascript
function safeFetch(url, options = {}) {
  const fetchOptions = { ...options };
  
  // Check if referrerPolicy is supported
  if ('referrerPolicy' in new Request('')) {
    fetchOptions.referrerPolicy = 'strict-origin-when-cross-origin';
  } else {
    // [Inference: Fallback behavior for older browsers]
    // Older browsers may not support referrerPolicy option
    console.warn('referrerPolicy not supported, using browser default');
  }
  
  return fetch(url, fetchOptions);
}
```

#### Content Delivery Networks (CDN)

Optimizing referrer for CDN requests:

```javascript
// Image or asset loading from CDN
fetch('https://cdn.example.com/images/photo.jpg', {
  referrerPolicy: 'no-referrer' // CDN doesn't need referrer info
})
  .then(r => r.blob())
  .then(blob => {
    const img = document.createElement('img');
    img.src = URL.createObjectURL(blob);
    document.body.appendChild(img);
  });
```

### Performance Implications

#### Reduced Header Size

Using restrictive referrer policies can reduce request header size:

```javascript
// Full URL referrer (larger header)
// From: https://example.com/very/long/path/to/page?with=many&query=parameters
fetch('/api/data', { referrerPolicy: 'unsafe-url' });
// Referer: https://example.com/very/long/path/to/page?with=many&query=parameters

// Origin only (smaller header)
fetch('/api/data', { referrerPolicy: 'origin' });
// Referer: https://example.com
```

#### Caching Considerations

[Inference: Referrer headers may affect caching behavior]:

```javascript
// Different referrers might trigger separate cache entries
// Using consistent referrer policy aids caching

fetch('/api/public-data', {
  referrerPolicy: 'no-referrer', // Consistent across all requests
  cache: 'default'
});
```

### Framework-Specific Integration

#### Setting Global Defaults

Wrapper for consistent referrer policy across application:

```javascript
// API client with default policy
class APIClient {
  constructor(baseURL, defaultPolicy = 'strict-origin-when-cross-origin') {
    this.baseURL = baseURL;
    this.defaultPolicy = defaultPolicy;
  }
  
  fetch(endpoint, options = {}) {
    return fetch(`${this.baseURL}${endpoint}`, {
      referrerPolicy: this.defaultPolicy,
      ...options,
      // Allow override if explicitly set
      ...(options.referrerPolicy && { 
        referrerPolicy: options.referrerPolicy 
      })
    });
  }
}

const api = new APIClient('https://api.example.com');
api.fetch('/users'); // Uses default policy
api.fetch('/sensitive', { 
  referrerPolicy: 'no-referrer' 
}); // Override for sensitive endpoint
```

#### Middleware Pattern

Intercepting and modifying referrer policies:

```javascript
function createFetchWithReferrerMiddleware(policyFn) {
  return function enhancedFetch(url, options = {}) {
    const policy = policyFn(url, options);
    return fetch(url, {
      ...options,
      referrerPolicy: policy
    });
  };
}

// Dynamic policy based on URL
const smartFetch = createFetchWithReferrerMiddleware((url) => {
  const urlObj = new URL(url, window.location.origin);
  
  if (urlObj.pathname.includes('/admin/')) {
    return 'no-referrer';
  }
  if (urlObj.origin === window.location.origin) {
    return 'same-origin';
  }
  return 'strict-origin';
});

smartFetch('/admin/users'); // no-referrer
smartFetch('/api/public'); // same-origin
smartFetch('https://external.com/data'); // strict-origin
```

---

## Integrity Checks

### Subresource Integrity (SRI) Basics

Subresource Integrity allows browsers to verify that fetched resources haven't been tampered with by comparing the resource against a cryptographic hash.

```javascript
fetch('https://cdn.example.com/script.js', {
  integrity: 'sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC',
  method: 'GET'
})
.then(response => {
  if (!response.ok) {
    throw new Error('Integrity check failed or resource not found');
  }
  return response.text();
})
.then(content => console.log('Resource verified:', content));
```

### Generating Integrity Hashes

#### Using Node.js Crypto Module

```javascript
const crypto = require('crypto');
const fs = require('fs');

function generateIntegrityHash(filePath, algorithm = 'sha384') {
  const content = fs.readFileSync(filePath);
  const hash = crypto.createHash(algorithm).update(content).digest('base64');
  return `${algorithm}-${hash}`;
}

// Usage
const integrity = generateIntegrityHash('./script.js');
console.log(integrity);
// Output: sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC
```

#### Using Web Crypto API

```javascript
async function generateIntegrityFromResponse(response) {
  const content = await response.arrayBuffer();
  const hashBuffer = await crypto.subtle.digest('SHA-384', content);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  return `sha384-${hashBase64}`;
}

// Usage
fetch('https://cdn.example.com/file.js')
  .then(response => response.clone())
  .then(generateIntegrityFromResponse)
  .then(hash => console.log('Integrity hash:', hash));
```

### Multiple Hash Algorithms

#### Supporting Multiple Algorithms

```javascript
fetch('https://cdn.example.com/library.js', {
  integrity: 'sha256-hash1 sha384-hash2 sha512-hash3',
  method: 'GET'
})
.then(response => response.text());
```

The browser will use the strongest algorithm it supports (sha512 > sha384 > sha256).

#### Generating Multiple Hashes

```javascript
async function generateMultipleHashes(content) {
  const algorithms = ['SHA-256', 'SHA-384', 'SHA-512'];
  const buffer = new TextEncoder().encode(content);
  
  const hashes = await Promise.all(
    algorithms.map(async algo => {
      const hashBuffer = await crypto.subtle.digest(algo, buffer);
      const hashArray = Array.from(new Uint8Array(hashBuffer));
      const hashBase64 = btoa(String.fromCharCode(...hashArray));
      const algoName = algo.toLowerCase().replace('-', '');
      return `${algoName}-${hashBase64}`;
    })
  );
  
  return hashes.join(' ');
}

// Usage
const content = 'console.log("Hello World");';
generateMultipleHashes(content)
  .then(integrity => console.log(integrity));
```

### CORS and Integrity

#### crossorigin Attribute Requirement

```javascript
// When using integrity with cross-origin requests
fetch('https://cdn.example.com/resource.js', {
  integrity: 'sha384-hash',
  mode: 'cors',
  credentials: 'omit'
})
.then(response => {
  // CORS headers must be present on the server
  return response.text();
});
```

#### Handling CORS Errors

```javascript
async function fetchWithIntegrity(url, integrity) {
  try {
    const response = await fetch(url, {
      integrity: integrity,
      mode: 'cors'
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    return await response.text();
    
  } catch (error) {
    if (error.name === 'TypeError') {
      console.error('CORS or integrity check failed');
    }
    throw error;
  }
}
```

### Integrity Check Failures

#### Detecting Integrity Failures

```javascript
fetch('https://cdn.example.com/script.js', {
  integrity: 'sha384-incorrectHash'
})
.then(response => {
  // This won't execute if integrity fails
  console.log('Integrity passed');
  return response.text();
})
.catch(error => {
  // Integrity failure throws a TypeError
  console.error('Integrity check failed:', error.message);
});
```

#### Fallback Strategy

```javascript
async function fetchWithFallback(primaryUrl, fallbackUrl, integrity) {
  try {
    const response = await fetch(primaryUrl, {
      integrity: integrity
    });
    return await response.text();
    
  } catch (primaryError) {
    console.warn('Primary resource failed, trying fallback');
    
    try {
      const fallbackResponse = await fetch(fallbackUrl, {
        integrity: integrity
      });
      return await fallbackResponse.text();
      
    } catch (fallbackError) {
      throw new Error('Both primary and fallback resources failed');
    }
  }
}

// Usage
fetchWithFallback(
  'https://cdn1.example.com/lib.js',
  'https://cdn2.example.com/lib.js',
  'sha384-hash'
);
```

### Custom Integrity Verification

#### Manual Hash Verification

```javascript
async function fetchAndVerify(url, expectedHash, algorithm = 'SHA-384') {
  const response = await fetch(url);
  const content = await response.arrayBuffer();
  
  const hashBuffer = await crypto.subtle.digest(algorithm, content);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  const actualHash = `${algorithm.toLowerCase().replace('-', '')}-${hashBase64}`;
  
  if (actualHash !== expectedHash) {
    throw new Error('Integrity verification failed');
  }
  
  return new Response(content);
}

// Usage
fetchAndVerify(
  'https://example.com/data.json',
  'sha384-expectedHashValue'
)
.then(response => response.json())
.then(data => console.log('Verified data:', data));
```

#### Verifying JSON Responses

```javascript
async function fetchJsonWithIntegrity(url, expectedHash) {
  const response = await fetch(url);
  const text = await response.text();
  
  // Compute hash of the text content
  const buffer = new TextEncoder().encode(text);
  const hashBuffer = await crypto.subtle.digest('SHA-384', buffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  const computedHash = `sha384-${hashBase64}`;
  
  if (computedHash !== expectedHash) {
    throw new Error('JSON integrity check failed');
  }
  
  return JSON.parse(text);
}
```

### Integrity with Dynamic Content

#### Caching with Integrity

```javascript
class IntegrityCache {
  constructor() {
    this.cache = new Map();
  }
  
  async fetch(url, integrity) {
    const cacheKey = `${url}:${integrity}`;
    
    if (this.cache.has(cacheKey)) {
      console.log('Returning cached content');
      return this.cache.get(cacheKey);
    }
    
    const response = await fetch(url, { integrity });
    const content = await response.text();
    
    this.cache.set(cacheKey, content);
    return content;
  }
  
  clear() {
    this.cache.clear();
  }
}

const cache = new IntegrityCache();
cache.fetch('https://cdn.example.com/lib.js', 'sha384-hash');
```

#### Versioned Resources

```javascript
async function fetchVersionedResource(baseUrl, version, integrity) {
  const url = `${baseUrl}?v=${version}`;
  
  try {
    const response = await fetch(url, {
      integrity: integrity,
      cache: 'default'
    });
    
    if (!response.ok) {
      throw new Error(`Failed to fetch version ${version}`);
    }
    
    return await response.text();
    
  } catch (error) {
    console.error(`Integrity or fetch failed for version ${version}`);
    throw error;
  }
}

// Usage
fetchVersionedResource(
  'https://cdn.example.com/app.js',
  '2.1.0',
  'sha384-hashForVersion2.1.0'
);
```

### Content Security Policy Integration

#### CSP with Integrity

```javascript
// The CSP header would include: require-sri-for script style;
// This forces all scripts and styles to have integrity attributes

function loadScriptWithIntegrity(url, integrity) {
  const script = document.createElement('script');
  script.src = url;
  script.integrity = integrity;
  script.crossOrigin = 'anonymous';
  
  return new Promise((resolve, reject) => {
    script.onload = () => resolve(script);
    script.onerror = () => reject(new Error('Script failed to load'));
    document.head.appendChild(script);
  });
}

// Usage
loadScriptWithIntegrity(
  'https://cdn.example.com/lib.js',
  'sha384-hash'
)
.then(() => console.log('Script loaded and verified'))
.catch(error => console.error('Failed:', error));
```

### Integrity for Binary Data

#### Verifying Binary Files

```javascript
async function fetchBinaryWithIntegrity(url, expectedHash) {
  const response = await fetch(url);
  const arrayBuffer = await response.arrayBuffer();
  
  const hashBuffer = await crypto.subtle.digest('SHA-384', arrayBuffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  const actualHash = `sha384-${hashBase64}`;
  
  if (actualHash !== expectedHash) {
    throw new Error('Binary file integrity check failed');
  }
  
  return arrayBuffer;
}

// Usage
fetchBinaryWithIntegrity(
  'https://example.com/image.png',
  'sha384-hash'
)
.then(buffer => {
  const blob = new Blob([buffer]);
  const url = URL.createObjectURL(blob);
  console.log('Verified image URL:', url);
});
```

#### Stream-Based Verification

```javascript
async function verifyStreamIntegrity(url, expectedHash) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  const chunks = [];
  let totalLength = 0;
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    chunks.push(value);
    totalLength += value.length;
  }
  
  // Combine chunks
  const combined = new Uint8Array(totalLength);
  let position = 0;
  for (const chunk of chunks) {
    combined.set(chunk, position);
    position += chunk.length;
  }
  
  // Verify integrity
  const hashBuffer = await crypto.subtle.digest('SHA-384', combined);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  const actualHash = `sha384-${hashBase64}`;
  
  if (actualHash !== expectedHash) {
    throw new Error('Stream integrity verification failed');
  }
  
  return combined;
}
```

### Integrity Manager Pattern

```javascript
class IntegrityManager {
  constructor() {
    this.knownHashes = new Map();
  }
  
  register(url, integrity) {
    this.knownHashes.set(url, integrity);
  }
  
  async fetch(url, options = {}) {
    const integrity = this.knownHashes.get(url);
    
    if (!integrity) {
      console.warn(`No integrity hash registered for ${url}`);
      return fetch(url, options);
    }
    
    return fetch(url, {
      ...options,
      integrity: integrity
    });
  }
  
  async verifyAndCache(url) {
    const response = await this.fetch(url);
    const content = await response.text();
    
    return {
      url,
      content,
      verified: true,
      timestamp: Date.now()
    };
  }
}

// Usage
const manager = new IntegrityManager();
manager.register(
  'https://cdn.example.com/lib.js',
  'sha384-hash'
);

manager.fetch('https://cdn.example.com/lib.js')
  .then(response => response.text())
  .then(content => console.log('Verified content loaded'));
```

### Integrity for APIs

#### API Response Verification

```javascript
async function fetchApiWithIntegrity(url, expectedSignature) {
  const response = await fetch(url);
  const data = await response.json();
  
  // Server includes signature in response
  const serverSignature = response.headers.get('X-Content-Signature');
  
  if (serverSignature !== expectedSignature) {
    throw new Error('API response signature mismatch');
  }
  
  return data;
}
```

#### HMAC Verification

```javascript
async function verifyHMAC(data, secret, receivedHmac) {
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secret);
  const messageData = encoder.encode(JSON.stringify(data));
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign', 'verify']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  const signatureArray = Array.from(new Uint8Array(signature));
  const signatureHex = signatureArray
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  return signatureHex === receivedHmac;
}

// Usage
async function fetchWithHMAC(url, secret) {
  const response = await fetch(url);
  const data = await response.json();
  const hmac = response.headers.get('X-HMAC-Signature');
  
  const isValid = await verifyHMAC(data, secret, hmac);
  
  if (!isValid) {
    throw new Error('HMAC verification failed');
  }
  
  return data;
}
```

### Error Handling for Integrity Checks

#### Comprehensive Error Handling

```javascript
async function safeIntegrityFetch(url, integrity, retries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < retries; attempt++) {
    try {
      const response = await fetch(url, { integrity });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return await response.text();
      
    } catch (error) {
      lastError = error;
      
      if (error.name === 'TypeError' && error.message.includes('integrity')) {
        console.error('Integrity check failed, not retrying');
        break;
      }
      
      console.warn(`Attempt ${attempt + 1} failed:`, error.message);
      
      if (attempt < retries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
      }
    }
  }
  
  throw new Error(`Failed after ${retries} attempts: ${lastError.message}`);
}
```

#### Logging Integrity Failures

```javascript
class IntegrityLogger {
  constructor() {
    this.failures = [];
  }
  
  async fetch(url, integrity) {
    try {
      const response = await fetch(url, { integrity });
      
      this.log('success', url, integrity);
      return response;
      
    } catch (error) {
      this.log('failure', url, integrity, error);
      throw error;
    }
  }
  
  log(status, url, integrity, error = null) {
    const entry = {
      timestamp: new Date().toISOString(),
      status,
      url,
      integrity,
      error: error?.message
    };
    
    if (status === 'failure') {
      this.failures.push(entry);
    }
    
    console.log('Integrity check:', entry);
  }
  
  getFailures() {
    return this.failures;
  }
}

const logger = new IntegrityLogger();
logger.fetch('https://cdn.example.com/lib.js', 'sha384-hash');
```

### Performance Considerations

#### Preloading with Integrity

```javascript
function preloadWithIntegrity(url, integrity, type = 'script') {
  const link = document.createElement('link');
  link.rel = 'preload';
  link.as = type;
  link.href = url;
  link.integrity = integrity;
  link.crossOrigin = 'anonymous';
  
  document.head.appendChild(link);
}

// Usage
preloadWithIntegrity(
  'https://cdn.example.com/lib.js',
  'sha384-hash',
  'script'
);
```

#### Parallel Fetching with Integrity

```javascript
async function fetchMultipleWithIntegrity(resources) {
  const promises = resources.map(({ url, integrity }) =>
    fetch(url, { integrity })
      .then(response => response.text())
      .then(content => ({ url, content, verified: true }))
      .catch(error => ({ url, error: error.message, verified: false }))
  );
  
  return Promise.all(promises);
}

// Usage
const resources = [
  { url: 'https://cdn.example.com/lib1.js', integrity: 'sha384-hash1' },
  { url: 'https://cdn.example.com/lib2.js', integrity: 'sha384-hash2' },
  { url: 'https://cdn.example.com/lib3.js', integrity: 'sha384-hash3' }
];

fetchMultipleWithIntegrity(resources)
  .then(results => {
    const verified = results.filter(r => r.verified);
    const failed = results.filter(r => !r.verified);
    console.log(`Verified: ${verified.length}, Failed: ${failed.length}`);
  });
```

---

## Keepalive Option with Bearer Tokens

### Basic Syntax

```javascript
fetch('https://api.example.com/data', {
  method: 'POST',
  keepalive: true,
  headers: {
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({ data: 'value' })
});
```

### Purpose and Behavior

The `keepalive` option allows fetch requests to continue even after the page that initiated them has been unloaded or navigated away. This is particularly useful for analytics, logging, and cleanup operations.

```javascript
// Request continues even if user closes tab/navigates away
window.addEventListener('beforeunload', () => {
  fetch('https://api.example.com/logout', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`
    }
  });
});
```

### Size Limitations

Keepalive requests have a maximum body size of 64 KiB (65,536 bytes) per request. This limit applies to the entire request body.

```javascript
const data = JSON.stringify({ userId: 123, action: 'click' });
const bodySize = new Blob([data]).size;

if (bodySize <= 65536) {
  fetch('https://api.example.com/analytics', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: data
  });
} else {
  // Handle oversized payload
  console.error('Payload exceeds keepalive limit');
}
```

### Use Cases with Authentication

#### Session Termination

```javascript
function logoutUser(token) {
  fetch('https://api.example.com/auth/logout', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ timestamp: Date.now() })
  });
  
  // Clear local token
  sessionStorage.removeItem('authToken');
}

window.addEventListener('beforeunload', () => {
  const token = sessionStorage.getItem('authToken');
  if (token) {
    logoutUser(token);
  }
});
```

#### Analytics Events

```javascript
function trackEvent(eventName, eventData, token) {
  const payload = {
    event: eventName,
    data: eventData,
    timestamp: Date.now()
  };

  fetch('https://api.example.com/analytics', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(payload)
  });
}

// Track page exit
window.addEventListener('visibilitychange', () => {
  if (document.visibilityState === 'hidden') {
    const token = sessionStorage.getItem('authToken');
    trackEvent('page_exit', { duration: getSessionDuration() }, token);
  }
});
```

#### Error Reporting

```javascript
function reportError(error, token) {
  const errorReport = {
    message: error.message,
    stack: error.stack,
    url: window.location.href,
    userAgent: navigator.userAgent,
    timestamp: Date.now()
  };

  fetch('https://api.example.com/errors', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(errorReport)
  });
}

window.addEventListener('error', (event) => {
  const token = sessionStorage.getItem('authToken');
  if (token) {
    reportError(event.error, token);
  }
});
```

### Combination with Page Lifecycle Events

#### beforeunload Event

```javascript
window.addEventListener('beforeunload', (event) => {
  const token = sessionStorage.getItem('authToken');
  
  fetch('https://api.example.com/session/end', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({
      sessionId: getSessionId(),
      duration: getSessionDuration()
    })
  });
  
  // Note: Cannot reliably wait for response here
});
```

#### pagehide Event

```javascript
// More reliable than beforeunload for mobile
window.addEventListener('pagehide', (event) => {
  const token = sessionStorage.getItem('authToken');
  
  if (event.persisted) {
    // Page is being cached (bfcache)
    console.log('Page entering bfcache');
  }
  
  fetch('https://api.example.com/tracking/pagehide', {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({ timestamp: Date.now() })
  });
});
```

#### visibilitychange Event

```javascript
document.addEventListener('visibilitychange', () => {
  const token = sessionStorage.getItem('authToken');
  
  if (document.visibilityState === 'hidden') {
    // Page is being hidden
    fetch('https://api.example.com/tracking/visibility', {
      method: 'POST',
      keepalive: true,
      headers: {
        'Authorization': `Bearer ${token}`
      },
      body: JSON.stringify({
        state: 'hidden',
        timestamp: Date.now()
      })
    });
  }
});
```

### Browser Support and Fallbacks

```javascript
function sendWithKeepalive(url, token, data) {
  if ('keepalive' in Request.prototype) {
    // Browser supports keepalive
    return fetch(url, {
      method: 'POST',
      keepalive: true,
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
    });
  } else {
    // Fallback to navigator.sendBeacon
    const blob = new Blob(
      [JSON.stringify(data)],
      { type: 'application/json' }
    );
    
    // Note: sendBeacon doesn't support custom headers
    // [Inference] Token must be sent via URL or alternative method
    const urlWithToken = `${url}?token=${encodeURIComponent(token)}`;
    navigator.sendBeacon(urlWithToken, blob);
  }
}
```

### Keepalive vs sendBeacon Comparison

```javascript
// fetch with keepalive - supports custom headers
fetch('https://api.example.com/analytics', {
  method: 'POST',
  keepalive: true,
  headers: {
    'Authorization': `Bearer ${token}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify(data)
});

// sendBeacon - no custom headers, but simpler
// Cannot send Authorization header directly
const blob = new Blob([JSON.stringify(data)], { type: 'application/json' });
navigator.sendBeacon('https://api.example.com/analytics', blob);
```

### Limitations and Constraints

#### No Response Handling

```javascript
// Cannot reliably access response with keepalive during unload
window.addEventListener('beforeunload', () => {
  const token = sessionStorage.getItem('authToken');
  
  fetch('https://api.example.com/data', {
    method: 'POST',
    keepalive: true,
    headers: { 'Authorization': `Bearer ${token}` },
    body: JSON.stringify({ data: 'value' })
  })
  .then(response => response.json())
  .then(data => {
    // [Unverified] This may not execute if page unloads
    console.log(data);
  });
});
```

#### Request Queuing

```javascript
// Multiple keepalive requests queue and execute
window.addEventListener('beforeunload', () => {
  const token = sessionStorage.getItem('authToken');
  
  // All these requests will be queued
  fetch('https://api.example.com/event1', {
    method: 'POST',
    keepalive: true,
    headers: { 'Authorization': `Bearer ${token}` },
    body: JSON.stringify({ event: 1 })
  });
  
  fetch('https://api.example.com/event2', {
    method: 'POST',
    keepalive: true,
    headers: { 'Authorization': `Bearer ${token}` },
    body: JSON.stringify({ event: 2 })
  });
  
  fetch('https://api.example.com/event3', {
    method: 'POST',
    keepalive: true,
    headers: { 'Authorization': `Bearer ${token}` },
    body: JSON.stringify({ event: 3 })
  });
});
```

#### Payload Size Validation

```javascript
function sendKeepaliveWithValidation(url, token, data) {
  const body = JSON.stringify(data);
  const size = new TextEncoder().encode(body).length;
  
  const MAX_KEEPALIVE_SIZE = 65536; // 64 KiB
  
  if (size > MAX_KEEPALIVE_SIZE) {
    // Split or truncate data
    console.error(`Payload size ${size} exceeds keepalive limit`);
    
    // Option 1: Truncate
    const truncated = JSON.stringify({
      ...data,
      _truncated: true
    });
    
    // Option 2: Send without keepalive
    // Option 3: Send to queue for later
    
    return false;
  }
  
  fetch(url, {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: body
  });
  
  return true;
}
```

### Security Considerations

#### Token Exposure During Unload

```javascript
// Token remains in memory during keepalive request
// [Inference] Ensure tokens are not logged or exposed elsewhere

window.addEventListener('beforeunload', () => {
  const token = sessionStorage.getItem('authToken');
  
  // DO: Use keepalive for logout
  fetch('https://api.example.com/logout', {
    method: 'POST',
    keepalive: true,
    headers: { 'Authorization': `Bearer ${token}` }
  });
  
  // DON'T: Log sensitive data
  // console.log('Logging out with token:', token); // SECURITY RISK
});
```

#### HTTPS Requirement

```javascript
// Keepalive requests should only be sent over HTTPS
function sendSecureKeepalive(url, token, data) {
  if (!url.startsWith('https://')) {
    console.error('Keepalive requests must use HTTPS');
    return;
  }
  
  fetch(url, {
    method: 'POST',
    keepalive: true,
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
  });
}
```

### Practical Implementation Pattern

```javascript
class KeepaliveTracker {
  constructor(endpoint, tokenProvider) {
    this.endpoint = endpoint;
    this.tokenProvider = tokenProvider;
    this.queue = [];
    this.maxPayloadSize = 65536;
    
    this.setupListeners();
  }
  
  setupListeners() {
    window.addEventListener('beforeunload', () => this.flush());
    window.addEventListener('pagehide', () => this.flush());
    
    document.addEventListener('visibilitychange', () => {
      if (document.visibilityState === 'hidden') {
        this.flush();
      }
    });
  }
  
  track(eventName, eventData) {
    this.queue.push({
      event: eventName,
      data: eventData,
      timestamp: Date.now()
    });
    
    // Auto-flush if queue gets large
    if (this.queue.length >= 10) {
      this.flush();
    }
  }
  
  flush() {
    if (this.queue.length === 0) return;
    
    const token = this.tokenProvider();
    if (!token) return;
    
    const payload = JSON.stringify({ events: this.queue });
    const size = new TextEncoder().encode(payload).length;
    
    if (size <= this.maxPayloadSize) {
      fetch(this.endpoint, {
        method: 'POST',
        keepalive: true,
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/json'
        },
        body: payload
      });
      
      this.queue = [];
    } else {
      // Send in batches
      const midpoint = Math.floor(this.queue.length / 2);
      const batch1 = this.queue.slice(0, midpoint);
      const batch2 = this.queue.slice(midpoint);
      
      this.sendBatch(batch1, token);
      this.sendBatch(batch2, token);
      
      this.queue = [];
    }
  }
  
  sendBatch(events, token) {
    const payload = JSON.stringify({ events });
    
    fetch(this.endpoint, {
      method: 'POST',
      keepalive: true,
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: payload
    });
  }
}

// Usage
const tracker = new KeepaliveTracker(
  'https://api.example.com/analytics',
  () => sessionStorage.getItem('authToken')
);

tracker.track('page_view', { url: window.location.href });
tracker.track('button_click', { buttonId: 'submit' });
```

---

## AbortSignal & Request Cancellation

### Basic Abort Pattern

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Fetch aborted');
    } else {
      console.error('Fetch error:', error);
    }
  });

// Abort the request
controller.abort();
```

### Timeout Implementation

```javascript
// Simple timeout
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  return fetch(url, {
    ...options,
    signal: controller.signal
  }).finally(() => {
    clearTimeout(timeoutId);
  });
}

// Usage
try {
  const response = await fetchWithTimeout('https://api.example.com/data', {}, 3000);
  const data = await response.json();
} catch (error) {
  if (error.name === 'AbortError') {
    console.error('Request timed out');
  }
}
```

### AbortSignal.timeout() Method

```javascript
// Modern approach (Node 18+, modern browsers)
try {
  const response = await fetch('https://api.example.com/data', {
    signal: AbortSignal.timeout(5000) // 5 second timeout
  });
  const data = await response.json();
} catch (error) {
  if (error.name === 'TimeoutError' || error.name === 'AbortError') {
    console.error('Request timed out');
  }
}
```

### Combining Multiple Signals

```javascript
// Combine multiple abort signals
function combineSignals(...signals) {
  const controller = new AbortController();

  for (const signal of signals) {
    if (signal.aborted) {
      controller.abort();
      return controller.signal;
    }

    signal.addEventListener('abort', () => controller.abort(), { once: true });
  }

  return controller.signal;
}

// Usage
const userController = new AbortController();
const timeoutSignal = AbortSignal.timeout(10000);

const combinedSignal = combineSignals(
  userController.signal,
  timeoutSignal
);

fetch('https://api.example.com/data', { signal: combinedSignal });

// Can abort from either source
userController.abort(); // User cancellation
// or timeout will trigger automatically
```

### AbortSignal.any() Method

```javascript
// Modern approach (newer browsers/Node.js)
const userController = new AbortController();

const response = await fetch('https://api.example.com/data', {
  signal: AbortSignal.any([
    userController.signal,
    AbortSignal.timeout(5000)
  ])
});

// Aborts if either user cancels OR timeout occurs
```

### Component Lifecycle Integration (React)

```javascript
// React useEffect cleanup
function DataComponent() {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const controller = new AbortController();

    fetch('https://api.example.com/data', {
      signal: controller.signal
    })
      .then(response => response.json())
      .then(data => {
        setData(data);
        setLoading(false);
      })
      .catch(error => {
        if (error.name !== 'AbortError') {
          console.error('Fetch error:', error);
        }
        setLoading(false);
      });

    // Cleanup: abort on unmount
    return () => controller.abort();
  }, []);

  return loading ? <div>Loading...</div> : <div>{JSON.stringify(data)}</div>;
}
```

### Search Input Debouncing with Abort

```javascript
class SearchHandler {
  constructor() {
    this.controller = null;
  }

  async search(query) {
    // Abort previous request if still pending
    if (this.controller) {
      this.controller.abort();
    }

    // Create new controller for this request
    this.controller = new AbortController();

    try {
      const response = await fetch(
        `https://api.example.com/search?q=${encodeURIComponent(query)}`,
        { signal: this.controller.signal }
      );
      return await response.json();
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Search cancelled');
        return null;
      }
      throw error;
    }
  }
}

// Usage
const searchHandler = new SearchHandler();

searchInput.addEventListener('input', async (e) => {
  const results = await searchHandler.search(e.target.value);
  if (results) {
    displayResults(results);
  }
});
```

### Abort Event Listener

```javascript
const controller = new AbortController();
const signal = controller.signal;

// Listen for abort event
signal.addEventListener('abort', () => {
  console.log('Request was aborted');
  console.log('Abort reason:', signal.reason);
});

// Check if already aborted
if (signal.aborted) {
  console.log('Signal already aborted');
}

fetch('https://api.example.com/data', { signal });

// Abort with custom reason
controller.abort(new Error('User cancelled the operation'));
```

### Multiple Concurrent Requests with Individual Control

```javascript
class RequestManager {
  constructor() {
    this.requests = new Map();
  }

  async fetch(id, url, options = {}) {
    // Create controller for this request
    const controller = new AbortController();
    this.requests.set(id, controller);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } finally {
      this.requests.delete(id);
    }
  }

  abort(id) {
    const controller = this.requests.get(id);
    if (controller) {
      controller.abort();
      this.requests.delete(id);
    }
  }

  abortAll() {
    for (const [id, controller] of this.requests) {
      controller.abort();
    }
    this.requests.clear();
  }

  isActive(id) {
    return this.requests.has(id);
  }

  getActiveCount() {
    return this.requests.size;
  }
}

// Usage
const manager = new RequestManager();

// Start multiple requests
manager.fetch('users', 'https://api.example.com/users');
manager.fetch('posts', 'https://api.example.com/posts');
manager.fetch('comments', 'https://api.example.com/comments');

// Abort specific request
manager.abort('posts');

// Abort all requests
manager.abortAll();
```

### Retry with Abort

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  const controller = new AbortController();
  let lastError;

  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      return response;
    } catch (error) {
      lastError = error;

      // Don't retry if aborted
      if (error.name === 'AbortError') {
        throw error;
      }

      // Wait before retry (exponential backoff)
      if (i < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, i)));
      }
    }
  }

  throw lastError;
}

// Usage with external abort control
const controller = new AbortController();

fetchWithRetry('https://api.example.com/data', {
  signal: controller.signal
});

// Can abort retry loop
controller.abort();
```

### Priority Queue with Abort

```javascript
class PriorityRequestQueue {
  constructor(maxConcurrent = 3) {
    this.maxConcurrent = maxConcurrent;
    this.active = 0;
    this.queue = [];
  }

  async fetch(url, options = {}, priority = 0) {
    return new Promise((resolve, reject) => {
      const controller = new AbortController();
      
      const request = {
        url,
        options: { ...options, signal: controller.signal },
        priority,
        resolve,
        reject,
        controller
      };

      // Insert by priority
      const index = this.queue.findIndex(r => r.priority < priority);
      if (index === -1) {
        this.queue.push(request);
      } else {
        this.queue.splice(index, 0, request);
      }

      this.process();

      // Return abort function
      return controller;
    });
  }

  async process() {
    if (this.active >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }

    this.active++;
    const request = this.queue.shift();

    try {
      const response = await fetch(request.url, request.options);
      const data = await response.json();
      request.resolve(data);
    } catch (error) {
      request.reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }

  abortAll() {
    for (const request of this.queue) {
      request.controller.abort();
      request.reject(new Error('Request aborted'));
    }
    this.queue = [];
  }
}

// Usage
const queue = new PriorityRequestQueue(3);

// High priority request
queue.fetch('https://api.example.com/critical', {}, 10);

// Normal priority
queue.fetch('https://api.example.com/normal', {}, 5);

// Low priority
queue.fetch('https://api.example.com/background', {}, 1);

// Abort all pending
queue.abortAll();
```

### Abort on Navigation

```javascript
// Vanilla JS
class FetchManager {
  constructor() {
    this.activeRequests = new Set();
    
    // Abort all on page unload
    window.addEventListener('beforeunload', () => {
      this.abortAll();
    });
  }

  async fetch(url, options = {}) {
    const controller = new AbortController();
    this.activeRequests.add(controller);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return response;
    } finally {
      this.activeRequests.delete(controller);
    }
  }

  abortAll() {
    for (const controller of this.activeRequests) {
      controller.abort();
    }
    this.activeRequests.clear();
  }
}

const fetchManager = new FetchManager();
```

### Progressive Timeout

```javascript
// Start with short timeout, increase if needed
async function fetchWithProgressiveTimeout(url, options = {}) {
  const timeouts = [2000, 5000, 10000]; // Progressive timeouts
  let lastError;

  for (const timeout of timeouts) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        console.log(`Timeout after ${timeout}ms, retrying with longer timeout`);
        lastError = error;
        continue;
      }
      
      throw error;
    }
  }

  throw new Error('All attempts timed out');
}
```

### Abort with Race Conditions

```javascript
// Race multiple endpoints, abort losers
async function fetchRace(urls, options = {}) {
  const controllers = urls.map(() => new AbortController());

  const requests = urls.map((url, index) =>
    fetch(url, {
      ...options,
      signal: controllers[index].signal
    }).then(response => ({
      response,
      index,
      url
    }))
  );

  try {
    const winner = await Promise.race(requests);
    
    // Abort all other requests
    controllers.forEach((controller, index) => {
      if (index !== winner.index) {
        controller.abort();
      }
    });

    return winner.response;
  } catch (error) {
    // Abort all on error
    controllers.forEach(controller => controller.abort());
    throw error;
  }
}

// Usage
const response = await fetchRace([
  'https://api1.example.com/data',
  'https://api2.example.com/data',
  'https://api3.example.com/data'
]);
```

### Chained Requests with Abort

```javascript
async function fetchChain(urls, options = {}) {
  const controller = new AbortController();
  const results = [];

  try {
    for (const url of urls) {
      // Check if aborted before each request
      if (controller.signal.aborted) {
        throw new Error('Chain aborted');
      }

      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      const data = await response.json();
      results.push(data);

      // Use data from previous request in next request
      // options.body = JSON.stringify({ previousData: data });
    }

    return results;
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Chain aborted at request', results.length + 1);
    }
    throw error;
  }
}

// Abort entire chain
const controller = new AbortController();

fetchChain(
  ['/api/step1', '/api/step2', '/api/step3'],
  { signal: controller.signal }
);

// Abort after 5 seconds
setTimeout(() => controller.abort(), 5000);
```

### Abort with Promise.allSettled

```javascript
async function fetchAllWithAbort(requests, timeout = 10000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  const promises = requests.map(({ url, options = {} }) =>
    fetch(url, {
      ...options,
      signal: controller.signal
    })
      .then(response => response.json())
      .then(data => ({ status: 'fulfilled', value: data, url }))
      .catch(error => ({ status: 'rejected', reason: error, url }))
  );

  const results = await Promise.allSettled(promises);
  clearTimeout(timeoutId);

  return results.map((result, index) => ({
    url: requests[index].url,
    ...result
  }));
}

// Usage
const results = await fetchAllWithAbort([
  { url: 'https://api.example.com/users' },
  { url: 'https://api.example.com/posts' },
  { url: 'https://api.example.com/comments' }
], 5000);

results.forEach(result => {
  if (result.status === 'fulfilled') {
    console.log(`${result.url}: Success`, result.value);
  } else {
    console.log(`${result.url}: Failed`, result.reason);
  }
});
```

### Abort Signal Forwarding

```javascript
// Pass signal through multiple layers
async function apiLayer1(signal) {
  return apiLayer2(signal);
}

async function apiLayer2(signal) {
  return apiLayer3(signal);
}

async function apiLayer3(signal) {
  return fetch('https://api.example.com/data', { signal });
}

// Single abort point controls entire chain
const controller = new AbortController();
apiLayer1(controller.signal);
controller.abort(); // Aborts at any level
```

### Conditional Abort Based on Response

```javascript
async function fetchWithResponseCheck(url, options = {}) {
  const controller = new AbortController();
  
  const response = await fetch(url, {
    ...options,
    signal: controller.signal
  });

  // Check response before reading body
  if (!response.ok) {
    controller.abort(); // Abort reading body
    throw new Error(`HTTP ${response.status}`);
  }

  // Read body only if response is ok
  const data = await response.json();

  // Conditional abort based on data
  if (data.error || data.status === 'invalid') {
    controller.abort();
    throw new Error('Invalid data received');
  }

  return data;
}
```

### Abort with Streaming Response

```javascript
async function fetchStreamWithAbort(url, onChunk, timeout = 30000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  try {
    const response = await fetch(url, {
      signal: controller.signal
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      // Check if aborted
      if (controller.signal.aborted) {
        reader.cancel();
        break;
      }

      const { done, value } = await reader.read();
      
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      onChunk(chunk);

      // Can abort based on chunk content
      if (chunk.includes('ERROR')) {
        controller.abort();
        break;
      }
    }
  } finally {
    clearTimeout(timeoutId);
  }
}

// Usage
fetchStreamWithAbort(
  'https://api.example.com/stream',
  (chunk) => console.log('Received:', chunk)
);
```

### AbortSignal State Management

```javascript
class AbortSignalManager {
  constructor() {
    this.controllers = new Map();
    this.signals = new Map();
  }

  create(id) {
    const controller = new AbortController();
    this.controllers.set(id, controller);
    this.signals.set(id, controller.signal);

    // Auto-cleanup on abort
    controller.signal.addEventListener('abort', () => {
      this.controllers.delete(id);
      this.signals.delete(id);
    }, { once: true });

    return controller.signal;
  }

  abort(id, reason) {
    const controller = this.controllers.get(id);
    if (controller) {
      controller.abort(reason);
    }
  }

  abortAll(reason) {
    for (const [id, controller] of this.controllers) {
      controller.abort(reason);
    }
    this.controllers.clear();
    this.signals.clear();
  }

  isAborted(id) {
    const signal = this.signals.get(id);
    return signal ? signal.aborted : true;
  }

  getActiveCount() {
    return this.controllers.size;
  }

  async fetchWithSignal(id, url, options = {}) {
    const signal = this.create(id);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal
      });
      return await response.json();
    } finally {
      this.controllers.delete(id);
      this.signals.delete(id);
    }
  }
}

// Usage
const manager = new AbortSignalManager();

manager.fetchWithSignal('request-1', 'https://api.example.com/data');
manager.fetchWithSignal('request-2', 'https://api.example.com/users');

// Abort specific request
manager.abort('request-1', 'User cancelled');

// Abort all
manager.abortAll('Component unmounted');
```

### Custom AbortSignal Wrapper

```javascript
class SmartAbortController {
  constructor() {
    this.controller = new AbortController();
    this.abortCallbacks = [];
    this.aborted = false;
    this.reason = null;
  }

  get signal() {
    return this.controller.signal;
  }

  abort(reason) {
    if (this.aborted) return;

    this.aborted = true;
    this.reason = reason;
    this.controller.abort(reason);

    // Execute callbacks
    for (const callback of this.abortCallbacks) {
      callback(reason);
    }
  }

  onAbort(callback) {
    if (this.aborted) {
      callback(this.reason);
    } else {
      this.abortCallbacks.push(callback);
    }

    // Return unsubscribe function
    return () => {
      const index = this.abortCallbacks.indexOf(callback);
      if (index > -1) {
        this.abortCallbacks.splice(index, 1);
      }
    };
  }

  isAborted() {
    return this.aborted;
  }

  getAbortReason() {
    return this.reason;
  }
}

// Usage
const controller = new SmartAbortController();

const unsubscribe = controller.onAbort((reason) => {
  console.log('Aborted because:', reason);
});

fetch('https://api.example.com/data', {
  signal: controller.signal
});

controller.abort('User navigated away');
```

---

# Abort and Cancellation

## AbortSignal & Request Cancellation

### Basic Abort Pattern

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Fetch aborted');
    } else {
      console.error('Fetch error:', error);
    }
  });

// Abort the request
controller.abort();
```

### Timeout Implementation

```javascript
// Simple timeout
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  return fetch(url, {
    ...options,
    signal: controller.signal
  }).finally(() => {
    clearTimeout(timeoutId);
  });
}

// Usage
try {
  const response = await fetchWithTimeout('https://api.example.com/data', {}, 3000);
  const data = await response.json();
} catch (error) {
  if (error.name === 'AbortError') {
    console.error('Request timed out');
  }
}
```

### AbortSignal.timeout() Method

```javascript
// Modern approach (Node 18+, modern browsers)
try {
  const response = await fetch('https://api.example.com/data', {
    signal: AbortSignal.timeout(5000) // 5 second timeout
  });
  const data = await response.json();
} catch (error) {
  if (error.name === 'TimeoutError' || error.name === 'AbortError') {
    console.error('Request timed out');
  }
}
```

### Combining Multiple Signals

```javascript
// Combine multiple abort signals
function combineSignals(...signals) {
  const controller = new AbortController();

  for (const signal of signals) {
    if (signal.aborted) {
      controller.abort();
      return controller.signal;
    }

    signal.addEventListener('abort', () => controller.abort(), { once: true });
  }

  return controller.signal;
}

// Usage
const userController = new AbortController();
const timeoutSignal = AbortSignal.timeout(10000);

const combinedSignal = combineSignals(
  userController.signal,
  timeoutSignal
);

fetch('https://api.example.com/data', { signal: combinedSignal });

// Can abort from either source
userController.abort(); // User cancellation
// or timeout will trigger automatically
```

### AbortSignal.any() Method

```javascript
// Modern approach (newer browsers/Node.js)
const userController = new AbortController();

const response = await fetch('https://api.example.com/data', {
  signal: AbortSignal.any([
    userController.signal,
    AbortSignal.timeout(5000)
  ])
});

// Aborts if either user cancels OR timeout occurs
```

### Component Lifecycle Integration (React)

```javascript
// React useEffect cleanup
function DataComponent() {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const controller = new AbortController();

    fetch('https://api.example.com/data', {
      signal: controller.signal
    })
      .then(response => response.json())
      .then(data => {
        setData(data);
        setLoading(false);
      })
      .catch(error => {
        if (error.name !== 'AbortError') {
          console.error('Fetch error:', error);
        }
        setLoading(false);
      });

    // Cleanup: abort on unmount
    return () => controller.abort();
  }, []);

  return loading ? <div>Loading...</div> : <div>{JSON.stringify(data)}</div>;
}
```

### Search Input Debouncing with Abort

```javascript
class SearchHandler {
  constructor() {
    this.controller = null;
  }

  async search(query) {
    // Abort previous request if still pending
    if (this.controller) {
      this.controller.abort();
    }

    // Create new controller for this request
    this.controller = new AbortController();

    try {
      const response = await fetch(
        `https://api.example.com/search?q=${encodeURIComponent(query)}`,
        { signal: this.controller.signal }
      );
      return await response.json();
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Search cancelled');
        return null;
      }
      throw error;
    }
  }
}

// Usage
const searchHandler = new SearchHandler();

searchInput.addEventListener('input', async (e) => {
  const results = await searchHandler.search(e.target.value);
  if (results) {
    displayResults(results);
  }
});
```

### Abort Event Listener

```javascript
const controller = new AbortController();
const signal = controller.signal;

// Listen for abort event
signal.addEventListener('abort', () => {
  console.log('Request was aborted');
  console.log('Abort reason:', signal.reason);
});

// Check if already aborted
if (signal.aborted) {
  console.log('Signal already aborted');
}

fetch('https://api.example.com/data', { signal });

// Abort with custom reason
controller.abort(new Error('User cancelled the operation'));
```

### Multiple Concurrent Requests with Individual Control

```javascript
class RequestManager {
  constructor() {
    this.requests = new Map();
  }

  async fetch(id, url, options = {}) {
    // Create controller for this request
    const controller = new AbortController();
    this.requests.set(id, controller);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } finally {
      this.requests.delete(id);
    }
  }

  abort(id) {
    const controller = this.requests.get(id);
    if (controller) {
      controller.abort();
      this.requests.delete(id);
    }
  }

  abortAll() {
    for (const [id, controller] of this.requests) {
      controller.abort();
    }
    this.requests.clear();
  }

  isActive(id) {
    return this.requests.has(id);
  }

  getActiveCount() {
    return this.requests.size;
  }
}

// Usage
const manager = new RequestManager();

// Start multiple requests
manager.fetch('users', 'https://api.example.com/users');
manager.fetch('posts', 'https://api.example.com/posts');
manager.fetch('comments', 'https://api.example.com/comments');

// Abort specific request
manager.abort('posts');

// Abort all requests
manager.abortAll();
```

### Retry with Abort

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  const controller = new AbortController();
  let lastError;

  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      return response;
    } catch (error) {
      lastError = error;

      // Don't retry if aborted
      if (error.name === 'AbortError') {
        throw error;
      }

      // Wait before retry (exponential backoff)
      if (i < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, i)));
      }
    }
  }

  throw lastError;
}

// Usage with external abort control
const controller = new AbortController();

fetchWithRetry('https://api.example.com/data', {
  signal: controller.signal
});

// Can abort retry loop
controller.abort();
```

### Priority Queue with Abort

```javascript
class PriorityRequestQueue {
  constructor(maxConcurrent = 3) {
    this.maxConcurrent = maxConcurrent;
    this.active = 0;
    this.queue = [];
  }

  async fetch(url, options = {}, priority = 0) {
    return new Promise((resolve, reject) => {
      const controller = new AbortController();
      
      const request = {
        url,
        options: { ...options, signal: controller.signal },
        priority,
        resolve,
        reject,
        controller
      };

      // Insert by priority
      const index = this.queue.findIndex(r => r.priority < priority);
      if (index === -1) {
        this.queue.push(request);
      } else {
        this.queue.splice(index, 0, request);
      }

      this.process();

      // Return abort function
      return controller;
    });
  }

  async process() {
    if (this.active >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }

    this.active++;
    const request = this.queue.shift();

    try {
      const response = await fetch(request.url, request.options);
      const data = await response.json();
      request.resolve(data);
    } catch (error) {
      request.reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }

  abortAll() {
    for (const request of this.queue) {
      request.controller.abort();
      request.reject(new Error('Request aborted'));
    }
    this.queue = [];
  }
}

// Usage
const queue = new PriorityRequestQueue(3);

// High priority request
queue.fetch('https://api.example.com/critical', {}, 10);

// Normal priority
queue.fetch('https://api.example.com/normal', {}, 5);

// Low priority
queue.fetch('https://api.example.com/background', {}, 1);

// Abort all pending
queue.abortAll();
```

### Abort on Navigation

```javascript
// Vanilla JS
class FetchManager {
  constructor() {
    this.activeRequests = new Set();
    
    // Abort all on page unload
    window.addEventListener('beforeunload', () => {
      this.abortAll();
    });
  }

  async fetch(url, options = {}) {
    const controller = new AbortController();
    this.activeRequests.add(controller);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return response;
    } finally {
      this.activeRequests.delete(controller);
    }
  }

  abortAll() {
    for (const controller of this.activeRequests) {
      controller.abort();
    }
    this.activeRequests.clear();
  }
}

const fetchManager = new FetchManager();
```

### Progressive Timeout

```javascript
// Start with short timeout, increase if needed
async function fetchWithProgressiveTimeout(url, options = {}) {
  const timeouts = [2000, 5000, 10000]; // Progressive timeouts
  let lastError;

  for (const timeout of timeouts) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        console.log(`Timeout after ${timeout}ms, retrying with longer timeout`);
        lastError = error;
        continue;
      }
      
      throw error;
    }
  }

  throw new Error('All attempts timed out');
}
```

### Abort with Race Conditions

```javascript
// Race multiple endpoints, abort losers
async function fetchRace(urls, options = {}) {
  const controllers = urls.map(() => new AbortController());

  const requests = urls.map((url, index) =>
    fetch(url, {
      ...options,
      signal: controllers[index].signal
    }).then(response => ({
      response,
      index,
      url
    }))
  );

  try {
    const winner = await Promise.race(requests);
    
    // Abort all other requests
    controllers.forEach((controller, index) => {
      if (index !== winner.index) {
        controller.abort();
      }
    });

    return winner.response;
  } catch (error) {
    // Abort all on error
    controllers.forEach(controller => controller.abort());
    throw error;
  }
}

// Usage
const response = await fetchRace([
  'https://api1.example.com/data',
  'https://api2.example.com/data',
  'https://api3.example.com/data'
]);
```

### Chained Requests with Abort

```javascript
async function fetchChain(urls, options = {}) {
  const controller = new AbortController();
  const results = [];

  try {
    for (const url of urls) {
      // Check if aborted before each request
      if (controller.signal.aborted) {
        throw new Error('Chain aborted');
      }

      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      const data = await response.json();
      results.push(data);

      // Use data from previous request in next request
      // options.body = JSON.stringify({ previousData: data });
    }

    return results;
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Chain aborted at request', results.length + 1);
    }
    throw error;
  }
}

// Abort entire chain
const controller = new AbortController();

fetchChain(
  ['/api/step1', '/api/step2', '/api/step3'],
  { signal: controller.signal }
);

// Abort after 5 seconds
setTimeout(() => controller.abort(), 5000);
```

### Abort with Promise.allSettled

```javascript
async function fetchAllWithAbort(requests, timeout = 10000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  const promises = requests.map(({ url, options = {} }) =>
    fetch(url, {
      ...options,
      signal: controller.signal
    })
      .then(response => response.json())
      .then(data => ({ status: 'fulfilled', value: data, url }))
      .catch(error => ({ status: 'rejected', reason: error, url }))
  );

  const results = await Promise.allSettled(promises);
  clearTimeout(timeoutId);

  return results.map((result, index) => ({
    url: requests[index].url,
    ...result
  }));
}

// Usage
const results = await fetchAllWithAbort([
  { url: 'https://api.example.com/users' },
  { url: 'https://api.example.com/posts' },
  { url: 'https://api.example.com/comments' }
], 5000);

results.forEach(result => {
  if (result.status === 'fulfilled') {
    console.log(`${result.url}: Success`, result.value);
  } else {
    console.log(`${result.url}: Failed`, result.reason);
  }
});
```

### Abort Signal Forwarding

```javascript
// Pass signal through multiple layers
async function apiLayer1(signal) {
  return apiLayer2(signal);
}

async function apiLayer2(signal) {
  return apiLayer3(signal);
}

async function apiLayer3(signal) {
  return fetch('https://api.example.com/data', { signal });
}

// Single abort point controls entire chain
const controller = new AbortController();
apiLayer1(controller.signal);
controller.abort(); // Aborts at any level
```

### Conditional Abort Based on Response

```javascript
async function fetchWithResponseCheck(url, options = {}) {
  const controller = new AbortController();
  
  const response = await fetch(url, {
    ...options,
    signal: controller.signal
  });

  // Check response before reading body
  if (!response.ok) {
    controller.abort(); // Abort reading body
    throw new Error(`HTTP ${response.status}`);
  }

  // Read body only if response is ok
  const data = await response.json();

  // Conditional abort based on data
  if (data.error || data.status === 'invalid') {
    controller.abort();
    throw new Error('Invalid data received');
  }

  return data;
}
```

### Abort with Streaming Response

```javascript
async function fetchStreamWithAbort(url, onChunk, timeout = 30000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  try {
    const response = await fetch(url, {
      signal: controller.signal
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      // Check if aborted
      if (controller.signal.aborted) {
        reader.cancel();
        break;
      }

      const { done, value } = await reader.read();
      
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      onChunk(chunk);

      // Can abort based on chunk content
      if (chunk.includes('ERROR')) {
        controller.abort();
        break;
      }
    }
  } finally {
    clearTimeout(timeoutId);
  }
}

// Usage
fetchStreamWithAbort(
  'https://api.example.com/stream',
  (chunk) => console.log('Received:', chunk)
);
```

### AbortSignal State Management

```javascript
class AbortSignalManager {
  constructor() {
    this.controllers = new Map();
    this.signals = new Map();
  }

  create(id) {
    const controller = new AbortController();
    this.controllers.set(id, controller);
    this.signals.set(id, controller.signal);

    // Auto-cleanup on abort
    controller.signal.addEventListener('abort', () => {
      this.controllers.delete(id);
      this.signals.delete(id);
    }, { once: true });

    return controller.signal;
  }

  abort(id, reason) {
    const controller = this.controllers.get(id);
    if (controller) {
      controller.abort(reason);
    }
  }

  abortAll(reason) {
    for (const [id, controller] of this.controllers) {
      controller.abort(reason);
    }
    this.controllers.clear();
    this.signals.clear();
  }

  isAborted(id) {
    const signal = this.signals.get(id);
    return signal ? signal.aborted : true;
  }

  getActiveCount() {
    return this.controllers.size;
  }

  async fetchWithSignal(id, url, options = {}) {
    const signal = this.create(id);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal
      });
      return await response.json();
    } finally {
      this.controllers.delete(id);
      this.signals.delete(id);
    }
  }
}

// Usage
const manager = new AbortSignalManager();

manager.fetchWithSignal('request-1', 'https://api.example.com/data');
manager.fetchWithSignal('request-2', 'https://api.example.com/users');

// Abort specific request
manager.abort('request-1', 'User cancelled');

// Abort all
manager.abortAll('Component unmounted');
```

### Custom AbortSignal Wrapper

```javascript
class SmartAbortController {
  constructor() {
    this.controller = new AbortController();
    this.abortCallbacks = [];
    this.aborted = false;
    this.reason = null;
  }

  get signal() {
    return this.controller.signal;
  }

  abort(reason) {
    if (this.aborted) return;

    this.aborted = true;
    this.reason = reason;
    this.controller.abort(reason);

    // Execute callbacks
    for (const callback of this.abortCallbacks) {
      callback(reason);
    }
  }

  onAbort(callback) {
    if (this.aborted) {
      callback(this.reason);
    } else {
      this.abortCallbacks.push(callback);
    }

    // Return unsubscribe function
    return () => {
      const index = this.abortCallbacks.indexOf(callback);
      if (index > -1) {
        this.abortCallbacks.splice(index, 1);
      }
    };
  }

  isAborted() {
    return this.aborted;
  }

  getAbortReason() {
    return this.reason;
  }
}

// Usage
const controller = new SmartAbortController();

const unsubscribe = controller.onAbort((reason) => {
  console.log('Aborted because:', reason);
});

fetch('https://api.example.com/data', {
  signal: controller.signal
});

controller.abort('User navigated away');
```

---

## AbortSignal Usage

### Core Integration

The `AbortSignal` integrates with fetch through the `signal` option in the request configuration. When the associated `AbortController` calls `abort()`, the fetch request terminates immediately and rejects with an `AbortError`.

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('Request aborted');
    }
  });

// Abort the request
controller.abort();
```

### Timeout Implementation

`AbortSignal.timeout()` creates a signal that automatically aborts after a specified duration in milliseconds.

```javascript
// Aborts after 5 seconds
fetch('https://api.example.com/data', {
  signal: AbortSignal.timeout(5000)
})
.catch(err => {
  if (err.name === 'TimeoutError') {
    console.log('Request timed out');
  }
});
```

### Signal Composition with AbortSignal.any()

`AbortSignal.any()` combines multiple signals, aborting when any of the input signals aborts. This enables complex cancellation scenarios.

```javascript
const userController = new AbortController();
const timeoutSignal = AbortSignal.timeout(10000);

const combinedSignal = AbortSignal.any([
  userController.signal,
  timeoutSignal
]);

fetch('https://api.example.com/data', { signal: combinedSignal })
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('Aborted by user');
    } else if (err.name === 'TimeoutError') {
      console.log('Request timeout');
    }
  });

// User can still manually abort
userController.abort();
```

### Event Handling

The `abort` event fires when a signal is aborted, allowing cleanup operations or state updates.

```javascript
const controller = new AbortController();
const signal = controller.signal;

signal.addEventListener('abort', () => {
  console.log('Signal aborted');
  console.log('Abort reason:', signal.reason);
});

fetch('https://api.example.com/data', { signal });

controller.abort('User cancelled operation');
```

### Abort Reasons

Custom abort reasons provide context about why cancellation occurred.

```javascript
const controller = new AbortController();

fetch('https://api.example.com/data', { signal: controller.signal })
  .catch(err => {
    console.log(err.message); // Custom reason
  });

controller.abort(new Error('Network switch detected'));
```

### Signal Reuse Patterns

Signals cannot be reused after abortion. Each new request sequence requires a fresh `AbortController`.

```javascript
// Incorrect - reusing aborted signal
const controller = new AbortController();
controller.abort();

fetch('https://api.example.com/data', { signal: controller.signal });
// This immediately fails with AbortError

// Correct - new controller per request
function makeRequest() {
  const controller = new AbortController();
  
  fetch('https://api.example.com/data', { 
    signal: controller.signal 
  });
  
  return controller;
}
```

### Race Condition Handling

Check `signal.aborted` before initiating expensive operations that follow fetch.

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .then(data => {
    // Check if aborted before processing
    if (signal.aborted) {
      return;
    }
    
    // Expensive processing
    processLargeDataset(data);
  });
```

### Cleanup in Async Functions

Proper cleanup ensures resources release even when requests abort mid-flight.

```javascript
async function fetchWithCleanup(url, signal) {
  let stream;
  
  try {
    const response = await fetch(url, { signal });
    stream = response.body;
    
    const reader = stream.getReader();
    
    while (true) {
      const { done, value } = await reader.read();
      
      if (done || signal.aborted) break;
      
      processChunk(value);
    }
  } catch (err) {
    if (err.name === 'AbortError') {
      console.log('Streaming aborted');
    }
    throw err;
  } finally {
    if (stream) {
      await stream.cancel();
    }
  }
}
```

### Debounced Request Pattern

Cancel previous requests when new ones are initiated rapidly, common in search-as-you-type scenarios.

```javascript
let currentController = null;

async function searchAPI(query) {
  // Abort previous request
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  
  try {
    const response = await fetch(
      `https://api.example.com/search?q=${query}`,
      { signal: currentController.signal }
    );
    
    const results = await response.json();
    displayResults(results);
  } catch (err) {
    if (err.name !== 'AbortError') {
      console.error('Search failed:', err);
    }
  }
}
```

### Multiple Concurrent Requests

Manage multiple requests with individual or grouped cancellation capabilities.

```javascript
class RequestManager {
  constructor() {
    this.controllers = new Map();
  }
  
  async fetch(id, url, options = {}) {
    const controller = new AbortController();
    this.controllers.set(id, controller);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } finally {
      this.controllers.delete(id);
    }
  }
  
  abort(id) {
    const controller = this.controllers.get(id);
    if (controller) {
      controller.abort();
    }
  }
  
  abortAll() {
    for (const controller of this.controllers.values()) {
      controller.abort();
    }
    this.controllers.clear();
  }
}
```

### Navigation-Based Cancellation

Cancel requests when users navigate away from pages or components.

```javascript
// React example
useEffect(() => {
  const controller = new AbortController();
  
  fetch('https://api.example.com/data', {
    signal: controller.signal
  })
    .then(response => response.json())
    .then(data => setState(data))
    .catch(err => {
      if (err.name !== 'AbortError') {
        console.error(err);
      }
    });
  
  // Cleanup on unmount
  return () => controller.abort();
}, []);
```

### Priority-Based Cancellation

Abort lower-priority requests when higher-priority ones are initiated.

```javascript
class PriorityRequestQueue {
  constructor() {
    this.currentRequest = null;
    this.currentPriority = 0;
  }
  
  async fetch(url, priority = 0) {
    // Cancel if lower priority request exists
    if (this.currentRequest && priority > this.currentPriority) {
      this.currentRequest.abort();
    }
    
    const controller = new AbortController();
    this.currentRequest = controller;
    this.currentPriority = priority;
    
    try {
      const response = await fetch(url, { 
        signal: controller.signal 
      });
      return await response.json();
    } finally {
      if (this.currentRequest === controller) {
        this.currentRequest = null;
      }
    }
  }
}
```

### Signal Propagation in Request Chains

Propagate abort signals through multiple dependent requests.

```javascript
async function fetchUserWithPosts(userId, signal) {
  // First request - fetch user
  const userResponse = await fetch(
    `https://api.example.com/users/${userId}`,
    { signal }
  );
  const user = await userResponse.json();
  
  // Check if aborted between requests
  if (signal.aborted) {
    throw new DOMException('Aborted', 'AbortError');
  }
  
  // Second request - fetch posts, using same signal
  const postsResponse = await fetch(
    `https://api.example.com/users/${userId}/posts`,
    { signal }
  );
  const posts = await postsResponse.json();
  
  return { user, posts };
}
```

### ThrowIfAborted Pattern

The `signal.throwIfAborted()` method throws an `AbortError` if the signal is already aborted, useful for early exit checks.

```javascript
async function complexOperation(signal) {
  // Check at start
  signal.throwIfAborted();
  
  await step1();
  
  // Check between steps
  signal.throwIfAborted();
  
  await step2();
  
  signal.throwIfAborted();
  
  await step3();
}
```

### Custom Abort Controllers

Extend `AbortController` for specialized cancellation logic.

```javascript
class RetryableController extends AbortController {
  constructor(maxRetries = 3) {
    super();
    this.maxRetries = maxRetries;
    this.attempt = 0;
  }
  
  async fetchWithRetry(url, options = {}) {
    while (this.attempt < this.maxRetries) {
      try {
        this.attempt++;
        
        const response = await fetch(url, {
          ...options,
          signal: this.signal
        });
        
        if (!response.ok && this.attempt < this.maxRetries) {
          await new Promise(resolve => 
            setTimeout(resolve, 1000 * this.attempt)
          );
          continue;
        }
        
        return response;
      } catch (err) {
        if (err.name === 'AbortError' || 
            this.attempt >= this.maxRetries) {
          throw err;
        }
      }
    }
  }
}
```

### Memory Leak Prevention

Ensure controllers and event listeners are properly cleaned up to prevent memory leaks.

```javascript
class RequestHandler {
  constructor() {
    this.activeControllers = new Set();
  }
  
  async fetch(url, options = {}) {
    const controller = new AbortController();
    this.activeControllers.add(controller);
    
    const cleanup = () => {
      this.activeControllers.delete(controller);
    };
    
    controller.signal.addEventListener('abort', cleanup);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } finally {
      cleanup();
    }
  }
  
  destroy() {
    // Abort all active requests
    for (const controller of this.activeControllers) {
      controller.abort();
    }
    this.activeControllers.clear();
  }
}
```

### Conditional Abort Logic

Implement abort conditions based on response characteristics or runtime state.

```javascript
async function fetchWithSizeLimit(url, maxBytes) {
  const controller = new AbortController();
  let bytesReceived = 0;
  
  const response = await fetch(url, { 
    signal: controller.signal 
  });
  
  const reader = response.body.getReader();
  const chunks = [];
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;
    
    bytesReceived += value.length;
    
    if (bytesReceived > maxBytes) {
      controller.abort('Size limit exceeded');
      break;
    }
    
    chunks.push(value);
  }
  
  return chunks;
}
```

---

## Cancelling In-Flight Requests

### AbortController and AbortSignal

The `AbortController` interface provides the standard mechanism for cancelling fetch requests. It works through a signal-based pattern where an `AbortController` generates an `AbortSignal` that can be passed to fetch operations.

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Request was cancelled');
    }
  });

// Abort the request
controller.abort();
```

### AbortController Mechanics

#### Creating and Using Controllers

Each `AbortController` instance is single-use. Once `abort()` is called, the controller cannot be reset or reused. The associated signal's `aborted` property becomes `true` and remains so permanently.

```javascript
const controller = new AbortController();
console.log(controller.signal.aborted); // false

controller.abort();
console.log(controller.signal.aborted); // true

// This controller is now permanently aborted
// Create a new one for subsequent requests
```

#### Signal Propagation

The signal is passed as an option to fetch. Once the controller aborts, any associated fetch request that hasn't completed will be cancelled immediately.

```javascript
const controller = new AbortController();

fetch('/api/slow-endpoint', {
  signal: controller.signal,
  method: 'POST',
  body: JSON.stringify({ data: 'value' })
});

// Abort after 5 seconds
setTimeout(() => controller.abort(), 5000);
```

### Timeout Implementation

Implementing request timeouts using `AbortController`:

```javascript
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const signal = controller.signal;
  
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  return fetch(url, { ...options, signal })
    .finally(() => clearTimeout(timeoutId));
}

// Usage
fetchWithTimeout('/api/data', {}, 3000)
  .then(response => response.json())
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Request timed out');
    }
  });
```

### Abort Reasons

The `abort()` method accepts an optional reason parameter that becomes the rejection value:

```javascript
const controller = new AbortController();

fetch('/api/data', { signal: controller.signal })
  .catch(error => {
    console.log(error); // DOMException or custom error
    console.log(error.message); // "User cancelled the request"
  });

controller.abort(new Error('User cancelled the request'));
```

Without a reason, the default `DOMException` with name `'AbortError'` is used.

### Multiple Requests with One Controller

A single `AbortController` can cancel multiple simultaneous requests:

```javascript
const controller = new AbortController();
const signal = controller.signal;

const requests = [
  fetch('/api/users', { signal }),
  fetch('/api/posts', { signal }),
  fetch('/api/comments', { signal })
];

Promise.all(requests)
  .then(responses => Promise.all(responses.map(r => r.json())))
  .then(data => console.log(data))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('All requests cancelled');
    }
  });

// Cancel all three requests at once
controller.abort();
```

### Signal Event Listeners

The `AbortSignal` is an `EventTarget` and emits an `abort` event when cancelled:

```javascript
const controller = new AbortController();
const signal = controller.signal;

signal.addEventListener('abort', () => {
  console.log('Request was aborted');
  console.log('Abort reason:', signal.reason);
});

fetch('/api/data', { signal });

controller.abort('User navigated away');
```

The `signal.reason` property contains the abort reason passed to `controller.abort()`.

### AbortSignal.timeout()

Modern browsers support `AbortSignal.timeout()` as a convenience method for timeout-based cancellation:

```javascript
// Automatically abort after 5 seconds
fetch('/api/data', {
  signal: AbortSignal.timeout(5000)
})
.catch(error => {
  if (error.name === 'TimeoutError') {
    console.log('Request timed out');
  }
});
```

This creates a signal that automatically aborts after the specified milliseconds, throwing a `TimeoutError` rather than an `AbortError`.

### AbortSignal.any()

Combine multiple signals to abort when any of them triggers:

```javascript
const userController = new AbortController();
const timeoutSignal = AbortSignal.timeout(10000);

const combinedSignal = AbortSignal.any([
  userController.signal,
  timeoutSignal
]);

fetch('/api/data', { signal: combinedSignal })
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Cancelled by user');
    } else if (error.name === 'TimeoutError') {
      console.log('Request timed out');
    }
  });

// User can cancel early
document.getElementById('cancel').onclick = () => {
  userController.abort();
};
```

### Race Conditions and Stale Requests

When requests can be cancelled and reissued rapidly (such as in search-as-you-type), managing controllers prevents stale data:

```javascript
let currentController = null;

function searchUsers(query) {
  // Cancel previous request if still in flight
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  const signal = currentController.signal;
  
  return fetch(`/api/search?q=${query}`, { signal })
    .then(response => response.json())
    .then(results => {
      // Only process if this request wasn't aborted
      if (!signal.aborted) {
        displayResults(results);
      }
    })
    .catch(error => {
      if (error.name !== 'AbortError') {
        console.error('Search failed:', error);
      }
    });
}

// Rapid user input
searchInput.addEventListener('input', (e) => {
  searchUsers(e.target.value);
});
```

### Request Cleanup Patterns

Proper cleanup ensures resources are released:

```javascript
class RequestManager {
  constructor() {
    this.controllers = new Map();
  }
  
  fetch(id, url, options = {}) {
    // Cancel existing request with same ID
    this.cancel(id);
    
    const controller = new AbortController();
    this.controllers.set(id, controller);
    
    return fetch(url, { ...options, signal: controller.signal })
      .finally(() => {
        // Clean up after completion or cancellation
        this.controllers.delete(id);
      });
  }
  
  cancel(id) {
    const controller = this.controllers.get(id);
    if (controller) {
      controller.abort();
      this.controllers.delete(id);
    }
  }
  
  cancelAll() {
    this.controllers.forEach(controller => controller.abort());
    this.controllers.clear();
  }
}

// Usage
const manager = new RequestManager();

manager.fetch('userData', '/api/user/123');
manager.fetch('userPosts', '/api/user/123/posts');

// Cancel specific request
manager.cancel('userData');

// Cancel all requests (e.g., on component unmount)
manager.cancelAll();
```

### React Integration Pattern

Cancelling requests on component unmount:

```javascript
function UserProfile({ userId }) {
  const [user, setUser] = useState(null);
  
  useEffect(() => {
    const controller = new AbortController();
    
    fetch(`/api/users/${userId}`, {
      signal: controller.signal
    })
      .then(response => response.json())
      .then(data => setUser(data))
      .catch(error => {
        if (error.name !== 'AbortError') {
          console.error('Failed to fetch user:', error);
        }
      });
    
    // Cleanup function cancels request on unmount
    return () => controller.abort();
  }, [userId]);
  
  return user ? <div>{user.name}</div> : <div>Loading...</div>;
}
```

### Network State Considerations

[Inference] When `abort()` is called, the browser attempts to cancel the network request. However, the actual network behavior depends on timing:

- If the request hasn't been sent yet, it won't be sent
- If the request is in-flight, the browser closes the connection
- If the response headers have been received but the body is still downloading, the download is stopped
- If the response is complete, abortion has no network effect but the promise still rejects

### Error Handling Patterns

Distinguishing between abortion and other errors:

```javascript
async function fetchData(url, signal) {
  try {
    const response = await fetch(url, { signal });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    return await response.json();
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Request cancelled');
      return null; // Or handle cancellation-specific logic
    }
    
    if (error.name === 'TimeoutError') {
      console.log('Request timed out');
      throw error; // Re-throw or handle differently
    }
    
    // Other network or parsing errors
    console.error('Request failed:', error);
    throw error;
  }
}
```

### Polling with Cancellation

Implementing cancellable polling:

```javascript
class Poller {
  constructor(url, interval = 5000) {
    this.url = url;
    this.interval = interval;
    this.controller = null;
    this.timeoutId = null;
  }
  
  start(callback) {
    this.stop(); // Stop any existing polling
    this.controller = new AbortController();
    
    const poll = async () => {
      try {
        const response = await fetch(this.url, {
          signal: this.controller.signal
        });
        const data = await response.json();
        callback(data);
        
        // Schedule next poll
        this.timeoutId = setTimeout(poll, this.interval);
      } catch (error) {
        if (error.name !== 'AbortError') {
          console.error('Polling error:', error);
          // Retry after interval
          this.timeoutId = setTimeout(poll, this.interval);
        }
      }
    };
    
    poll();
  }
  
  stop() {
    if (this.controller) {
      this.controller.abort();
      this.controller = null;
    }
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
}

// Usage
const poller = new Poller('/api/status', 3000);
poller.start(data => console.log('Status:', data));

// Stop polling
poller.stop();
```

### Progressive Loading with Cancellation

Cancelling while reading streaming responses:

```javascript
async function fetchWithProgress(url, onProgress) {
  const controller = new AbortController();
  const signal = controller.signal;
  
  try {
    const response = await fetch(url, { signal });
    const reader = response.body.getReader();
    const contentLength = +response.headers.get('Content-Length');
    
    let receivedLength = 0;
    const chunks = [];
    
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      chunks.push(value);
      receivedLength += value.length;
      
      onProgress(receivedLength, contentLength);
      
      // Check if aborted during streaming
      if (signal.aborted) {
        reader.cancel();
        throw new DOMException('Aborted', 'AbortError');
      }
    }
    
    return new Blob(chunks);
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Download cancelled');
    }
    throw error;
  }
  
  // Return controller for external cancellation
  return { controller };
}
```

### Debounced Requests

Combining debouncing with automatic cancellation:

```javascript
function debounceWithAbort(func, delay) {
  let timeoutId;
  let controller;
  
  return function(...args) {
    // Cancel previous request
    if (controller) {
      controller.abort();
    }
    
    // Clear previous timeout
    clearTimeout(timeoutId);
    
    // Create new controller for this request
    controller = new AbortController();
    
    // Set new timeout
    timeoutId = setTimeout(() => {
      func.apply(this, [...args, controller.signal]);
    }, delay);
    
    // Return controller for manual cancellation if needed
    return controller;
  };
}

// Usage
const debouncedSearch = debounceWithAbort((query, signal) => {
  fetch(`/api/search?q=${query}`, { signal })
    .then(response => response.json())
    .then(results => displayResults(results))
    .catch(error => {
      if (error.name !== 'AbortError') {
        console.error('Search failed:', error);
      }
    });
}, 300);

searchInput.addEventListener('input', (e) => {
  debouncedSearch(e.target.value);
});
```

### Browser Compatibility Notes

`AbortController` and `AbortSignal` are supported in all modern browsers. `AbortSignal.timeout()` and `AbortSignal.any()` are newer additions with more limited support. For older browsers, polyfills exist or manual timeout implementations can be used as shown in earlier examples.

---

## Timeout Implementation for Fetch API

### Native AbortController Approach

The `AbortController` interface provides the standard mechanism for implementing timeouts with fetch requests. This approach integrates directly with the fetch API's abort signal system.

```javascript
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 5000);

try {
  const response = await fetch('https://api.example.com/data', {
    signal: controller.signal
  });
  clearTimeout(timeoutId);
  const data = await response.json();
} catch (error) {
  if (error.name === 'AbortError') {
    console.error('Request timed out');
  }
  throw error;
}
```

### Timeout Wrapper Function

Encapsulating timeout logic in a reusable wrapper function improves code organization and maintainability.

```javascript
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  return fetch(url, {
    ...options,
    signal: controller.signal
  }).finally(() => clearTimeout(timeoutId));
}

// Usage
const response = await fetchWithTimeout('https://api.example.com/data', {}, 8000);
```

### Promise.race Pattern

Using `Promise.race` allows explicit timeout promise construction, providing more control over timeout behavior and error messages.

```javascript
function createTimeout(ms) {
  return new Promise((_, reject) => {
    setTimeout(() => reject(new Error(`Request timeout after ${ms}ms`)), ms);
  });
}

try {
  const response = await Promise.race([
    fetch('https://api.example.com/data'),
    createTimeout(5000)
  ]);
} catch (error) {
  console.error(error.message);
}
```

### Combining AbortController with Promise.race

This pattern provides both proper request cancellation and custom timeout errors.

```javascript
async function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  
  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => {
      controller.abort();
      reject(new Error(`Timeout: Request exceeded ${timeout}ms`));
    }, timeout);
  });
  
  try {
    return await Promise.race([
      fetch(url, { ...options, signal: controller.signal }),
      timeoutPromise
    ]);
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new Error(`Request aborted due to timeout (${timeout}ms)`);
    }
    throw error;
  }
}
```

### Timeout with Retry Logic

Implementing retry mechanisms with timeouts handles transient network issues gracefully.

```javascript
async function fetchWithRetry(url, options = {}, timeout = 5000, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      lastError = error;
      
      if (error.name === 'AbortError') {
        console.warn(`Attempt ${attempt + 1} timed out`);
      }
      
      if (attempt < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
      }
    }
  }
  
  throw lastError;
}
```

### Separate Read/Connection Timeouts

Distinguishing between connection establishment and data transfer timeouts provides finer control over network operations.

```javascript
async function fetchWithDualTimeout(url, options = {}, connectTimeout = 5000, readTimeout = 30000) {
  const connectController = new AbortController();
  const readController = new AbortController();
  
  const connectTimeoutId = setTimeout(() => connectController.abort(), connectTimeout);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: connectController.signal
    });
    
    clearTimeout(connectTimeoutId);
    
    const readTimeoutId = setTimeout(() => readController.abort(), readTimeout);
    
    const reader = response.body.getReader();
    const chunks = [];
    
    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
        
        if (readController.signal.aborted) {
          throw new Error('Read timeout exceeded');
        }
      }
      clearTimeout(readTimeoutId);
      
      const blob = new Blob(chunks);
      return new Response(blob, {
        status: response.status,
        statusText: response.statusText,
        headers: response.headers
      });
    } catch (error) {
      clearTimeout(readTimeoutId);
      throw error;
    }
  } catch (error) {
    clearTimeout(connectTimeoutId);
    if (error.name === 'AbortError') {
      throw new Error('Connection timeout exceeded');
    }
    throw error;
  }
}
```

### Timeout Class Implementation

Object-oriented approach for managing complex timeout scenarios with multiple requests.

```javascript
class FetchTimeout {
  constructor(defaultTimeout = 5000) {
    this.defaultTimeout = defaultTimeout;
    this.activeRequests = new Map();
  }
  
  async fetch(url, options = {}, timeout = this.defaultTimeout) {
    const controller = new AbortController();
    const requestId = Symbol();
    
    const timeoutId = setTimeout(() => {
      controller.abort();
      this.activeRequests.delete(requestId);
    }, timeout);
    
    this.activeRequests.set(requestId, { controller, timeoutId, url });
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      this.activeRequests.delete(requestId);
      
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      this.activeRequests.delete(requestId);
      throw error;
    }
  }
  
  abortAll() {
    for (const [requestId, { controller, timeoutId }] of this.activeRequests) {
      controller.abort();
      clearTimeout(timeoutId);
    }
    this.activeRequests.clear();
  }
  
  getActiveCount() {
    return this.activeRequests.size;
  }
}

// Usage
const fetcher = new FetchTimeout(8000);
const response = await fetcher.fetch('https://api.example.com/data');
```

### Progressive Timeout Strategy

Implementing increasing timeouts for retry attempts accommodates varying network conditions.

```javascript
async function fetchWithProgressiveTimeout(url, options = {}, baseTimeout = 3000, maxAttempts = 3) {
  for (let attempt = 0; attempt < maxAttempts; attempt++) {
    const timeout = baseTimeout * Math.pow(2, attempt);
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError' && attempt < maxAttempts - 1) {
        console.warn(`Timeout at ${timeout}ms, retrying with longer timeout`);
        continue;
      }
      throw error;
    }
  }
}
```

### Timeout with Progress Tracking

For large file downloads or uploads, tracking progress while maintaining timeout enforcement.

```javascript
async function fetchWithTimeoutAndProgress(url, options = {}, timeout = 30000, onProgress) {
  const controller = new AbortController();
  let lastActivity = Date.now();
  
  const activityCheck = setInterval(() => {
    if (Date.now() - lastActivity > timeout) {
      controller.abort();
      clearInterval(activityCheck);
    }
  }, 1000);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    
    const contentLength = response.headers.get('content-length');
    const total = parseInt(contentLength, 10);
    let loaded = 0;
    
    const reader = response.body.getReader();
    const chunks = [];
    
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      chunks.push(value);
      loaded += value.length;
      lastActivity = Date.now();
      
      if (onProgress) {
        onProgress({ loaded, total });
      }
    }
    
    clearInterval(activityCheck);
    
    const blob = new Blob(chunks);
    return new Response(blob, {
      status: response.status,
      statusText: response.statusText,
      headers: response.headers
    });
  } catch (error) {
    clearInterval(activityCheck);
    throw error;
  }
}
```

### Idle Timeout vs Absolute Timeout

Differentiating between inactivity timeout and maximum duration timeout.

```javascript
async function fetchWithIdleTimeout(url, options = {}, idleTimeout = 5000, absoluteTimeout = 60000) {
  const controller = new AbortController();
  let idleTimeoutId;
  let absoluteTimeoutId;
  
  const resetIdleTimeout = () => {
    clearTimeout(idleTimeoutId);
    idleTimeoutId = setTimeout(() => controller.abort(), idleTimeout);
  };
  
  absoluteTimeoutId = setTimeout(() => controller.abort(), absoluteTimeout);
  resetIdleTimeout();
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    
    resetIdleTimeout();
    
    const reader = response.body.getReader();
    const chunks = [];
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      chunks.push(value);
      resetIdleTimeout();
    }
    
    clearTimeout(idleTimeoutId);
    clearTimeout(absoluteTimeoutId);
    
    const blob = new Blob(chunks);
    return new Response(blob, {
      status: response.status,
      statusText: response.statusText,
      headers: response.headers
    });
  } catch (error) {
    clearTimeout(idleTimeoutId);
    clearTimeout(absoluteTimeoutId);
    throw error;
  }
}
```

### Custom TimeoutError Class

Creating specific error types improves error handling and debugging.

```javascript
class TimeoutError extends Error {
  constructor(message, duration, url) {
    super(message);
    this.name = 'TimeoutError';
    this.duration = duration;
    this.url = url;
    this.timestamp = new Date();
  }
}

async function fetchWithCustomError(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    clearTimeout(timeoutId);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    if (error.name === 'AbortError') {
      throw new TimeoutError(
        `Request to ${url} exceeded timeout of ${timeout}ms`,
        timeout,
        url
      );
    }
    throw error;
  }
}
```

### Timeout with Request Queuing

Managing multiple requests with individual timeouts while respecting concurrency limits.

```javascript
class TimeoutQueue {
  constructor(concurrency = 5, defaultTimeout = 5000) {
    this.concurrency = concurrency;
    this.defaultTimeout = defaultTimeout;
    this.queue = [];
    this.active = 0;
  }
  
  async fetch(url, options = {}, timeout = this.defaultTimeout) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, timeout, resolve, reject });
      this.processQueue();
    });
  }
  
  async processQueue() {
    if (this.active >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { url, options, timeout, resolve, reject } = this.queue.shift();
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      resolve(response);
    } catch (error) {
      clearTimeout(timeoutId);
      reject(error);
    } finally {
      this.active--;
      this.processQueue();
    }
  }
}
```

### Timeout Metrics Collection

Tracking timeout occurrences and durations for monitoring and optimization.

```javascript
class FetchWithMetrics {
  constructor(defaultTimeout = 5000) {
    this.defaultTimeout = defaultTimeout;
    this.metrics = {
      totalRequests: 0,
      timeouts: 0,
      successfulRequests: 0,
      averageResponseTime: 0,
      timeoutsByUrl: new Map()
    };
  }
  
  async fetch(url, options = {}, timeout = this.defaultTimeout) {
    const startTime = Date.now();
    this.metrics.totalRequests++;
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      const duration = Date.now() - startTime;
      this.metrics.successfulRequests++;
      this.updateAverageResponseTime(duration);
      
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        this.metrics.timeouts++;
        const urlTimeouts = this.metrics.timeoutsByUrl.get(url) || 0;
        this.metrics.timeoutsByUrl.set(url, urlTimeouts + 1);
      }
      
      throw error;
    }
  }
  
  updateAverageResponseTime(duration) {
    const total = this.metrics.averageResponseTime * (this.metrics.successfulRequests - 1);
    this.metrics.averageResponseTime = (total + duration) / this.metrics.successfulRequests;
  }
  
  getMetrics() {
    return { ...this.metrics };
  }
}
```

---

## Multiple Request Cancellation

### AbortController for Multiple Requests

The `AbortController` API enables cancellation of multiple fetch requests simultaneously by sharing a single signal across requests or managing multiple controllers.

```javascript
const controller = new AbortController();
const signal = controller.signal;

// Multiple requests sharing one signal
const requests = [
  fetch('/api/users', { signal }),
  fetch('/api/posts', { signal }),
  fetch('/api/comments', { signal })
];

// Cancel all requests at once
controller.abort();
```

### Managing Multiple Controllers

When requests need independent cancellation alongside group cancellation, maintain separate controllers while providing a mechanism to abort all.

```javascript
const controllers = new Map();

function makeRequest(id, url) {
  const controller = new AbortController();
  controllers.set(id, controller);
  
  return fetch(url, { signal: controller.signal })
    .then(response => response.json())
    .finally(() => controllers.delete(id));
}

// Cancel specific request
function cancelRequest(id) {
  const controller = controllers.get(id);
  if (controller) {
    controller.abort();
    controllers.delete(id);
  }
}

// Cancel all requests
function cancelAllRequests() {
  controllers.forEach(controller => controller.abort());
  controllers.clear();
}
```

### Hierarchical Signal Propagation

Create parent-child relationships between abort signals using `AbortSignal.any()` to cascade cancellation through request hierarchies.

```javascript
// Parent controller for all requests
const parentController = new AbortController();

// Child controllers for specific groups
const userRequestsController = new AbortController();
const postRequestsController = new AbortController();

// Combine signals - abort if either parent OR child signals
const userSignal = AbortSignal.any([
  parentController.signal,
  userRequestsController.signal
]);

const postSignal = AbortSignal.any([
  parentController.signal,
  postRequestsController.signal
]);

// Requests respect both hierarchies
fetch('/api/users', { signal: userSignal });
fetch('/api/posts', { signal: postSignal });

// Cancel all users requests only
userRequestsController.abort();

// Cancel everything
parentController.abort();
```

### Promise.allSettled with Cancellation

Handle multiple requests with cancellation while tracking individual outcomes.

```javascript
async function fetchMultipleWithCancellation(urls, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  const requests = urls.map(url =>
    fetch(url, { signal: controller.signal })
      .then(response => response.json())
      .then(data => ({ status: 'fulfilled', value: data, url }))
      .catch(error => ({ 
        status: 'rejected', 
        reason: error.name === 'AbortError' ? 'Cancelled' : error.message,
        url 
      }))
  );
  
  const results = await Promise.allSettled(requests);
  clearTimeout(timeoutId);
  
  return results;
}
```

### Cancellation with Cleanup

Implement proper cleanup when cancelling multiple requests to prevent memory leaks and ensure resources are released.

```javascript
class RequestManager {
  constructor() {
    this.activeRequests = new Map();
  }
  
  async fetch(id, url, options = {}) {
    // Cancel existing request with same ID
    this.cancel(id);
    
    const controller = new AbortController();
    const signal = options.signal 
      ? AbortSignal.any([controller.signal, options.signal])
      : controller.signal;
    
    const requestData = {
      controller,
      url,
      promise: null
    };
    
    this.activeRequests.set(id, requestData);
    
    try {
      const response = await fetch(url, { ...options, signal });
      const data = await response.json();
      return data;
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log(`Request ${id} cancelled`);
      }
      throw error;
    } finally {
      this.activeRequests.delete(id);
    }
  }
  
  cancel(id) {
    const request = this.activeRequests.get(id);
    if (request) {
      request.controller.abort();
      this.activeRequests.delete(id);
    }
  }
  
  cancelAll() {
    this.activeRequests.forEach((request, id) => {
      request.controller.abort();
    });
    this.activeRequests.clear();
  }
  
  cancelByPattern(pattern) {
    this.activeRequests.forEach((request, id) => {
      if (pattern.test(request.url) || pattern.test(id)) {
        request.controller.abort();
        this.activeRequests.delete(id);
      }
    });
  }
  
  get activeCount() {
    return this.activeRequests.size;
  }
}

// Usage
const manager = new RequestManager();

manager.fetch('user-1', '/api/users/1');
manager.fetch('user-2', '/api/users/2');
manager.fetch('posts', '/api/posts');

// Cancel specific request
manager.cancel('user-1');

// Cancel by pattern
manager.cancelByPattern(/^user-/);

// Cancel all
manager.cancelAll();
```

### Race Conditions and Latest Request Pattern

Cancel previous requests when new ones are initiated, ensuring only the latest request completes.

```javascript
let currentController = null;

async function fetchLatest(url) {
  // Cancel previous request
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  const signal = currentController.signal;
  
  try {
    const response = await fetch(url, { signal });
    const data = await response.json();
    
    // Only process if this is still the current request
    if (signal.aborted) return null;
    
    return data;
  } catch (error) {
    if (error.name === 'AbortError') {
      return null; // Silent cancellation
    }
    throw error;
  }
}

// Debounced search with cancellation
function createDebouncedSearch(delay = 300) {
  let timeoutId;
  let controller;
  
  return async function(query) {
    clearTimeout(timeoutId);
    
    if (controller) {
      controller.abort();
    }
    
    return new Promise((resolve, reject) => {
      timeoutId = setTimeout(async () => {
        controller = new AbortController();
        
        try {
          const response = await fetch(`/api/search?q=${query}`, {
            signal: controller.signal
          });
          const data = await response.json();
          resolve(data);
        } catch (error) {
          if (error.name !== 'AbortError') {
            reject(error);
          }
        }
      }, delay);
    });
  };
}
```

### Batch Cancellation with Priorities

Implement priority-based cancellation where low-priority requests are cancelled when high-priority requests are initiated.

```javascript
class PriorityRequestManager {
  constructor() {
    this.requests = new Map();
    this.priorities = { LOW: 1, MEDIUM: 2, HIGH: 3 };
  }
  
  async fetch(id, url, priority = this.priorities.MEDIUM, options = {}) {
    const controller = new AbortController();
    
    const requestData = {
      controller,
      priority,
      url,
      timestamp: Date.now()
    };
    
    this.requests.set(id, requestData);
    
    // Cancel lower priority requests if we're at capacity
    this.enforceLimits(priority);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } finally {
      this.requests.delete(id);
    }
  }
  
  enforceLimits(newRequestPriority, maxConcurrent = 5) {
    if (this.requests.size < maxConcurrent) return;
    
    // Cancel lowest priority requests
    const sortedRequests = Array.from(this.requests.entries())
      .sort(([, a], [, b]) => {
        if (a.priority !== b.priority) {
          return a.priority - b.priority;
        }
        return a.timestamp - b.timestamp;
      });
    
    for (const [id, request] of sortedRequests) {
      if (request.priority < newRequestPriority) {
        this.cancel(id);
        if (this.requests.size < maxConcurrent) break;
      }
    }
  }
  
  cancel(id) {
    const request = this.requests.get(id);
    if (request) {
      request.controller.abort();
      this.requests.delete(id);
    }
  }
  
  cancelByPriority(priority) {
    this.requests.forEach((request, id) => {
      if (request.priority === priority) {
        request.controller.abort();
        this.requests.delete(id);
      }
    });
  }
}
```

### Timeout-Based Group Cancellation

Apply timeouts to groups of requests with differential timeout policies.

```javascript
class TimeoutRequestGroup {
  constructor(defaultTimeout = 5000) {
    this.defaultTimeout = defaultTimeout;
    this.groups = new Map();
  }
  
  async fetchGroup(groupId, requests, timeout = this.defaultTimeout) {
    const controller = new AbortController();
    
    const timeoutId = setTimeout(() => {
      controller.abort();
    }, timeout);
    
    const groupData = {
      controller,
      timeoutId,
      requests: new Set()
    };
    
    this.groups.set(groupId, groupData);
    
    try {
      const promises = requests.map(({ url, options = {} }) => {
        const requestPromise = fetch(url, {
          ...options,
          signal: controller.signal
        }).then(r => r.json());
        
        groupData.requests.add(requestPromise);
        return requestPromise;
      });
      
      const results = await Promise.allSettled(promises);
      return results;
    } finally {
      clearTimeout(timeoutId);
      this.groups.delete(groupId);
    }
  }
  
  cancelGroup(groupId) {
    const group = this.groups.get(groupId);
    if (group) {
      clearTimeout(group.timeoutId);
      group.controller.abort();
      this.groups.delete(groupId);
    }
  }
  
  cancelAllGroups() {
    this.groups.forEach((group, groupId) => {
      this.cancelGroup(groupId);
    });
  }
}

// Usage
const groupManager = new TimeoutRequestGroup();

groupManager.fetchGroup('user-data', [
  { url: '/api/user/profile' },
  { url: '/api/user/settings' },
  { url: '/api/user/preferences' }
], 3000);

groupManager.fetchGroup('dashboard-data', [
  { url: '/api/dashboard/stats' },
  { url: '/api/dashboard/activity' }
], 5000);

// Cancel specific group
groupManager.cancelGroup('user-data');
```

### Event-Driven Cancellation

Implement cancellation triggered by application events or state changes.

```javascript
class EventDrivenRequestManager extends EventTarget {
  constructor() {
    super();
    this.requests = new Map();
  }
  
  async fetch(id, url, options = {}) {
    const controller = new AbortController();
    
    // Cancel on specific events
    const cancelOnEvents = options.cancelOn || [];
    const eventHandlers = [];
    
    cancelOnEvents.forEach(eventName => {
      const handler = () => controller.abort();
      this.addEventListener(eventName, handler);
      eventHandlers.push({ eventName, handler });
    });
    
    this.requests.set(id, {
      controller,
      eventHandlers,
      url
    });
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      return await response.json();
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log(`Request ${id} cancelled by event`);
      }
      throw error;
    } finally {
      // Cleanup event listeners
      eventHandlers.forEach(({ eventName, handler }) => {
        this.removeEventListener(eventName, handler);
      });
      this.requests.delete(id);
    }
  }
  
  cancel(id) {
    const request = this.requests.get(id);
    if (request) {
      request.controller.abort();
    }
  }
  
  triggerCancellation(eventName) {
    this.dispatchEvent(new Event(eventName));
  }
}

// Usage
const manager = new EventDrivenRequestManager();

// These requests will cancel on logout
manager.fetch('data-1', '/api/data/1', { 
  cancelOn: ['logout', 'page-change'] 
});
manager.fetch('data-2', '/api/data/2', { 
  cancelOn: ['logout'] 
});

// Trigger cancellation
manager.triggerCancellation('logout');
```

### Memory-Efficient Cancellation Tracking

Track cancelled requests efficiently without memory leaks in long-running applications.

```javascript
class EfficientRequestTracker {
  constructor(maxHistory = 100) {
    this.active = new Map();
    this.cancelled = new Map();
    this.maxHistory = maxHistory;
  }
  
  async fetch(id, url, options = {}) {
    const controller = new AbortController();
    const startTime = Date.now();
    
    this.active.set(id, {
      controller,
      url,
      startTime
    });
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      const data = await response.json();
      this.active.delete(id);
      return data;
    } catch (error) {
      this.active.delete(id);
      
      if (error.name === 'AbortError') {
        this.recordCancellation(id, Date.now() - startTime);
      }
      throw error;
    }
  }
  
  cancel(id) {
    const request = this.active.get(id);
    if (request) {
      request.controller.abort();
    }
  }
  
  cancelAll() {
    this.active.forEach((request) => {
      request.controller.abort();
    });
  }
  
  recordCancellation(id, duration) {
    this.cancelled.set(id, {
      timestamp: Date.now(),
      duration
    });
    
    // Prevent memory growth
    if (this.cancelled.size > this.maxHistory) {
      const oldest = Array.from(this.cancelled.keys())[0];
      this.cancelled.delete(oldest);
    }
  }
  
  getStats() {
    return {
      active: this.active.size,
      totalCancelled: this.cancelled.size,
      cancelled: Array.from(this.cancelled.entries())
    };
  }
}
```

### Composite Signal Patterns

Create complex cancellation conditions by combining multiple abort signals.

```javascript
// Cancel on any condition
function createCompositeSignal(...conditions) {
  const controllers = [];
  const signals = [];
  
  conditions.forEach(condition => {
    if (condition.signal) {
      signals.push(condition.signal);
    } else if (condition.timeout) {
      const controller = new AbortController();
      setTimeout(() => controller.abort(), condition.timeout);
      controllers.push(controller);
      signals.push(controller.signal);
    } else if (condition.event) {
      const controller = new AbortController();
      const handler = () => controller.abort();
      condition.target.addEventListener(condition.event, handler, { once: true });
      controllers.push(controller);
      signals.push(controller.signal);
    }
  });
  
  return AbortSignal.any(signals);
}

// Usage
const button = document.querySelector('#cancel-btn');

const signal = createCompositeSignal(
  { timeout: 5000 },
  { target: button, event: 'click' },
  { signal: parentController.signal }
);

fetch('/api/data', { signal });
```

### Cancellation with Retry Logic

Implement cancellation that respects retry attempts and backoff strategies.

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  const {
    signal: externalSignal,
    retryDelay = 1000,
    backoffMultiplier = 2,
    ...fetchOptions
  } = options;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    const controller = new AbortController();
    const signal = externalSignal
      ? AbortSignal.any([controller.signal, externalSignal])
      : controller.signal;
    
    try {
      const response = await fetch(url, { ...fetchOptions, signal });
      
      if (!response.ok && attempt < maxRetries) {
        const delay = retryDelay * Math.pow(backoffMultiplier, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
      
      return await response.json();
    } catch (error) {
      if (error.name === 'AbortError') {
        throw error; // Don't retry on cancellation
      }
      
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = retryDelay * Math.pow(backoffMultiplier, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}

// Multiple retrying requests with shared cancellation
const globalController = new AbortController();

Promise.all([
  fetchWithRetry('/api/data/1', { signal: globalController.signal }),
  fetchWithRetry('/api/data/2', { signal: globalController.signal }),
  fetchWithRetry('/api/data/3', { signal: globalController.signal })
]);

// Cancel all retrying requests
globalController.abort();
```

---

## Cleanup Patterns 

## AbortController and Request Cancellation

### Basic Abort Pattern

```javascript
const controller = new AbortController();
const signal = controller.signal;

fetch('https://api.example.com/data', { signal })
  .then(response => response.json())
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('Fetch aborted');
    }
  });

// Cancel the request
controller.abort();
```

### Timeout Implementation

```javascript
function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const signal = controller.signal;
  
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  return fetch(url, { ...options, signal })
    .finally(() => clearTimeout(timeoutId));
}
```

### Multiple Request Cancellation

```javascript
const controller = new AbortController();

Promise.all([
  fetch('/api/users', { signal: controller.signal }),
  fetch('/api/posts', { signal: controller.signal }),
  fetch('/api/comments', { signal: controller.signal })
])
  .then(responses => Promise.all(responses.map(r => r.json())))
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('All requests aborted');
    }
  });

// Abort all requests simultaneously
controller.abort();
```

## React Cleanup Patterns

### useEffect with Fetch

```javascript
useEffect(() => {
  const controller = new AbortController();
  
  fetch('/api/data', { signal: controller.signal })
    .then(res => res.json())
    .then(data => setState(data))
    .catch(err => {
      if (err.name !== 'AbortError') {
        setError(err);
      }
    });
  
  return () => controller.abort();
}, []);
```

### Preventing State Updates After Unmount

```javascript
useEffect(() => {
  let isMounted = true;
  const controller = new AbortController();
  
  fetch('/api/data', { signal: controller.signal })
    .then(res => res.json())
    .then(data => {
      if (isMounted) {
        setState(data);
      }
    })
    .catch(err => {
      if (isMounted && err.name !== 'AbortError') {
        setError(err);
      }
    });
  
  return () => {
    isMounted = false;
    controller.abort();
  };
}, []);
```

### Custom Hook Pattern

```javascript
function useFetch(url, options = {}) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    const controller = new AbortController();
    
    setLoading(true);
    fetch(url, { ...options, signal: controller.signal })
      .then(res => {
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        return res.json();
      })
      .then(data => {
        setData(data);
        setError(null);
      })
      .catch(err => {
        if (err.name !== 'AbortError') {
          setError(err);
        }
      })
      .finally(() => setLoading(false));
    
    return () => controller.abort();
  }, [url]);
  
  return { data, loading, error };
}
```

## Response Body Cleanup

### Stream Cancellation

```javascript
const response = await fetch('/large-file');
const reader = response.body.getReader();

try {
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // Process chunk
    if (shouldCancel) {
      await reader.cancel();
      break;
    }
  }
} finally {
  reader.releaseLock();
}
```

### Blob URL Cleanup

```javascript
const response = await fetch('/image.jpg');
const blob = await response.blob();
const blobUrl = URL.createObjectURL(blob);

// Use the URL
img.src = blobUrl;

// Cleanup when done
img.onload = () => {
  URL.revokeObjectURL(blobUrl);
};

// Or in React
useEffect(() => {
  const url = URL.createObjectURL(blob);
  setImageUrl(url);
  
  return () => URL.revokeObjectURL(url);
}, [blob]);
```

## Connection Pool Management

### Request Queue Pattern

```javascript
class FetchQueue {
  constructor(concurrency = 6) {
    this.concurrency = concurrency;
    this.running = 0;
    this.queue = [];
  }
  
  async add(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.running >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.running++;
    const { url, options, resolve, reject } = this.queue.shift();
    
    try {
      const response = await fetch(url, options);
      resolve(response);
    } catch (err) {
      reject(err);
    } finally {
      this.running--;
      this.process();
    }
  }
  
  clear() {
    this.queue.forEach(({ reject }) => {
      reject(new Error('Queue cleared'));
    });
    this.queue = [];
  }
}
```

### Connection Reuse with Keep-Alive

```javascript
// Keep-alive is enabled by default in fetch, but can be explicit
const keepAliveAgent = {
  keepalive: true
};

// In Node.js with custom agent
const https = require('https');
const agent = new https.Agent({
  keepAlive: true,
  maxSockets: 10,
  maxFreeSockets: 5,
  timeout: 60000
});

// Cleanup when done
agent.destroy();
```

## Memory Leak Prevention

### Avoid Holding Response References

```javascript
// Bad - holds entire response in memory
const responses = [];
for (const url of urls) {
  const response = await fetch(url);
  responses.push(response);
}

// Good - process and discard
for (const url of urls) {
  const response = await fetch(url);
  const data = await response.json();
  processData(data);
  // response is now eligible for garbage collection
}
```

### Response Body Consumption

```javascript
// Always consume the response body
const response = await fetch('/api/data');

// If you don't need the data, still consume it
if (!response.ok) {
  await response.text(); // Consume and discard
  throw new Error(`HTTP ${response.status}`);
}

// Or explicitly ignore
if (response.status === 204) {
  // No content, nothing to consume
} else {
  await response.json();
}
```

### EventSource Alternative Pattern

```javascript
// For long-lived connections, consider cleanup
const eventSource = new EventSource('/events');

eventSource.onmessage = (event) => {
  console.log(event.data);
};

// Cleanup
const cleanup = () => {
  eventSource.close();
};

// In React
useEffect(() => {
  const es = new EventSource('/events');
  es.onmessage = handleMessage;
  
  return () => es.close();
}, []);
```

## Debouncing and Request Deduplication

### Debounced Fetch

```javascript
function debouncedFetch(url, options = {}, delay = 300) {
  let timeoutId;
  let controller;
  
  return function() {
    // Cancel previous request
    if (controller) {
      controller.abort();
    }
    
    clearTimeout(timeoutId);
    
    return new Promise((resolve, reject) => {
      timeoutId = setTimeout(() => {
        controller = new AbortController();
        
        fetch(url, { ...options, signal: controller.signal })
          .then(resolve)
          .catch(reject);
      }, delay);
    });
  };
}
```

### Request Deduplication

```javascript
class FetchCache {
  constructor() {
    this.pending = new Map();
  }
  
  async fetch(url, options = {}) {
    const key = this.getKey(url, options);
    
    if (this.pending.has(key)) {
      return this.pending.get(key);
    }
    
    const promise = fetch(url, options)
      .then(res => res.json())
      .finally(() => {
        this.pending.delete(key);
      });
    
    this.pending.set(key, promise);
    return promise;
  }
  
  getKey(url, options) {
    return `${url}-${JSON.stringify(options)}`;
  }
  
  clear() {
    this.pending.clear();
  }
}
```

## Error Cleanup Patterns

### Retry with Abort

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  let controller;
  
  for (let i = 0; i < maxRetries; i++) {
    controller = new AbortController();
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      if (response.ok) return response;
      
      // Don't retry client errors
      if (response.status >= 400 && response.status < 500) {
        throw new Error(`Client error: ${response.status}`);
      }
    } catch (err) {
      if (err.name === 'AbortError' || i === maxRetries - 1) {
        throw err;
      }
      
      await new Promise(resolve => 
        setTimeout(resolve, Math.pow(2, i) * 1000)
      );
    }
  }
}

// Usage with cleanup
const controller = new AbortController();
fetchWithRetry('/api/data', { signal: controller.signal })
  .catch(err => console.error(err));

// Can still abort all retry attempts
controller.abort();
```

### Graceful Degradation Pattern

```javascript
async function fetchWithFallback(urls, options = {}) {
  const controller = new AbortController();
  const errors = [];
  
  for (const url of urls) {
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      if (response.ok) {
        return response;
      }
      
      errors.push({ url, status: response.status });
    } catch (err) {
      if (err.name === 'AbortError') throw err;
      errors.push({ url, error: err.message });
    }
  }
  
  throw new Error(`All endpoints failed: ${JSON.stringify(errors)}`);
}
```

## Cleanup in Navigation Context

### Page Navigation Abort

```javascript
// Vanilla JS
let currentFetch;

document.querySelectorAll('a').forEach(link => {
  link.addEventListener('click', () => {
    if (currentFetch) {
      currentFetch.abort();
    }
  });
});

function navigateAndFetch(url) {
  currentFetch = new AbortController();
  
  return fetch(url, { signal: currentFetch.signal })
    .then(res => res.json())
    .catch(err => {
      if (err.name !== 'AbortError') {
        throw err;
      }
    });
}
```

### Single Page Application Pattern

```javascript
// Router-based cleanup
class Router {
  constructor() {
    this.currentController = null;
  }
  
  async navigate(route) {
    // Abort previous route's requests
    if (this.currentController) {
      this.currentController.abort();
    }
    
    this.currentController = new AbortController();
    
    try {
      const data = await fetch(`/api${route}`, {
        signal: this.currentController.signal
      });
      
      this.render(await data.json());
    } catch (err) {
      if (err.name !== 'AbortError') {
        this.renderError(err);
      }
    }
  }
}
```

## Background Fetch Cleanup

### Service Worker Pattern

```javascript
// In service worker
self.addEventListener('fetch', (event) => {
  event.respondWith(
    fetch(event.request)
      .catch(err => {
        // Cleanup cached responses if needed
        return caches.match(event.request);
      })
  );
});

// Background sync cleanup
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-data') {
    event.waitUntil(
      syncData().then(() => {
        // Cleanup sync queue
        return clearSyncQueue();
      })
    );
  }
});
```

## Testing Cleanup Patterns

### Mock Abort Testing

```javascript
// Jest example
test('should abort fetch on unmount', () => {
  const abortSpy = jest.spyOn(AbortController.prototype, 'abort');
  
  const { unmount } = render(<Component />);
  unmount();
  
  expect(abortSpy).toHaveBeenCalled();
  abortSpy.mockRestore();
});
```

### Memory Leak Detection

```javascript
// Check for lingering promises
const pendingPromises = new Set();

const originalFetch = window.fetch;
window.fetch = function(...args) {
  const promise = originalFetch.apply(this, args);
  
  pendingPromises.add(promise);
  promise.finally(() => pendingPromises.delete(promise));
  
  return promise;
};

// After cleanup
console.log('Pending requests:', pendingPromises.size);
```

## Resource Management Patterns

### Pooled Resource Cleanup

```javascript
class ResourcePool {
  constructor(maxSize = 10) {
    this.pool = [];
    this.maxSize = maxSize;
    this.controllers = new Set();
  }
  
  async acquire() {
    if (this.pool.length > 0) {
      return this.pool.pop();
    }
    
    const controller = new AbortController();
    this.controllers.add(controller);
    
    return controller;
  }
  
  release(controller) {
    if (this.pool.length < this.maxSize) {
      this.pool.push(controller);
    } else {
      this.controllers.delete(controller);
    }
  }
  
  cleanup() {
    this.controllers.forEach(c => c.abort());
    this.controllers.clear();
    this.pool = [];
  }
}
```

### Automatic Cleanup with Proxies

```javascript
function createAutoCleanupFetch(timeoutMs = 30000) {
  const activeControllers = new WeakMap();
  
  return new Proxy(fetch, {
    apply(target, thisArg, args) {
      const [url, options = {}] = args;
      const controller = new AbortController();
      
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, timeoutMs);
      
      const enhancedOptions = {
        ...options,
        signal: controller.signal
      };
      
      return Reflect.apply(target, thisArg, [url, enhancedOptions])
        .finally(() => clearTimeout(timeoutId));
    }
  });
}

const autoFetch = createAutoCleanupFetch();
```

---

## Race Conditions 

## Understanding Race Conditions with Fetch

Race conditions occur when multiple fetch requests are initiated, and their responses arrive in unpredictable order. The completion order may differ from the initiation order, potentially causing stale data to overwrite fresh data, duplicate processing, or inconsistent UI states.

## Common Race Condition Scenarios

### Rapid Sequential Requests

When users trigger multiple requests in quick succession (typing in search boxes, clicking buttons rapidly, toggling filters), earlier requests may complete after later ones, displaying outdated results.

### Concurrent Requests to Same Resource

Multiple components or functions fetching the same resource simultaneously can lead to redundant network calls and inconsistent state updates depending on which response processes last.

### Dependent Request Chains

When requests depend on previous responses but are initiated without proper sequencing, the application may attempt to use data before it's available or process responses out of logical order.

## Mitigation Strategies

### AbortController Pattern

The AbortController provides a standardized mechanism to cancel in-flight requests:

```javascript
let controller = new AbortController();

async function fetchData(query) {
  // Cancel previous request
  controller.abort();
  
  // Create new controller for this request
  controller = new AbortController();
  
  try {
    const response = await fetch(`/api/search?q=${query}`, {
      signal: controller.signal
    });
    const data = await response.json();
    return data;
  } catch (error) {
    if (error.name === 'AbortError') {
      // Request was cancelled, this is expected
      return null;
    }
    throw error;
  }
}
```

Each new request aborts the previous one, ensuring only the most recent request's response is processed. The AbortError catch block handles cancelled requests gracefully.

### Request Sequence Tracking

Track request order using incrementing counters or timestamps:

```javascript
let requestId = 0;

async function fetchWithSequence(url) {
  const currentRequestId = ++requestId;
  
  const response = await fetch(url);
  const data = await response.json();
  
  // Only process if this is still the latest request
  if (currentRequestId === requestId) {
    processData(data);
  }
}
```

This pattern allows all requests to complete but only processes the most recent, avoiding unnecessary network cancellations while preventing stale data updates.

### Debouncing and Throttling

Limit request frequency to prevent races from rapid user input:

```javascript
function debounce(func, delay) {
  let timeoutId;
  return function(...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => func.apply(this, args), delay);
  };
}

const debouncedFetch = debounce(async (query) => {
  const response = await fetch(`/api/search?q=${query}`);
  return response.json();
}, 300);
```

Debouncing delays execution until activity stops, while throttling limits execution frequency. Both reduce the number of concurrent requests.

### Promise Race Resolution

Use `Promise.race()` to handle whichever request completes first:

```javascript
async function fetchFirstAvailable(urls) {
  const fetchPromises = urls.map(url => fetch(url));
  
  const response = await Promise.race(fetchPromises);
  return response.json();
}
```

This is useful for redundant endpoints or fallback sources where any successful response suffices.

### Mutex/Lock Pattern

Implement mutual exclusion to ensure only one request executes at a time:

```javascript
class RequestMutex {
  constructor() {
    this.locked = false;
    this.queue = [];
  }
  
  async lock() {
    if (!this.locked) {
      this.locked = true;
      return;
    }
    
    return new Promise(resolve => {
      this.queue.push(resolve);
    });
  }
  
  unlock() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    } else {
      this.locked = false;
    }
  }
  
  async execute(fn) {
    await this.lock();
    try {
      return await fn();
    } finally {
      this.unlock();
    }
  }
}

const mutex = new RequestMutex();

async function fetchWithMutex(url) {
  return mutex.execute(async () => {
    const response = await fetch(url);
    return response.json();
  });
}
```

This serializes requests, guaranteeing execution order matches initiation order.

### Request Deduplication

Prevent multiple identical requests by caching in-flight promises:

```javascript
const pendingRequests = new Map();

async function fetchWithDedup(url) {
  if (pendingRequests.has(url)) {
    return pendingRequests.get(url);
  }
  
  const promise = fetch(url)
    .then(res => res.json())
    .finally(() => {
      pendingRequests.delete(url);
    });
  
  pendingRequests.set(url, promise);
  return promise;
}
```

Multiple simultaneous calls to the same URL return the same promise, eliminating redundant network requests.

### Optimistic Updates with Rollback

Update UI immediately, then reconcile with server response:

```javascript
async function optimisticUpdate(item, updateFn) {
  const previousState = { ...item };
  const optimisticState = updateFn(item);
  
  // Update UI immediately
  renderItem(optimisticState);
  
  try {
    const response = await fetch('/api/items', {
      method: 'PUT',
      body: JSON.stringify(optimisticState)
    });
    const serverState = await response.json();
    
    // Reconcile with server
    renderItem(serverState);
  } catch (error) {
    // Rollback on failure
    renderItem(previousState);
  }
}
```

This provides immediate feedback while handling potential conflicts between local and server state.

## Advanced Patterns

### Request Coalescing Window

Batch multiple requests within a time window:

```javascript
class RequestCoalescer {
  constructor(delay = 50) {
    this.delay = delay;
    this.pending = [];
    this.timeoutId = null;
  }
  
  add(request) {
    return new Promise((resolve, reject) => {
      this.pending.push({ request, resolve, reject });
      
      if (!this.timeoutId) {
        this.timeoutId = setTimeout(() => {
          this.flush();
        }, this.delay);
      }
    });
  }
  
  async flush() {
    const batch = this.pending;
    this.pending = [];
    this.timeoutId = null;
    
    // Process batch as single request
    const ids = batch.map(b => b.request.id);
    const response = await fetch('/api/batch', {
      method: 'POST',
      body: JSON.stringify({ ids })
    });
    const results = await response.json();
    
    // Resolve individual promises
    batch.forEach((item, index) => {
      item.resolve(results[index]);
    });
  }
}
```

This reduces server load by combining rapid requests into fewer network calls.

### Version-Based Conflict Resolution

Use version numbers or ETags to detect and handle conflicts:

```javascript
async function fetchWithVersion(url, expectedVersion) {
  const response = await fetch(url, {
    headers: {
      'If-Match': expectedVersion
    }
  });
  
  if (response.status === 412) { // Precondition Failed
    // Version conflict detected
    const latestResponse = await fetch(url);
    const latestData = await latestResponse.json();
    
    // Handle conflict (merge, prompt user, etc.)
    return handleConflict(latestData);
  }
  
  return response.json();
}
```

The server validates the version, preventing updates based on stale data.

### State Machine for Request Lifecycle

Manage request states explicitly to prevent invalid transitions:

```javascript
class RequestStateMachine {
  constructor() {
    this.state = 'idle';
    this.controller = null;
  }
  
  async fetch(url) {
    if (this.state === 'loading') {
      // Cancel in-progress request
      this.controller.abort();
    }
    
    this.state = 'loading';
    this.controller = new AbortController();
    
    try {
      const response = await fetch(url, {
        signal: this.controller.signal
      });
      const data = await response.json();
      
      this.state = 'success';
      return data;
    } catch (error) {
      if (error.name === 'AbortError') {
        this.state = 'cancelled';
      } else {
        this.state = 'error';
      }
      throw error;
    }
  }
}
```

Explicit state tracking prevents processing responses in invalid states.

## Framework-Specific Considerations

### React Patterns

React's component lifecycle and re-renders introduce additional race condition opportunities:

```javascript
function SearchComponent() {
  const [results, setResults] = useState([]);
  const [query, setQuery] = useState('');
  
  useEffect(() => {
    const controller = new AbortController();
    
    async function search() {
      try {
        const response = await fetch(`/api/search?q=${query}`, {
          signal: controller.signal
        });
        const data = await response.json();
        setResults(data);
      } catch (error) {
        if (error.name !== 'AbortError') {
          console.error(error);
        }
      }
    }
    
    if (query) {
      search();
    }
    
    // Cleanup function aborts request on unmount or query change
    return () => controller.abort();
  }, [query]);
  
  return (/* JSX */);
}
```

The cleanup function in useEffect prevents race conditions when dependencies change or component unmounts.

### React Query/SWR Patterns

Libraries like React Query handle race conditions automatically through request deduplication and cache invalidation:

```javascript
import { useQuery } from 'react-query';

function SearchComponent({ query }) {
  const { data, isLoading } = useQuery(
    ['search', query],
    () => fetch(`/api/search?q=${query}`).then(r => r.json()),
    {
      enabled: !!query,
      keepPreviousData: true // Prevents flash of empty state
    }
  );
  
  return (/* JSX */);
}
```

The library manages request cancellation, deduplication, and cache updates automatically.

## Testing Race Conditions

### Simulating Delayed Responses

Introduce artificial delays to expose race conditions:

```javascript
async function fetchWithDelay(url, delay) {
  const response = await fetch(url);
  await new Promise(resolve => setTimeout(resolve, delay));
  return response.json();
}

// Test: later request completes first
await Promise.all([
  fetchWithDelay('/api/data?v=1', 200),
  fetchWithDelay('/api/data?v=2', 50)
]);
```

Variable delays help identify order-dependent bugs.

### Parallel Request Testing

Fire multiple requests simultaneously to verify handling:

```javascript
async function testRaceCondition() {
  const requests = Array.from({ length: 10 }, (_, i) => 
    fetch(`/api/data?id=${i}`)
  );
  
  const responses = await Promise.all(requests);
  const results = await Promise.all(
    responses.map(r => r.json())
  );
  
  // Verify consistency
  verifyResults(results);
}
```

### Network Condition Simulation

Use browser DevTools or libraries to simulate slow/unreliable networks:

```javascript
// Using service worker for network simulation
self.addEventListener('fetch', (event) => {
  const delay = Math.random() * 2000; // Random 0-2s delay
  
  event.respondWith(
    new Promise(resolve => {
      setTimeout(() => {
        resolve(fetch(event.request));
      }, delay);
    })
  );
});
```

## Performance Considerations

### Request Cancellation Overhead

AbortController cancellation is lightweight but not zero-cost. The browser still initiates the connection and may transfer partial data before cancellation takes effect. For extremely rapid requests (millisecond intervals), cancellation overhead can accumulate.

### Memory Leaks from Uncancelled Requests

Failing to abort requests or clean up references can cause memory leaks:

```javascript
// Potential leak: response handlers hold references
function leakyFetch(url) {
  fetch(url).then(response => {
    // This closure captures the entire scope
    processLargeData(response);
  });
  // No way to cancel this request
}

// Better: store controller reference for cleanup
class Component {
  constructor() {
    this.controllers = [];
  }
  
  fetch(url) {
    const controller = new AbortController();
    this.controllers.push(controller);
    
    return fetch(url, { signal: controller.signal });
  }
  
  cleanup() {
    this.controllers.forEach(c => c.abort());
    this.controllers = [];
  }
}
```

### Request Queue Depth

Browsers limit concurrent HTTP/1.1 connections per domain (typically 6). For HTTP/2, multiplexing allows more concurrent requests, but excessive parallel requests still impact performance. Consider:

```javascript
class RequestQueue {
  constructor(concurrency = 6) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async add(fetchFn) {
    if (this.active >= this.concurrency) {
      await new Promise(resolve => this.queue.push(resolve));
    }
    
    this.active++;
    try {
      return await fetchFn();
    } finally {
      this.active--;
      if (this.queue.length > 0) {
        const resolve = this.queue.shift();
        resolve();
      }
    }
  }
}
```

## Common Pitfalls

### Assuming Response Order Matches Request Order

[Inference] Network latency varies based on request size, server load, routing, and processing complexity. Smaller or cached responses often return faster than earlier, larger requests.

### Not Handling Aborted Requests

AbortError must be caught explicitly; otherwise it propagates as an unhandled rejection:

```javascript
// Wrong: AbortError treated as failure
try {
  await fetch(url, { signal });
} catch (error) {
  showErrorMessage(error); // Shows error for intentional cancellation
}

// Correct: Distinguish abort from failure
try {
  await fetch(url, { signal });
} catch (error) {
  if (error.name === 'AbortError') {
    return; // Expected cancellation
  }
  showErrorMessage(error);
}
```

### Shared AbortController Across Independent Requests

Using one controller for multiple independent requests causes unintended cancellations:

```javascript
// Wrong: One controller for all requests
const controller = new AbortController();

fetch('/api/user', { signal: controller.signal });
fetch('/api/posts', { signal: controller.signal });

controller.abort(); // Cancels BOTH requests

// Correct: Separate controllers
const userController = new AbortController();
const postsController = new AbortController();

fetch('/api/user', { signal: userController.signal });
fetch('/api/posts', { signal: postsController.signal });
```

### Race Conditions in Error Handlers

Error handling itself can race with subsequent requests:

```javascript
// Problematic: error handler may run after newer request
let currentError = null;

fetch(url1).catch(error => {
  currentError = error; // May overwrite error from url2
});

fetch(url2).catch(error => {
  currentError = error;
});

// Better: Track errors per request
const errors = new Map();

async function fetchTracked(id, url) {
  try {
    return await fetch(url);
  } catch (error) {
    errors.set(id, error);
    throw error;
  }
}
```

### Relying on Finally Blocks Without Sequencing

Finally blocks execute regardless of resolution order:

```javascript
// Problematic
let isLoading = false;

async function fetchData(url) {
  isLoading = true;
  try {
    return await fetch(url);
  } finally {
    isLoading = false; // May clear loading state from newer request
  }
}

// Better: Track per request
const loadingStates = new Map();

async function fetchData(id, url) {
  loadingStates.set(id, true);
  try {
    return await fetch(url);
  } finally {
    loadingStates.set(id, false);
  }
}
```

## Browser API Interactions

### Service Workers and Race Conditions

Service workers intercept fetch requests and can introduce additional race conditions:

```javascript
// Service worker cache race
self.addEventListener('fetch', (event) => {
  event.respondWith(
    Promise.race([
      caches.match(event.request),
      fetch(event.request)
    ]).then(response => {
      // First response wins, but may be stale cache
      return response || fetch(event.request);
    })
  );
});
```

Cache-first, network-first, or stale-while-revalidate strategies each have different race characteristics.

### Intersection with Browser Back/Forward Cache

Pages in back/forward cache may have pending requests that resume when restored, potentially racing with new requests initiated on page restoration.

```javascript
// Handle page visibility changes
document.addEventListener('visibilitychange', () => {
  if (document.hidden) {
    // Page going into bfcache, cancel requests
    abortAllRequests();
  }
});
```

### Request Priority and Browser Scheduling

[Inference] Browsers schedule requests based on resource type (HTML, CSS, JS, images) and priority hints. Fetch requests default to medium priority but can race with higher-priority resource loading, affecting completion order.

```javascript
fetch(url, {
  priority: 'high' // or 'low', 'auto'
});
```

Priority hints influence browser scheduling but don't eliminate race conditions.

---


# Streaming

## ReadableStream API

ReadableStream is a Web Streams API interface representing a readable stream of byte data. It provides a standardized way to handle streaming data in JavaScript, enabling efficient processing of large datasets without loading everything into memory at once.

### Core Concepts

#### Stream States

A ReadableStream exists in one of three states:

- **Readable**: The stream is active and can produce chunks
- **Closed**: The stream has successfully completed and will produce no more chunks
- **Errored**: The stream has encountered an error and is now permanently unusable

#### Stream Types

ReadableStreams come in two fundamental types:

**Byte streams** handle raw binary data with a `ReadableStreamBYOBReader` (Bring Your Own Buffer), allowing consumers to provide their own buffers for more efficient memory usage.

**Default streams** handle chunks of any type, typically using a `ReadableStreamDefaultReader`.

### Constructor

```javascript
new ReadableStream(underlyingSource, queuingStrategy)
```

#### underlyingSource Object

The underlying source defines how the stream obtains its data:

**start(controller)**: Called immediately when the stream is constructed. Use this to set up data sources or perform initialization. Returns a promise if asynchronous work is needed.

**pull(controller)**: Called when the stream's internal queue isn't full. This is where you enqueue new chunks. Should return a promise. The stream won't call `pull()` again until the returned promise fulfills.

**cancel(reason)**: Called when the consumer cancels the stream. Use this to release resources or abort ongoing operations.

**type**: Set to `"bytes"` for byte streams, or omit for default streams.

**autoAllocateChunkSize**: For byte streams only. When set, the stream will automatically allocate buffers of this size for BYOB reads.

#### queuingStrategy Object

Controls buffering behavior:

**highWaterMark**: The maximum number of chunks (or total size) to buffer before backpressure is applied. Default is 1 for default streams.

**size(chunk)**: A function that returns the size of each chunk. Used with `highWaterMark` to determine when the queue is full.

### ReadableStreamDefaultController

The controller object passed to underlying source methods provides control over the stream:

**enqueue(chunk)**: Adds a chunk to the stream's queue. Throws if the stream is not readable or if the queue is full beyond the high water mark.

**close()**: Signals that no more chunks will be enqueued. The stream will close once all queued chunks are read.

**error(error)**: Causes the stream to error with the given reason. All future interactions will fail with this error.

**desiredSize**: Returns the desired size to fill the stream's queue. Positive when more data is needed, zero or negative when the queue is full or overfull. Becomes `null` when the stream is closed or errored.

### ReadableStreamBYOBController

For byte streams, the controller has similar methods but with byte-specific handling:

**enqueue(chunk)**: The chunk must be an ArrayBufferView (typed array).

**byobRequest**: Returns a `ReadableStreamBYOBRequest` or null. When a BYOB reader is waiting for data, this property provides a view into the consumer's buffer where you can write data directly.

```javascript
if (controller.byobRequest) {
  const view = controller.byobRequest.view;
  // Write data directly into view
  controller.byobRequest.respond(bytesWritten);
}
```

### Reading Streams

#### Default Reader

```javascript
const reader = stream.getReader();
```

**read()**: Returns a promise that resolves to `{value: chunk, done: false}` when a chunk is available, or `{value: undefined, done: true}` when the stream closes.

**releaseLock()**: Releases the reader's lock on the stream, allowing other readers to be obtained.

**closed**: A promise that fulfills when the stream closes or rejects when it errors.

**cancel(reason)**: Cancels the stream and releases the lock.

#### BYOB Reader

```javascript
const reader = stream.getReader({ mode: 'byob' });
```

**read(view)**: Similar to the default reader's `read()`, but accepts an ArrayBufferView. The stream will fill this buffer with data. The returned promise resolves with a new view into the same buffer, indicating how much was filled.

```javascript
const buffer = new ArrayBuffer(1024);
const view = new Uint8Array(buffer);
const { value, done } = await reader.read(view);
// value is a new Uint8Array view, potentially shorter than view
```

### Locking Mechanism

A stream can only have one active reader at a time. Attempting to get a second reader while one is active throws a TypeError. This prevents multiple consumers from receiving chunks in an undefined order.

To switch readers, call `releaseLock()` on the current reader first.

### Piping and Transformation

#### pipeTo()

```javascript
readableStream.pipeTo(writableStream, options)
```

Pipes the readable stream to a writable stream, handling backpressure automatically. Returns a promise that fulfills when piping completes successfully.

**Options**:

- **preventClose**: If true, doesn't close the destination when the source closes
- **preventAbort**: If true, doesn't abort the destination if the source errors
- **preventCancel**: If true, doesn't cancel the source if the destination errors
- **signal**: An AbortSignal to abort the piping operation

#### pipeThrough()

```javascript
readableStream.pipeThrough(transformStream, options)
```

Pipes through a transform stream (which has both readable and writable sides), returning the readable side. This allows chaining transformations.

```javascript
const transformed = stream
  .pipeThrough(new TextDecoderStream())
  .pipeThrough(new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(chunk.toUpperCase());
    }
  }));
```

#### tee()

```javascript
const [branch1, branch2] = stream.tee();
```

Splits the stream into two branches that receive the same chunks. Useful when you need to consume the same data in multiple ways. Both branches must be consumed for the original stream to make progress.

### Backpressure

Backpressure is the mechanism that prevents a fast producer from overwhelming a slow consumer:

1. The `desiredSize` property indicates how much more data is desired
2. When `desiredSize` becomes zero or negative, the queue is full
3. The `pull()` method won't be called again until space becomes available
4. Readers waiting for data will only trigger `pull()` when they're ready to consume

This creates a natural flow control where production slows when consumption slows.

### Async Iteration

ReadableStreams are async iterables, allowing use with `for await...of`:

```javascript
for await (const chunk of stream) {
  // Process chunk
}
```

This automatically handles reading and releasing the lock when done or if an error occurs.

### Common Patterns

#### Creating from Data

```javascript
const stream = new ReadableStream({
  start(controller) {
    controller.enqueue('chunk 1');
    controller.enqueue('chunk 2');
    controller.close();
  }
});
```

#### Creating from Async Source

```javascript
const stream = new ReadableStream({
  async pull(controller) {
    const data = await fetchNextChunk();
    if (data) {
      controller.enqueue(data);
    } else {
      controller.close();
    }
  }
});
```

#### Manual Reading Loop

```javascript
const reader = stream.getReader();
try {
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    // Process value
  }
} finally {
  reader.releaseLock();
}
```

#### Handling Errors

```javascript
const stream = new ReadableStream({
  async pull(controller) {
    try {
      const data = await riskyOperation();
      controller.enqueue(data);
    } catch (error) {
      controller.error(error);
    }
  }
});
```

### Integration with Fetch API

The Response body in the Fetch API is a ReadableStream:

```javascript
const response = await fetch(url);
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  // value is a Uint8Array chunk
}
```

This enables processing large responses incrementally without waiting for the entire download.

### Performance Considerations

**Chunk size**: Larger chunks reduce overhead but increase latency. Balance based on your use case.

**Buffer allocation**: BYOB readers reduce garbage collection pressure by reusing buffers.

**Queue management**: Monitor `desiredSize` to avoid building up large queues that consume memory.

**Cancellation**: Always implement `cancel()` in underlying sources to properly release resources when streams are abandoned.

### Browser Support

[Inference] ReadableStream has broad modern browser support. The BYOB reader functionality may have more limited support in older browsers. Check compatibility requirements for your target environments.

---

## Response Body Streaming

### ReadableStream Interface

The Fetch API exposes response bodies as `ReadableStream` objects, enabling chunk-by-chunk processing of data without waiting for the entire response to download. The `response.body` property returns a `ReadableStream` of `Uint8Array` chunks.

```javascript
const response = await fetch('https://example.com/large-file');
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  // value is a Uint8Array chunk
  console.log('Received chunk:', value.length, 'bytes');
}
```

### Getting a Reader

The `getReader()` method locks the stream to a single reader, preventing other consumers from accessing it simultaneously. This returns a `ReadableStreamDefaultReader` that provides the `read()` method.

```javascript
const reader = response.body.getReader();
// Stream is now locked - no other code can read from response.body
```

[Inference] Once locked, attempting to get another reader or use convenience methods like `.text()` or `.json()` will throw an error, as the stream can only have one active reader at a time.

### Reading Chunks

The `read()` method returns a Promise that resolves to an object with two properties:

- `done`: Boolean indicating if the stream has ended
- `value`: `Uint8Array` containing the chunk data (undefined when done is true)

```javascript
const { done, value } = await reader.read();

if (!done) {
  // Process the Uint8Array chunk
  const text = new TextDecoder().decode(value);
}
```

### Processing Streamed Text

For text responses, combine `TextDecoder` with streaming to process data incrementally:

```javascript
const response = await fetch('https://example.com/stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, { stream: true });
  console.log('Text chunk:', chunk);
}
```

The `{ stream: true }` option tells `TextDecoder` to preserve incomplete multi-byte characters across chunks, completing them when the next chunk arrives.

### Canceling Streams

Call `reader.cancel()` to abort downloading and close the stream:

```javascript
const reader = response.body.getReader();

try {
  const { value } = await reader.read();
  // Process first chunk...
  
  if (someCondition) {
    await reader.cancel('User cancelled');
    return;
  }
} finally {
  reader.releaseLock();
}
```

### Releasing the Lock

The `releaseLock()` method releases the reader's exclusive lock on the stream, allowing other code to obtain a new reader:

```javascript
reader.releaseLock();
// Stream is now unlocked
const newReader = response.body.getReader();
```

[Inference] After releasing the lock, the original reader becomes unusable and attempting to read from it will throw an error.

### Teeing Streams

The `tee()` method splits a readable stream into two independent streams that can be consumed separately:

```javascript
const response = await fetch('https://example.com/data');
const [stream1, stream2] = response.body.tee();

// Consume both streams independently
const reader1 = stream1.getReader();
const reader2 = stream2.getReader();

// Both readers receive the same data
```

### Piping Streams

Transform or redirect streams using `pipeThrough()` and `pipeTo()`:

```javascript
const response = await fetch('https://example.com/data');

// Pipe through a transform stream
const decompressed = response.body.pipeThrough(
  new DecompressionStream('gzip')
);

// Pipe to a writable stream
const writable = new WritableStream({
  write(chunk) {
    console.log('Received:', chunk);
  }
});

await decompressed.pipeTo(writable);
```

### Progress Tracking

Monitor download progress by accumulating chunk sizes:

```javascript
const response = await fetch('https://example.com/file');
const contentLength = response.headers.get('Content-Length');
const total = parseInt(contentLength, 10);
let loaded = 0;

const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  loaded += value.length;
  const progress = (loaded / total) * 100;
  console.log(`Progress: ${progress.toFixed(2)}%`);
}
```

[Inference] This approach requires the server to send a `Content-Length` header; without it, total size cannot be determined in advance.

### Accumulating Chunks

Collect all chunks into a single buffer:

```javascript
const response = await fetch('https://example.com/data');
const reader = response.body.getReader();
const chunks = [];

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  chunks.push(value);
}

// Combine chunks
const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
const combined = new Uint8Array(totalLength);
let offset = 0;

for (const chunk of chunks) {
  combined.set(chunk, offset);
  offset += chunk.length;
}
```

### Response Body Convenience Methods

While streaming provides granular control, convenience methods consume the entire body:

```javascript
// These internally consume the ReadableStream
const text = await response.text();
const json = await response.json();
const blob = await response.blob();
const buffer = await response.arrayBuffer();
const formData = await response.formData();
```

[Inference] Using convenience methods after obtaining a reader, or vice versa, will fail because the stream becomes locked or already consumed.

### Streaming JSON Parsing

Parse JSON incrementally for large responses:

```javascript
const response = await fetch('https://example.com/large.json');
const reader = response.body.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  buffer += decoder.decode(value, { stream: true });
  
  // Attempt to parse complete objects
  try {
    const data = JSON.parse(buffer);
    console.log('Parsed:', data);
    buffer = ''; // Clear buffer after successful parse
  } catch (e) {
    // Not yet complete, continue accumulating
  }
}
```

[Inference] This basic approach assumes the JSON fits in memory; for truly large streaming JSON, specialized libraries that parse incomplete JSON structures would be needed.

### Creating Custom Response Streams

Generate custom `Response` objects with streaming bodies:

```javascript
const stream = new ReadableStream({
  start(controller) {
    controller.enqueue(new TextEncoder().encode('chunk 1\n'));
    controller.enqueue(new TextEncoder().encode('chunk 2\n'));
    controller.close();
  }
});

const response = new Response(stream, {
  headers: { 'Content-Type': 'text/plain' }
});

const text = await response.text();
// 'chunk 1\nchunk 2\n'
```

### Async Iterator Support

Modern environments support async iteration over readable streams:

```javascript
const response = await fetch('https://example.com/data');

for await (const chunk of response.body) {
  // chunk is a Uint8Array
  console.log('Chunk size:', chunk.length);
}
```

[Inference] This simplifies streaming code by avoiding manual reader management and the while-loop pattern.

### Transform Streams

Apply transformations to streaming data:

```javascript
const transformStream = new TransformStream({
  transform(chunk, controller) {
    // Modify chunk
    const modified = chunk.map(byte => byte ^ 0xFF); // Invert bits
    controller.enqueue(modified);
  }
});

const response = await fetch('https://example.com/data');
const transformed = response.body.pipeThrough(transformStream);
const reader = transformed.getReader();
```

### Error Handling

Handle stream errors appropriately:

```javascript
const reader = response.body.getReader();

try {
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // Process chunk
    processChunk(value);
  }
} catch (error) {
  console.error('Stream error:', error);
  await reader.cancel(); // Clean up
} finally {
  reader.releaseLock();
}
```

### Server-Sent Events Pattern

Parse SSE-style streams:

```javascript
const response = await fetch('https://example.com/events');
const reader = response.body.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  buffer += decoder.decode(value, { stream: true });
  const lines = buffer.split('\n');
  buffer = lines.pop(); // Keep incomplete line
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = line.slice(6);
      console.log('Event:', data);
    }
  }
}
```

### Memory Efficiency

Streaming enables processing large files without loading them entirely into memory:

```javascript
// Bad: Loads entire file into memory
const response = await fetch('https://example.com/10GB-file');
const blob = await response.blob(); // Memory spike

// Good: Processes in chunks
const response = await fetch('https://example.com/10GB-file');
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  // Process small chunk, then garbage collected
  await processChunk(value);
}
```

### Backpressure Handling

[Inference] The browser's implementation of `ReadableStream` handles backpressure automatically—if the consumer processes chunks slowly, the browser will naturally slow the rate at which it reads from the network connection, though this behavior is managed internally and not directly controllable by JavaScript code.

### Browser Compatibility

Response body streaming is widely supported in modern browsers. The `ReadableStream` API and `response.body` are available in Chrome 43+, Firefox 65+, Safari 10.1+, and Edge 14+.

[Inference] Async iteration over streams (`for await...of`) requires newer browser versions or polyfills, as it depends on the async iteration protocol support.

### Comparison with XMLHttpRequest Progress

While `XMLHttpRequest` offers progress events, it requires waiting for complete chunks:

```javascript
// XHR approach
const xhr = new XMLHttpRequest();
xhr.onprogress = (e) => {
  console.log(`Downloaded ${e.loaded} of ${e.total} bytes`);
};

// Fetch streaming approach
const response = await fetch(url);
const reader = response.body.getReader();
// More granular, chunk-level control
```

The Fetch API's streaming provides lower-level access to data as it arrives, enabling more sophisticated processing patterns.

---

## Chunked Transfer Encoding 

### Overview of Chunked Responses

Chunked transfer encoding allows servers to send response data in discrete chunks rather than as a single complete payload. With the Fetch API, you can process these chunks as they arrive using the `ReadableStream` interface exposed through `response.body`.

### Detecting Chunked Responses

```javascript
const response = await fetch('https://api.example.com/stream');

// Check if body is readable stream
if (response.body) {
  console.log('Response supports streaming');
}

// [Inference] Transfer-Encoding header typically indicates chunked encoding
const transferEncoding = response.headers.get('Transfer-Encoding');
if (transferEncoding === 'chunked') {
  console.log('Explicitly chunked response');
}
```

### Reading Chunks with ReadableStream

#### Basic Stream Reading

```javascript
const response = await fetch('https://api.example.com/data');
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  
  if (done) {
    console.log('Stream complete');
    break;
  }
  
  // value is a Uint8Array containing the chunk
  console.log('Received chunk:', value.length, 'bytes');
}
```

#### Decoding Text Chunks

```javascript
const response = await fetch('https://api.example.com/text-stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  
  if (done) break;
  
  // Decode chunk to string
  const chunk = decoder.decode(value, { stream: true });
  console.log('Text chunk:', chunk);
}
```

### Handling Partial Data Across Chunks

#### Buffering Strategy

```javascript
const response = await fetch('https://api.example.com/json-stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (true) {
  const { done, value } = await reader.read();
  
  if (done) break;
  
  // Append to buffer
  buffer += decoder.decode(value, { stream: true });
  
  // Process complete lines
  let newlineIndex;
  while ((newlineIndex = buffer.indexOf('\n')) !== -1) {
    const line = buffer.slice(0, newlineIndex);
    buffer = buffer.slice(newlineIndex + 1);
    
    // Process complete line
    console.log('Complete line:', line);
  }
}

// Process remaining buffer
if (buffer.length > 0) {
  console.log('Final data:', buffer);
}
```

#### JSON Streaming Pattern

```javascript
async function* streamJSONLines(response) {
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      buffer += decoder.decode(value, { stream: true });
      
      const lines = buffer.split('\n');
      buffer = lines.pop() || ''; // Keep incomplete line in buffer
      
      for (const line of lines) {
        if (line.trim()) {
          yield JSON.parse(line);
        }
      }
    }
    
    // Process final buffer
    if (buffer.trim()) {
      yield JSON.parse(buffer);
    }
  } finally {
    reader.releaseLock();
  }
}

// Usage
const response = await fetch('https://api.example.com/ndjson');
for await (const obj of streamJSONLines(response)) {
  console.log('Parsed object:', obj);
}
```

### Stream Transformation with TransformStream

#### Decompression Example

```javascript
const response = await fetch('https://api.example.com/compressed');

// Pipe through decompression
const decompressedStream = response.body.pipeThrough(
  new DecompressionStream('gzip')
);

const reader = decompressedStream.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  console.log('Decompressed chunk:', decoder.decode(value, { stream: true }));
}
```

#### Custom Transform Stream

```javascript
class ChunkCounter extends TransformStream {
  constructor() {
    let chunkCount = 0;
    let totalBytes = 0;
    
    super({
      transform(chunk, controller) {
        chunkCount++;
        totalBytes += chunk.length;
        console.log(`Chunk ${chunkCount}: ${chunk.length} bytes (total: ${totalBytes})`);
        controller.enqueue(chunk);
      },
      flush(controller) {
        console.log(`Stream complete: ${chunkCount} chunks, ${totalBytes} bytes`);
      }
    });
  }
}

const response = await fetch('https://api.example.com/data');
const countedStream = response.body.pipeThrough(new ChunkCounter());

// Continue processing countedStream
```

### Progress Tracking

#### Download Progress with Content-Length

```javascript
async function fetchWithProgress(url, onProgress) {
  const response = await fetch(url);
  const contentLength = response.headers.get('Content-Length');
  
  if (!contentLength) {
    console.warn('Content-Length not available');
    return response;
  }
  
  const total = parseInt(contentLength, 10);
  let loaded = 0;
  
  const reader = response.body.getReader();
  const stream = new ReadableStream({
    async start(controller) {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          controller.close();
          break;
        }
        
        loaded += value.length;
        onProgress({ loaded, total, percentage: (loaded / total) * 100 });
        controller.enqueue(value);
      }
    }
  });
  
  return new Response(stream, {
    headers: response.headers,
    status: response.status,
    statusText: response.statusText
  });
}

// Usage
const response = await fetchWithProgress(
  'https://api.example.com/large-file',
  ({ loaded, total, percentage }) => {
    console.log(`Progress: ${percentage.toFixed(2)}% (${loaded}/${total})`);
  }
);
```

#### Streaming Without Content-Length

```javascript
async function streamWithChunkProgress(url, onChunk) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  let chunkIndex = 0;
  let totalBytes = 0;
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;
    
    totalBytes += value.length;
    onChunk({
      chunkIndex: chunkIndex++,
      chunkSize: value.length,
      totalBytes
    });
  }
  
  return { chunkIndex, totalBytes };
}
```

### Server-Sent Events (SSE) Pattern

```javascript
async function consumeSSE(url, onMessage, onError) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  
  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      buffer += decoder.decode(value, { stream: true });
      
      const lines = buffer.split('\n\n');
      buffer = lines.pop() || '';
      
      for (const message of lines) {
        if (!message.trim()) continue;
        
        const event = parseSSEMessage(message);
        if (event) {
          onMessage(event);
        }
      }
    }
  } catch (error) {
    onError(error);
  } finally {
    reader.releaseLock();
  }
}

function parseSSEMessage(raw) {
  const lines = raw.split('\n');
  const event = {};
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      event.data = (event.data || '') + line.slice(6);
    } else if (line.startsWith('event: ')) {
      event.type = line.slice(7);
    } else if (line.startsWith('id: ')) {
      event.id = line.slice(4);
    } else if (line.startsWith('retry: ')) {
      event.retry = parseInt(line.slice(7), 10);
    }
  }
  
  return event.data ? event : null;
}

// Usage
consumeSSE(
  'https://api.example.com/events',
  (event) => {
    console.log('Event:', event.type, event.data);
  },
  (error) => {
    console.error('SSE error:', error);
  }
);
```

### Memory Management

#### Cancellation and Cleanup

```javascript
const controller = new AbortController();

async function streamWithCancellation(url, signal) {
  const response = await fetch(url, { signal });
  const reader = response.body.getReader();
  
  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      // Process chunk
      console.log('Chunk:', value.length);
    }
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Stream cancelled');
    } else {
      throw error;
    }
  } finally {
    reader.releaseLock();
  }
}

// Start streaming
const streamPromise = streamWithCancellation(
  'https://api.example.com/stream',
  controller.signal
);

// Cancel after 5 seconds
setTimeout(() => controller.abort(), 5000);
```

#### Backpressure Handling

```javascript
async function processWithBackpressure(response, processChunk) {
  const reader = response.body.getReader();
  
  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      // Wait for processing to complete before reading next chunk
      await processChunk(value);
    }
  } finally {
    reader.releaseLock();
  }
}

// Usage with slow processing
await processWithBackpressure(
  await fetch('https://api.example.com/data'),
  async (chunk) => {
    // Simulate slow processing
    await new Promise(resolve => setTimeout(resolve, 100));
    console.log('Processed chunk:', chunk.length);
  }
);
```

### Piping Streams

#### Direct Piping to WritableStream

```javascript
async function downloadToFile(url, writableStream) {
  const response = await fetch(url);
  
  if (!response.body) {
    throw new Error('Response body is null');
  }
  
  await response.body.pipeTo(writableStream);
}

// [Unverified] Example assumes File System Access API availability
// Usage with File System Access API (where supported)
// const fileHandle = await window.showSaveFilePicker();
// const writable = await fileHandle.createWritable();
// await downloadToFile('https://api.example.com/file', writable);
```

#### Tee for Multiple Consumers

```javascript
const response = await fetch('https://api.example.com/data');
const [stream1, stream2] = response.body.tee();

// Consumer 1: Calculate size
async function calculateSize(stream) {
  const reader = stream.getReader();
  let total = 0;
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    total += value.length;
  }
  
  return total;
}

// Consumer 2: Calculate hash
async function calculateHash(stream) {
  const reader = stream.getReader();
  // [Inference] Hash calculation implementation would go here
  // This is a simplified example
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    // Process chunk for hash
  }
}

// Process both simultaneously
const [size, hash] = await Promise.all([
  calculateSize(stream1),
  calculateHash(stream2)
]);

console.log('Size:', size, 'Hash:', hash);
```

### Error Handling in Streams

#### Retry Logic

```javascript
async function fetchStreamWithRetry(url, maxRetries = 3) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await fetch(url);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const reader = response.body.getReader();
      const chunks = [];
      
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;
        
        chunks.push(value);
      }
      
      return chunks;
      
    } catch (error) {
      console.error(`Attempt ${attempt + 1} failed:`, error);
      
      if (attempt === maxRetries - 1) {
        throw error;
      }
      
      // Wait before retry
      await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
    }
  }
}
```

#### Partial Failure Recovery

```javascript
async function resumableStreamFetch(url, onChunk, onError) {
  let bytesReceived = 0;
  let lastSuccessfulByte = 0;
  
  async function attemptStream(rangeStart = 0) {
    const headers = rangeStart > 0 
      ? { 'Range': `bytes=${rangeStart}-` }
      : {};
    
    try {
      const response = await fetch(url, { headers });
      const reader = response.body.getReader();
      
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          lastSuccessfulByte = bytesReceived;
          break;
        }
        
        bytesReceived += value.length;
        await onChunk(value, bytesReceived);
      }
      
    } catch (error) {
      onError(error, lastSuccessfulByte);
      
      // Resume from last successful position
      console.log(`Resuming from byte ${lastSuccessfulByte}`);
      await attemptStream(lastSuccessfulByte);
    }
  }
  
  await attemptStream();
}
```

### Performance Considerations

#### Chunk Size Analysis

```javascript
async function analyzeChunkSizes(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  const sizes = [];
  let startTime = performance.now();
  let lastChunkTime = startTime;
  
  while (true) {
    const chunkStartTime = performance.now();
    const { done, value } = await reader.read();
    
    if (done) break;
    
    const chunkEndTime = performance.now();
    const timeSinceLastChunk = chunkStartTime - lastChunkTime;
    
    sizes.push({
      size: value.length,
      receiveTime: chunkEndTime - chunkStartTime,
      intervalTime: timeSinceLastChunk
    });
    
    lastChunkTime = chunkEndTime;
  }
  
  const totalTime = performance.now() - startTime;
  const totalBytes = sizes.reduce((sum, s) => sum + s.size, 0);
  
  return {
    chunks: sizes.length,
    totalBytes,
    totalTime,
    averageChunkSize: totalBytes / sizes.length,
    throughput: (totalBytes / totalTime) * 1000, // bytes per second
    chunkDetails: sizes
  };
}
```

#### Optimal Buffer Size

```javascript
class BufferedStreamReader {
  constructor(stream, bufferSize = 64 * 1024) { // 64KB default
    this.reader = stream.getReader();
    this.bufferSize = bufferSize;
    this.buffer = new Uint8Array(bufferSize);
    this.bufferFilled = 0;
    this.bufferPosition = 0;
  }
  
  async read(size) {
    // If requested size is larger than buffer, read directly
    if (size > this.bufferSize) {
      const result = await this.reader.read();
      return result;
    }
    
    // Check if we have enough data in buffer
    const available = this.bufferFilled - this.bufferPosition;
    
    if (available >= size) {
      const data = this.buffer.slice(
        this.bufferPosition,
        this.bufferPosition + size
      );
      this.bufferPosition += size;
      return { done: false, value: data };
    }
    
    // Fill buffer
    const { done, value } = await this.reader.read();
    
    if (done) {
      return { done: true, value: undefined };
    }
    
    // Copy to buffer
    this.buffer.set(value, 0);
    this.bufferFilled = value.length;
    this.bufferPosition = 0;
    
    return this.read(size);
  }
  
  releaseLock() {
    this.reader.releaseLock();
  }
}
```

### Browser Compatibility Considerations

```javascript
function supportsStreams() {
  return (
    typeof ReadableStream !== 'undefined' &&
    typeof Response !== 'undefined' &&
    typeof Response.prototype.body !== 'undefined'
  );
}

async function fetchWithFallback(url) {
  if (supportsStreams()) {
    // Modern streaming approach
    const response = await fetch(url);
    const reader = response.body.getReader();
    
    // Process stream...
    
  } else {
    // Fallback: wait for complete response
    const response = await fetch(url);
    const data = await response.arrayBuffer();
    
    // Process complete data...
  }
}
```

### Integration with Other APIs

#### Web Workers for Stream Processing

```javascript
// Main thread
const worker = new Worker('stream-processor.js');

async function processStreamInWorker(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  worker.onmessage = (event) => {
    console.log('Processed result:', event.data);
  };
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) {
      worker.postMessage({ done: true });
      break;
    }
    
    // Transfer chunk to worker (zero-copy)
    worker.postMessage({ chunk: value.buffer }, [value.buffer]);
  }
}

// stream-processor.js (Worker)
self.onmessage = async (event) => {
  if (event.data.done) {
    // Finalize processing
    return;
  }
  
  const chunk = new Uint8Array(event.data.chunk);
  // Process chunk...
  
  self.postMessage({ processed: true });
};
```

#### IndexedDB Storage During Streaming

```javascript
async function streamToIndexedDB(url, dbName, storeName) {
  const db = await openDatabase(dbName);
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  let chunkIndex = 0;
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;
    
    // Store chunk in IndexedDB
    const tx = db.transaction([storeName], 'readwrite');
    const store = tx.objectStore(storeName);
    
    await store.put({
      id: chunkIndex++,
      data: value,
      timestamp: Date.now()
    });
    
    await tx.complete;
  }
  
  console.log(`Stored ${chunkIndex} chunks in IndexedDB`);
}

function openDatabase(dbName) {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(dbName, 1);
    
    request.onerror = () => reject(request.error);
    request.onsuccess = () => resolve(request.result);
    
    request.onupgradeneeded = (event) => {
      const db = event.target.result;
      if (!db.objectStoreNames.contains('chunks')) {
        db.createObjectStore('chunks', { keyPath: 'id' });
      }
    };
  });
}
```

---

## Progress Tracking 

### ReadableStream and Response Body

The Fetch API provides access to the response body as a `ReadableStream`, enabling byte-level progress tracking. The `Response.body` property exposes this stream, allowing you to process chunks as they arrive.

```javascript
const response = await fetch('https://example.com/large-file.zip');
const reader = response.body.getReader();
const contentLength = +response.headers.get('Content-Length');

let receivedLength = 0;
const chunks = [];

while (true) {
  const {done, value} = await reader.read();
  
  if (done) break;
  
  chunks.push(value);
  receivedLength += value.length;
  
  console.log(`Received ${receivedLength} of ${contentLength}`);
}
```

### Content-Length Header

Progress tracking relies heavily on the `Content-Length` response header. Without it, you can only track bytes received, not percentage complete.

```javascript
const contentLength = response.headers.get('Content-Length');

if (!contentLength) {
  console.warn('Content-Length not available - cannot calculate percentage');
}
```

#### Server Requirements

Servers must send `Content-Length` for accurate progress tracking. Compressed responses or chunked transfer encoding may omit this header. Some CDNs and proxies strip `Content-Length` when using compression.

### Download Progress Pattern

```javascript
async function fetchWithProgress(url, onProgress) {
  const response = await fetch(url);
  
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  
  const contentLength = response.headers.get('Content-Length');
  
  if (!contentLength) {
    console.warn('Content-Length unavailable');
    return response.blob(); // Fallback without progress
  }
  
  const total = parseInt(contentLength, 10);
  let loaded = 0;
  
  const reader = response.body.getReader();
  const chunks = [];
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    loaded += value.length;
    
    if (onProgress) {
      onProgress({
        loaded,
        total,
        percentage: (loaded / total) * 100
      });
    }
  }
  
  // Reconstruct the complete response
  const blob = new Blob(chunks);
  return blob;
}

// Usage
const blob = await fetchWithProgress('file.zip', (progress) => {
  console.log(`${progress.percentage.toFixed(2)}%`);
});
```

### Reconstructing Response Data

After consuming the stream, you must manually reconstruct the data:

#### Binary Data (Blob)

```javascript
const chunks = [];
const reader = response.body.getReader();

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  chunks.push(value);
}

const blob = new Blob(chunks);
```

#### Text Data

```javascript
const decoder = new TextDecoder();
let text = '';

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  text += decoder.decode(value, {stream: true});
}

text += decoder.decode(); // Final flush
```

#### JSON Data

```javascript
const chunks = [];
// ... read chunks ...

const blob = new Blob(chunks);
const text = await blob.text();
const data = JSON.parse(text);
```

### Typed Arrays and Memory Management

Stream chunks are `Uint8Array` instances. For large files, be mindful of memory accumulation.

```javascript
const chunks = [];
let totalSize = 0;

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  
  chunks.push(value);
  totalSize += value.length;
  
  // Memory check
  if (totalSize > MAX_SIZE) {
    throw new Error('File too large');
  }
}
```

### Stream Processing Without Accumulation

For very large files, process chunks without storing them all in memory:

```javascript
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, {stream: true});
  
  // Process chunk immediately
  processChunk(chunk);
  
  // Chunk is now garbage-collectable
}
```

### Upload Progress Limitations

The Fetch API does **not** support upload progress tracking. The `Request.body` stream cannot be monitored.

```javascript
// This does NOT work for upload progress
const response = await fetch(url, {
  method: 'POST',
  body: largeFile // No way to track upload progress
});
```

#### Alternative: XMLHttpRequest

For upload progress, use `XMLHttpRequest`:

```javascript
function uploadWithProgress(url, data, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable && onProgress) {
        onProgress({
          loaded: e.loaded,
          total: e.total,
          percentage: (e.loaded / e.total) * 100
        });
      }
    });
    
    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(xhr.response);
      } else {
        reject(new Error(`HTTP ${xhr.status}`));
      }
    });
    
    xhr.addEventListener('error', () => reject(new Error('Upload failed')));
    
    xhr.open('POST', url);
    xhr.send(data);
  });
}
```

### Abortable Progress Tracking

Combine progress tracking with `AbortController`:

```javascript
async function fetchWithProgressAndAbort(url, onProgress, signal) {
  const response = await fetch(url, { signal });
  const contentLength = +response.headers.get('Content-Length');
  const reader = response.body.getReader();
  
  let loaded = 0;
  const chunks = [];
  
  try {
    while (true) {
      const {done, value} = await reader.read();
      
      if (done) break;
      
      chunks.push(value);
      loaded += value.length;
      
      if (onProgress) {
        onProgress({ loaded, total: contentLength });
      }
    }
    
    return new Blob(chunks);
  } catch (error) {
    await reader.cancel(); // Clean up stream
    throw error;
  }
}

// Usage
const controller = new AbortController();

fetchWithProgressAndAbort(url, onProgress, controller.signal)
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('Download cancelled');
    }
  });

// Cancel later
controller.abort();
```

### Progress Events with Custom Events

Dispatch browser events for UI integration:

```javascript
async function fetchWithEvents(url, element) {
  const response = await fetch(url);
  const contentLength = +response.headers.get('Content-Length');
  const reader = response.body.getReader();
  
  let loaded = 0;
  const chunks = [];
  
  element.dispatchEvent(new CustomEvent('downloadstart', {
    detail: { total: contentLength }
  }));
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    loaded += value.length;
    
    element.dispatchEvent(new CustomEvent('downloadprogress', {
      detail: { loaded, total: contentLength }
    }));
  }
  
  element.dispatchEvent(new CustomEvent('downloadcomplete', {
    detail: { total: contentLength }
  }));
  
  return new Blob(chunks);
}

// Usage
element.addEventListener('downloadprogress', (e) => {
  const percent = (e.detail.loaded / e.detail.total) * 100;
  progressBar.value = percent;
});
```

### Response Cloning and Progress

You cannot track progress on cloned responses. Once `response.clone()` is called, the original body stream is consumed independently.

```javascript
const response = await fetch(url);
const clone = response.clone();

// These consume separate streams - no shared progress tracking
const blob1 = await response.blob();
const blob2 = await clone.blob();
```

### Compressed Responses

When responses use `Content-Encoding: gzip` or similar, the browser decompresses automatically. Progress tracking shows **compressed bytes**, not decompressed size.

```javascript
// Content-Length: 1000 (compressed size)
// Actual decompressed: 5000 bytes

// Progress will show 1000 bytes total, not 5000
```

The `Content-Length` header, when present with compression, reflects the compressed payload size.

### Service Workers and Progress

Service Workers can intercept fetch requests and create custom streaming responses with progress tracking:

```javascript
// In Service Worker
self.addEventListener('fetch', (event) => {
  if (event.request.url.includes('/tracked/')) {
    event.respondWith(fetchWithProgress(event.request));
  }
});

async function fetchWithProgress(request) {
  const response = await fetch(request);
  const reader = response.body.getReader();
  
  const stream = new ReadableStream({
    async start(controller) {
      while (true) {
        const {done, value} = await reader.read();
        
        if (done) {
          controller.close();
          break;
        }
        
        // Send progress message to clients
        self.clients.matchAll().then(clients => {
          clients.forEach(client => {
            client.postMessage({
              type: 'progress',
              loaded: value.length
            });
          });
        });
        
        controller.enqueue(value);
      }
    }
  });
  
  return new Response(stream, {
    headers: response.headers
  });
}
```

### Throttling Progress Updates

Avoid overwhelming the UI with progress updates:

```javascript
async function fetchWithThrottledProgress(url, onProgress, throttleMs = 100) {
  const response = await fetch(url);
  const contentLength = +response.headers.get('Content-Length');
  const reader = response.body.getReader();
  
  let loaded = 0;
  let lastUpdate = 0;
  const chunks = [];
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) {
      // Final update
      if (onProgress) {
        onProgress({ loaded, total: contentLength });
      }
      break;
    }
    
    chunks.push(value);
    loaded += value.length;
    
    const now = Date.now();
    if (now - lastUpdate >= throttleMs) {
      if (onProgress) {
        onProgress({ loaded, total: contentLength });
      }
      lastUpdate = now;
    }
  }
  
  return new Blob(chunks);
}
```

### Cross-Origin and Content-Length

CORS policies may prevent access to the `Content-Length` header:

```javascript
const contentLength = response.headers.get('Content-Length');

if (!contentLength) {
  // Might be blocked by CORS
  // Server needs: Access-Control-Expose-Headers: Content-Length
}
```

The server must explicitly expose the header:

```
Access-Control-Expose-Headers: Content-Length
```

### Browser Support Considerations

All modern browsers support `ReadableStream` and `response.body`. For older browsers, progress tracking is unavailable, requiring fallback:

```javascript
async function fetchWithOptionalProgress(url, onProgress) {
  const response = await fetch(url);
  
  // Check for stream support
  if (!response.body || !response.body.getReader) {
    console.warn('Streaming not supported - no progress tracking');
    return response.blob();
  }
  
  // Proceed with progress tracking
  return fetchWithProgress(url, onProgress);
}
```

---

## Stream Processing 

### Reading Response Streams

The Fetch API provides access to the underlying `ReadableStream` of the response body through `response.body`. This enables progressive processing of data as it arrives rather than waiting for the complete response.

```javascript
const response = await fetch('https://api.example.com/large-dataset');
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  // value is a Uint8Array chunk
  processChunk(value);
}
```

### Stream Decoding with TextDecoderStream

Raw stream chunks are `Uint8Array` buffers. Use `TextDecoderStream` to convert bytes to text while handling multi-byte characters that may span chunk boundaries.

```javascript
const response = await fetch('https://api.example.com/stream');
const stream = response.body
  .pipeThrough(new TextDecoderStream())
  .getReader();

while (true) {
  const { done, value } = await stream.read();
  if (done) break;
  console.log(value); // Already decoded text
}
```

### Manual Reader Control

Direct reader access provides fine-grained control over stream consumption. Each `read()` returns a promise resolving to `{ done, value }`.

```javascript
const reader = response.body.getReader();

try {
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) {
      console.log('Stream complete');
      break;
    }
    
    // Process chunk
    await processChunk(value);
  }
} finally {
  reader.releaseLock();
}
```

### Stream Piping and Transformation

The Streams API allows chaining transformations using `pipeThrough()` and `pipeTo()`.

```javascript
const response = await fetch('https://api.example.com/data');

await response.body
  .pipeThrough(new TextDecoderStream())
  .pipeThrough(new TransformStream({
    transform(chunk, controller) {
      // Transform each chunk
      controller.enqueue(chunk.toUpperCase());
    }
  }))
  .pipeTo(new WritableStream({
    write(chunk) {
      console.log(chunk);
    }
  }));
```

### Custom TransformStream Implementation

Create reusable stream transformers for common processing patterns.

```javascript
class JSONLineParser extends TransformStream {
  constructor() {
    let buffer = '';
    
    super({
      transform(chunk, controller) {
        buffer += chunk;
        const lines = buffer.split('\n');
        buffer = lines.pop(); // Keep incomplete line
        
        for (const line of lines) {
          if (line.trim()) {
            try {
              controller.enqueue(JSON.parse(line));
            } catch (e) {
              console.error('Parse error:', e);
            }
          }
        }
      },
      
      flush(controller) {
        if (buffer.trim()) {
          try {
            controller.enqueue(JSON.parse(buffer));
          } catch (e) {
            console.error('Final parse error:', e);
          }
        }
      }
    });
  }
}

// Usage
const response = await fetch('https://api.example.com/ndjson');
const reader = response.body
  .pipeThrough(new TextDecoderStream())
  .pipeThrough(new JSONLineParser())
  .getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  console.log(value); // Parsed JSON objects
}
```

### Server-Sent Events (SSE) Processing

Parse SSE format streams manually for event-driven data consumption.

```javascript
async function consumeSSE(url) {
  const response = await fetch(url);
  const reader = response.body
    .pipeThrough(new TextDecoderStream())
    .getReader();
  
  let buffer = '';
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    buffer += value;
    const lines = buffer.split('\n\n');
    buffer = lines.pop();
    
    for (const eventText of lines) {
      const event = parseSSEEvent(eventText);
      if (event.data) {
        handleEvent(event);
      }
    }
  }
}

function parseSSEEvent(text) {
  const lines = text.split('\n');
  const event = { data: '', event: 'message' };
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      event.data += line.slice(6) + '\n';
    } else if (line.startsWith('event: ')) {
      event.event = line.slice(7);
    } else if (line.startsWith('id: ')) {
      event.id = line.slice(4);
    }
  }
  
  event.data = event.data.trim();
  return event;
}
```

### Streaming JSON Parsing

Process large JSON arrays incrementally without loading the entire response into memory.

```javascript
class StreamingJSONParser extends TransformStream {
  constructor() {
    let depth = 0;
    let buffer = '';
    let inString = false;
    let escape = false;
    
    super({
      transform(chunk, controller) {
        for (let i = 0; i < chunk.length; i++) {
          const char = chunk[i];
          buffer += char;
          
          if (escape) {
            escape = false;
            continue;
          }
          
          if (char === '\\' && inString) {
            escape = true;
            continue;
          }
          
          if (char === '"') {
            inString = !inString;
            continue;
          }
          
          if (inString) continue;
          
          if (char === '{' || char === '[') {
            depth++;
          } else if (char === '}' || char === ']') {
            depth--;
            
            if (depth === 1 && char === '}') {
              try {
                controller.enqueue(JSON.parse(buffer));
                buffer = '';
              } catch (e) {
                // Incomplete object, continue buffering
              }
            }
          }
        }
      }
    });
  }
}
```

### Backpressure Handling

Streams automatically handle backpressure when the consumer processes data slower than it arrives.

```javascript
const response = await fetch('https://api.example.com/stream');
const reader = response.body.getReader();

async function processWithBackpressure() {
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // Slow processing - backpressure automatically applied
    await simulateSlowProcessing(value);
  }
}

async function simulateSlowProcessing(chunk) {
  return new Promise(resolve => {
    setTimeout(() => {
      console.log(`Processed ${chunk.length} bytes`);
      resolve();
    }, 100);
  });
}
```

### Teeing Streams

Split a stream into multiple independent consumers using `tee()`.

```javascript
const response = await fetch('https://api.example.com/data');
const [stream1, stream2] = response.body.tee();

// Consumer 1: Save to cache
stream1
  .pipeThrough(new TextDecoderStream())
  .pipeTo(new WritableStream({
    write(chunk) {
      cache.append(chunk);
    }
  }));

// Consumer 2: Display to user
const reader = stream2
  .pipeThrough(new TextDecoderStream())
  .getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  displayToUser(value);
}
```

### Aborting Streams

Cancel stream processing using `AbortController`.

```javascript
const controller = new AbortController();
const signal = controller.signal;

setTimeout(() => controller.abort(), 5000); // Abort after 5s

try {
  const response = await fetch('https://api.example.com/stream', { signal });
  const reader = response.body.getReader();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    processChunk(value);
  }
} catch (err) {
  if (err.name === 'AbortError') {
    console.log('Stream aborted');
  }
}
```

### Progress Tracking

Monitor download progress with `Content-Length` header and accumulated chunk sizes.

```javascript
const response = await fetch('https://api.example.com/large-file');
const contentLength = response.headers.get('Content-Length');
const total = parseInt(contentLength, 10);

let loaded = 0;
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  
  if (done) {
    console.log('Download complete');
    break;
  }
  
  loaded += value.length;
  const progress = (loaded / total) * 100;
  console.log(`Progress: ${progress.toFixed(2)}%`);
}
```

### Streaming Upload with Request Body

Send data as a stream for efficient large file uploads.

```javascript
const stream = new ReadableStream({
  async start(controller) {
    for (let i = 0; i < 1000; i++) {
      const chunk = generateChunk(i);
      controller.enqueue(new TextEncoder().encode(chunk));
      await sleep(10);
    }
    controller.close();
  }
});

const response = await fetch('https://api.example.com/upload', {
  method: 'POST',
  body: stream,
  headers: {
    'Content-Type': 'application/octet-stream'
  },
  duplex: 'half' // Required for streaming requests
});
```

### Compressed Stream Decompression

Decompress gzip/deflate streams using `DecompressionStream`.

```javascript
const response = await fetch('https://api.example.com/compressed');

const decompressed = response.body
  .pipeThrough(new DecompressionStream('gzip'))
  .pipeThrough(new TextDecoderStream());

const reader = decompressed.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  console.log(value); // Decompressed text
}
```

### Error Handling in Streams

Properly handle errors at each stage of stream processing.

```javascript
const response = await fetch('https://api.example.com/stream');

try {
  const reader = response.body
    .pipeThrough(new TextDecoderStream())
    .pipeThrough(new TransformStream({
      transform(chunk, controller) {
        try {
          const processed = riskyOperation(chunk);
          controller.enqueue(processed);
        } catch (error) {
          controller.error(error);
        }
      }
    }))
    .getReader();
  
  while (true) {
    try {
      const { done, value } = await reader.read();
      if (done) break;
      await handleValue(value);
    } catch (error) {
      console.error('Stream processing error:', error);
      break;
    }
  }
} catch (error) {
  console.error('Stream setup error:', error);
} finally {
  // Cleanup
}
```

### Async Iterator Pattern

Convert streams to async iterables for more ergonomic consumption.

```javascript
async function* streamAsyncIterator(stream) {
  const reader = stream.getReader();
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) return;
      yield value;
    }
  } finally {
    reader.releaseLock();
  }
}

// Usage
const response = await fetch('https://api.example.com/stream');
const textStream = response.body.pipeThrough(new TextDecoderStream());

for await (const chunk of streamAsyncIterator(textStream)) {
  console.log(chunk);
}
```

### Chunked Transfer Encoding

Fetch automatically handles chunked transfer encoding, exposing a seamless stream interface regardless of the underlying HTTP transfer mechanism.

```javascript
// Server sends with Transfer-Encoding: chunked
const response = await fetch('https://api.example.com/chunked');

// Client receives as normal stream - chunking is transparent
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  // Chunks don't necessarily align with HTTP chunks
  processChunk(value);
}
```

### Memory-Efficient Large File Processing

Process files larger than available memory by streaming through transformations.

```javascript
async function processLargeCSV(url) {
  const response = await fetch(url);
  
  let lineBuffer = '';
  const reader = response.body
    .pipeThrough(new TextDecoderStream())
    .getReader();
  
  let lineCount = 0;
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) {
      if (lineBuffer) {
        processLine(lineBuffer);
        lineCount++;
      }
      break;
    }
    
    lineBuffer += value;
    const lines = lineBuffer.split('\n');
    lineBuffer = lines.pop(); // Keep incomplete line
    
    for (const line of lines) {
      processLine(line);
      lineCount++;
      
      if (lineCount % 1000 === 0) {
        await updateProgress(lineCount);
      }
    }
  }
  
  return lineCount;
}

function processLine(line) {
  const fields = line.split(',');
  // Process individual line without keeping all in memory
  saveToDatabase(fields);
}
```

### CompressionStream for Upload

Compress data before uploading to reduce bandwidth.

```javascript
const fileStream = file.stream();

const compressedStream = fileStream
  .pipeThrough(new CompressionStream('gzip'));

const response = await fetch('https://api.example.com/upload', {
  method: 'POST',
  body: compressedStream,
  headers: {
    'Content-Encoding': 'gzip',
    'Content-Type': 'application/octet-stream'
  },
  duplex: 'half'
});
```

### Stream Buffering Strategies

Control memory usage with custom buffering strategies using `queuingStrategy`.

```javascript
const stream = new ReadableStream({
  start(controller) {
    // Producer
  }
}, new CountQueuingStrategy({ highWaterMark: 10 }));

// Or bytes-based
const byteStream = new ReadableStream({
  type: 'bytes',
  start(controller) {
    // Producer
  }
}, new ByteLengthQueuingStrategy({ highWaterMark: 1024 * 64 })); // 64KB buffer
```

### Parallel Stream Processing

Process stream chunks in parallel while maintaining order.

```javascript
async function parallelStreamProcess(url, concurrency = 3) {
  const response = await fetch(url);
  const reader = response.body
    .pipeThrough(new TextDecoderStream())
    .getReader();
  
  const workers = [];
  let chunkId = 0;
  const results = new Map();
  let nextOutputId = 0;
  
  async function worker() {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const id = chunkId++;
      const result = await processChunkAsync(value);
      results.set(id, result);
      
      // Output results in order
      while (results.has(nextOutputId)) {
        outputResult(results.get(nextOutputId));
        results.delete(nextOutputId);
        nextOutputId++;
      }
    }
  }
  
  // Start parallel workers
  for (let i = 0; i < concurrency; i++) {
    workers.push(worker());
  }
  
  await Promise.all(workers);
}
```

---

## Backpressure Handling 

### Understanding Backpressure in Streams

Backpressure occurs when data is being produced faster than it can be consumed. In the context of the Fetch API, this typically happens when:

- A server sends response data faster than the client can process it
- A client attempts to send request data faster than the network can transmit it
- Memory buffers fill up because the consuming side cannot keep pace with the producing side

The Streams API, which underlies fetch's request and response bodies, provides built-in backpressure mechanisms through the ReadableStream and WritableStream interfaces.

### ReadableStream Backpressure Mechanics

#### Internal Queue and High Water Mark

ReadableStreams maintain an internal queue with a configurable high water mark (HWM). The HWM determines when backpressure signals should be sent:

```javascript
const stream = new ReadableStream({
  start(controller) {},
  pull(controller) {
    // Called when internal queue drops below HWM
  },
  cancel(reason) {}
}, {
  highWaterMark: 1, // Number of chunks
  size(chunk) {
    return 1; // Or return actual byte size
  }
});
```

When the internal queue size exceeds the HWM, the stream signals backpressure by not calling `pull()` until space is available.

#### Automatic Backpressure with getReader()

When consuming a response body with a reader, backpressure is handled automatically:

```javascript
const response = await fetch('https://example.com/large-file');
const reader = response.body.getReader();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  // Process chunk - backpressure automatically applied
  await processChunk(value);
  
  // Stream won't read next chunk until this completes
}
```

The key mechanism: the stream will not enqueue new chunks while `reader.read()` is pending. This creates natural backpressure since the consuming code controls when the next chunk is requested.

### pipeTo() and Backpressure Propagation

The `pipeTo()` method automatically handles backpressure between readable and writable streams:

```javascript
const response = await fetch('https://example.com/large-file');

// Backpressure flows from writable back to readable
await response.body.pipeTo(writableStream);
```

#### Backpressure Flow in pipeTo()

1. WritableStream's internal queue fills up
2. WritableStream signals it's not ready for more data
3. pipeTo() stops pulling from ReadableStream
4. ReadableStream's internal queue stops filling
5. Fetch stops reading from network until ReadableStream has capacity

This creates an automatic backpressure chain from the final consumer all the way back to the network layer.

### TransformStream and Backpressure

TransformStreams sit between readable and writable streams, and must handle backpressure in both directions:

```javascript
const transformStream = new TransformStream({
  async transform(chunk, controller) {
    // Backpressure from downstream affects enqueue()
    controller.enqueue(processedChunk);
    
    // If downstream is full, this may pause
  },
  
  flush(controller) {
    // Called when upstream closes
  }
}, 
{
  highWaterMark: 1,  // Readable side
  size: (chunk) => 1
},
{
  highWaterMark: 1,  // Writable side  
  size: (chunk) => 1
});

await response.body
  .pipeThrough(transformStream)
  .pipeTo(destination);
```

The `transform()` function won't be called again until:

- The previous `transform()` call completes
- The downstream writable stream has capacity

### Manual Backpressure Control

#### Using desiredSize

The `controller.desiredSize` property indicates how much capacity remains:

```javascript
const stream = new ReadableStream({
  async pull(controller) {
    // Check available capacity
    console.log('Desired size:', controller.desiredSize);
    
    if (controller.desiredSize > 0) {
      const chunk = await getNextChunk();
      controller.enqueue(chunk);
    }
    // If desiredSize <= 0, backpressure is signaled
  }
}, {
  highWaterMark: 5,
  size: (chunk) => chunk.byteLength
});
```

When `desiredSize` becomes zero or negative, the stream is experiencing backpressure and `pull()` won't be called until space frees up.

#### Implementing Rate Limiting

```javascript
class RateLimitedStream {
  constructor(sourceStream, bytesPerSecond) {
    this.source = sourceStream.getReader();
    this.rate = bytesPerSecond;
    this.lastChunkTime = Date.now();
    
    return new ReadableStream({
      pull: async (controller) => {
        const { done, value } = await this.source.read();
        
        if (done) {
          controller.close();
          return;
        }
        
        // Calculate required delay for rate limiting
        const now = Date.now();
        const elapsed = now - this.lastChunkTime;
        const requiredTime = (value.byteLength / this.rate) * 1000;
        const delay = Math.max(0, requiredTime - elapsed);
        
        if (delay > 0) {
          await new Promise(resolve => setTimeout(resolve, delay));
        }
        
        this.lastChunkTime = Date.now();
        controller.enqueue(value);
      }
    });
  }
}
```

### Request Body Backpressure

When uploading data with fetch, backpressure flows from the network back to your readable stream:

```javascript
const uploadStream = new ReadableStream({
  async pull(controller) {
    const chunk = await generateChunk();
    controller.enqueue(chunk);
    
    // Network backpressure automatically prevents
    // this from being called too frequently
  }
});

await fetch('https://example.com/upload', {
  method: 'POST',
  body: uploadStream,
  duplex: 'half' // Required for streaming request bodies
});
```

[Inference] The browser's fetch implementation manages the rate at which `pull()` is called based on network conditions and TCP flow control.

### Memory Management Through Backpressure

#### Preventing Memory Exhaustion

Without proper backpressure handling, a fast producer can exhaust memory:

```javascript
// BAD: No backpressure - stores all chunks in memory
const chunks = [];
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  chunks.push(value); // Accumulates in memory
}

// GOOD: Processes chunks immediately with automatic backpressure
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  await processAndDiscard(value); // Chunk can be garbage collected
}
```

#### Streaming to Disk with Backpressure

Using the File System Access API (where supported):

```javascript
const fileHandle = await window.showSaveFilePicker();
const writable = await fileHandle.createWritable();

// Backpressure automatically managed
await response.body.pipeTo(writable);

// File writes control fetch read speed
```

### Handling Slow Consumers

#### Aborting Slow Requests

```javascript
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 30000);

try {
  const response = await fetch(url, {
    signal: controller.signal
  });
  
  const reader = response.body.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // If processing takes too long, the entire operation aborts
    await slowProcessing(value);
  }
  
  clearTimeout(timeoutId);
} catch (err) {
  if (err.name === 'AbortError') {
    console.log('Aborted due to slow processing');
  }
}
```

#### Buffering Strategy

When you need to decouple producer and consumer speeds:

```javascript
class BufferedTransform extends TransformStream {
  constructor(maxBufferSize) {
    const buffer = [];
    let bufferSize = 0;
    
    super({
      async transform(chunk, controller) {
        buffer.push(chunk);
        bufferSize += chunk.byteLength;
        
        // Drain buffer when it reaches threshold
        if (bufferSize >= maxBufferSize) {
          while (buffer.length > 0) {
            controller.enqueue(buffer.shift());
          }
          bufferSize = 0;
        }
      },
      
      flush(controller) {
        // Flush remaining buffer
        buffer.forEach(chunk => controller.enqueue(chunk));
      }
    });
  }
}
```

[Inference] This pattern allows temporary speed mismatches but still applies backpressure once the buffer fills, preventing unbounded memory growth.

### tee() and Backpressure

The `tee()` method creates two independent branches, each with their own backpressure:

```javascript
const response = await fetch(url);
const [stream1, stream2] = response.body.tee();

// Both branches must consume for data to flow
const branch1 = stream1.pipeTo(destination1);
const branch2 = stream2.pipeTo(destination2);

await Promise.all([branch1, branch2]);
```

[Inference] The original stream's backpressure is determined by the slowest consumer. If one branch is slower, it gates the entire operation because chunks must be held in memory for the slower branch.

### Backpressure with Byte Streams

When using byte-oriented streams (BYOB readers), backpressure works at the buffer level:

```javascript
const response = await fetch(url);
const reader = response.body.getReader({ mode: 'byob' });

const buffer = new ArrayBuffer(1024);
let offset = 0;

while (offset < buffer.byteLength) {
  const { done, value } = await reader.read(
    new Uint8Array(buffer, offset, buffer.byteLength - offset)
  );
  
  if (done) break;
  offset += value.byteLength;
  
  // Backpressure: next read won't start until this completes
}
```

The consumer controls exactly how much data to request and when, providing fine-grained backpressure control.

### Cross-Origin and Backpressure

[Inference] Cross-origin requests may have different backpressure characteristics due to:

- CORS preflight requests delaying stream start
- Opaque responses limiting control over streaming
- Service Worker interception affecting flow control

```javascript
const response = await fetch('https://different-origin.com/data', {
  mode: 'cors'
});

// Backpressure still works, but timing may differ
await response.body.pipeTo(destination);
```

### Debugging Backpressure Issues

#### Monitoring Stream State

```javascript
const stream = new ReadableStream({
  pull(controller) {
    console.log({
      desiredSize: controller.desiredSize,
      timestamp: Date.now()
    });
    
    // Large negative values indicate severe backpressure
    if (controller.desiredSize < -10) {
      console.warn('Severe backpressure detected');
    }
  }
}, {
  highWaterMark: 5,
  size: (chunk) => chunk.byteLength
});
```

#### Measuring Pipeline Throughput

```javascript
class ThroughputMonitor extends TransformStream {
  constructor() {
    let bytesProcessed = 0;
    let startTime = Date.now();
    
    super({
      transform(chunk, controller) {
        bytesProcessed += chunk.byteLength;
        const elapsed = (Date.now() - startTime) / 1000;
        const mbps = (bytesProcessed / elapsed / 1024 / 1024).toFixed(2);
        
        console.log(`Throughput: ${mbps} MB/s`);
        controller.enqueue(chunk);
      }
    });
  }
}

await response.body
  .pipeThrough(new ThroughputMonitor())
  .pipeTo(destination);
```

### Implementation Considerations

#### Browser Differences

[Unverified] Different browsers may implement backpressure buffering with different default high water marks and queue management strategies. Testing across browsers is important for performance-critical applications.

#### Service Workers and Backpressure

When streaming through a Service Worker:

```javascript
// In service worker
self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request).then(response => {
      // Backpressure flows through service worker
      return new Response(response.body, {
        headers: response.headers
      });
    })
  );
});
```

The Service Worker acts as a transparent pipe, preserving backpressure signals between the network and the client.

#### Compression and Backpressure

Compression streams affect backpressure because the compressed/decompressed size differs:

```javascript
const decompressed = response.body
  .pipeThrough(new DecompressionStream('gzip'));

// Backpressure based on decompressed data size
await decompressed.pipeTo(destination);
```

The backpressure signal travels through the decompression layer, but the rate limiting occurs on the decompressed data flow.

---

## Transform Streams 

### Core Concepts

Transform streams provide a mechanism to modify data as it flows through a stream pipeline. In the context of the Fetch API, they enable processing response bodies progressively without loading entire payloads into memory. A TransformStream consists of a readable side and a writable side, with transformation logic applied to chunks passing through.

### TransformStream Constructor

```javascript
const transformStream = new TransformStream({
  start(controller) {
    // Called when stream is constructed
  },
  
  transform(chunk, controller) {
    // Called for each chunk
    controller.enqueue(modifiedChunk);
  },
  
  flush(controller) {
    // Called when no more chunks will be written
  }
}, writableStrategy, readableStrategy);
```

#### Controller Methods

The `controller` parameter provides methods to manipulate the stream:

- `controller.enqueue(chunk)` - Adds a chunk to the readable side
- `controller.terminate()` - Closes both sides of the stream
- `controller.error(reason)` - Errors both sides of the stream
- `controller.desiredSize` - Returns the desired size to fill the queue

### Piping with Response Streams

#### Basic Pipeline

```javascript
const response = await fetch('https://api.example.com/data');

const transformStream = new TransformStream({
  transform(chunk, controller) {
    // Process chunk
    controller.enqueue(chunk);
  }
});

const transformedResponse = new Response(
  response.body.pipeThrough(transformStream)
);
```

#### Multiple Transformations

```javascript
const response = await fetch('https://api.example.com/data');

const decompressor = new DecompressionStream('gzip');
const decoder = new TextDecoderStream();
const customTransform = new TransformStream({
  transform(chunk, controller) {
    const modified = chunk.toUpperCase();
    controller.enqueue(modified);
  }
});

const stream = response.body
  .pipeThrough(decompressor)
  .pipeThrough(decoder)
  .pipeThrough(customTransform);

const reader = stream.getReader();
```

### Common Transformation Patterns

#### Text Processing

```javascript
const textTransformer = new TransformStream({
  transform(chunk, controller) {
    // chunk is Uint8Array
    const text = new TextDecoder().decode(chunk, { stream: true });
    const processed = text.replace(/old/g, 'new');
    controller.enqueue(new TextEncoder().encode(processed));
  }
});

fetch('https://api.example.com/text')
  .then(response => response.body.pipeThrough(textTransformer))
  .then(stream => new Response(stream).text())
  .then(result => console.log(result));
```

#### JSON Streaming

```javascript
class JSONLineParser extends TransformStream {
  constructor() {
    let buffer = '';
    
    super({
      transform(chunk, controller) {
        buffer += new TextDecoder().decode(chunk, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';
        
        for (const line of lines) {
          if (line.trim()) {
            try {
              const obj = JSON.parse(line);
              controller.enqueue(obj);
            } catch (e) {
              controller.error(e);
            }
          }
        }
      },
      
      flush(controller) {
        if (buffer.trim()) {
          try {
            const obj = JSON.parse(buffer);
            controller.enqueue(obj);
          } catch (e) {
            controller.error(e);
          }
        }
      }
    });
  }
}

const response = await fetch('https://api.example.com/ndjson');
const stream = response.body
  .pipeThrough(new TextDecoderStream())
  .pipeThrough(new JSONLineParser());

const reader = stream.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  console.log(value); // Parsed JSON object
}
```

#### Compression/Decompression

```javascript
// Decompression
const response = await fetch('https://api.example.com/compressed');
const decompressed = response.body.pipeThrough(
  new DecompressionStream('gzip')
);

// Compression
const text = 'Large text content...';
const stream = new Blob([text]).stream();
const compressed = stream.pipeThrough(
  new CompressionStream('gzip')
);

await fetch('https://api.example.com/upload', {
  method: 'POST',
  body: compressed,
  headers: {
    'Content-Encoding': 'gzip'
  }
});
```

#### Progress Tracking

```javascript
let bytesReceived = 0;

const progressTransform = new TransformStream({
  transform(chunk, controller) {
    bytesReceived += chunk.byteLength;
    console.log(`Received: ${bytesReceived} bytes`);
    controller.enqueue(chunk);
  }
});

const response = await fetch('https://api.example.com/large-file');
const contentLength = response.headers.get('Content-Length');

const stream = response.body.pipeThrough(progressTransform);
const blob = await new Response(stream).blob();
```

#### Chunked Data Aggregation

```javascript
class ChunkAggregator extends TransformStream {
  constructor(chunkSize) {
    let buffer = new Uint8Array(0);
    
    super({
      transform(chunk, controller) {
        const newBuffer = new Uint8Array(buffer.length + chunk.length);
        newBuffer.set(buffer);
        newBuffer.set(chunk, buffer.length);
        buffer = newBuffer;
        
        while (buffer.length >= chunkSize) {
          controller.enqueue(buffer.slice(0, chunkSize));
          buffer = buffer.slice(chunkSize);
        }
      },
      
      flush(controller) {
        if (buffer.length > 0) {
          controller.enqueue(buffer);
        }
      }
    });
  }
}

const response = await fetch('https://api.example.com/data');
const aggregated = response.body.pipeThrough(new ChunkAggregator(1024));
```

### Backpressure Management

Transform streams automatically handle backpressure through queuing strategies:

```javascript
const transform = new TransformStream(
  {
    transform(chunk, controller) {
      // Slow operation
      const processed = expensiveOperation(chunk);
      controller.enqueue(processed);
    }
  },
  { highWaterMark: 1 },  // Writable strategy
  { highWaterMark: 1 }   // Readable strategy
);
```

#### Custom Queuing Strategy

```javascript
class ByteLengthQueuingStrategy {
  constructor(options) {
    this.highWaterMark = options.highWaterMark;
  }
  
  size(chunk) {
    return chunk.byteLength;
  }
}

const transform = new TransformStream(
  { /* transformer */ },
  new ByteLengthQueuingStrategy({ highWaterMark: 1024 * 1024 }), // 1MB
  new ByteLengthQueuingStrategy({ highWaterMark: 1024 * 1024 })
);
```

### Error Handling

#### Transformation Errors

```javascript
const errorHandlingTransform = new TransformStream({
  transform(chunk, controller) {
    try {
      const result = riskyOperation(chunk);
      controller.enqueue(result);
    } catch (error) {
      controller.error(new Error(`Transform failed: ${error.message}`));
    }
  }
});

try {
  const response = await fetch('https://api.example.com/data');
  const stream = response.body.pipeThrough(errorHandlingTransform);
  const reader = stream.getReader();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    console.log(value);
  }
} catch (error) {
  console.error('Stream error:', error);
}
```

#### Stream Abortion

```javascript
const controller = new AbortController();

const transform = new TransformStream({
  transform(chunk, controller) {
    if (controller.signal.aborted) {
      controller.error(new DOMException('Aborted', 'AbortError'));
      return;
    }
    controller.enqueue(chunk);
  }
});

fetch('https://api.example.com/data', { signal: controller.signal })
  .then(response => response.body.pipeThrough(transform))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Stream aborted');
    }
  });

// Abort after 5 seconds
setTimeout(() => controller.abort(), 5000);
```

### Tee Operations with Transforms

```javascript
const response = await fetch('https://api.example.com/data');
const [stream1, stream2] = response.body.tee();

// Apply different transforms to each stream
const upperCaseTransform = new TransformStream({
  transform(chunk, controller) {
    const text = new TextDecoder().decode(chunk);
    controller.enqueue(new TextEncoder().encode(text.toUpperCase()));
  }
});

const lowerCaseTransform = new TransformStream({
  transform(chunk, controller) {
    const text = new TextDecoder().decode(chunk);
    controller.enqueue(new TextEncoder().encode(text.toLowerCase()));
  }
});

const upper = stream1.pipeThrough(upperCaseTransform);
const lower = stream2.pipeThrough(lowerCaseTransform);

// Process both streams independently
const [upperResult, lowerResult] = await Promise.all([
  new Response(upper).text(),
  new Response(lower).text()
]);
```

### Identity Transforms

An identity transform passes data through unchanged but can be useful for monitoring:

```javascript
const identityTransform = new TransformStream({
  transform(chunk, controller) {
    console.log('Chunk size:', chunk.byteLength);
    controller.enqueue(chunk);
  }
});

const response = await fetch('https://api.example.com/data');
const monitored = response.body.pipeThrough(identityTransform);
```

### Writable Stream Destination

Transform streams can pipe to writable destinations:

```javascript
const response = await fetch('https://api.example.com/data');

const transform = new TransformStream({
  transform(chunk, controller) {
    // Process chunk
    controller.enqueue(chunk);
  }
});

const writableStream = new WritableStream({
  write(chunk) {
    console.log('Writing chunk:', chunk);
  },
  close() {
    console.log('Stream closed');
  }
});

await response.body
  .pipeThrough(transform)
  .pipeTo(writableStream);
```

### Performance Considerations

#### Memory Efficiency

Transform streams process data incrementally, avoiding memory spikes:

```javascript
// Memory-efficient large file processing
const response = await fetch('https://api.example.com/large-file');

const hashTransform = new TransformStream({
  async transform(chunk, controller) {
    // Process chunk without accumulating
    await processChunk(chunk);
    controller.enqueue(chunk);
  }
});

await response.body
  .pipeThrough(hashTransform)
  .pipeTo(someDestination);
```

#### Buffering Strategy

```javascript
class BufferedTransform extends TransformStream {
  constructor(bufferSize) {
    let buffer = [];
    
    super({
      transform(chunk, controller) {
        buffer.push(chunk);
        
        if (buffer.length >= bufferSize) {
          const combined = concatenateChunks(buffer);
          controller.enqueue(combined);
          buffer = [];
        }
      },
      
      flush(controller) {
        if (buffer.length > 0) {
          const combined = concatenateChunks(buffer);
          controller.enqueue(combined);
        }
      }
    });
  }
}
```

### Browser Compatibility

[Inference] Transform streams are part of the Streams API specification. Modern browsers implement this functionality, but specific features like CompressionStream may have varying support levels across different browser versions and environments.

---

## Server-Sent Events Integration with Fetch API

### Core Integration Pattern

The fetch API provides the foundation for establishing Server-Sent Events (SSE) connections. While the EventSource API is the traditional interface for SSE, fetch offers more control over request configuration, particularly for authentication, custom headers, and request body inclusion.

```javascript
const response = await fetch('/events', {
  headers: {
    'Accept': 'text/event-stream',
    'Authorization': 'Bearer token123'
  }
});

const reader = response.body.getReader();
const decoder = new TextDecoder();
```

### ReadableStream Processing

SSE responses arrive as a ReadableStream that must be manually processed. The stream delivers chunks of data that require parsing according to SSE protocol specifications.

```javascript
let buffer = '';

while (true) {
  const { done, value } = await reader.read();
  
  if (done) break;
  
  buffer += decoder.decode(value, { stream: true });
  
  const lines = buffer.split('\n');
  buffer = lines.pop(); // Keep incomplete line in buffer
  
  for (const line of lines) {
    processLine(line);
  }
}
```

### SSE Protocol Parsing

The SSE protocol uses specific field formats that must be parsed from the stream. Each event consists of multiple lines with field-value pairs.

**Field Types:**

- `event:` - Event type identifier
- `data:` - Message payload (can span multiple lines)
- `id:` - Event identifier for reconnection
- `retry:` - Reconnection time in milliseconds
- `:` - Comment line (ignored)

```javascript
let currentEvent = {
  event: 'message',
  data: '',
  id: '',
  retry: null
};

function processLine(line) {
  if (line === '') {
    // Empty line dispatches the event
    if (currentEvent.data) {
      dispatchEvent(currentEvent);
      currentEvent = { event: 'message', data: '', id: '', retry: null };
    }
    return;
  }
  
  if (line.startsWith(':')) return; // Comment
  
  const colonIndex = line.indexOf(':');
  const field = colonIndex !== -1 ? line.slice(0, colonIndex) : line;
  let value = colonIndex !== -1 ? line.slice(colonIndex + 1) : '';
  
  if (value.startsWith(' ')) value = value.slice(1);
  
  switch (field) {
    case 'event':
      currentEvent.event = value;
      break;
    case 'data':
      currentEvent.data += (currentEvent.data ? '\n' : '') + value;
      break;
    case 'id':
      if (!value.includes('\0')) currentEvent.id = value;
      break;
    case 'retry':
      const retryNum = parseInt(value, 10);
      if (!isNaN(retryNum)) currentEvent.retry = retryNum;
      break;
  }
}
```

### Event Dispatching

Custom event handling replaces the EventSource's built-in event system when using fetch.

```javascript
const eventTarget = new EventTarget();

function dispatchEvent(eventData) {
  const event = new MessageEvent(eventData.event, {
    data: eventData.data,
    lastEventId: eventData.id,
    origin: new URL('/events', location.href).origin
  });
  
  eventTarget.dispatchEvent(event);
}

// Usage
eventTarget.addEventListener('message', (e) => {
  console.log('Default message:', e.data);
});

eventTarget.addEventListener('customEvent', (e) => {
  console.log('Custom event:', e.data);
});
```

### Reconnection Logic

Fetch-based SSE requires manual implementation of reconnection logic that EventSource provides automatically.

```javascript
let lastEventId = '';
let reconnectDelay = 3000;
let shouldReconnect = true;

async function connect() {
  try {
    const response = await fetch('/events', {
      headers: {
        'Accept': 'text/event-stream',
        'Last-Event-ID': lastEventId
      }
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    await processStream(response.body);
    
  } catch (error) {
    console.error('Connection error:', error);
    
    if (shouldReconnect) {
      setTimeout(connect, reconnectDelay);
    }
  }
}

function processLine(line) {
  // ... parsing logic ...
  
  if (field === 'id') {
    lastEventId = value;
  } else if (field === 'retry') {
    reconnectDelay = parseInt(value, 10);
  }
}
```

### AbortController Integration

Proper connection termination requires AbortController to cancel in-flight requests.

```javascript
let abortController = new AbortController();

async function connect() {
  abortController = new AbortController();
  
  try {
    const response = await fetch('/events', {
      signal: abortController.signal,
      headers: {
        'Accept': 'text/event-stream',
        'Last-Event-ID': lastEventId
      }
    });
    
    await processStream(response.body);
    
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Connection aborted');
      return;
    }
    // Handle other errors
  }
}

function disconnect() {
  shouldReconnect = false;
  abortController.abort();
}
```

### POST Requests with SSE

Unlike EventSource (which only supports GET), fetch enables POST requests with request bodies for SSE connections.

```javascript
const response = await fetch('/events', {
  method: 'POST',
  headers: {
    'Accept': 'text/event-stream',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    filter: 'updates',
    userId: '12345'
  })
});
```

### Error Handling and Connection States

Comprehensive error handling tracks connection lifecycle states.

```javascript
const ConnectionState = {
  CONNECTING: 0,
  OPEN: 1,
  CLOSED: 2
};

class FetchSSE {
  constructor(url, options = {}) {
    this.url = url;
    this.options = options;
    this.readyState = ConnectionState.CONNECTING;
    this.eventTarget = new EventTarget();
  }
  
  async connect() {
    this.readyState = ConnectionState.CONNECTING;
    
    try {
      const response = await fetch(this.url, {
        ...this.options,
        headers: {
          'Accept': 'text/event-stream',
          ...this.options.headers
        }
      });
      
      if (!response.ok) {
        this.dispatchError(new Error(`HTTP ${response.status}`));
        return;
      }
      
      if (!response.headers.get('content-type')?.includes('text/event-stream')) {
        this.dispatchError(new Error('Invalid content-type'));
        return;
      }
      
      this.readyState = ConnectionState.OPEN;
      this.dispatchOpen();
      
      await this.processStream(response.body);
      
    } catch (error) {
      this.dispatchError(error);
    } finally {
      this.readyState = ConnectionState.CLOSED;
    }
  }
  
  dispatchOpen() {
    this.eventTarget.dispatchEvent(new Event('open'));
  }
  
  dispatchError(error) {
    this.eventTarget.dispatchEvent(new ErrorEvent('error', { error }));
  }
}
```

### Backpressure Handling

The ReadableStream can apply backpressure if the consumer cannot process data fast enough.

```javascript
async function processStream(stream) {
  const reader = stream.getReader();
  
  try {
    while (true) {
      // This await naturally applies backpressure
      const { done, value } = await reader.read();
      
      if (done) break;
      
      // Slow processing creates backpressure
      await processChunk(value);
    }
  } finally {
    reader.releaseLock();
  }
}
```

### Credential Handling

Fetch provides explicit control over credential inclusion in cross-origin SSE requests.

```javascript
const response = await fetch('https://api.example.com/events', {
  credentials: 'include', // 'omit', 'same-origin', 'include'
  headers: {
    'Accept': 'text/event-stream'
  }
});
```

### CORS Considerations

Cross-origin SSE connections require proper CORS headers from the server.

**Required Server Headers:**

```
Access-Control-Allow-Origin: https://example.com
Access-Control-Allow-Credentials: true
Access-Control-Allow-Headers: Last-Event-ID
Content-Type: text/event-stream
Cache-Control: no-cache
```

For preflight requests with custom headers:

```javascript
const response = await fetch('https://api.example.com/events', {
  headers: {
    'Accept': 'text/event-stream',
    'X-Custom-Header': 'value' // Triggers preflight
  }
});
```

### Chunked Transfer Encoding

SSE relies on chunked transfer encoding. The fetch API handles this transparently through the ReadableStream interface.

```javascript
// Server must send chunked responses
// fetch automatically handles Transfer-Encoding: chunked

const reader = response.body.getReader();
// Each read() returns a chunk as it arrives
```

### Buffering Strategies

Different buffering approaches optimize for different use cases.

**Line-based buffering:**

```javascript
let buffer = '';

async function processStream(stream) {
  const reader = stream.getReader();
  const decoder = new TextDecoder();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    buffer += decoder.decode(value, { stream: true });
    
    let newlineIndex;
    while ((newlineIndex = buffer.indexOf('\n')) !== -1) {
      const line = buffer.slice(0, newlineIndex);
      buffer = buffer.slice(newlineIndex + 1);
      processLine(line);
    }
  }
  
  // Process remaining buffer
  if (buffer) processLine(buffer);
}
```

**Event-based buffering:**

```javascript
let eventBuffer = {
  event: 'message',
  data: [],
  id: '',
  retry: null
};

function processLine(line) {
  if (line === '') {
    if (eventBuffer.data.length > 0) {
      const event = {
        ...eventBuffer,
        data: eventBuffer.data.join('\n')
      };
      dispatchEvent(event);
      eventBuffer = { event: 'message', data: [], id: '', retry: null };
    }
    return;
  }
  
  // Parse and accumulate
}
```

### Memory Management

Long-running SSE connections require careful memory management.

```javascript
class SSEConnection {
  constructor() {
    this.reader = null;
    this.buffer = '';
    this.bufferLimit = 1024 * 1024; // 1MB limit
  }
  
  async processStream(stream) {
    this.reader = stream.getReader();
    
    try {
      while (true) {
        const { done, value } = await this.reader.read();
        if (done) break;
        
        const chunk = this.decoder.decode(value, { stream: true });
        
        // Prevent unbounded buffer growth
        if (this.buffer.length + chunk.length > this.bufferLimit) {
          throw new Error('Buffer limit exceeded');
        }
        
        this.buffer += chunk;
        this.processBuffer();
      }
    } finally {
      this.cleanup();
    }
  }
  
  cleanup() {
    if (this.reader) {
      this.reader.releaseLock();
      this.reader = null;
    }
    this.buffer = '';
  }
}
```

### Performance Optimization

Optimizations for high-throughput SSE streams.

**Batch Processing:**

```javascript
let eventQueue = [];
let processingScheduled = false;

function queueEvent(event) {
  eventQueue.push(event);
  
  if (!processingScheduled) {
    processingScheduled = true;
    queueMicrotask(processEventQueue);
  }
}

function processEventQueue() {
  const events = eventQueue;
  eventQueue = [];
  processingScheduled = false;
  
  for (const event of events) {
    dispatchEvent(event);
  }
}
```

**Decoder Reuse:**

```javascript
const decoder = new TextDecoder();

// Reuse decoder across reads
async function processStream(stream) {
  const reader = stream.getReader();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // Decoder maintains internal state
    const text = decoder.decode(value, { stream: true });
    processText(text);
  }
  
  // Flush decoder at end
  const remaining = decoder.decode();
  if (remaining) processText(remaining);
}
```

### Integration with Async Iterators

Modern streaming patterns using async iteration.

```javascript
async function* parseSSE(response) {
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  let currentEvent = { event: 'message', data: '', id: '' };
  
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop();
      
      for (const line of lines) {
        if (line === '') {
          if (currentEvent.data) {
            yield { ...currentEvent };
            currentEvent = { event: 'message', data: '', id: '' };
          }
        } else {
          // Parse line into currentEvent
        }
      }
    }
  } finally {
    reader.releaseLock();
  }
}

// Usage
const response = await fetch('/events');
for await (const event of parseSSE(response)) {
  console.log(event);
}
```

### Timeout Handling

Implementing connection timeouts for stale connections.

```javascript
async function connectWithTimeout(url, timeout = 45000) {
  const abortController = new AbortController();
  let timeoutId;
  
  const timeoutPromise = new Promise((_, reject) => {
    timeoutId = setTimeout(() => {
      abortController.abort();
      reject(new Error('Connection timeout'));
    }, timeout);
  });
  
  try {
    const response = await Promise.race([
      fetch(url, {
        signal: abortController.signal,
        headers: { 'Accept': 'text/event-stream' }
      }),
      timeoutPromise
    ]);
    
    clearTimeout(timeoutId);
    
    // Reset timeout on each chunk
    return processStreamWithTimeout(response.body, timeout);
    
  } catch (error) {
    clearTimeout(timeoutId);
    throw error;
  }
}

async function processStreamWithTimeout(stream, timeout) {
  const reader = stream.getReader();
  
  while (true) {
    const timeoutPromise = new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Read timeout')), timeout)
    );
    
    const { done, value } = await Promise.race([
      reader.read(),
      timeoutPromise
    ]);
    
    if (done) break;
    
    // Process value
  }
}
```

### Connection Pooling Considerations

[Inference] Unlike traditional HTTP requests, SSE connections are long-lived and may interact differently with browser connection limits. Browsers typically limit concurrent connections per domain (commonly 6-8 connections).

```javascript
class SSEConnectionPool {
  constructor(maxConnections = 6) {
    this.maxConnections = maxConnections;
    this.activeConnections = new Set();
    this.pendingConnections = [];
  }
  
  async connect(url, options) {
    if (this.activeConnections.size >= this.maxConnections) {
      await new Promise(resolve => this.pendingConnections.push(resolve));
    }
    
    const connection = new SSEConnection(url, options);
    this.activeConnections.add(connection);
    
    connection.addEventListener('close', () => {
      this.activeConnections.delete(connection);
      const next = this.pendingConnections.shift();
      if (next) next();
    });
    
    return connection;
  }
}
```

### Service Worker Integration

Fetch-based SSE can operate within service workers for background event handling.

```javascript
// service-worker.js
self.addEventListener('fetch', (event) => {
  if (event.request.url.includes('/events')) {
    event.respondWith(handleSSE(event.request));
  }
});

async function handleSSE(request) {
  const response = await fetch(request);
  
  // Transform stream
  const { readable, writable } = new TransformStream({
    transform(chunk, controller) {
      // Process SSE data
      controller.enqueue(chunk);
    }
  });
  
  response.body.pipeTo(writable);
  
  return new Response(readable, {
    headers: response.headers
  });
}
```

---

# File Operations

## File Upload with the Fetch API

### Basic File Upload

The fetch API handles file uploads by sending `File` or `Blob` objects within a `FormData` payload. The browser automatically sets the appropriate `Content-Type` header with boundary parameters.

```javascript
const fileInput = document.querySelector('input[type="file"]');
const file = fileInput.files[0];

const formData = new FormData();
formData.append('file', file);

fetch('/upload', {
  method: 'POST',
  body: formData
})
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => console.error(error));
```

### Multiple File Upload

FormData supports appending multiple files to the same field name or different field names.

```javascript
const fileInput = document.querySelector('input[type="file"][multiple]');
const files = fileInput.files;

const formData = new FormData();

// Same field name (creates array on server)
for (let i = 0; i < files.length; i++) {
  formData.append('files[]', files[i]);
}

// Or different field names
Array.from(files).forEach((file, index) => {
  formData.append(`file_${index}`, file);
});

fetch('/upload-multiple', {
  method: 'POST',
  body: formData
});
```

### File Upload with Additional Fields

FormData can combine file uploads with other form data in a single request.

```javascript
const formData = new FormData();
formData.append('file', file);
formData.append('userId', '12345');
formData.append('description', 'Profile photo');
formData.append('category', 'images');
formData.append('metadata', JSON.stringify({ tags: ['profile', 'user'] }));

fetch('/upload', {
  method: 'POST',
  body: formData
});
```

### Custom Filename and MIME Type

The `append()` method accepts an optional third parameter to specify a custom filename, which is particularly useful for Blob objects.

```javascript
const blob = new Blob(['file content'], { type: 'text/plain' });

formData.append('file', blob, 'custom-filename.txt');

// For File objects, override the original filename
formData.append('file', file, 'renamed-file.pdf');
```

### Direct Binary Upload

Files can be uploaded directly as the request body without FormData, requiring manual `Content-Type` header configuration.

```javascript
const file = fileInput.files[0];

fetch('/upload', {
  method: 'POST',
  headers: {
    'Content-Type': file.type,
    'Content-Length': file.size.toString(),
    'X-Filename': encodeURIComponent(file.name)
  },
  body: file
});
```

### Upload Progress Tracking

The fetch API itself does not expose upload progress events. [Inference] Progress tracking requires XMLHttpRequest or the emerging Upload Progress API proposal (not yet standardized).

```javascript
// Using XMLHttpRequest for progress
function uploadWithProgress(file, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const percentComplete = (e.loaded / e.total) * 100;
        onProgress(percentComplete);
      }
    });
    
    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(JSON.parse(xhr.responseText));
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    });
    
    xhr.addEventListener('error', () => reject(new Error('Upload failed')));
    
    const formData = new FormData();
    formData.append('file', file);
    
    xhr.open('POST', '/upload');
    xhr.send(formData);
  });
}

uploadWithProgress(file, (percent) => {
  console.log(`Upload progress: ${percent.toFixed(2)}%`);
});
```

### Chunked File Upload

Large files can be split into chunks and uploaded sequentially or in parallel, enabling resume functionality and better error handling.

```javascript
async function uploadFileInChunks(file, chunkSize = 1024 * 1024) {
  const totalChunks = Math.ceil(file.size / chunkSize);
  
  for (let i = 0; i < totalChunks; i++) {
    const start = i * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', i.toString());
    formData.append('totalChunks', totalChunks.toString());
    formData.append('fileId', generateFileId(file));
    
    const response = await fetch('/upload-chunk', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Chunk ${i} upload failed`);
    }
  }
}

function generateFileId(file) {
  return `${file.name}-${file.size}-${file.lastModified}`;
}
```

### Parallel Chunk Upload

```javascript
async function uploadFileInParallel(file, chunkSize = 1024 * 1024, maxParallel = 3) {
  const totalChunks = Math.ceil(file.size / chunkSize);
  const chunks = [];
  
  for (let i = 0; i < totalChunks; i++) {
    chunks.push(i);
  }
  
  async function uploadChunk(index) {
    const start = index * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', index.toString());
    formData.append('totalChunks', totalChunks.toString());
    
    return fetch('/upload-chunk', {
      method: 'POST',
      body: formData
    });
  }
  
  // Upload in batches
  for (let i = 0; i < chunks.length; i += maxParallel) {
    const batch = chunks.slice(i, i + maxParallel);
    await Promise.all(batch.map(uploadChunk));
  }
}
```

### Upload with Authentication

Authentication credentials can be included via headers or cookies, depending on the authentication mechanism.

```javascript
// Bearer token
fetch('/upload', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer ' + authToken
  },
  body: formData
});

// With credentials (cookies)
fetch('/upload', {
  method: 'POST',
  credentials: 'include',
  body: formData
});

// API key
fetch('/upload', {
  method: 'POST',
  headers: {
    'X-API-Key': apiKey
  },
  body: formData
});
```

### File Validation Before Upload

Client-side validation reduces unnecessary server requests but should always be complemented with server-side validation.

```javascript
function validateFile(file, options = {}) {
  const {
    maxSize = 10 * 1024 * 1024, // 10MB
    allowedTypes = ['image/jpeg', 'image/png', 'application/pdf'],
    allowedExtensions = ['.jpg', '.jpeg', '.png', '.pdf']
  } = options;
  
  // Size validation
  if (file.size > maxSize) {
    throw new Error(`File size exceeds ${maxSize / (1024 * 1024)}MB`);
  }
  
  // MIME type validation
  if (!allowedTypes.includes(file.type)) {
    throw new Error(`File type ${file.type} not allowed`);
  }
  
  // Extension validation
  const extension = file.name.substring(file.name.lastIndexOf('.')).toLowerCase();
  if (!allowedExtensions.includes(extension)) {
    throw new Error(`File extension ${extension} not allowed`);
  }
  
  return true;
}

// Usage
try {
  validateFile(file);
  // Proceed with upload
} catch (error) {
  console.error('Validation failed:', error.message);
}
```

### Image Preview Before Upload

```javascript
function previewImage(file) {
  return new Promise((resolve, reject) => {
    if (!file.type.startsWith('image/')) {
      reject(new Error('Not an image file'));
      return;
    }
    
    const reader = new FileReader();
    
    reader.onload = (e) => {
      const img = document.createElement('img');
      img.src = e.target.result;
      img.style.maxWidth = '300px';
      document.getElementById('preview').appendChild(img);
      resolve(e.target.result);
    };
    
    reader.onerror = () => reject(new Error('Failed to read file'));
    
    reader.readAsDataURL(file);
  });
}
```

### Upload Retry Logic

Implementing automatic retry with exponential backoff improves reliability for transient network failures.

```javascript
async function uploadWithRetry(file, maxRetries = 3, baseDelay = 1000) {
  const formData = new FormData();
  formData.append('file', file);
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch('/upload', {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      return await response.json();
    } catch (error) {
      if (attempt === maxRetries) {
        throw new Error(`Upload failed after ${maxRetries} retries: ${error.message}`);
      }
      
      const delay = baseDelay * Math.pow(2, attempt);
      console.log(`Retry ${attempt + 1} after ${delay}ms`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Drag and Drop File Upload

```javascript
const dropZone = document.getElementById('drop-zone');

dropZone.addEventListener('dragover', (e) => {
  e.preventDefault();
  e.stopPropagation();
  dropZone.classList.add('dragover');
});

dropZone.addEventListener('dragleave', (e) => {
  e.preventDefault();
  e.stopPropagation();
  dropZone.classList.remove('dragover');
});

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  e.stopPropagation();
  dropZone.classList.remove('dragover');
  
  const files = Array.from(e.dataTransfer.files);
  
  for (const file of files) {
    const formData = new FormData();
    formData.append('file', file);
    
    try {
      const response = await fetch('/upload', {
        method: 'POST',
        body: formData
      });
      
      const result = await response.json();
      console.log('Uploaded:', result);
    } catch (error) {
      console.error('Upload failed:', error);
    }
  }
});
```

### Upload Cancellation

The AbortController enables upload cancellation, though the server-side handling depends on implementation.

```javascript
const controller = new AbortController();
const signal = controller.signal;

const uploadPromise = fetch('/upload', {
  method: 'POST',
  body: formData,
  signal: signal
});

// Cancel after 5 seconds or on user action
setTimeout(() => controller.abort(), 5000);

// Or bind to button
document.getElementById('cancel-btn').addEventListener('click', () => {
  controller.abort();
});

uploadPromise
  .then(response => response.json())
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Upload cancelled');
    } else {
      console.error('Upload failed:', error);
    }
  });
```

### Multipart Upload for Large Files

Some servers require multipart upload initiation, chunk upload, and completion steps for very large files.

```javascript
async function multipartUpload(file) {
  // Step 1: Initiate multipart upload
  const initResponse = await fetch('/upload/initiate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      filename: file.name,
      contentType: file.type,
      size: file.size
    })
  });
  
  const { uploadId, partSize } = await initResponse.json();
  
  // Step 2: Upload parts
  const totalParts = Math.ceil(file.size / partSize);
  const parts = [];
  
  for (let partNumber = 1; partNumber <= totalParts; partNumber++) {
    const start = (partNumber - 1) * partSize;
    const end = Math.min(start + partSize, file.size);
    const chunk = file.slice(start, end);
    
    const partResponse = await fetch(`/upload/part?uploadId=${uploadId}&partNumber=${partNumber}`, {
      method: 'PUT',
      body: chunk
    });
    
    const { etag } = await partResponse.json();
    parts.push({ partNumber, etag });
  }
  
  // Step 3: Complete multipart upload
  const completeResponse = await fetch('/upload/complete', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      uploadId,
      parts
    })
  });
  
  return await completeResponse.json();
}
```

### Reading File Content Before Upload

File content can be read into various formats before or instead of uploading.

```javascript
// Read as text
function readAsText(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result);
    reader.onerror = reject;
    reader.readAsText(file);
  });
}

// Read as Data URL (base64)
function readAsDataURL(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

// Read as ArrayBuffer
function readAsArrayBuffer(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result);
    reader.onerror = reject;
    reader.readAsArrayBuffer(file);
  });
}

// Upload base64 encoded file
async function uploadBase64(file) {
  const base64 = await readAsDataURL(file);
  
  await fetch('/upload-base64', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      filename: file.name,
      contentType: file.type,
      data: base64
    })
  });
}
```

### Compressing Images Before Upload

```javascript
async function compressImage(file, maxWidth = 1920, quality = 0.8) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    
    reader.onload = (e) => {
      const img = new Image();
      
      img.onload = () => {
        const canvas = document.createElement('canvas');
        let width = img.width;
        let height = img.height;
        
        if (width > maxWidth) {
          height *= maxWidth / width;
          width = maxWidth;
        }
        
        canvas.width = width;
        canvas.height = height;
        
        const ctx = canvas.getContext('2d');
        ctx.drawImage(img, 0, 0, width, height);
        
        canvas.toBlob((blob) => {
          resolve(new File([blob], file.name, {
            type: 'image/jpeg',
            lastModified: Date.now()
          }));
        }, 'image/jpeg', quality);
      };
      
      img.onerror = reject;
      img.src = e.target.result;
    };
    
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

// Usage
const compressed = await compressImage(originalFile);
const formData = new FormData();
formData.append('file', compressed);
await fetch('/upload', { method: 'POST', body: formData });
```

### Handling Upload Responses

```javascript
async function handleUpload(file) {
  const formData = new FormData();
  formData.append('file', file);
  
  try {
    const response = await fetch('/upload', {
      method: 'POST',
      body: formData
    });
    
    // Check response status
    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.message || `HTTP ${response.status}`);
    }
    
    // Parse success response
    const result = await response.json();
    
    // Common response fields
    console.log('File ID:', result.id);
    console.log('File URL:', result.url);
    console.log('File size:', result.size);
    console.log('Upload timestamp:', result.uploadedAt);
    
    return result;
  } catch (error) {
    if (error.name === 'TypeError') {
      console.error('Network error:', error.message);
    } else {
      console.error('Upload error:', error.message);
    }
    throw error;
  }
}
```

### CORS Considerations

Cross-origin file uploads require proper CORS headers on the server. The client must handle preflight requests for methods other than simple POST requests.

```javascript
// For cross-origin uploads
fetch('https://api.example.com/upload', {
  method: 'POST',
  body: formData,
  credentials: 'include', // If cookies needed
  headers: {
    // Do NOT set Content-Type manually for FormData
    // Browser sets it with boundary
    'Authorization': 'Bearer token'
  }
});

// Server must respond with:
// Access-Control-Allow-Origin: https://your-domain.com
// Access-Control-Allow-Methods: POST, OPTIONS
// Access-Control-Allow-Headers: Authorization
// Access-Control-Allow-Credentials: true (if using credentials)
```

### FormData Inspection

FormData contents are not directly enumerable in all browsers, but can be inspected via iterator methods.

```javascript
const formData = new FormData();
formData.append('file', file);
formData.append('userId', '123');

// Iterate over entries
for (const [key, value] of formData.entries()) {
  console.log(key, value);
}

// Get specific values
console.log(formData.get('userId')); // '123'

// Get all values for a key
console.log(formData.getAll('files[]'));

// Check if key exists
console.log(formData.has('file')); // true

// Delete entry
formData.delete('userId');
```

### Memory Management for Large Files

File objects reference disk data and don't necessarily load entirely into memory. However, operations like slicing or reading can increase memory usage.

```javascript
// Efficient: uses references
const chunk = file.slice(0, 1024 * 1024);

// Less efficient: loads entire file into memory
const arrayBuffer = await file.arrayBuffer();

// Clean up object URLs after use
const url = URL.createObjectURL(file);
// Use url...
URL.revokeObjectURL(url); // Free memory
```

### Uploading from Clipboard

```javascript
document.addEventListener('paste', async (e) => {
  const items = e.clipboardData.items;
  
  for (const item of items) {
    if (item.type.startsWith('image/')) {
      const file = item.getAsFile();
      
      const formData = new FormData();
      formData.append('file', file, `pasted-${Date.now()}.png`);
      
      await fetch('/upload', {
        method: 'POST',
        body: formData
      });
    }
  }
});
```

### Upload Queue Management

```javascript
class UploadQueue {
  constructor(concurrency = 2) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async add(file) {
    return new Promise((resolve, reject) => {
      this.queue.push({ file, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.active >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { file, resolve, reject } = this.queue.shift();
    
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await fetch('/upload', {
        method: 'POST',
        body: formData
      });
      
      const result = await response.json();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }
}

// Usage
const queue = new UploadQueue(3);
const files = fileInput.files;

for (const file of files) {
  queue.add(file)
    .then(result => console.log('Uploaded:', result))
    .catch(error => console.error('Failed:', error));
}
```

### Presigned URL Upload

Some services (like AWS S3) provide presigned URLs that allow direct client-to-storage uploads without proxying through your server.

```javascript
async function uploadToPresignedUrl(file) {
  // Step 1: Get presigned URL from your server
  const urlResponse = await fetch('/get-upload-url', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      filename: file.name,
      contentType: file.type
    })
  });
  
  const { uploadUrl, fileUrl } = await urlResponse.json();
  
  // Step 2: Upload directly to storage
  await fetch(uploadUrl, {
    method: 'PUT',
    headers: {
      'Content-Type': file.type
    },
    body: file
  });
  
  // Step 3: Notify your server of completion (optional)
  await fetch('/upload-complete', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ fileUrl })
  });
  
  return fileUrl;
}
```

---

## File Download with Fetch API

### Handling Binary Response Data

The fetch API provides multiple methods to handle downloaded file data through the Response object. The choice depends on the file type and intended use:

```javascript
// For binary files - returns ArrayBuffer
const response = await fetch('https://example.com/file.pdf');
const buffer = await response.arrayBuffer();

// For text files - returns string
const text = await response.text();

// For JSON data - returns parsed object
const json = await response.json();

// For streaming - returns ReadableStream
const stream = response.body;
```

### Blob-Based Downloads

Converting response data to Blob objects enables browser-native download mechanisms:

```javascript
const response = await fetch('https://example.com/document.pdf');
const blob = await response.blob();

// Create object URL
const url = URL.createObjectURL(blob);

// Trigger download
const a = document.createElement('a');
a.href = url;
a.download = 'document.pdf';
document.body.appendChild(a);
a.click();

// Cleanup
document.body.removeChild(a);
URL.revokeObjectURL(url);
```

### Download Progress Tracking

Streaming responses through ReadableStream enables real-time progress monitoring:

```javascript
const response = await fetch('https://example.com/large-file.zip');
const contentLength = response.headers.get('Content-Length');
const total = parseInt(contentLength, 10);
let received = 0;

const reader = response.body.getReader();
const chunks = [];

while (true) {
  const { done, value } = await reader.read();
  
  if (done) break;
  
  chunks.push(value);
  received += value.length;
  
  const progress = (received / total) * 100;
  console.log(`Progress: ${progress.toFixed(2)}%`);
}

const blob = new Blob(chunks);
```

### Handling Large Files

For files exceeding memory constraints, streaming directly to disk or processing in chunks prevents memory issues:

```javascript
async function downloadLargeFile(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  // Process chunks as they arrive
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;
    
    // Process chunk (e.g., write to IndexedDB, FileSystem API)
    await processChunk(value);
  }
}
```

### Content-Type and MIME Type Handling

Proper MIME type specification ensures correct file handling:

```javascript
const response = await fetch('https://example.com/file');
const contentType = response.headers.get('Content-Type');

// Create blob with explicit type
const blob = await response.blob();
const typedBlob = new Blob([blob], { type: contentType });

// Or specify custom type
const pdfBlob = new Blob([blob], { type: 'application/pdf' });
```

### Filename Extraction

Extracting filenames from Content-Disposition headers:

```javascript
function getFilenameFromResponse(response) {
  const disposition = response.headers.get('Content-Disposition');
  
  if (!disposition) return 'download';
  
  // Match filename*=UTF-8''encoded or filename="quoted"
  const utf8Match = disposition.match(/filename\*=UTF-8''(.+)/i);
  if (utf8Match) {
    return decodeURIComponent(utf8Match[1]);
  }
  
  const quotedMatch = disposition.match(/filename="(.+)"/i);
  if (quotedMatch) {
    return quotedMatch[1];
  }
  
  const unquotedMatch = disposition.match(/filename=([^;]+)/i);
  if (unquotedMatch) {
    return unquotedMatch[1].trim();
  }
  
  return 'download';
}

const response = await fetch('https://example.com/file');
const filename = getFilenameFromResponse(response);
```

### Cross-Origin Download Considerations

CORS policies affect file downloads from different origins:

```javascript
// Server must send appropriate CORS headers
fetch('https://other-domain.com/file.pdf', {
  mode: 'cors',
  credentials: 'include' // If authentication needed
})
  .then(response => {
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    return response.blob();
  })
  .then(blob => {
    // Process download
  });
```

Required server headers:

```
Access-Control-Allow-Origin: https://your-domain.com
Access-Control-Allow-Credentials: true
Access-Control-Expose-Headers: Content-Disposition, Content-Length
```

### Authentication and Authorization

Including credentials in download requests:

```javascript
// Bearer token
fetch('https://api.example.com/files/123', {
  headers: {
    'Authorization': 'Bearer ' + token
  }
})
  .then(response => response.blob());

// Cookie-based authentication
fetch('https://api.example.com/files/123', {
  credentials: 'include'
})
  .then(response => response.blob());

// Custom headers
fetch('https://api.example.com/files/123', {
  headers: {
    'X-API-Key': apiKey,
    'X-User-Token': userToken
  }
})
  .then(response => response.blob());
```

### Error Handling and Retry Logic

Robust error handling for download failures:

```javascript
async function downloadWithRetry(url, maxRetries = 3) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const blob = await response.blob();
      return blob;
      
    } catch (error) {
      console.error(`Attempt ${attempt} failed:`, error);
      
      if (attempt === maxRetries) {
        throw new Error(`Download failed after ${maxRetries} attempts`);
      }
      
      // Exponential backoff
      await new Promise(resolve => 
        setTimeout(resolve, Math.pow(2, attempt) * 1000)
      );
    }
  }
}
```

### Range Requests for Resumable Downloads

Implementing partial content downloads:

```javascript
async function downloadRange(url, start, end) {
  const response = await fetch(url, {
    headers: {
      'Range': `bytes=${start}-${end}`
    }
  });
  
  if (response.status === 206) { // Partial Content
    return await response.arrayBuffer();
  }
  
  throw new Error('Range requests not supported');
}

// Resume interrupted download
async function resumableDownload(url) {
  const chunks = [];
  const chunkSize = 1024 * 1024; // 1MB chunks
  let downloaded = 0;
  
  // Get total size
  const headResponse = await fetch(url, { method: 'HEAD' });
  const totalSize = parseInt(headResponse.headers.get('Content-Length'), 10);
  
  while (downloaded < totalSize) {
    const end = Math.min(downloaded + chunkSize - 1, totalSize - 1);
    const chunk = await downloadRange(url, downloaded, end);
    chunks.push(chunk);
    downloaded = end + 1;
    
    console.log(`Downloaded: ${downloaded}/${totalSize}`);
  }
  
  return new Blob(chunks);
}
```

### Memory-Efficient Streaming Downloads

Using streams to avoid loading entire files into memory:

```javascript
async function streamToFile(url, filename) {
  const response = await fetch(url);
  
  // Check if browser supports File System Access API
  if ('showSaveFilePicker' in window) {
    const handle = await window.showSaveFilePicker({
      suggestedName: filename
    });
    const writable = await handle.createWritable();
    
    const reader = response.body.getReader();
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      await writable.write(value);
    }
    
    await writable.close();
  } else {
    // Fallback to blob download
    const blob = await response.blob();
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    a.click();
    URL.revokeObjectURL(url);
  }
}
```

### Concurrent Chunk Downloads

Downloading file segments in parallel for improved speed:

```javascript
async function parallelDownload(url, numConnections = 4) {
  // Get file size
  const headResponse = await fetch(url, { method: 'HEAD' });
  const fileSize = parseInt(headResponse.headers.get('Content-Length'), 10);
  
  const chunkSize = Math.ceil(fileSize / numConnections);
  const promises = [];
  
  for (let i = 0; i < numConnections; i++) {
    const start = i * chunkSize;
    const end = Math.min(start + chunkSize - 1, fileSize - 1);
    
    promises.push(
      fetch(url, {
        headers: { 'Range': `bytes=${start}-${end}` }
      }).then(response => response.arrayBuffer())
    );
  }
  
  const chunks = await Promise.all(promises);
  return new Blob(chunks);
}
```

### Download Cancellation

Implementing cancellable downloads with AbortController:

```javascript
let abortController = null;

async function startDownload(url) {
  abortController = new AbortController();
  
  try {
    const response = await fetch(url, {
      signal: abortController.signal
    });
    
    const reader = response.body.getReader();
    const chunks = [];
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
    }
    
    const blob = new Blob(chunks);
    return blob;
    
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Download cancelled');
    } else {
      throw error;
    }
  }
}

function cancelDownload() {
  if (abortController) {
    abortController.abort();
  }
}
```

### Integrity Verification

Validating downloaded files using checksums:

```javascript
async function downloadAndVerify(url, expectedHash) {
  const response = await fetch(url);
  const buffer = await response.arrayBuffer();
  
  // Calculate hash
  const hashBuffer = await crypto.subtle.digest('SHA-256', buffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  
  if (hashHex !== expectedHash) {
    throw new Error('Integrity check failed: hash mismatch');
  }
  
  return new Blob([buffer]);
}
```

### Compression Handling

Dealing with compressed responses:

```javascript
async function downloadCompressed(url) {
  const response = await fetch(url);
  const encoding = response.headers.get('Content-Encoding');
  
  if (encoding === 'gzip' || encoding === 'deflate' || encoding === 'br') {
    // Browser automatically decompresses
    const blob = await response.blob();
    return blob;
  }
  
  // Manual decompression for unsupported formats
  const buffer = await response.arrayBuffer();
  // Use third-party library for decompression
  return buffer;
}
```

### Download Queue Management

Managing multiple simultaneous downloads:

```javascript
class DownloadQueue {
  constructor(maxConcurrent = 3) {
    this.maxConcurrent = maxConcurrent;
    this.active = 0;
    this.queue = [];
  }
  
  async add(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.active >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }
    
    const { url, options, resolve, reject } = this.queue.shift();
    this.active++;
    
    try {
      const response = await fetch(url, options);
      const blob = await response.blob();
      resolve(blob);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }
}

const queue = new DownloadQueue(3);
queue.add('https://example.com/file1.pdf');
queue.add('https://example.com/file2.pdf');
```

### Response Caching

Leveraging browser cache for repeated downloads:

```javascript
// Force cache revalidation
fetch(url, {
  cache: 'reload'
});

// Use cached version if available
fetch(url, {
  cache: 'force-cache'
});

// Default behavior - check freshness
fetch(url, {
  cache: 'default'
});

// Only use cache, fail if not cached
fetch(url, {
  cache: 'only-if-cached',
  mode: 'same-origin'
});
```

### Service Worker Integration

Intercepting downloads in service workers:

```javascript
// In service worker
self.addEventListener('fetch', event => {
  if (event.request.url.endsWith('.pdf')) {
    event.respondWith(
      caches.match(event.request).then(cached => {
        if (cached) return cached;
        
        return fetch(event.request).then(response => {
          const clone = response.clone();
          caches.open('downloads').then(cache => {
            cache.put(event.request, clone);
          });
          return response;
        });
      })
    );
  }
});
```

### Bandwidth Throttling Simulation

Testing downloads under constrained network conditions:

```javascript
async function throttledDownload(url, bytesPerSecond) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const chunks = [];
  
  const chunkDelay = 100; // ms
  const bytesPerChunk = (bytesPerSecond * chunkDelay) / 1000;
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    chunks.push(value);
    
    // Simulate throttling
    await new Promise(resolve => setTimeout(resolve, chunkDelay));
  }
  
  return new Blob(chunks);
}
```

### Multi-Part File Assembly

Downloading and assembling files split across multiple endpoints:

```javascript
async function downloadMultipart(urls) {
  const chunks = await Promise.all(
    urls.map(url => 
      fetch(url).then(response => response.arrayBuffer())
    )
  );
  
  // Calculate total size
  const totalSize = chunks.reduce((sum, chunk) => sum + chunk.byteLength, 0);
  
  // Combine into single ArrayBuffer
  const combined = new Uint8Array(totalSize);
  let offset = 0;
  
  for (const chunk of chunks) {
    combined.set(new Uint8Array(chunk), offset);
    offset += chunk.byteLength;
  }
  
  return new Blob([combined.buffer]);
}
```

### Download State Persistence

Storing download progress for recovery:

```javascript
class PersistentDownload {
  constructor(url, storageKey) {
    this.url = url;
    this.storageKey = storageKey;
  }
  
  async download() {
    // Load previous progress
    const savedProgress = localStorage.getItem(this.storageKey);
    let downloaded = savedProgress ? parseInt(savedProgress, 10) : 0;
    
    const response = await fetch(this.url, {
      headers: downloaded > 0 ? { 'Range': `bytes=${downloaded}-` } : {}
    });
    
    const reader = response.body.getReader();
    const chunks = [];
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      chunks.push(value);
      downloaded += value.length;
      
      // Save progress
      localStorage.setItem(this.storageKey, downloaded.toString());
    }
    
    // Clear progress on completion
    localStorage.removeItem(this.storageKey);
    
    return new Blob(chunks);
  }
}
```

### TypeScript Type Safety

Type definitions for download operations:

```typescript
interface DownloadOptions {
  method?: string;
  headers?: Record<string, string>;
  signal?: AbortSignal;
  onProgress?: (loaded: number, total: number) => void;
}

interface DownloadResult {
  blob: Blob;
  filename: string;
  contentType: string;
  size: number;
}

async function downloadFile(
  url: string, 
  options: DownloadOptions = {}
): Promise<DownloadResult> {
  const response = await fetch(url, {
    method: options.method || 'GET',
    headers: options.headers,
    signal: options.signal
  });
  
  if (!response.ok) {
    throw new Error(`Download failed: ${response.status}`);
  }
  
  const contentLength = response.headers.get('Content-Length');
  const total = contentLength ? parseInt(contentLength, 10) : 0;
  let loaded = 0;
  
  const reader = response.body!.getReader();
  const chunks: Uint8Array[] = [];
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    chunks.push(value);
    loaded += value.length;
    
    if (options.onProgress && total > 0) {
      options.onProgress(loaded, total);
    }
  }
  
  const blob = new Blob(chunks);
  
  return {
    blob,
    filename: getFilenameFromResponse(response),
    contentType: response.headers.get('Content-Type') || 'application/octet-stream',
    size: blob.size
  };
}
```

---

## Progress Monitoring in Fetch API File Operations

### Understanding Progress Events

The Fetch API itself does not directly expose progress events for uploads or downloads. Unlike `XMLHttpRequest`, which provides `progress`, `load`, and `error` events through its event system, the Fetch API uses Streams API for progress monitoring.

### Download Progress Monitoring

#### Using ReadableStream

Response bodies in Fetch are exposed as `ReadableStream` objects, allowing chunk-by-chunk processing:

```javascript
const response = await fetch('https://example.com/largefile.zip');
const reader = response.body.getReader();
const contentLength = +response.headers.get('Content-Length');

let receivedLength = 0;
const chunks = [];

while(true) {
  const {done, value} = await reader.read();
  
  if (done) break;
  
  chunks.push(value);
  receivedLength += value.length;
  
  const progress = (receivedLength / contentLength) * 100;
  console.log(`Downloaded: ${progress.toFixed(2)}%`);
}
```

#### Reconstructing the Complete Response

After reading all chunks, combine them into a single response:

```javascript
const chunksAll = new Uint8Array(receivedLength);
let position = 0;

for(const chunk of chunks) {
  chunksAll.set(chunk, position);
  position += chunk.length;
}

// Convert to appropriate format
const blob = new Blob([chunksAll]);
const text = new TextDecoder("utf-8").decode(chunksAll);
const json = JSON.parse(text);
```

#### Handling Missing Content-Length

[Inference] When `Content-Length` header is absent (streaming responses, chunked transfer encoding), total size cannot be determined:

```javascript
const contentLength = +response.headers.get('Content-Length');

if (!contentLength) {
  console.log(`Downloaded: ${receivedLength} bytes (total unknown)`);
} else {
  const progress = (receivedLength / contentLength) * 100;
  console.log(`Downloaded: ${progress.toFixed(2)}%`);
}
```

### Upload Progress Monitoring

#### The Fundamental Limitation

The Fetch API does not provide built-in upload progress monitoring. The request body is sent as a complete operation without intermediate progress callbacks.

#### Alternative Approaches

**XMLHttpRequest for Upload Progress:**

```javascript
function uploadWithProgress(url, file, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const progress = (e.loaded / e.total) * 100;
        onProgress(progress);
      }
    });
    
    xhr.addEventListener('load', () => {
      resolve(xhr.response);
    });
    
    xhr.addEventListener('error', () => {
      reject(new Error('Upload failed'));
    });
    
    xhr.open('POST', url);
    xhr.send(file);
  });
}
```

**[Unverified] Custom Stream Implementation:**

[Speculation] While theoretically possible to create a custom `ReadableStream` that tracks bytes written, browser implementations may buffer the entire stream before transmission, making progress tracking unreliable.

### Practical Implementation Patterns

#### Download Progress Component

```javascript
async function downloadWithProgress(url, onProgress) {
  const response = await fetch(url);
  
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  
  const contentLength = +response.headers.get('Content-Length');
  const reader = response.body.getReader();
  
  let receivedLength = 0;
  const chunks = [];
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    receivedLength += value.length;
    
    if (contentLength) {
      onProgress({
        loaded: receivedLength,
        total: contentLength,
        percentage: (receivedLength / contentLength) * 100
      });
    } else {
      onProgress({
        loaded: receivedLength,
        total: null,
        percentage: null
      });
    }
  }
  
  const blob = new Blob(chunks);
  return blob;
}
```

#### Cancelable Downloads

Combining `AbortController` with progress monitoring:

```javascript
const controller = new AbortController();
const signal = controller.signal;

async function cancelableDownload(url, onProgress) {
  const response = await fetch(url, { signal });
  const reader = response.body.getReader();
  const contentLength = +response.headers.get('Content-Length');
  
  let receivedLength = 0;
  const chunks = [];
  
  try {
    while (true) {
      const {done, value} = await reader.read();
      
      if (done) break;
      
      chunks.push(value);
      receivedLength += value.length;
      
      onProgress(receivedLength, contentLength);
    }
    
    return new Blob(chunks);
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Download canceled');
    }
    throw error;
  }
}

// Cancel the download
controller.abort();
```

### Memory Management Considerations

#### Streaming to Disk (Service Workers)

[Inference] In Service Workers with Cache API, chunks can be written incrementally to avoid memory accumulation:

```javascript
// Service Worker context
async function streamToCache(url, cacheName) {
  const response = await fetch(url);
  const cache = await caches.open(cacheName);
  
  // Cache the response while monitoring progress
  await cache.put(url, response.clone());
  
  // Monitor progress separately
  const reader = response.body.getReader();
  let receivedLength = 0;
  
  while (true) {
    const {done, value} = await reader.read();
    if (done) break;
    receivedLength += value.length;
    
    // Send progress to clients
    self.clients.matchAll().then(clients => {
      clients.forEach(client => {
        client.postMessage({
          type: 'download-progress',
          loaded: receivedLength
        });
      });
    });
  }
}
```

#### Chunked Processing

For large files, process chunks immediately rather than accumulating:

```javascript
async function processLargeFile(url, chunkProcessor) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    // Process each chunk immediately
    await chunkProcessor(value);
  }
}

// Example: Hash calculation without storing entire file
import { SHA256 } from 'crypto-js';

let hash = SHA256.create();

await processLargeFile(url, (chunk) => {
  const wordArray = SHA256.lib.WordArray.create(chunk);
  hash.update(wordArray);
});

const finalHash = hash.finalize().toString();
```

### Browser Compatibility and Fallbacks

#### Feature Detection

```javascript
function supportsStreamProgress() {
  return 'body' in Response.prototype && 
         'getReader' in ReadableStream.prototype;
}

async function downloadFile(url, onProgress) {
  if (supportsStreamProgress()) {
    return downloadWithProgress(url, onProgress);
  } else {
    // Fallback: download without progress
    const response = await fetch(url);
    return response.blob();
  }
}
```

### Performance Optimization

#### Throttling Progress Updates

Avoid excessive UI updates by throttling progress callbacks:

```javascript
function createThrottledProgress(callback, delay = 100) {
  let lastUpdate = 0;
  
  return (loaded, total) => {
    const now = Date.now();
    
    if (now - lastUpdate >= delay) {
      callback(loaded, total);
      lastUpdate = now;
    }
  };
}

const throttledProgress = createThrottledProgress((loaded, total) => {
  updateProgressBar(loaded, total);
}, 100);

await downloadWithProgress(url, throttledProgress);
```

#### RequestAnimationFrame for Smooth UI

```javascript
let rafId;
let currentProgress = { loaded: 0, total: 0 };

function updateProgressRAF() {
  updateProgressBar(currentProgress.loaded, currentProgress.total);
  rafId = requestAnimationFrame(updateProgressRAF);
}

rafId = requestAnimationFrame(updateProgressRAF);

await downloadWithProgress(url, (loaded, total) => {
  currentProgress = { loaded, total };
});

cancelAnimationFrame(rafId);
```

### Real-World Implementation Example

```javascript
class DownloadManager {
  constructor() {
    this.downloads = new Map();
  }
  
  async download(url, options = {}) {
    const id = crypto.randomUUID();
    const controller = new AbortController();
    
    const downloadInfo = {
      id,
      url,
      controller,
      progress: { loaded: 0, total: null, percentage: 0 },
      status: 'pending'
    };
    
    this.downloads.set(id, downloadInfo);
    
    try {
      downloadInfo.status = 'downloading';
      
      const response = await fetch(url, {
        signal: controller.signal
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const contentLength = +response.headers.get('Content-Length');
      const reader = response.body.getReader();
      
      let receivedLength = 0;
      const chunks = [];
      
      while (true) {
        const {done, value} = await reader.read();
        
        if (done) break;
        
        chunks.push(value);
        receivedLength += value.length;
        
        downloadInfo.progress = {
          loaded: receivedLength,
          total: contentLength || null,
          percentage: contentLength 
            ? (receivedLength / contentLength) * 100 
            : null
        };
        
        if (options.onProgress) {
          options.onProgress(downloadInfo.progress);
        }
      }
      
      downloadInfo.status = 'completed';
      const blob = new Blob(chunks);
      
      return { id, blob, url };
      
    } catch (error) {
      downloadInfo.status = error.name === 'AbortError' 
        ? 'canceled' 
        : 'failed';
      downloadInfo.error = error.message;
      throw error;
      
    } finally {
      if (options.onComplete) {
        options.onComplete(downloadInfo);
      }
    }
  }
  
  cancel(id) {
    const download = this.downloads.get(id);
    if (download && download.status === 'downloading') {
      download.controller.abort();
    }
  }
  
  getProgress(id) {
    return this.downloads.get(id)?.progress;
  }
  
  getAllDownloads() {
    return Array.from(this.downloads.values());
  }
}
```

---

## Large File Handling with the Fetch API

### Understanding the Challenge

Large file operations present unique challenges when using the fetch API. Memory constraints, network interruptions, timeout issues, and user experience concerns all become critical factors. The browser's memory limitations mean that loading an entire large file into memory can cause crashes or severe performance degradation, particularly on mobile devices or systems with limited resources.

### Streaming Responses with ReadableStream

The fetch API provides native streaming capabilities through the ReadableStream interface, allowing you to process large files incrementally rather than waiting for the complete download.

```javascript
async function streamLargeFile(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const contentLength = +response.headers.get('Content-Length');
  
  let receivedLength = 0;
  let chunks = [];
  
  while(true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    receivedLength += value.length;
    
    // Progress tracking
    const progress = (receivedLength / contentLength) * 100;
    console.log(`Downloaded ${progress.toFixed(2)}%`);
  }
  
  // Concatenate chunks
  const chunksAll = new Uint8Array(receivedLength);
  let position = 0;
  for(let chunk of chunks) {
    chunksAll.set(chunk, position);
    position += chunk.length;
  }
  
  return chunksAll;
}
```

### Processing Data During Download

Rather than accumulating all chunks, process them immediately to minimize memory usage:

```javascript
async function processStreamingData(url, processFn) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  
  while(true) {
    const {done, value} = await reader.read();
    if (done) break;
    
    // Process each chunk immediately
    const chunk = decoder.decode(value, {stream: true});
    await processFn(chunk);
  }
}

// Example: Process large CSV file line by line
await processStreamingData('large-data.csv', async (chunk) => {
  const lines = chunk.split('\n');
  for (const line of lines) {
    // Process each line
    await processRow(line);
  }
});
```

### Implementing Range Requests

Range requests allow you to download large files in segments, enabling pause/resume functionality and reducing memory footprint:

```javascript
async function downloadWithRanges(url, chunkSize = 1024 * 1024) { // 1MB chunks
  // Get file size
  const headResponse = await fetch(url, { method: 'HEAD' });
  const fileSize = +headResponse.headers.get('Content-Length');
  
  const chunks = [];
  let start = 0;
  
  while (start < fileSize) {
    const end = Math.min(start + chunkSize - 1, fileSize - 1);
    
    const response = await fetch(url, {
      headers: {
        'Range': `bytes=${start}-${end}`
      }
    });
    
    const chunk = await response.arrayBuffer();
    chunks.push(new Uint8Array(chunk));
    
    start = end + 1;
    
    // Progress reporting
    const progress = (start / fileSize) * 100;
    console.log(`Progress: ${progress.toFixed(2)}%`);
  }
  
  // Combine chunks
  const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  
  for (const chunk of chunks) {
    result.set(chunk, offset);
    offset += chunk.length;
  }
  
  return result;
}
```

### Resumable Downloads

Implement resumable downloads by tracking progress and supporting range requests:

```javascript
class ResumableDownload {
  constructor(url, filename) {
    this.url = url;
    this.filename = filename;
    this.downloadedBytes = 0;
    this.totalBytes = 0;
    this.chunks = [];
    this.paused = false;
    this.abortController = null;
  }
  
  async getFileSize() {
    const response = await fetch(this.url, { method: 'HEAD' });
    this.totalBytes = +response.headers.get('Content-Length');
    return this.totalBytes;
  }
  
  async start() {
    await this.getFileSize();
    this.abortController = new AbortController();
    
    const response = await fetch(this.url, {
      headers: {
        'Range': `bytes=${this.downloadedBytes}-`
      },
      signal: this.abortController.signal
    });
    
    const reader = response.body.getReader();
    
    try {
      while (true) {
        if (this.paused) {
          await new Promise(resolve => {
            this.resumeCallback = resolve;
          });
        }
        
        const {done, value} = await reader.read();
        if (done) break;
        
        this.chunks.push(value);
        this.downloadedBytes += value.length;
        
        this.onProgress?.(this.downloadedBytes, this.totalBytes);
      }
      
      this.onComplete?.(this.combineChunks());
    } catch (error) {
      if (error.name === 'AbortError') {
        this.onPause?.(this.downloadedBytes);
      } else {
        this.onError?.(error);
      }
    }
  }
  
  pause() {
    this.paused = true;
    this.abortController?.abort();
  }
  
  resume() {
    this.paused = false;
    this.resumeCallback?.();
    this.start();
  }
  
  combineChunks() {
    const totalLength = this.chunks.reduce((acc, chunk) => acc + chunk.length, 0);
    const result = new Uint8Array(totalLength);
    let offset = 0;
    
    for (const chunk of this.chunks) {
      result.set(chunk, offset);
      offset += chunk.length;
    }
    
    return result;
  }
}

// Usage
const download = new ResumableDownload('large-file.zip', 'file.zip');
download.onProgress = (downloaded, total) => {
  console.log(`${(downloaded/total*100).toFixed(2)}%`);
};
download.onComplete = (data) => {
  console.log('Download complete', data);
};
download.start();
```

### Uploading Large Files

Uploading large files requires different strategies to handle size limitations and provide progress feedback:

```javascript
async function uploadLargeFile(file, url, chunkSize = 5 * 1024 * 1024) { // 5MB chunks
  const totalChunks = Math.ceil(file.size / chunkSize);
  
  for (let chunkIndex = 0; chunkIndex < totalChunks; chunkIndex++) {
    const start = chunkIndex * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', chunkIndex);
    formData.append('totalChunks', totalChunks);
    formData.append('filename', file.name);
    
    const response = await fetch(url, {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Upload failed for chunk ${chunkIndex}`);
    }
    
    // Progress tracking
    const progress = ((chunkIndex + 1) / totalChunks) * 100;
    console.log(`Upload progress: ${progress.toFixed(2)}%`);
  }
}
```

### Using XMLHttpRequest for Upload Progress

While fetch is modern, XMLHttpRequest still provides better upload progress tracking:

```javascript
function uploadWithProgress(file, url) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const percentComplete = (e.loaded / e.total) * 100;
        console.log(`Upload: ${percentComplete.toFixed(2)}%`);
      }
    });
    
    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(xhr.response);
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    });
    
    xhr.addEventListener('error', () => reject(new Error('Upload error')));
    
    const formData = new FormData();
    formData.append('file', file);
    
    xhr.open('POST', url);
    xhr.send(formData);
  });
}
```

### Streaming Upload with Fetch (Experimental)

Modern browsers support streaming request bodies, though browser support varies:

```javascript
async function streamUpload(file, url) {
  const stream = file.stream();
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': file.type,
      'Content-Length': file.size
    },
    body: stream,
    duplex: 'half' // Required for streaming requests
  });
  
  return response;
}
```

### Memory-Efficient File Processing

Process files without loading them entirely into memory:

```javascript
async function processLargeFileInChunks(file, processFn, chunkSize = 1024 * 1024) {
  let offset = 0;
  
  while (offset < file.size) {
    const chunk = file.slice(offset, offset + chunkSize);
    const arrayBuffer = await chunk.arrayBuffer();
    
    await processFn(new Uint8Array(arrayBuffer), offset);
    
    offset += chunkSize;
    
    // Allow garbage collection
    await new Promise(resolve => setTimeout(resolve, 0));
  }
}

// Example: Calculate hash of large file
async function hashLargeFile(file) {
  const hashBuffer = await crypto.subtle.digest('SHA-256', 
    await file.arrayBuffer()
  );
  return Array.from(new Uint8Array(hashBuffer))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
}
```

### Handling Timeouts and Retries

Large file operations need robust error handling and retry logic:

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  const controller = new AbortController();
  const timeout = options.timeout || 300000; // 5 minutes default
  
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  let lastError;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return response;
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries) {
        // Exponential backoff
        const delay = Math.min(1000 * Math.pow(2, attempt), 10000);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}
```

### Parallel Chunk Downloads

Download multiple chunks simultaneously to maximize throughput:

```javascript
async function parallelChunkDownload(url, options = {}) {
  const { maxParallel = 4, chunkSize = 2 * 1024 * 1024 } = options;
  
  // Get file size
  const headResponse = await fetch(url, { method: 'HEAD' });
  const fileSize = +headResponse.headers.get('Content-Length');
  
  const numChunks = Math.ceil(fileSize / chunkSize);
  const chunks = new Array(numChunks);
  
  async function downloadChunk(index) {
    const start = index * chunkSize;
    const end = Math.min(start + chunkSize - 1, fileSize - 1);
    
    const response = await fetch(url, {
      headers: { 'Range': `bytes=${start}-${end}` }
    });
    
    chunks[index] = new Uint8Array(await response.arrayBuffer());
  }
  
  // Download in parallel batches
  for (let i = 0; i < numChunks; i += maxParallel) {
    const batch = [];
    for (let j = 0; j < maxParallel && i + j < numChunks; j++) {
      batch.push(downloadChunk(i + j));
    }
    await Promise.all(batch);
  }
  
  // Combine chunks
  const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  
  for (const chunk of chunks) {
    result.set(chunk, offset);
    offset += chunk.length;
  }
  
  return result;
}
```

### Service Worker Caching for Large Files

Use service workers to cache large files efficiently:

```javascript
// service-worker.js
self.addEventListener('fetch', (event) => {
  if (event.request.url.includes('/large-files/')) {
    event.respondWith(
      caches.open('large-files-v1').then(async (cache) => {
        const cached = await cache.match(event.request);
        
        if (cached) {
          return cached;
        }
        
        const response = await fetch(event.request);
        
        // Only cache successful responses
        if (response.ok) {
          cache.put(event.request, response.clone());
        }
        
        return response;
      })
    );
  }
});
```

### Download Progress with Transform Streams

Use Transform Streams for processing data while tracking progress:

```javascript
async function downloadWithTransform(url, transformFn) {
  const response = await fetch(url);
  const contentLength = +response.headers.get('Content-Length');
  let receivedLength = 0;
  
  const transformStream = new TransformStream({
    transform(chunk, controller) {
      receivedLength += chunk.length;
      const progress = (receivedLength / contentLength) * 100;
      
      // Report progress
      self.postMessage({ type: 'progress', progress });
      
      // Transform the chunk if needed
      const transformed = transformFn ? transformFn(chunk) : chunk;
      controller.enqueue(transformed);
    }
  });
  
  const transformedResponse = new Response(
    response.body.pipeThrough(transformStream)
  );
  
  return transformedResponse;
}
```

### Blob URL Management

Create and manage blob URLs for large downloaded files:

```javascript
class LargeFileManager {
  constructor() {
    this.blobUrls = new Map();
  }
  
  async download(url, filename) {
    const response = await fetch(url);
    const blob = await response.blob();
    
    const blobUrl = URL.createObjectURL(blob);
    this.blobUrls.set(filename, blobUrl);
    
    return blobUrl;
  }
  
  trigger(filename) {
    const blobUrl = this.blobUrls.get(filename);
    if (!blobUrl) return;
    
    const a = document.createElement('a');
    a.href = blobUrl;
    a.download = filename;
    a.click();
  }
  
  revoke(filename) {
    const blobUrl = this.blobUrls.get(filename);
    if (blobUrl) {
      URL.revokeObjectURL(blobUrl);
      this.blobUrls.delete(filename);
    }
  }
  
  revokeAll() {
    for (const [filename, blobUrl] of this.blobUrls) {
      URL.revokeObjectURL(blobUrl);
    }
    this.blobUrls.clear();
  }
}
```

### Compression During Transfer

Apply compression to reduce transfer size:

```javascript
async function downloadCompressed(url) {
  const response = await fetch(url, {
    headers: {
      'Accept-Encoding': 'gzip, deflate, br'
    }
  });
  
  // Check if compressed
  const encoding = response.headers.get('Content-Encoding');
  console.log('Encoding:', encoding);
  
  // Decompress if needed (browser handles automatically)
  const decompressed = await response.arrayBuffer();
  
  return decompressed;
}

// Manual decompression with DecompressionStream
async function manualDecompress(compressedData, format = 'gzip') {
  const stream = new Blob([compressedData]).stream();
  const decompressedStream = stream.pipeThrough(
    new DecompressionStream(format)
  );
  
  const response = new Response(decompressedStream);
  return response.arrayBuffer();
}
```

### Monitoring Network Conditions

Adapt chunk sizes based on network conditions:

```javascript
class AdaptiveDownloader {
  constructor(url) {
    this.url = url;
    this.chunkSize = 1024 * 1024; // Start with 1MB
    this.minChunkSize = 256 * 1024; // 256KB
    this.maxChunkSize = 10 * 1024 * 1024; // 10MB
  }
  
  async download() {
    const connection = navigator.connection;
    
    // Adjust based on connection type
    if (connection) {
      const effectiveType = connection.effectiveType;
      
      switch(effectiveType) {
        case 'slow-2g':
        case '2g':
          this.chunkSize = this.minChunkSize;
          break;
        case '3g':
          this.chunkSize = 512 * 1024;
          break;
        case '4g':
          this.chunkSize = this.maxChunkSize;
          break;
      }
    }
    
    // Monitor for changes
    connection?.addEventListener('change', () => {
      console.log('Connection changed:', connection.effectiveType);
    });
    
    return this.downloadWithChunks();
  }
  
  async downloadWithChunks() {
    const response = await fetch(this.url, { method: 'HEAD' });
    const fileSize = +response.headers.get('Content-Length');
    
    let downloaded = 0;
    const chunks = [];
    
    while (downloaded < fileSize) {
      const start = downloaded;
      const end = Math.min(downloaded + this.chunkSize - 1, fileSize - 1);
      
      const startTime = performance.now();
      
      const chunkResponse = await fetch(this.url, {
        headers: { 'Range': `bytes=${start}-${end}` }
      });
      
      const chunk = await chunkResponse.arrayBuffer();
      const endTime = performance.now();
      
      chunks.push(new Uint8Array(chunk));
      downloaded = end + 1;
      
      // Adapt chunk size based on download speed
      const duration = endTime - startTime;
      const bytesPerMs = chunk.byteLength / duration;
      
      // Adjust if too slow or too fast
      if (duration > 5000) { // More than 5 seconds
        this.chunkSize = Math.max(
          this.minChunkSize,
          this.chunkSize * 0.75
        );
      } else if (duration < 1000) { // Less than 1 second
        this.chunkSize = Math.min(
          this.maxChunkSize,
          this.chunkSize * 1.5
        );
      }
    }
    
    return this.combineChunks(chunks);
  }
  
  combineChunks(chunks) {
    const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
    const result = new Uint8Array(totalLength);
    let offset = 0;
    
    for (const chunk of chunks) {
      result.set(chunk, offset);
      offset += chunk.length;
    }
    
    return result;
  }
}
```

### IndexedDB Storage for Large Files

Store large files in IndexedDB for offline access:

```javascript
class FileStorage {
  constructor(dbName = 'LargeFilesDB') {
    this.dbName = dbName;
    this.db = null;
  }
  
  async init() {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, 1);
      
      request.onerror = () => reject(request.error);
      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };
      
      request.onupgradeneeded = (event) => {
        const db = event.target.result;
        if (!db.objectStoreNames.contains('files')) {
          db.createObjectStore('files', { keyPath: 'id' });
        }
      };
    });
  }
  
  async saveFile(id, data, metadata = {}) {
    const transaction = this.db.transaction(['files'], 'readwrite');
    const store = transaction.objectStore('files');
    
    await store.put({
      id,
      data,
      metadata,
      timestamp: Date.now()
    });
  }
  
  async getFile(id) {
    const transaction = this.db.transaction(['files'], 'readonly');
    const store = transaction.objectStore('files');
    
    return new Promise((resolve, reject) => {
      const request = store.get(id);
      request.onsuccess = () => resolve(request.result);
      request.onerror = () => reject(request.error);
    });
  }
  
  async deleteFile(id) {
    const transaction = this.db.transaction(['files'], 'readwrite');
    const store = transaction.objectStore('files');
    await store.delete(id);
  }
}
```

### Best Practices Summary

Always implement proper progress tracking for user feedback during long operations. Use streaming whenever possible to minimize memory usage. Implement retry logic with exponential backoff for network failures. Consider chunking strategies based on file size and network conditions. Use range requests for resumable downloads. Monitor memory usage and release resources promptly using `URL.revokeObjectURL()`. Implement proper error boundaries and user-friendly error messages. Test with various file sizes and network conditions. Consider using Web Workers for CPU-intensive processing during file operations. Implement proper cancellation mechanisms using AbortController.

---

## Blob URL Creation

### Core Mechanism

Blob URLs are temporary, browser-generated references to binary data stored in memory. Created via `URL.createObjectURL()`, they produce strings with the `blob:` protocol scheme followed by an origin and unique identifier (e.g., `blob:https://example.com/550e8400-e29b-41d4-a716-446655440000`).

```javascript
const blob = new Blob(['Hello, world!'], { type: 'text/plain' });
const blobUrl = URL.createObjectURL(blob);
// Result: "blob:https://example.com/550e8400-e29b-41d4-a716-446655440000"
```

The browser maintains an internal registry mapping these URLs to Blob objects. The URL remains valid only within the creating document's context and lifetime.

### Blob Construction for URL Creation

#### From Raw Data

```javascript
// Text content
const textBlob = new Blob(['Line 1\n', 'Line 2'], { type: 'text/plain' });

// JSON data
const jsonBlob = new Blob(
  [JSON.stringify({ key: 'value' }, null, 2)], 
  { type: 'application/json' }
);

// Binary data from ArrayBuffer
const buffer = new Uint8Array([0x89, 0x50, 0x4E, 0x47]);
const binaryBlob = new Blob([buffer], { type: 'image/png' });

// Mixed content types
const htmlBlob = new Blob(
  ['<html><body>', '<h1>Title</h1>', '</body></html>'], 
  { type: 'text/html' }
);
```

#### From Canvas

```javascript
canvas.toBlob((blob) => {
  const url = URL.createObjectURL(blob);
  // Use url
  URL.revokeObjectURL(url);
}, 'image/png', 0.95);
```

#### From Fetch Response

```javascript
const response = await fetch('https://example.com/image.jpg');
const blob = await response.blob();
const url = URL.createObjectURL(blob);
```

#### From File Input

```javascript
input.addEventListener('change', (e) => {
  const file = e.target.files[0];
  const url = URL.createObjectURL(file);
  // File objects are Blob subclasses, work directly
});
```

### Memory Management

#### Manual Revocation

```javascript
const blob = new Blob(['data'], { type: 'text/plain' });
const url = URL.createObjectURL(blob);

// Use the URL
document.querySelector('img').src = url;

// Revoke when no longer needed
URL.revokeObjectURL(url);
```

Once revoked, the URL becomes invalid. Attempts to fetch it return network errors. [Inference] The browser may delay actual memory deallocation until all active references (e.g., loading images) complete.

#### Automatic Revocation on Document Unload

Blob URLs are automatically revoked when the document that created them unloads. They cannot be shared across origins or persisted beyond the browser session.

#### Memory Leak Prevention

```javascript
// BAD: Creates leak if revocation is forgotten
function displayImage(blob) {
  const url = URL.createObjectURL(blob);
  img.src = url;
  // Missing revocation
}

// GOOD: Revoke after load
function displayImage(blob) {
  const url = URL.createObjectURL(blob);
  img.src = url;
  img.onload = () => URL.revokeObjectURL(url);
}

// GOOD: Cleanup in finally block
async function processBlob(blob) {
  const url = URL.createObjectURL(blob);
  try {
    await someAsyncOperation(url);
  } finally {
    URL.revokeObjectURL(url);
  }
}
```

### Common Use Cases

#### Image Preview from File Upload

```javascript
const input = document.querySelector('input[type="file"]');
const preview = document.querySelector('img');

input.addEventListener('change', (e) => {
  const file = e.target.files[0];
  if (file && file.type.startsWith('image/')) {
    // Revoke previous URL to prevent leak
    if (preview.src.startsWith('blob:')) {
      URL.revokeObjectURL(preview.src);
    }
    
    const url = URL.createObjectURL(file);
    preview.src = url;
    
    // Revoke after image loads
    preview.onload = () => URL.revokeObjectURL(url);
  }
});
```

#### Download Generated Content

```javascript
function downloadJSON(data, filename) {
  const blob = new Blob([JSON.stringify(data, null, 2)], {
    type: 'application/json'
  });
  const url = URL.createObjectURL(blob);
  
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  document.body.appendChild(a);
  a.click();
  
  // Cleanup
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}
```

#### Video/Audio Playback

```javascript
const response = await fetch('/video.mp4');
const blob = await response.blob();
const url = URL.createObjectURL(blob);

const video = document.querySelector('video');
video.src = url;

// Revoke when video ends or component unmounts
video.onended = () => URL.revokeObjectURL(url);
```

#### PDF Display in iframe

```javascript
async function displayPDF(pdfBlob) {
  const url = URL.createObjectURL(pdfBlob);
  const iframe = document.querySelector('iframe');
  iframe.src = url;
  
  // Cleanup when iframe is removed
  return () => URL.revokeObjectURL(url);
}
```

#### Worker Script Creation

```javascript
const workerCode = `
  self.addEventListener('message', (e) => {
    self.postMessage(e.data * 2);
  });
`;

const blob = new Blob([workerCode], { type: 'application/javascript' });
const url = URL.createObjectURL(blob);
const worker = new Worker(url);

worker.postMessage(5);
worker.onmessage = (e) => console.log(e.data); // 10

// Cleanup
worker.terminate();
URL.revokeObjectURL(url);
```

### Blob URL vs Data URL

#### Size Considerations

```javascript
// Small data: Data URL is efficient (no separate object in memory)
const dataUrl = 'data:text/plain;base64,SGVsbG8gd29ybGQ=';
img.src = dataUrl;

// Large data: Blob URL is better (no Base64 encoding overhead)
const largeBlob = new Blob([largeArrayBuffer]);
const blobUrl = URL.createObjectURL(largeBlob);
img.src = blobUrl;
```

Data URLs are immediately usable and persist in the HTML/CSS, but they:

- Increase size by ~33% due to Base64 encoding
- Are embedded in the document (increase memory/transfer size)
- Cannot be revoked

Blob URLs:

- No encoding overhead
- Can be revoked to free memory
- Only valid within the creating context
- Require active memory management

#### Performance Comparison

For data under ~1KB, Data URLs may be more efficient. For larger data (images, videos, documents), Blob URLs avoid encoding costs and enable memory cleanup.

### Cross-Origin and Security

Blob URLs inherit the origin of the document that created them. They cannot be accessed cross-origin:

```javascript
// On https://example.com
const blob = new Blob(['secret'], { type: 'text/plain' });
const url = URL.createObjectURL(blob);

// This URL cannot be accessed from https://other-site.com
// Even if the string is passed to another origin
```

Blob URLs are not subject to CORS because they reference local memory, not network resources. However, blobs created from fetch responses carry the same-origin policy of their source.

### Browser Storage Limitations

Blob URLs reference in-memory data. The total size is limited by available browser memory, not localStorage or sessionStorage quotas. [Inference] Browsers typically allow several hundred megabytes to a few gigabytes depending on available system resources and 32-bit vs 64-bit architecture.

Creating extremely large blobs may trigger out-of-memory errors:

```javascript
try {
  // Attempting to create 2GB blob
  const hugeBlob = new Blob([new ArrayBuffer(2 * 1024 * 1024 * 1024)]);
  const url = URL.createObjectURL(hugeBlob);
} catch (e) {
  console.error('Out of memory'); // [Inference] May occur on 32-bit systems
}
```

### Integration with Modern APIs

#### Clipboard API

```javascript
async function copyImageToClipboard(blob) {
  await navigator.clipboard.write([
    new ClipboardItem({ [blob.type]: blob })
  ]);
}
```

#### FileSystem Access API

```javascript
async function saveBlob(blob, suggestedName) {
  const handle = await window.showSaveFilePicker({ suggestedName });
  const writable = await handle.createWritable();
  await writable.write(blob);
  await writable.close();
}
```

#### Cache API

```javascript
const cache = await caches.open('v1');
const response = new Response(blob, {
  headers: { 'Content-Type': blob.type }
});
await cache.put('/cached-resource', response);
```

### React/Framework Patterns

```javascript
// React hook for blob URL management
function useBlobUrl(blob) {
  const [url, setUrl] = useState(null);
  
  useEffect(() => {
    if (!blob) return;
    
    const objectUrl = URL.createObjectURL(blob);
    setUrl(objectUrl);
    
    return () => URL.revokeObjectURL(objectUrl);
  }, [blob]);
  
  return url;
}

// Usage
function ImagePreview({ file }) {
  const url = useBlobUrl(file);
  return url ? <img src={url} alt="Preview" /> : null;
}
```

### Debugging Blob URLs

Blob URLs can be examined in DevTools:

```javascript
const blob = new Blob(['test'], { type: 'text/plain' });
const url = URL.createObjectURL(blob);

// In Chrome DevTools, paste the blob URL in the console
// Then use fetch to inspect contents
fetch(url).then(r => r.text()).then(console.log);
```

Network tabs show blob URL loads as "(blob)" with no network activity since data is local.

### Edge Cases

#### Multiple References

```javascript
const blob = new Blob(['data']);
const url1 = URL.createObjectURL(blob);
const url2 = URL.createObjectURL(blob);

// url1 !== url2 (different URLs, same underlying blob)
// Must revoke both to free memory fully [Inference]
URL.revokeObjectURL(url1);
URL.revokeObjectURL(url2);
```

#### Revocation Timing

```javascript
const url = URL.createObjectURL(blob);
img.src = url;
URL.revokeObjectURL(url); // Immediate revocation

// [Inference] Image may still load if browser has buffered the blob
// but new elements cannot use this URL
```

#### Empty Blobs

```javascript
const emptyBlob = new Blob([]);
const url = URL.createObjectURL(emptyBlob);
// Valid URL, points to 0-byte blob
```

---

## Multiple File Uploads with Fetch API

### Handling Multiple File Inputs

When uploading multiple files using the fetch API, you work with `<input type="file" multiple>` elements. The `files` property of the input returns a `FileList` object containing all selected files.

```javascript
const input = document.querySelector('input[type="file"]');
const files = input.files; // FileList object

// Iterate through files
for (let i = 0; i < files.length; i++) {
  console.log(files[i].name, files[i].size);
}
```

### Using FormData for Multiple Files

FormData is the standard approach for sending multiple files. You can append multiple files to the same field name or use different field names.

#### Same Field Name (Array-style)

```javascript
const formData = new FormData();
const fileInput = document.querySelector('input[type="file"]');

// Append all files to the same field name
for (const file of fileInput.files) {
  formData.append('files[]', file);
}

fetch('/upload', {
  method: 'POST',
  body: formData
});
```

#### Different Field Names

```javascript
const formData = new FormData();

formData.append('document', files[0]);
formData.append('image', files[1]);
formData.append('attachment', files[2]);

fetch('/upload', {
  method: 'POST',
  body: formData
});
```

### Complete Upload Implementation

```javascript
async function uploadMultipleFiles(files) {
  const formData = new FormData();
  
  // Append each file
  Array.from(files).forEach((file, index) => {
    formData.append('files[]', file);
    // Or use indexed names: formData.append(`file_${index}`, file);
  });
  
  // Add additional metadata
  formData.append('userId', '12345');
  formData.append('uploadDate', new Date().toISOString());
  
  try {
    const response = await fetch('/api/upload', {
      method: 'POST',
      body: formData
      // Note: Do NOT set Content-Type header manually
      // Browser sets it automatically with boundary parameter
    });
    
    if (!response.ok) {
      throw new Error(`Upload failed: ${response.status}`);
    }
    
    const result = await response.json();
    return result;
  } catch (error) {
    console.error('Upload error:', error);
    throw error;
  }
}
```

### Progress Tracking with XMLHttpRequest

[Note: Fetch API does not natively support upload progress tracking. This requires XMLHttpRequest.]

```javascript
function uploadWithProgress(files, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    const formData = new FormData();
    
    Array.from(files).forEach(file => {
      formData.append('files[]', file);
    });
    
    // Track upload progress
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const percentComplete = (e.loaded / e.total) * 100;
        onProgress(percentComplete, e.loaded, e.total);
      }
    });
    
    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(JSON.parse(xhr.responseText));
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    });
    
    xhr.addEventListener('error', () => {
      reject(new Error('Network error'));
    });
    
    xhr.open('POST', '/api/upload');
    xhr.send(formData);
  });
}

// Usage
uploadWithProgress(files, (percent, loaded, total) => {
  console.log(`${percent.toFixed(2)}% (${loaded}/${total} bytes)`);
});
```

### File Validation Before Upload

```javascript
function validateFiles(files, options = {}) {
  const {
    maxSize = 10 * 1024 * 1024, // 10MB default
    maxFiles = 10,
    allowedTypes = ['image/jpeg', 'image/png', 'application/pdf']
  } = options;
  
  const errors = [];
  
  // Check file count
  if (files.length > maxFiles) {
    errors.push(`Maximum ${maxFiles} files allowed`);
  }
  
  // Validate each file
  Array.from(files).forEach((file, index) => {
    // Check file size
    if (file.size > maxSize) {
      errors.push(`File ${index + 1} (${file.name}) exceeds ${maxSize / 1024 / 1024}MB`);
    }
    
    // Check file type
    if (!allowedTypes.includes(file.type)) {
      errors.push(`File ${index + 1} (${file.name}) has invalid type: ${file.type}`);
    }
  });
  
  return {
    valid: errors.length === 0,
    errors
  };
}

// Usage
const validation = validateFiles(fileInput.files, {
  maxSize: 5 * 1024 * 1024, // 5MB
  maxFiles: 5,
  allowedTypes: ['image/jpeg', 'image/png']
});

if (validation.valid) {
  await uploadMultipleFiles(fileInput.files);
} else {
  console.error('Validation errors:', validation.errors);
}
```

### Concurrent vs Sequential Uploads

#### Sequential Uploads

```javascript
async function uploadSequentially(files) {
  const results = [];
  
  for (const file of files) {
    const formData = new FormData();
    formData.append('file', file);
    
    const response = await fetch('/api/upload', {
      method: 'POST',
      body: formData
    });
    
    results.push(await response.json());
  }
  
  return results;
}
```

#### Concurrent Uploads

```javascript
async function uploadConcurrently(files) {
  const uploadPromises = Array.from(files).map(file => {
    const formData = new FormData();
    formData.append('file', file);
    
    return fetch('/api/upload', {
      method: 'POST',
      body: formData
    }).then(res => res.json());
  });
  
  return Promise.all(uploadPromises);
}
```

#### Controlled Concurrency (Chunked)

```javascript
async function uploadWithConcurrencyLimit(files, limit = 3) {
  const results = [];
  const fileArray = Array.from(files);
  
  for (let i = 0; i < fileArray.length; i += limit) {
    const chunk = fileArray.slice(i, i + limit);
    const chunkResults = await Promise.all(
      chunk.map(file => {
        const formData = new FormData();
        formData.append('file', file);
        
        return fetch('/api/upload', {
          method: 'POST',
          body: formData
        }).then(res => res.json());
      })
    );
    
    results.push(...chunkResults);
  }
  
  return results;
}
```

### Handling Upload Errors and Retries

```javascript
async function uploadWithRetry(file, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      return await response.json();
    } catch (error) {
      lastError = error;
      console.warn(`Upload attempt ${attempt} failed:`, error);
      
      if (attempt < maxRetries) {
        // Exponential backoff
        await new Promise(resolve => 
          setTimeout(resolve, Math.pow(2, attempt) * 1000)
        );
      }
    }
  }
  
  throw new Error(`Upload failed after ${maxRetries} attempts: ${lastError.message}`);
}

async function uploadMultipleWithRetry(files) {
  const results = await Promise.allSettled(
    Array.from(files).map(file => uploadWithRetry(file))
  );
  
  const successful = results.filter(r => r.status === 'fulfilled');
  const failed = results.filter(r => r.status === 'rejected');
  
  return {
    successful: successful.map(r => r.value),
    failed: failed.map(r => r.reason)
  };
}
```

### Chunked File Uploads for Large Files

```javascript
async function uploadFileInChunks(file, chunkSize = 1024 * 1024) { // 1MB chunks
  const chunks = Math.ceil(file.size / chunkSize);
  const uploadId = Date.now().toString();
  
  for (let i = 0; i < chunks; i++) {
    const start = i * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('fileName', file.name);
    formData.append('uploadId', uploadId);
    formData.append('chunkIndex', i);
    formData.append('totalChunks', chunks);
    
    const response = await fetch('/api/upload/chunk', {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Chunk ${i} upload failed`);
    }
  }
  
  // Finalize upload
  const finalResponse = await fetch('/api/upload/finalize', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      uploadId,
      fileName: file.name,
      totalChunks: chunks
    })
  });
  
  return finalResponse.json();
}
```

### Resumable Uploads

```javascript
class ResumableUpload {
  constructor(file, endpoint) {
    this.file = file;
    this.endpoint = endpoint;
    this.chunkSize = 1024 * 1024; // 1MB
    this.uploadedChunks = new Set();
    this.uploadId = null;
  }
  
  async start() {
    // Initialize upload session
    const initResponse = await fetch(`${this.endpoint}/init`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        fileName: this.file.name,
        fileSize: this.file.size,
        totalChunks: Math.ceil(this.file.size / this.chunkSize)
      })
    });
    
    const { uploadId, uploadedChunks } = await initResponse.json();
    this.uploadId = uploadId;
    this.uploadedChunks = new Set(uploadedChunks || []);
    
    await this.uploadChunks();
  }
  
  async uploadChunks() {
    const totalChunks = Math.ceil(this.file.size / this.chunkSize);
    
    for (let i = 0; i < totalChunks; i++) {
      if (this.uploadedChunks.has(i)) {
        continue; // Skip already uploaded chunks
      }
      
      const start = i * this.chunkSize;
      const end = Math.min(start + this.chunkSize, this.file.size);
      const chunk = this.file.slice(start, end);
      
      const formData = new FormData();
      formData.append('chunk', chunk);
      formData.append('uploadId', this.uploadId);
      formData.append('chunkIndex', i);
      
      await fetch(`${this.endpoint}/chunk`, {
        method: 'POST',
        body: formData
      });
      
      this.uploadedChunks.add(i);
    }
    
    // Finalize
    await fetch(`${this.endpoint}/finalize`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ uploadId: this.uploadId })
    });
  }
}

// Usage
const uploader = new ResumableUpload(file, '/api/upload');
await uploader.start();
```

### Drag and Drop Multiple Files

```javascript
const dropZone = document.getElementById('dropZone');

dropZone.addEventListener('dragover', (e) => {
  e.preventDefault();
  dropZone.classList.add('drag-over');
});

dropZone.addEventListener('dragleave', () => {
  dropZone.classList.remove('drag-over');
});

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  dropZone.classList.remove('drag-over');
  
  const files = Array.from(e.dataTransfer.files);
  
  // Handle directories if needed
  const items = e.dataTransfer.items;
  if (items) {
    const allFiles = [];
    
    for (const item of items) {
      if (item.kind === 'file') {
        const entry = item.webkitGetAsEntry();
        if (entry.isDirectory) {
          const dirFiles = await readDirectory(entry);
          allFiles.push(...dirFiles);
        } else {
          allFiles.push(item.getAsFile());
        }
      }
    }
    
    await uploadMultipleFiles(allFiles);
  } else {
    await uploadMultipleFiles(files);
  }
});

async function readDirectory(directoryEntry) {
  const files = [];
  const reader = directoryEntry.createReader();
  
  return new Promise((resolve) => {
    const readEntries = () => {
      reader.readEntries(async (entries) => {
        if (entries.length === 0) {
          resolve(files);
          return;
        }
        
        for (const entry of entries) {
          if (entry.isFile) {
            const file = await new Promise(res => entry.file(res));
            files.push(file);
          } else if (entry.isDirectory) {
            const dirFiles = await readDirectory(entry);
            files.push(...dirFiles);
          }
        }
        
        readEntries(); // Continue reading
      });
    };
    
    readEntries();
  });
}
```

### Response Handling and Status Updates

```javascript
async function uploadWithStatusUpdates(files, onUpdate) {
  const totalFiles = files.length;
  let completed = 0;
  
  onUpdate({ stage: 'starting', completed: 0, total: totalFiles });
  
  const results = [];
  
  for (const file of files) {
    onUpdate({ 
      stage: 'uploading', 
      currentFile: file.name,
      completed, 
      total: totalFiles 
    });
    
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData
      });
      
      const result = await response.json();
      results.push({ file: file.name, success: true, data: result });
      
      completed++;
      onUpdate({ 
        stage: 'uploading', 
        completed, 
        total: totalFiles,
        lastCompleted: file.name
      });
    } catch (error) {
      results.push({ file: file.name, success: false, error: error.message });
      completed++;
    }
  }
  
  onUpdate({ stage: 'complete', completed: totalFiles, total: totalFiles, results });
  
  return results;
}

// Usage
await uploadWithStatusUpdates(files, (status) => {
  if (status.stage === 'uploading') {
    console.log(`Uploading ${status.currentFile} (${status.completed}/${status.total})`);
  } else if (status.stage === 'complete') {
    console.log('All uploads complete:', status.results);
  }
});
```

### Abort Multiple Uploads

```javascript
class MultiFileUploader {
  constructor() {
    this.controllers = new Map();
  }
  
  async uploadFile(file, fileId) {
    const controller = new AbortController();
    this.controllers.set(fileId, controller);
    
    const formData = new FormData();
    formData.append('file', file);
    
    try {
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData,
        signal: controller.signal
      });
      
      return await response.json();
    } finally {
      this.controllers.delete(fileId);
    }
  }
  
  async uploadAll(files) {
    const uploads = Array.from(files).map((file, index) => {
      const fileId = `file_${index}`;
      return this.uploadFile(file, fileId);
    });
    
    return Promise.allSettled(uploads);
  }
  
  abort(fileId) {
    const controller = this.controllers.get(fileId);
    if (controller) {
      controller.abort();
    }
  }
  
  abortAll() {
    this.controllers.forEach(controller => controller.abort());
    this.controllers.clear();
  }
}

// Usage
const uploader = new MultiFileUploader();

// Start uploads
const uploadPromise = uploader.uploadAll(files);

// Cancel all uploads
uploader.abortAll();
```

### Memory Management for Large File Sets

```javascript
async function uploadLargeFileSet(files) {
  // Process files in batches to avoid memory issues
  const BATCH_SIZE = 5;
  const results = [];
  
  for (let i = 0; i < files.length; i += BATCH_SIZE) {
    const batch = Array.from(files).slice(i, i + BATCH_SIZE);
    
    const batchResults = await Promise.all(
      batch.map(async (file) => {
        const formData = new FormData();
        formData.append('file', file);
        
        const response = await fetch('/api/upload', {
          method: 'POST',
          body: formData
        });
        
        return response.json();
      })
    );
    
    results.push(...batchResults);
    
    // Allow garbage collection between batches
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  return results;
}
```

---

## Drag-and-Drop Integration with Fetch API

### Overview of Integration Patterns

Drag-and-drop file uploads combine the HTML5 Drag and Drop API with the Fetch API to create seamless file transfer experiences. The integration involves capturing drag events, extracting file data from `DataTransfer` objects, and transmitting files via fetch requests with `FormData` or binary payloads.

### Event Handlers for Drag Operations

#### Essential Drag Events

Four primary events handle the drag-and-drop lifecycle:

- **`dragenter`**: Fired when dragged items enter a valid drop target
- **`dragover`**: Continuously fired while items are over the drop zone
- **`dragleave`**: Fired when items leave the drop zone boundary
- **`drop`**: Fired when items are released over the drop zone

#### Preventing Default Behaviors

```javascript
dropZone.addEventListener('dragover', (e) => {
  e.preventDefault();
  e.stopPropagation();
});

dropZone.addEventListener('drop', (e) => {
  e.preventDefault();
  e.stopPropagation();
});
```

Both `dragover` and `drop` require `preventDefault()` to override the browser's default behavior (typically opening files in a new tab). Without this, the drop operation will not function as intended.

### Extracting Files from DataTransfer

#### Accessing Files from Drop Events

```javascript
dropZone.addEventListener('drop', (e) => {
  e.preventDefault();
  
  const files = e.dataTransfer.files;
  
  if (files.length > 0) {
    handleFiles(files);
  }
});
```

The `e.dataTransfer.files` property returns a `FileList` object containing all dropped files. This is array-like but not a true array.

#### Handling DataTransfer Items

For more granular control, especially when dealing with directories or non-file data:

```javascript
dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  
  const items = e.dataTransfer.items;
  
  for (let i = 0; i < items.length; i++) {
    const item = items[i];
    
    if (item.kind === 'file') {
      const file = item.getAsFile();
      await uploadFile(file);
    }
  }
});
```

The `DataTransferItem` interface provides `kind` property ('file' or 'string') and methods like `getAsFile()` for more sophisticated handling.

### Upload Strategies with Fetch

#### Single File Upload with FormData

```javascript
async function uploadFile(file) {
  const formData = new FormData();
  formData.append('file', file);
  formData.append('filename', file.name);
  
  try {
    const response = await fetch('/upload', {
      method: 'POST',
      body: formData
      // Do not set Content-Type header - browser sets it automatically with boundary
    });
    
    if (!response.ok) {
      throw new Error(`Upload failed: ${response.status}`);
    }
    
    const result = await response.json();
    return result;
  } catch (error) {
    console.error('Upload error:', error);
    throw error;
  }
}
```

When using `FormData`, the browser automatically sets the `Content-Type` header to `multipart/form-data` with the appropriate boundary parameter.

#### Multiple File Upload

```javascript
async function uploadMultipleFiles(files) {
  const formData = new FormData();
  
  Array.from(files).forEach((file, index) => {
    formData.append('files[]', file);
    // Or use unique keys: formData.append(`file_${index}`, file);
  });
  
  const response = await fetch('/upload/multiple', {
    method: 'POST',
    body: formData
  });
  
  return response.json();
}
```

#### Binary Upload (Direct File Stream)

```javascript
async function uploadBinary(file) {
  const response = await fetch('/upload/binary', {
    method: 'POST',
    headers: {
      'Content-Type': file.type || 'application/octet-stream',
      'X-File-Name': encodeURIComponent(file.name),
      'X-File-Size': file.size.toString()
    },
    body: file // File objects are Blob-like and can be sent directly
  });
  
  return response.json();
}
```

This approach sends the raw file data without multipart encoding, useful for APIs that expect binary payloads.

### Progress Tracking Integration

#### Using Fetch with Progress Events

[Inference] Fetch API does not natively support upload progress tracking. The standard approach combines `XMLHttpRequest` with drag-and-drop for progress monitoring, or uses the Streams API for approximations.

#### XMLHttpRequest Alternative for Progress

```javascript
function uploadWithProgress(file, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    const formData = new FormData();
    formData.append('file', file);
    
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const percentage = (e.loaded / e.total) * 100;
        onProgress(percentage);
      }
    });
    
    xhr.addEventListener('load', () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(JSON.parse(xhr.responseText));
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    });
    
    xhr.addEventListener('error', () => reject(new Error('Upload failed')));
    xhr.addEventListener('abort', () => reject(new Error('Upload aborted')));
    
    xhr.open('POST', '/upload');
    xhr.send(formData);
  });
}

// Usage with drag-and-drop
dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = e.dataTransfer.files;
  
  for (const file of files) {
    await uploadWithProgress(file, (percent) => {
      console.log(`${file.name}: ${percent}%`);
    });
  }
});
```

#### Streams API for Chunked Upload

```javascript
async function uploadWithChunks(file, chunkSize = 1024 * 1024) {
  let offset = 0;
  
  while (offset < file.size) {
    const chunk = file.slice(offset, offset + chunkSize);
    
    await fetch('/upload/chunk', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/octet-stream',
        'X-Chunk-Index': Math.floor(offset / chunkSize).toString(),
        'X-Total-Size': file.size.toString(),
        'X-File-Name': encodeURIComponent(file.name)
      },
      body: chunk
    });
    
    offset += chunkSize;
    
    const progress = (offset / file.size) * 100;
    updateProgressBar(progress);
  }
  
  // Finalize upload
  await fetch('/upload/finalize', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ filename: file.name, totalSize: file.size })
  });
}
```

### Visual Feedback Patterns

#### Drag State Management

```javascript
const dropZone = document.getElementById('dropzone');
let dragCounter = 0;

dropZone.addEventListener('dragenter', (e) => {
  e.preventDefault();
  dragCounter++;
  dropZone.classList.add('drag-over');
});

dropZone.addEventListener('dragleave', (e) => {
  e.preventDefault();
  dragCounter--;
  
  if (dragCounter === 0) {
    dropZone.classList.remove('drag-over');
  }
});

dropZone.addEventListener('drop', (e) => {
  e.preventDefault();
  dragCounter = 0;
  dropZone.classList.remove('drag-over');
  
  const files = e.dataTransfer.files;
  handleFileDrop(files);
});
```

The `dragCounter` pattern handles nested elements within the drop zone that can trigger false `dragleave` events.

#### Drop Effect Indicators

```javascript
dropZone.addEventListener('dragover', (e) => {
  e.preventDefault();
  e.dataTransfer.dropEffect = 'copy'; // Shows copy cursor
  // Other values: 'move', 'link', 'none'
});
```

### File Validation Before Upload

#### Type and Size Validation

```javascript
function validateFile(file, options = {}) {
  const {
    maxSize = 10 * 1024 * 1024, // 10MB default
    allowedTypes = ['image/jpeg', 'image/png', 'application/pdf']
  } = options;
  
  const errors = [];
  
  if (file.size > maxSize) {
    errors.push(`File size ${(file.size / 1024 / 1024).toFixed(2)}MB exceeds limit of ${(maxSize / 1024 / 1024).toFixed(2)}MB`);
  }
  
  if (allowedTypes.length > 0 && !allowedTypes.includes(file.type)) {
    errors.push(`File type ${file.type} not allowed. Allowed: ${allowedTypes.join(', ')}`);
  }
  
  return {
    valid: errors.length === 0,
    errors
  };
}

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = Array.from(e.dataTransfer.files);
  
  for (const file of files) {
    const validation = validateFile(file, {
      maxSize: 5 * 1024 * 1024,
      allowedTypes: ['image/jpeg', 'image/png']
    });
    
    if (validation.valid) {
      await uploadFile(file);
    } else {
      console.error(`Validation failed for ${file.name}:`, validation.errors);
    }
  }
});
```

#### MIME Type Verification

[Inference] Client-side MIME type checking via `file.type` relies on file extensions and can be spoofed. Server-side verification by reading file headers is necessary for security-critical applications.

```javascript
async function verifyFileType(file) {
  return new Promise((resolve) => {
    const reader = new FileReader();
    
    reader.onload = (e) => {
      const arr = new Uint8Array(e.target.result).subarray(0, 4);
      let header = '';
      for (let i = 0; i < arr.length; i++) {
        header += arr[i].toString(16);
      }
      
      // Common file signatures (magic numbers)
      const signatures = {
        '89504e47': 'image/png',
        'ffd8ffe0': 'image/jpeg',
        'ffd8ffe1': 'image/jpeg',
        '25504446': 'application/pdf'
      };
      
      const detectedType = signatures[header.toLowerCase()];
      resolve({
        declared: file.type,
        detected: detectedType,
        matches: file.type === detectedType
      });
    };
    
    reader.readAsArrayBuffer(file.slice(0, 4));
  });
}
```

### Concurrent Upload Management

#### Parallel Uploads with Concurrency Limit

```javascript
async function uploadFilesWithLimit(files, concurrency = 3) {
  const results = [];
  const executing = [];
  
  for (const file of files) {
    const promise = uploadFile(file).then(result => {
      executing.splice(executing.indexOf(promise), 1);
      return result;
    });
    
    results.push(promise);
    executing.push(promise);
    
    if (executing.length >= concurrency) {
      await Promise.race(executing);
    }
  }
  
  return Promise.all(results);
}

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = Array.from(e.dataTransfer.files);
  
  try {
    const uploadResults = await uploadFilesWithLimit(files, 3);
    console.log('All uploads completed:', uploadResults);
  } catch (error) {
    console.error('Upload batch failed:', error);
  }
});
```

#### Queue-Based Upload System

```javascript
class UploadQueue {
  constructor(concurrency = 2) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async add(file) {
    return new Promise((resolve, reject) => {
      this.queue.push({ file, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.active >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { file, resolve, reject } = this.queue.shift();
    
    try {
      const result = await uploadFile(file);
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }
}

const uploadQueue = new UploadQueue(3);

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = Array.from(e.dataTransfer.files);
  
  const uploads = files.map(file => uploadQueue.add(file));
  await Promise.allSettled(uploads);
});
```

### Error Handling and Retry Logic

#### Exponential Backoff Retry

```javascript
async function uploadWithRetry(file, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await fetch('/upload', {
        method: 'POST',
        body: createFormData(file)
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return await response.json();
      
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries - 1) {
        const delay = Math.pow(2, attempt) * 1000; // 1s, 2s, 4s
        console.log(`Upload attempt ${attempt + 1} failed, retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw new Error(`Upload failed after ${maxRetries} attempts: ${lastError.message}`);
}
```

#### Network Error Detection

```javascript
async function uploadWithNetworkCheck(file) {
  try {
    const response = await fetch('/upload', {
      method: 'POST',
      body: createFormData(file),
      signal: AbortSignal.timeout(30000) // 30 second timeout
    });
    
    return await response.json();
    
  } catch (error) {
    if (error.name === 'AbortError' || error.name === 'TimeoutError') {
      throw new Error('Upload timeout - check your connection');
    }
    
    if (!navigator.onLine) {
      throw new Error('No internet connection detected');
    }
    
    if (error instanceof TypeError && error.message.includes('fetch')) {
      throw new Error('Network request failed - unable to reach server');
    }
    
    throw error;
  }
}
```

### Drag-and-Drop from External Sources

#### Handling URLs and Text

```javascript
dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  
  // Check for URL data
  const url = e.dataTransfer.getData('text/uri-list');
  if (url) {
    await handleUrlDrop(url);
    return;
  }
  
  // Check for plain text
  const text = e.dataTransfer.getData('text/plain');
  if (text) {
    await handleTextDrop(text);
    return;
  }
  
  // Handle files
  const files = e.dataTransfer.files;
  if (files.length > 0) {
    await handleFileDrop(files);
  }
});

async function handleUrlDrop(url) {
  // Fetch the URL content and upload
  const response = await fetch(url);
  const blob = await response.blob();
  
  // Extract filename from URL
  const filename = url.split('/').pop() || 'download';
  const file = new File([blob], filename, { type: blob.type });
  
  await uploadFile(file);
}
```

#### Downloading Remote Images

```javascript
async function downloadAndUploadImage(imageUrl) {
  try {
    const response = await fetch(imageUrl, {
      mode: 'cors'
    });
    
    if (!response.ok) {
      throw new Error(`Failed to fetch image: ${response.status}`);
    }
    
    const blob = await response.blob();
    const filename = imageUrl.split('/').pop().split('?')[0] || 'image.jpg';
    const file = new File([blob], filename, { type: blob.type });
    
    return await uploadFile(file);
    
  } catch (error) {
    console.error('Image download failed:', error);
    throw error;
  }
}
```

### Directory Drop Handling

#### Recursive Directory Traversal

```javascript
async function handleDirectoryDrop(item) {
  const files = [];
  
  async function traverseDirectory(directoryReader, path = '') {
    const entries = await new Promise((resolve, reject) => {
      directoryReader.readEntries(resolve, reject);
    });
    
    for (const entry of entries) {
      if (entry.isFile) {
        const file = await new Promise((resolve, reject) => {
          entry.file(resolve, reject);
        });
        
        // Preserve directory structure
        Object.defineProperty(file, 'webkitRelativePath', {
          value: path + file.name
        });
        
        files.push(file);
      } else if (entry.isDirectory) {
        const reader = entry.createReader();
        await traverseDirectory(reader, path + entry.name + '/');
      }
    }
    
    // Continue reading if there are more entries
    if (entries.length > 0) {
      await traverseDirectory(directoryReader, path);
    }
  }
  
  if (item.isDirectory) {
    const reader = item.createReader();
    await traverseDirectory(reader);
  }
  
  return files;
}

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const items = Array.from(e.dataTransfer.items);
  const allFiles = [];
  
  for (const item of items) {
    if (item.kind === 'file') {
      const entry = item.webkitGetAsEntry();
      
      if (entry.isDirectory) {
        const dirFiles = await handleDirectoryDrop(entry);
        allFiles.push(...dirFiles);
      } else {
        allFiles.push(item.getAsFile());
      }
    }
  }
  
  await uploadMultipleFiles(allFiles);
});
```

### Abort and Cancellation

#### AbortController Integration

```javascript
class UploadManager {
  constructor() {
    this.controllers = new Map();
  }
  
  async upload(file) {
    const controller = new AbortController();
    const uploadId = `${file.name}-${Date.now()}`;
    
    this.controllers.set(uploadId, controller);
    
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      const response = await fetch('/upload', {
        method: 'POST',
        body: formData,
        signal: controller.signal
      });
      
      if (!response.ok) {
        throw new Error(`Upload failed: ${response.status}`);
      }
      
      return await response.json();
      
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log(`Upload cancelled: ${file.name}`);
        return null;
      }
      throw error;
      
    } finally {
      this.controllers.delete(uploadId);
    }
  }
  
  cancel(uploadId) {
    const controller = this.controllers.get(uploadId);
    if (controller) {
      controller.abort();
    }
  }
  
  cancelAll() {
    this.controllers.forEach(controller => controller.abort());
    this.controllers.clear();
  }
}

const uploadManager = new UploadManager();

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = Array.from(e.dataTransfer.files);
  
  for (const file of files) {
    uploadManager.upload(file);
  }
});

cancelButton.addEventListener('click', () => {
  uploadManager.cancelAll();
});
```

### Security Considerations

#### Content Security Policy Headers

```javascript
async function uploadWithCSRF(file) {
  // Retrieve CSRF token from meta tag or cookie
  const csrfToken = document.querySelector('meta[name="csrf-token"]')?.content;
  
  const formData = new FormData();
  formData.append('file', file);
  
  const response = await fetch('/upload', {
    method: 'POST',
    headers: {
      'X-CSRF-Token': csrfToken
    },
    body: formData,
    credentials: 'same-origin' // Include cookies
  });
  
  return response.json();
}
```

#### File Name Sanitization

```javascript
function sanitizeFilename(filename) {
  // Remove path traversal attempts
  filename = filename.replace(/^.*[\\\/]/, '');
  
  // Remove potentially dangerous characters
  filename = filename.replace(/[^a-zA-Z0-9._-]/g, '_');
  
  // Limit length
  const maxLength = 255;
  if (filename.length > maxLength) {
    const ext = filename.split('.').pop();
    const name = filename.substring(0, maxLength - ext.length - 1);
    filename = `${name}.${ext}`;
  }
  
  return filename;
}

async function uploadSafeFile(file) {
  const safeFilename = sanitizeFilename(file.name);
  const safeFile = new File([file], safeFilename, { type: file.type });
  
  return uploadFile(safeFile);
}
```

### Performance Optimization

#### File Reading Optimization

```javascript
async function optimizeImageBeforeUpload(file, maxWidth = 1920, maxHeight = 1080, quality = 0.85) {
  if (!file.type.startsWith('image/')) {
    return file;
  }
  
  return new Promise((resolve) => {
    const img = new Image();
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    img.onload = () => {
      let { width, height } = img;
      
      if (width > maxWidth || height > maxHeight) {
        const ratio = Math.min(maxWidth / width, maxHeight / height);
        width *= ratio;
        height *= ratio;
      }
      
      canvas.width = width;
      canvas.height = height;
      ctx.drawImage(img, 0, 0, width, height);
      
      canvas.toBlob(
        (blob) => {
          const optimizedFile = new File([blob], file.name, {
            type: 'image/jpeg',
            lastModified: Date.now()
          });
          resolve(optimizedFile);
        },
        'image/jpeg',
        quality
      );
    };
    
    img.src = URL.createObjectURL(file);
  });
}

dropZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  const files = Array.from(e.dataTransfer.files);
  
  for (const file of files) {
    const optimized = await optimizeImageBeforeUpload(file);
    await uploadFile(optimized);
  }
});
```

#### Memory Management for Large Files

```javascript
async function uploadLargeFile(file) {
  const chunkSize = 5 * 1024 * 1024; // 5MB chunks
  const chunks = Math.ceil(file.size / chunkSize);
  
  for (let i = 0; i < chunks; i++) {
    const start = i * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', i.toString());
    formData.append('totalChunks', chunks.toString());
    formData.append('filename', file.name);
    
    await fetch('/upload/chunk', {
      method: 'POST',
      body: formData
    });
    
    // Chunk goes out of scope and can be garbage collected
  }
  
  // Finalize
  await fetch('/upload/complete', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ filename: file.name, totalChunks: chunks })
  });
}
```

### Authentication and Authorization

#### Token-Based Upload

```javascript
async function uploadWithAuth(file, accessToken) {
  const formData = new FormData();
  formData.append('file', file);
  
  const response = await fetch('/upload', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${accessToken}`
    },
    body: formData
  });
  
  if (response.status === 401) {
    // Token expired, refresh and retry
    const newToken = await refreshAccessToken();
    return uploadWithAuth(file, newToken);
  }
  
  return response.json();
}

async function refreshAccessToken() {
  const response = await fetch('/auth/refresh', {
    method: 'POST',
    credentials: 'include'
  });
  
  const data = await response.json();
  return data.accessToken;
}
```

#### Pre-signed URL Upload

```javascript
async function uploadToPresignedUrl(file) {
  // Get pre-signed URL from your server
  const urlResponse = await fetch('/upload/presigned-url', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      filename: file.name,
      contentType: file.type,
      size: file.size
    })
  });
  
  const { uploadUrl, key } = await urlResponse.json();
  
  // Upload directly to storage (e.g., S3)
  const uploadResponse = await fetch(uploadUrl, {
    method: 'PUT',
    headers: {
      'Content-Type': file.type
    },
    body: file
  });
  
  if (!uploadResponse.ok) {
    throw new Error(`Upload to storage failed: ${uploadResponse.status}`);
  }
  
  // Confirm upload with your server
  await fetch('/upload/confirm', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ key, filename: file.name })
  });
  
  return { key, filename: file.name };
}
```

### Cross-Browser Compatibility

#### Feature Detection

```javascript
function checkDragDropSupport() {
  const div = document.createElement('div');
  const support = {
    dragAndDrop: ('draggable' in div) || ('ondragstart' in div && 'ondrop' in div),
    fileAPI: 'FileReader' in window,
    formData: 'FormData' in window,
    fetch: 'fetch' in window
  };
  
  return support;
}

const support = checkDragDropSupport();

if (!support.dragAndDrop) {
  // Fallback to input file element
  showFileInputFallback();
} else {
  initializeDragDrop();
}
```

#### Polyfill Strategy

```javascript
// Check for fetch support
if (!window.fetch) {
  // Load fetch polyfill
  const script = document.createElement('script');
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/fetch/3.6.2/fetch.min.js';
  document.head.appendChild(script);
}

// Fallback for older browsers
function uploadWithXHR(file) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    const formData = new FormData();
    formData.append('file', file);
    
    xhr.onload = () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        resolve(JSON.parse(xhr.responseText));
      } else {
        reject(new Error(`Upload failed: ${xhr.status}`));
      }
    };
    
    xhr.onerror = () => reject(new Error('Network error'));
    xhr.open('POST', '/upload');
    xhr.send(formData);
  });
}

// Use appropriate method
const uploadMethod = window.fetch ? uploadFile : uploadWithXHR;
```

### Testing Strategies

#### Mock File Creation for Testing

```javascript
function createMockFile(name, size, type) {
  const content = new Array(size).fill('a').join('');
  const blob = new Blob([content], { type });
  return new File([blob], name, { type, lastModified: Date.now() });
}

// Simulate drop event
function simulateFileDrop(element, files) {
  const dataTransfer = new DataTransfer();
  
  files.forEach(file => {
    dataTransfer.items.add(file);
  });
  
  const dropEvent = new DragEvent('drop', {
    bubbles: true,
    cancelable: true,
    dataTransfer
  });
  
  element.dispatchEvent(dropEvent);
}

// Test usage
const testFile = createMockFile('test.jpg', 1024 * 1024, 'image/jpeg');
simulateFileDrop(dropZone, [testFile]);
```

#### Integration Test Example

```javascript
async function testDragDropUpload() {
  const testFile = createMockFile('test-image.png', 2048, 'image/png');
  
  // Mock fetch
  global.fetch = jest.fn(() =>
    Promise.resolve({
      ok: true,
      json: () => Promise.resolve({ id: '123', url: '/files/123' })
    })
  );
  
  // Simulate drop
  const files = [testFile];
  const result = await uploadMultipleFiles(files);
  
  expect(fetch).toHaveBeenCalledWith('/upload/multiple', {
    method: 'POST',
    body: expect.any(FormData)
  });
  
  expect(result).toHaveProperty('id');
}
```

---

## File Validation with Fetch API

### Client-Side Validation Before Upload

#### MIME Type Validation

Validate file types using the `type` property from File objects before sending via fetch:

```javascript
const allowedTypes = ['image/jpeg', 'image/png', 'application/pdf'];
const file = input.files[0];

if (!allowedTypes.includes(file.type)) {
  throw new Error(`Invalid file type: ${file.type}`);
}
```

**Critical limitation**: MIME types are user-controllable and should never be trusted as the sole validation mechanism. Browsers determine MIME types from file extensions, which can be spoofed.

#### Extension-Based Validation

```javascript
const allowedExtensions = ['.jpg', '.jpeg', '.png', '.pdf'];
const fileName = file.name.toLowerCase();
const hasValidExtension = allowedExtensions.some(ext => fileName.endsWith(ext));

if (!hasValidExtension) {
  throw new Error('Invalid file extension');
}
```

Combine with MIME type checking for defense-in-depth:

```javascript
function validateFileType(file, config) {
  const ext = file.name.toLowerCase().match(/\.[^.]+$/)?.[0];
  const expectedMime = config.extensionToMime[ext];
  
  return ext && 
         config.allowedExtensions.includes(ext) &&
         file.type === expectedMime;
}
```

#### File Size Validation

```javascript
const maxSize = 5 * 1024 * 1024; // 5MB
if (file.size > maxSize) {
  throw new Error(`File too large: ${(file.size / 1024 / 1024).toFixed(2)}MB`);
}

if (file.size === 0) {
  throw new Error('Empty file not allowed');
}
```

### Magic Number (File Signature) Validation

Validate actual file content by reading magic bytes—the most reliable client-side validation method:

```javascript
async function validateFileSignature(file, expectedSignatures) {
  const buffer = await file.slice(0, 8).arrayBuffer();
  const bytes = new Uint8Array(buffer);
  const signature = Array.from(bytes)
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  return expectedSignatures.some(sig => 
    signature.toLowerCase().startsWith(sig.toLowerCase())
  );
}

// Usage
const jpegSignatures = ['ffd8ffe0', 'ffd8ffe1', 'ffd8ffe2'];
const pngSignature = ['89504e47'];

const isValidJpeg = await validateFileSignature(file, jpegSignatures);
```

Common file signatures:

- JPEG: `FF D8 FF`
- PNG: `89 50 4E 47 0D 0A 1A 0A`
- PDF: `25 50 44 46` (%PDF)
- GIF: `47 49 46 38` (GIF8)
- ZIP: `50 4B 03 04` or `50 4B 05 06`

### Dimension Validation for Images

```javascript
async function validateImageDimensions(file, maxWidth, maxHeight) {
  return new Promise((resolve, reject) => {
    const img = new Image();
    const url = URL.createObjectURL(file);
    
    img.onload = () => {
      URL.revokeObjectURL(url);
      if (img.width > maxWidth || img.height > maxHeight) {
        reject(new Error(`Image dimensions ${img.width}x${img.height} exceed limit`));
      } else {
        resolve({ width: img.width, height: img.height });
      }
    };
    
    img.onerror = () => {
      URL.revokeObjectURL(url);
      reject(new Error('Failed to load image'));
    };
    
    img.src = url;
  });
}
```

Validate aspect ratio:

```javascript
function validateAspectRatio(width, height, expectedRatio, tolerance = 0.01) {
  const actualRatio = width / height;
  return Math.abs(actualRatio - expectedRatio) <= tolerance;
}
```

### Content Validation

#### Image Content Analysis

Detect corrupt images by attempting to decode:

```javascript
async function validateImageIntegrity(file) {
  const bitmap = await createImageBitmap(file);
  bitmap.close();
  return true; // Will throw if corrupt
}
```

#### Text File Content Validation

```javascript
async function validateTextContent(file, maxLines, maxLineLength) {
  const text = await file.text();
  const lines = text.split('\n');
  
  if (lines.length > maxLines) {
    throw new Error(`Too many lines: ${lines.length}`);
  }
  
  const longLine = lines.find(line => line.length > maxLineLength);
  if (longLine) {
    throw new Error(`Line exceeds maximum length`);
  }
  
  return text;
}
```

Validate character encoding:

```javascript
async function validateUTF8(file) {
  const buffer = await file.arrayBuffer();
  const decoder = new TextDecoder('utf-8', { fatal: true });
  
  try {
    decoder.decode(buffer);
    return true;
  } catch (e) {
    throw new Error('Invalid UTF-8 encoding');
  }
}
```

### Sending Validated Files with Fetch

#### FormData Approach

```javascript
async function uploadValidatedFile(file, endpoint) {
  // Perform all validations
  await validateFileSignature(file, expectedSignatures);
  if (file.size > maxSize) throw new Error('File too large');
  
  const formData = new FormData();
  formData.append('file', file);
  formData.append('originalName', file.name);
  formData.append('clientValidated', 'true');
  
  const response = await fetch(endpoint, {
    method: 'POST',
    body: formData
    // Note: Don't set Content-Type header; browser sets it with boundary
  });
  
  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || 'Upload failed');
  }
  
  return response.json();
}
```

#### Multiple File Upload with Validation

```javascript
async function uploadMultipleFiles(files, endpoint) {
  const validationResults = await Promise.allSettled(
    files.map(file => validateFile(file))
  );
  
  const validFiles = validationResults
    .map((result, index) => result.status === 'fulfilled' ? files[index] : null)
    .filter(Boolean);
  
  const failedFiles = validationResults
    .map((result, index) => result.status === 'rejected' ? {
      file: files[index].name,
      error: result.reason.message
    } : null)
    .filter(Boolean);
  
  if (validFiles.length === 0) {
    throw new Error('No valid files to upload');
  }
  
  const formData = new FormData();
  validFiles.forEach((file, index) => {
    formData.append(`files[${index}]`, file);
  });
  
  const response = await fetch(endpoint, {
    method: 'POST',
    body: formData
  });
  
  return {
    uploaded: await response.json(),
    failed: failedFiles
  };
}
```

### Server Response Validation

#### Handling Server-Side Validation Errors

```javascript
async function handleUploadWithServerValidation(file, endpoint) {
  const formData = new FormData();
  formData.append('file', file);
  
  const response = await fetch(endpoint, {
    method: 'POST',
    body: formData
  });
  
  const data = await response.json();
  
  if (!response.ok) {
    // Parse structured validation errors
    if (data.validationErrors) {
      const errors = data.validationErrors.map(err => 
        `${err.field}: ${err.message}`
      ).join(', ');
      throw new Error(`Validation failed: ${errors}`);
    }
    throw new Error(data.message || 'Upload failed');
  }
  
  // Verify server response contains expected fields
  if (!data.fileId || !data.url) {
    throw new Error('Invalid server response');
  }
  
  return data;
}
```

#### Validating File URL from Server

```javascript
async function validateUploadedFile(fileUrl, expectedMime) {
  const response = await fetch(fileUrl, { method: 'HEAD' });
  
  const contentType = response.headers.get('content-type');
  const contentLength = parseInt(response.headers.get('content-length'));
  
  if (!contentType.startsWith(expectedMime)) {
    throw new Error(`Unexpected content type: ${contentType}`);
  }
  
  if (contentLength === 0) {
    throw new Error('Uploaded file is empty');
  }
  
  return { contentType, contentLength };
}
```

### Chunked Upload with Validation

For large files, validate chunks before and during upload:

```javascript
async function uploadFileInChunks(file, endpoint, chunkSize = 1024 * 1024) {
  // Initial validation
  await validateFile(file);
  
  const totalChunks = Math.ceil(file.size / chunkSize);
  const fileId = crypto.randomUUID();
  
  for (let chunkIndex = 0; chunkIndex < totalChunks; chunkIndex++) {
    const start = chunkIndex * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    
    // Validate chunk
    if (chunk.size === 0) {
      throw new Error(`Invalid chunk at index ${chunkIndex}`);
    }
    
    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', chunkIndex);
    formData.append('totalChunks', totalChunks);
    formData.append('fileId', fileId);
    formData.append('fileName', file.name);
    
    const response = await fetch(endpoint, {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Chunk ${chunkIndex} upload failed`);
    }
    
    const result = await response.json();
    
    // Validate server received correct chunk
    if (result.chunkIndex !== chunkIndex) {
      throw new Error('Chunk index mismatch');
    }
  }
  
  // Finalize upload
  return await fetch(`${endpoint}/finalize`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ fileId, fileName: file.name })
  }).then(r => r.json());
}
```

### Checksum Validation

Validate file integrity using checksums:

```javascript
async function calculateChecksum(file, algorithm = 'SHA-256') {
  const buffer = await file.arrayBuffer();
  const hashBuffer = await crypto.subtle.digest(algorithm, buffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
}

async function uploadWithChecksum(file, endpoint) {
  const checksum = await calculateChecksum(file);
  
  const formData = new FormData();
  formData.append('file', file);
  formData.append('checksum', checksum);
  formData.append('algorithm', 'SHA-256');
  
  const response = await fetch(endpoint, {
    method: 'POST',
    body: formData
  });
  
  const data = await response.json();
  
  // Verify server calculated same checksum
  if (data.checksum !== checksum) {
    throw new Error('Checksum mismatch - file may be corrupted');
  }
  
  return data;
}
```

### Virus Scanning Integration

Handle virus scanning during upload:

```javascript
async function uploadWithVirusScan(file, endpoint) {
  const formData = new FormData();
  formData.append('file', file);
  
  const response = await fetch(endpoint, {
    method: 'POST',
    body: formData
  });
  
  const data = await response.json();
  
  if (data.scanStatus === 'infected') {
    throw new Error(`File infected: ${data.threatName}`);
  }
  
  if (data.scanStatus === 'pending') {
    // Poll for scan results
    return await pollScanResults(data.scanId);
  }
  
  return data;
}

async function pollScanResults(scanId, maxAttempts = 30) {
  for (let i = 0; i < maxAttempts; i++) {
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    const response = await fetch(`/api/scan-status/${scanId}`);
    const data = await response.json();
    
    if (data.status === 'clean') return data;
    if (data.status === 'infected') throw new Error('File infected');
  }
  
  throw new Error('Scan timeout');
}
```

### Comprehensive Validation Pipeline

```javascript
class FileValidator {
  constructor(config) {
    this.config = {
      maxSize: config.maxSize || 10 * 1024 * 1024,
      allowedTypes: config.allowedTypes || [],
      allowedExtensions: config.allowedExtensions || [],
      magicNumbers: config.magicNumbers || {},
      checkDimensions: config.checkDimensions || false,
      maxWidth: config.maxWidth,
      maxHeight: config.maxHeight,
      calculateChecksum: config.calculateChecksum || false
    };
  }
  
  async validate(file) {
    const errors = [];
    
    // Size validation
    if (file.size > this.config.maxSize) {
      errors.push(`File size ${file.size} exceeds maximum ${this.config.maxSize}`);
    }
    
    if (file.size === 0) {
      errors.push('File is empty');
    }
    
    // Type validation
    if (this.config.allowedTypes.length > 0 && 
        !this.config.allowedTypes.includes(file.type)) {
      errors.push(`File type ${file.type} not allowed`);
    }
    
    // Extension validation
    const ext = file.name.toLowerCase().match(/\.[^.]+$/)?.[0];
    if (this.config.allowedExtensions.length > 0 && 
        !this.config.allowedExtensions.includes(ext)) {
      errors.push(`File extension ${ext} not allowed`);
    }
    
    // Magic number validation
    if (this.config.magicNumbers[ext]) {
      try {
        const isValid = await validateFileSignature(
          file, 
          this.config.magicNumbers[ext]
        );
        if (!isValid) {
          errors.push('File signature does not match extension');
        }
      } catch (e) {
        errors.push(`Signature validation failed: ${e.message}`);
      }
    }
    
    // Image dimension validation
    if (this.config.checkDimensions && file.type.startsWith('image/')) {
      try {
        await validateImageDimensions(
          file, 
          this.config.maxWidth, 
          this.config.maxHeight
        );
      } catch (e) {
        errors.push(e.message);
      }
    }
    
    if (errors.length > 0) {
      throw new Error(`Validation failed: ${errors.join('; ')}`);
    }
    
    // Calculate checksum if needed
    let checksum;
    if (this.config.calculateChecksum) {
      checksum = await calculateChecksum(file);
    }
    
    return {
      valid: true,
      file,
      checksum,
      metadata: {
        name: file.name,
        size: file.size,
        type: file.type,
        lastModified: file.lastModified
      }
    };
  }
  
  async validateAndUpload(file, endpoint) {
    const result = await this.validate(file);
    
    const formData = new FormData();
    formData.append('file', file);
    
    if (result.checksum) {
      formData.append('checksum', result.checksum);
    }
    
    const response = await fetch(endpoint, {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.message || 'Upload failed');
    }
    
    return response.json();
  }
}

// Usage
const validator = new FileValidator({
  maxSize: 5 * 1024 * 1024,
  allowedTypes: ['image/jpeg', 'image/png'],
  allowedExtensions: ['.jpg', '.jpeg', '.png'],
  magicNumbers: {
    '.jpg': ['ffd8ffe0', 'ffd8ffe1'],
    '.jpeg': ['ffd8ffe0', 'ffd8ffe1'],
    '.png': ['89504e47']
  },
  checkDimensions: true,
  maxWidth: 4096,
  maxHeight: 4096,
  calculateChecksum: true
});

try {
  const result = await validator.validateAndUpload(file, '/api/upload');
  console.log('Upload successful:', result);
} catch (error) {
  console.error('Validation/upload failed:', error.message);
}
```

### Error Recovery and Retry Logic

```javascript
async function uploadWithRetry(file, endpoint, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      // Revalidate before each attempt
      await validateFile(file);
      
      const formData = new FormData();
      formData.append('file', file);
      formData.append('attempt', attempt + 1);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 30000);
      
      const response = await fetch(endpoint, {
        method: 'POST',
        body: formData,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        const error = await response.json();
        
        // Don't retry validation errors
        if (response.status === 400 || response.status === 413) {
          throw new Error(error.message);
        }
        
        throw new Error(`HTTP ${response.status}: ${error.message}`);
      }
      
      return await response.json();
      
    } catch (error) {
      lastError = error;
      
      if (error.name === 'AbortError') {
        console.warn(`Upload attempt ${attempt + 1} timed out`);
      } else if (!error.message.includes('Validation')) {
        console.warn(`Upload attempt ${attempt + 1} failed:`, error.message);
      } else {
        // Don't retry validation errors
        throw error;
      }
      
      if (attempt < maxRetries - 1) {
        const delay = Math.pow(2, attempt) * 1000; // Exponential backoff
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw new Error(`Upload failed after ${maxRetries} attempts: ${lastError.message}`);
}
```

### Security Considerations

Never trust client-side validation alone. All validation must be repeated server-side because:

- JavaScript can be disabled or modified
- Requests can be crafted outside the browser
- File contents can be manipulated after client validation
- MIME types and extensions are trivially spoofed

Additional security measures:

```javascript
// Sanitize filename before upload
function sanitizeFileName(fileName) {
  return fileName
    .replace(/[^a-zA-Z0-9.-]/g, '_')
    .replace(/\.{2,}/g, '.')
    .substring(0, 255);
}

// Validate Content-Disposition header in response
async function validateDownloadResponse(response, expectedFileName) {
  const contentDisposition = response.headers.get('content-disposition');
  
  if (!contentDisposition || !contentDisposition.includes('attachment')) {
    throw new Error('Invalid content disposition');
  }
  
  // Prevent path traversal in filename
  const filenameMatch = contentDisposition.match(/filename="?([^"]+)"?/);
  if (filenameMatch) {
    const filename = filenameMatch[1];
    if (filename.includes('..') || filename.includes('/') || filename.includes('\\')) {
      throw new Error('Invalid filename in response');
    }
  }
  
  return response;
}
```

---

# Caching Strategies

## Cache API Integration with Fetch API

### Understanding the Cache Interface

The Cache API provides a storage mechanism for Request/Response object pairs that are cached in long-lived memory. Each Cache object represents a named cache that persists across browser sessions. The CacheStorage interface manages multiple Cache instances, accessible via `window.caches` or `self.caches` in service workers.

```javascript
// Accessing the cache storage
const cache = await caches.open('my-cache-v1');
```

### Core Cache Operations with Fetch

#### Storing Fetch Responses

The `cache.put()` method stores a Request/Response pair explicitly, while `cache.add()` and `cache.addAll()` fetch and store in a single operation.

```javascript
// Explicit put with fetch
const response = await fetch('/api/data');
const cache = await caches.open('api-cache');
await cache.put('/api/data', response.clone());

// Direct add (fetches internally)
await cache.add('/api/data');

// Batch adding
await cache.addAll([
  '/api/users',
  '/api/posts',
  '/assets/style.css'
]);
```

**Critical consideration**: Response objects can only be read once due to their body being a ReadableStream. Always use `response.clone()` when caching a response you also need to return or process.

### Reading from Cache

#### Basic Cache Retrieval

```javascript
const cache = await caches.open('my-cache-v1');
const cachedResponse = await cache.match('/api/data');

if (cachedResponse) {
  const data = await cachedResponse.json();
  // Use cached data
}
```

#### Cache Matching with Options

The `match()` method accepts an options object for fine-grained control:

```javascript
const response = await cache.match(request, {
  ignoreSearch: true,    // Ignore query parameters
  ignoreMethod: false,   // Respect HTTP method
  ignoreVary: false      // Respect Vary header
});
```

### Cache-First Strategy Pattern

This strategy checks the cache before making network requests, falling back to fetch when necessary:

```javascript
async function cacheFirst(request) {
  const cache = await caches.open('my-cache-v1');
  const cachedResponse = await cache.match(request);
  
  if (cachedResponse) {
    return cachedResponse;
  }
  
  const networkResponse = await fetch(request);
  
  // Cache the new response for future use
  if (networkResponse.ok) {
    cache.put(request, networkResponse.clone());
  }
  
  return networkResponse;
}
```

### Network-First Strategy Pattern

This prioritizes fresh data but falls back to cache on network failure:

```javascript
async function networkFirst(request) {
  const cache = await caches.open('my-cache-v1');
  
  try {
    const networkResponse = await fetch(request);
    
    if (networkResponse.ok) {
      cache.put(request, networkResponse.clone());
    }
    
    return networkResponse;
  } catch (error) {
    const cachedResponse = await cache.match(request);
    
    if (cachedResponse) {
      return cachedResponse;
    }
    
    throw error;
  }
}
```

### Stale-While-Revalidate Pattern

Returns cached content immediately while fetching fresh data in the background:

```javascript
async function staleWhileRevalidate(request) {
  const cache = await caches.open('my-cache-v1');
  const cachedResponse = await cache.match(request);
  
  // Fetch fresh data in background
  const fetchPromise = fetch(request).then(networkResponse => {
    if (networkResponse.ok) {
      cache.put(request, networkResponse.clone());
    }
    return networkResponse;
  });
  
  // Return cached version immediately if available
  return cachedResponse || fetchPromise;
}
```

### Cache Invalidation and Updates

#### Deleting Specific Entries

```javascript
const cache = await caches.open('my-cache-v1');
const deleted = await cache.delete('/api/data');

// With options
await cache.delete(request, {
  ignoreSearch: true,
  ignoreMethod: false,
  ignoreVary: false
});
```

#### Deleting Entire Caches

```javascript
// Delete a specific cache
await caches.delete('my-cache-v1');

// Delete old cache versions
const cacheNames = await caches.keys();
await Promise.all(
  cacheNames
    .filter(name => name !== 'my-cache-v2')
    .map(name => caches.delete(name))
);
```

#### Cache Versioning Strategy

```javascript
const CACHE_VERSION = 'v2';
const CACHE_NAME = `my-app-${CACHE_VERSION}`;

// During service worker activation
self.addEventListener('activate', event => {
  event.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames
          .filter(name => name !== CACHE_NAME)
          .map(name => caches.delete(name))
      );
    })
  );
});
```

### Query and Inspection Methods

#### Listing Cache Contents

```javascript
const cache = await caches.open('my-cache-v1');
const requests = await cache.keys();

requests.forEach(request => {
  console.log(request.url);
});

// Filter specific patterns
const apiRequests = requests.filter(req => 
  req.url.includes('/api/')
);
```

#### Checking Multiple Caches

```javascript
// Match across all caches
const response = await caches.match('/api/data');

// List all cache names
const allCaches = await caches.keys();
console.log(allCaches); // ['cache-v1', 'cache-v2', 'images']
```

### Request/Response Matching Details

#### URL Matching Behavior

The Cache API performs strict URL matching by default:

```javascript
// These are considered different URLs
await cache.put('https://api.example.com/data', response1);
await cache.match('https://api.example.com/data?id=1'); // null

// Use ignoreSearch to match regardless of query params
await cache.match('https://api.example.com/data?id=1', {
  ignoreSearch: true
}); // Returns response1
```

#### Vary Header Handling

The Vary response header affects cache matching:

```javascript
// Response with Vary: Accept-Language
const response = await fetch('/api/content');
await cache.put(request, response);

// Must match the Vary header values to retrieve
const match = await cache.match(request); // Checks Accept-Language header
```

### Service Worker Integration

#### Installation Phase Caching

```javascript
const CACHE_NAME = 'app-v1';
const urlsToCache = [
  '/',
  '/styles/main.css',
  '/scripts/app.js'
];

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then(cache => cache.addAll(urlsToCache))
  );
});
```

#### Fetch Event Interception

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request)
      .then(cachedResponse => {
        if (cachedResponse) {
          return cachedResponse;
        }
        
        return fetch(event.request).then(response => {
          // Don't cache non-GET requests or failed responses
          if (event.request.method !== 'GET' || !response.ok) {
            return response;
          }
          
          const responseToCache = response.clone();
          caches.open(CACHE_NAME)
            .then(cache => {
              cache.put(event.request, responseToCache);
            });
          
          return response;
        });
      })
  );
});
```

### Advanced Caching Strategies

#### Cache with Network Timeout

```javascript
async function cacheWithTimeout(request, timeout = 3000) {
  const cache = await caches.open('my-cache-v1');
  
  const timeoutPromise = new Promise((_, reject) => 
    setTimeout(() => reject(new Error('Network timeout')), timeout)
  );
  
  try {
    const networkResponse = await Promise.race([
      fetch(request),
      timeoutPromise
    ]);
    
    cache.put(request, networkResponse.clone());
    return networkResponse;
  } catch (error) {
    const cachedResponse = await cache.match(request);
    if (cachedResponse) {
      return cachedResponse;
    }
    throw error;
  }
}
```

#### Cache Then Network with Update

```javascript
async function cacheThenNetworkUpdate(request, callback) {
  const cache = await caches.open('my-cache-v1');
  
  // Return cached immediately
  const cachedResponse = await cache.match(request);
  if (cachedResponse) {
    callback(cachedResponse.clone());
  }
  
  // Fetch and update
  try {
    const networkResponse = await fetch(request);
    if (networkResponse.ok) {
      cache.put(request, networkResponse.clone());
      callback(networkResponse.clone());
    }
  } catch (error) {
    if (!cachedResponse) {
      throw error;
    }
  }
}

// Usage
cacheThenNetworkUpdate('/api/data', response => {
  response.json().then(data => updateUI(data));
});
```

#### Selective Caching Based on Criteria

```javascript
function shouldCache(request, response) {
  // Only cache successful GET requests
  if (request.method !== 'GET' || !response.ok) {
    return false;
  }
  
  // Don't cache certain content types
  const contentType = response.headers.get('Content-Type') || '';
  if (contentType.includes('text/html')) {
    return false;
  }
  
  // Don't cache responses with no-store
  const cacheControl = response.headers.get('Cache-Control') || '';
  if (cacheControl.includes('no-store')) {
    return false;
  }
  
  return true;
}

self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request).then(response => {
      if (shouldCache(event.request, response)) {
        const cache = caches.open('selective-cache');
        cache.then(c => c.put(event.request, response.clone()));
      }
      return response;
    })
  );
});
```

### Cache Size Management

#### Manual Cache Pruning

```javascript
async function pruneCache(cacheName, maxItems) {
  const cache = await caches.open(cacheName);
  const keys = await cache.keys();
  
  if (keys.length > maxItems) {
    // Remove oldest entries (FIFO approach)
    const keysToDelete = keys.slice(0, keys.length - maxItems);
    await Promise.all(
      keysToDelete.map(key => cache.delete(key))
    );
  }
}
```

#### Time-Based Expiration

```javascript
async function cacheWithExpiry(request, response, maxAge) {
  const cache = await caches.open('time-based-cache');
  
  // Create modified response with expiry metadata
  const expiryTime = Date.now() + maxAge;
  const modifiedResponse = new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers: new Headers(response.headers)
  });
  
  modifiedResponse.headers.set('X-Cache-Expiry', expiryTime.toString());
  await cache.put(request, modifiedResponse);
}

async function matchWithExpiry(request) {
  const cache = await caches.open('time-based-cache');
  const response = await cache.match(request);
  
  if (!response) {
    return null;
  }
  
  const expiryTime = response.headers.get('X-Cache-Expiry');
  if (expiryTime && Date.now() > parseInt(expiryTime)) {
    await cache.delete(request);
    return null;
  }
  
  return response;
}
```

### Error Handling Patterns

#### Graceful Degradation

```javascript
async function fetchWithCacheFallback(request) {
  const cache = await caches.open('my-cache-v1');
  
  try {
    const response = await fetch(request);
    
    if (response.ok) {
      cache.put(request, response.clone());
      return response;
    }
    
    // Network responded but with error status
    const cached = await cache.match(request);
    return cached || response;
  } catch (networkError) {
    // Network failed completely
    const cached = await cache.match(request);
    
    if (cached) {
      return cached;
    }
    
    // Return offline fallback page
    return cache.match('/offline.html');
  }
}
```

#### Cache Operation Error Handling

```javascript
async function safeCacheOperation(operation) {
  try {
    return await operation();
  } catch (error) {
    // QuotaExceededError handling
    if (error.name === 'QuotaExceededError') {
      console.error('Cache storage quota exceeded');
      // Implement cleanup strategy
      await cleanupOldCaches();
      return null;
    }
    
    console.error('Cache operation failed:', error);
    return null;
  }
}

// Usage
await safeCacheOperation(async () => {
  const cache = await caches.open('my-cache');
  return cache.put(request, response);
});
```

### Cross-Origin Resource Caching

#### Opaque Responses

```javascript
// Opaque responses from no-cors requests
const response = await fetch('https://third-party.com/image.jpg', {
  mode: 'no-cors'
});

const cache = await caches.open('images');
await cache.put(request, response);

// [Inference] Opaque responses can be cached but have limitations
// - Cannot read response body or headers
// - Status is always 0
// - Can only verify successful cache through retrieval
```

#### CORS-Enabled Resources

```javascript
// Full access to CORS-enabled responses
const response = await fetch('https://api.example.com/data', {
  mode: 'cors'
});

if (response.ok) {
  const cache = await caches.open('api-cache');
  await cache.put(request, response.clone());
  
  // Can access response details
  console.log(response.status);
  console.log(response.headers.get('Content-Type'));
}
```

### Performance Considerations

#### Parallel Cache Operations

```javascript
// Parallel cache checks across multiple caches
async function findInAnyCaches(request) {
  const cacheNames = await caches.keys();
  
  const searchPromises = cacheNames.map(name =>
    caches.open(name).then(cache => cache.match(request))
  );
  
  const results = await Promise.all(searchPromises);
  return results.find(response => response !== undefined);
}
```

#### Batch Cache Updates

```javascript
async function updateMultipleEntries(entries) {
  const cache = await caches.open('my-cache-v1');
  
  await Promise.all(
    entries.map(({ request, response }) => 
      cache.put(request, response)
    )
  );
}
```

### Cache API Limitations and Constraints

#### Storage Quota

[Inference] The Cache API is subject to browser storage quotas, which vary by browser and available disk space. Exceeding quotas results in `QuotaExceededError`. The Storage API can query available space:

```javascript
if ('storage' in navigator && 'estimate' in navigator.storage) {
  const estimate = await navigator.storage.estimate();
  const percentUsed = (estimate.usage / estimate.quota) * 100;
  console.log(`Using ${percentUsed.toFixed(2)}% of storage`);
}
```

#### Request Matching Restrictions

- Only HTTP/HTTPS schemes are cached
- Request method matters (default matching respects method)
- Fragment identifiers are ignored in URLs
- Credentials mode affects opaque response caching

### Testing and Debugging

#### Cache Inspection in DevTools

```javascript
// Programmatic cache inspection utility
async function inspectCache(cacheName) {
  const cache = await caches.open(cacheName);
  const requests = await cache.keys();
  
  const entries = await Promise.all(
    requests.map(async request => {
      const response = await cache.match(request);
      return {
        url: request.url,
        method: request.method,
        status: response.status,
        headers: Object.fromEntries(response.headers.entries())
      };
    })
  );
  
  return entries;
}
```

#### Cache State Verification

```javascript
async function verifyCacheState(expectedUrls, cacheName) {
  const cache = await caches.open(cacheName);
  const requests = await cache.keys();
  const cachedUrls = requests.map(req => req.url);
  
  const missing = expectedUrls.filter(url => !cachedUrls.includes(url));
  const unexpected = cachedUrls.filter(url => !expectedUrls.includes(url));
  
  return { missing, unexpected, allPresent: missing.length === 0 };
}
```

---

## Cache-Control Headers in Fetch API

### Understanding Cache Directives

Cache-Control headers control how HTTP responses are cached by browsers, CDNs, and intermediate proxies. When using the fetch API, these headers determine whether responses are stored, for how long, and under what conditions they can be reused.

The Cache-Control header contains one or more directives separated by commas. Each directive modifies caching behavior for the request or response.

### Response Directives

#### max-age

Specifies the maximum time in seconds a response remains fresh. After this period, the cached response becomes stale.

```javascript
// Response with max-age
fetch('https://api.example.com/data')
  .then(response => {
    console.log(response.headers.get('Cache-Control')); // "max-age=3600"
  });
```

A `max-age=3600` means the response can be cached for one hour without revalidation.

#### s-maxage

Overrides max-age for shared caches (CDNs, proxy servers) but not private browser caches. Ignored by private caches.

```
Cache-Control: max-age=600, s-maxage=3600
```

Private caches use 600 seconds, shared caches use 3600 seconds.

#### no-cache

Forces caches to revalidate with the origin server before using cached responses. The response can still be cached, but must be validated each time.

```
Cache-Control: no-cache
```

With conditional requests:

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'If-None-Match': etag // ETag from previous response
  }
});
```

#### no-store

Prevents any caching of the request or response. Use for sensitive data.

```
Cache-Control: no-store
```

The browser stores nothing about the request or response in any cache.

#### must-revalidate

Once a response becomes stale, caches must revalidate with the origin server before using it. Without this, some caches might serve stale content under certain conditions.

```
Cache-Control: max-age=3600, must-revalidate
```

#### proxy-revalidate

Similar to must-revalidate but only applies to shared caches, not private browser caches.

#### public

Indicates the response may be cached by any cache, including CDNs and proxies, even if the response would normally be non-cacheable (e.g., authenticated requests).

```
Cache-Control: public, max-age=86400
```

#### private

Restricts caching to the user's browser only. Shared caches must not store the response.

```
Cache-Control: private, max-age=3600
```

Commonly used for user-specific data.

#### immutable

Indicates the response body will never change during its freshness lifetime. Browsers can skip revalidation even when users perform a manual refresh.

```
Cache-Control: max-age=31536000, immutable
```

Ideal for versioned static assets (e.g., `app.v123.js`).

#### stale-while-revalidate

Allows serving stale content while asynchronously revalidating in the background.

```
Cache-Control: max-age=600, stale-while-revalidate=1800
```

Fresh for 10 minutes, then serves stale content for up to 30 more minutes while fetching fresh data.

#### stale-if-error

Permits serving stale content if revalidation fails or the origin server is unavailable.

```
Cache-Control: max-age=600, stale-if-error=86400
```

Serves stale content for up to 24 hours if errors occur during revalidation.

### Request Directives

#### no-cache (request)

Forces intermediate caches to revalidate with the origin server.

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'Cache-Control': 'no-cache'
  }
});
```

#### no-store (request)

Requests that caches not store anything about this request or response.

#### max-age (request)

Client specifies the maximum age of a cached response it will accept.

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'Cache-Control': 'max-age=0'
  }
});
```

`max-age=0` forces revalidation.

#### max-stale

Client indicates willingness to accept stale responses.

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'Cache-Control': 'max-stale=600'
  }
});
```

Accepts responses up to 10 minutes past their expiration.

#### min-fresh

Client wants responses that will remain fresh for at least the specified number of seconds.

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'Cache-Control': 'min-fresh=300'
  }
});
```

#### only-if-cached

Client wants only cached responses. If no cached response exists, returns a 504 Gateway Timeout.

```javascript
fetch('https://api.example.com/data', {
  headers: {
    'Cache-Control': 'only-if-cached'
  }
});
```

### Fetch API Cache Modes

The fetch API provides the `cache` option to control request caching behavior independent of headers:

#### default

Standard caching behavior following HTTP semantics.

```javascript
fetch(url, { cache: 'default' });
```

#### no-store

Bypasses cache entirely for both request and response.

```javascript
fetch(url, { cache: 'no-store' });
```

#### reload

Ignores cache for request but updates cache with response.

```javascript
fetch(url, { cache: 'reload' });
```

Equivalent to setting `Cache-Control: no-cache` on the request.

#### no-cache

Checks cache for matching entry, validates with server using conditional requests, then uses cached response if valid.

```javascript
fetch(url, { cache: 'no-cache' });
```

#### force-cache

Uses cached response regardless of staleness. Only fetches from network if no cached response exists.

```javascript
fetch(url, { cache: 'force-cache' });
```

#### only-if-cached

Returns cached response or fails. Must be used with `mode: 'same-origin'`.

```javascript
fetch(url, { 
  cache: 'only-if-cached',
  mode: 'same-origin'
});
```

### Conditional Requests and Revalidation

Cache revalidation uses conditional request headers:

#### ETag and If-None-Match

```javascript
// Initial request
const response = await fetch('https://api.example.com/data');
const etag = response.headers.get('ETag');

// Subsequent request with revalidation
const revalidated = await fetch('https://api.example.com/data', {
  headers: {
    'If-None-Match': etag
  }
});

if (revalidated.status === 304) {
  // Use cached response
} else {
  // New content available
}
```

#### Last-Modified and If-Modified-Since

```javascript
// Initial request
const response = await fetch('https://api.example.com/data');
const lastModified = response.headers.get('Last-Modified');

// Subsequent request
const revalidated = await fetch('https://api.example.com/data', {
  headers: {
    'If-Modified-Since': lastModified
  }
});
```

### Cache Busting Strategies

#### Query Parameters

```javascript
fetch(`https://api.example.com/data?t=${Date.now()}`);
```

Each request gets a unique URL, bypassing cache.

#### Versioned URLs

```javascript
const version = 'v2.1.0';
fetch(`https://api.example.com/data?version=${version}`);
```

#### Cache Control Headers

```javascript
fetch('https://api.example.com/data', {
  cache: 'reload',
  headers: {
    'Cache-Control': 'no-cache'
  }
});
```

### Interaction with Service Workers

Service workers intercept fetch requests and can implement custom caching strategies:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cachedResponse => {
      if (cachedResponse) {
        // Return cached response
        return cachedResponse;
      }
      
      return fetch(event.request).then(response => {
        // Cache new response
        return caches.open('v1').then(cache => {
          cache.put(event.request, response.clone());
          return response;
        });
      });
    })
  );
});
```

Service workers can override Cache-Control headers from the server.

### Common Patterns

#### API Responses with Short-Term Caching

```
Cache-Control: private, max-age=300
```

Caches user-specific data for 5 minutes in browser only.

#### Static Assets with Long-Term Caching

```
Cache-Control: public, max-age=31536000, immutable
```

Caches versioned assets for one year with immutability guarantee.

#### Dynamic Content with Revalidation

```
Cache-Control: no-cache, must-revalidate
```

Always validates before serving, ensures freshness.

#### CDN-Optimized Responses

```
Cache-Control: public, max-age=300, s-maxage=3600
```

Browser caches for 5 minutes, CDN caches for 1 hour.

#### Offline-First with Stale Content

```
Cache-Control: max-age=600, stale-while-revalidate=86400
```

Serves stale content while revalidating, enabling offline access.

### Debugging Cache Behavior

#### Inspecting Response Headers

```javascript
fetch('https://api.example.com/data')
  .then(response => {
    const cacheControl = response.headers.get('Cache-Control');
    const age = response.headers.get('Age');
    const expires = response.headers.get('Expires');
    
    console.log('Cache-Control:', cacheControl);
    console.log('Age:', age);
    console.log('Expires:', expires);
  });
```

#### Chrome DevTools

Network tab shows:

- Request headers (including `Cache-Control`)
- Response headers
- Cache status (from disk cache, from memory cache)
- Size (actual size or "from cache")

#### Testing Cache Behavior

```javascript
// First request - should hit network
await fetch('https://api.example.com/data');

// Second request - may use cache depending on directives
await fetch('https://api.example.com/data');

// Force fresh request
await fetch('https://api.example.com/data', { cache: 'reload' });
```

### Security Considerations

#### Sensitive Data

Always use `no-store` for sensitive information:

```
Cache-Control: no-store, no-cache, must-revalidate, private
```

#### Authenticated Requests

Use `private` to prevent shared cache storage:

```
Cache-Control: private, max-age=300
```

#### CORS and Caching

Cached responses must match CORS requirements. Vary header ensures proper cache separation:

```
Cache-Control: public, max-age=3600
Vary: Origin
```

### Limitations and Browser Differences

Different browsers may implement caching heuristics differently when no explicit Cache-Control is provided. Some browsers apply heuristic caching based on Last-Modified dates.

The `cache` option in fetch may not work identically across all browsers. The `only-if-cached` mode has restricted usage and browser-specific behavior.

Service worker caches operate independently of HTTP cache and have their own storage quotas and eviction policies.

### Performance Optimization

#### Minimize Cache Misses

Use consistent URLs and avoid unnecessary query parameters that create unique cache entries.

#### Balance Freshness and Performance

```
Cache-Control: max-age=3600, stale-while-revalidate=86400
```

Provides good performance while maintaining reasonable freshness.

#### Leverage CDN Caching

```
Cache-Control: public, s-maxage=604800, max-age=300
```

CDN caches for 7 days, browser caches for 5 minutes.

#### Use Immutable for Static Assets

```
Cache-Control: public, max-age=31536000, immutable
```

Eliminates unnecessary revalidation for versioned assets during page reloads.

---

## ETags and Validation with Fetch API

### ETag Response Header

ETags are identifier strings returned by servers in the `ETag` response header that represent a specific version of a resource. The server generates these identifiers based on resource content.

```javascript
const response = await fetch('/api/data');
const etag = response.headers.get('ETag');
// Example: "33a64df551425fcc55e4d42a148795d9f25f89d4"
// Example: W/"0815" (weak ETag)
```

**ETag Format Types:**

- **Strong ETags**: `"686897696a7c876b7e"` - Byte-for-byte identical resources
- **Weak ETags**: `W/"686897696a7c876b7e"` - Semantically equivalent resources

### Conditional Requests with If-None-Match

The `If-None-Match` request header sends stored ETags to the server for validation.

```javascript
// Initial request
const response1 = await fetch('/api/data');
const etag = response1.headers.get('ETag');
const data = await response1.json();

// Store etag with data
localStorage.setItem('data', JSON.stringify(data));
localStorage.setItem('data-etag', etag);

// Subsequent request with validation
const storedEtag = localStorage.getItem('data-etag');
const response2 = await fetch('/api/data', {
  headers: {
    'If-None-Match': storedEtag
  }
});

if (response2.status === 304) {
  // Not Modified - use cached data
  const cachedData = JSON.parse(localStorage.getItem('data'));
  console.log('Using cached data');
} else {
  // Resource changed - update cache
  const newEtag = response2.headers.get('ETag');
  const newData = await response2.json();
  localStorage.setItem('data', JSON.stringify(newData));
  localStorage.setItem('data-etag', newEtag);
}
```

### 304 Not Modified Response

When ETags match, the server returns status 304 with no response body, saving bandwidth.

```javascript
const response = await fetch('/api/data', {
  headers: {
    'If-None-Match': '"abc123"'
  }
});

console.log(response.status); // 304
console.log(response.statusText); // "Not Modified"
console.log(response.ok); // false (status not in 200-299 range)

// response.body is null for 304 responses
const body = await response.text(); // Empty string
```

### Multiple ETag Validation

The `If-None-Match` header accepts multiple ETags separated by commas.

```javascript
const etags = [
  '"686897696a7c876b7e"',
  '"1234567890abcdef"',
  'W/"weak-etag"'
];

const response = await fetch('/api/data', {
  headers: {
    'If-None-Match': etags.join(', ')
  }
});

// Server returns 304 if resource matches ANY provided ETag
```

### Wildcard Validation

The `*` wildcard matches any existing resource version.

```javascript
const response = await fetch('/api/data', {
  headers: {
    'If-None-Match': '*'
  }
});

// Returns 304 if resource exists, regardless of version
// Useful for "create only if not exists" scenarios
```

### If-Match for Safe Updates

The `If-Match` header ensures updates only occur if the resource hasn't changed.

```javascript
// Read current resource
const getResponse = await fetch('/api/user/123');
const currentEtag = getResponse.headers.get('ETag');
const userData = await getResponse.json();

// Modify data
userData.email = 'newemail@example.com';

// Update with conditional request
const updateResponse = await fetch('/api/user/123', {
  method: 'PUT',
  headers: {
    'Content-Type': 'application/json',
    'If-Match': currentEtag
  },
  body: JSON.stringify(userData)
});

if (updateResponse.status === 412) {
  // Precondition Failed - resource was modified by another client
  console.error('Resource was modified by another user');
} else if (updateResponse.ok) {
  // Update succeeded
  const newEtag = updateResponse.headers.get('ETag');
  console.log('Updated successfully');
}
```

### 412 Precondition Failed

When `If-Match` validation fails, the server returns status 412.

```javascript
const response = await fetch('/api/document/5', {
  method: 'PUT',
  headers: {
    'If-Match': '"old-etag"',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({ content: 'Updated content' })
});

if (response.status === 412) {
  // Resource changed since last read
  // Typical resolution: refetch and retry
  const freshResponse = await fetch('/api/document/5');
  const freshEtag = freshResponse.headers.get('ETag');
  const freshData = await freshResponse.json();
  
  // Resolve conflicts, then retry with fresh ETag
}
```

### Range Requests with ETags

ETags validate partial content requests using `If-Range`.

```javascript
const etag = '"abc123"';

// Request partial content only if ETag matches
const response = await fetch('/large-file.bin', {
  headers: {
    'Range': 'bytes=0-1023',
    'If-Range': etag
  }
});

if (response.status === 206) {
  // Partial Content - ETag matched
  const chunk = await response.arrayBuffer();
} else if (response.status === 200) {
  // Full content - ETag didn't match, resource changed
  const fullContent = await response.arrayBuffer();
}
```

### Combining If-Match and If-None-Match

[Inference] Both headers can appear in the same request, though this is uncommon. The server evaluates `If-Match` first.

```javascript
const response = await fetch('/api/resource', {
  method: 'PUT',
  headers: {
    'If-Match': '"current-version"',
    'If-None-Match': '"conflicting-version"',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify(data)
});
```

### Weak vs Strong Comparison

Strong ETags require byte-for-byte identical content. Weak ETags allow semantic equivalence.

```javascript
// Strong ETag comparison (If-Match, If-None-Match with strong ETags)
const response1 = await fetch('/api/data', {
  headers: {
    'If-None-Match': '"abc123"' // Must match exactly
  }
});

// Weak ETag comparison (If-None-Match accepts weak ETags)
const response2 = await fetch('/api/data', {
  headers: {
    'If-None-Match': 'W/"abc123"' // Semantic equivalence
  }
});

// If-Range requires strong comparison
const response3 = await fetch('/file.bin', {
  headers: {
    'Range': 'bytes=0-1023',
    'If-Range': 'W/"weak"' // Server treats as non-matching
  }
});
```

### Cache Integration

ETags integrate with browser HTTP cache for automatic validation.

```javascript
// First request - server returns ETag
const response1 = await fetch('/api/data', {
  cache: 'default' // Use HTTP cache
});
// Response headers: ETag: "abc123", Cache-Control: max-age=3600

// Request within max-age - served from cache, no network request

// Request after max-age - browser automatically sends If-None-Match
const response2 = await fetch('/api/data', {
  cache: 'default'
});
// Browser sends: If-None-Match: "abc123"
// Server returns 304 if unchanged
```

### Cache Control Directives

Different cache directives affect ETag validation behavior.

```javascript
// Force revalidation even within max-age
const response = await fetch('/api/data', {
  cache: 'no-cache' // Always revalidate with If-None-Match
});

// Skip cache entirely
const response2 = await fetch('/api/data', {
  cache: 'reload' // Bypass cache, no If-None-Match sent
});

// Use cache without revalidation
const response3 = await fetch('/api/data', {
  cache: 'force-cache' // Use cached response without validation
});
```

### Manual Cache Management

Building a cache layer that uses ETags for validation.

```javascript
class ETagCache {
  constructor() {
    this.cache = new Map();
  }
  
  async fetch(url, options = {}) {
    const cacheKey = this.getCacheKey(url, options);
    const cached = this.cache.get(cacheKey);
    
    const headers = { ...options.headers };
    
    if (cached?.etag) {
      headers['If-None-Match'] = cached.etag;
    }
    
    const response = await fetch(url, { ...options, headers });
    
    if (response.status === 304 && cached) {
      // Return cached data
      return {
        ...cached.response,
        fromCache: true
      };
    }
    
    if (response.ok) {
      const etag = response.headers.get('ETag');
      const clonedResponse = response.clone();
      
      if (etag) {
        const data = await clonedResponse.json();
        this.cache.set(cacheKey, {
          etag,
          response: {
            status: response.status,
            headers: Object.fromEntries(response.headers.entries()),
            data
          }
        });
      }
    }
    
    return response;
  }
  
  getCacheKey(url, options) {
    return `${url}:${options.method || 'GET'}`;
  }
  
  clear() {
    this.cache.clear();
  }
}

// Usage
const cache = new ETagCache();
const response = await cache.fetch('/api/data');
```

### Optimistic Locking Pattern

Using ETags to implement optimistic concurrency control.

```javascript
async function updateWithOptimisticLock(url, updateFn, maxRetries = 3) {
  let retries = 0;
  
  while (retries < maxRetries) {
    // Fetch current version
    const getResponse = await fetch(url);
    
    if (!getResponse.ok) {
      throw new Error(`Failed to fetch: ${getResponse.status}`);
    }
    
    const etag = getResponse.headers.get('ETag');
    const currentData = await getResponse.json();
    
    // Apply updates
    const updatedData = updateFn(currentData);
    
    // Attempt conditional update
    const putResponse = await fetch(url, {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        'If-Match': etag
      },
      body: JSON.stringify(updatedData)
    });
    
    if (putResponse.ok) {
      return await putResponse.json();
    }
    
    if (putResponse.status === 412) {
      // Conflict - retry
      retries++;
      console.log(`Conflict detected, retry ${retries}/${maxRetries}`);
      continue;
    }
    
    throw new Error(`Update failed: ${putResponse.status}`);
  }
  
  throw new Error('Max retries exceeded');
}

// Usage
const result = await updateWithOptimisticLock(
  '/api/counter',
  (data) => ({ ...data, count: data.count + 1 })
);
```

### DELETE with If-Match

Conditional deletion prevents accidental removal of updated resources.

```javascript
const response = await fetch('/api/resource/123', {
  method: 'DELETE',
  headers: {
    'If-Match': storedEtag
  }
});

if (response.status === 412) {
  console.error('Resource was modified, cannot delete');
} else if (response.status === 204 || response.ok) {
  console.log('Deleted successfully');
}
```

### POST with If-None-Match

Using `If-None-Match: *` to prevent duplicate resource creation.

```javascript
const response = await fetch('/api/resources', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'If-None-Match': '*'
  },
  body: JSON.stringify({
    id: 'unique-id-123',
    data: 'value'
  })
});

if (response.status === 412) {
  // Resource already exists
  console.log('Resource already created');
} else if (response.status === 201) {
  // Created successfully
  const newEtag = response.headers.get('ETag');
}
```

### Vary Header Interaction

The `Vary` header affects ETag validation for content negotiation.

```javascript
// Request with Accept-Language
const response1 = await fetch('/api/content', {
  headers: {
    'Accept-Language': 'en-US',
    'If-None-Match': '"abc123"'
  }
});
// Response headers: Vary: Accept-Language

// Same ETag, different language - may return 200 instead of 304
const response2 = await fetch('/api/content', {
  headers: {
    'Accept-Language': 'es-ES',
    'If-None-Match': '"abc123"'
  }
});
```

### ETag Generation Strategies

[Inference] While ETag generation happens server-side, understanding common strategies helps predict behavior:

**Content-based (Strong):**

- MD5/SHA hash of response body
- Guarantees byte-for-byte equality

**Metadata-based (Weak):**

- Last-Modified timestamp
- Version number
- Database row version

```javascript
// Client perspective: both appear the same
const etag1 = response.headers.get('ETag');
// Could be: "5d41402abc4b2a76b9719d911017c592" (MD5)
// Could be: "v7" (version)
// Could be: W/"1638360000" (timestamp)
```

### Response Header Extraction

Complete ETag-related header extraction pattern.

```javascript
async function fetchWithValidation(url, options = {}) {
  const response = await fetch(url, options);
  
  const validationInfo = {
    etag: response.headers.get('ETag'),
    lastModified: response.headers.get('Last-Modified'),
    cacheControl: response.headers.get('Cache-Control'),
    vary: response.headers.get('Vary'),
    age: response.headers.get('Age'),
    expires: response.headers.get('Expires')
  };
  
  return {
    response,
    validationInfo
  };
}
```

### Handling Missing ETags

Not all servers provide ETags. Fallback strategies for validation.

```javascript
async function fetchWithFallbackValidation(url, cachedData) {
  const headers = {};
  
  // Prefer ETag if available
  if (cachedData.etag) {
    headers['If-None-Match'] = cachedData.etag;
  } 
  // Fallback to Last-Modified
  else if (cachedData.lastModified) {
    headers['If-Modified-Since'] = cachedData.lastModified;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 304) {
    return cachedData.content;
  }
  
  const newEtag = response.headers.get('ETag');
  const newLastModified = response.headers.get('Last-Modified');
  const content = await response.json();
  
  return {
    content,
    etag: newEtag,
    lastModified: newLastModified
  };
}
```

### GraphQL Integration

ETags with GraphQL require custom implementation as GraphQL typically uses POST.

```javascript
async function graphqlFetchWithETag(query, variables, cachedEtag) {
  // Generate deterministic cache key
  const cacheKey = JSON.stringify({ query, variables });
  const cacheKeyHash = await hashString(cacheKey);
  
  const response = await fetch('/graphql', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'X-GraphQL-Cache-Key': cacheKeyHash,
      ...(cachedEtag && { 'If-None-Match': cachedEtag })
    },
    body: JSON.stringify({ query, variables })
  });
  
  // Server can return 304 based on cache key and ETag
  if (response.status === 304) {
    return getCachedResult(cacheKeyHash);
  }
  
  const etag = response.headers.get('ETag');
  const data = await response.json();
  
  if (etag) {
    cacheResult(cacheKeyHash, data, etag);
  }
  
  return data;
}
```

### SPA Navigation Caching

Using ETags for efficient single-page application data caching.

```javascript
class SPACache {
  constructor() {
    this.routeCache = new Map();
  }
  
  async fetchRoute(url) {
    const cached = this.routeCache.get(url);
    
    const response = await fetch(url, {
      headers: {
        'Accept': 'application/json',
        ...(cached?.etag && { 'If-None-Match': cached.etag })
      }
    });
    
    if (response.status === 304) {
      console.log('Using cached route data');
      return cached.data;
    }
    
    const etag = response.headers.get('ETag');
    const data = await response.json();
    
    if (etag) {
      this.routeCache.set(url, { etag, data, timestamp: Date.now() });
    }
    
    return data;
  }
  
  invalidate(url) {
    this.routeCache.delete(url);
  }
  
  invalidatePattern(pattern) {
    for (const [url] of this.routeCache) {
      if (url.includes(pattern)) {
        this.routeCache.delete(url);
      }
    }
  }
}
```

### Stale-While-Revalidate Pattern

Serving stale content while revalidating in the background.

```javascript
async function fetchWithStaleWhileRevalidate(url, cachedData) {
  // Return cached data immediately if available
  const returnCached = cachedData?.data 
    ? Promise.resolve(cachedData.data)
    : null;
  
  // Start revalidation in background
  const revalidatePromise = (async () => {
    const response = await fetch(url, {
      headers: {
        ...(cachedData?.etag && { 'If-None-Match': cachedData.etag })
      }
    });
    
    if (response.status === 304) {
      // Still fresh
      return { fresh: true, data: cachedData.data };
    }
    
    const etag = response.headers.get('ETag');
    const data = await response.json();
    
    // Update cache
    updateCache(url, { etag, data });
    
    return { fresh: false, data };
  })();
  
  if (returnCached) {
    // Return cached immediately, revalidate in background
    revalidatePromise.catch(console.error);
    return cachedData.data;
  }
  
  // No cache, wait for network
  const result = await revalidatePromise;
  return result.data;
}
```

### Batch Validation Requests

Validating multiple resources with a single request.

```javascript
async function batchValidate(resources) {
  // Construct If-None-Match with all ETags
  const etags = resources
    .map(r => r.etag)
    .filter(Boolean)
    .join(', ');
  
  const response = await fetch('/api/batch-validate', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'If-None-Match': etags
    },
    body: JSON.stringify({
      resources: resources.map(r => ({
        url: r.url,
        etag: r.etag
      }))
    })
  });
  
  // Server returns which resources have changed
  const validationResults = await response.json();
  // { changed: ['/api/user/1'], unchanged: ['/api/user/2', '/api/user/3'] }
  
  return validationResults;
}
```

### ETag with Server-Sent Events

[Inference] Using ETags to resume SSE streams after disconnection.

```javascript
let lastEventETag = null;

async function connectSSE(url) {
  const headers = {
    'Accept': 'text/event-stream'
  };
  
  if (lastEventETag) {
    headers['If-None-Match'] = lastEventETag;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 304) {
    // No new events, can reconnect with same state
    console.log('No new events since last connection');
    return;
  }
  
  // Server may include ETag in response headers
  const etag = response.headers.get('ETag');
  
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const text = decoder.decode(value);
    // Process SSE events
    
    // Update ETag as events are consumed
    if (etag) lastEventETag = etag;
  }
}
```

### CORS Preflight with Conditional Headers

Conditional headers may trigger CORS preflight requests.

```javascript
// Simple request - no preflight
const response1 = await fetch('https://api.example.com/data', {
  headers: {
    'If-None-Match': '"abc123"' // Safe header
  }
});

// Preflight required - If-Match not in CORS-safelisted headers
const response2 = await fetch('https://api.example.com/data', {
  method: 'PUT',
  headers: {
    'Content-Type': 'application/json',
    'If-Match': '"abc123"' // Triggers preflight
  },
  body: JSON.stringify(data)
});

// Server must include in preflight response:
// Access-Control-Allow-Headers: If-Match, Content-Type
```

### Error Boundary Integration

Handling ETag validation errors within application error boundaries.

```javascript
class ETagFetchError extends Error {
  constructor(message, status, etag) {
    super(message);
    this.name = 'ETagFetchError';
    this.status = status;
    this.etag = etag;
  }
}

async function safeFetchWithETag(url, etag) {
  try {
    const response = await fetch(url, {
      headers: {
        ...(etag && { 'If-None-Match': etag })
      }
    });
    
    if (response.status === 304) {
      return { status: 'not-modified', etag };
    }
    
    if (!response.ok) {
      throw new ETagFetchError(
        `HTTP ${response.status}`,
        response.status,
        response.headers.get('ETag')
      );
    }
    
    const newEtag = response.headers.get('ETag');
    const data = await response.json();
    
    return { status: 'success', data, etag: newEtag };
    
  } catch (error) {
    if (error instanceof ETagFetchError) {
      // Handle ETag-specific errors
      console.error('ETag validation failed:', error);
    }
    throw error;
  }
}
```

---

## Conditional Requests with the Fetch API

### Overview of Conditional Requests

Conditional requests allow clients to ask servers to process requests only if certain conditions are met. This mechanism reduces bandwidth, improves performance, and enables efficient caching by avoiding unnecessary data transfers when content hasn't changed.

### HTTP Headers for Conditional Requests

Conditional requests rely on specific HTTP headers that carry validation tokens or timestamps:

**Validation Headers (sent by server):**

- `ETag`: Entity tag, typically a hash or version identifier of the resource
- `Last-Modified`: Timestamp when the resource was last modified

**Conditional Request Headers (sent by client):**

- `If-None-Match`: Matches against `ETag` values
- `If-Match`: Matches against `ETag` values (requires match to proceed)
- `If-Modified-Since`: Matches against `Last-Modified` timestamp
- `If-Unmodified-Since`: Matches against `Last-Modified` timestamp (requires no modification to proceed)
- `If-Range`: Used with `Range` header for partial content requests

### Basic If-None-Match Request

The `If-None-Match` header is used with cached `ETag` values to check if a resource has changed.

```javascript
// Initial request - server returns ETag
const response1 = await fetch('/api/data');
const etag = response1.headers.get('ETag');
const data = await response1.json();

// Store etag with cached data
localStorage.setItem('data-etag', etag);
localStorage.setItem('data', JSON.stringify(data));

// Subsequent request with If-None-Match
const cachedEtag = localStorage.getItem('data-etag');

const response2 = await fetch('/api/data', {
  headers: {
    'If-None-Match': cachedEtag
  }
});

if (response2.status === 304) {
  // Not Modified - use cached data
  const cachedData = JSON.parse(localStorage.getItem('data'));
  console.log('Using cached data:', cachedData);
} else if (response2.ok) {
  // Resource changed - update cache
  const newEtag = response2.headers.get('ETag');
  const newData = await response2.json();
  
  localStorage.setItem('data-etag', newEtag);
  localStorage.setItem('data', JSON.stringify(newData));
  console.log('Using fresh data:', newData);
}
```

### If-Modified-Since Request

The `If-Modified-Since` header uses timestamps to determine if content has changed.

```javascript
// Initial request
const response1 = await fetch('/api/article/123');
const lastModified = response1.headers.get('Last-Modified');
const content = await response1.text();

// Save timestamp
localStorage.setItem('article-modified', lastModified);

// Later request
const cachedModified = localStorage.getItem('article-modified');

const response2 = await fetch('/api/article/123', {
  headers: {
    'If-Modified-Since': cachedModified
  }
});

if (response2.status === 304) {
  console.log('Article unchanged, using cached version');
} else {
  const newContent = await response2.text();
  const newModified = response2.headers.get('Last-Modified');
  localStorage.setItem('article-modified', newModified);
  console.log('Article updated:', newContent);
}
```

### Combining If-None-Match and If-Modified-Since

Both headers can be used together, with `If-None-Match` taking precedence when both are present.

```javascript
const response = await fetch('/api/resource', {
  headers: {
    'If-None-Match': cachedEtag,
    'If-Modified-Since': cachedLastModified
  }
});

// Server evaluates If-None-Match first
// If ETag matches, returns 304 without checking Last-Modified
// If no ETag, falls back to If-Modified-Since comparison
```

### If-Match for Optimistic Locking

The `If-Match` header enforces that a resource hasn't changed before allowing an update, preventing lost updates in concurrent editing scenarios.

```javascript
// User loads document for editing
const getResponse = await fetch('/api/document/456');
const etag = getResponse.headers.get('ETag');
const document = await getResponse.json();

// User edits document...
document.content = 'Updated content';

// Submit changes only if document hasn't changed
const updateResponse = await fetch('/api/document/456', {
  method: 'PUT',
  headers: {
    'Content-Type': 'application/json',
    'If-Match': etag
  },
  body: JSON.stringify(document)
});

if (updateResponse.status === 412) {
  // Precondition Failed - document was modified by someone else
  console.error('Document was modified by another user');
  
  // Fetch latest version
  const latestResponse = await fetch('/api/document/456');
  const latestDoc = await latestResponse.json();
  
  // Handle conflict (merge, notify user, etc.)
} else if (updateResponse.ok) {
  console.log('Document updated successfully');
}
```

### If-Unmodified-Since for Safe Updates

The `If-Unmodified-Since` header allows updates only if the resource hasn't been modified since a specific timestamp.

```javascript
const lastModified = response.headers.get('Last-Modified');

// Later, attempt update
const updateResponse = await fetch('/api/resource', {
  method: 'PUT',
  headers: {
    'Content-Type': 'application/json',
    'If-Unmodified-Since': lastModified
  },
  body: JSON.stringify(updatedData)
});

if (updateResponse.status === 412) {
  console.error('Resource was modified since last fetch');
} else if (updateResponse.ok) {
  console.log('Update successful');
}
```

### Wildcard ETag Matching

The asterisk (`*`) wildcard can be used with `If-Match` or `If-None-Match` for special behaviors.

```javascript
// If-Match: * succeeds only if resource exists
const response = await fetch('/api/resource', {
  method: 'PUT',
  headers: {
    'If-Match': '*',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify(data)
});

// 412 Precondition Failed if resource doesn't exist
// Useful for "update only" operations

// If-None-Match: * succeeds only if resource doesn't exist
const createResponse = await fetch('/api/resource', {
  method: 'PUT',
  headers: {
    'If-None-Match': '*',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify(data)
});

// 412 if resource already exists
// Useful for "create only" operations
```

### Multiple ETag Values

`If-None-Match` can accept multiple ETags as a comma-separated list.

```javascript
const response = await fetch('/api/data', {
  headers: {
    'If-None-Match': '"etag1", "etag2", "etag3"'
  }
});

// Returns 304 if current ETag matches any of the provided values
```

### If-Range for Resumable Downloads

The `If-Range` header enables conditional range requests, useful for resuming interrupted downloads.

```javascript
// Initial partial download
const response1 = await fetch('/large-file.zip', {
  headers: {
    'Range': 'bytes=0-1048575' // First 1MB
  }
});

const etag = response1.headers.get('ETag');
const partialData = await response1.arrayBuffer();

// Save partial data and etag
// Later, resume download

const response2 = await fetch('/large-file.zip', {
  headers: {
    'Range': 'bytes=1048576-', // From 1MB onwards
    'If-Range': etag
  }
});

if (response2.status === 206) {
  // Partial Content - file unchanged, resume successful
  const remainingData = await response2.arrayBuffer();
  
  // Combine partial downloads
  const combined = new Uint8Array(partialData.byteLength + remainingData.byteLength);
  combined.set(new Uint8Array(partialData), 0);
  combined.set(new Uint8Array(remainingData), partialData.byteLength);
} else if (response2.status === 200) {
  // File changed - server sent complete file instead
  const completeData = await response2.arrayBuffer();
}
```

### Caching Helper Class

```javascript
class ConditionalCache {
  constructor(storage = localStorage) {
    this.storage = storage;
  }
  
  getCacheKey(url, prefix = 'cache') {
    return `${prefix}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const cacheKey = this.getCacheKey(url);
    const cached = this.storage.getItem(cacheKey);
    
    if (cached) {
      const { etag, lastModified, data } = JSON.parse(cached);
      
      // Add conditional headers
      const headers = new Headers(options.headers || {});
      
      if (etag) {
        headers.set('If-None-Match', etag);
      }
      
      if (lastModified) {
        headers.set('If-Modified-Since', lastModified);
      }
      
      const response = await fetch(url, {
        ...options,
        headers
      });
      
      if (response.status === 304) {
        // Return cached data with synthetic response
        return {
          ok: true,
          status: 304,
          cached: true,
          json: async () => data,
          text: async () => JSON.stringify(data)
        };
      }
      
      if (response.ok) {
        // Update cache with new data
        const newData = await response.json();
        
        this.storage.setItem(cacheKey, JSON.stringify({
          etag: response.headers.get('ETag'),
          lastModified: response.headers.get('Last-Modified'),
          data: newData
        }));
        
        return {
          ok: true,
          status: response.status,
          cached: false,
          json: async () => newData
        };
      }
      
      return response;
    }
    
    // No cache - normal fetch
    const response = await fetch(url, options);
    
    if (response.ok) {
      const data = await response.json();
      
      this.storage.setItem(cacheKey, JSON.stringify({
        etag: response.headers.get('ETag'),
        lastModified: response.headers.get('Last-Modified'),
        data
      }));
      
      return {
        ok: true,
        status: response.status,
        cached: false,
        json: async () => data
      };
    }
    
    return response;
  }
  
  clear(url) {
    if (url) {
      this.storage.removeItem(this.getCacheKey(url));
    } else {
      // Clear all cached items
      const keys = Object.keys(this.storage);
      keys.forEach(key => {
        if (key.startsWith('cache:')) {
          this.storage.removeItem(key);
        }
      });
    }
  }
}

// Usage
const cache = new ConditionalCache();

const response = await cache.fetch('/api/data');
console.log('From cache:', response.cached);
const data = await response.json();
```

### Handling 304 Not Modified Responses

When a server returns 304, the response body is empty, requiring the client to use cached data.

```javascript
async function fetchWithCache(url, cacheKey) {
  const cached = sessionStorage.getItem(cacheKey);
  const cachedMeta = sessionStorage.getItem(`${cacheKey}:meta`);
  
  let headers = {};
  
  if (cachedMeta) {
    const meta = JSON.parse(cachedMeta);
    if (meta.etag) headers['If-None-Match'] = meta.etag;
    if (meta.lastModified) headers['If-Modified-Since'] = meta.lastModified;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 304) {
    // Parse cached data
    return JSON.parse(cached);
  }
  
  if (response.ok) {
    const data = await response.json();
    
    // Cache response and metadata
    sessionStorage.setItem(cacheKey, JSON.stringify(data));
    sessionStorage.setItem(`${cacheKey}:meta`, JSON.stringify({
      etag: response.headers.get('ETag'),
      lastModified: response.headers.get('Last-Modified'),
      timestamp: Date.now()
    }));
    
    return data;
  }
  
  throw new Error(`HTTP ${response.status}`);
}
```

### Weak vs Strong ETags

ETags can be weak or strong. Weak ETags are prefixed with `W/` and indicate semantic equivalence rather than byte-for-byte identity.

```javascript
// Strong ETag - byte-for-byte identical
// ETag: "686897696a7c876b7e"

// Weak ETag - semantically equivalent
// ETag: W/"686897696a7c876b7e"

const response = await fetch('/api/data', {
  headers: {
    'If-None-Match': 'W/"686897696a7c876b7e"'
  }
});

// Weak ETags can be used with If-None-Match
// Strong validators required for If-Range
```

### Conditional Requests for API Versioning

ETags can encode version information for API resources.

```javascript
async function updateResource(id, data, currentVersion) {
  const response = await fetch(`/api/resource/${id}`, {
    method: 'PATCH',
    headers: {
      'Content-Type': 'application/json',
      'If-Match': `"v${currentVersion}"`
    },
    body: JSON.stringify(data)
  });
  
  if (response.status === 412) {
    // Version conflict
    const latest = await fetch(`/api/resource/${id}`);
    const latestData = await latest.json();
    const latestVersion = latest.headers.get('ETag').match(/v(\d+)/)[1];
    
    return {
      conflict: true,
      currentVersion: latestVersion,
      currentData: latestData
    };
  }
  
  return await response.json();
}
```

### Polling with Conditional Requests

Conditional requests optimize polling scenarios by reducing data transfer when content hasn't changed.

```javascript
class ConditionalPoller {
  constructor(url, interval = 5000) {
    this.url = url;
    this.interval = interval;
    this.etag = null;
    this.lastModified = null;
    this.timerId = null;
    this.listeners = [];
  }
  
  async poll() {
    const headers = {};
    
    if (this.etag) {
      headers['If-None-Match'] = this.etag;
    }
    
    if (this.lastModified) {
      headers['If-Modified-Since'] = this.lastModified;
    }
    
    try {
      const response = await fetch(this.url, { headers });
      
      if (response.status === 304) {
        // No change
        console.log('No updates');
        return null;
      }
      
      if (response.ok) {
        this.etag = response.headers.get('ETag');
        this.lastModified = response.headers.get('Last-Modified');
        
        const data = await response.json();
        this.notifyListeners(data);
        return data;
      }
    } catch (error) {
      console.error('Poll failed:', error);
    }
    
    return null;
  }
  
  start() {
    this.poll(); // Initial poll
    this.timerId = setInterval(() => this.poll(), this.interval);
  }
  
  stop() {
    if (this.timerId) {
      clearInterval(this.timerId);
      this.timerId = null;
    }
  }
  
  onChange(callback) {
    this.listeners.push(callback);
  }
  
  notifyListeners(data) {
    this.listeners.forEach(callback => callback(data));
  }
}

// Usage
const poller = new ConditionalPoller('/api/notifications', 10000);

poller.onChange((data) => {
  console.log('New notifications:', data);
  updateUI(data);
});

poller.start();
```

### Conditional DELETE Requests

Conditional headers can prevent accidental deletion of modified resources.

```javascript
async function safeDelete(url, etag) {
  const response = await fetch(url, {
    method: 'DELETE',
    headers: {
      'If-Match': etag
    }
  });
  
  if (response.status === 412) {
    console.error('Resource was modified, cannot delete');
    return { success: false, reason: 'modified' };
  }
  
  if (response.status === 404) {
    console.error('Resource not found');
    return { success: false, reason: 'not_found' };
  }
  
  if (response.ok || response.status === 204) {
    return { success: true };
  }
  
  return { success: false, reason: 'unknown' };
}
```

### Browser Cache Integration

The fetch API respects HTTP caching directives, and conditional requests work with the browser's cache.

```javascript
// cache: 'default' uses standard HTTP cache with conditional requests
const response = await fetch('/api/data', {
  cache: 'default' // Browser may send If-None-Match/If-Modified-Since automatically
});

// cache: 'no-cache' forces validation with conditional requests
const freshResponse = await fetch('/api/data', {
  cache: 'no-cache' // Always validates with origin, using conditional requests
});

// cache: 'reload' bypasses cache entirely
const completelyFreshResponse = await fetch('/api/data', {
  cache: 'reload' // No conditional requests, ignores cache
});

// cache: 'force-cache' uses cache without validation
const cachedResponse = await fetch('/api/data', {
  cache: 'force-cache' // No conditional requests, uses stale cache if available
});
```

### Handling Precondition Failures

```javascript
async function handleConditionalUpdate(url, data, etag, maxRetries = 3) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    const response = await fetch(url, {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        'If-Match': etag
      },
      body: JSON.stringify(data)
    });
    
    if (response.ok) {
      return { success: true, data: await response.json() };
    }
    
    if (response.status === 412) {
      // Precondition failed - fetch latest version
      const latestResponse = await fetch(url);
      
      if (!latestResponse.ok) {
        return { success: false, error: 'fetch_failed' };
      }
      
      etag = latestResponse.headers.get('ETag');
      const latestData = await latestResponse.json();
      
      // Attempt to merge changes
      const merged = mergeData(latestData, data);
      data = merged;
      
      // Retry with new ETag
      continue;
    }
    
    return { success: false, error: `http_${response.status}` };
  }
  
  return { success: false, error: 'max_retries_exceeded' };
}

function mergeData(base, changes) {
  // Application-specific merge logic
  return { ...base, ...changes };
}
```

### Conditional Requests with Service Workers

Service workers can implement conditional request caching strategies.

```javascript
// In service worker
self.addEventListener('fetch', (event) => {
  if (event.request.method !== 'GET') return;
  
  event.respondWith(
    caches.open('conditional-cache').then(async (cache) => {
      const cached = await cache.match(event.request);
      
      if (cached) {
        const etag = cached.headers.get('ETag');
        const lastModified = cached.headers.get('Last-Modified');
        
        // Create new request with conditional headers
        const headers = new Headers(event.request.headers);
        if (etag) headers.set('If-None-Match', etag);
        if (lastModified) headers.set('If-Modified-Since', lastModified);
        
        const conditionalRequest = new Request(event.request.url, {
          method: event.request.method,
          headers: headers
        });
        
        const response = await fetch(conditionalRequest);
        
        if (response.status === 304) {
          // Return cached response
          return cached;
        }
        
        if (response.ok) {
          // Update cache
          cache.put(event.request, response.clone());
          return response;
        }
      }
      
      // No cache or error - normal fetch
      const response = await fetch(event.request);
      
      if (response.ok) {
        cache.put(event.request, response.clone());
      }
      
      return response;
    })
  );
});
```

### Time-Based Cache Invalidation

Combining conditional requests with time-based cache invalidation provides a balance between freshness and efficiency.

```javascript
class TimedConditionalCache {
  constructor(maxAge = 300000) { // 5 minutes default
    this.maxAge = maxAge;
    this.cache = new Map();
  }
  
  async fetch(url, options = {}) {
    const cached = this.cache.get(url);
    const now = Date.now();
    
    // Check if cache is fresh enough
    if (cached && (now - cached.timestamp) < this.maxAge) {
      return cached.data;
    }
    
    // Cache expired or doesn't exist - use conditional request
    const headers = new Headers(options.headers || {});
    
    if (cached) {
      if (cached.etag) headers.set('If-None-Match', cached.etag);
      if (cached.lastModified) headers.set('If-Modified-Since', cached.lastModified);
    }
    
    const response = await fetch(url, { ...options, headers });
    
    if (response.status === 304 && cached) {
      // Update timestamp but keep data
      cached.timestamp = now;
      return cached.data;
    }
    
    if (response.ok) {
      const data = await response.json();
      
      this.cache.set(url, {
        data,
        etag: response.headers.get('ETag'),
        lastModified: response.headers.get('Last-Modified'),
        timestamp: now
      });
      
      return data;
    }
    
    throw new Error(`HTTP ${response.status}`);
  }
  
  invalidate(url) {
    if (url) {
      this.cache.delete(url);
    } else {
      this.cache.clear();
    }
  }
}
```

### GraphQL with Conditional Requests

[Inference] GraphQL APIs can leverage ETags for query result caching, though this depends on server implementation.

```javascript
async function graphqlWithCache(query, variables = {}) {
  const cacheKey = `graphql:${btoa(JSON.stringify({ query, variables }))}`;
  const cached = localStorage.getItem(cacheKey);
  
  let headers = {
    'Content-Type': 'application/json'
  };
  
  if (cached) {
    const { etag } = JSON.parse(cached);
    if (etag) {
      headers['If-None-Match'] = etag;
    }
  }
  
  const response = await fetch('/graphql', {
    method: 'POST',
    headers,
    body: JSON.stringify({ query, variables })
  });
  
  if (response.status === 304) {
    const { data } = JSON.parse(cached);
    return data;
  }
  
  if (response.ok) {
    const result = await response.json();
    const etag = response.headers.get('ETag');
    
    if (etag) {
      localStorage.setItem(cacheKey, JSON.stringify({
        data: result.data,
        etag
      }));
    }
    
    return result.data;
  }
  
  throw new Error(`GraphQL request failed: ${response.status}`);
}
```

---

## Service Worker Caching with Fetch API

### Cache Storage API Fundamentals

Service workers access caches through the CacheStorage interface, available via the global `caches` object:

```javascript
// Open or create a cache
const cache = await caches.open('my-cache-v1');

// Add single resource
await cache.add('/styles.css');

// Add multiple resources
await cache.addAll([
  '/index.html',
  '/styles.css',
  '/script.js',
  '/image.png'
]);

// Store custom response
await cache.put('/api/data', new Response('{"key":"value"}'));

// Retrieve cached response
const response = await cache.match('/styles.css');

// Delete cached response
await cache.delete('/styles.css');

// Get all cached request URLs
const requests = await cache.keys();
```

### Cache Lifecycle Management

Managing cache versions and cleanup:

```javascript
const CACHE_VERSION = 'v2';
const CACHE_NAME = `my-app-${CACHE_VERSION}`;

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME).then(cache => {
      return cache.addAll([
        '/',
        '/index.html',
        '/styles.css',
        '/script.js'
      ]);
    })
  );
  
  // Activate immediately without waiting
  self.skipWaiting();
});

self.addEventListener('activate', event => {
  event.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames
          .filter(name => name !== CACHE_NAME)
          .map(name => caches.delete(name))
      );
    })
  );
  
  // Take control of all clients immediately
  return self.clients.claim();
});
```

### Caching Strategies

#### Cache First (Cache Falling Back to Network)

Prioritizes cached content, fetches from network if cache miss:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      if (cached) {
        return cached;
      }
      
      return fetch(event.request).then(response => {
        // Clone response before caching
        const responseClone = response.clone();
        
        caches.open(CACHE_NAME).then(cache => {
          cache.put(event.request, responseClone);
        });
        
        return response;
      });
    })
  );
});
```

#### Network First (Network Falling Back to Cache)

Attempts network first, falls back to cache on failure:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request)
      .then(response => {
        const responseClone = response.clone();
        
        caches.open(CACHE_NAME).then(cache => {
          cache.put(event.request, responseClone);
        });
        
        return response;
      })
      .catch(() => {
        return caches.match(event.request);
      })
  );
});
```

#### Stale While Revalidate

Returns cached content immediately while fetching fresh content in background:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      const fetchPromise = fetch(event.request).then(response => {
        const responseClone = response.clone();
        
        caches.open(CACHE_NAME).then(cache => {
          cache.put(event.request, responseClone);
        });
        
        return response;
      });
      
      // Return cached immediately, update cache in background
      return cached || fetchPromise;
    })
  );
});
```

#### Network Only

Always fetches from network, bypasses cache:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(fetch(event.request));
});
```

#### Cache Only

Only serves cached content, never fetches from network:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(caches.match(event.request));
});
```

### Strategy-Based Routing

Applying different strategies based on request characteristics:

```javascript
self.addEventListener('fetch', event => {
  const { request } = event;
  const url = new URL(request.url);
  
  // Cache first for static assets
  if (url.pathname.match(/\.(css|js|png|jpg|jpeg|gif|svg|woff2?)$/)) {
    event.respondWith(cacheFirst(request));
    return;
  }
  
  // Network first for API calls
  if (url.pathname.startsWith('/api/')) {
    event.respondWith(networkFirst(request));
    return;
  }
  
  // Stale while revalidate for HTML pages
  if (request.headers.get('Accept').includes('text/html')) {
    event.respondWith(staleWhileRevalidate(request));
    return;
  }
  
  // Network only for everything else
  event.respondWith(fetch(request));
});

async function cacheFirst(request) {
  const cached = await caches.match(request);
  if (cached) return cached;
  
  const response = await fetch(request);
  const cache = await caches.open(CACHE_NAME);
  cache.put(request, response.clone());
  return response;
}

async function networkFirst(request) {
  try {
    const response = await fetch(request);
    const cache = await caches.open(CACHE_NAME);
    cache.put(request, response.clone());
    return response;
  } catch (error) {
    const cached = await caches.match(request);
    if (cached) return cached;
    throw error;
  }
}

async function staleWhileRevalidate(request) {
  const cached = await caches.match(request);
  
  const fetchPromise = fetch(request).then(response => {
    caches.open(CACHE_NAME).then(cache => {
      cache.put(request, response.clone());
    });
    return response;
  });
  
  return cached || fetchPromise;
}
```

### Request Matching Options

Fine-grained control over cache matching:

```javascript
// Ignore query parameters
const response = await cache.match(request, {
  ignoreSearch: true
});

// Ignore request method (match GET for POST)
const response = await cache.match(request, {
  ignoreMethod: true
});

// Ignore vary header
const response = await cache.match(request, {
  ignoreVary: true
});

// Complete control
const response = await cache.match(request, {
  ignoreSearch: true,
  ignoreMethod: false,
  ignoreVary: false
});
```

### Conditional Caching

Caching based on response characteristics:

```javascript
self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request).then(response => {
      // Only cache successful responses
      if (!response || response.status !== 200 || response.type === 'error') {
        return response;
      }
      
      // Only cache specific content types
      const contentType = response.headers.get('Content-Type');
      if (!contentType || !contentType.includes('text/html')) {
        return response;
      }
      
      // Check response size
      const contentLength = response.headers.get('Content-Length');
      if (contentLength && parseInt(contentLength) > 5 * 1024 * 1024) {
        // Skip caching files over 5MB
        return response;
      }
      
      const responseClone = response.clone();
      
      caches.open(CACHE_NAME).then(cache => {
        cache.put(event.request, responseClone);
      });
      
      return response;
    })
  );
});
```

### Cache Expiration

Implementing time-based cache invalidation:

```javascript
const CACHE_EXPIRATION = 24 * 60 * 60 * 1000; // 24 hours

async function getCachedWithExpiration(request) {
  const cache = await caches.open(CACHE_NAME);
  const cached = await cache.match(request);
  
  if (!cached) return null;
  
  // Check custom expiration header
  const cachedTime = cached.headers.get('sw-cached-time');
  
  if (cachedTime) {
    const age = Date.now() - parseInt(cachedTime);
    if (age > CACHE_EXPIRATION) {
      // Expired, delete from cache
      await cache.delete(request);
      return null;
    }
  }
  
  return cached;
}

async function cacheWithExpiration(request, response) {
  const cache = await caches.open(CACHE_NAME);
  
  // Add timestamp header
  const headers = new Headers(response.headers);
  headers.set('sw-cached-time', Date.now().toString());
  
  const modifiedResponse = new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers: headers
  });
  
  await cache.put(request, modifiedResponse);
}

self.addEventListener('fetch', event => {
  event.respondWith(
    getCachedWithExpiration(event.request).then(cached => {
      if (cached) return cached;
      
      return fetch(event.request).then(response => {
        cacheWithExpiration(event.request, response.clone());
        return response;
      });
    })
  );
});
```

### Cache Quota Management

Monitoring and managing storage usage:

```javascript
async function getCacheSize(cacheName) {
  const cache = await caches.open(cacheName);
  const keys = await cache.keys();
  
  let totalSize = 0;
  
  for (const request of keys) {
    const response = await cache.match(request);
    const blob = await response.blob();
    totalSize += blob.size;
  }
  
  return totalSize;
}

async function enforceQuota(maxSize) {
  const cache = await caches.open(CACHE_NAME);
  const keys = await cache.keys();
  
  // Build array with sizes and timestamps
  const entries = [];
  
  for (const request of keys) {
    const response = await cache.match(request);
    const blob = await response.blob();
    const timestamp = response.headers.get('sw-cached-time') || '0';
    
    entries.push({
      request,
      size: blob.size,
      timestamp: parseInt(timestamp)
    });
  }
  
  // Sort by timestamp (oldest first)
  entries.sort((a, b) => a.timestamp - b.timestamp);
  
  let currentSize = entries.reduce((sum, e) => sum + e.size, 0);
  
  // Remove oldest entries until under quota
  for (const entry of entries) {
    if (currentSize <= maxSize) break;
    
    await cache.delete(entry.request);
    currentSize -= entry.size;
  }
}

// Run periodically
self.addEventListener('activate', event => {
  event.waitUntil(
    enforceQuota(50 * 1024 * 1024) // 50MB limit
  );
});
```

### Precaching Strategy

Loading critical resources during installation:

```javascript
const PRECACHE_URLS = [
  '/',
  '/index.html',
  '/styles/main.css',
  '/scripts/app.js',
  '/images/logo.png',
  '/fonts/roboto.woff2'
];

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME).then(cache => {
      return cache.addAll(PRECACHE_URLS);
    }).then(() => {
      return self.skipWaiting();
    })
  );
});

// Serve precached resources with cache-first strategy
self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  if (PRECACHE_URLS.includes(url.pathname)) {
    event.respondWith(
      caches.match(event.request).then(cached => {
        return cached || fetch(event.request);
      })
    );
  }
});
```

### Runtime Caching

Dynamically caching resources as they're requested:

```javascript
const RUNTIME_CACHE = 'runtime-cache-v1';
const MAX_RUNTIME_ENTRIES = 50;

async function addToRuntimeCache(request, response) {
  const cache = await caches.open(RUNTIME_CACHE);
  
  // Enforce max entries
  const keys = await cache.keys();
  
  if (keys.length >= MAX_RUNTIME_ENTRIES) {
    // Remove first (oldest) entry
    await cache.delete(keys[0]);
  }
  
  await cache.put(request, response);
}

self.addEventListener('fetch', event => {
  // Skip non-GET requests
  if (event.request.method !== 'GET') {
    return;
  }
  
  event.respondWith(
    fetch(event.request)
      .then(response => {
        // Only cache successful responses
        if (response.status === 200) {
          addToRuntimeCache(event.request, response.clone());
        }
        return response;
      })
      .catch(() => {
        return caches.match(event.request);
      })
  );
});
```

### Offline Fallback

Serving fallback content when offline:

```javascript
const OFFLINE_PAGE = '/offline.html';
const OFFLINE_IMAGE = '/images/offline.png';

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME).then(cache => {
      return cache.addAll([OFFLINE_PAGE, OFFLINE_IMAGE]);
    })
  );
});

self.addEventListener('fetch', event => {
  event.respondWith(
    fetch(event.request)
      .catch(() => {
        return caches.match(event.request).then(cached => {
          if (cached) return cached;
          
          // Serve offline page for navigation requests
          if (event.request.mode === 'navigate') {
            return caches.match(OFFLINE_PAGE);
          }
          
          // Serve offline image for image requests
          if (event.request.destination === 'image') {
            return caches.match(OFFLINE_IMAGE);
          }
          
          // Return minimal response for other requests
          return new Response('Offline', {
            status: 503,
            statusText: 'Service Unavailable',
            headers: new Headers({
              'Content-Type': 'text/plain'
            })
          });
        });
      })
  );
});
```

### Cache Versioning and Migration

Managing multiple cache versions:

```javascript
const CACHE_CONFIG = {
  static: 'static-v1',
  dynamic: 'dynamic-v1',
  api: 'api-v1'
};

self.addEventListener('install', event => {
  event.waitUntil(
    Promise.all([
      caches.open(CACHE_CONFIG.static).then(cache => {
        return cache.addAll([
          '/index.html',
          '/styles.css',
          '/script.js'
        ]);
      }),
      caches.open(CACHE_CONFIG.dynamic),
      caches.open(CACHE_CONFIG.api)
    ])
  );
});

self.addEventListener('activate', event => {
  const validCaches = Object.values(CACHE_CONFIG);
  
  event.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames
          .filter(name => !validCaches.includes(name))
          .map(name => caches.delete(name))
      );
    })
  );
});

self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  // Route to appropriate cache
  if (url.pathname.startsWith('/api/')) {
    event.respondWith(handleApiRequest(event.request));
  } else if (url.pathname.match(/\.(css|js|png)$/)) {
    event.respondWith(handleStaticRequest(event.request));
  } else {
    event.respondWith(handleDynamicRequest(event.request));
  }
});

async function handleStaticRequest(request) {
  const cache = await caches.open(CACHE_CONFIG.static);
  const cached = await cache.match(request);
  return cached || fetch(request);
}

async function handleDynamicRequest(request) {
  const cache = await caches.open(CACHE_CONFIG.dynamic);
  
  try {
    const response = await fetch(request);
    cache.put(request, response.clone());
    return response;
  } catch (error) {
    return await cache.match(request);
  }
}

async function handleApiRequest(request) {
  const cache = await caches.open(CACHE_CONFIG.api);
  
  const fetchPromise = fetch(request).then(response => {
    if (response.ok) {
      cache.put(request, response.clone());
    }
    return response;
  });
  
  const cached = await cache.match(request);
  return cached || fetchPromise;
}
```

### Cache Warming

Preloading resources based on usage patterns:

```javascript
// Warm cache with likely next pages
async function warmCache(urls) {
  const cache = await caches.open(CACHE_NAME);
  
  for (const url of urls) {
    try {
      const response = await fetch(url);
      if (response.ok) {
        await cache.put(url, response);
      }
    } catch (error) {
      console.log(`Failed to warm cache for ${url}`);
    }
  }
}

self.addEventListener('message', event => {
  if (event.data.type === 'WARM_CACHE') {
    event.waitUntil(warmCache(event.data.urls));
  }
});

// In page context
navigator.serviceWorker.controller.postMessage({
  type: 'WARM_CACHE',
  urls: ['/page2.html', '/page3.html', '/data.json']
});
```

### Background Sync for Cache Updates

Updating cache when connectivity is restored:

```javascript
self.addEventListener('sync', event => {
  if (event.tag === 'update-cache') {
    event.waitUntil(updateCache());
  }
});

async function updateCache() {
  const cache = await caches.open(CACHE_NAME);
  const keys = await cache.keys();
  
  const updatePromises = keys.map(async request => {
    try {
      const response = await fetch(request);
      if (response.ok) {
        await cache.put(request, response);
      }
    } catch (error) {
      // Network error, skip update
    }
  });
  
  await Promise.all(updatePromises);
}

// Register sync from page
navigator.serviceWorker.ready.then(registration => {
  return registration.sync.register('update-cache');
});
```

### Cache Debugging and Inspection

Tools for monitoring cache state:

```javascript
// Expose cache inspection via message
self.addEventListener('message', async event => {
  if (event.data.type === 'GET_CACHE_INFO') {
    const cacheNames = await caches.keys();
    const info = {};
    
    for (const name of cacheNames) {
      const cache = await caches.open(name);
      const keys = await cache.keys();
      
      info[name] = {
        count: keys.length,
        urls: keys.map(req => req.url)
      };
    }
    
    event.ports[0].postMessage(info);
  }
  
  if (event.data.type === 'CLEAR_CACHE') {
    const cacheNames = await caches.keys();
    await Promise.all(cacheNames.map(name => caches.delete(name)));
    event.ports[0].postMessage({ success: true });
  }
});

// In page context
async function getCacheInfo() {
  const messageChannel = new MessageChannel();
  
  return new Promise(resolve => {
    messageChannel.port1.onmessage = event => {
      resolve(event.data);
    };
    
    navigator.serviceWorker.controller.postMessage(
      { type: 'GET_CACHE_INFO' },
      [messageChannel.port2]
    );
  });
}

async function clearAllCaches() {
  const messageChannel = new MessageChannel();
  
  return new Promise(resolve => {
    messageChannel.port1.onmessage = event => {
      resolve(event.data);
    };
    
    navigator.serviceWorker.controller.postMessage(
      { type: 'CLEAR_CACHE' },
      [messageChannel.port2]
    );
  });
}
```

### Cross-Origin Resource Caching

Handling CORS and opaque responses:

```javascript
self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  // Cross-origin request
  if (url.origin !== self.location.origin) {
    event.respondWith(handleCrossOrigin(event.request));
    return;
  }
  
  // Same-origin request
  event.respondWith(handleSameOrigin(event.request));
});

async function handleCrossOrigin(request) {
  const cached = await caches.match(request);
  if (cached) return cached;
  
  try {
    // Opaque responses (no-cors mode)
    const response = await fetch(request, { mode: 'no-cors' });
    
    // Note: Cannot read opaque response details
    // response.status will be 0, response.ok will be false
    
    const cache = await caches.open(CACHE_NAME);
    await cache.put(request, response.clone());
    
    return response;
  } catch (error) {
    return cached || new Response('Network error', { status: 408 });
  }
}

async function handleSameOrigin(request) {
  try {
    const response = await fetch(request);
    
    if (response.ok) {
      const cache = await caches.open(CACHE_NAME);
      await cache.put(request, response.clone());
    }
    
    return response;
  } catch (error) {
    return await caches.match(request);
  }
}
```

### Selective Cache Invalidation

Removing specific cached resources:

```javascript
async function invalidateCache(pattern) {
  const cacheNames = await caches.keys();
  
  for (const name of cacheNames) {
    const cache = await caches.open(name);
    const requests = await cache.keys();
    
    for (const request of requests) {
      if (pattern.test(request.url)) {
        await cache.delete(request);
      }
    }
  }
}

self.addEventListener('message', event => {
  if (event.data.type === 'INVALIDATE_CACHE') {
    const pattern = new RegExp(event.data.pattern);
    event.waitUntil(invalidateCache(pattern));
  }
});

// Invalidate all API responses
navigator.serviceWorker.controller.postMessage({
  type: 'INVALIDATE_CACHE',
  pattern: '/api/'
});

// Invalidate specific resource
navigator.serviceWorker.controller.postMessage({
  type: 'INVALIDATE_CACHE',
  pattern: '/images/old-logo\\.png$'
});
```

### Cache Performance Monitoring

Tracking cache hit rates and performance:

```javascript
const cacheStats = {
  hits: 0,
  misses: 0,
  errors: 0
};

self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      if (cached) {
        cacheStats.hits++;
        return cached;
      }
      
      cacheStats.misses++;
      
      return fetch(event.request)
        .then(response => {
          const cache = caches.open(CACHE_NAME);
          cache.then(c => c.put(event.request, response.clone()));
          return response;
        })
        .catch(error => {
          cacheStats.errors++;
          throw error;
        });
    })
  );
});

self.addEventListener('message', event => {
  if (event.data.type === 'GET_STATS') {
    const total = cacheStats.hits + cacheStats.misses;
    const hitRate = total > 0 ? (cacheStats.hits / total * 100).toFixed(2) : 0;
    
    event.ports[0].postMessage({
      ...cacheStats,
      hitRate: `${hitRate}%`,
      total
    });
  }
  
  if (event.data.type === 'RESET_STATS') {
    cacheStats.hits = 0;
    cacheStats.misses = 0;
    cacheStats.errors = 0;
    event.ports[0].postMessage({ success: true });
  }
});
```

### Streamed Response Caching

Caching while streaming to client:

```javascript
async function cacheAndStream(request) {
  const response = await fetch(request);
  
  const cache = await caches.open(CACHE_NAME);
  
  // Create readable stream that tees the response
  const { readable, writable } = new TransformStream();
  
  const reader = response.body.getReader();
  const writer = writable.getWriter();
  const chunks = [];
  
  // Stream to both client and cache
  reader.read().then(function processChunk({ done, value }) {
    if (done) {
      writer.close();
      
      // Store complete response in cache
      const blob = new Blob(chunks);
      const cachedResponse = new Response(blob, {
        status: response.status,
        statusText: response.statusText,
        headers: response.headers
      });
      
      cache.put(request, cachedResponse);
      return;
    }
    
    chunks.push(value);
    writer.write(value);
    
    return reader.read().then(processChunk);
  });
  
  return new Response(readable, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}
```

### Cache Prioritization

Prioritizing important resources:

```javascript
const CACHE_PRIORITIES = {
  critical: ['/', '/index.html', '/app.js', '/styles.css'],
  high: ['/images/logo.png', '/fonts/main.woff2'],
  medium: ['/api/user', '/api/settings'],
  low: ['/api/analytics', '/tracking.js']
};

async function enforcePriority() {
  const cache = await caches.open(CACHE_NAME);
  const requests = await cache.keys();
  
  // Calculate current cache size
  let totalSize = 0;
  const entries = [];
  
  for (const request of requests) {
    const response = await cache.match(request);
    const blob = await response.blob();
    const priority = getPriority(request.url);
    
    entries.push({
      request,
      size: blob.size,
      priority
    });
    
    totalSize += blob.size;
  }
  
  // If over quota, remove lowest priority items
  const MAX_SIZE = 50 * 1024 * 1024; // 50MB
  
  if (totalSize > MAX_SIZE) {
    entries.sort((a, b) => a.priority - b.priority);
    
    for (const entry of entries) {
      if (totalSize <= MAX_SIZE) break;
      
      if (entry.priority >= 3) { // Only remove low priority
        await cache.delete(entry.request);
        totalSize -= entry.size;
      }
    }
  }
}

function getPriority(url) {
  if (CACHE_PRIORITIES.critical.some(u => url.includes(u))) return 0;
  if (CACHE_PRIORITIES.high.some(u => url.includes(u))) return 1;
  if (CACHE_PRIORITIES.medium.some(u => url.includes(u))) return 2;
  return 3; // low priority
}
```

---

## Cache-First Strategies

### Core Concept

Cache-first strategies prioritize serving resources from the cache before attempting network requests. The browser or service worker checks the cache first; only if the resource is not found does it fall back to the network. This approach optimizes for speed and offline functionality.

### Basic Cache-First Implementation

#### Service Worker Pattern

```javascript
self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request)
      .then((cachedResponse) => {
        if (cachedResponse) {
          return cachedResponse;
        }
        return fetch(event.request);
      })
  );
});
```

#### With Cache Population

```javascript
self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request)
      .then((cachedResponse) => {
        if (cachedResponse) {
          return cachedResponse;
        }
        
        return fetch(event.request).then((networkResponse) => {
          // Cache the network response for future requests
          return caches.open('dynamic-cache-v1').then((cache) => {
            cache.put(event.request, networkResponse.clone());
            return networkResponse;
          });
        });
      })
  );
});
```

### Strategy Variants

#### Cache-First with Network Fallback

The standard pattern where cache is always checked first:

```javascript
async function cacheFirst(request) {
  const cachedResponse = await caches.match(request);
  
  if (cachedResponse) {
    return cachedResponse;
  }
  
  try {
    const networkResponse = await fetch(request);
    
    if (networkResponse.ok) {
      const cache = await caches.open('runtime-cache');
      cache.put(request, networkResponse.clone());
    }
    
    return networkResponse;
  } catch (error) {
    // Network failed and no cache available
    return new Response('Network error occurred', {
      status: 408,
      headers: { 'Content-Type': 'text/plain' }
    });
  }
}

self.addEventListener('fetch', (event) => {
  event.respondWith(cacheFirst(event.request));
});
```

#### Cache-First with Timeout

Attempt network request if cache lookup takes too long:

```javascript
async function cacheFirstWithTimeout(request, timeout = 500) {
  const cachePromise = caches.match(request);
  const timeoutPromise = new Promise((resolve) => {
    setTimeout(() => resolve(null), timeout);
  });
  
  const cachedResponse = await Promise.race([
    cachePromise,
    timeoutPromise
  ]);
  
  if (cachedResponse) {
    return cachedResponse;
  }
  
  // Cache lookup timed out or returned nothing
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    const cache = await caches.open('runtime-cache');
    cache.put(request, networkResponse.clone());
  }
  
  return networkResponse;
}
```

#### Cache-First with Background Update (Stale-While-Revalidate)

Return cached content immediately while updating cache in background:

```javascript
async function cacheFirstBackgroundUpdate(request) {
  const cachedResponse = await caches.match(request);
  
  // Initiate background fetch
  const fetchPromise = fetch(request).then((networkResponse) => {
    if (networkResponse.ok) {
      caches.open('dynamic-cache').then((cache) => {
        cache.put(request, networkResponse.clone());
      });
    }
    return networkResponse;
  });
  
  // Return cached version immediately, or wait for network
  return cachedResponse || fetchPromise;
}
```

### Selective Caching Strategies

#### By Resource Type

```javascript
self.addEventListener('fetch', (event) => {
  const { request } = event;
  const url = new URL(request.url);
  
  // Images: cache-first with long TTL
  if (request.destination === 'image') {
    event.respondWith(cacheFirstImage(request));
  }
  // Scripts and styles: cache-first with versioning
  else if (request.destination === 'script' || request.destination === 'style') {
    event.respondWith(cacheFirstAsset(request));
  }
  // API calls: network-first
  else if (url.pathname.startsWith('/api/')) {
    event.respondWith(networkFirst(request));
  }
  // Everything else: cache-first
  else {
    event.respondWith(cacheFirst(request));
  }
});
```

#### By URL Pattern

```javascript
const CACHE_STRATEGIES = {
  static: /\.(js|css|png|jpg|jpeg|svg|gif|woff2?)$/,
  api: /\/api\//,
  pages: /\.(html|htm)$/
};

self.addEventListener('fetch', (event) => {
  const url = new URL(event.request.url);
  
  if (CACHE_STRATEGIES.static.test(url.pathname)) {
    event.respondWith(cacheFirstLongTerm(event.request));
  } else if (CACHE_STRATEGIES.api.test(url.pathname)) {
    event.respondWith(networkFirstWithCache(event.request));
  } else if (CACHE_STRATEGIES.pages.test(url.pathname)) {
    event.respondWith(cacheFirstWithUpdate(event.request));
  } else {
    event.respondWith(fetch(event.request));
  }
});
```

### Cache Expiration and Freshness

#### Time-Based Expiration

```javascript
const CACHE_DURATION = 24 * 60 * 60 * 1000; // 24 hours

async function cacheFirstWithExpiration(request) {
  const cache = await caches.open('timed-cache');
  const cachedResponse = await cache.match(request);
  
  if (cachedResponse) {
    const cachedDate = new Date(cachedResponse.headers.get('sw-cached-date'));
    const now = new Date();
    
    if (now - cachedDate < CACHE_DURATION) {
      return cachedResponse;
    }
    
    // Cache expired, delete and fetch fresh
    await cache.delete(request);
  }
  
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    const responseToCache = networkResponse.clone();
    const headers = new Headers(responseToCache.headers);
    headers.append('sw-cached-date', new Date().toISOString());
    
    const responseWithDate = new Response(responseToCache.body, {
      status: responseToCache.status,
      statusText: responseToCache.statusText,
      headers: headers
    });
    
    await cache.put(request, responseWithDate);
  }
  
  return networkResponse;
}
```

#### ETag-Based Validation

```javascript
async function cacheFirstWithETag(request) {
  const cache = await caches.open('etag-cache');
  const cachedResponse = await cache.match(request);
  
  if (cachedResponse) {
    const etag = cachedResponse.headers.get('etag');
    
    if (etag) {
      // Send conditional request
      const conditionalRequest = new Request(request, {
        headers: {
          'If-None-Match': etag
        }
      });
      
      try {
        const networkResponse = await fetch(conditionalRequest);
        
        if (networkResponse.status === 304) {
          // Not modified, return cached version
          return cachedResponse;
        }
        
        // Modified, cache new version
        if (networkResponse.ok) {
          await cache.put(request, networkResponse.clone());
        }
        
        return networkResponse;
      } catch (error) {
        // Network error, return cached version
        return cachedResponse;
      }
    }
    
    return cachedResponse;
  }
  
  // No cache, fetch from network
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    await cache.put(request, networkResponse.clone());
  }
  
  return networkResponse;
}
```

### Cache Management

#### Size-Limited Cache

```javascript
class CacheManager {
  constructor(cacheName, maxItems = 50) {
    this.cacheName = cacheName;
    this.maxItems = maxItems;
  }
  
  async put(request, response) {
    const cache = await caches.open(this.cacheName);
    await cache.put(request, response);
    await this.trimCache();
  }
  
  async trimCache() {
    const cache = await caches.open(this.cacheName);
    const keys = await cache.keys();
    
    if (keys.length > this.maxItems) {
      // Remove oldest entries (FIFO)
      const keysToDelete = keys.slice(0, keys.length - this.maxItems);
      
      await Promise.all(
        keysToDelete.map(key => cache.delete(key))
      );
    }
  }
  
  async match(request) {
    const cache = await caches.open(this.cacheName);
    return cache.match(request);
  }
}

const imageCache = new CacheManager('images-v1', 100);

async function cacheFirstManagedSize(request) {
  const cachedResponse = await imageCache.match(request);
  
  if (cachedResponse) {
    return cachedResponse;
  }
  
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    await imageCache.put(request, networkResponse.clone());
  }
  
  return networkResponse;
}
```

#### LRU Cache Implementation

```javascript
class LRUCache {
  constructor(cacheName, maxItems = 50) {
    this.cacheName = cacheName;
    this.maxItems = maxItems;
    this.accessLog = [];
  }
  
  async match(request) {
    const cache = await caches.open(this.cacheName);
    const response = await cache.match(request);
    
    if (response) {
      // Update access order
      const url = request.url || request;
      this.accessLog = this.accessLog.filter(u => u !== url);
      this.accessLog.push(url);
    }
    
    return response;
  }
  
  async put(request, response) {
    const cache = await caches.open(this.cacheName);
    const url = request.url || request;
    
    await cache.put(request, response);
    
    this.accessLog = this.accessLog.filter(u => u !== url);
    this.accessLog.push(url);
    
    await this.trimCache(cache);
  }
  
  async trimCache(cache) {
    const keys = await cache.keys();
    
    if (keys.length > this.maxItems) {
      const urlsToKeep = new Set(
        this.accessLog.slice(-this.maxItems)
      );
      
      const keysToDelete = keys.filter(
        key => !urlsToKeep.has(key.url)
      );
      
      await Promise.all(
        keysToDelete.map(key => cache.delete(key))
      );
    }
  }
}
```

### Offline-First Patterns

#### Complete Offline Support

```javascript
const STATIC_CACHE = 'static-v1';
const DYNAMIC_CACHE = 'dynamic-v1';

const STATIC_ASSETS = [
  '/',
  '/index.html',
  '/styles/main.css',
  '/scripts/app.js',
  '/offline.html'
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(STATIC_CACHE)
      .then((cache) => cache.addAll(STATIC_ASSETS))
  );
});

self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request)
      .then((cachedResponse) => {
        if (cachedResponse) {
          return cachedResponse;
        }
        
        return fetch(event.request)
          .then((networkResponse) => {
            // Only cache successful GET requests
            if (event.request.method === 'GET' && networkResponse.ok) {
              const responseToCache = networkResponse.clone();
              
              caches.open(DYNAMIC_CACHE)
                .then((cache) => {
                  cache.put(event.request, responseToCache);
                });
            }
            
            return networkResponse;
          })
          .catch(() => {
            // Network failed, return offline page for navigation requests
            if (event.request.mode === 'navigate') {
              return caches.match('/offline.html');
            }
          });
      })
  );
});
```

#### Offline Queue for Mutations

```javascript
class OfflineQueue {
  constructor() {
    this.queue = [];
    this.storageKey = 'offline-queue';
    this.loadQueue();
  }
  
  async loadQueue() {
    const stored = await this.getFromStorage();
    this.queue = stored || [];
  }
  
  async add(request) {
    const requestData = {
      url: request.url,
      method: request.method,
      headers: Object.fromEntries(request.headers.entries()),
      body: await request.text(),
      timestamp: Date.now()
    };
    
    this.queue.push(requestData);
    await this.saveQueue();
  }
  
  async process() {
    const failedRequests = [];
    
    for (const requestData of this.queue) {
      try {
        const response = await fetch(requestData.url, {
          method: requestData.method,
          headers: requestData.headers,
          body: requestData.body
        });
        
        if (!response.ok) {
          failedRequests.push(requestData);
        }
      } catch (error) {
        failedRequests.push(requestData);
      }
    }
    
    this.queue = failedRequests;
    await this.saveQueue();
    
    return this.queue.length === 0;
  }
  
  async saveQueue() {
    await this.saveToStorage(this.queue);
  }
  
  async getFromStorage() {
    const data = await caches.open('queue-storage')
      .then(cache => cache.match(this.storageKey))
      .then(response => response ? response.json() : null);
    return data;
  }
  
  async saveToStorage(data) {
    const response = new Response(JSON.stringify(data));
    const cache = await caches.open('queue-storage');
    await cache.put(this.storageKey, response);
  }
}

const offlineQueue = new OfflineQueue();

self.addEventListener('fetch', (event) => {
  if (event.request.method !== 'GET') {
    event.respondWith(
      fetch(event.request).catch(() => {
        offlineQueue.add(event.request.clone());
        return new Response(JSON.stringify({ queued: true }), {
          headers: { 'Content-Type': 'application/json' }
        });
      })
    );
  }
});

self.addEventListener('online', () => {
  offlineQueue.process();
});
```

### Performance Optimization

#### Parallel Cache and Network

Race cache against network, return whichever completes first:

```javascript
async function raceStrategy(request) {
  return new Promise((resolve, reject) => {
    let resolved = false;
    
    const maybeResolve = (response) => {
      if (!resolved) {
        resolved = true;
        resolve(response);
      }
    };
    
    const maybeReject = (error) => {
      if (!resolved) {
        resolved = true;
        reject(error);
      }
    };
    
    // Try cache
    caches.match(request)
      .then(cachedResponse => {
        if (cachedResponse) {
          maybeResolve(cachedResponse);
        }
      })
      .catch(() => {});
    
    // Try network
    fetch(request)
      .then(networkResponse => {
        maybeResolve(networkResponse);
        
        if (networkResponse.ok) {
          caches.open('race-cache').then(cache => {
            cache.put(request, networkResponse.clone());
          });
        }
      })
      .catch(maybeReject);
  });
}
```

#### Prefetch Critical Resources

```javascript
self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open('prefetch-v1').then(async (cache) => {
      // Prefetch critical resources
      const criticalResources = [
        '/api/user/profile',
        '/api/content/featured',
        '/api/navigation/menu'
      ];
      
      const responses = await Promise.allSettled(
        criticalResources.map(url => fetch(url))
      );
      
      responses.forEach((result, index) => {
        if (result.status === 'fulfilled' && result.value.ok) {
          cache.put(criticalResources[index], result.value);
        }
      });
    })
  );
});
```

### Advanced Patterns

#### Cache Hierarchy

Multiple cache layers with different priorities:

```javascript
const CACHE_HIERARCHY = [
  'critical-v1',    // Always available
  'frequent-v1',    // Often used
  'occasional-v1'   // Sometimes used
];

async function hierarchicalCache(request) {
  // Check each cache level
  for (const cacheName of CACHE_HIERARCHY) {
    const cache = await caches.open(cacheName);
    const response = await cache.match(request);
    
    if (response) {
      return response;
    }
  }
  
  // Not in any cache, fetch from network
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    // Determine cache level based on usage pattern
    const cacheLevel = determineCacheLevel(request);
    const cache = await caches.open(cacheLevel);
    await cache.put(request, networkResponse.clone());
  }
  
  return networkResponse;
}

function determineCacheLevel(request) {
  // [Inference] Logic to determine appropriate cache level
  // based on URL patterns, content type, or usage statistics
  
  if (request.destination === 'script' || request.destination === 'style') {
    return 'critical-v1';
  } else if (request.destination === 'image') {
    return 'frequent-v1';
  }
  return 'occasional-v1';
}
```

#### Versioned Cache Strategy

```javascript
const VERSION = '1.0.0';
const CACHE_NAME = `app-cache-${VERSION}`;

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((cacheNames) => {
      return Promise.all(
        cacheNames
          .filter((name) => name.startsWith('app-cache-') && name !== CACHE_NAME)
          .map((name) => caches.delete(name))
      );
    })
  );
});

async function versionedCacheFirst(request) {
  const cachedResponse = await caches.match(request);
  
  if (cachedResponse) {
    const cacheVersion = cachedResponse.headers.get('x-cache-version');
    
    if (cacheVersion === VERSION) {
      return cachedResponse;
    }
    
    // Version mismatch, delete old cache entry
    const cache = await caches.open(CACHE_NAME);
    await cache.delete(request);
  }
  
  const networkResponse = await fetch(request);
  
  if (networkResponse.ok) {
    const cache = await caches.open(CACHE_NAME);
    const headers = new Headers(networkResponse.headers);
    headers.append('x-cache-version', VERSION);
    
    const versionedResponse = new Response(networkResponse.body, {
      status: networkResponse.status,
      statusText: networkResponse.statusText,
      headers: headers
    });
    
    await cache.put(request, versionedResponse);
    return networkResponse;
  }
  
  return networkResponse;
}
```

---

## Network-First Strategies with the Fetch API

### Core Concept

Network-first strategies prioritize fetching fresh data from the network, falling back to cached data only when the network is unavailable or fails. This approach ensures users receive the most current data while maintaining offline functionality. The strategy is particularly valuable for dynamic content, API responses, and resources where freshness is critical.

### Basic Network-First Implementation

```javascript
async function networkFirst(request) {
  try {
    const networkResponse = await fetch(request);
    
    if (networkResponse.ok) {
      // Cache the successful response
      const cache = await caches.open('dynamic-v1');
      cache.put(request, networkResponse.clone());
      return networkResponse;
    }
    
    // If network response is not ok, try cache
    return await caches.match(request) || networkResponse;
  } catch (error) {
    // Network failed, try cache
    const cachedResponse = await caches.match(request);
    
    if (cachedResponse) {
      return cachedResponse;
    }
    
    // No cache available, return error response
    return new Response('Network error and no cache available', {
      status: 503,
      statusText: 'Service Unavailable'
    });
  }
}
```

### Network-First with Timeout

Prevent waiting too long for slow network responses:

```javascript
async function networkFirstWithTimeout(request, timeout = 3000) {
  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('Network timeout')), timeout);
  });
  
  try {
    const networkResponse = await Promise.race([
      fetch(request),
      timeoutPromise
    ]);
    
    if (networkResponse.ok) {
      const cache = await caches.open('dynamic-v1');
      cache.put(request, networkResponse.clone());
    }
    
    return networkResponse;
  } catch (error) {
    console.log('Network failed or timed out, using cache');
    
    const cachedResponse = await caches.match(request);
    
    if (cachedResponse) {
      return cachedResponse;
    }
    
    return new Response(JSON.stringify({ error: 'No connection' }), {
      status: 408,
      statusText: 'Request Timeout',
      headers: { 'Content-Type': 'application/json' }
    });
  }
}
```

### Service Worker Integration

Implement network-first in a service worker for comprehensive offline support:

```javascript
// service-worker.js
const CACHE_NAME = 'network-first-v1';
const TIMEOUT = 5000;

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME).then((cache) => {
      return cache.addAll([
        '/offline.html',
        '/offline.css'
      ]);
    })
  );
});

self.addEventListener('fetch', (event) => {
  // Apply network-first to API requests
  if (event.request.url.includes('/api/')) {
    event.respondWith(networkFirstStrategy(event.request));
  }
});

async function networkFirstStrategy(request) {
  const cache = await caches.open(CACHE_NAME);
  
  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), TIMEOUT);
    
    const networkResponse = await fetch(request, {
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (networkResponse.ok) {
      cache.put(request, networkResponse.clone());
    }
    
    return networkResponse;
  } catch (error) {
    console.log('Fetching from cache:', request.url);
    
    const cachedResponse = await cache.match(request);
    
    if (cachedResponse) {
      return cachedResponse;
    }
    
    // Return offline page for navigation requests
    if (request.mode === 'navigate') {
      return cache.match('/offline.html');
    }
    
    return new Response(
      JSON.stringify({ 
        error: 'Network unavailable',
        cached: false 
      }),
      {
        status: 503,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
}
```

### Conditional Network-First

Apply network-first selectively based on request characteristics:

```javascript
class ConditionalNetworkFirst {
  constructor(config = {}) {
    this.cacheName = config.cacheName || 'conditional-cache-v1';
    this.timeout = config.timeout || 5000;
    this.maxAge = config.maxAge || 3600000; // 1 hour default
  }
  
  shouldUseNetworkFirst(request) {
    const url = new URL(request.url);
    
    // Always use network-first for:
    // - POST/PUT/DELETE requests
    // - URLs with query parameters indicating freshness needed
    // - Specific paths
    
    if (request.method !== 'GET') {
      return true;
    }
    
    if (url.searchParams.has('nocache')) {
      return true;
    }
    
    const freshPaths = ['/api/live/', '/api/realtime/', '/api/current/'];
    return freshPaths.some(path => url.pathname.includes(path));
  }
  
  async fetch(request) {
    if (!this.shouldUseNetworkFirst(request)) {
      // Use cache-first for other requests
      return this.cacheFirst(request);
    }
    
    return this.networkFirst(request);
  }
  
  async networkFirst(request) {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), this.timeout);
      
      const response = await fetch(request, {
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        await this.updateCache(request, response.clone());
      }
      
      return response;
    } catch (error) {
      const cached = await this.getCached(request);
      
      if (cached) {
        return this.addStaleHeader(cached);
      }
      
      throw error;
    }
  }
  
  async cacheFirst(request) {
    const cached = await this.getCached(request);
    
    if (cached && !this.isExpired(cached)) {
      return cached;
    }
    
    try {
      const response = await fetch(request);
      
      if (response.ok) {
        await this.updateCache(request, response.clone());
      }
      
      return response;
    } catch (error) {
      if (cached) {
        return this.addStaleHeader(cached);
      }
      throw error;
    }
  }
  
  async updateCache(request, response) {
    const cache = await caches.open(this.cacheName);
    const metadata = {
      timestamp: Date.now(),
      headers: Object.fromEntries(response.headers.entries())
    };
    
    // Store metadata separately
    await cache.put(
      this.getMetadataKey(request),
      new Response(JSON.stringify(metadata))
    );
    
    await cache.put(request, response);
  }
  
  async getCached(request) {
    const cache = await caches.open(this.cacheName);
    return cache.match(request);
  }
  
  async isExpired(response) {
    const cache = await caches.open(this.cacheName);
    const metadataResponse = await cache.match(
      this.getMetadataKey(response.url)
    );
    
    if (!metadataResponse) return true;
    
    const metadata = await metadataResponse.json();
    const age = Date.now() - metadata.timestamp;
    
    return age > this.maxAge;
  }
  
  getMetadataKey(request) {
    const url = typeof request === 'string' ? request : request.url;
    return `${url}__metadata__`;
  }
  
  addStaleHeader(response) {
    const headers = new Headers(response.headers);
    headers.set('X-Cache-Status', 'stale');
    
    return new Response(response.body, {
      status: response.status,
      statusText: response.statusText,
      headers
    });
  }
}

// Usage
const fetcher = new ConditionalNetworkFirst({
  timeout: 3000,
  maxAge: 600000 // 10 minutes
});

const response = await fetcher.fetch(new Request('/api/data'));
```

### Background Sync for Failed Requests

Queue failed network requests for retry when connection is restored:

```javascript
// service-worker.js
const QUEUE_NAME = 'failed-requests';

self.addEventListener('sync', (event) => {
  if (event.tag === 'retry-failed-requests') {
    event.waitUntil(retryFailedRequests());
  }
});

async function networkFirstWithQueue(request) {
  try {
    const response = await fetch(request.clone());
    
    if (response.ok) {
      const cache = await caches.open('dynamic-v1');
      cache.put(request, response.clone());
    }
    
    return response;
  } catch (error) {
    // Queue for background sync
    await queueRequest(request);
    
    // Try cache
    const cached = await caches.match(request);
    
    if (cached) {
      return addQueuedHeader(cached);
    }
    
    return new Response(JSON.stringify({
      error: 'Request queued for retry',
      queued: true
    }), {
      status: 202,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}

async function queueRequest(request) {
  const cache = await caches.open(QUEUE_NAME);
  const queuedRequest = {
    url: request.url,
    method: request.method,
    headers: Object.fromEntries(request.headers.entries()),
    body: request.method !== 'GET' ? await request.text() : null,
    timestamp: Date.now()
  };
  
  await cache.put(
    new Request(request.url + '__queued__' + Date.now()),
    new Response(JSON.stringify(queuedRequest))
  );
  
  // Register background sync
  if ('sync' in self.registration) {
    await self.registration.sync.register('retry-failed-requests');
  }
}

async function retryFailedRequests() {
  const cache = await caches.open(QUEUE_NAME);
  const requests = await cache.keys();
  
  for (const request of requests) {
    try {
      const response = await cache.match(request);
      const queuedRequest = await response.json();
      
      const retryResponse = await fetch(queuedRequest.url, {
        method: queuedRequest.method,
        headers: queuedRequest.headers,
        body: queuedRequest.body
      });
      
      if (retryResponse.ok) {
        await cache.delete(request);
        
        // Send message to client about successful retry
        const clients = await self.clients.matchAll();
        clients.forEach(client => {
          client.postMessage({
            type: 'request-retry-success',
            url: queuedRequest.url
          });
        });
      }
    } catch (error) {
      console.log('Retry failed, will try again later');
    }
  }
}

function addQueuedHeader(response) {
  const headers = new Headers(response.headers);
  headers.set('X-Request-Status', 'queued');
  
  return new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers
  });
}
```

### Stale-While-Revalidate Pattern

Return cached content immediately while fetching fresh data in the background:

```javascript
async function staleWhileRevalidate(request) {
  const cache = await caches.open('swr-cache-v1');
  const cachedResponse = await cache.match(request);
  
  // Fetch fresh data in background
  const fetchPromise = fetch(request).then(async (response) => {
    if (response.ok) {
      await cache.put(request, response.clone());
    }
    return response;
  }).catch(() => null);
  
  // Return cached immediately if available
  if (cachedResponse) {
    // Don't await - let it update in background
    fetchPromise;
    return cachedResponse;
  }
  
  // No cache, wait for network
  return fetchPromise || new Response('Not available', { status: 503 });
}
```

### Network-First with Race Condition

Race between network and cache after timeout:

```javascript
async function networkFirstRace(request, fastTimeout = 1000) {
  const cache = await caches.open('race-cache-v1');
  
  const networkPromise = fetch(request).then(async (response) => {
    if (response.ok) {
      await cache.put(request, response.clone());
    }
    return { source: 'network', response };
  });
  
  const timeoutPromise = new Promise((resolve) => {
    setTimeout(async () => {
      const cached = await cache.match(request);
      if (cached) {
        resolve({ source: 'cache', response: cached });
      }
    }, fastTimeout);
  });
  
  try {
    // Race between network and timeout
    const result = await Promise.race([
      networkPromise,
      timeoutPromise
    ].filter(Boolean));
    
    if (result.response) {
      return result.response;
    }
    
    // If race didn't produce result, wait for network
    const networkResult = await networkPromise;
    return networkResult.response;
  } catch (error) {
    const cached = await cache.match(request);
    
    if (cached) {
      return cached;
    }
    
    throw error;
  }
}
```

### Adaptive Timeout Strategy

Adjust timeout based on historical performance:

```javascript
class AdaptiveNetworkFirst {
  constructor() {
    this.cacheName = 'adaptive-cache-v1';
    this.performanceCache = new Map();
    this.defaultTimeout = 3000;
    this.minTimeout = 1000;
    this.maxTimeout = 10000;
  }
  
  getAdaptiveTimeout(url) {
    const urlKey = new URL(url).pathname;
    const history = this.performanceCache.get(urlKey) || [];
    
    if (history.length === 0) {
      return this.defaultTimeout;
    }
    
    // Calculate average response time
    const avg = history.reduce((sum, time) => sum + time, 0) / history.length;
    
    // Add buffer (1.5x average)
    const timeout = Math.min(
      Math.max(avg * 1.5, this.minTimeout),
      this.maxTimeout
    );
    
    return Math.round(timeout);
  }
  
  recordPerformance(url, duration) {
    const urlKey = new URL(url).pathname;
    const history = this.performanceCache.get(urlKey) || [];
    
    history.push(duration);
    
    // Keep last 10 measurements
    if (history.length > 10) {
      history.shift();
    }
    
    this.performanceCache.set(urlKey, history);
  }
  
  async fetch(request) {
    const url = request.url;
    const timeout = this.getAdaptiveTimeout(url);
    const startTime = performance.now();
    
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      const response = await fetch(request, {
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      const duration = performance.now() - startTime;
      this.recordPerformance(url, duration);
      
      if (response.ok) {
        const cache = await caches.open(this.cacheName);
        await cache.put(request, response.clone());
      }
      
      return response;
    } catch (error) {
      const cache = await caches.open(this.cacheName);
      const cached = await cache.match(request);
      
      if (cached) {
        return cached;
      }
      
      throw error;
    }
  }
}

// Usage
const adaptiveFetcher = new AdaptiveNetworkFirst();
const response = await adaptiveFetcher.fetch(new Request('/api/data'));
```

### Priority-Based Network-First

Handle multiple concurrent requests with priority:

```javascript
class PriorityNetworkFirst {
  constructor() {
    this.cacheName = 'priority-cache-v1';
    this.requestQueue = [];
    this.activeRequests = new Map();
    this.maxConcurrent = 4;
    this.processing = false;
  }
  
  async fetch(request, priority = 'normal') {
    return new Promise((resolve, reject) => {
      this.requestQueue.push({
        request,
        priority,
        resolve,
        reject,
        timestamp: Date.now()
      });
      
      this.requestQueue.sort((a, b) => {
        const priorityOrder = { high: 0, normal: 1, low: 2 };
        return priorityOrder[a.priority] - priorityOrder[b.priority];
      });
      
      this.processQueue();
    });
  }
  
  async processQueue() {
    if (this.processing) return;
    this.processing = true;
    
    while (this.requestQueue.length > 0 && 
           this.activeRequests.size < this.maxConcurrent) {
      const item = this.requestQueue.shift();
      this.executeRequest(item);
    }
    
    this.processing = false;
  }
  
  async executeRequest({ request, resolve, reject, timestamp }) {
    const requestId = `${request.url}-${timestamp}`;
    this.activeRequests.set(requestId, true);
    
    try {
      const response = await this.networkFirst(request);
      resolve(response);
    } catch (error) {
      reject(error);
    } finally {
      this.activeRequests.delete(requestId);
      this.processQueue();
    }
  }
  
  async networkFirst(request) {
    try {
      const response = await fetch(request);
      
      if (response.ok) {
        const cache = await caches.open(this.cacheName);
        await cache.put(request, response.clone());
      }
      
      return response;
    } catch (error) {
      const cache = await caches.open(this.cacheName);
      const cached = await cache.match(request);
      
      if (cached) {
        return cached;
      }
      
      throw error;
    }
  }
}

// Usage
const priorityFetcher = new PriorityNetworkFirst();

// High priority request
const criticalData = priorityFetcher.fetch(
  new Request('/api/critical'),
  'high'
);

// Normal priority
const normalData = priorityFetcher.fetch(
  new Request('/api/data'),
  'normal'
);

// Low priority
const backgroundData = priorityFetcher.fetch(
  new Request('/api/background'),
  'low'
);
```

### Network-First with Partial Response

Return partial cached data while waiting for network:

```javascript
async function networkFirstWithPartial(request) {
  const cache = await caches.open('partial-cache-v1');
  const cached = await cache.match(request);
  
  if (cached) {
    // Return cached data with indicator
    const cachedData = await cached.json();
    
    // Send partial response immediately
    const partialResponse = new Response(
      JSON.stringify({
        data: cachedData,
        partial: true,
        loading: true
      }),
      {
        headers: {
          'Content-Type': 'application/json',
          'X-Cache-Status': 'partial'
        }
      }
    );
    
    // Fetch fresh data in background
    fetch(request).then(async (response) => {
      if (response.ok) {
        await cache.put(request, response.clone());
        
        // Notify about fresh data via BroadcastChannel
        const channel = new BroadcastChannel('data-updates');
        const freshData = await response.json();
        channel.postMessage({
          url: request.url,
          data: freshData
        });
      }
    }).catch(() => {});
    
    return partialResponse;
  }
  
  // No cache, wait for network
  const response = await fetch(request);
  
  if (response.ok) {
    await cache.put(request, response.clone());
  }
  
  return response;
}

// Client-side listener
const channel = new BroadcastChannel('data-updates');
channel.addEventListener('message', (event) => {
  console.log('Fresh data received:', event.data);
  // Update UI with fresh data
});
```

### Connection-Aware Strategy

Adapt behavior based on connection quality:

```javascript
class ConnectionAwareNetworkFirst {
  constructor() {
    this.cacheName = 'connection-aware-v1';
  }
  
  getConnectionQuality() {
    const connection = navigator.connection;
    
    if (!connection) {
      return 'unknown';
    }
    
    const effectiveType = connection.effectiveType;
    const saveData = connection.saveData;
    
    if (saveData) {
      return 'save-data';
    }
    
    switch (effectiveType) {
      case 'slow-2g':
      case '2g':
        return 'poor';
      case '3g':
        return 'moderate';
      case '4g':
        return 'good';
      default:
        return 'unknown';
    }
  }
  
  async fetch(request) {
    const quality = this.getConnectionQuality();
    
    switch (quality) {
      case 'poor':
      case 'save-data':
        return this.cacheFirst(request);
      
      case 'moderate':
        return this.networkFirstWithShortTimeout(request, 2000);
      
      case 'good':
      case 'unknown':
      default:
        return this.networkFirst(request, 5000);
    }
  }
  
  async networkFirst(request, timeout) {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      const response = await fetch(request, {
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        const cache = await caches.open(this.cacheName);
        await cache.put(request, response.clone());
      }
      
      return response;
    } catch (error) {
      return this.fallbackToCache(request);
    }
  }
  
  async networkFirstWithShortTimeout(request, timeout) {
    return this.networkFirst(request, timeout);
  }
  
  async cacheFirst(request) {
    const cache = await caches.open(this.cacheName);
    const cached = await cache.match(request);
    
    if (cached) {
      // Update cache in background
      fetch(request).then(response => {
        if (response.ok) {
          cache.put(request, response.clone());
        }
      }).catch(() => {});
      
      return cached;
    }
    
    return fetch(request);
  }
  
  async fallbackToCache(request) {
    const cache = await caches.open(this.cacheName);
    const cached = await cache.match(request);
    
    if (cached) {
      return cached;
    }
    
    return new Response('Network unavailable', { status: 503 });
  }
}

// Usage with connection monitoring
const fetcher = new ConnectionAwareNetworkFirst();

navigator.connection?.addEventListener('change', () => {
  console.log('Connection changed:', fetcher.getConnectionQuality());
});

const response = await fetcher.fetch(new Request('/api/data'));
```

### Metrics and Monitoring

Track network-first strategy performance:

```javascript
class MonitoredNetworkFirst {
  constructor() {
    this.cacheName = 'monitored-cache-v1';
    this.metrics = {
      networkHits: 0,
      cacheHits: 0,
      failures: 0,
      averageNetworkTime: 0,
      timeouts: 0
    };
  }
  
  async fetch(request, timeout = 5000) {
    const startTime = performance.now();
    
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
        this.metrics.timeouts++;
      }, timeout);
      
      const response = await fetch(request, {
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      const duration = performance.now() - startTime;
      this.updateNetworkMetrics(duration);
      
      if (response.ok) {
        this.metrics.networkHits++;
        const cache = await caches.open(this.cacheName);
        await cache.put(request, response.clone());
      }
      
      return response;
    } catch (error) {
      this.metrics.failures++;
      
      const cache = await caches.open(this.cacheName);
      const cached = await cache.match(request);
      
      if (cached) {
        this.metrics.cacheHits++;
        return cached;
      }
      
      throw error;
    }
  }
  
  updateNetworkMetrics(duration) {
    const total = this.metrics.networkHits + 1;
    this.metrics.averageNetworkTime = 
      (this.metrics.averageNetworkTime * (total - 1) + duration) / total;
  }
  
  getMetrics() {
    const total = this.metrics.networkHits + this.metrics.cacheHits;
    
    return {
      ...this.metrics,
      cacheHitRate: total > 0 ? this.metrics.cacheHits / total : 0,
      failureRate: total > 0 ? this.metrics.failures / total : 0
    };
  }
  
  resetMetrics() {
    this.metrics = {
      networkHits: 0,
      cacheHits: 0,
      failures: 0,
      averageNetworkTime: 0,
      timeouts: 0
    };
  }
}

// Usage
const monitoredFetcher = new MonitoredNetworkFirst();

// Make requests
await monitoredFetcher.fetch(new Request('/api/data1'));
await monitoredFetcher.fetch(new Request('/api/data2'));

// Check metrics
console.log(monitoredFetcher.getMetrics());
// {
//   networkHits: 2,
//   cacheHits: 0,
//   failures: 0,
//   averageNetworkTime: 245.5,
//   timeouts: 0,
//   cacheHitRate: 0,
//   failureRate: 0
// }
```

### Best Practices Summary

Set appropriate timeouts based on expected response times and connection quality. Always implement fallback to cache when network fails. Update cache with successful network responses to ensure fresh data for future fallbacks. Consider using different strategies for different types of requests based on their freshness requirements. Implement proper error handling and user feedback mechanisms. Monitor network conditions and adapt strategy accordingly. Use background sync for critical requests that fail. Implement request queuing for offline scenarios. Track metrics to optimize timeout values and cache policies. Consider the trade-off between freshness and availability for each use case. Clean up expired cache entries periodically to manage storage. Test thoroughly with various network conditions including offline, slow connections, and timeouts.

---

## Stale-While-Revalidate

### HTTP Cache-Control Directive

`stale-while-revalidate` is a Cache-Control extension that allows serving stale cached responses while asynchronously fetching fresh content in the background. It accepts a duration in seconds during which stale content remains servable after expiration.

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400
```

This header instructs the browser:

- Serve cached response for 3600 seconds (1 hour) as fresh
- After expiration, serve stale cached response for up to 86400 seconds (24 hours) additional while revalidating
- During revalidation window, update cache in background without blocking the response

### Operational Timeline

```
Time 0s:           Response cached with max-age=3600, swr=86400
Time 0-3600s:      Cache is fresh, served directly
Time 3600s:        Cache expires, enters stale period
Time 3601-90000s:  Stale response served immediately + background fetch initiated
Time 90000s+:      Cache fully expired, must revalidate before serving
```

### Background Revalidation Mechanism

When a request hits during the stale window:

1. Browser immediately returns the stale cached response
2. Browser simultaneously initiates a background fetch to the origin
3. Background fetch updates the cache when complete
4. Subsequent requests receive the updated content

```javascript
// Request at time=4000s (past max-age, within swr window)
fetch('/api/data')
  .then(response => response.json())
  .then(data => {
    // Receives stale data immediately
    // Browser fetches fresh data in background
  });

// Next request receives updated content (if background fetch completed)
```

[Inference] The background revalidation is best-effort; if the background fetch fails, the stale content continues to be served until the stale-while-revalidate window expires.

### Combining with Other Directives

#### With must-revalidate

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400, must-revalidate
```

`must-revalidate` takes precedence after max-age expires, preventing stale content from being served. The combination is contradictory and typically results in `must-revalidate` overriding `stale-while-revalidate`. [Inference] Browser behavior may vary, but most implementations honor `must-revalidate`.

#### With stale-if-error

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400, stale-if-error=604800
```

These directives work together:

- `stale-while-revalidate`: Serves stale content while revalidating successfully
- `stale-if-error`: Serves stale content when revalidation fails (network error, 5xx status)

The `stale-if-error` window typically extends beyond `stale-while-revalidate` for fallback coverage.

#### With immutable

```http
Cache-Control: max-age=31536000, immutable, stale-while-revalidate=86400
```

`immutable` indicates the resource never changes during its freshness lifetime. Adding `stale-while-revalidate` is redundant since immutable resources shouldn't require revalidation. [Inference] Browsers likely ignore `stale-while-revalidate` when `immutable` is present.

#### With no-cache

```http
Cache-Control: no-cache, stale-while-revalidate=86400
```

`no-cache` requires validation before serving any cached response, making `stale-while-revalidate` ineffective. The directives conflict fundamentally.

### Browser Support and Implementation

#### Current Support

Modern browsers (Chrome 75+, Firefox 68+, Edge 79+, Safari 15.4+) support `stale-while-revalidate`. Older browsers ignore the directive and follow standard cache behavior.

```javascript
// Feature detection (indirect)
// No direct API to detect stale-while-revalidate support
// Observe timing to infer behavior [Unverified approach]
```

#### Service Worker Interaction

Service Workers can intercept requests and implement custom stale-while-revalidate logic:

```javascript
self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request).then((cachedResponse) => {
      const fetchPromise = fetch(event.request).then((networkResponse) => {
        // Update cache with fresh response
        caches.open('v1').then((cache) => {
          cache.put(event.request, networkResponse.clone());
        });
        return networkResponse;
      });

      // Return cached response immediately, or wait for network
      return cachedResponse || fetchPromise;
    })
  );
});
```

This pattern provides manual control over stale-while-revalidate behavior regardless of server headers.

### Use Cases

#### Social Media Feeds

```http
Cache-Control: max-age=60, stale-while-revalidate=3600
```

Serve slightly outdated feed content immediately while fetching latest posts in background. Users see content instantly; refreshing shows updated posts.

#### User Profiles

```http
Cache-Control: max-age=300, stale-while-revalidate=86400
```

Profile data changes infrequently. Serve cached profiles immediately, update in background. Balance freshness with perceived performance.

#### API Responses with Frequent Updates

```http
Cache-Control: max-age=30, stale-while-revalidate=600
```

Short freshness window with longer stale tolerance. Appropriate for dashboards, analytics, or monitoring interfaces where slightly stale data is acceptable.

#### Static Assets with Versioning

```http
Cache-Control: max-age=3600, stale-while-revalidate=604800
```

CSS/JS files that change occasionally. Serve cached versions immediately, update in background when new versions deploy. Combine with versioned filenames for cache busting.

#### News Articles

```http
Cache-Control: max-age=300, stale-while-revalidate=86400
```

Article content rarely changes after publication. Aggressive stale tolerance provides availability during network issues or origin downtime.

### Performance Characteristics

#### Latency Reduction

First request after expiration:

- Without `stale-while-revalidate`: Blocks for network round-trip (100-500ms typical)
- With `stale-while-revalidate`: Serves from cache (1-10ms typical)

Performance improvement is most pronounced for:

- High-latency connections
- Mobile networks
- Users far from origin servers

#### Network Traffic

Background revalidation occurs on every request during the stale window, potentially increasing server load:

```
User A requests at t=3601s: Serves stale + revalidates
User B requests at t=3602s: Serves stale + revalidates (duplicate)
User C requests at t=3603s: Serves stale + revalidates (duplicate)
```

[Inference] Browsers may implement request coalescing to prevent duplicate background fetches, but this behavior is not standardized.

#### Cache Storage Pressure

Stale responses remain in cache longer, consuming storage space. For aggressive `stale-while-revalidate` values (weeks/months), monitor cache size limits.

### Server-Side Considerations

#### Origin Load Patterns

Background revalidation shifts when cache misses occur but doesn't eliminate them. Origin sees:

- Requests spread over stale window rather than concentrated at expiration
- [Inference] Potentially higher total request volume if multiple clients trigger separate revalidations

#### Response Size Implications

Large responses benefit more from immediate stale serving:

```http
# 5MB video response
Cache-Control: max-age=3600, stale-while-revalidate=86400
```

Downloading 5MB in foreground blocks rendering; serving stale immediately improves user experience significantly.

Small responses (few KB) have minimal latency difference:

```http
# 2KB JSON response
Cache-Control: max-age=60, stale-while-revalidate=300
```

Benefit is less pronounced but still positive.

### CDN and Proxy Behavior

#### Shared Caches

CDNs and forward proxies may handle `stale-while-revalidate` differently than browsers:

- **Cloudflare**: Supports `stale-while-revalidate`, revalidates to origin in background
- **Fastly**: Supports via `stale-if-error` and `stale-while-revalidate` directives
- **AWS CloudFront**: [Unverified] Support status unclear; may require custom Lambda@Edge logic
- **Nginx**: Requires custom configuration with proxy_cache_use_stale and background updates

```nginx
# Nginx configuration for similar behavior
proxy_cache_use_stale updating;
proxy_cache_background_update on;
proxy_cache_valid 200 1h;
```

#### Shared Cache Considerations

When CDNs use `stale-while-revalidate`, all users benefit from a single background revalidation:

```
CDN cache expires at t=3600s
First user request at t=3601s: Triggers single revalidation
All subsequent users during revalidation: Receive stale content
After revalidation completes: All users receive fresh content
```

This is more efficient than per-client revalidation in browser caches.

### Testing and Verification

#### Manual Testing

```bash
# Initial request - should cache response
curl -i https://example.com/api/data

# Note Date and Age headers
# Wait until max-age expires

# Request during stale window - should serve instantly
time curl https://example.com/api/data

# Check if background revalidation occurred
# Request again after brief delay
curl -i https://example.com/api/data
```

Expect immediate response during stale window, with updated content on subsequent request.

#### Chrome DevTools

1. Open Network tab
2. Disable cache in DevTools settings
3. Make request, note Cache-Control header
4. Re-enable cache, wait for max-age to expire
5. Make request again during stale window
6. Observe "(from disk cache)" status with fast timing
7. Check for additional background request [Inference] (may not be visible in DevTools)

#### Programmatic Verification

```javascript
async function testStaleWhileRevalidate(url) {
  const start = performance.now();
  const response = await fetch(url);
  const duration = performance.now() - start;
  
  const age = parseInt(response.headers.get('age') || '0');
  const cacheControl = response.headers.get('cache-control');
  
  console.log({
    duration,
    age,
    cacheControl,
    fromCache: duration < 50 // [Inference] Fast response suggests cache hit
  });
}
```

### Security and Privacy Implications

#### Serving Stale Authenticated Content

```http
Cache-Control: max-age=300, stale-while-revalidate=3600, private
```

Stale user-specific content may expose outdated information:

- Old notification counts
- Stale permission states
- Outdated security-sensitive data

For authenticated endpoints, prefer shorter `stale-while-revalidate` windows or avoid entirely.

#### Cache Poisoning Concerns

If an attacker successfully poisons the cache during the fresh period, `stale-while-revalidate` extends the poisoned content's lifetime. Combine with:

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400
Vary: Origin, Accept-Encoding
```

Proper `Vary` headers prevent shared cache poisoning across different request contexts.

#### Privacy Considerations

Background revalidation generates network requests without explicit user action. In privacy-sensitive contexts, this may be undesirable. [Inference] Browsers in private/incognito mode may disable or limit background revalidation.

### Error Handling During Revalidation

#### Network Failures

When background revalidation fails:

```
Time 3601s: Serve stale content, initiate background fetch
Background fetch: Network error (DNS failure, timeout, etc.)
Time 3602s: Another request arrives
```

[Inference] Browser behavior varies:

- May retry revalidation on next request
- May serve stale content until stale-while-revalidate window expires
- May mark cache entry for eager revalidation

#### Server Errors (5xx)

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400, stale-if-error=604800
```

Background revalidation receives 500 Internal Server Error:

- `stale-if-error` allows serving stale content during errors
- Cache entry remains stale but servable
- [Inference] Next revalidation attempt may occur on subsequent request or after a delay

#### Client Errors (4xx)

Background revalidation receives 404 Not Found:

- [Inference] Cache entry is likely invalidated
- Stale content no longer served
- Subsequent requests receive the 404 directly

### Monitoring and Observability

#### Server-Side Metrics

Track revalidation requests at the origin:

```javascript
// Express.js middleware example
app.use((req, res, next) => {
  // Detect potential revalidation request
  if (req.headers['cache-control']?.includes('max-age=0')) {
    metrics.increment('cache.revalidation');
  }
  next();
});
```

[Inference] Distinguishing background revalidations from normal requests requires heuristics since browsers don't send explicit signals.

#### Client-Side Metrics

```javascript
// Measure cache hit rates
const observer = new PerformanceObserver((list) => {
  for (const entry of list.getEntries()) {
    if (entry.entryType === 'resource') {
      const fromCache = entry.transferSize === 0 && entry.decodedBodySize > 0;
      analytics.track('resource_loaded', {
        fromCache,
        duration: entry.duration,
        url: entry.name
      });
    }
  }
});
observer.observe({ entryTypes: ['resource'] });
```

#### CDN Analytics

Most CDNs provide cache hit/miss metrics:

- Cache HIT: Served from CDN cache (fresh or stale)
- Cache MISS: Fetched from origin
- Cache UPDATING: [Inference] Some CDNs may indicate background revalidation separately

### Comparison with Alternative Strategies

#### Versus No Caching

```http
# No caching
Cache-Control: no-store

# With stale-while-revalidate
Cache-Control: max-age=60, stale-while-revalidate=300
```

No caching: Every request hits origin, consistent latency With SWR: First request fast (from cache), always up-to-date eventually

#### Versus Long max-age

```http
# Long max-age
Cache-Control: max-age=86400

# Shorter max-age with SWR
Cache-Control: max-age=3600, stale-while-revalidate=82800
```

Long max-age: Content may be stale for 24 hours SWR approach: Content updates more frequently while maintaining fast responses

#### Versus ETag Validation

```http
# ETag-based validation
Cache-Control: no-cache
ETag: "abc123"

# SWR approach
Cache-Control: max-age=3600, stale-while-revalidate=86400
```

ETag validation: Always validates before serving (304 Not Modified saves bandwidth but not latency) SWR: Serves immediately during stale window, validates in background (saves both)

### Advanced Patterns

#### Adaptive Stale Windows

```javascript
// Server-side logic to adjust based on content change frequency
function getCacheControl(resourceType) {
  const configs = {
    userProfile: 'max-age=300, stale-while-revalidate=86400',
    newsFeed: 'max-age=60, stale-while-revalidate=600',
    staticAsset: 'max-age=31536000, immutable'
  };
  return configs[resourceType];
}
```

#### Conditional Stale Serving

Service Worker can implement conditional logic:

```javascript
self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request).then((cached) => {
      if (!cached) return fetch(event.request);
      
      const cacheTime = new Date(cached.headers.get('date'));
      const age = Date.now() - cacheTime;
      const maxAge = 3600000; // 1 hour
      const staleTime = 86400000; // 24 hours
      
      const networkFetch = fetch(event.request).then((response) => {
        caches.open('v1').then((cache) => {
          cache.put(event.request, response.clone());
        });
        return response;
      });
      
      // Only serve stale during certain conditions
      if (age < maxAge) {
        return cached; // Fresh
      } else if (age < maxAge + staleTime && navigator.connection?.effectiveType === '4g') {
        networkFetch; // Fire and forget [Inference]
        return cached; // Serve stale on fast connections
      } else {
        return networkFetch; // Wait for network on slow connections or expired
      }
    })
  );
});
```

#### Progressive Enhancement

```javascript
// Client-side fallback for browsers without SWR support [Inference]
async function fetchWithSWR(url, options = {}) {
  const cacheKey = `swr-${url}`;
  
  try {
    const cached = localStorage.getItem(cacheKey);
    if (cached) {
      const { data, timestamp } = JSON.parse(cached);
      const age = Date.now() - timestamp;
      
      if (age < 3600000) {
        // Fresh, return immediately
        return data;
      } else if (age < 90000000) {
        // Stale, return and revalidate
        fetch(url, options)
          .then(r => r.json())
          .then(fresh => {
            localStorage.setItem(cacheKey, JSON.stringify({
              data: fresh,
              timestamp: Date.now()
            }));
          });
        return data;
      }
    }
  } catch (e) {
    // LocalStorage unavailable or corrupt
  }
  
  // No cache or expired, fetch fresh
  const response = await fetch(url, options);
  const data = await response.json();
  
  try {
    localStorage.setItem(cacheKey, JSON.stringify({
      data,
      timestamp: Date.now()
    }));
  } catch (e) {
    // Storage quota exceeded
  }
  
  return data;
}
```

### Framework and Library Support

#### Next.js

Next.js can set cache headers via configuration:

```javascript
// next.config.js
module.exports = {
  async headers() {
    return [
      {
        source: '/api/:path*',
        headers: [
          {
            key: 'Cache-Control',
            value: 'max-age=60, stale-while-revalidate=86400'
          }
        ]
      }
    ];
  }
};
```

#### SWR Library (React)

The SWR library implements stale-while-revalidate pattern at the application level:

```javascript
import useSWR from 'swr';

function Profile() {
  const { data, error } = useSWR('/api/user', fetcher);
  
  // Returns cached data immediately, revalidates in background
  if (error) return <div>Failed to load</div>;
  if (!data) return <div>Loading...</div>;
  return <div>Hello {data.name}!</div>;
}
```

This provides SWR behavior regardless of server headers, with client-side control.

#### React Query

```javascript
import { useQuery } from 'react-query';

function Dashboard() {
  const { data } = useQuery('dashboard', fetchDashboard, {
    staleTime: 60000, // Consider fresh for 1 minute
    cacheTime: 86400000, // Keep in cache for 24 hours
    refetchOnMount: 'always' // Revalidate on component mount
  });
  
  return <div>{/* Render dashboard */}</div>;
}
```

Implements similar patterns with JavaScript-based caching rather than HTTP caching.

---

# Request Interceptors

## Global Fetch Wrapping

### Basic Fetch Wrapper Implementation

A global fetch wrapper intercepts all fetch calls to add common functionality like authentication, logging, error handling, and request/response transformation.

```javascript
const originalFetch = window.fetch;

window.fetch = function(...args) {
  console.log('Fetch intercepted:', args[0]);
  
  // Call original fetch
  return originalFetch.apply(this, args)
    .then(response => {
      console.log('Response received:', response.status);
      return response;
    });
};
```

### Comprehensive Fetch Wrapper Class

```javascript
class FetchWrapper {
  constructor(config = {}) {
    this.config = {
      baseURL: config.baseURL || '',
      headers: config.headers || {},
      timeout: config.timeout || 30000,
      retries: config.retries || 0,
      retryDelay: config.retryDelay || 1000,
      interceptors: {
        request: config.interceptors?.request || [],
        response: config.interceptors?.response || []
      }
    };
    
    this.originalFetch = window.fetch;
  }
  
  install() {
    const self = this;
    
    window.fetch = function(url, options = {}) {
      return self.fetch(url, options);
    };
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
  
  async fetch(url, options = {}) {
    // Build full URL
    const fullURL = this.buildURL(url);
    
    // Merge options
    const mergedOptions = this.mergeOptions(options);
    
    // Apply request interceptors
    let requestConfig = { url: fullURL, options: mergedOptions };
    for (const interceptor of this.config.interceptors.request) {
      requestConfig = await interceptor(requestConfig);
    }
    
    // Execute fetch with retry logic
    let lastError;
    for (let attempt = 0; attempt <= this.config.retries; attempt++) {
      try {
        const response = await this.executeWithTimeout(
          requestConfig.url,
          requestConfig.options
        );
        
        // Apply response interceptors
        let finalResponse = response;
        for (const interceptor of this.config.interceptors.response) {
          finalResponse = await interceptor(finalResponse, requestConfig);
        }
        
        return finalResponse;
      } catch (error) {
        lastError = error;
        
        if (attempt < this.config.retries) {
          await this.delay(this.config.retryDelay * Math.pow(2, attempt));
        }
      }
    }
    
    throw lastError;
  }
  
  buildURL(url) {
    if (url.startsWith('http://') || url.startsWith('https://')) {
      return url;
    }
    
    const base = this.config.baseURL.replace(/\/$/, '');
    const path = url.startsWith('/') ? url : `/${url}`;
    return `${base}${path}`;
  }
  
  mergeOptions(options) {
    return {
      ...options,
      headers: {
        ...this.config.headers,
        ...options.headers
      }
    };
  }
  
  async executeWithTimeout(url, options) {
    const controller = new AbortController();
    const timeoutId = setTimeout(
      () => controller.abort(),
      this.config.timeout
    );
    
    try {
      const response = await this.originalFetch(url, {
        ...options,
        signal: controller.signal
      });
      
      return response;
    } finally {
      clearTimeout(timeoutId);
    }
  }
  
  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Usage
const wrapper = new FetchWrapper({
  baseURL: 'https://api.example.com',
  headers: {
    'Content-Type': 'application/json'
  },
  timeout: 10000,
  retries: 3
});

wrapper.install();
```

### Request Interceptors

```javascript
// Add authentication token
wrapper.config.interceptors.request.push(async (config) => {
  const token = localStorage.getItem('authToken');
  
  if (token) {
    config.options.headers = {
      ...config.options.headers,
      'Authorization': `Bearer ${token}`
    };
  }
  
  return config;
});

// Add request ID for tracking
wrapper.config.interceptors.request.push(async (config) => {
  const requestId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  
  config.options.headers = {
    ...config.options.headers,
    'X-Request-ID': requestId
  };
  
  config.requestId = requestId;
  return config;
});

// Log requests
wrapper.config.interceptors.request.push(async (config) => {
  console.log('Request:', {
    url: config.url,
    method: config.options.method || 'GET',
    headers: config.options.headers
  });
  
  return config;
});

// Transform request body
wrapper.config.interceptors.request.push(async (config) => {
  if (config.options.body && typeof config.options.body === 'object') {
    // Only transform if not FormData or other special types
    if (!(config.options.body instanceof FormData)) {
      config.options.body = JSON.stringify(config.options.body);
      config.options.headers = {
        ...config.options.headers,
        'Content-Type': 'application/json'
      };
    }
  }
  
  return config;
});
```

### Response Interceptors

```javascript
// Handle HTTP errors
wrapper.config.interceptors.response.push(async (response, requestConfig) => {
  if (!response.ok) {
    const error = new Error(`HTTP ${response.status}: ${response.statusText}`);
    error.response = response;
    error.status = response.status;
    
    // Try to parse error body
    try {
      const contentType = response.headers.get('content-type');
      if (contentType?.includes('application/json')) {
        error.data = await response.clone().json();
      } else {
        error.data = await response.clone().text();
      }
    } catch (e) {
      // Ignore parse errors
    }
    
    throw error;
  }
  
  return response;
});

// Auto-parse JSON responses
wrapper.config.interceptors.response.push(async (response) => {
  const contentType = response.headers.get('content-type');
  
  if (contentType?.includes('application/json')) {
    const clonedResponse = response.clone();
    const data = await clonedResponse.json();
    
    // Attach parsed data to response object
    response.data = data;
  }
  
  return response;
});

// Log responses
wrapper.config.interceptors.response.push(async (response, requestConfig) => {
  console.log('Response:', {
    requestId: requestConfig.requestId,
    status: response.status,
    url: requestConfig.url
  });
  
  return response;
});

// Handle token refresh
wrapper.config.interceptors.response.push(async (response, requestConfig) => {
  if (response.status === 401) {
    const refreshToken = localStorage.getItem('refreshToken');
    
    if (refreshToken) {
      try {
        // Refresh token
        const refreshResponse = await originalFetch('/auth/refresh', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ refreshToken })
        });
        
        const { token } = await refreshResponse.json();
        localStorage.setItem('authToken', token);
        
        // Retry original request with new token
        requestConfig.options.headers.Authorization = `Bearer ${token}`;
        return await originalFetch(requestConfig.url, requestConfig.options);
      } catch (error) {
        // Refresh failed, logout user
        localStorage.removeItem('authToken');
        localStorage.removeItem('refreshToken');
        window.location.href = '/login';
      }
    }
  }
  
  return response;
});
```

### Advanced Wrapper with Middleware Pattern

```javascript
class EnhancedFetchWrapper {
  constructor() {
    this.middlewares = [];
    this.originalFetch = window.fetch;
  }
  
  use(middleware) {
    this.middlewares.push(middleware);
    return this;
  }
  
  install() {
    const self = this;
    
    window.fetch = async function(url, options = {}) {
      return self.executeMiddlewareChain(url, options);
    };
  }
  
  async executeMiddlewareChain(url, options) {
    let index = 0;
    
    const next = async () => {
      if (index >= this.middlewares.length) {
        return this.originalFetch(url, options);
      }
      
      const middleware = this.middlewares[index++];
      return middleware({ url, options }, next);
    };
    
    return next();
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage with middlewares
const wrapper = new EnhancedFetchWrapper();

// Logging middleware
wrapper.use(async (context, next) => {
  console.log('→', context.options.method || 'GET', context.url);
  const startTime = Date.now();
  
  const response = await next();
  
  console.log('←', response.status, `${Date.now() - startTime}ms`);
  return response;
});

// Authentication middleware
wrapper.use(async (context, next) => {
  const token = localStorage.getItem('authToken');
  
  if (token) {
    context.options.headers = {
      ...context.options.headers,
      'Authorization': `Bearer ${token}`
    };
  }
  
  return next();
});

// Error handling middleware
wrapper.use(async (context, next) => {
  try {
    const response = await next();
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    return response;
  } catch (error) {
    console.error('Fetch error:', error);
    throw error;
  }
});

wrapper.install();
```

### Caching Wrapper

```javascript
class CachingFetchWrapper {
  constructor(config = {}) {
    this.cache = new Map();
    this.config = {
      ttl: config.ttl || 60000, // 1 minute default
      maxSize: config.maxSize || 100
    };
    this.originalFetch = window.fetch;
  }
  
  getCacheKey(url, options) {
    const method = options.method || 'GET';
    const body = options.body || '';
    return `${method}:${url}:${body}`;
  }
  
  install() {
    const self = this;
    
    window.fetch = async function(url, options = {}) {
      // Only cache GET requests
      if ((options.method || 'GET').toUpperCase() !== 'GET') {
        return self.originalFetch(url, options);
      }
      
      const cacheKey = self.getCacheKey(url, options);
      const cached = self.cache.get(cacheKey);
      
      if (cached && Date.now() - cached.timestamp < self.config.ttl) {
        console.log('Cache hit:', url);
        // Return cloned response
        return new Response(cached.body, {
          status: cached.status,
          statusText: cached.statusText,
          headers: cached.headers
        });
      }
      
      console.log('Cache miss:', url);
      const response = await self.originalFetch(url, options);
      
      // Clone and cache successful responses
      if (response.ok) {
        const cloned = response.clone();
        const body = await cloned.blob();
        
        self.cache.set(cacheKey, {
          body,
          status: response.status,
          statusText: response.statusText,
          headers: new Headers(response.headers),
          timestamp: Date.now()
        });
        
        // Enforce cache size limit
        if (self.cache.size > self.config.maxSize) {
          const firstKey = self.cache.keys().next().value;
          self.cache.delete(firstKey);
        }
      }
      
      return response;
    };
  }
  
  clearCache() {
    this.cache.clear();
  }
  
  invalidate(pattern) {
    for (const key of this.cache.keys()) {
      if (key.includes(pattern)) {
        this.cache.delete(key);
      }
    }
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const cachingWrapper = new CachingFetchWrapper({
  ttl: 300000, // 5 minutes
  maxSize: 50
});

cachingWrapper.install();

// Clear specific cache entries
cachingWrapper.invalidate('/api/users');
```

### Request Queue and Rate Limiting

```javascript
class RateLimitedFetchWrapper {
  constructor(config = {}) {
    this.config = {
      maxConcurrent: config.maxConcurrent || 6,
      requestsPerSecond: config.requestsPerSecond || 10
    };
    
    this.queue = [];
    this.activeRequests = 0;
    this.requestTimestamps = [];
    this.originalFetch = window.fetch;
  }
  
  install() {
    const self = this;
    
    window.fetch = function(url, options = {}) {
      return self.enqueue(url, options);
    };
  }
  
  enqueue(url, options) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.processQueue();
    });
  }
  
  async processQueue() {
    if (this.activeRequests >= this.config.maxConcurrent) {
      return;
    }
    
    if (this.queue.length === 0) {
      return;
    }
    
    // Check rate limit
    const now = Date.now();
    this.requestTimestamps = this.requestTimestamps.filter(
      ts => now - ts < 1000
    );
    
    if (this.requestTimestamps.length >= this.config.requestsPerSecond) {
      // Wait before processing next request
      const oldestTimestamp = this.requestTimestamps[0];
      const delay = 1000 - (now - oldestTimestamp);
      
      setTimeout(() => this.processQueue(), delay);
      return;
    }
    
    const item = this.queue.shift();
    this.activeRequests++;
    this.requestTimestamps.push(now);
    
    try {
      const response = await this.originalFetch(item.url, item.options);
      item.resolve(response);
    } catch (error) {
      item.reject(error);
    } finally {
      this.activeRequests--;
      this.processQueue();
    }
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const rateLimitedWrapper = new RateLimitedFetchWrapper({
  maxConcurrent: 3,
  requestsPerSecond: 5
});

rateLimitedWrapper.install();
```

### Mock/Stub Wrapper for Testing

```javascript
class MockFetchWrapper {
  constructor() {
    this.mocks = new Map();
    this.originalFetch = window.fetch;
  }
  
  mock(pattern, handler) {
    this.mocks.set(pattern, handler);
  }
  
  mockOnce(pattern, handler) {
    const wrappedHandler = async (...args) => {
      this.mocks.delete(pattern);
      return handler(...args);
    };
    
    this.mocks.set(pattern, wrappedHandler);
  }
  
  install() {
    const self = this;
    
    window.fetch = async function(url, options = {}) {
      // Check for matching mock
      for (const [pattern, handler] of self.mocks) {
        const matches = typeof pattern === 'string' 
          ? url.includes(pattern)
          : pattern.test(url);
        
        if (matches) {
          console.log('Mock matched:', pattern);
          return handler(url, options);
        }
      }
      
      // No mock found, use original fetch
      return self.originalFetch(url, options);
    };
  }
  
  clearMocks() {
    this.mocks.clear();
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const mockWrapper = new MockFetchWrapper();

// Mock successful response
mockWrapper.mock('/api/users', async (url, options) => {
  return new Response(JSON.stringify([
    { id: 1, name: 'John' },
    { id: 2, name: 'Jane' }
  ]), {
    status: 200,
    headers: { 'Content-Type': 'application/json' }
  });
});

// Mock error response
mockWrapper.mock('/api/error', async () => {
  return new Response(JSON.stringify({ error: 'Not found' }), {
    status: 404,
    headers: { 'Content-Type': 'application/json' }
  });
});

// Mock with regex pattern
mockWrapper.mock(/\/api\/users\/\d+/, async (url) => {
  const id = url.match(/\/api\/users\/(\d+)/)[1];
  return new Response(JSON.stringify({ id, name: `User ${id}` }), {
    status: 200,
    headers: { 'Content-Type': 'application/json' }
  });
});

mockWrapper.install();
```

### Analytics and Monitoring Wrapper

```javascript
class AnalyticsFetchWrapper {
  constructor() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      requestsByEndpoint: new Map(),
      averageResponseTime: 0,
      slowRequests: []
    };
    
    this.originalFetch = window.fetch;
  }
  
  install() {
    const self = this;
    
    window.fetch = async function(url, options = {}) {
      const startTime = performance.now();
      const endpoint = self.getEndpoint(url);
      
      self.metrics.totalRequests++;
      
      // Track endpoint usage
      const endpointCount = self.metrics.requestsByEndpoint.get(endpoint) || 0;
      self.metrics.requestsByEndpoint.set(endpoint, endpointCount + 1);
      
      try {
        const response = await self.originalFetch(url, options);
        const duration = performance.now() - startTime;
        
        if (response.ok) {
          self.metrics.successfulRequests++;
        } else {
          self.metrics.failedRequests++;
        }
        
        // Track slow requests
        if (duration > 3000) {
          self.metrics.slowRequests.push({
            url,
            duration,
            timestamp: Date.now()
          });
          
          // Keep only last 50 slow requests
          if (self.metrics.slowRequests.length > 50) {
            self.metrics.slowRequests.shift();
          }
        }
        
        // Update average response time
        self.updateAverageResponseTime(duration);
        
        // Send analytics
        self.sendAnalytics({
          url,
          method: options.method || 'GET',
          status: response.status,
          duration
        });
        
        return response;
      } catch (error) {
        self.metrics.failedRequests++;
        
        self.sendAnalytics({
          url,
          method: options.method || 'GET',
          error: error.message,
          duration: performance.now() - startTime
        });
        
        throw error;
      }
    };
  }
  
  getEndpoint(url) {
    try {
      const urlObj = new URL(url, window.location.origin);
      return urlObj.pathname;
    } catch (e) {
      return url;
    }
  }
  
  updateAverageResponseTime(duration) {
    const total = this.metrics.totalRequests;
    const current = this.metrics.averageResponseTime;
    
    this.metrics.averageResponseTime = 
      (current * (total - 1) + duration) / total;
  }
  
  sendAnalytics(data) {
    // Send to analytics service
    console.log('Analytics:', data);
    
    // Example: Send to external service
    // navigator.sendBeacon('/analytics', JSON.stringify(data));
  }
  
  getMetrics() {
    return {
      ...this.metrics,
      successRate: this.metrics.totalRequests > 0
        ? (this.metrics.successfulRequests / this.metrics.totalRequests) * 100
        : 0,
      requestsByEndpoint: Object.fromEntries(this.metrics.requestsByEndpoint)
    };
  }
  
  resetMetrics() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      requestsByEndpoint: new Map(),
      averageResponseTime: 0,
      slowRequests: []
    };
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const analyticsWrapper = new AnalyticsFetchWrapper();
analyticsWrapper.install();

// Get metrics
console.log(analyticsWrapper.getMetrics());
```

### Composable Wrapper System

```javascript
class FetchWrapperComposer {
  constructor() {
    this.wrappers = [];
    this.originalFetch = window.fetch;
  }
  
  addWrapper(wrapper) {
    this.wrappers.push(wrapper);
    return this;
  }
  
  install() {
    let currentFetch = this.originalFetch;
    
    // Apply wrappers in reverse order so first added is outermost
    for (let i = this.wrappers.length - 1; i >= 0; i--) {
      const wrapper = this.wrappers[i];
      const previousFetch = currentFetch;
      
      currentFetch = function(url, options) {
        return wrapper(url, options, previousFetch);
      };
    }
    
    window.fetch = currentFetch;
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Define individual wrapper functions
function loggingWrapper(url, options, next) {
  console.log('→', options.method || 'GET', url);
  return next(url, options).then(response => {
    console.log('←', response.status);
    return response;
  });
}

function authWrapper(url, options, next) {
  const token = localStorage.getItem('authToken');
  
  if (token) {
    options = {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    };
  }
  
  return next(url, options);
}

function errorHandlingWrapper(url, options, next) {
  return next(url, options).then(response => {
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }
    return response;
  });
}

// Compose wrappers
const composer = new FetchWrapperComposer();
composer
  .addWrapper(loggingWrapper)
  .addWrapper(authWrapper)
  .addWrapper(errorHandlingWrapper)
  .install();
```

### Typed Wrapper with TypeScript Support

```javascript
class TypedFetchWrapper {
  constructor() {
    this.originalFetch = window.fetch;
  }
  
  install() {
    const self = this;
    
    window.fetch = function(url, options = {}) {
      return self.typedFetch(url, options);
    };
  }
  
  async typedFetch(url, options) {
    const response = await this.originalFetch(url, options);
    
    // Add type-safe methods
    response.json = async function() {
      const data = await Response.prototype.json.call(this);
      return data;
    };
    
    response.typedJson = async function(validator) {
      const data = await Response.prototype.json.call(this);
      
      if (validator && !validator(data)) {
        throw new Error('Response data validation failed');
      }
      
      return data;
    };
    
    return response;
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const typedWrapper = new TypedFetchWrapper();
typedWrapper.install();

// With validation
const response = await fetch('/api/user/1');
const user = await response.typedJson((data) => {
  return data && typeof data.id === 'number' && typeof data.name === 'string';
});
```

### Environment-Aware Wrapper

```javascript
class EnvironmentFetchWrapper {
  constructor(config = {}) {
    this.environments = config.environments || {
      development: 'http://localhost:3000',
      staging: 'https://staging.example.com',
      production: 'https://api.example.com'
    };
    
    this.currentEnv = config.currentEnv || 'production';
    this.originalFetch = window.fetch;
  }
  
  install() {
    const self = this;
    
    window.fetch = function(url, options = {}) {
      const fullURL = self.resolveURL(url);
      return self.originalFetch(fullURL, options);
    };
  }
  
  resolveURL(url) {
    if (url.startsWith('http://') || url.startsWith('https://')) {
      return url;
    }
    
    const baseURL = this.environments[this.currentEnv];
    const path = url.startsWith('/') ? url : `/${url}`;
    
    return `${baseURL}${path}`;
  }
  
  setEnvironment(env) {
    if (this.environments[env]) {
      this.currentEnv = env;
    }
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
}

// Usage
const envWrapper = new EnvironmentFetchWrapper({
  environments: {
    development: 'http://localhost:3000',
    staging: 'https://staging-api.example.com',
    production: 'https://api.example.com'
  },
  currentEnv: process.env.NODE_ENV || 'production'
});

envWrapper.install();

// Switch environment
envWrapper.setEnvironment('development');
```

---

## Middleware Patterns for Fetch API

### Core Middleware Concepts

Middleware in the context of Fetch API refers to composable functions that intercept, modify, or enhance HTTP requests and responses. These patterns enable separation of concerns by extracting cross-cutting functionality like authentication, logging, error handling, and request transformation into reusable layers.

### Basic Middleware Structure

#### Function Composition Pattern

```javascript
function createFetchMiddleware(middlewares) {
  return async (url, options = {}) => {
    let modifiedOptions = { ...options };
    let modifiedUrl = url;
    
    // Request phase - execute middlewares in order
    for (const middleware of middlewares) {
      if (middleware.request) {
        const result = await middleware.request(modifiedUrl, modifiedOptions);
        modifiedUrl = result.url || modifiedUrl;
        modifiedOptions = result.options || modifiedOptions;
      }
    }
    
    // Execute fetch
    let response = await fetch(modifiedUrl, modifiedOptions);
    
    // Response phase - execute middlewares in reverse order
    for (const middleware of [...middlewares].reverse()) {
      if (middleware.response) {
        response = await middleware.response(response, modifiedUrl, modifiedOptions);
      }
    }
    
    return response;
  };
}

// Usage
const enhancedFetch = createFetchMiddleware([
  authMiddleware,
  loggingMiddleware,
  errorHandlingMiddleware
]);

const response = await enhancedFetch('/api/data');
```

#### Chain of Responsibility Pattern

```javascript
class FetchMiddleware {
  constructor() {
    this.middlewares = [];
  }
  
  use(middleware) {
    this.middlewares.push(middleware);
    return this;
  }
  
  async fetch(url, options = {}) {
    const chain = [...this.middlewares];
    
    const dispatch = async (index, url, options) => {
      if (index >= chain.length) {
        return fetch(url, options);
      }
      
      const middleware = chain[index];
      return middleware(url, options, (nextUrl, nextOptions) => {
        return dispatch(index + 1, nextUrl || url, nextOptions || options);
      });
    };
    
    return dispatch(0, url, options);
  }
}

// Middleware function signature
function loggingMiddleware(url, options, next) {
  console.log(`Request: ${options.method || 'GET'} ${url}`);
  const startTime = Date.now();
  
  return next(url, options).then(response => {
    console.log(`Response: ${response.status} (${Date.now() - startTime}ms)`);
    return response;
  });
}

// Usage
const client = new FetchMiddleware();
client
  .use(loggingMiddleware)
  .use(authMiddleware)
  .use(retryMiddleware);

const response = await client.fetch('/api/users');
```

### Authentication Middleware

#### Bearer Token Injection

```javascript
function createAuthMiddleware(getToken) {
  return {
    request: async (url, options) => {
      const token = await getToken();
      
      if (!token) {
        return { url, options };
      }
      
      const headers = new Headers(options.headers);
      headers.set('Authorization', `Bearer ${token}`);
      
      return {
        url,
        options: {
          ...options,
          headers
        }
      };
    }
  };
}

// Usage
const authMiddleware = createAuthMiddleware(async () => {
  return localStorage.getItem('access_token');
});
```

#### Token Refresh Middleware

```javascript
function createTokenRefreshMiddleware(tokenManager) {
  return {
    request: async (url, options) => {
      const token = await tokenManager.getValidToken();
      const headers = new Headers(options.headers);
      headers.set('Authorization', `Bearer ${token}`);
      
      return {
        url,
        options: { ...options, headers }
      };
    },
    
    response: async (response, url, options) => {
      if (response.status === 401) {
        // Token expired, refresh and retry
        const refreshed = await tokenManager.refresh();
        
        if (refreshed) {
          const newToken = await tokenManager.getValidToken();
          const headers = new Headers(options.headers);
          headers.set('Authorization', `Bearer ${newToken}`);
          
          // Retry the request
          return fetch(url, {
            ...options,
            headers
          });
        }
      }
      
      return response;
    }
  };
}

class TokenManager {
  constructor() {
    this.accessToken = null;
    this.refreshToken = null;
    this.expiresAt = null;
  }
  
  async getValidToken() {
    if (this.accessToken && Date.now() < this.expiresAt) {
      return this.accessToken;
    }
    
    await this.refresh();
    return this.accessToken;
  }
  
  async refresh() {
    try {
      const response = await fetch('/auth/refresh', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ refreshToken: this.refreshToken })
      });
      
      if (!response.ok) {
        return false;
      }
      
      const data = await response.json();
      this.accessToken = data.accessToken;
      this.expiresAt = Date.now() + (data.expiresIn * 1000);
      
      return true;
    } catch (error) {
      return false;
    }
  }
}
```

#### API Key Middleware

```javascript
function createApiKeyMiddleware(apiKey, headerName = 'X-API-Key') {
  return {
    request: (url, options) => {
      const headers = new Headers(options.headers);
      headers.set(headerName, apiKey);
      
      return {
        url,
        options: { ...options, headers }
      };
    }
  };
}
```

### Logging and Monitoring Middleware

#### Request/Response Logger

```javascript
function createLoggingMiddleware(logger = console) {
  return {
    request: async (url, options) => {
      const requestId = crypto.randomUUID();
      
      logger.log({
        type: 'request',
        requestId,
        timestamp: new Date().toISOString(),
        method: options.method || 'GET',
        url,
        headers: Object.fromEntries(new Headers(options.headers || {})),
        body: options.body
      });
      
      // Attach requestId to options for response correlation
      return {
        url,
        options: {
          ...options,
          __requestId: requestId
        }
      };
    },
    
    response: async (response, url, options) => {
      const clonedResponse = response.clone();
      
      try {
        const body = await clonedResponse.text();
        
        logger.log({
          type: 'response',
          requestId: options.__requestId,
          timestamp: new Date().toISOString(),
          status: response.status,
          statusText: response.statusText,
          headers: Object.fromEntries(response.headers),
          body: body.substring(0, 1000) // Truncate for logging
        });
      } catch (error) {
        logger.error('Failed to log response body:', error);
      }
      
      return response;
    }
  };
}
```

#### Performance Monitoring

```javascript
function createPerformanceMiddleware(onMetric) {
  return {
    request: (url, options) => {
      const startTime = performance.now();
      
      return {
        url,
        options: {
          ...options,
          __startTime: startTime,
          __performanceUrl: url
        }
      };
    },
    
    response: async (response, url, options) => {
      const duration = performance.now() - options.__startTime;
      
      onMetric({
        url: options.__performanceUrl,
        method: options.method || 'GET',
        status: response.status,
        duration,
        timestamp: Date.now()
      });
      
      return response;
    }
  };
}

// Usage with aggregation
class MetricsCollector {
  constructor() {
    this.metrics = [];
  }
  
  record(metric) {
    this.metrics.push(metric);
    
    if (this.metrics.length >= 100) {
      this.flush();
    }
  }
  
  flush() {
    if (this.metrics.length === 0) return;
    
    // Send to analytics service
    fetch('/analytics/metrics', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(this.metrics)
    }).catch(console.error);
    
    this.metrics = [];
  }
  
  getStats() {
    const durations = this.metrics.map(m => m.duration);
    return {
      count: durations.length,
      avg: durations.reduce((a, b) => a + b, 0) / durations.length,
      min: Math.min(...durations),
      max: Math.max(...durations)
    };
  }
}

const collector = new MetricsCollector();
const performanceMiddleware = createPerformanceMiddleware(
  (metric) => collector.record(metric)
);
```

### Error Handling Middleware

#### Global Error Handler

```javascript
function createErrorHandlingMiddleware(errorHandler) {
  return {
    response: async (response, url, options) => {
      if (!response.ok) {
        const error = new FetchError(
          `HTTP ${response.status}: ${response.statusText}`,
          response.status,
          response
        );
        
        try {
          error.body = await response.clone().json();
        } catch {
          error.body = await response.clone().text();
        }
        
        const handled = await errorHandler(error, url, options);
        
        if (handled) {
          return handled;
        }
        
        throw error;
      }
      
      return response;
    }
  };
}

class FetchError extends Error {
  constructor(message, status, response) {
    super(message);
    this.name = 'FetchError';
    this.status = status;
    this.response = response;
    this.body = null;
  }
}

// Usage
const errorMiddleware = createErrorHandlingMiddleware(async (error, url, options) => {
  if (error.status === 429) {
    // Rate limited - wait and retry
    const retryAfter = parseInt(error.response.headers.get('Retry-After') || '5');
    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
    return fetch(url, options);
  }
  
  if (error.status >= 500) {
    // Server error - log to monitoring service
    await fetch('/api/errors', {
      method: 'POST',
      body: JSON.stringify({
        url,
        status: error.status,
        message: error.message,
        body: error.body
      })
    });
  }
  
  return null; // Let error propagate
});
```

#### Retry with Exponential Backoff

```javascript
function createRetryMiddleware(options = {}) {
  const {
    maxRetries = 3,
    retryDelay = 1000,
    retryStatusCodes = [408, 429, 500, 502, 503, 504],
    shouldRetry = (response) => retryStatusCodes.includes(response.status)
  } = options;
  
  return async (url, fetchOptions, next) => {
    let lastError;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await next(url, fetchOptions);
        
        if (response.ok || !shouldRetry(response)) {
          return response;
        }
        
        lastError = new Error(`HTTP ${response.status}`);
        
        if (attempt < maxRetries) {
          const delay = retryDelay * Math.pow(2, attempt);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
        
      } catch (error) {
        lastError = error;
        
        if (attempt < maxRetries) {
          const delay = retryDelay * Math.pow(2, attempt);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }
    
    throw lastError;
  };
}
```

### Request Transformation Middleware

#### Content Type Handler

```javascript
function createContentTypeMiddleware() {
  return {
    request: (url, options) => {
      if (!options.body) {
        return { url, options };
      }
      
      const headers = new Headers(options.headers);
      
      // Auto-detect and set Content-Type
      if (typeof options.body === 'string') {
        try {
          JSON.parse(options.body);
          if (!headers.has('Content-Type')) {
            headers.set('Content-Type', 'application/json');
          }
        } catch {
          if (!headers.has('Content-Type')) {
            headers.set('Content-Type', 'text/plain');
          }
        }
      } else if (options.body instanceof FormData) {
        // Browser sets multipart/form-data automatically
        headers.delete('Content-Type');
      } else if (options.body instanceof URLSearchParams) {
        headers.set('Content-Type', 'application/x-www-form-urlencoded');
      } else if (typeof options.body === 'object') {
        // Auto-stringify objects
        options.body = JSON.stringify(options.body);
        headers.set('Content-Type', 'application/json');
      }
      
      return {
        url,
        options: { ...options, headers }
      };
    }
  };
}
```

#### Request Body Compression

```javascript
function createCompressionMiddleware(minSize = 1024) {
  return {
    request: async (url, options) => {
      if (!options.body || typeof options.body !== 'string') {
        return { url, options };
      }
      
      if (options.body.length < minSize) {
        return { url, options };
      }
      
      // Check if CompressionStream is available
      if (!window.CompressionStream) {
        return { url, options };
      }
      
      const blob = new Blob([options.body]);
      const stream = blob.stream();
      const compressedStream = stream.pipeThrough(
        new CompressionStream('gzip')
      );
      
      const compressedBlob = await new Response(compressedStream).blob();
      
      const headers = new Headers(options.headers);
      headers.set('Content-Encoding', 'gzip');
      
      return {
        url,
        options: {
          ...options,
          body: compressedBlob,
          headers
        }
      };
    }
  };
}
```

#### Query Parameter Serialization

```javascript
function createQueryParamsMiddleware() {
  return {
    request: (url, options) => {
      if (!options.params) {
        return { url, options };
      }
      
      const urlObj = new URL(url, window.location.origin);
      
      Object.entries(options.params).forEach(([key, value]) => {
        if (value !== null && value !== undefined) {
          if (Array.isArray(value)) {
            value.forEach(v => urlObj.searchParams.append(key, v));
          } else {
            urlObj.searchParams.set(key, value);
          }
        }
      });
      
      const { params, ...restOptions } = options;
      
      return {
        url: urlObj.toString(),
        options: restOptions
      };
    }
  };
}

// Usage
const response = await enhancedFetch('/api/users', {
  params: {
    page: 1,
    limit: 10,
    tags: ['javascript', 'fetch']
  }
});
// Requests: /api/users?page=1&limit=10&tags=javascript&tags=fetch
```

### Response Transformation Middleware

#### Auto-Parse Response

```javascript
function createResponseParserMiddleware() {
  return {
    response: async (response, url, options) => {
      const contentType = response.headers.get('Content-Type');
      
      if (!contentType) {
        return response;
      }
      
      const cloned = response.clone();
      
      try {
        if (contentType.includes('application/json')) {
          const data = await cloned.json();
          response.data = data;
        } else if (contentType.includes('text/')) {
          const text = await cloned.text();
          response.data = text;
        } else if (contentType.includes('application/octet-stream')) {
          const blob = await cloned.blob();
          response.data = blob;
        }
      } catch (error) {
        // Failed to parse, leave response as-is
      }
      
      return response;
    }
  };
}

// Usage
const response = await enhancedFetch('/api/users');
console.log(response.data); // Pre-parsed JSON
```

#### Response Caching Middleware

```javascript
function createCacheMiddleware(cacheConfig = {}) {
  const cache = new Map();
  const {
    ttl = 60000, // 1 minute default
    methods = ['GET'],
    shouldCache = (url, options) => methods.includes(options.method || 'GET')
  } = cacheConfig;
  
  return {
    request: async (url, options) => {
      if (!shouldCache(url, options)) {
        return { url, options };
      }
      
      const cacheKey = `${options.method || 'GET'}:${url}`;
      const cached = cache.get(cacheKey);
      
      if (cached && Date.now() - cached.timestamp < ttl) {
        // Return cached response
        options.__cached = true;
        options.__cachedResponse = cached.response.clone();
      }
      
      return { url, options };
    },
    
    response: async (response, url, options) => {
      if (options.__cached) {
        return options.__cachedResponse;
      }
      
      if (shouldCache(url, options) && response.ok) {
        const cacheKey = `${options.method || 'GET'}:${url}`;
        cache.set(cacheKey, {
          response: response.clone(),
          timestamp: Date.now()
        });
        
        // Clean up expired entries
        for (const [key, value] of cache.entries()) {
          if (Date.now() - value.timestamp > ttl) {
            cache.delete(key);
          }
        }
      }
      
      return response;
    }
  };
}
```

### Timeout Middleware

#### Request Timeout Handler

```javascript
function createTimeoutMiddleware(timeoutMs = 30000) {
  return async (url, options, next) => {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
    
    try {
      const response = await next(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      return response;
      
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        throw new Error(`Request timeout after ${timeoutMs}ms`);
      }
      
      throw error;
    }
  };
}
```

#### Adaptive Timeout

```javascript
function createAdaptiveTimeoutMiddleware() {
  const metrics = new Map();
  
  return async (url, options, next) => {
    const key = `${options.method || 'GET'}:${url}`;
    const history = metrics.get(key) || [];
    
    // Calculate adaptive timeout based on historical performance
    const avgDuration = history.length > 0
      ? history.reduce((a, b) => a + b, 0) / history.length
      : 5000;
    
    const timeout = Math.min(Math.max(avgDuration * 2, 3000), 30000);
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    const startTime = performance.now();
    
    try {
      const response = await next(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      // Record duration
      const duration = performance.now() - startTime;
      history.push(duration);
      
      // Keep last 10 measurements
      if (history.length > 10) {
        history.shift();
      }
      
      metrics.set(key, history);
      
      return response;
      
    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  };
}
```

### Rate Limiting Middleware

#### Token Bucket Implementation

```javascript
class TokenBucket {
  constructor(capacity, refillRate) {
    this.capacity = capacity;
    this.tokens = capacity;
    this.refillRate = refillRate;
    this.lastRefill = Date.now();
  }
  
  async consume(tokens = 1) {
    this.refill();
    
    if (this.tokens >= tokens) {
      this.tokens -= tokens;
      return true;
    }
    
    // Wait until tokens available
    const waitTime = ((tokens - this.tokens) / this.refillRate) * 1000;
    await new Promise(resolve => setTimeout(resolve, waitTime));
    
    this.refill();
    this.tokens -= tokens;
    return true;
  }
  
  refill() {
    const now = Date.now();
    const elapsed = (now - this.lastRefill) / 1000;
    const tokensToAdd = elapsed * this.refillRate;
    
    this.tokens = Math.min(this.capacity, this.tokens + tokensToAdd);
    this.lastRefill = now;
  }
}

function createRateLimitMiddleware(requestsPerSecond = 10) {
  const bucket = new TokenBucket(requestsPerSecond, requestsPerSecond);
  
  return async (url, options, next) => {
    await bucket.consume(1);
    return next(url, options);
  };
}
```

#### Per-Endpoint Rate Limiting

```javascript
function createPerEndpointRateLimiter(config = {}) {
  const buckets = new Map();
  
  const getOrCreateBucket = (endpoint) => {
    if (!buckets.has(endpoint)) {
      const endpointConfig = config[endpoint] || config.default || { rps: 10 };
      buckets.set(endpoint, new TokenBucket(endpointConfig.rps, endpointConfig.rps));
    }
    return buckets.get(endpoint);
  };
  
  return async (url, options, next) => {
    const urlObj = new URL(url, window.location.origin);
    const endpoint = urlObj.pathname;
    
    const bucket = getOrCreateBucket(endpoint);
    await bucket.consume(1);
    
    return next(url, options);
  };
}

// Usage
const rateLimiter = createPerEndpointRateLimiter({
  '/api/search': { rps: 5 },
  '/api/upload': { rps: 2 },
  default: { rps: 10 }
});
```

### CSRF Protection Middleware

#### Token Injection

```javascript
function createCsrfMiddleware(options = {}) {
  const {
    tokenName = 'csrf_token',
    headerName = 'X-CSRF-Token',
    getToken = () => {
      const meta = document.querySelector(`meta[name="${tokenName}"]`);
      return meta ? meta.content : null;
    },
    methods = ['POST', 'PUT', 'PATCH', 'DELETE']
  } = options;
  
  return {
    request: (url, fetchOptions) => {
      const method = fetchOptions.method?.toUpperCase() || 'GET';
      
      if (!methods.includes(method)) {
        return { url, options: fetchOptions };
      }
      
      const token = getToken();
      
      if (!token) {
        console.warn('CSRF token not found');
        return { url, options: fetchOptions };
      }
      
      const headers = new Headers(fetchOptions.headers);
      headers.set(headerName, token);
      
      return {
        url,
        options: {
          ...fetchOptions,
          headers
        }
      };
    }
  };
}
```

### Base URL Middleware

#### URL Prefix Handler

```javascript
function createBaseUrlMiddleware(baseUrl) {
  return {
    request: (url, options) => {
      // Skip if URL is already absolute
      if (url.startsWith('http://') || url.startsWith('https://')) {
        return { url, options };
      }
      
      // Remove leading slash from relative URL if base URL has trailing slash
      const normalizedUrl = url.startsWith('/') ? url.slice(1) : url;
      const normalizedBase = baseUrl.endsWith('/') ? baseUrl : `${baseUrl}/`;
      
      return {
        url: `${normalizedBase}${normalizedUrl}`,
        options
      };
    }
  };
}

// Usage
const apiClient = createFetchMiddleware([
  createBaseUrlMiddleware('https://api.example.com/v1'),
  authMiddleware,
  loggingMiddleware
]);

const response = await apiClient('users'); // Requests https://api.example.com/v1/users
```

### Request Deduplication Middleware

#### Identical Request Coalescing

```javascript
function createDeduplicationMiddleware() {
  const pending = new Map();
  
  const getCacheKey = (url, options) => {
    const method = options.method || 'GET';
    const body = options.body || '';
    return `${method}:${url}:${body}`;
  };
  
  return async (url, options, next) => {
    const key = getCacheKey(url, options);
    
    // Check if identical request is already in flight
    if (pending.has(key)) {
      return pending.get(key);
    }
    
    // Execute request and store promise
    const promise = next(url, options)
      .then(response => {
        pending.delete(key);
        return response.clone();
      })
      .catch(error => {
        pending.delete(key);
        throw error;
      });
    
    pending.set(key, promise);
    return promise;
  };
}
```

### Circuit Breaker Middleware

#### Failure Threshold Pattern

```javascript
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.threshold = threshold;
    this.timeout = timeout;
    this.failures = 0;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.nextAttempt = Date.now();
  }
  
  async execute(fn) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }
    
    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failures = 0;
    this.state = 'CLOSED';
  }
  
  onFailure() {
    this.failures++;
    
    if (this.failures >= this.threshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.timeout;
    }
  }
}

function createCircuitBreakerMiddleware(options = {}) {
  const breakers = new Map();
  
  const getBreaker = (url) => {
    const urlObj = new URL(url, window.location.origin);
    const key = `${urlObj.protocol}//${urlObj.host}`;
    
    if (!breakers.has(key)) {
      breakers.set(key, new CircuitBreaker(
        options.threshold,
        options.timeout
      ));
    }
    
    return breakers.get(key);
  };
  
  return async (url, fetchOptions, next) => {
    const breaker = getBreaker(url);
    
    return breaker.execute(() => next(url, fetchOptions));
  };
}
```

### Header Injection Middleware

#### Custom Headers

```javascript
function createHeadersMiddleware(headers = {}) {
  return {
    request: (url, options) => {
      const mergedHeaders = new Headers(options.headers);
      
      Object.entries(headers).forEach(([key, value]) => {
        if (typeof value === 'function') {
          const computed = value(url, options);
          if (computed) {
            mergedHeaders.set(key, computed);
          }
        } else if (value) {
          mergedHeaders.set(key, value);
        }
      });
      
      return {
        url,
        options: {
          ...options,
          headers: mergedHeaders
        }
      };
    }
  };
}

// Usage
const headersMiddleware = createHeadersMiddleware({
  'X-Client-Version': '1.0.0',
  'X-Request-ID': () => crypto.randomUUID(),
  'X-User-Agent': () => navigator.userAgent
});
```

### Conditional Request Middleware

#### ETag and Last-Modified Support

```javascript
function createConditionalRequestMiddleware() {
  const cache = new Map();
  
  return {
    request: (url, options) => {
      const method = options.method || 'GET';
      
      if (method !== 'GET') {
        return { url, options };
      }
      
      const cached = cache.get(url);
      
      if (!cached) {
        return { url, options };
      }
      
      const headers = new Headers(options.headers);
      
      if (cached.etag) {
        headers.set('If-None-Match', cached.etag);
      }
      
      if (cached.lastModified) {
        headers.set('If-Modified-Since', cached.lastModified);
      }
      
      return {
        url,
        options: { ...options, headers }
      };
    },
    
    response: async (response, url, options) => {
      if (response.status === 304) {
        // Not modified - return cached response
        const cached = cache.get(url);
        return cached.response.clone();
      }
      
      if (response.ok) {
        const etag = response.headers.get('ETag');
        const lastModified = response.headers.get('Last-Modified');
        
        if (etag || lastModified) {
          cache.set(url, {
            response: response.clone(),
            etag,
            lastModified
          });
        }
      }
      
      return response;
    }
  };
}
```

### Middleware Composition Utilities

#### Middleware Pipeline Builder

```javascript
class FetchPipeline {
  constructor() {
    this.middlewares = [];
  }
  
  use(middleware) {
    this.middlewares.push(middleware);
    return this;
  }
  
	group(builder) {
	  const subPipeline = new FetchPipeline();
	  builder(subPipeline);
	  this.middlewares.push(...subPipeline.middlewares);
	  return this;
	}
	
	when(condition, middleware) {
	  this.middlewares.push(
	    async (url, options, next) => {
	      if (condition(url, options)) {
	        return middleware(url, options, next);
	      }
	      return next(url, options);
	    }
	  );
	  return this;
	}
	
	build() {
	  return createFetchMiddleware(this.middlewares);
	}
}

// Usage
const client = new FetchPipeline()
  .use(createBaseUrlMiddleware('https://api.example.com'))
  .use(createHeadersMiddleware({ 'X-Client': 'web' }))
  .group(pipeline => {
    pipeline
      .use(authMiddleware)
      .use(createCsrfMiddleware());
  })
  .when(
    url => url.includes('/api/'),
    createRateLimitMiddleware(10)
  )
  .use(createLoggingMiddleware())
  .build();

```

---

## Request Transformation with Fetch API

### Header Transformation

#### Adding Custom Headers

```javascript
const response = await fetch('/api/data', {
  headers: {
    'Content-Type': 'application/json',
    'X-API-Key': 'your-api-key',
    'X-Request-ID': crypto.randomUUID(),
    'Accept-Language': 'en-US',
    'X-Client-Version': '1.0.0'
  }
});
```

#### Dynamic Header Generation

```javascript
function createHeaders(options = {}) {
  const headers = new Headers();
  
  // Base headers
  headers.set('Content-Type', options.contentType || 'application/json');
  headers.set('Accept', options.accept || 'application/json');
  
  // Authentication
  if (options.token) {
    headers.set('Authorization', `Bearer ${options.token}`);
  }
  
  // Correlation ID for tracing
  headers.set('X-Correlation-ID', options.correlationId || crypto.randomUUID());
  
  // Client metadata
  headers.set('X-Client-Platform', navigator.platform);
  headers.set('X-Client-Timestamp', new Date().toISOString());
  
  // Custom headers
  if (options.customHeaders) {
    Object.entries(options.customHeaders).forEach(([key, value]) => {
      headers.set(key, value);
    });
  }
  
  return headers;
}

// Usage
const response = await fetch('/api/data', {
  headers: createHeaders({
    token: localStorage.getItem('authToken'),
    customHeaders: {
      'X-Feature-Flag': 'new-ui'
    }
  })
});
```

#### Conditional Headers

```javascript
async function fetchWithConditionalHeaders(url, options = {}) {
  const headers = new Headers(options.headers);
  
  // Add ETag for caching
  const cachedETag = localStorage.getItem(`etag:${url}`);
  if (cachedETag) {
    headers.set('If-None-Match', cachedETag);
  }
  
  // Add Last-Modified for conditional requests
  const lastModified = localStorage.getItem(`lastModified:${url}`);
  if (lastModified) {
    headers.set('If-Modified-Since', lastModified);
  }
  
  // Add compression support
  headers.set('Accept-Encoding', 'gzip, deflate, br');
  
  const response = await fetch(url, {
    ...options,
    headers
  });
  
  // Cache validation headers
  if (response.status === 200) {
    const etag = response.headers.get('ETag');
    const lastMod = response.headers.get('Last-Modified');
    
    if (etag) localStorage.setItem(`etag:${url}`, etag);
    if (lastMod) localStorage.setItem(`lastModified:${url}`, lastMod);
  }
  
  return response;
}
```

#### Header Normalization

```javascript
function normalizeHeaders(headers) {
  const normalized = new Headers();
  
  Object.entries(headers).forEach(([key, value]) => {
    // Convert to kebab-case
    const normalizedKey = key
      .replace(/([a-z])([A-Z])/g, '$1-$2')
      .toLowerCase();
    
    // Trim whitespace
    const normalizedValue = String(value).trim();
    
    // Skip empty values
    if (normalizedValue) {
      normalized.set(normalizedKey, normalizedValue);
    }
  });
  
  return normalized;
}
```

### Body Transformation

#### JSON to FormData

```javascript
function jsonToFormData(obj, formData = new FormData(), parentKey = '') {
  Object.entries(obj).forEach(([key, value]) => {
    const fullKey = parentKey ? `${parentKey}[${key}]` : key;
    
    if (value === null || value === undefined) {
      return;
    }
    
    if (value instanceof File || value instanceof Blob) {
      formData.append(fullKey, value);
    } else if (Array.isArray(value)) {
      value.forEach((item, index) => {
        if (typeof item === 'object' && !(item instanceof File)) {
          jsonToFormData(item, formData, `${fullKey}[${index}]`);
        } else {
          formData.append(`${fullKey}[]`, item);
        }
      });
    } else if (typeof value === 'object' && !(value instanceof Date)) {
      jsonToFormData(value, formData, fullKey);
    } else {
      formData.append(fullKey, value);
    }
  });
  
  return formData;
}

// Usage
const data = {
  name: 'John',
  age: 30,
  tags: ['developer', 'designer'],
  profile: {
    bio: 'Hello world',
    avatar: fileInput.files[0]
  }
};

const response = await fetch('/api/users', {
  method: 'POST',
  body: jsonToFormData(data)
});
```

#### JSON Serialization with Transformation

```javascript
function transformAndSerialize(data, transformers = {}) {
  const transformed = JSON.parse(JSON.stringify(data)); // Deep clone
  
  function transform(obj, path = '') {
    Object.entries(obj).forEach(([key, value]) => {
      const currentPath = path ? `${path}.${key}` : key;
      
      // Apply field-specific transformer
      if (transformers[currentPath]) {
        obj[key] = transformers[currentPath](value);
      }
      
      // Recursively transform nested objects
      if (value && typeof value === 'object' && !Array.isArray(value)) {
        transform(value, currentPath);
      }
    });
  }
  
  transform(transformed);
  return JSON.stringify(transformed);
}

// Usage
const data = {
  user: {
    email: 'user@example.com',
    createdAt: new Date(),
    price: 19.99
  }
};

const body = transformAndSerialize(data, {
  'user.email': (email) => email.toLowerCase(),
  'user.createdAt': (date) => date.toISOString(),
  'user.price': (price) => Math.round(price * 100) // Convert to cents
});

await fetch('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body
});
```

#### Nested Object Flattening

```javascript
function flattenObject(obj, prefix = '', separator = '.') {
  return Object.entries(obj).reduce((acc, [key, value]) => {
    const newKey = prefix ? `${prefix}${separator}${key}` : key;
    
    if (value && typeof value === 'object' && !Array.isArray(value) && 
        !(value instanceof Date) && !(value instanceof File)) {
      Object.assign(acc, flattenObject(value, newKey, separator));
    } else {
      acc[newKey] = value;
    }
    
    return acc;
  }, {});
}

// Usage
const nested = {
  user: {
    profile: {
      name: 'John',
      address: {
        city: 'NYC'
      }
    }
  }
};

const flattened = flattenObject(nested);
// Result: { 'user.profile.name': 'John', 'user.profile.address.city': 'NYC' }

await fetch('/api/data', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(flattened)
});
```

#### Array to Query String

```javascript
function arrayToQueryString(arr, paramName) {
  // Multiple approaches based on API requirements
  
  // Approach 1: Repeated parameter names
  // tags=a&tags=b&tags=c
  const repeated = arr.map(val => `${paramName}=${encodeURIComponent(val)}`).join('&');
  
  // Approach 2: Bracket notation
  // tags[]=a&tags[]=b&tags[]=c
  const brackets = arr.map(val => `${paramName}[]=${encodeURIComponent(val)}`).join('&');
  
  // Approach 3: Comma-separated
  // tags=a,b,c
  const commaSeparated = `${paramName}=${arr.map(encodeURIComponent).join(',')}`;
  
  // Approach 4: Indexed
  // tags[0]=a&tags[1]=b&tags[2]=c
  const indexed = arr.map((val, i) => 
    `${paramName}[${i}]=${encodeURIComponent(val)}`
  ).join('&');
  
  return { repeated, brackets, commaSeparated, indexed };
}
```

#### Binary Data Transformation

```javascript
async function transformBinaryData(file, options = {}) {
  // Convert to ArrayBuffer
  const arrayBuffer = await file.arrayBuffer();
  
  // Transform to Uint8Array
  const uint8Array = new Uint8Array(arrayBuffer);
  
  // Apply transformations
  if (options.encrypt) {
    // Example: XOR cipher (use proper encryption in production)
    const key = options.encryptionKey || 0x42;
    for (let i = 0; i < uint8Array.length; i++) {
      uint8Array[i] ^= key;
    }
  }
  
  // Convert to Blob with new MIME type
  const blob = new Blob([uint8Array], { 
    type: options.mimeType || file.type 
  });
  
  return blob;
}

// Usage
const transformedBlob = await transformBinaryData(file, {
  encrypt: true,
  encryptionKey: 0x5A,
  mimeType: 'application/octet-stream'
});

await fetch('/api/upload', {
  method: 'POST',
  body: transformedBlob
});
```

#### Base64 Encoding/Decoding

```javascript
async function fileToBase64(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result.split(',')[1]);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

function base64ToBlob(base64, mimeType) {
  const byteCharacters = atob(base64);
  const byteNumbers = new Array(byteCharacters.length);
  
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i);
  }
  
  const byteArray = new Uint8Array(byteNumbers);
  return new Blob([byteArray], { type: mimeType });
}

// Usage: Send file as base64 in JSON
const base64Data = await fileToBase64(file);
await fetch('/api/upload', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    filename: file.name,
    data: base64Data,
    mimeType: file.type
  })
});
```

### URL Transformation

#### Query Parameter Building

```javascript
function buildQueryString(params) {
  const searchParams = new URLSearchParams();
  
  Object.entries(params).forEach(([key, value]) => {
    if (value === null || value === undefined) {
      return; // Skip null/undefined
    }
    
    if (Array.isArray(value)) {
      value.forEach(v => searchParams.append(key, v));
    } else if (typeof value === 'object') {
      searchParams.append(key, JSON.stringify(value));
    } else {
      searchParams.append(key, value);
    }
  });
  
  return searchParams.toString();
}

// Usage
const params = {
  search: 'javascript',
  tags: ['fetch', 'api'],
  page: 1,
  filters: { category: 'tech' }
};

const url = `/api/search?${buildQueryString(params)}`;
await fetch(url);
```

#### URL Path Parameter Substitution

```javascript
function buildUrlWithParams(template, params) {
  let url = template;
  
  // Replace path parameters: /users/:id/posts/:postId
  Object.entries(params).forEach(([key, value]) => {
    url = url.replace(`:${key}`, encodeURIComponent(value));
    url = url.replace(`{${key}}`, encodeURIComponent(value));
  });
  
  // Check for unreplaced parameters
  const unreplaced = url.match(/:[a-zA-Z_]+|{[a-zA-Z_]+}/g);
  if (unreplaced) {
    throw new Error(`Missing parameters: ${unreplaced.join(', ')}`);
  }
  
  return url;
}

// Usage
const url = buildUrlWithParams('/users/:userId/posts/:postId', {
  userId: 123,
  postId: 456
});
// Result: /users/123/posts/456

await fetch(url);
```

#### URL Normalization

```javascript
function normalizeUrl(url, baseUrl = '') {
  // Remove duplicate slashes
  let normalized = url.replace(/([^:]\/)\/+/g, '$1');
  
  // Ensure leading slash for relative URLs
  if (!normalized.startsWith('http') && !normalized.startsWith('/')) {
    normalized = '/' + normalized;
  }
  
  // Remove trailing slash
  if (normalized.length > 1 && normalized.endsWith('/')) {
    normalized = normalized.slice(0, -1);
  }
  
  // Combine with base URL
  if (baseUrl) {
    const base = baseUrl.replace(/\/$/, '');
    const path = normalized.startsWith('/') ? normalized : '/' + normalized;
    return base + path;
  }
  
  return normalized;
}

// Usage
const url = normalizeUrl('//api//users//123/', 'https://example.com/');
// Result: https://example.com/api/users/123
```

### Request Method Transformation

#### HTTP Method Override

```javascript
async function fetchWithMethodOverride(url, method, options = {}) {
  // Some servers only accept GET/POST but support X-HTTP-Method-Override
  const actualMethod = ['GET', 'POST'].includes(method) ? method : 'POST';
  
  const headers = new Headers(options.headers);
  
  if (actualMethod !== method) {
    headers.set('X-HTTP-Method-Override', method);
    headers.set('X-HTTP-Method', method);
  }
  
  return fetch(url, {
    ...options,
    method: actualMethod,
    headers
  });
}

// Usage: Send DELETE as POST with override header
await fetchWithMethodOverride('/api/users/123', 'DELETE');
```

#### JSONP to Fetch Migration

```javascript
async function jsonpToFetch(url, callbackParam = 'callback') {
  // Convert JSONP-style URL to regular fetch
  const urlObj = new URL(url);
  urlObj.searchParams.delete(callbackParam);
  
  const response = await fetch(urlObj.toString(), {
    headers: {
      'Accept': 'application/json'
    }
  });
  
  return response.json();
}
```

### Request Body Transformation Pipeline

```javascript
class BodyTransformer {
  constructor() {
    this.transformers = [];
  }
  
  use(transformer) {
    this.transformers.push(transformer);
    return this;
  }
  
  async transform(data) {
    let result = data;
    
    for (const transformer of this.transformers) {
      result = await transformer(result);
    }
    
    return result;
  }
}

// Example transformers
const sanitizeTransformer = (data) => {
  if (typeof data === 'object') {
    const sanitized = {};
    Object.entries(data).forEach(([key, value]) => {
      // Remove null/undefined
      if (value !== null && value !== undefined) {
        sanitized[key] = typeof value === 'string' ? value.trim() : value;
      }
    });
    return sanitized;
  }
  return data;
};

const timestampTransformer = (data) => {
  return {
    ...data,
    timestamp: Date.now(),
    requestId: crypto.randomUUID()
  };
};

const encryptTransformer = async (data) => {
  // Simplified example - use proper encryption
  const json = JSON.stringify(data);
  const encoder = new TextEncoder();
  const dataBuffer = encoder.encode(json);
  
  return {
    encrypted: true,
    data: btoa(String.fromCharCode(...new Uint8Array(dataBuffer)))
  };
};

// Usage
const transformer = new BodyTransformer()
  .use(sanitizeTransformer)
  .use(timestampTransformer)
  .use(encryptTransformer);

const originalData = {
  username: '  john  ',
  email: null,
  age: 30
};

const transformedBody = await transformer.transform(originalData);

await fetch('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(transformedBody)
});
```

### Content Negotiation

```javascript
async function fetchWithContentNegotiation(url, data, options = {}) {
  const acceptedTypes = options.accept || [
    'application/json',
    'application/xml',
    'text/html'
  ];
  
  const headers = new Headers(options.headers);
  headers.set('Accept', acceptedTypes.join(', '));
  
  // Transform body based on Content-Type
  let body = data;
  const contentType = headers.get('Content-Type') || 'application/json';
  
  if (contentType.includes('application/json')) {
    body = JSON.stringify(data);
  } else if (contentType.includes('application/x-www-form-urlencoded')) {
    body = new URLSearchParams(data).toString();
  } else if (contentType.includes('multipart/form-data')) {
    body = jsonToFormData(data);
    headers.delete('Content-Type'); // Let browser set with boundary
  } else if (contentType.includes('text/plain')) {
    body = String(data);
  }
  
  const response = await fetch(url, {
    ...options,
    headers,
    body
  });
  
  // Parse response based on Content-Type
  const responseType = response.headers.get('Content-Type') || '';
  
  if (responseType.includes('application/json')) {
    return response.json();
  } else if (responseType.includes('application/xml') || 
             responseType.includes('text/xml')) {
    const text = await response.text();
    return new DOMParser().parseFromString(text, 'text/xml');
  } else if (responseType.includes('text/')) {
    return response.text();
  } else {
    return response.blob();
  }
}
```

### Request Compression

```javascript
async function compressRequest(data) {
  const json = JSON.stringify(data);
  const encoder = new TextEncoder();
  const dataBuffer = encoder.encode(json);
  
  // Use CompressionStream API (modern browsers)
  const stream = new ReadableStream({
    start(controller) {
      controller.enqueue(dataBuffer);
      controller.close();
    }
  });
  
  const compressedStream = stream.pipeThrough(
    new CompressionStream('gzip')
  );
  
  const compressedData = await new Response(compressedStream).arrayBuffer();
  
  return new Blob([compressedData], { type: 'application/gzip' });
}

// Usage
const largeData = { /* large object */ };
const compressed = await compressRequest(largeData);

await fetch('/api/data', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Content-Encoding': 'gzip'
  },
  body: compressed
});
```

### Multipart Request Building

```javascript
function buildMultipartRequest(parts, boundary) {
  boundary = boundary || `----WebKitFormBoundary${Math.random().toString(36).slice(2)}`;
  
  const lines = [];
  
  parts.forEach(part => {
    lines.push(`--${boundary}`);
    
    // Content-Disposition header
    let disposition = `Content-Disposition: form-data; name="${part.name}"`;
    if (part.filename) {
      disposition += `; filename="${part.filename}"`;
    }
    lines.push(disposition);
    
    // Content-Type header
    if (part.contentType) {
      lines.push(`Content-Type: ${part.contentType}`);
    }
    
    // Additional headers
    if (part.headers) {
      Object.entries(part.headers).forEach(([key, value]) => {
        lines.push(`${key}: ${value}`);
      });
    }
    
    lines.push(''); // Empty line before content
    lines.push(part.content);
  });
  
  lines.push(`--${boundary}--`);
  lines.push('');
  
  return {
    body: lines.join('\r\n'),
    contentType: `multipart/form-data; boundary=${boundary}`
  };
}

// Usage
const multipart = buildMultipartRequest([
  {
    name: 'metadata',
    content: JSON.stringify({ title: 'Document' }),
    contentType: 'application/json'
  },
  {
    name: 'file',
    filename: 'document.pdf',
    content: fileData,
    contentType: 'application/pdf'
  }
]);

await fetch('/api/upload', {
  method: 'POST',
  headers: {
    'Content-Type': multipart.contentType
  },
  body: multipart.body
});
```

### Schema-Based Transformation

```javascript
function transformBySchema(data, schema) {
  const result = {};
  
  Object.entries(schema).forEach(([key, config]) => {
    const value = data[config.from || key];
    
    if (value === undefined && !config.required) {
      if (config.default !== undefined) {
        result[key] = config.default;
      }
      return;
    }
    
    if (value === undefined && config.required) {
      throw new Error(`Missing required field: ${key}`);
    }
    
    let transformed = value;
    
    // Type transformation
    switch (config.type) {
      case 'string':
        transformed = String(value);
        break;
      case 'number':
        transformed = Number(value);
        break;
      case 'boolean':
        transformed = Boolean(value);
        break;
      case 'date':
        transformed = new Date(value).toISOString();
        break;
      case 'array':
        transformed = Array.isArray(value) ? value : [value];
        break;
    }
    
    // Custom transformer
    if (config.transform) {
      transformed = config.transform(transformed);
    }
    
    // Validation
    if (config.validate && !config.validate(transformed)) {
      throw new Error(`Validation failed for field: ${key}`);
    }
    
    result[key] = transformed;
  });
  
  return result;
}

// Usage
const schema = {
  userId: {
    from: 'user_id',
    type: 'number',
    required: true
  },
  fullName: {
    from: 'name',
    type: 'string',
    transform: (v) => v.trim().toUpperCase()
  },
  email: {
    type: 'string',
    validate: (v) => /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(v)
  },
  createdAt: {
    type: 'date',
    default: new Date().toISOString()
  },
  tags: {
    type: 'array',
    default: []
  }
};

const inputData = {
  user_id: '123',
  name: '  john doe  ',
  email: 'john@example.com'
};

const transformed = transformBySchema(inputData, schema);

await fetch('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(transformed)
});
```

### Request Cloning and Modification

```javascript
function cloneAndModifyRequest(request, modifications) {
  const headers = new Headers(request.headers);
  
  // Modify headers
  if (modifications.headers) {
    Object.entries(modifications.headers).forEach(([key, value]) => {
      if (value === null) {
        headers.delete(key);
      } else {
        headers.set(key, value);
      }
    });
  }
  
  // Clone with modifications
  const init = {
    method: modifications.method || request.method,
    headers: headers,
    mode: modifications.mode || request.mode,
    credentials: modifications.credentials || request.credentials,
    cache: modifications.cache || request.cache,
    redirect: modifications.redirect || request.redirect,
    referrer: modifications.referrer || request.referrer,
    integrity: modifications.integrity || request.integrity
  };
  
  // Handle body (can only be read once)
  if (request.method !== 'GET' && request.method !== 'HEAD') {
    init.body = modifications.body || request.body;
  }
  
  const url = modifications.url || request.url;
  
  return new Request(url, init);
}

// Usage
const originalRequest = new Request('/api/data', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ data: 'original' })
});

const modifiedRequest = cloneAndModifyRequest(originalRequest, {
  headers: {
    'Authorization': 'Bearer token123',
    'X-Custom-Header': 'value'
  },
  url: '/api/v2/data'
});

await fetch(modifiedRequest);
```

### Interceptor Pattern

```javascript
class FetchInterceptor {
  constructor() {
    this.requestInterceptors = [];
    this.responseInterceptors = [];
  }
  
  addRequestInterceptor(interceptor) {
    this.requestInterceptors.push(interceptor);
    return this;
  }
  
  addResponseInterceptor(interceptor) {
    this.responseInterceptors.push(interceptor);
    return this;
  }
  
  async fetch(url, options = {}) {
    // Transform request through interceptors
    let transformedUrl = url;
    let transformedOptions = { ...options };
    
    for (const interceptor of this.requestInterceptors) {
      const result = await interceptor(transformedUrl, transformedOptions);
      transformedUrl = result.url || transformedUrl;
      transformedOptions = result.options || transformedOptions;
    }
    
    // Make request
    let response = await fetch(transformedUrl, transformedOptions);
    
    // Transform response through interceptors
    for (const interceptor of this.responseInterceptors) {
      response = await interceptor(response) || response;
    }
    
    return response;
  }
}

// Usage
const interceptor = new FetchInterceptor();

// Add authentication
interceptor.addRequestInterceptor(async (url, options) => {
  const token = await getAuthToken();
  return {
    url,
    options: {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    }
  };
});

// Add timestamp
interceptor.addRequestInterceptor(async (url, options) => {
  const urlObj = new URL(url, window.location.origin);
  urlObj.searchParams.set('_t', Date.now());
  
  return {
    url: urlObj.toString(),
    options
  };
});

// Log response
interceptor.addResponseInterceptor(async (response) => {
  console.log(`Response from ${response.url}: ${response.status}`);
  return response;
});

// Use interceptor
const response = await interceptor.fetch('/api/data', {
  method: 'POST',
  body: JSON.stringify({ data: 'test' })
});
```

### Custom Serialization

```javascript
class CustomSerializer {
  static serialize(data, format = 'json') {
    switch (format) {
      case 'json':
        return this.toJSON(data);
      case 'xml':
        return this.toXML(data);
      case 'yaml':
        return this.toYAML(data);
      case 'msgpack':
        return this.toMsgPack(data);
      default:
        throw new Error(`Unsupported format: ${format}`);
    }
  }
  
  static toJSON(data) {
    return JSON.stringify(data, (key, value) => {
      // Custom Date serialization
      if (value instanceof Date) {
        return { __type: 'Date', value: value.toISOString() };
      }
      // Custom RegExp serialization
      if (value instanceof RegExp) {
        return { __type: 'RegExp', value: value.toString() };
      }
      // Custom Map serialization
      if (value instanceof Map) {
        return {
          __type: 'Map',
          value: Array.from(value.entries())
        };
      }
      // Custom Set serialization
      if (value instanceof Set) {
        return {
          __type: 'Set',
          value: Array.from(value)
        };
      }
      return value;
    });
  }
  
  static toXML(data, rootName = 'root') {
    function buildXML(obj, name) {
      if (obj === null || obj === undefined) {
        return `<${name}/>`;
      }
      
      if (typeof obj !== 'object') {
        return `<${name}>${escapeXML(String(obj))}</${name}>`;
      }
      
      if (Array.isArray(obj)) {
        return obj.map(item => buildXML(item, 'item')).join('');
      }
      
      const children = Object.entries(obj)
        .map(([key, value]) => buildXML(value, key))
        .join('');
      
      return `<${name}>${children}</${name}>`;
    }
    
    function escapeXML(str) {
      return str
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/"/g, '&quot;')
        .replace(/'/g, '&apos;');
    }
    
    return `<?xml version="1.0" encoding="UTF-8"?>${buildXML(data, rootName)}`;
  }
  
  static toYAML(data, indent = 0) {
    const spaces = '  '.repeat(indent);
    
    if (data === null) return 'null';
    if (typeof data === 'boolean') return String(data);
    if (typeof data === 'number') return String(data);
    if (typeof data === 'string') {
      return data.includes('\n') ? `|\n${data.split('\n').map(l => spaces + '  ' + l).join('\n')}` : `"${data}"`;
    }
    
    if (Array.isArray(data)) {
      return '\n' + data.map(item => 
        `${spaces}- ${this.toYAML(item, indent + 1).trim()}` ).join('\n'); }

if (typeof data === 'object') {
  return '\n' + Object.entries(data).map(([key, value]) => {
    const val = this.toYAML(value, indent + 1);
    return `${spaces}${key}:${val.startsWith('\n') ? val : ' ' + val}`;
  }).join('\n');
}

return String(data);

}

static toMsgPack(data) { // Simplified MessagePack encoding function encode(obj) { if (obj === null) return new Uint8Array([0xc0]); if (obj === false) return new Uint8Array([0xc2]); if (obj === true) return new Uint8Array([0xc3]);

  if (typeof obj === 'number') {
    if (Number.isInteger(obj) && obj >= 0 && obj <= 127) {
      return new Uint8Array([obj]);
    }
    // Simplified: just use float64 for all other numbers
    const buffer = new ArrayBuffer(9);
    const view = new DataView(buffer);
    view.setUint8(0, 0xcb);
    view.setFloat64(1, obj);
    return new Uint8Array(buffer);
  }
  
  if (typeof obj === 'string') {
    const encoder = new TextEncoder();
    const strBytes = encoder.encode(obj);
    const len = strBytes.length;
    
    if (len <= 31) {
      const result = new Uint8Array(1 + len);
      result[0] = 0xa0 | len;
      result.set(strBytes, 1);
      return result;
    }
    
    // Simplified: handle longer strings as needed
    throw new Error('String too long for simplified encoding');
  }
  
  throw new Error('Unsupported type for MessagePack');
}

return encode(data);

} }

// Usage const data = { name: 'John', date: new Date(), items: [1, 2, 3] };

const jsonBody = CustomSerializer.serialize(data, 'json'); const xmlBody = CustomSerializer.serialize(data, 'xml'); const yamlBody = CustomSerializer.serialize(data, 'yaml');

await fetch('/api/data', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: jsonBody });
```

---

## Response Transformation with Fetch API

### Understanding Response Immutability

Response objects in the Fetch API are immutable once created. The body stream can only be read once, making response transformation require careful handling through cloning and reconstruction.

```javascript
const response = await fetch('/api/data');

// Body can only be consumed once
const data1 = await response.json(); // Works
const data2 = await response.json(); // TypeError: Body already read

// Must clone to read multiple times
const response2 = await fetch('/api/data');
const clone = response2.clone();
const data3 = await clone.json();
const data4 = await response2.json(); // Both work
```

### Creating New Response Objects

#### Basic Response Construction

```javascript
// Create from scratch
const customResponse = new Response('Hello World', {
  status: 200,
  statusText: 'OK',
  headers: {
    'Content-Type': 'text/plain',
    'X-Custom-Header': 'value'
  }
});

// Create from JSON data
const jsonResponse = new Response(
  JSON.stringify({ message: 'Success', data: [1, 2, 3] }),
  {
    status: 200,
    headers: { 'Content-Type': 'application/json' }
  }
);

// Create from Blob
const blob = new Blob(['Binary data'], { type: 'application/octet-stream' });
const blobResponse = new Response(blob);
```

#### Response Construction from Existing Response

```javascript
const originalResponse = await fetch('/api/data');
const originalBody = await originalResponse.text();

const modifiedResponse = new Response(originalBody, {
  status: originalResponse.status,
  statusText: originalResponse.statusText,
  headers: originalResponse.headers
});
```

### Header Transformation

#### Adding and Modifying Headers

```javascript
async function addHeaders(response, newHeaders) {
  const modifiedHeaders = new Headers(response.headers);
  
  Object.entries(newHeaders).forEach(([key, value]) => {
    modifiedHeaders.set(key, value);
  });
  
  return new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers: modifiedHeaders
  });
}

// Usage
const response = await fetch('/api/data');
const transformed = await addHeaders(response, {
  'X-Processed-By': 'Service Worker',
  'X-Timestamp': Date.now().toString()
});
```

#### Removing Headers

```javascript
async function removeHeaders(response, headersToRemove) {
  const modifiedHeaders = new Headers(response.headers);
  
  headersToRemove.forEach(header => {
    modifiedHeaders.delete(header);
  });
  
  return new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers: modifiedHeaders
  });
}

// Remove sensitive headers before caching
const sanitized = await removeHeaders(response, [
  'Set-Cookie',
  'Authorization',
  'X-Internal-Token'
]);
```

#### Header Value Transformation

```javascript
async function transformHeaderValues(response, transformations) {
  const headers = new Headers(response.headers);
  
  Object.entries(transformations).forEach(([header, transformFn]) => {
    const currentValue = headers.get(header);
    if (currentValue) {
      headers.set(header, transformFn(currentValue));
    }
  });
  
  return new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers
  });
}

// Usage: Modify Cache-Control
const transformed = await transformHeaderValues(response, {
  'Cache-Control': (value) => value.replace('max-age=3600', 'max-age=7200'),
  'Content-Type': (value) => value + '; charset=utf-8'
});
```

### Body Transformation

#### Text Content Transformation

```javascript
async function transformTextResponse(response, transformFn) {
  const text = await response.text();
  const transformedText = transformFn(text);
  
  return new Response(transformedText, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Replace placeholders in HTML
const response = await fetch('/template.html');
const personalized = await transformTextResponse(response, text => {
  return text
    .replace('{{USERNAME}}', currentUser.name)
    .replace('{{TIMESTAMP}}', new Date().toISOString());
});
```

#### JSON Transformation

```javascript
async function transformJSONResponse(response, transformFn) {
  const data = await response.json();
  const transformedData = transformFn(data);
  
  const newBody = JSON.stringify(transformedData);
  const headers = new Headers(response.headers);
  headers.set('Content-Length', new Blob([newBody]).size.toString());
  
  return new Response(newBody, {
    status: response.status,
    statusText: response.statusText,
    headers
  });
}

// Add computed fields to API response
const response = await fetch('/api/users');
const enhanced = await transformJSONResponse(response, data => {
  return data.map(user => ({
    ...user,
    fullName: `${user.firstName} ${user.lastName}`,
    avatarUrl: `/avatars/${user.id}.jpg`,
    isActive: user.lastLogin > Date.now() - 86400000
  }));
});
```

#### Binary Data Transformation

```javascript
async function transformBinaryResponse(response, transformFn) {
  const arrayBuffer = await response.arrayBuffer();
  const transformedBuffer = await transformFn(arrayBuffer);
  
  return new Response(transformedBuffer, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Example: Decompress gzipped response
async function decompressResponse(response) {
  const blob = await response.blob();
  const decompressedStream = blob.stream().pipeThrough(
    new DecompressionStream('gzip')
  );
  
  const headers = new Headers(response.headers);
  headers.delete('Content-Encoding');
  
  return new Response(decompressedStream, {
    status: response.status,
    statusText: response.statusText,
    headers
  });
}
```

### Stream Transformation

#### TransformStream for Body Processing

```javascript
async function transformResponseStream(response, transformer) {
  const transformStream = new TransformStream({
    transform(chunk, controller) {
      const transformed = transformer(chunk);
      controller.enqueue(transformed);
    }
  });
  
  const transformedBody = response.body.pipeThrough(transformStream);
  
  return new Response(transformedBody, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Convert text to uppercase as it streams
const response = await fetch('/api/stream');
const uppercased = await transformResponseStream(response, chunk => {
  const text = new TextDecoder().decode(chunk);
  const transformed = text.toUpperCase();
  return new TextEncoder().encode(transformed);
});
```

#### Line-by-Line Stream Processing

```javascript
class LineTransformStream extends TransformStream {
  constructor(transformFn) {
    let buffer = '';
    
    super({
      transform(chunk, controller) {
        buffer += new TextDecoder().decode(chunk);
        const lines = buffer.split('\n');
        
        // Keep last incomplete line in buffer
        buffer = lines.pop();
        
        lines.forEach(line => {
          const transformed = transformFn(line);
          controller.enqueue(new TextEncoder().encode(transformed + '\n'));
        });
      },
      
      flush(controller) {
        if (buffer) {
          const transformed = transformFn(buffer);
          controller.enqueue(new TextEncoder().encode(transformed));
        }
      }
    });
  }
}

// Usage: Prefix each line with line number
const response = await fetch('/log.txt');
let lineNum = 0;
const numbered = response.body.pipeThrough(
  new LineTransformStream(line => `${++lineNum}: ${line}`)
);

const transformedResponse = new Response(numbered, {
  headers: response.headers
});
```

#### Chunked Processing for Large Responses

```javascript
async function processLargeResponse(response, chunkProcessor) {
  const reader = response.body.getReader();
  const stream = new ReadableStream({
    async start(controller) {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          controller.close();
          break;
        }
        
        const processed = await chunkProcessor(value);
        controller.enqueue(processed);
      }
    }
  });
  
  return new Response(stream, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Filter out specific patterns from stream
const response = await fetch('/large-data.txt');
const filtered = await processLargeResponse(response, chunk => {
  const text = new TextDecoder().decode(chunk);
  const filtered = text.replace(/SENSITIVE_DATA/g, '[REDACTED]');
  return new TextEncoder().encode(filtered);
});
```

### Status Code Transformation

#### Normalizing Error Responses

```javascript
async function normalizeErrorResponse(response) {
  if (!response.ok) {
    const errorBody = await response.text();
    const normalizedBody = JSON.stringify({
      error: true,
      status: response.status,
      message: response.statusText,
      details: errorBody
    });
    
    return new Response(normalizedBody, {
      status: 200, // Normalize to 200 for easier client handling
      statusText: 'OK',
      headers: {
        'Content-Type': 'application/json',
        'X-Original-Status': response.status.toString()
      }
    });
  }
  
  return response;
}
```

#### Converting Status Codes

```javascript
async function convertStatusCode(response, statusMap) {
  const newStatus = statusMap[response.status] || response.status;
  
  return new Response(response.body, {
    status: newStatus,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Convert 404 to 200 with empty array
const response = await fetch('/api/search?q=rare');
const converted = await convertStatusCode(response, {
  404: 200
});

if (response.status === 404) {
  const emptyResult = new Response(JSON.stringify([]), {
    status: 200,
    headers: { 'Content-Type': 'application/json' }
  });
}
```

### Content-Type Transformation

#### Format Conversion

```javascript
async function convertResponseFormat(response, targetFormat) {
  const sourceType = response.headers.get('Content-Type') || '';
  
  if (sourceType.includes('application/json') && targetFormat === 'xml') {
    const data = await response.json();
    const xml = jsonToXml(data); // Implementation needed
    
    return new Response(xml, {
      status: response.status,
      headers: {
        'Content-Type': 'application/xml'
      }
    });
  }
  
  if (sourceType.includes('application/xml') && targetFormat === 'json') {
    const xml = await response.text();
    const data = xmlToJson(xml); // Implementation needed
    
    return new Response(JSON.stringify(data), {
      status: response.status,
      headers: {
        'Content-Type': 'application/json'
      }
    });
  }
  
  return response;
}
```

#### CSV to JSON Transformation

```javascript
async function csvToJsonResponse(response) {
  const csv = await response.text();
  const lines = csv.trim().split('\n');
  const headers = lines[0].split(',');
  
  const data = lines.slice(1).map(line => {
    const values = line.split(',');
    return headers.reduce((obj, header, index) => {
      obj[header.trim()] = values[index]?.trim() || '';
      return obj;
    }, {});
  });
  
  return new Response(JSON.stringify(data), {
    status: response.status,
    headers: {
      'Content-Type': 'application/json'
    }
  });
}
```

### Response Wrapping and Metadata Addition

#### Adding Metadata to Response Body

```javascript
async function wrapWithMetadata(response, metadata) {
  const originalData = await response.json();
  
  const wrappedData = {
    metadata: {
      timestamp: Date.now(),
      source: response.url,
      status: response.status,
      ...metadata
    },
    data: originalData
  };
  
  return new Response(JSON.stringify(wrappedData), {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage
const response = await fetch('/api/users');
const wrapped = await wrapWithMetadata(response, {
  cachedAt: Date.now(),
  version: 'v2',
  count: Array.isArray(await response.clone().json()) 
    ? (await response.clone().json()).length 
    : null
});
```

#### Response Envelope Pattern

```javascript
async function envelopeResponse(response) {
  const body = await response.text();
  let parsedBody;
  
  try {
    parsedBody = JSON.parse(body);
  } catch {
    parsedBody = body;
  }
  
  const envelope = {
    success: response.ok,
    status: response.status,
    statusText: response.statusText,
    headers: Object.fromEntries(response.headers.entries()),
    body: parsedBody,
    timestamp: new Date().toISOString()
  };
  
  return new Response(JSON.stringify(envelope), {
    status: 200,
    headers: {
      'Content-Type': 'application/json'
    }
  });
}
```

### Filtering and Sanitization

#### Removing Sensitive Fields

```javascript
async function sanitizeResponse(response, fieldsToRemove) {
  const data = await response.json();
  
  const sanitize = (obj) => {
    if (Array.isArray(obj)) {
      return obj.map(sanitize);
    }
    
    if (obj && typeof obj === 'object') {
      const sanitized = { ...obj };
      fieldsToRemove.forEach(field => {
        delete sanitized[field];
      });
      
      Object.keys(sanitized).forEach(key => {
        sanitized[key] = sanitize(sanitized[key]);
      });
      
      return sanitized;
    }
    
    return obj;
  };
  
  const sanitizedData = sanitize(data);
  
  return new Response(JSON.stringify(sanitizedData), {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Remove sensitive user fields
const response = await fetch('/api/users');
const public = await sanitizeResponse(response, [
  'password',
  'socialSecurityNumber',
  'creditCard',
  'apiKey'
]);
```

#### Content Filtering

```javascript
async function filterResponseContent(response, predicate) {
  const data = await response.json();
  
  let filtered;
  if (Array.isArray(data)) {
    filtered = data.filter(predicate);
  } else if (data && typeof data === 'object') {
    filtered = Object.entries(data)
      .filter(([_, value]) => predicate(value))
      .reduce((obj, [key, value]) => {
        obj[key] = value;
        return obj;
      }, {});
  } else {
    filtered = data;
  }
  
  return new Response(JSON.stringify(filtered), {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Filter users by active status
const response = await fetch('/api/users');
const activeOnly = await filterResponseContent(
  response,
  user => user.isActive === true
);
```

### Response Merging and Aggregation

#### Combining Multiple Responses

```javascript
async function mergeResponses(responses, mergeStrategy = 'array') {
  const dataPromises = responses.map(r => r.json());
  const allData = await Promise.all(dataPromises);
  
  let merged;
  if (mergeStrategy === 'array') {
    merged = allData.flat();
  } else if (mergeStrategy === 'object') {
    merged = Object.assign({}, ...allData);
  } else if (typeof mergeStrategy === 'function') {
    merged = mergeStrategy(allData);
  }
  
  return new Response(JSON.stringify(merged), {
    status: 200,
    headers: {
      'Content-Type': 'application/json'
    }
  });
}

// Usage: Fetch from multiple endpoints
const [users, posts, comments] = await Promise.all([
  fetch('/api/users'),
  fetch('/api/posts'),
  fetch('/api/comments')
]);

const combined = await mergeResponses([users, posts, comments], data => ({
  users: data[0],
  posts: data[1],
  comments: data[2]
}));
```

#### Paginated Response Aggregation

```javascript
async function aggregatePaginatedResponses(baseUrl, pageParam = 'page') {
  const allData = [];
  let page = 1;
  let hasMore = true;
  
  while (hasMore) {
    const url = `${baseUrl}${baseUrl.includes('?') ? '&' : '?'}${pageParam}=${page}`;
    const response = await fetch(url);
    const data = await response.json();
    
    if (Array.isArray(data) && data.length > 0) {
      allData.push(...data);
      page++;
    } else {
      hasMore = false;
    }
  }
  
  return new Response(JSON.stringify(allData), {
    status: 200,
    headers: {
      'Content-Type': 'application/json',
      'X-Total-Pages': (page - 1).toString()
    }
  });
}
```

### Conditional Transformation

#### Transform Based on Response Characteristics

```javascript
async function conditionalTransform(response, conditions) {
  for (const { predicate, transform } of conditions) {
    if (await predicate(response.clone())) {
      return transform(response);
    }
  }
  
  return response;
}

// Usage
const transformed = await conditionalTransform(response, [
  {
    predicate: async (r) => r.headers.get('Content-Type')?.includes('text/html'),
    transform: async (r) => {
      const html = await r.text();
      const minified = html.replace(/\s+/g, ' ');
      return new Response(minified, { headers: r.headers });
    }
  },
  {
    predicate: async (r) => r.status === 404,
    transform: async (r) => {
      return new Response(JSON.stringify({ error: 'Not found' }), {
        status: 404,
        headers: { 'Content-Type': 'application/json' }
      });
    }
  }
]);
```

#### Transform Based on Request Context

```javascript
async function contextualTransform(request, response, context) {
  const userRole = context.userRole || 'guest';
  
  if (userRole === 'admin') {
    // Admins get full data
    return response;
  }
  
  if (userRole === 'user') {
    // Regular users get filtered data
    return sanitizeResponse(response, ['internalId', 'adminNotes']);
  }
  
  // Guests get minimal data
  const data = await response.json();
  const publicData = Array.isArray(data) 
    ? data.map(item => ({ id: item.id, title: item.title }))
    : { id: data.id, title: data.title };
  
  return new Response(JSON.stringify(publicData), {
    status: response.status,
    headers: response.headers
  });
}
```

### Response Validation and Schema Enforcement

#### Schema Validation

```javascript
async function validateAndTransform(response, schema) {
  const data = await response.json();
  
  const validate = (obj, schema) => {
    const validated = {};
    
    for (const [key, type] of Object.entries(schema)) {
      if (obj.hasOwnProperty(key)) {
        if (typeof obj[key] === type) {
          validated[key] = obj[key];
        } else {
          // Coerce type if possible
          if (type === 'number') {
            validated[key] = Number(obj[key]);
          } else if (type === 'string') {
            validated[key] = String(obj[key]);
          } else if (type === 'boolean') {
            validated[key] = Boolean(obj[key]);
          }
        }
      }
    }
    
    return validated;
  };
  
  const validatedData = Array.isArray(data)
    ? data.map(item => validate(item, schema))
    : validate(data, schema);
  
  return new Response(JSON.stringify(validatedData), {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage
const schema = {
  id: 'number',
  name: 'string',
  isActive: 'boolean',
  createdAt: 'string'
};

const validated = await validateAndTransform(response, schema);
```

#### Default Values Injection

```javascript
async function injectDefaults(response, defaults) {
  const data = await response.json();
  
  const applyDefaults = (obj) => {
    if (Array.isArray(obj)) {
      return obj.map(applyDefaults);
    }
    
    if (obj && typeof obj === 'object') {
      return { ...defaults, ...obj };
    }
    
    return obj;
  };
  
  const enriched = applyDefaults(data);
  
  return new Response(JSON.stringify(enriched), {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Usage: Add default values to all objects
const response = await fetch('/api/items');
const withDefaults = await injectDefaults(response, {
  isActive: true,
  createdAt: new Date().toISOString(),
  version: '1.0'
});
```

### Response Compression and Encoding

#### Manual Compression

```javascript
async function compressResponse(response) {
  const blob = await response.blob();
  const compressionStream = new CompressionStream('gzip');
  const compressedStream = blob.stream().pipeThrough(compressionStream);
  
  const headers = new Headers(response.headers);
  headers.set('Content-Encoding', 'gzip');
  
  return new Response(compressedStream, {
    status: response.status,
    statusText: response.statusText,
    headers
  });
}
```

#### Base64 Encoding Response

```javascript
async function base64EncodeResponse(response) {
  const buffer = await response.arrayBuffer();
  const bytes = new Uint8Array(buffer);
  const binary = bytes.reduce((acc, byte) => acc + String.fromCharCode(byte), '');
  const base64 = btoa(binary);
  
  return new Response(base64, {
    status: response.status,
    headers: {
      'Content-Type': 'text/plain',
      'Content-Transfer-Encoding': 'base64'
    }
  });
}
```

### Caching-Aware Transformations

#### Transform with Cache Consideration

```javascript
async function transformAndCache(request, response, transformFn) {
  const transformed = await transformFn(response.clone());
  
  // Cache the transformed version
  const cache = await caches.open('transformed-v1');
  await cache.put(request, transformed.clone());
  
  return transformed;
}

// Usage in service worker
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      if (cached) return cached;
      
      return fetch(event.request).then(response => {
        return transformAndCache(
          event.request,
          response,
          async (r) => {
            // Apply transformation
            const data = await r.json();
            const enhanced = data.map(item => ({
              ...item,
              cached: true,
              timestamp: Date.now()
            }));
            
            return new Response(JSON.stringify(enhanced), {
              headers: r.headers
            });
          }
        );
      });
    })
  );
});
```

### Error Response Transformation

#### Standardizing Error Format

```javascript
async function standardizeErrorResponse(response) {
  if (!response.ok) {
    let errorDetails;
    
    try {
      errorDetails = await response.json();
    } catch {
      errorDetails = await response.text();
    }
    
    const standardError = {
      error: {
        code: response.status,
        message: response.statusText,
        details: errorDetails,
        timestamp: new Date().toISOString(),
        requestId: response.headers.get('X-Request-Id') || null
      }
    };
    
    return new Response(JSON.stringify(standardError), {
      status: response.status,
      headers: {
        'Content-Type': 'application/json'
      }
    });
  }
  
  return response;
}
```

#### Retry with Transformed Request

```javascript
async function transformAndRetry(request, response, maxRetries = 3) {
  let attempt = 0;
  let currentResponse = response;
  
  while (!currentResponse.ok && attempt < maxRetries) {
    // Transform request for retry
    const retryRequest = new Request(request.url, {
      method: request.method,
      headers: new Headers({
        ...Object.fromEntries(request.headers.entries()),
        'X-Retry-Attempt': (attempt + 1).toString()
      }),
      body: request.body
    });
    
    currentResponse = await fetch(retryRequest);
    attempt++;
  }
  
  return currentResponse;
}
```

### Performance Optimization Through Transformation

#### Lazy Loading Transformation

```javascript
async function createLazyLoadResponse(response, chunkSize = 100) {
  const allData = await response.json();
  
  // Store full data in closure
  let offset = 0;
  
  // Return initial chunk
  const initialChunk = allData.slice(0, chunkSize);
  const hasMore = allData.length > chunkSize;
  
  const responseBody = {
    data: initialChunk,
    pagination: {
      offset: 0,
      limit: chunkSize,
      total: allData.length,
      hasMore
    }
  };
  
  return new Response(JSON.stringify(responseBody), {
    status: response.status,
    headers: {
      'Content-Type': 'application/json',
      'X-Has-More': hasMore.toString()
    }
  });
}
```

#### Response Deduplication

```javascript
async function deduplicateResponse(response, keyFn = item => item.id) {
  const data = await response.json();
  
  if (!Array.isArray(data)) {
    return response;
  }
  
  const seen = new Set();
  const deduplicated = data.filter(item => {
    const key = keyFn(item);
    if (seen.has(key)) {
      return false;
    }
    seen.add(key);
    return true;
  });
  
  return new Response(JSON.stringify(deduplicated), {
    status: response.status,
    headers: {
      ...Object.fromEntries(response.headers.entries()),
      'X-Original-Count': data.length.toString(),
      'X-Deduplicated-Count': deduplicated.length.toString()
    }
  });
}
```

---

## Logging and Monitoring with Request Interceptors

### Native Fetch Interception Approaches

The fetch API does not provide built-in interceptor mechanisms like some HTTP libraries (e.g., Axios). Interception requires wrapping or monkey-patching the global fetch function.

### Basic Fetch Wrapper Pattern

#### Simple Logging Wrapper

```javascript
const originalFetch = window.fetch;

window.fetch = function(...args) {
  const [resource, config] = args;
  
  console.log('Fetch initiated:', {
    url: resource,
    method: config?.method || 'GET',
    headers: config?.headers,
    timestamp: new Date().toISOString()
  });
  
  return originalFetch.apply(this, args);
};
```

This wraps the native fetch to log every request without modifying application code.

#### Request and Response Logging

```javascript
const originalFetch = window.fetch;

window.fetch = async function(...args) {
  const [resource, config] = args;
  const startTime = performance.now();
  
  console.log('→ Request:', {
    url: resource,
    method: config?.method || 'GET',
    timestamp: new Date().toISOString()
  });
  
  try {
    const response = await originalFetch.apply(this, args);
    const duration = performance.now() - startTime;
    
    console.log('← Response:', {
      url: resource,
      status: response.status,
      statusText: response.statusText,
      duration: `${duration.toFixed(2)}ms`,
      timestamp: new Date().toISOString()
    });
    
    return response;
  } catch (error) {
    const duration = performance.now() - startTime;
    
    console.error('✗ Request failed:', {
      url: resource,
      error: error.message,
      duration: `${duration.toFixed(2)}ms`,
      timestamp: new Date().toISOString()
    });
    
    throw error;
  }
};
```

### Advanced Interceptor Implementation

#### Class-Based Interceptor Manager

```javascript
class FetchInterceptor {
  constructor() {
    this.requestInterceptors = [];
    this.responseInterceptors = [];
    this.errorInterceptors = [];
    this.originalFetch = window.fetch;
    this.isAttached = false;
  }
  
  attach() {
    if (this.isAttached) return;
    
    const self = this;
    
    window.fetch = async function(...args) {
      let [resource, config] = args;
      
      // Run request interceptors
      for (const interceptor of self.requestInterceptors) {
        const result = await interceptor(resource, config);
        if (result) {
          resource = result.resource || resource;
          config = result.config || config;
        }
      }
      
      try {
        let response = await self.originalFetch(resource, config);
        
        // Run response interceptors
        for (const interceptor of self.responseInterceptors) {
          const result = await interceptor(response, resource, config);
          if (result) {
            response = result;
          }
        }
        
        return response;
      } catch (error) {
        // Run error interceptors
        for (const interceptor of self.errorInterceptors) {
          await interceptor(error, resource, config);
        }
        throw error;
      }
    };
    
    this.isAttached = true;
  }
  
  detach() {
    if (!this.isAttached) return;
    window.fetch = this.originalFetch;
    this.isAttached = false;
  }
  
  addRequestInterceptor(interceptor) {
    this.requestInterceptors.push(interceptor);
    return () => {
      const index = this.requestInterceptors.indexOf(interceptor);
      if (index > -1) {
        this.requestInterceptors.splice(index, 1);
      }
    };
  }
  
  addResponseInterceptor(interceptor) {
    this.responseInterceptors.push(interceptor);
    return () => {
      const index = this.responseInterceptors.indexOf(interceptor);
      if (index > -1) {
        this.responseInterceptors.splice(index, 1);
      }
    };
  }
  
  addErrorInterceptor(interceptor) {
    this.errorInterceptors.push(interceptor);
    return () => {
      const index = this.errorInterceptors.indexOf(interceptor);
      if (index > -1) {
        this.errorInterceptors.splice(index, 1);
      }
    };
  }
  
  clear() {
    this.requestInterceptors = [];
    this.responseInterceptors = [];
    this.errorInterceptors = [];
  }
}
```

#### Usage Example

```javascript
const interceptor = new FetchInterceptor();
interceptor.attach();

// Add request logging
interceptor.addRequestInterceptor((resource, config) => {
  console.log('Request to:', resource);
  return { resource, config };
});

// Add response logging
interceptor.addResponseInterceptor((response, resource, config) => {
  console.log('Response from:', resource, 'Status:', response.status);
  return response;
});

// Add error handling
interceptor.addErrorInterceptor((error, resource, config) => {
  console.error('Request failed:', resource, error);
});
```

### Performance Monitoring

#### Timing Metrics Collection

```javascript
class PerformanceMonitor {
  constructor() {
    this.metrics = [];
  }
  
  createInterceptor() {
    return async (resource, config) => {
      const url = typeof resource === 'string' ? resource : resource.url;
      const startTime = performance.now();
      const startMark = `fetch-start-${Date.now()}`;
      const endMark = `fetch-end-${Date.now()}`;
      
      performance.mark(startMark);
      
      const originalFetch = window.fetch;
      
      try {
        const response = await originalFetch(resource, config);
        performance.mark(endMark);
        
        const duration = performance.now() - startTime;
        
        this.metrics.push({
          url,
          method: config?.method || 'GET',
          status: response.status,
          duration,
          startTime: new Date(startTime),
          success: response.ok,
          cached: response.headers.has('Age'),
          size: response.headers.get('Content-Length')
        });
        
        performance.measure(`fetch-${url}`, startMark, endMark);
        
        return response;
      } catch (error) {
        performance.mark(endMark);
        const duration = performance.now() - startTime;
        
        this.metrics.push({
          url,
          method: config?.method || 'GET',
          duration,
          startTime: new Date(startTime),
          success: false,
          error: error.message
        });
        
        throw error;
      }
    };
  }
  
  getMetrics() {
    return this.metrics;
  }
  
  getAverageResponseTime(url) {
    const filtered = url 
      ? this.metrics.filter(m => m.url === url)
      : this.metrics;
    
    if (filtered.length === 0) return 0;
    
    const sum = filtered.reduce((acc, m) => acc + m.duration, 0);
    return sum / filtered.length;
  }
  
  getSuccessRate(url) {
    const filtered = url 
      ? this.metrics.filter(m => m.url === url)
      : this.metrics;
    
    if (filtered.length === 0) return 0;
    
    const successful = filtered.filter(m => m.success).length;
    return (successful / filtered.length) * 100;
  }
  
  getSlowestRequests(count = 10) {
    return [...this.metrics]
      .sort((a, b) => b.duration - a.duration)
      .slice(0, count);
  }
  
  clear() {
    this.metrics = [];
  }
}
```

#### Integration

```javascript
const monitor = new PerformanceMonitor();
const originalFetch = window.fetch;

window.fetch = async function(...args) {
  const interceptor = monitor.createInterceptor();
  return interceptor(...args);
};

// Later, analyze metrics
console.log('Average response time:', monitor.getAverageResponseTime());
console.log('Success rate:', monitor.getSuccessRate(), '%');
console.log('Slowest requests:', monitor.getSlowestRequests(5));
```

### Request Modification Interceptors

#### Adding Authentication Headers

```javascript
interceptor.addRequestInterceptor((resource, config = {}) => {
  const token = localStorage.getItem('authToken');
  
  if (token) {
    config.headers = {
      ...config.headers,
      'Authorization': `Bearer ${token}`
    };
  }
  
  return { resource, config };
});
```

#### Adding Default Headers

```javascript
interceptor.addRequestInterceptor((resource, config = {}) => {
  config.headers = {
    'Content-Type': 'application/json',
    'X-Client-Version': '1.2.3',
    'X-Request-ID': crypto.randomUUID(),
    ...config.headers
  };
  
  return { resource, config };
});
```

#### Request Transformation

```javascript
interceptor.addRequestInterceptor((resource, config = {}) => {
  if (config.body && typeof config.body === 'object') {
    // Transform object to JSON string
    config.body = JSON.stringify(config.body);
    config.headers = {
      'Content-Type': 'application/json',
      ...config.headers
    };
  }
  
  return { resource, config };
});
```

#### URL Modification

```javascript
interceptor.addRequestInterceptor((resource, config) => {
  const baseURL = 'https://api.example.com';
  
  if (typeof resource === 'string' && !resource.startsWith('http')) {
    resource = `${baseURL}${resource.startsWith('/') ? '' : '/'}${resource}`;
  }
  
  return { resource, config };
});
```

### Response Processing Interceptors

#### Response Data Extraction

```javascript
interceptor.addResponseInterceptor(async (response, resource, config) => {
  const clonedResponse = response.clone();
  
  if (response.ok) {
    try {
      const data = await response.json();
      console.log('Response data:', data);
    } catch (e) {
      // Not JSON, ignore
    }
  }
  
  return clonedResponse;
});
```

Note: Response bodies can only be read once, so cloning is necessary for inspection without consuming the original.

#### Status Code Handling

```javascript
interceptor.addResponseInterceptor(async (response, resource, config) => {
  if (response.status === 401) {
    console.warn('Unauthorized request, redirecting to login');
    window.location.href = '/login';
  }
  
  if (response.status === 403) {
    console.error('Forbidden access to:', resource);
  }
  
  if (response.status >= 500) {
    console.error('Server error occurred:', response.status);
  }
  
  return response;
});
```

#### Response Caching

```javascript
const responseCache = new Map();

interceptor.addResponseInterceptor(async (response, resource, config) => {
  if (response.ok && config?.method === 'GET') {
    const cloned = response.clone();
    const data = await cloned.json();
    
    responseCache.set(resource, {
      data,
      timestamp: Date.now(),
      status: response.status,
      headers: Object.fromEntries(response.headers.entries())
    });
  }
  
  return response;
});
```

### Error Handling and Retry Logic

#### Automatic Retry Mechanism

```javascript
async function fetchWithRetry(resource, config = {}, maxRetries = 3) {
  const originalFetch = window.fetch;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await originalFetch(resource, config);
      
      if (response.ok) {
        return response;
      }
      
      // Retry on 5xx errors
      if (response.status >= 500 && attempt < maxRetries) {
        const delay = Math.pow(2, attempt) * 1000; // Exponential backoff
        console.log(`Retrying after ${delay}ms (attempt ${attempt + 1}/${maxRetries})`);
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
      
      return response;
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = Math.pow(2, attempt) * 1000;
      console.log(`Network error, retrying after ${delay}ms (attempt ${attempt + 1}/${maxRetries})`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

#### Circuit Breaker Pattern

```javascript
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.failureCount = 0;
    this.threshold = threshold;
    this.timeout = timeout;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.nextAttempt = Date.now();
  }
  
  async execute(fn) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }
    
    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failureCount = 0;
    this.state = 'CLOSED';
  }
  
  onFailure() {
    this.failureCount++;
    
    if (this.failureCount >= this.threshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.timeout;
      console.warn('Circuit breaker opened due to failures');
    }
  }
  
  reset() {
    this.failureCount = 0;
    this.state = 'CLOSED';
    this.nextAttempt = Date.now();
  }
}

// Usage
const breaker = new CircuitBreaker(5, 30000);

async function protectedFetch(resource, config) {
  return breaker.execute(() => fetch(resource, config));
}
```

### Structured Logging

#### Contextual Logger

```javascript
class RequestLogger {
  constructor(context = {}) {
    this.context = context;
    this.logs = [];
  }
  
  log(level, message, data = {}) {
    const entry = {
      level,
      message,
      timestamp: new Date().toISOString(),
      context: this.context,
      ...data
    };
    
    this.logs.push(entry);
    
    const method = level === 'error' ? 'error' : 
                   level === 'warn' ? 'warn' : 'log';
    console[method](`[${level.toUpperCase()}]`, message, entry);
  }
  
  info(message, data) {
    this.log('info', message, data);
  }
  
  warn(message, data) {
    this.log('warn', message, data);
  }
  
  error(message, data) {
    this.log('error', message, data);
  }
  
  createRequestLogger() {
    return (resource, config) => {
      const requestId = crypto.randomUUID();
      const url = typeof resource === 'string' ? resource : resource.url;
      
      this.info('Request initiated', {
        requestId,
        url,
        method: config?.method || 'GET',
        headers: config?.headers
      });
      
      return { resource, config: { ...config, requestId } };
    };
  }
  
  createResponseLogger() {
    return (response, resource, config) => {
      const url = typeof resource === 'string' ? resource : resource.url;
      
      this.info('Response received', {
        requestId: config?.requestId,
        url,
        status: response.status,
        statusText: response.statusText,
        headers: Object.fromEntries(response.headers.entries())
      });
      
      return response;
    };
  }
  
  createErrorLogger() {
    return (error, resource, config) => {
      const url = typeof resource === 'string' ? resource : resource.url;
      
      this.error('Request failed', {
        requestId: config?.requestId,
        url,
        method: config?.method || 'GET',
        error: error.message,
        stack: error.stack
      });
    };
  }
  
  getLogs(filter = {}) {
    let filtered = this.logs;
    
    if (filter.level) {
      filtered = filtered.filter(log => log.level === filter.level);
    }
    
    if (filter.since) {
      filtered = filtered.filter(log => new Date(log.timestamp) >= filter.since);
    }
    
    return filtered;
  }
  
  exportLogs() {
    return JSON.stringify(this.logs, null, 2);
  }
  
  clear() {
    this.logs = [];
  }
}
```

#### Usage with Interceptor

```javascript
const logger = new RequestLogger({ service: 'frontend', version: '1.0.0' });
const interceptor = new FetchInterceptor();

interceptor.addRequestInterceptor(logger.createRequestLogger());
interceptor.addResponseInterceptor(logger.createResponseLogger());
interceptor.addErrorInterceptor(logger.createErrorLogger());

interceptor.attach();
```

### Request Deduplication

#### Preventing Duplicate Concurrent Requests

```javascript
class RequestDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  createInterceptor() {
    return async (resource, config = {}) => {
      const key = this.generateKey(resource, config);
      
      if (this.pendingRequests.has(key)) {
        console.log('Deduplicating request:', key);
        return this.pendingRequests.get(key);
      }
      
      const promise = fetch(resource, config)
        .finally(() => {
          this.pendingRequests.delete(key);
        });
      
      this.pendingRequests.set(key, promise);
      return promise;
    };
  }
  
  generateKey(resource, config) {
    const url = typeof resource === 'string' ? resource : resource.url;
    const method = config.method || 'GET';
    const body = config.body ? JSON.stringify(config.body) : '';
    
    return `${method}:${url}:${body}`;
  }
  
  clear() {
    this.pendingRequests.clear();
  }
}
```

### Request Queuing and Rate Limiting

#### Rate Limiter

```javascript
class RateLimiter {
  constructor(maxRequests = 10, timeWindow = 1000) {
    this.maxRequests = maxRequests;
    this.timeWindow = timeWindow;
    this.requests = [];
  }
  
  async waitForSlot() {
    const now = Date.now();
    this.requests = this.requests.filter(time => now - time < this.timeWindow);
    
    if (this.requests.length >= this.maxRequests) {
      const oldestRequest = Math.min(...this.requests);
      const waitTime = this.timeWindow - (now - oldestRequest);
      
      console.log(`Rate limit reached, waiting ${waitTime}ms`);
      await new Promise(resolve => setTimeout(resolve, waitTime + 10));
      return this.waitForSlot();
    }
    
    this.requests.push(now);
  }
  
  createInterceptor() {
    return async (resource, config) => {
      await this.waitForSlot();
      return { resource, config };
    };
  }
}

// Usage
const rateLimiter = new RateLimiter(5, 1000); // 5 requests per second
interceptor.addRequestInterceptor(rateLimiter.createInterceptor());
```

#### Request Queue

```javascript
class RequestQueue {
  constructor(concurrency = 3) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async enqueue(fn) {
    while (this.active >= this.concurrency) {
      await new Promise(resolve => {
        this.queue.push(resolve);
      });
    }
    
    this.active++;
    
    try {
      return await fn();
    } finally {
      this.active--;
      const next = this.queue.shift();
      if (next) next();
    }
  }
  
  createInterceptor() {
    return async (resource, config) => {
      const result = await this.enqueue(async () => {
        return { resource, config };
      });
      return result;
    };
  }
}
```

### Analytics and Metrics Export

#### Metrics Aggregator

```javascript
class MetricsAggregator {
  constructor() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalDuration: 0,
      byEndpoint: new Map(),
      byStatusCode: new Map(),
      byMethod: new Map()
    };
  }
  
  record(data) {
    this.metrics.totalRequests++;
    
    if (data.success) {
      this.metrics.successfulRequests++;
    } else {
      this.metrics.failedRequests++;
    }
    
    this.metrics.totalDuration += data.duration;
    
    // By endpoint
    const endpointStats = this.metrics.byEndpoint.get(data.url) || {
      count: 0,
      totalDuration: 0,
      successes: 0,
      failures: 0
    };
    endpointStats.count++;
    endpointStats.totalDuration += data.duration;
    if (data.success) endpointStats.successes++;
    else endpointStats.failures++;
    this.metrics.byEndpoint.set(data.url, endpointStats);
    
    // By status code
    if (data.status) {
      const statusCount = this.metrics.byStatusCode.get(data.status) || 0;
      this.metrics.byStatusCode.set(data.status, statusCount + 1);
    }
    
    // By method
    const methodCount = this.metrics.byMethod.get(data.method) || 0;
    this.metrics.byMethod.set(data.method, methodCount + 1);
  }
  
  getReport() {
    return {
      summary: {
        totalRequests: this.metrics.totalRequests,
        successRate: (this.metrics.successfulRequests / this.metrics.totalRequests * 100).toFixed(2) + '%',
        averageDuration: (this.metrics.totalDuration / this.metrics.totalRequests).toFixed(2) + 'ms'
      },
      byEndpoint: Object.fromEntries(
        Array.from(this.metrics.byEndpoint.entries()).map(([url, stats]) => [
          url,
          {
            ...stats,
            averageDuration: (stats.totalDuration / stats.count).toFixed(2) + 'ms',
            successRate: (stats.successes / stats.count * 100).toFixed(2) + '%'
          }
        ])
      ),
      byStatusCode: Object.fromEntries(this.metrics.byStatusCode),
      byMethod: Object.fromEntries(this.metrics.byMethod)
    };
  }
  
  sendToAnalytics() {
    const report = this.getReport();
    
    // Send to analytics service
    fetch('https://analytics.example.com/metrics', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(report)
    }).catch(err => console.error('Failed to send metrics:', err));
  }
  
  reset() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalDuration: 0,
      byEndpoint: new Map(),
      byStatusCode: new Map(),
      byMethod: new Map()
    };
  }
}
```

### Development vs Production Interceptors

#### Environment-Aware Configuration

```javascript
class InterceptorConfig {
  constructor(environment = 'development') {
    this.environment = environment;
    this.interceptor = new FetchInterceptor();
  }
  
  setup() {
    if (this.environment === 'development') {
      this.setupDevelopment();
    } else {
      this.setupProduction();
    }
    
    this.interceptor.attach();
  }
  
  setupDevelopment() {
    // Verbose logging
    this.interceptor.addRequestInterceptor((resource, config) => {
      console.group('🚀 Request');
      console.log('URL:', resource);
      console.log('Method:', config?.method || 'GET');
      console.log('Headers:', config?.headers);
      console.log('Body:', config?.body);
      console.groupEnd();
      return { resource, config };
    });
    
    this.interceptor.addResponseInterceptor(async (response, resource) => {
      const cloned = response.clone();
      console.group('✅ Response');
      console.log('URL:', resource);
      console.log('Status:', response.status);
      console.log('Headers:', Object.fromEntries(response.headers.entries()));
      try {
        const data = await cloned.json();
        console.log('Data:', data);
      } catch (e) {
        // Not JSON
      }
      console.groupEnd();
      return response;
    });
    
    // Mock slow network
    this.interceptor.addRequestInterceptor(async (resource, config) => {
      await new Promise(resolve => setTimeout(resolve, 500));
      return { resource, config };
    });
  }
  
  setupProduction() {
    // Error tracking only
    const metrics = new MetricsAggregator();
    
    this.interceptor.addErrorInterceptor((error, resource, config) => {
      metrics.record({
        url: resource,
        method: config?.method || 'GET',
        success: false,
        error: error.message,
        duration: 0
      });
      
      // Send to error tracking service
      fetch('https://errors.example.com/track', {
        method: 'POST',
        body: JSON.stringify({
          error: error.message,
          url: resource,
          timestamp: Date.now()
        })
      }).catch(() => {}); // Silent fail
    });
    
    // Periodic metrics reporting
    setInterval(() => {
      metrics.sendToAnalytics();
      metrics.reset();
    }, 60000); // Every minute
  }
}

// Usage
const config = new InterceptorConfig(process.env.NODE_ENV);
config.setup();
```

### Request/Response Transformation Pipeline

#### Composable Transformers

```javascript
class TransformPipeline {
  constructor() {
    this.requestTransformers = [];
    this.responseTransformers = [];
  }
  
  addRequestTransformer(transformer) {
    this.requestTransformers.push(transformer);
  }
  
  addResponseTransformer(transformer) {
    this.responseTransformers.push(transformer);
  }
  
  async transformRequest(resource, config) {
    let result = { resource, config };
    
    for (const transformer of this.requestTransformers) {
      result = await transformer(result.resource, result.config);
    }
    
    return result;
  }
  
  async transformResponse(response) {
    let result = response;
    
    for (const transformer of this.responseTransformers) {
      result = await transformer(result);
    }
    
    return result;
  }
  
  createInterceptor() {
    return {
      request: async (resource, config) => {
        return this.transformRequest(resource, config);
      },
      response: async (response) => {
        return this.transformResponse(response);
      }
    };
  }
}

// Example transformers
const jsonTransformer = (resource, config) => {
  if (config?.body && typeof config.body === 'object') {
    config.body = JSON.stringify(config.body);
    config.headers = {
      'Content-Type': 'application/json',
      ...config.headers
    };
  }
  return { resource, config };
};

const authTransformer = (resource, config = {}) => {
  const token = getAuthToken();
  if (token) {
    config.headers = {
      ...config.headers,
      'Authorization': `Bearer ${token}`
    };
  }
  return { resource, config };
};

const responseDataTransformer = async (response) => {
  if (response.ok && response.headers.get('Content-Type')?.includes('json')) {
    const data = await response.json();
    // Add transformed data to response object
    response.data = data;
  }
  return response;
};

// Usage
const pipeline = new TransformPipeline();
pipeline.addRequestTransformer(jsonTransformer);
pipeline.addRequestTransformer(authTransformer);
pipeline.addResponseTransformer(responseDataTransformer);
```

### Memory Management Considerations

Interceptors that store data (logs, metrics, cached responses) can accumulate memory over time. Implement cleanup strategies:

```javascript
class ManagedInterceptor {
  constructor(maxLogSize = 1000, maxCacheSize = 100) {
    this.logs = [];
    this.cache = new Map();
    this.maxLogSize = maxLogSize;
    this.maxCacheSize = maxCacheSize;
  }
  
  addLog(entry) {
    this.logs.push(entry);
    
    if (this.logs.length > this.maxLogSize) {
      this.logs = this.logs.slice(-this.maxLogSize);
    }
  }
  
  addToCache(key, value) {
    if (this.cache.size >= this.maxCacheSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }
    
    this.cache.set(key, value);
  }
  
  clearOldLogs(maxAge = 3600000) { // 1 hour default
    const now = Date.now();
    this.logs = this.logs.filter(log => 
      now - new Date(log.timestamp).getTime() < maxAge
    );
  }
  
  clearStaleCache(maxAge = 600000) { // 10 minutes default
    const now = Date.now();
    for (const [key, value] of this.cache.entries()) {
      if (now - value.timestamp > maxAge) {
        this.cache.delete(key);
      }
    }
  }
}
```

---

## Authentication Injection with Fetch API

### Authorization Header

The `Authorization` header is the primary mechanism for injecting authentication credentials into fetch requests.

```javascript
const response = await fetch('/api/protected', {
  headers: {
    'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...'
  }
});
```

**Common Authorization Schemes:**

- `Bearer <token>` - OAuth 2.0, JWT tokens
- `Basic <credentials>` - Base64-encoded username:password
- `Digest <credentials>` - Digest authentication
- `API-Key <key>` - Custom API key schemes

### Bearer Token Authentication

OAuth 2.0 and JWT token injection pattern.

```javascript
class AuthenticatedFetch {
  constructor(accessToken) {
    this.accessToken = accessToken;
  }
  
  async fetch(url, options = {}) {
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.accessToken}`
      }
    });
  }
}

// Usage
const authFetch = new AuthenticatedFetch('your-jwt-token');
const response = await authFetch.fetch('/api/user/profile');
```

### Basic Authentication

HTTP Basic Authentication with base64-encoded credentials.

```javascript
function createBasicAuthHeader(username, password) {
  const credentials = btoa(`${username}:${password}`);
  return `Basic ${credentials}`;
}

const response = await fetch('/api/protected', {
  headers: {
    'Authorization': createBasicAuthHeader('user@example.com', 'password123')
  }
});
```

**Security Note:** Basic authentication transmits credentials with every request and should only be used over HTTPS.

### Custom API Key Headers

Many APIs use custom headers for API key authentication.

```javascript
const response = await fetch('https://api.example.com/data', {
  headers: {
    'X-API-Key': 'your-api-key-here',
    'Content-Type': 'application/json'
  }
});

// Alternative header names
const response2 = await fetch('https://api.example.com/data', {
  headers: {
    'X-Auth-Token': 'token',
    'X-Client-Id': 'client-id',
    'X-Client-Secret': 'client-secret'
  }
});
```

### Token Refresh Pattern

Automatic token refresh when access tokens expire.

```javascript
class TokenManager {
  constructor(accessToken, refreshToken) {
    this.accessToken = accessToken;
    this.refreshToken = refreshToken;
    this.refreshPromise = null;
  }
  
  async fetch(url, options = {}) {
    try {
      return await this.fetchWithAuth(url, options);
    } catch (error) {
      if (error.status === 401) {
        // Token expired, refresh and retry
        await this.refreshAccessToken();
        return await this.fetchWithAuth(url, options);
      }
      throw error;
    }
  }
  
  async fetchWithAuth(url, options = {}) {
    const response = await fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.accessToken}`
      }
    });
    
    if (response.status === 401) {
      const error = new Error('Unauthorized');
      error.status = 401;
      throw error;
    }
    
    return response;
  }
  
  async refreshAccessToken() {
    // Prevent multiple simultaneous refresh requests
    if (this.refreshPromise) {
      return this.refreshPromise;
    }
    
    this.refreshPromise = (async () => {
      try {
        const response = await fetch('/auth/refresh', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            refreshToken: this.refreshToken
          })
        });
        
        if (!response.ok) {
          throw new Error('Refresh failed');
        }
        
        const data = await response.json();
        this.accessToken = data.accessToken;
        
        if (data.refreshToken) {
          this.refreshToken = data.refreshToken;
        }
        
      } finally {
        this.refreshPromise = null;
      }
    })();
    
    return this.refreshPromise;
  }
}

// Usage
const tokenManager = new TokenManager('access-token', 'refresh-token');
const response = await tokenManager.fetch('/api/protected-resource');
```

### Credentials Mode

The `credentials` option controls cookie and authentication header transmission.

```javascript
// Send cookies only for same-origin requests (default)
const response1 = await fetch('/api/data', {
  credentials: 'same-origin'
});

// Always send cookies, even cross-origin
const response2 = await fetch('https://api.example.com/data', {
  credentials: 'include'
});

// Never send cookies
const response3 = await fetch('/api/data', {
  credentials: 'omit'
});
```

**CORS Requirements for `credentials: 'include'`:**

```javascript
// Server must respond with:
// Access-Control-Allow-Credentials: true
// Access-Control-Allow-Origin: https://specific-origin.com (not *)

const response = await fetch('https://api.example.com/data', {
  credentials: 'include',
  headers: {
    'Authorization': 'Bearer token'
  }
});
```

### Cookie-Based Authentication

Session cookies are automatically sent when `credentials` is configured.

```javascript
// Login request sets session cookie
const loginResponse = await fetch('/auth/login', {
  method: 'POST',
  credentials: 'include', // Receive and store cookies
  headers: {
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    username: 'user',
    password: 'pass'
  })
});

// Subsequent requests automatically include session cookie
const dataResponse = await fetch('/api/protected', {
  credentials: 'include' // Send cookies
});
```

### Interceptor Pattern

Global authentication injection for all fetch requests.

```javascript
class FetchInterceptor {
  constructor() {
    this.requestInterceptors = [];
    this.responseInterceptors = [];
  }
  
  addRequestInterceptor(interceptor) {
    this.requestInterceptors.push(interceptor);
  }
  
  addResponseInterceptor(interceptor) {
    this.responseInterceptors.push(interceptor);
  }
  
  async fetch(url, options = {}) {
    // Apply request interceptors
    let modifiedOptions = { ...options };
    for (const interceptor of this.requestInterceptors) {
      modifiedOptions = await interceptor(url, modifiedOptions);
    }
    
    // Make request
    let response = await fetch(url, modifiedOptions);
    
    // Apply response interceptors
    for (const interceptor of this.responseInterceptors) {
      response = await interceptor(response, url, modifiedOptions);
    }
    
    return response;
  }
}

// Setup
const interceptor = new FetchInterceptor();

// Add auth interceptor
interceptor.addRequestInterceptor(async (url, options) => {
  const token = await getAccessToken();
  return {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`
    }
  };
});

// Add retry interceptor for 401s
interceptor.addResponseInterceptor(async (response, url, options) => {
  if (response.status === 401) {
    await refreshToken();
    const token = await getAccessToken();
    
    // Retry with new token
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });
  }
  return response;
});

// Usage
const response = await interceptor.fetch('/api/data');
```

### Proxy Pattern for Authentication

Wrapper function that adds authentication to all requests.

```javascript
const authenticatedFetch = (() => {
  let token = null;
  
  return async (url, options = {}) => {
    if (!token) {
      token = await loadTokenFromStorage();
    }
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });
  };
})();

// Replace global fetch
const originalFetch = window.fetch;
window.fetch = authenticatedFetch;

// All fetch calls now include authentication
const response = await fetch('/api/data');
```

### Multi-Tenant Authentication

Injecting tenant identifiers alongside authentication.

```javascript
class MultiTenantFetch {
  constructor(token, tenantId) {
    this.token = token;
    this.tenantId = tenantId;
  }
  
  async fetch(url, options = {}) {
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.token}`,
        'X-Tenant-ID': this.tenantId
      }
    });
  }
}

// Usage
const tenantFetch = new MultiTenantFetch('jwt-token', 'tenant-123');
const response = await tenantFetch.fetch('/api/resources');
```

### OAuth 2.0 Flow Integration

Complete OAuth 2.0 authorization code flow with fetch.

```javascript
class OAuth2Client {
  constructor(clientId, redirectUri, authEndpoint, tokenEndpoint) {
    this.clientId = clientId;
    this.redirectUri = redirectUri;
    this.authEndpoint = authEndpoint;
    this.tokenEndpoint = tokenEndpoint;
    this.accessToken = null;
    this.refreshToken = null;
  }
  
  getAuthorizationUrl(state, scope = 'read write') {
    const params = new URLSearchParams({
      client_id: this.clientId,
      redirect_uri: this.redirectUri,
      response_type: 'code',
      scope,
      state
    });
    
    return `${this.authEndpoint}?${params}`;
  }
  
  async exchangeCodeForToken(code) {
    const response = await fetch(this.tokenEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded'
      },
      body: new URLSearchParams({
        grant_type: 'authorization_code',
        code,
        client_id: this.clientId,
        redirect_uri: this.redirectUri
      })
    });
    
    if (!response.ok) {
      throw new Error('Token exchange failed');
    }
    
    const data = await response.json();
    this.accessToken = data.access_token;
    this.refreshToken = data.refresh_token;
    
    return data;
  }
  
  async fetchWithAuth(url, options = {}) {
    if (!this.accessToken) {
      throw new Error('Not authenticated');
    }
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.accessToken}`
      }
    });
  }
}
```

### JWT Token Parsing

Extracting information from JWT tokens for conditional authentication.

```javascript
function parseJWT(token) {
  try {
    const base64Url = token.split('.')[1];
    const base64 = base64Url.replace(/-/g, '+').replace(/_/g, '/');
    const jsonPayload = decodeURIComponent(
      atob(base64)
        .split('')
        .map(c => '%' + ('00' + c.charCodeAt(0).toString(16)).slice(-2))
        .join('')
    );
    
    return JSON.parse(jsonPayload);
  } catch (error) {
    return null;
  }
}

function isTokenExpired(token) {
  const payload = parseJWT(token);
  if (!payload || !payload.exp) return true;
  
  return Date.now() >= payload.exp * 1000;
}

async function fetchWithTokenCheck(url, token, options = {}) {
  if (isTokenExpired(token)) {
    token = await refreshToken();
  }
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`
    }
  });
}
```

### Header Priority and Merging

Handling authentication header conflicts and merging.

```javascript
function mergeFetchOptions(defaults, overrides) {
  return {
    ...defaults,
    ...overrides,
    headers: {
      ...defaults.headers,
      ...overrides.headers
    }
  };
}

const defaultAuthOptions = {
  headers: {
    'Authorization': 'Bearer default-token',
    'X-Client-Version': '1.0.0'
  }
};

// Override Authorization but keep other defaults
const response = await fetch('/api/data', mergeFetchOptions(
  defaultAuthOptions,
  {
    headers: {
      'Authorization': 'Bearer specific-token'
    }
  }
));
```

### Device Fingerprinting

Adding device identifiers to authentication headers.

```javascript
async function getDeviceFingerprint() {
  const components = [
    navigator.userAgent,
    navigator.language,
    screen.width,
    screen.height,
    new Date().getTimezoneOffset()
  ];
  
  const fingerprint = components.join('|');
  
  // Hash the fingerprint
  const encoder = new TextEncoder();
  const data = encoder.encode(fingerprint);
  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
}

async function fetchWithDeviceAuth(url, token, options = {}) {
  const deviceId = await getDeviceFingerprint();
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`,
      'X-Device-ID': deviceId
    }
  });
}
```

### Request Signing

HMAC-based request signature for authentication.

```javascript
async function signRequest(method, url, body, secretKey) {
  const timestamp = Date.now().toString();
  const message = `${method}\n${url}\n${timestamp}\n${body || ''}`;
  
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secretKey);
  const messageData = encoder.encode(message);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  const signatureArray = Array.from(new Uint8Array(signature));
  const signatureHex = signatureArray
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  return { signature: signatureHex, timestamp };
}

async function fetchWithSignature(url, secretKey, options = {}) {
  const method = options.method || 'GET';
  const body = options.body;
  
  const { signature, timestamp } = await signRequest(method, url, body, secretKey);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Timestamp': timestamp
    }
  });
}

// Usage
const response = await fetchWithSignature(
  '/api/data',
  'secret-key',
  {
    method: 'POST',
    body: JSON.stringify({ data: 'value' })
  }
);
```

### Rate Limit Token Bucket

Client-side rate limiting with authentication awareness.

```javascript
class RateLimitedFetch {
  constructor(token, requestsPerSecond = 10) {
    this.token = token;
    this.requestsPerSecond = requestsPerSecond;
    this.tokens = requestsPerSecond;
    this.lastRefill = Date.now();
  }
  
  refillTokens() {
    const now = Date.now();
    const timePassed = (now - this.lastRefill) / 1000;
    const tokensToAdd = timePassed * this.requestsPerSecond;
    
    this.tokens = Math.min(
      this.requestsPerSecond,
      this.tokens + tokensToAdd
    );
    this.lastRefill = now;
  }
  
  async fetch(url, options = {}) {
    this.refillTokens();
    
    if (this.tokens < 1) {
      const waitTime = (1 - this.tokens) / this.requestsPerSecond * 1000;
      await new Promise(resolve => setTimeout(resolve, waitTime));
      this.refillTokens();
    }
    
    this.tokens -= 1;
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.token}`
      }
    });
  }
}
```

### Service Worker Authentication Injection

Injecting authentication at the service worker level.

```javascript
// service-worker.js
self.addEventListener('fetch', (event) => {
  if (event.request.url.includes('/api/')) {
    event.respondWith(handleAuthenticatedRequest(event.request));
  }
});

async function handleAuthenticatedRequest(request) {
  // Get token from IndexedDB or cache
  const token = await getTokenFromStorage();
  
  // Clone and modify request
  const headers = new Headers(request.headers);
  headers.set('Authorization', `Bearer ${token}`);
  
  const authenticatedRequest = new Request(request, {
    headers
  });
  
  return fetch(authenticatedRequest);
}

async function getTokenFromStorage() {
  const cache = await caches.open('auth-cache');
  const response = await cache.match('auth-token');
  
  if (response) {
    const data = await response.json();
    return data.token;
  }
  
  return null;
}
```

### Client Credentials Flow

OAuth 2.0 client credentials grant for machine-to-machine authentication.

```javascript
class ClientCredentialsAuth {
  constructor(clientId, clientSecret, tokenEndpoint) {
    this.clientId = clientId;
    this.clientSecret = clientSecret;
    this.tokenEndpoint = tokenEndpoint;
    this.accessToken = null;
    this.expiresAt = null;
  }
  
  async getAccessToken() {
    // Return cached token if still valid
    if (this.accessToken && this.expiresAt > Date.now()) {
      return this.accessToken;
    }
    
    // Request new token
    const credentials = btoa(`${this.clientId}:${this.clientSecret}`);
    
    const response = await fetch(this.tokenEndpoint, {
      method: 'POST',
      headers: {
        'Authorization': `Basic ${credentials}`,
        'Content-Type': 'application/x-www-form-urlencoded'
      },
      body: new URLSearchParams({
        grant_type: 'client_credentials'
      })
    });
    
    if (!response.ok) {
      throw new Error('Failed to obtain access token');
    }
    
    const data = await response.json();
    this.accessToken = data.access_token;
    this.expiresAt = Date.now() + (data.expires_in * 1000);
    
    return this.accessToken;
  }
  
  async fetch(url, options = {}) {
    const token = await this.getAccessToken();
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });
  }
}
```

### Impersonation Headers

Admin impersonation with preserved authentication.

```javascript
async function fetchWithImpersonation(url, adminToken, impersonateUserId, options = {}) {
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${adminToken}`,
      'X-Impersonate-User': impersonateUserId
    }
  });
}

// Usage
const response = await fetchWithImpersonation(
  '/api/user/profile',
  'admin-token',
  'user-123'
);
```

### Conditional Authentication

Applying authentication only when required.

```javascript
class ConditionalAuthFetch {
  constructor(token) {
    this.token = token;
    this.publicEndpoints = ['/api/public', '/health'];
  }
  
  requiresAuth(url) {
    const urlPath = new URL(url, location.origin).pathname;
    return !this.publicEndpoints.some(endpoint => 
      urlPath.startsWith(endpoint)
    );
  }
  
  async fetch(url, options = {}) {
    const fetchOptions = { ...options };
    
    if (this.requiresAuth(url)) {
      fetchOptions.headers = {
        ...fetchOptions.headers,
        'Authorization': `Bearer ${this.token}`
      };
    }
    
    return fetch(url, fetchOptions);
  }
}
```

### Exponential Backoff for Auth Failures

Retry logic with exponential backoff for authentication errors.

```javascript
async function fetchWithAuthRetry(url, token, options = {}, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await fetch(url, {
        ...options,
        headers: {
          ...options.headers,
          'Authorization': `Bearer ${token}`
        }
      });
      
      if (response.status === 401 && attempt < maxRetries - 1) {
        // Authentication failed, refresh token and retry
        token = await refreshAuthToken();
        
        // Exponential backoff
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
        
        continue;
      }
      
      return response;
      
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries - 1) {
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError || new Error('Max retries exceeded');
}
```

### Security Context Headers

Adding security context information to authenticated requests.

```javascript
async function fetchWithSecurityContext(url, token, options = {}) {
  const securityContext = {
    requestId: crypto.randomUUID(),
    timestamp: new Date().toISOString(),
    userAgent: navigator.userAgent,
    referrer: document.referrer || 'direct'
  };
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`,
      'X-Request-ID': securityContext.requestId,
      'X-Request-Timestamp': securityContext.timestamp,
      'X-Client-Info': btoa(JSON.stringify({
        userAgent: securityContext.userAgent,
        referrer: securityContext.referrer
      }))
    }
  });
}
```

### Token Storage Strategies

Different approaches for storing authentication tokens.

```javascript
class TokenStorage {
  // Memory storage (most secure, lost on refresh)
  static setInMemory(token) {
    this._memoryToken = token;
  }
  
  static getFromMemory() {
    return this._memoryToken;
  }
  
  // sessionStorage (per-tab, lost on tab close)
  static setInSession(token) {
    sessionStorage.setItem('auth_token', token);
  }
  
  static getFromSession() {
    return sessionStorage.getItem('auth_token');
  }
  
  // localStorage (persistent, shared across tabs)
  static setInLocal(token) {
    localStorage.setItem('auth_token', token);
  }
  
  static getFromLocal() {
    return localStorage.getItem('auth_token');
  }
  
  // Encrypted storage in IndexedDB
  static async setEncrypted(token, encryptionKey) {
    const encrypted = await this.encrypt(token, encryptionKey);
    
    const db = await this.openDB();
    const transaction = db.transaction(['auth'], 'readwrite');
    const store = transaction.objectStore('auth');
    await store.put({ id: 'token', value: encrypted });
  }
  
  static async getEncrypted(encryptionKey) {
    const db = await this.openDB();
    const transaction = db.transaction(['auth'], 'readonly');
    const store = transaction.objectStore('auth');
    const record = await store.get('token');
    
    if (record) {
      return await this.decrypt(record.value, encryptionKey);
    }
    
    return null;
  }
}
```

### Cross-Tab Authentication Sync

Synchronizing authentication state across browser tabs.

```javascript
class CrossTabAuth {
  constructor() {
    this.token = null;
    this.listeners = [];
    
    // Listen for storage events from other tabs
    window.addEventListener('storage', (e) => {
      if (e.key === 'auth_token') {
        this.token = e.newValue;
        this.notifyListeners();
      }
    });
  }
  
  setToken(token) {
    this.token = token;
    localStorage.setItem('auth_token', token);
    this.notifyListeners();
  }
  
  getToken() {
    if (!this.token) {
      this.token = localStorage.getItem('auth_token');
    }
    return this.token;
  }
  
  clearToken() {
    this.token = null;
    localStorage.removeItem('auth_token');
    this.notifyListeners();
  }
  
  onTokenChange(callback) {
    this.listeners.push(callback);
  }
  
  notifyListeners() {
    this.listeners.forEach(callback => callback(this.token));
  }
  
  async fetch(url, options = {}) {
    const token = this.getToken();
    
    if (!token) {
      throw new Error('No authentication token available');
    }
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });
  }
}

// Usage
const auth = new CrossTabAuth();

auth.onTokenChange((token) => {
  if (!token) {
    // Logged out in another tab
    window.location.href = '/login';
  }
});
```

---

## Retry Logic Implementation (Request Interceptor)

### Basic Retry Wrapper

A simple retry wrapper that attempts a fetch request multiple times on failure.

```javascript
async function fetchWithRetry(url, options = {}, retries = 3) {
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      // Don't retry client errors (4xx), except specific cases
      if (response.status >= 400 && response.status < 500 && response.status !== 408 && response.status !== 429) {
        return response;
      }
      
      // Last attempt, return response even if failed
      if (attempt === retries) {
        return response;
      }
      
      console.log(`Attempt ${attempt + 1} failed with status ${response.status}, retrying...`);
    } catch (error) {
      // Last attempt, throw error
      if (attempt === retries) {
        throw error;
      }
      
      console.log(`Attempt ${attempt + 1} failed with error: ${error.message}, retrying...`);
    }
  }
}
```

### Exponential Backoff

Exponential backoff increases wait time between retries, reducing server load and improving success rates.

```javascript
async function fetchWithExponentialBackoff(url, options = {}, config = {}) {
  const {
    maxRetries = 3,
    baseDelay = 1000,
    maxDelay = 30000,
    factor = 2
  } = config;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      // Don't retry client errors except 408, 429
      if (response.status >= 400 && response.status < 500 && 
          response.status !== 408 && response.status !== 429) {
        return response;
      }
      
      if (attempt === maxRetries) {
        return response;
      }
      
      // Calculate delay with exponential backoff
      const delay = Math.min(baseDelay * Math.pow(factor, attempt), maxDelay);
      console.log(`Retry ${attempt + 1} after ${delay}ms`);
      
      await new Promise(resolve => setTimeout(resolve, delay));
      
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = Math.min(baseDelay * Math.pow(factor, attempt), maxDelay);
      console.log(`Network error, retry ${attempt + 1} after ${delay}ms`);
      
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Exponential Backoff with Jitter

Adding jitter (randomization) to delays prevents thundering herd problems when multiple clients retry simultaneously.

```javascript
async function fetchWithJitter(url, options = {}, config = {}) {
  const {
    maxRetries = 3,
    baseDelay = 1000,
    maxDelay = 30000,
    factor = 2,
    jitterType = 'full' // 'full', 'equal', 'decorrelated'
  } = config;
  
  let previousDelay = baseDelay;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      if (shouldNotRetry(response.status) || attempt === maxRetries) {
        return response;
      }
      
      const delay = calculateDelay(attempt, baseDelay, maxDelay, factor, jitterType, previousDelay);
      previousDelay = delay;
      
      console.log(`Retry ${attempt + 1} after ${delay}ms`);
      await new Promise(resolve => setTimeout(resolve, delay));
      
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = calculateDelay(attempt, baseDelay, maxDelay, factor, jitterType, previousDelay);
      previousDelay = delay;
      
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}

function calculateDelay(attempt, baseDelay, maxDelay, factor, jitterType, previousDelay) {
  const exponentialDelay = baseDelay * Math.pow(factor, attempt);
  
  switch (jitterType) {
    case 'full':
      // Random delay between 0 and exponential delay
      return Math.min(Math.random() * exponentialDelay, maxDelay);
      
    case 'equal':
      // Half exponential delay plus random half
      const halfDelay = exponentialDelay / 2;
      return Math.min(halfDelay + Math.random() * halfDelay, maxDelay);
      
    case 'decorrelated':
      // Random between baseDelay and 3x previous delay
      const decorrelated = baseDelay + Math.random() * (previousDelay * 3 - baseDelay);
      return Math.min(decorrelated, maxDelay);
      
    default:
      return Math.min(exponentialDelay, maxDelay);
  }
}

function shouldNotRetry(status) {
  // Don't retry client errors except specific cases
  return status >= 400 && status < 500 && status !== 408 && status !== 429;
}
```

### Retry with Status Code Filtering

Different status codes require different retry strategies.

```javascript
async function fetchWithStatusHandling(url, options = {}, config = {}) {
  const {
    maxRetries = 3,
    baseDelay = 1000,
    retryableStatusCodes = [408, 429, 500, 502, 503, 504],
    retryableErrors = ['NetworkError', 'TypeError']
  } = config;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      // Check if status code is retryable
      if (!retryableStatusCodes.includes(response.status)) {
        return response;
      }
      
      if (attempt === maxRetries) {
        return response;
      }
      
      const delay = baseDelay * Math.pow(2, attempt);
      console.log(`Status ${response.status} is retryable, waiting ${delay}ms`);
      
      await new Promise(resolve => setTimeout(resolve, delay));
      
    } catch (error) {
      // Check if error type is retryable
      const isRetryableError = retryableErrors.some(type => 
        error.name === type || error.constructor.name === type
      );
      
      if (!isRetryableError || attempt === maxRetries) {
        throw error;
      }
      
      const delay = baseDelay * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Retry-After Header Support

Respect the `Retry-After` header when servers indicate when to retry.

```javascript
async function fetchWithRetryAfter(url, options = {}, maxRetries = 3) {
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      if (attempt === maxRetries) {
        return response;
      }
      
      // Check for Retry-After header
      if (response.status === 429 || response.status === 503) {
        const retryAfter = response.headers.get('Retry-After');
        
        if (retryAfter) {
          let delay;
          
          // Retry-After can be seconds or HTTP date
          if (/^\d+$/.test(retryAfter)) {
            // Seconds
            delay = parseInt(retryAfter, 10) * 1000;
          } else {
            // HTTP date
            const retryDate = new Date(retryAfter);
            delay = retryDate.getTime() - Date.now();
          }
          
          // Cap delay at 60 seconds for safety
          delay = Math.min(Math.max(delay, 0), 60000);
          
          console.log(`Server requested retry after ${delay}ms`);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
      }
      
      // Fallback to exponential backoff
      const delay = 1000 * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
      
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = 1000 * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Request Interceptor Class

A comprehensive request interceptor that wraps fetch with retry logic and hooks.

```javascript
class FetchInterceptor {
  constructor(config = {}) {
    this.config = {
      maxRetries: 3,
      baseDelay: 1000,
      maxDelay: 30000,
      factor: 2,
      retryableStatusCodes: [408, 429, 500, 502, 503, 504],
      retryableErrors: ['NetworkError', 'TypeError'],
      ...config
    };
    
    this.beforeRequestHooks = [];
    this.afterResponseHooks = [];
    this.onRetryHooks = [];
    this.onErrorHooks = [];
  }
  
  beforeRequest(hook) {
    this.beforeRequestHooks.push(hook);
    return this;
  }
  
  afterResponse(hook) {
    this.afterResponseHooks.push(hook);
    return this;
  }
  
  onRetry(hook) {
    this.onRetryHooks.push(hook);
    return this;
  }
  
  onError(hook) {
    this.onErrorHooks.push(hook);
    return this;
  }
  
  async fetch(url, options = {}) {
    // Execute before request hooks
    let modifiedOptions = { ...options };
    
    for (const hook of this.beforeRequestHooks) {
      modifiedOptions = await hook(url, modifiedOptions) || modifiedOptions;
    }
    
    // Perform request with retry logic
    return await this._fetchWithRetry(url, modifiedOptions);
  }
  
  async _fetchWithRetry(url, options) {
    const { maxRetries, baseDelay, maxDelay, factor, retryableStatusCodes, retryableErrors } = this.config;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        // Execute after response hooks
        for (const hook of this.afterResponseHooks) {
          await hook(response.clone(), attempt);
        }
        
        if (response.ok) {
          return response;
        }
        
        // Check if should retry
        if (!retryableStatusCodes.includes(response.status) || attempt === maxRetries) {
          return response;
        }
        
        // Calculate delay
        const delay = this._calculateDelay(attempt, response);
        
        // Execute retry hooks
        for (const hook of this.onRetryHooks) {
          await hook(attempt + 1, delay, response.status);
        }
        
        console.log(`Retrying request (${attempt + 1}/${maxRetries}) after ${delay}ms`);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        // Execute error hooks
        for (const hook of this.onErrorHooks) {
          await hook(error, attempt);
        }
        
        const isRetryableError = retryableErrors.some(type => 
          error.name === type || error.constructor.name === type
        );
        
        if (!isRetryableError || attempt === maxRetries) {
          throw error;
        }
        
        const delay = Math.min(baseDelay * Math.pow(factor, attempt), maxDelay);
        
        for (const hook of this.onRetryHooks) {
          await hook(attempt + 1, delay, error.message);
        }
        
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  _calculateDelay(attempt, response) {
    const { baseDelay, maxDelay, factor } = this.config;
    
    // Check for Retry-After header
    if (response && (response.status === 429 || response.status === 503)) {
      const retryAfter = response.headers.get('Retry-After');
      
      if (retryAfter) {
        if (/^\d+$/.test(retryAfter)) {
          return Math.min(parseInt(retryAfter, 10) * 1000, maxDelay);
        } else {
          const retryDate = new Date(retryAfter);
          return Math.min(Math.max(retryDate.getTime() - Date.now(), 0), maxDelay);
        }
      }
    }
    
    // Exponential backoff with jitter
    const exponentialDelay = baseDelay * Math.pow(factor, attempt);
    const jitter = Math.random() * exponentialDelay;
    
    return Math.min(jitter, maxDelay);
  }
}

// Usage
const interceptor = new FetchInterceptor({
  maxRetries: 5,
  baseDelay: 1000,
  retryableStatusCodes: [408, 429, 500, 502, 503, 504]
});

interceptor.beforeRequest((url, options) => {
  console.log('Making request to:', url);
  options.headers = {
    ...options.headers,
    'X-Request-ID': crypto.randomUUID()
  };
  return options;
});

interceptor.afterResponse((response, attempt) => {
  console.log('Response received:', response.status, 'on attempt', attempt + 1);
});

interceptor.onRetry((attempt, delay, statusOrError) => {
  console.log(`Retry attempt ${attempt} after ${delay}ms due to: ${statusOrError}`);
});

interceptor.onError((error, attempt) => {
  console.error(`Error on attempt ${attempt + 1}:`, error.message);
});

const response = await interceptor.fetch('/api/data', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ data: 'example' })
});
```

### Idempotency Key Support

For non-idempotent operations, use idempotency keys to safely retry without duplicate side effects.

```javascript
class IdempotentFetchInterceptor {
  constructor(config = {}) {
    this.config = {
      maxRetries: 3,
      baseDelay: 1000,
      idempotencyHeader: 'Idempotency-Key',
      ...config
    };
  }
  
  async fetch(url, options = {}) {
    const method = (options.method || 'GET').toUpperCase();
    const needsIdempotency = ['POST', 'PUT', 'PATCH', 'DELETE'].includes(method);
    
    // Generate idempotency key for non-idempotent operations
    if (needsIdempotency) {
      const idempotencyKey = this._generateIdempotencyKey(url, options);
      
      options.headers = {
        ...options.headers,
        [this.config.idempotencyHeader]: idempotencyKey
      };
    }
    
    return await this._retryFetch(url, options);
  }
  
  _generateIdempotencyKey(url, options) {
    // Generate unique key based on request details
    const key = `${url}-${options.method}-${Date.now()}-${Math.random()}`;
    
    // Use crypto API if available
    if (typeof crypto !== 'undefined' && crypto.randomUUID) {
      return crypto.randomUUID();
    }
    
    // Fallback to simple hash
    return btoa(key).substring(0, 32);
  }
  
  async _retryFetch(url, options) {
    const { maxRetries, baseDelay } = this.config;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok) {
          return response;
        }
        
        // Don't retry if server says request was processed
        if (response.status === 409) {
          // Conflict - idempotency key indicates duplicate
          return response;
        }
        
        if (attempt === maxRetries) {
          return response;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        if (attempt === maxRetries) {
          throw error;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
}
```

### Timeout with Retry

Combining timeout logic with retry attempts using AbortController.

```javascript
async function fetchWithTimeoutAndRetry(url, options = {}, config = {}) {
  const {
    maxRetries = 3,
    timeout = 5000,
    baseDelay = 1000
  } = config;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        return response;
      }
      
      if (attempt === maxRetries) {
        return response;
      }
      
      const delay = baseDelay * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
      
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        console.log(`Request timeout on attempt ${attempt + 1}`);
      }
      
      if (attempt === maxRetries) {
        throw error;
      }
      
      const delay = baseDelay * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Circuit Breaker Pattern

Prevent overwhelming failing services by opening the circuit after consecutive failures.

```javascript
class CircuitBreaker {
  constructor(config = {}) {
    this.config = {
      failureThreshold: 5,
      resetTimeout: 60000,
      monitoringPeriod: 10000,
      ...config
    };
    
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failureCount = 0;
    this.lastFailureTime = null;
    this.successCount = 0;
  }
  
  async fetch(url, options = {}, retryConfig = {}) {
    // Check circuit state
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime >= this.config.resetTimeout) {
        console.log('Circuit transitioning to HALF_OPEN');
        this.state = 'HALF_OPEN';
        this.successCount = 0;
      } else {
        throw new Error('Circuit breaker is OPEN - request blocked');
      }
    }
    
    try {
      const response = await this._fetchWithRetry(url, options, retryConfig);
      
      if (response.ok) {
        this._recordSuccess();
        return response;
      }
      
      // Server errors count as failures
      if (response.status >= 500) {
        this._recordFailure();
      }
      
      return response;
      
    } catch (error) {
      this._recordFailure();
      throw error;
    }
  }
  
  async _fetchWithRetry(url, options, config) {
    const { maxRetries = 3, baseDelay = 1000 } = config;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok || response.status < 500) {
          return response;
        }
        
        if (attempt === maxRetries) {
          return response;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        if (attempt === maxRetries) {
          throw error;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  _recordSuccess() {
    this.failureCount = 0;
    
    if (this.state === 'HALF_OPEN') {
      this.successCount++;
      
      // After some successes in HALF_OPEN, close circuit
      if (this.successCount >= 2) {
        console.log('Circuit closing after successful requests');
        this.state = 'CLOSED';
        this.successCount = 0;
      }
    }
  }
  
  _recordFailure() {
    this.failureCount++;
    this.lastFailureTime = Date.now();
    
    if (this.failureCount >= this.config.failureThreshold) {
      console.log('Circuit opening due to consecutive failures');
      this.state = 'OPEN';
    }
  }
  
  reset() {
    this.state = 'CLOSED';
    this.failureCount = 0;
    this.lastFailureTime = null;
    this.successCount = 0;
  }
  
  getState() {
    return {
      state: this.state,
      failureCount: this.failureCount,
      lastFailureTime: this.lastFailureTime
    };
  }
}

// Usage
const breaker = new CircuitBreaker({
  failureThreshold: 3,
  resetTimeout: 30000
});

try {
  const response = await breaker.fetch('/api/unstable-endpoint', {
    method: 'GET'
  }, {
    maxRetries: 2,
    baseDelay: 500
  });
  
  const data = await response.json();
  console.log(data);
} catch (error) {
  console.error('Request failed:', error.message);
  console.log('Circuit state:', breaker.getState());
}
```

### Request Queue with Retry

Queue requests with retry logic to prevent overwhelming the client or server.

```javascript
class RequestQueue {
  constructor(config = {}) {
    this.config = {
      concurrency: 3,
      maxRetries: 3,
      baseDelay: 1000,
      ...config
    };
    
    this.queue = [];
    this.active = 0;
  }
  
  async fetch(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this._process();
    });
  }
  
  async _process() {
    if (this.active >= this.config.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { url, options, resolve, reject } = this.queue.shift();
    
    try {
      const response = await this._fetchWithRetry(url, options);
      resolve(response);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this._process();
    }
  }
  
  async _fetchWithRetry(url, options) {
    const { maxRetries, baseDelay } = this.config;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok || response.status < 500) {
          return response;
        }
        
        if (attempt === maxRetries) {
          return response;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        if (attempt === maxRetries) {
          throw error;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  getStats() {
    return {
      queued: this.queue.length,
      active: this.active
    };
  }
}

// Usage
const queue = new RequestQueue({ concurrency: 2, maxRetries: 3 });

const urls = ['/api/data1', '/api/data2', '/api/data3', '/api/data4'];

const promises = urls.map(url => queue.fetch(url));

const results = await Promise.allSettled(promises);
results.forEach((result, index) => {
  if (result.status === 'fulfilled') {
    console.log(`Request ${index + 1} succeeded`);
  } else {
    console.error(`Request ${index + 1} failed:`, result.reason);
  }
});
```

### Adaptive Retry Strategy

Adjust retry behavior based on response patterns and success rates.

```javascript
class AdaptiveRetryInterceptor {
  constructor(config = {}) {
    this.config = {
      initialMaxRetries: 3,
      minRetries: 1,
      maxRetries: 10,
      baseDelay: 1000,
      successThreshold: 0.8,
      evaluationWindow: 100,
      ...config
    };
    
    this.maxRetries = this.config.initialMaxRetries;
    this.requestHistory = [];
  }
  
  async fetch(url, options = {}) {
    const startTime = Date.now();
    
    try {
      const response = await this._fetchWithRetry(url, options);
      
      this._recordRequest(true, Date.now() - startTime);
      this._adjustStrategy();
      
      return response;
      
    } catch (error) {
      this._recordRequest(false, Date.now() - startTime);
      this._adjustStrategy();
      
      throw error;
    }
  }
  
  async _fetchWithRetry(url, options) {
    const { baseDelay } = this.config;
    
    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok) {
          return response;
        }
        
        if (response.status < 500 || attempt === this.maxRetries) {
          return response;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        if (attempt === this.maxRetries) {
          throw error;
        }
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  _recordRequest(success, duration) {
    this.requestHistory.push({ success, duration, timestamp: Date.now() });
    
    // Keep only recent history
    if (this.requestHistory.length > this.config.evaluationWindow) {
      this.requestHistory.shift();
    }
  }
  
  _adjustStrategy() {
    if (this.requestHistory.length < 20) {
      return; // Not enough data
    }
    
    const recentRequests = this.requestHistory.slice(-20);
    const successRate = recentRequests.filter(r => r.success).length / recentRequests.length;
    
    if (successRate >= this.config.successThreshold) {
      // High success rate - reduce retries
      this.maxRetries = Math.max(this.maxRetries - 1, this.config.minRetries);
      console.log(`Success rate high (${(successRate * 100).toFixed(1)}%), reducing retries to ${this.maxRetries}`);
    } else if (successRate < 0.5) {
      // Low success rate - increase retries
      this.maxRetries = Math.min(this.maxRetries + 1, this.config.maxRetries);
      console.log(`Success rate low (${(successRate * 100).toFixed(1)}%), increasing retries to ${this.maxRetries}`);
    }
  }
  
  getStats() {
    if (this.requestHistory.length === 0) {
      return { successRate: 0, averageDuration: 0, currentMaxRetries: this.maxRetries };
    }
    
    const successful = this.requestHistory.filter(r => r.success).length;
    const successRate = successful / this.requestHistory.length;
    const averageDuration = this.requestHistory.reduce((sum, r) => sum + r.duration, 0) / this.requestHistory.length;
    
    return {
      successRate: (successRate * 100).toFixed(2) + '%',
      averageDuration: Math.round(averageDuration) + 'ms',
      currentMaxRetries: this.maxRetries,
      totalRequests: this.requestHistory.length
    };
  }
}
```

### Retry with Request Deduplication

Prevent duplicate requests by deduplicating identical pending requests.

```javascript
class DeduplicatingInterceptor {
  constructor(config = {}) {
    this.config = {
      maxRetries: 3,
      baseDelay: 1000,
      ...config
    };

    this.pendingRequests = new Map();
  }

  async fetch(url, options = {}) {
    const requestKey = this._getRequestKey(url, options);

    // Check if identical request is pending
    if (this.pendingRequests.has(requestKey)) {
      console.log('Deduplicating request to:', url);
      return this.pendingRequests.get(requestKey);
    }

    // Create new request promise
    const requestPromise = this._fetchWithRetry(url, options)
      .finally(() => {
        // Clean up after request completes
        this.pendingRequests.delete(requestKey);
      });

    this.pendingRequests.set(requestKey, requestPromise);

    return requestPromise;
  }

  _getRequestKey(url, options) {
    const method = options.method || 'GET';
    const body = options.body || '';

    return `${method}:${url}:${body}`;
  }

  async _fetchWithRetry(url, options) {
    const { maxRetries, baseDelay } = this.config;

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);

        if (response.ok || response.status < 500) {
          return response;
        }

        if (attempt === maxRetries) {
          return response;
        }

        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));

      } catch (error) {
        if (attempt === maxRetries) {
          throw error;
        }

        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  clearPending() {
    this.pendingRequests.clear();
  }
}
````

### Retry with Metrics Collection

Track detailed metrics about retry behavior for monitoring and optimization.

```javascript
class MetricsCollectingInterceptor {
  constructor(config = {}) {
    this.config = {
      maxRetries: 3,
      baseDelay: 1000,
      ...config
    };
    
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      retriedRequests: 0,
      totalRetries: 0,
      statusCodes: {},
      errors: {},
      latencies: []
    };
  }
  
  async fetch(url, options = {}) {
    const startTime = Date.now();
    this.metrics.totalRequests++;
    
    let retryCount = 0;
    
    try {
      const response = await this._fetchWithRetry(url, options, (attempt) => {
        retryCount = attempt;
        this.metrics.totalRetries++;
      });
      
      const latency = Date.now() - startTime;
      this.metrics.latencies.push(latency);
      
      if (retryCount > 0) {
        this.metrics.retriedRequests++;
      }
      
      if (response.ok) {
        this.metrics.successfulRequests++;
      } else {
        this.metrics.failedRequests++;
      }
      
      // Track status codes
      const status = response.status;
      this.metrics.statusCodes[status] = (this.metrics.statusCodes[status] || 0) + 1;
      
      return response;
      
    } catch (error) {
      this.metrics.failedRequests++;
      
      if (retryCount > 0) {
        this.metrics.retriedRequests++;
      }
      
      // Track errors
      const errorType = error.name || 'Unknown';
      this.metrics.errors[errorType] = (this.metrics.errors[errorType] || 0) + 1;
      
      throw error;
    }
  }
  
  async _fetchWithRetry(url, options, onRetry) {
    const { maxRetries, baseDelay } = this.config;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok || response.status < 500) {
          return response;
        }
        
        if (attempt === maxRetries) {
          return response;
        }
        
        onRetry(attempt + 1);
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
        
      } catch (error) {
        if (attempt === maxRetries) {
          throw error;
        }
        
        onRetry(attempt + 1);
        
        const delay = baseDelay * Math.pow(2, attempt);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  getMetrics() {
    const avgLatency = this.metrics.latencies.length > 0
      ? this.metrics.latencies.reduce((a, b) => a + b, 0) / this.metrics.latencies.length
      : 0;
    
    const successRate = this.metrics.totalRequests > 0
      ? (this.metrics.successfulRequests / this.metrics.totalRequests) * 100
      : 0;
    
    return {
      totalRequests: this.metrics.totalRequests,
      successfulRequests: this.metrics.successfulRequests,
      failedRequests: this.metrics.failedRequests,
      successRate: successRate.toFixed(2) + '%',
      retriedRequests: this.metrics.retriedRequests,
      totalRetries: this.metrics.totalRetries,
      averageLatency: Math.round(avgLatency) + 'ms',
      statusCodes: this.metrics.statusCodes,
      errors: this.metrics.errors
    };
  }
  
  resetMetrics() {
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      retriedRequests: 0,
      totalRetries: 0,
      statusCodes: {},
      errors: {},
      latencies: []
    };
  }
}
````

---

# Advanced Patterns

## Request Pooling with Fetch API

### Basic Request Deduplication

Preventing duplicate concurrent requests to the same resource:

```javascript
const pendingRequests = new Map();

async function fetchWithDeduplication(url, options = {}) {
  const key = `${url}-${JSON.stringify(options)}`;
  
  // Return existing promise if request is in flight
  if (pendingRequests.has(key)) {
    return pendingRequests.get(key);
  }
  
  // Create new request promise
  const requestPromise = fetch(url, options)
    .then(response => response.clone())
    .finally(() => {
      // Clean up after request completes
      pendingRequests.delete(key);
    });
  
  pendingRequests.set(key, requestPromise);
  
  return requestPromise;
}

// Multiple calls return the same promise
const promise1 = fetchWithDeduplication('/api/data');
const promise2 = fetchWithDeduplication('/api/data'); // Reuses promise1
const promise3 = fetchWithDeduplication('/api/data'); // Reuses promise1
```

### Request Pool Manager

Managing concurrent request limits with queuing:

```javascript
class RequestPool {
  constructor(maxConcurrent = 6) {
    this.maxConcurrent = maxConcurrent;
    this.activeRequests = 0;
    this.queue = [];
  }
  
  async fetch(url, options = {}) {
    // Wait if at capacity
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue();
    }
    
    this.activeRequests++;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _enqueue() {
    return new Promise(resolve => {
      this.queue.push(resolve);
    });
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
  
  getStats() {
    return {
      active: this.activeRequests,
      queued: this.queue.length,
      capacity: this.maxConcurrent
    };
  }
}

const pool = new RequestPool(3);

// Only 3 requests execute concurrently, rest queue
Promise.all([
  pool.fetch('/api/1'),
  pool.fetch('/api/2'),
  pool.fetch('/api/3'),
  pool.fetch('/api/4'), // Queued
  pool.fetch('/api/5'), // Queued
  pool.fetch('/api/6')  // Queued
]);
```

### Priority-Based Request Queue

Executing high-priority requests before low-priority ones:

```javascript
class PriorityRequestPool {
  constructor(maxConcurrent = 6) {
    this.maxConcurrent = maxConcurrent;
    this.activeRequests = 0;
    this.queues = {
      critical: [],
      high: [],
      normal: [],
      low: []
    };
  }
  
  async fetch(url, options = {}, priority = 'normal') {
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue(priority);
    }
    
    this.activeRequests++;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _enqueue(priority) {
    return new Promise(resolve => {
      this.queues[priority].push(resolve);
    });
  }
  
  _dequeue() {
    // Process queues in priority order
    const priorities = ['critical', 'high', 'normal', 'low'];
    
    for (const priority of priorities) {
      if (this.queues[priority].length > 0) {
        const resolve = this.queues[priority].shift();
        resolve();
        return;
      }
    }
  }
  
  getQueueDepth() {
    return {
      critical: this.queues.critical.length,
      high: this.queues.high.length,
      normal: this.queues.normal.length,
      low: this.queues.low.length,
      total: Object.values(this.queues).reduce((sum, q) => sum + q.length, 0)
    };
  }
}

const pool = new PriorityRequestPool(2);

// Critical requests execute first
pool.fetch('/api/analytics', {}, 'low');
pool.fetch('/api/user', {}, 'critical');  // Executes immediately
pool.fetch('/api/settings', {}, 'high');   // Executes second
pool.fetch('/api/logs', {}, 'low');
```

### Per-Domain Connection Pooling

Limiting concurrent requests per domain:

```javascript
class DomainRequestPool {
  constructor(maxPerDomain = 6) {
    this.maxPerDomain = maxPerDomain;
    this.domainPools = new Map();
  }
  
  async fetch(url, options = {}) {
    const domain = new URL(url).origin;
    
    if (!this.domainPools.has(domain)) {
      this.domainPools.set(domain, {
        active: 0,
        queue: []
      });
    }
    
    const pool = this.domainPools.get(domain);
    
    // Wait if domain at capacity
    if (pool.active >= this.maxPerDomain) {
      await new Promise(resolve => pool.queue.push(resolve));
    }
    
    pool.active++;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      pool.active--;
      
      // Process next queued request for this domain
      if (pool.queue.length > 0) {
        const resolve = pool.queue.shift();
        resolve();
      }
    }
  }
  
  getDomainStats(domain) {
    const pool = this.domainPools.get(domain);
    if (!pool) return null;
    
    return {
      active: pool.active,
      queued: pool.queue.length
    };
  }
  
  getAllStats() {
    const stats = {};
    
    for (const [domain, pool] of this.domainPools) {
      stats[domain] = {
        active: pool.active,
        queued: pool.queue.length
      };
    }
    
    return stats;
  }
}

const pool = new DomainRequestPool(2);

// Each domain limited to 2 concurrent requests
pool.fetch('https://api1.com/data');
pool.fetch('https://api1.com/users');
pool.fetch('https://api1.com/posts');  // Queued for api1.com
pool.fetch('https://api2.com/data');   // Executes immediately (different domain)
```

### Request Batching

Combining multiple requests into a single batch:

```javascript
class RequestBatcher {
  constructor(batchInterval = 50, maxBatchSize = 10) {
    this.batchInterval = batchInterval;
    this.maxBatchSize = maxBatchSize;
    this.pending = [];
    this.timer = null;
  }
  
  async fetch(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.pending.push({ url, options, resolve, reject });
      
      // Flush immediately if batch full
      if (this.pending.length >= this.maxBatchSize) {
        this._flush();
      } else {
        // Schedule flush
        this._scheduleFlush();
      }
    });
  }
  
  _scheduleFlush() {
    if (this.timer) return;
    
    this.timer = setTimeout(() => {
      this._flush();
    }, this.batchInterval);
  }
  
  async _flush() {
    if (this.timer) {
      clearTimeout(this.timer);
      this.timer = null;
    }
    
    if (this.pending.length === 0) return;
    
    const batch = this.pending.splice(0, this.maxBatchSize);
    
    // Execute all requests in parallel
    const results = await Promise.allSettled(
      batch.map(({ url, options }) => fetch(url, options))
    );
    
    // Resolve/reject individual promises
    results.forEach((result, index) => {
      const { resolve, reject } = batch[index];
      
      if (result.status === 'fulfilled') {
        resolve(result.value);
      } else {
        reject(result.reason);
      }
    });
  }
  
  getPendingCount() {
    return this.pending.length;
  }
}

const batcher = new RequestBatcher(100, 5);

// These requests are batched and executed together
batcher.fetch('/api/1');
batcher.fetch('/api/2');
batcher.fetch('/api/3');
// After 100ms or 5 requests, batch executes
```

### Adaptive Request Pooling

Dynamically adjusting pool size based on performance:

```javascript
class AdaptiveRequestPool {
  constructor(initialSize = 6) {
    this.maxConcurrent = initialSize;
    this.minConcurrent = 2;
    this.maxLimit = 12;
    this.activeRequests = 0;
    this.queue = [];
    this.metrics = {
      successCount: 0,
      errorCount: 0,
      totalLatency: 0,
      requestCount: 0
    };
  }
  
  async fetch(url, options = {}) {
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue();
    }
    
    this.activeRequests++;
    const startTime = performance.now();
    
    try {
      const response = await fetch(url, options);
      
      const latency = performance.now() - startTime;
      this._recordSuccess(latency);
      
      return response;
    } catch (error) {
      this._recordError();
      throw error;
    } finally {
      this.activeRequests--;
      this._dequeue();
      this._adjustPoolSize();
    }
  }
  
  _recordSuccess(latency) {
    this.metrics.successCount++;
    this.metrics.totalLatency += latency;
    this.metrics.requestCount++;
  }
  
  _recordError() {
    this.metrics.errorCount++;
    this.metrics.requestCount++;
  }
  
  _adjustPoolSize() {
    // Only adjust every 10 requests
    if (this.metrics.requestCount % 10 !== 0) return;
    
    const errorRate = this.metrics.errorCount / this.metrics.requestCount;
    const avgLatency = this.metrics.totalLatency / this.metrics.successCount;
    
    // Decrease pool size if high error rate
    if (errorRate > 0.1 && this.maxConcurrent > this.minConcurrent) {
      this.maxConcurrent = Math.max(
        this.minConcurrent,
        this.maxConcurrent - 1
      );
      console.log(`Decreased pool size to ${this.maxConcurrent}`);
    }
    // Increase pool size if low latency and no errors
    else if (errorRate < 0.05 && avgLatency < 500 && this.maxConcurrent < this.maxLimit) {
      this.maxConcurrent = Math.min(
        this.maxLimit,
        this.maxConcurrent + 1
      );
      console.log(`Increased pool size to ${this.maxConcurrent}`);
    }
  }
  
  _enqueue() {
    return new Promise(resolve => this.queue.push(resolve));
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
  
  getMetrics() {
    return {
      ...this.metrics,
      errorRate: (this.metrics.errorCount / this.metrics.requestCount * 100).toFixed(2) + '%',
      avgLatency: (this.metrics.totalLatency / this.metrics.successCount).toFixed(2) + 'ms',
      poolSize: this.maxConcurrent,
      active: this.activeRequests,
      queued: this.queue.length
    };
  }
}
```

### Request Coalescing

Merging identical pending requests:

```javascript
class RequestCoalescer {
  constructor(coalescingWindow = 100) {
    this.coalescingWindow = coalescingWindow;
    this.pendingRequests = new Map();
  }
  
  async fetch(url, options = {}) {
    const key = this._generateKey(url, options);
    
    // Check for existing request
    if (this.pendingRequests.has(key)) {
      const existing = this.pendingRequests.get(key);
      
      // Add to listeners
      return new Promise((resolve, reject) => {
        existing.listeners.push({ resolve, reject });
      });
    }
    
    // Create new request entry
    const entry = {
      listeners: [],
      timer: null,
      promise: null
    };
    
    this.pendingRequests.set(key, entry);
    
    // Schedule request execution
    entry.timer = setTimeout(() => {
      this._executeRequest(key, url, options);
    }, this.coalescingWindow);
    
    // Return promise for first caller
    return new Promise((resolve, reject) => {
      entry.listeners.push({ resolve, reject });
    });
  }
  
  async _executeRequest(key, url, options) {
    const entry = this.pendingRequests.get(key);
    if (!entry) return;
    
    try {
      const response = await fetch(url, options);
      
      // Resolve all listeners with cloned responses
      for (const { resolve } of entry.listeners) {
        resolve(response.clone());
      }
    } catch (error) {
      // Reject all listeners
      for (const { reject } of entry.listeners) {
        reject(error);
      }
    } finally {
      this.pendingRequests.delete(key);
    }
  }
  
  _generateKey(url, options) {
    const method = options.method || 'GET';
    const body = options.body || '';
    const headers = JSON.stringify(options.headers || {});
    return `${method}:${url}:${body}:${headers}`;
  }
  
  flush(url, options = {}) {
    const key = this._generateKey(url, options);
    const entry = this.pendingRequests.get(key);
    
    if (entry && entry.timer) {
      clearTimeout(entry.timer);
      this._executeRequest(key, url, options);
    }
  }
}

const coalescer = new RequestCoalescer(50);

// These three calls coalesce into a single request
coalescer.fetch('/api/data');
coalescer.fetch('/api/data');
coalescer.fetch('/api/data');
// Single request executes after 50ms, all three callers get response
```

### Weighted Request Pool

Allocating pool capacity based on request weights:

```javascript
class WeightedRequestPool {
  constructor(maxConcurrent = 10) {
    this.maxConcurrent = maxConcurrent;
    this.currentWeight = 0;
    this.queue = [];
  }
  
  async fetch(url, options = {}, weight = 1) {
    // Wait until sufficient capacity available
    while (this.currentWeight + weight > this.maxConcurrent) {
      await new Promise(resolve => this.queue.push({ resolve, weight }));
    }
    
    this.currentWeight += weight;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      this.currentWeight -= weight;
      this._processQueue();
    }
  }
  
  _processQueue() {
    // Process queue in order, fitting requests that have available capacity
    let i = 0;
    
    while (i < this.queue.length) {
      const { resolve, weight } = this.queue[i];
      
      if (this.currentWeight + weight <= this.maxConcurrent) {
        this.queue.splice(i, 1);
        resolve();
      } else {
        i++;
      }
    }
  }
  
  getCapacity() {
    return {
      used: this.currentWeight,
      available: this.maxConcurrent - this.currentWeight,
      total: this.maxConcurrent,
      queued: this.queue.length
    };
  }
}

const pool = new WeightedRequestPool(10);

// Heavy request consumes more capacity
pool.fetch('/api/large-download', {}, 5);  // Weight: 5
pool.fetch('/api/data', {}, 1);            // Weight: 1
pool.fetch('/api/small', {}, 1);           // Weight: 1
pool.fetch('/api/medium', {}, 2);          // Weight: 2
pool.fetch('/api/another', {}, 2);         // Queued (would exceed 10)
```

### Request Pool with Timeout

Enforcing maximum wait time in queue:

```javascript
class TimeoutRequestPool {
  constructor(maxConcurrent = 6, queueTimeout = 5000) {
    this.maxConcurrent = maxConcurrent;
    this.queueTimeout = queueTimeout;
    this.activeRequests = 0;
    this.queue = [];
  }
  
  async fetch(url, options = {}) {
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueueWithTimeout();
    }
    
    this.activeRequests++;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _enqueueWithTimeout() {
    return new Promise((resolve, reject) => {
      const timer = setTimeout(() => {
        // Remove from queue
        const index = this.queue.findIndex(item => item.resolve === resolve);
        if (index !== -1) {
          this.queue.splice(index, 1);
        }
        
        reject(new Error('Request queue timeout exceeded'));
      }, this.queueTimeout);
      
      this.queue.push({ resolve, timer });
    });
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const { resolve, timer } = this.queue.shift();
      clearTimeout(timer);
      resolve();
    }
  }
}

const pool = new TimeoutRequestPool(2, 3000);

// If queued for more than 3 seconds, request fails
try {
  await pool.fetch('/api/data');
} catch (error) {
  console.error('Request timeout:', error.message);
}
```

### Circuit Breaker Pattern

Preventing requests to failing endpoints:

```javascript
class CircuitBreakerPool {
  constructor(maxConcurrent = 6, failureThreshold = 5, resetTimeout = 30000) {
    this.maxConcurrent = maxConcurrent;
    this.failureThreshold = failureThreshold;
    this.resetTimeout = resetTimeout;
    this.activeRequests = 0;
    this.queue = [];
    this.circuits = new Map();
  }
  
  async fetch(url, options = {}) {
    const endpoint = new URL(url).origin + new URL(url).pathname;
    
    // Check circuit state
    const circuit = this._getCircuit(endpoint);
    
    if (circuit.state === 'open') {
      throw new Error(`Circuit breaker open for ${endpoint}`);
    }
    
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue();
    }
    
    this.activeRequests++;
    
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        this._recordSuccess(endpoint);
      } else {
        this._recordFailure(endpoint);
      }
      
      return response;
    } catch (error) {
      this._recordFailure(endpoint);
      throw error;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _getCircuit(endpoint) {
    if (!this.circuits.has(endpoint)) {
      this.circuits.set(endpoint, {
        state: 'closed',
        failures: 0,
        successes: 0,
        nextAttempt: null
      });
    }
    
    const circuit = this.circuits.get(endpoint);
    
    // Check if should transition from open to half-open
    if (circuit.state === 'open' && Date.now() >= circuit.nextAttempt) {
      circuit.state = 'half-open';
      circuit.failures = 0;
    }
    
    return circuit;
  }
  
  _recordSuccess(endpoint) {
    const circuit = this.circuits.get(endpoint);
    
    if (circuit.state === 'half-open') {
      // Successful request in half-open state closes circuit
      circuit.state = 'closed';
      circuit.failures = 0;
      circuit.successes = 0;
    } else {
      circuit.successes++;
    }
  }
  
  _recordFailure(endpoint) {
    const circuit = this.circuits.get(endpoint);
    circuit.failures++;
    
    if (circuit.failures >= this.failureThreshold) {
      circuit.state = 'open';
      circuit.nextAttempt = Date.now() + this.resetTimeout;
      console.log(`Circuit opened for ${endpoint}, retry after ${this.resetTimeout}ms`);
    }
  }
  
  _enqueue() {
    return new Promise(resolve => this.queue.push(resolve));
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
  
  getCircuitState(endpoint) {
    return this.circuits.get(endpoint) || null;
  }
  
  resetCircuit(endpoint) {
    if (this.circuits.has(endpoint)) {
      this.circuits.set(endpoint, {
        state: 'closed',
        failures: 0,
        successes: 0,
        nextAttempt: null
      });
    }
  }
}
```

### Resource-Aware Request Pool

Adjusting pool size based on system resources:

```javascript
class ResourceAwarePool {
  constructor() {
    this.maxConcurrent = this._calculateOptimalSize();
    this.activeRequests = 0;
    this.queue = [];
    this._monitorResources();
  }
  
  _calculateOptimalSize() {
    // Base on available memory and connection capabilities
    const memory = navigator.deviceMemory || 4; // GB
    const connection = navigator.connection?.effectiveType || '4g';
    
    let baseSize = 6;
    
    // Adjust for memory
    if (memory >= 8) {
      baseSize += 4;
    } else if (memory <= 2) {
      baseSize -= 2;
    }
    
    // Adjust for connection
    if (connection === 'slow-2g' || connection === '2g') {
      baseSize = Math.max(2, baseSize - 3);
    } else if (connection === '3g') {
      baseSize = Math.max(3, baseSize - 2);
    }
    
    return Math.max(2, Math.min(12, baseSize));
  }
  
  _monitorResources() {
    // Adjust pool size when connection changes
    if (navigator.connection) {
      navigator.connection.addEventListener('change', () => {
        const newSize = this._calculateOptimalSize();
        
        if (newSize !== this.maxConcurrent) {
          console.log(`Adjusting pool size: ${this.maxConcurrent} → ${newSize}`);
          this.maxConcurrent = newSize;
          
          // Process queue if capacity increased
          if (newSize > this.maxConcurrent) {
            while (this.queue.length > 0 && this.activeRequests < this.maxConcurrent) {
              this._dequeue();
            }
          }
        }
      });
    }
  }
  
  async fetch(url, options = {}) {
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue();
    }
    
    this.activeRequests++;
    
    try {
      const response = await fetch(url, options);
      return response;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _enqueue() {
    return new Promise(resolve => this.queue.push(resolve));
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
  
  getPoolInfo() {
    return {
      maxConcurrent: this.maxConcurrent,
      active: this.activeRequests,
      queued: this.queue.length,
      memory: navigator.deviceMemory,
      connection: navigator.connection?.effectiveType
    };
  }
}
```

### Retry-Aware Request Pool

Integrating retry logic with pooling:

```javascript
class RetryRequestPool {
  constructor(maxConcurrent = 6, maxRetries = 3) {
    this.maxConcurrent = maxConcurrent;
    this.maxRetries = maxRetries;
    this.activeRequests = 0;
    this.queue = [];
  }
  
  async fetch(url, options = {}, retryOptions = {}) {
    const {
      maxRetries = this.maxRetries,
      retryDelay = 1000,
      backoffMultiplier = 2,
      retryOn = [408, 429, 500, 502, 503, 504]
    } = retryOptions;
    
    let lastError;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      if (this.activeRequests >= this.maxConcurrent) {
        await this._enqueue();
      }
      
      this.activeRequests++;
      
      try {
        const response = await fetch(url, options);
        
        // Check if should retry based on status
        if (attempt < maxRetries && retryOn.includes(response.status)) {
          this.activeRequests--;
          this._dequeue();
          
          const delay = retryDelay * Math.pow(backoffMultiplier, attempt);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
        
        return response;
      } catch (error) {
        lastError = error;
        
        // Retry on network errors
        if (attempt < maxRetries) {
          this.activeRequests--;
          this._dequeue();
          
          const delay = retryDelay * Math.pow(backoffMultiplier, attempt);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
      } finally {
        if (attempt === maxRetries) {
          this.activeRequests--;
          this._dequeue();
        }
      }
    }
    
    throw lastError;
  }
  
  _enqueue() {
    return new Promise(resolve => this.queue.push(resolve));
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
}

const pool = new RetryRequestPool(3, 3);

// Automatically retries with exponential backoff
await pool.fetch('/api/data', {}, {
  maxRetries: 5,
  retryDelay: 500,
  backoffMultiplier: 2,
  retryOn: [429, 503]
});
```

### Request Pool Analytics

Comprehensive monitoring and analytics:

```javascript
class AnalyticsRequestPool {
  constructor(maxConcurrent = 6) {
    this.maxConcurrent = maxConcurrent;
    this.activeRequests = 0;
    this.queue = [];
    this.analytics = {
      total: 0,
      completed: 0,
      failed: 0,
      timeInQueue: [],
      requestDuration: [],
      queueLengthHistory: [],
      activeConcurrentHistory: []
    };
    this._startMonitoring();
  }
  
  async fetch(url, options = {}) {
    const queueStartTime = performance.now();
    
    if (this.activeRequests >= this.maxConcurrent) {
      await this._enqueue();
    }
    
    const queueTime = performance.now() - queueStartTime;
    this.analytics.timeInQueue.push(queueTime);
    
    this.activeRequests++;
    this.analytics.total++;
    
    const requestStartTime = performance.now();
    
    try {
      const response = await fetch(url, options);
      this.analytics.completed++;
      
      const duration = performance.now() - requestStartTime;
      this.analytics.requestDuration.push(duration);
      
      return response;
    } catch (error) {
      this.analytics.failed++;
      throw error;
    } finally {
      this.activeRequests--;
      this._dequeue();
    }
  }
  
  _enqueue() {
    return new Promise(resolve => this.queue.push(resolve));
  }
  
  _dequeue() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    }
  }
  
  _startMonitoring() {
    setInterval(() => {
      this.analytics.queueLengthHistory.push({
        timestamp: Date.now(),
        length: this.queue.length
      });
      
      this.analytics.activeConcurrentHistory.push({
        timestamp: Date.now(),
        count: this.activeRequests
      });
      
      // Keep only last 100 samples
      if (this.analytics.queueLengthHistory.length > 100) {
        this.analytics.queueLengthHistory.shift();
      }
      if (this.analytics.activeConcurrentHistory.length > 100) {
        this.analytics.activeConcurrentHistory.shift();
      }
    }, 1000);
  }
  
  getAnalytics() {
    const avgQueueTime = this.analytics.timeInQueue.length > 0
      ? this.analytics.timeInQueue.reduce((a, b) => a + b, 0) / this.analytics.timeInQueue.length
      : 0;
    
    const avgDuration = this.analytics.requestDuration.length > 0
      ? this.analytics.requestDuration.reduce((a, b) => a + b, 0) / this.analytics.requestDuration.length
      : 0;
    
    const successRate = this.analytics.total > 0
      ? (this.analytics.completed / this.analytics.total * 100).toFixed(2)
      : 0;
    
    return {
      total: this.analytics.total,
      completed: this.analytics.completed,
      failed: this.analytics.failed,
      successRate: successRate + '%',
      avgQueueTime: avgQueueTime.toFixed(2) + 'ms',
      avgRequestDuration: avgDuration.toFixed(2) + 'ms',
      currentActive: this.activeRequests,
      currentQueued: this.queue.length,
      queueHistory: this.analytics.queueLengthHistory,
      concurrencyHistory: this.analytics.activeConcurrentHistory
    };
  }
  
resetAnalytics() {
  this.analytics = {
    total: 0,
    completed: 0,
    failed: 0,
    timeInQueue: [],
    requestDuration: [],
    queueLengthHistory: [],
    activeConcurrentHistory: []
  };
}
```

---

## Rate Limiting in Fetch API

### Client-Side Rate Limiting Fundamentals

Client-side rate limiting controls the frequency of outgoing requests to prevent overwhelming servers, avoid hitting API quotas, or manage resource consumption. Unlike server-side rate limiting which rejects requests, client-side implementation queues or delays requests before sending them.

### Basic Rate Limiting Patterns

#### Simple Token Bucket

```javascript
class TokenBucket {
  constructor(capacity, refillRate) {
    this.capacity = capacity;
    this.tokens = capacity;
    this.refillRate = refillRate; // tokens per second
    this.lastRefill = Date.now();
  }
  
  refill() {
    const now = Date.now();
    const timePassed = (now - this.lastRefill) / 1000;
    const tokensToAdd = timePassed * this.refillRate;
    
    this.tokens = Math.min(this.capacity, this.tokens + tokensToAdd);
    this.lastRefill = now;
  }
  
  async consume(tokens = 1) {
    this.refill();
    
    if (this.tokens >= tokens) {
      this.tokens -= tokens;
      return true;
    }
    
    // Wait until enough tokens are available
    const tokensNeeded = tokens - this.tokens;
    const waitTime = (tokensNeeded / this.refillRate) * 1000;
    
    await new Promise(resolve => setTimeout(resolve, waitTime));
    
    this.refill();
    this.tokens -= tokens;
    return true;
  }
}

// Usage
const bucket = new TokenBucket(10, 2); // 10 tokens, refill 2 per second

async function rateLimitedFetch(url, options) {
  await bucket.consume();
  return fetch(url, options);
}
```

#### Fixed Window Counter

```javascript
class FixedWindowRateLimiter {
  constructor(maxRequests, windowMs) {
    this.maxRequests = maxRequests;
    this.windowMs = windowMs;
    this.requests = [];
  }
  
  async acquire() {
    const now = Date.now();
    const windowStart = now - this.windowMs;
    
    // Remove requests outside current window
    this.requests = this.requests.filter(time => time > windowStart);
    
    if (this.requests.length >= this.maxRequests) {
      const oldestRequest = this.requests[0];
      const waitTime = oldestRequest + this.windowMs - now;
      
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.acquire();
    }
    
    this.requests.push(now);
  }
}

// Usage: 100 requests per minute
const limiter = new FixedWindowRateLimiter(100, 60000);

async function rateLimitedFetch(url, options) {
  await limiter.acquire();
  return fetch(url, options);
}
```

#### Sliding Window Log

```javascript
class SlidingWindowRateLimiter {
  constructor(maxRequests, windowMs) {
    this.maxRequests = maxRequests;
    this.windowMs = windowMs;
    this.requestLog = [];
  }
  
  async throttle() {
    const now = Date.now();
    const windowStart = now - this.windowMs;
    
    // Clean old entries
    this.requestLog = this.requestLog.filter(timestamp => timestamp > windowStart);
    
    if (this.requestLog.length >= this.maxRequests) {
      const oldestInWindow = this.requestLog[0];
      const waitTime = oldestInWindow + this.windowMs - now + 1;
      
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.throttle();
    }
    
    this.requestLog.push(now);
  }
}

const limiter = new SlidingWindowRateLimiter(50, 60000);

async function rateLimitedFetch(url, options) {
  await limiter.throttle();
  return fetch(url, options);
}
```

### Queue-Based Rate Limiting

#### Request Queue with Concurrent Limit

```javascript
class RequestQueue {
  constructor(concurrency = 5, delayMs = 0) {
    this.concurrency = concurrency;
    this.delayMs = delayMs;
    this.running = 0;
    this.queue = [];
  }
  
  async add(fn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ fn, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.running >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.running++;
    const { fn, resolve, reject } = this.queue.shift();
    
    try {
      const result = await fn();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.running--;
      
      if (this.delayMs > 0) {
        await new Promise(resolve => setTimeout(resolve, this.delayMs));
      }
      
      this.process();
    }
  }
  
  async fetch(url, options) {
    return this.add(() => fetch(url, options));
  }
}

// Usage: 5 concurrent requests, 200ms delay between each
const queue = new RequestQueue(5, 200);

// All requests automatically queued
const responses = await Promise.all([
  queue.fetch('/api/user/1'),
  queue.fetch('/api/user/2'),
  queue.fetch('/api/user/3'),
  // ... 100 more requests
]);
```

#### Priority Queue

```javascript
class PriorityRequestQueue {
  constructor(concurrency = 3) {
    this.concurrency = concurrency;
    this.running = 0;
    this.queue = [];
  }
  
  async add(fn, priority = 0) {
    return new Promise((resolve, reject) => {
      this.queue.push({ fn, resolve, reject, priority });
      this.queue.sort((a, b) => b.priority - a.priority);
      this.process();
    });
  }
  
  async process() {
    if (this.running >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.running++;
    const { fn, resolve, reject } = this.queue.shift();
    
    try {
      const result = await fn();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.running--;
      this.process();
    }
  }
  
  async fetch(url, options, priority = 0) {
    return this.add(() => fetch(url, options), priority);
  }
}

const queue = new PriorityRequestQueue(3);

// High priority requests processed first
await queue.fetch('/api/critical', {}, 10);
await queue.fetch('/api/normal', {}, 0);
await queue.fetch('/api/low', {}, -5);
```

### Adaptive Rate Limiting

#### Response-Based Adjustment

```javascript
class AdaptiveRateLimiter {
  constructor(initialRate = 10, minRate = 1, maxRate = 100) {
    this.currentRate = initialRate;
    this.minRate = minRate;
    this.maxRate = maxRate;
    this.queue = [];
    this.processing = false;
    this.successCount = 0;
    this.errorCount = 0;
  }
  
  adjustRate(success) {
    if (success) {
      this.successCount++;
      this.errorCount = Math.max(0, this.errorCount - 1);
      
      // Gradually increase rate on success
      if (this.successCount > 10) {
        this.currentRate = Math.min(this.maxRate, this.currentRate * 1.1);
        this.successCount = 0;
      }
    } else {
      this.errorCount++;
      this.successCount = 0;
      
      // Decrease rate on errors
      this.currentRate = Math.max(this.minRate, this.currentRate * 0.5);
    }
  }
  
  async fetch(url, options) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.processQueue();
    });
  }
  
  async processQueue() {
    if (this.processing || this.queue.length === 0) {
      return;
    }
    
    this.processing = true;
    
    while (this.queue.length > 0) {
      const { url, options, resolve, reject } = this.queue.shift();
      const delayMs = 1000 / this.currentRate;
      
      try {
        const response = await fetch(url, options);
        
        if (response.status === 429) {
          // Rate limited by server
          this.adjustRate(false);
          
          const retryAfter = response.headers.get('Retry-After');
          if (retryAfter) {
            await new Promise(r => setTimeout(r, parseInt(retryAfter) * 1000));
          }
          
          // Re-queue the request
          this.queue.unshift({ url, options, resolve, reject });
          continue;
        }
        
        this.adjustRate(response.ok);
        resolve(response);
      } catch (error) {
        this.adjustRate(false);
        reject(error);
      }
      
      if (this.queue.length > 0) {
        await new Promise(r => setTimeout(r, delayMs));
      }
    }
    
    this.processing = false;
  }
}

const limiter = new AdaptiveRateLimiter(10, 1, 50);

async function smartFetch(url, options) {
  return limiter.fetch(url, options);
}
```

#### Server Header Respect

```javascript
class HeaderBasedRateLimiter {
  constructor() {
    this.limits = new Map();
  }
  
  parseRateLimitHeaders(response, key) {
    const limit = parseInt(response.headers.get('X-RateLimit-Limit') || '0');
    const remaining = parseInt(response.headers.get('X-RateLimit-Remaining') || '0');
    const reset = parseInt(response.headers.get('X-RateLimit-Reset') || '0');
    
    if (limit && reset) {
      this.limits.set(key, {
        limit,
        remaining,
        reset: reset * 1000, // Convert to milliseconds
        lastUpdate: Date.now()
      });
    }
  }
  
  async waitIfNeeded(key) {
    const limitInfo = this.limits.get(key);
    
    if (!limitInfo) {
      return;
    }
    
    const now = Date.now();
    
    if (limitInfo.remaining <= 0 && limitInfo.reset > now) {
      const waitTime = limitInfo.reset - now;
      await new Promise(resolve => setTimeout(resolve, waitTime));
      
      // Reset the limit after waiting
      this.limits.delete(key);
    }
  }
  
  async fetch(url, options = {}) {
    const urlObj = new URL(url);
    const key = `${urlObj.hostname}${urlObj.pathname}`;
    
    await this.waitIfNeeded(key);
    
    const response = await fetch(url, options);
    this.parseRateLimitHeaders(response, key);
    
    if (response.status === 429) {
      const retryAfter = response.headers.get('Retry-After');
      
      if (retryAfter) {
        const waitMs = retryAfter.includes(':') 
          ? new Date(retryAfter).getTime() - Date.now()
          : parseInt(retryAfter) * 1000;
        
        await new Promise(resolve => setTimeout(resolve, waitMs));
        return this.fetch(url, options);
      }
    }
    
    return response;
  }
}

const limiter = new HeaderBasedRateLimiter();

async function respectedFetch(url, options) {
  return limiter.fetch(url, options);
}
```

### Per-Domain Rate Limiting

#### Multi-Domain Manager

```javascript
class MultiDomainRateLimiter {
  constructor(defaultConfig = { maxRequests: 10, windowMs: 1000 }) {
    this.defaultConfig = defaultConfig;
    this.limiters = new Map();
    this.domainConfigs = new Map();
  }
  
  setDomainConfig(domain, config) {
    this.domainConfigs.set(domain, config);
  }
  
  getLimiter(domain) {
    if (!this.limiters.has(domain)) {
      const config = this.domainConfigs.get(domain) || this.defaultConfig;
      this.limiters.set(domain, new SlidingWindowRateLimiter(
        config.maxRequests,
        config.windowMs
      ));
    }
    return this.limiters.get(domain);
  }
  
  async fetch(url, options) {
    const urlObj = new URL(url);
    const domain = urlObj.hostname;
    const limiter = this.getLimiter(domain);
    
    await limiter.throttle();
    return fetch(url, options);
  }
}

const multiLimiter = new MultiDomainRateLimiter();

// Configure specific domains
multiLimiter.setDomainConfig('api.github.com', {
  maxRequests: 60,
  windowMs: 60000
});

multiLimiter.setDomainConfig('api.twitter.com', {
  maxRequests: 15,
  windowMs: 900000
});

// Automatically applies correct limits per domain
await multiLimiter.fetch('https://api.github.com/user');
await multiLimiter.fetch('https://api.twitter.com/tweets');
```

### Exponential Backoff

#### Basic Exponential Backoff

```javascript
class ExponentialBackoff {
  constructor(initialDelay = 1000, maxDelay = 32000, maxRetries = 5) {
    this.initialDelay = initialDelay;
    this.maxDelay = maxDelay;
    this.maxRetries = maxRetries;
  }
  
  calculateDelay(attempt) {
    const exponentialDelay = this.initialDelay * Math.pow(2, attempt);
    const jitter = Math.random() * 0.3 * exponentialDelay;
    return Math.min(exponentialDelay + jitter, this.maxDelay);
  }
  
  async fetch(url, options = {}) {
    let lastError;
    
    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok) {
          return response;
        }
        
        // Retry on 429 or 5xx errors
        if (response.status === 429 || response.status >= 500) {
          if (attempt < this.maxRetries) {
            const delay = this.calculateDelay(attempt);
            await new Promise(resolve => setTimeout(resolve, delay));
            continue;
          }
        }
        
        return response;
      } catch (error) {
        lastError = error;
        
        if (attempt < this.maxRetries) {
          const delay = this.calculateDelay(attempt);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }
    
    throw lastError || new Error('Max retries exceeded');
  }
}

const backoff = new ExponentialBackoff(1000, 32000, 5);

async function resilientFetch(url, options) {
  return backoff.fetch(url, options);
}
```

#### Decorrelated Jitter

```javascript
class DecorrelatedJitter {
  constructor(baseDelay = 100, maxDelay = 20000) {
    this.baseDelay = baseDelay;
    this.maxDelay = maxDelay;
    this.previousDelay = baseDelay;
  }
  
  calculateDelay() {
    const delay = Math.random() * (this.previousDelay * 3 - this.baseDelay) + this.baseDelay;
    this.previousDelay = Math.min(delay, this.maxDelay);
    return this.previousDelay;
  }
  
  async fetch(url, options = {}, maxRetries = 5) {
    let attempt = 0;
    
    while (attempt <= maxRetries) {
      try {
        const response = await fetch(url, options);
        
        if (response.ok || (response.status !== 429 && response.status < 500)) {
          this.previousDelay = this.baseDelay; // Reset on success
          return response;
        }
        
        if (attempt < maxRetries) {
          const delay = this.calculateDelay();
          await new Promise(resolve => setTimeout(resolve, delay));
          attempt++;
        } else {
          return response;
        }
      } catch (error) {
        if (attempt < maxRetries) {
          const delay = this.calculateDelay();
          await new Promise(resolve => setTimeout(resolve, delay));
          attempt++;
        } else {
          throw error;
        }
      }
    }
  }
}
```

### Circuit Breaker Pattern

#### Request Circuit Breaker

```javascript
class CircuitBreaker {
  constructor(failureThreshold = 5, resetTimeout = 60000) {
    this.failureThreshold = failureThreshold;
    this.resetTimeout = resetTimeout;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failureCount = 0;
    this.nextAttempt = Date.now();
  }
  
  async fetch(url, options) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }
    
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        this.onSuccess();
      } else {
        this.onFailure();
      }
      
      return response;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failureCount = 0;
    if (this.state === 'HALF_OPEN') {
      this.state = 'CLOSED';
    }
  }
  
  onFailure() {
    this.failureCount++;
    
    if (this.failureCount >= this.failureThreshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.resetTimeout;
    }
  }
  
  getState() {
    return this.state;
  }
}

const breaker = new CircuitBreaker(5, 30000);

async function protectedFetch(url, options) {
  try {
    return await breaker.fetch(url, options);
  } catch (error) {
    if (error.message === 'Circuit breaker is OPEN') {
      // Return cached data or fallback
      return caches.match(url);
    }
    throw error;
  }
}
```

### Batch Request Optimization

#### Request Batching

```javascript
class RequestBatcher {
  constructor(batchSize = 10, flushInterval = 100) {
    this.batchSize = batchSize;
    this.flushInterval = flushInterval;
    this.batch = [];
    this.flushTimer = null;
  }
  
  async add(request) {
    return new Promise((resolve, reject) => {
      this.batch.push({ request, resolve, reject });
      
      if (this.batch.length >= this.batchSize) {
        this.flush();
      } else if (!this.flushTimer) {
        this.flushTimer = setTimeout(() => this.flush(), this.flushInterval);
      }
    });
  }
  
  async flush() {
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
      this.flushTimer = null;
    }
    
    if (this.batch.length === 0) {
      return;
    }
    
    const currentBatch = this.batch.splice(0);
    
    // Create batch request payload
    const batchPayload = currentBatch.map(item => item.request);
    
    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ requests: batchPayload })
      });
      
      const results = await response.json();
      
      currentBatch.forEach((item, index) => {
        item.resolve(results[index]);
      });
    } catch (error) {
      currentBatch.forEach(item => {
        item.reject(error);
      });
    }
  }
  
  async fetch(url, options) {
    const request = { url, options };
    return this.add(request);
  }
}

const batcher = new RequestBatcher(10, 100);

// Individual requests automatically batched
const results = await Promise.all([
  batcher.fetch('/api/user/1'),
  batcher.fetch('/api/user/2'),
  batcher.fetch('/api/user/3'),
  // Sent as single batch request
]);
```

### Comprehensive Rate Limiter

#### All-in-One Solution

```javascript
class ComprehensiveRateLimiter {
  constructor(config = {}) {
    this.config = {
      maxConcurrent: config.maxConcurrent || 5,
      maxPerSecond: config.maxPerSecond || 10,
      maxPerMinute: config.maxPerMinute || 100,
      retryAttempts: config.retryAttempts || 3,
      backoffMultiplier: config.backoffMultiplier || 2,
      circuitBreakerThreshold: config.circuitBreakerThreshold || 5,
      circuitBreakerTimeout: config.circuitBreakerTimeout || 60000,
      ...config
    };
    
    this.queue = [];
    this.running = 0;
    this.perSecondLog = [];
    this.perMinuteLog = [];
    this.circuitState = 'CLOSED';
    this.failureCount = 0;
    this.nextCircuitAttempt = Date.now();
  }
  
  async fetch(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject, attempts: 0 });
      this.processQueue();
    });
  }
  
  async processQueue() {
    if (this.running >= this.config.maxConcurrent || this.queue.length === 0) {
      return;
    }
    
    // Check circuit breaker
    if (this.circuitState === 'OPEN') {
      if (Date.now() < this.nextCircuitAttempt) {
        return;
      }
      this.circuitState = 'HALF_OPEN';
    }
    
    // Check rate limits
    await this.enforceRateLimits();
    
    this.running++;
    const task = this.queue.shift();
    
    try {
      const response = await this.executeWithRetry(task);
      this.onSuccess();
      task.resolve(response);
    } catch (error) {
      this.onFailure();
      task.reject(error);
    } finally {
      this.running--;
      this.processQueue();
    }
  }
  
  async enforceRateLimits() {
    const now = Date.now();
    
    // Per-second limit
    this.perSecondLog = this.perSecondLog.filter(t => t > now - 1000);
    if (this.perSecondLog.length >= this.config.maxPerSecond) {
      const oldestRequest = this.perSecondLog[0];
      const waitTime = 1000 - (now - oldestRequest);
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.enforceRateLimits();
    }
    
    // Per-minute limit
    this.perMinuteLog = this.perMinuteLog.filter(t => t > now - 60000);
    if (this.perMinuteLog.length >= this.config.maxPerMinute) {
      const oldestRequest = this.perMinuteLog[0];
      const waitTime = 60000 - (now - oldestRequest);
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.enforceRateLimits();
    }
    
    this.perSecondLog.push(now);
    this.perMinuteLog.push(now);
  }
  
  async executeWithRetry(task) {
    const { url, options, attempts } = task;
    
    try {
      const response = await fetch(url, options);
      
      if (response.status === 429 && attempts < this.config.retryAttempts) {
        const retryAfter = response.headers.get('Retry-After');
        const delay = retryAfter 
          ? parseInt(retryAfter) * 1000
          : this.config.backoffMultiplier ** attempts * 1000;
        
        await new Promise(resolve => setTimeout(resolve, delay));
        
        task.attempts++;
        this.queue.unshift(task);
        return this.processQueue();
      }
      
      return response;
    } catch (error) {
      if (attempts < this.config.retryAttempts) {
        const delay = this.config.backoffMultiplier ** attempts * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
        
        task.attempts++;
        this.queue.unshift(task);
        return this.processQueue();
      }
      
      throw error;
    }
  }
  
  onSuccess() {
    this.failureCount = 0;
    if (this.circuitState === 'HALF_OPEN') {
      this.circuitState = 'CLOSED';
    }
  }
  
  onFailure() {
    this.failureCount++;
    
    if (this.failureCount >= this.config.circuitBreakerThreshold) {
      this.circuitState = 'OPEN';
      this.nextCircuitAttempt = Date.now() + this.config.circuitBreakerTimeout;
    }
  }
  
  getStats() {
    return {
      queueLength: this.queue.length,
      running: this.running,
      circuitState: this.circuitState,
      failureCount: this.failureCount,
      perSecondCount: this.perSecondLog.length,
      perMinuteCount: this.perMinuteLog.length
    };
  }
}

// Usage
const limiter = new ComprehensiveRateLimiter({
  maxConcurrent: 5,
  maxPerSecond: 10,
  maxPerMinute: 100,
  retryAttempts: 3,
  backoffMultiplier: 2,
  circuitBreakerThreshold: 5,
  circuitBreakerTimeout: 60000
});

async function smartFetch(url, options) {
  return limiter.fetch(url, options);
}

// Monitor performance
setInterval(() => {
  console.log('Rate Limiter Stats:', limiter.getStats());
}, 5000);
```

### Service Worker Integration

#### Rate-Limited Service Worker

```javascript
// service-worker.js
class ServiceWorkerRateLimiter {
  constructor() {
    this.limiters = new Map();
  }
  
  getLimiter(domain) {
    if (!this.limiters.has(domain)) {
      this.limiters.set(domain, new SlidingWindowRateLimiter(100, 60000));
    }
    return this.limiters.get(domain);
  }
  
  async fetch(request) {
    const url = new URL(request.url);
    const domain = url.hostname;
    
    // Skip rate limiting for same-origin requests
    if (url.origin === self.location.origin) {
      return fetch(request);
    }
    
    const limiter = this.getLimiter(domain);
    await limiter.throttle();
    
    return fetch(request);
  }
}

const swLimiter = new ServiceWorkerRateLimiter();

self.addEventListener('fetch', (event) => {
  event.respondWith(swLimiter.fetch(event.request));
});
```

---

## Request Deduplication with the Fetch API

### Understanding the Problem

Request deduplication prevents multiple identical network requests from being sent simultaneously. When multiple components or code paths request the same resource concurrently, without deduplication each triggers a separate network request. This wastes bandwidth, increases server load, and can cause race conditions or inconsistent state. Deduplication ensures only one request is made, with all callers receiving the same response.

### Basic Request Deduplication

```javascript
class RequestDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    
    // Check if request is already pending
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    // Create new request
    const requestPromise = fetch(url, options)
      .then(response => {
        // Clone for multiple consumers
        return response.clone();
      })
      .finally(() => {
        // Clean up after request completes
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    const headers = JSON.stringify(options.headers || {});
    const body = options.body || '';
    
    return `${method}:${url}:${headers}:${body}`;
  }
}

// Usage
const deduplicator = new RequestDeduplicator();

// Multiple simultaneous calls - only one network request
const [result1, result2, result3] = await Promise.all([
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/data')
]);
```

### Advanced Key Generation

Handle complex request scenarios with sophisticated key generation:

```javascript
class AdvancedDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  generateKey(url, options = {}) {
    const parsedUrl = new URL(url, window.location.origin);
    
    // Normalize URL
    const normalizedUrl = parsedUrl.origin + parsedUrl.pathname;
    
    // Sort query parameters for consistent keys
    const params = Array.from(parsedUrl.searchParams.entries())
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([key, value]) => `${key}=${value}`)
      .join('&');
    
    // Normalize method
    const method = (options.method || 'GET').toUpperCase();
    
    // Sort and normalize headers
    const headers = options.headers || {};
    const normalizedHeaders = Object.keys(headers)
      .sort()
      .reduce((acc, key) => {
        // Ignore headers that shouldn't affect deduplication
        const ignoreHeaders = ['user-agent', 'referer', 'accept-language'];
        if (!ignoreHeaders.includes(key.toLowerCase())) {
          acc[key.toLowerCase()] = headers[key];
        }
        return acc;
      }, {});
    
    // Handle body for POST/PUT requests
    let bodyKey = '';
    if (options.body) {
      if (typeof options.body === 'string') {
        bodyKey = options.body;
      } else if (options.body instanceof FormData) {
        bodyKey = Array.from(options.body.entries())
          .sort(([a], [b]) => a.localeCompare(b))
          .map(([key, value]) => `${key}=${value}`)
          .join('&');
      } else {
        bodyKey = JSON.stringify(options.body);
      }
    }
    
    const keyParts = [
      method,
      normalizedUrl,
      params,
      JSON.stringify(normalizedHeaders),
      bodyKey
    ].filter(Boolean);
    
    return keyParts.join('::');
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    const requestPromise = fetch(url, options)
      .then(response => response.clone())
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
}
```

### Time-Based Deduplication

Deduplicate requests within a time window:

```javascript
class TimedDeduplicator {
  constructor(options = {}) {
    this.pendingRequests = new Map();
    this.recentResponses = new Map();
    this.deduplicationWindow = options.window || 1000; // 1 second default
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    return `${method}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    const now = Date.now();
    
    // Check if we have a recent response
    const recent = this.recentResponses.get(key);
    if (recent && (now - recent.timestamp) < this.deduplicationWindow) {
      return recent.response.clone();
    }
    
    // Check if request is pending
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    // Make new request
    const requestPromise = fetch(url, options)
      .then(response => {
        // Store response for deduplication window
        this.recentResponses.set(key, {
          response: response.clone(),
          timestamp: Date.now()
        });
        
        // Clean up after window expires
        setTimeout(() => {
          this.recentResponses.delete(key);
        }, this.deduplicationWindow);
        
        return response.clone();
      })
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
  
  clearCache() {
    this.recentResponses.clear();
  }
  
  invalidate(url, options = {}) {
    const key = this.generateKey(url, options);
    this.recentResponses.delete(key);
    this.pendingRequests.delete(key);
  }
}

// Usage
const deduplicator = new TimedDeduplicator({ window: 5000 });

// First call makes request
await deduplicator.fetch('/api/data');

// Second call within 5s returns cached response
await deduplicator.fetch('/api/data');

// After 5s, makes new request
setTimeout(async () => {
  await deduplicator.fetch('/api/data');
}, 6000);
```

### Request Batching

Combine multiple similar requests into a single batch request:

```javascript
class RequestBatcher {
  constructor(options = {}) {
    this.batchWindow = options.batchWindow || 50; // 50ms default
    this.maxBatchSize = options.maxBatchSize || 10;
    this.pendingBatches = new Map();
    this.batchEndpoint = options.batchEndpoint || '/api/batch';
  }
  
  async fetch(url, options = {}) {
    const endpoint = this.getEndpoint(url);
    
    if (!this.pendingBatches.has(endpoint)) {
      this.pendingBatches.set(endpoint, {
        requests: [],
        timer: null
      });
    }
    
    const batch = this.pendingBatches.get(endpoint);
    
    return new Promise((resolve, reject) => {
      batch.requests.push({
        url,
        options,
        resolve,
        reject
      });
      
      // Clear existing timer
      if (batch.timer) {
        clearTimeout(batch.timer);
      }
      
      // Execute batch if max size reached
      if (batch.requests.length >= this.maxBatchSize) {
        this.executeBatch(endpoint);
      } else {
        // Schedule batch execution
        batch.timer = setTimeout(() => {
          this.executeBatch(endpoint);
        }, this.batchWindow);
      }
    });
  }
  
  async executeBatch(endpoint) {
    const batch = this.pendingBatches.get(endpoint);
    if (!batch || batch.requests.length === 0) return;
    
    this.pendingBatches.delete(endpoint);
    
    const requests = batch.requests.map(({ url, options }) => ({
      url,
      method: options.method || 'GET',
      headers: options.headers,
      body: options.body
    }));
    
    try {
      const response = await fetch(this.batchEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ requests })
      });
      
      const results = await response.json();
      
      // Resolve individual promises
      batch.requests.forEach((request, index) => {
        const result = results[index];
        
        if (result.error) {
          request.reject(new Error(result.error));
        } else {
          const mockResponse = new Response(
            JSON.stringify(result.data),
            {
              status: result.status || 200,
              headers: result.headers || {}
            }
          );
          request.resolve(mockResponse);
        }
      });
    } catch (error) {
      // Reject all requests in batch
      batch.requests.forEach(request => {
        request.reject(error);
      });
    }
  }
  
  getEndpoint(url) {
    const parsed = new URL(url, window.location.origin);
    return parsed.origin + parsed.pathname.split('/').slice(0, -1).join('/');
  }
}

// Usage
const batcher = new RequestBatcher({ batchWindow: 100 });

// These will be batched together
const results = await Promise.all([
  batcher.fetch('/api/users/1'),
  batcher.fetch('/api/users/2'),
  batcher.fetch('/api/users/3'),
  batcher.fetch('/api/users/4')
]);
```

### GraphQL-Style Query Deduplication

Deduplicate based on query content rather than URL:

```javascript
class GraphQLDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  generateKey(query, variables = {}) {
    // Normalize query by removing whitespace and comments
    const normalizedQuery = query
      .replace(/\s+/g, ' ')
      .replace(/#[^\n]*/g, '')
      .trim();
    
    // Sort variables for consistent keys
    const sortedVariables = Object.keys(variables)
      .sort()
      .reduce((acc, key) => {
        acc[key] = variables[key];
        return acc;
      }, {});
    
    return `${normalizedQuery}::${JSON.stringify(sortedVariables)}`;
  }
  
  async query(endpoint, query, variables = {}, options = {}) {
    const key = this.generateKey(query, variables);
    
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    const requestPromise = fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      },
      body: JSON.stringify({ query, variables }),
      ...options
    })
      .then(response => response.json())
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
  
  async mutate(endpoint, mutation, variables = {}, options = {}) {
    // Mutations should not be deduplicated
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      },
      body: JSON.stringify({ query: mutation, variables }),
      ...options
    });
    
    return response.json();
  }
}

// Usage
const gqlDedup = new GraphQLDeduplicator();

const query = `
  query GetUser($id: ID!) {
    user(id: $id) {
      name
      email
    }
  }
`;

// Only one request made despite multiple calls
const [user1, user2, user3] = await Promise.all([
  gqlDedup.query('/graphql', query, { id: '123' }),
  gqlDedup.query('/graphql', query, { id: '123' }),
  gqlDedup.query('/graphql', query, { id: '123' })
]);
```

### Selective Deduplication

Apply deduplication rules based on request characteristics:

```javascript
class SelectiveDeduplicator {
  constructor(options = {}) {
    this.pendingRequests = new Map();
    this.config = {
      deduplicateGET: true,
      deduplicatePOST: false,
      deduplicateWithCredentials: false,
      ignoredHeaders: ['authorization', 'x-request-id'],
      ...options
    };
  }
  
  shouldDeduplicate(url, options = {}) {
    const method = (options.method || 'GET').toUpperCase();
    
    // Check method-based rules
    if (method === 'GET' && !this.config.deduplicateGET) {
      return false;
    }
    
    if (method === 'POST' && !this.config.deduplicatePOST) {
      return false;
    }
    
    // Check credentials
    if (options.credentials === 'include' && 
        !this.config.deduplicateWithCredentials) {
      return false;
    }
    
    // Check for no-cache headers
    const headers = options.headers || {};
    const cacheControl = headers['cache-control'] || headers['Cache-Control'];
    if (cacheControl && cacheControl.includes('no-cache')) {
      return false;
    }
    
    // Check URL patterns
    const parsedUrl = new URL(url, window.location.origin);
    if (parsedUrl.searchParams.has('nocache')) {
      return false;
    }
    
    return true;
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    const headers = { ...options.headers };
    
    // Remove ignored headers
    this.config.ignoredHeaders.forEach(header => {
      delete headers[header];
      delete headers[header.toLowerCase()];
    });
    
    return `${method}:${url}:${JSON.stringify(headers)}`;
  }
  
  async fetch(url, options = {}) {
    if (!this.shouldDeduplicate(url, options)) {
      return fetch(url, options);
    }
    
    const key = this.generateKey(url, options);
    
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    const requestPromise = fetch(url, options)
      .then(response => response.clone())
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
}

// Usage
const deduplicator = new SelectiveDeduplicator({
  deduplicateGET: true,
  deduplicatePOST: false,
  ignoredHeaders: ['x-request-id', 'x-correlation-id']
});

// GET requests are deduplicated
await Promise.all([
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/data')
]);

// POST requests are not deduplicated
await Promise.all([
  deduplicator.fetch('/api/data', { method: 'POST' }),
  deduplicator.fetch('/api/data', { method: 'POST' })
]);
```

### Deduplication with AbortController

Support request cancellation with proper cleanup:

```javascript
class AbortableDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    return `${method}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    
    // Check for existing request
    if (this.pendingRequests.has(key)) {
      const existing = this.pendingRequests.get(key);
      
      // Add this abort signal to the list
      if (options.signal) {
        existing.abortSignals.add(options.signal);
        
        // If any signal aborts and it's the last one, abort the main request
        options.signal.addEventListener('abort', () => {
          existing.abortSignals.delete(options.signal);
          
          if (existing.abortSignals.size === 0) {
            existing.controller.abort();
            this.pendingRequests.delete(key);
          }
        });
      }
      
      return existing.promise;
    }
    
    // Create new request with combined abort controller
    const controller = new AbortController();
    const abortSignals = new Set();
    
    if (options.signal) {
      abortSignals.add(options.signal);
      
      options.signal.addEventListener('abort', () => {
        abortSignals.delete(options.signal);
        
        if (abortSignals.size === 0) {
          controller.abort();
          this.pendingRequests.delete(key);
        }
      });
    }
    
    const requestPromise = fetch(url, {
      ...options,
      signal: controller.signal
    })
      .then(response => response.clone())
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, {
      promise: requestPromise,
      controller,
      abortSignals
    });
    
    return requestPromise;
  }
  
  abort(url, options = {}) {
    const key = this.generateKey(url, options);
    const pending = this.pendingRequests.get(key);
    
    if (pending) {
      pending.controller.abort();
      this.pendingRequests.delete(key);
    }
  }
  
  abortAll() {
    for (const [key, pending] of this.pendingRequests) {
      pending.controller.abort();
    }
    this.pendingRequests.clear();
  }
}

// Usage
const deduplicator = new AbortableDeduplicator();

const controller1 = new AbortController();
const controller2 = new AbortController();

// Both share the same underlying request
const promise1 = deduplicator.fetch('/api/data', {
  signal: controller1.signal
});

const promise2 = deduplicator.fetch('/api/data', {
  signal: controller2.signal
});

// Aborting one doesn't affect the other
controller1.abort();

// Request continues for promise2
const result = await promise2;
```

### Priority-Based Deduplication

Handle requests with different priority levels:

```javascript
class PriorityDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    // Don't include priority in key
    return `${method}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    const priority = options.priority || 'normal';
    
    if (this.pendingRequests.has(key)) {
      const existing = this.pendingRequests.get(key);
      
      // Upgrade priority if current request is higher priority
      const priorityLevels = { low: 0, normal: 1, high: 2 };
      const currentPriority = priorityLevels[existing.priority];
      const newPriority = priorityLevels[priority];
      
      if (newPriority > currentPriority) {
        // Cancel existing low-priority request
        existing.controller.abort();
        
        // Start new high-priority request
        return this.makeRequest(url, options, key);
      }
      
      // Return existing higher or equal priority request
      return existing.promise;
    }
    
    return this.makeRequest(url, options, key);
  }
  
  makeRequest(url, options, key) {
    const controller = new AbortController();
    const priority = options.priority || 'normal';
    
    const requestPromise = fetch(url, {
      ...options,
      signal: controller.signal
    })
      .then(response => response.clone())
      .catch(error => {
        if (error.name === 'AbortError') {
          // Request was upgraded, don't propagate error
          throw new Error('Request upgraded to higher priority');
        }
        throw error;
      })
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, {
      promise: requestPromise,
      controller,
      priority
    });
    
    return requestPromise;
  }
}

// Usage
const deduplicator = new PriorityDeduplicator();

// Low priority request starts
const lowPriority = deduplicator.fetch('/api/data', {
  priority: 'low'
});

// High priority request cancels low and starts new
const highPriority = deduplicator.fetch('/api/data', {
  priority: 'high'
});

// High priority completes
const result = await highPriority;
```

### React Hook Integration

Integrate deduplication with React components:

```javascript
class ReactDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    const body = options.body ? JSON.stringify(options.body) : '';
    return `${method}:${url}:${body}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    
    if (this.pendingRequests.has(key)) {
      const existing = this.pendingRequests.get(key);
      existing.subscribers++;
      
      return existing.promise.finally(() => {
        existing.subscribers--;
        if (existing.subscribers === 0) {
          // Clean up after a delay
          setTimeout(() => {
            if (this.pendingRequests.get(key)?.subscribers === 0) {
              this.pendingRequests.delete(key);
            }
          }, 1000);
        }
      });
    }
    
    const requestPromise = fetch(url, options)
      .then(response => response.clone());
    
    this.pendingRequests.set(key, {
      promise: requestPromise,
      subscribers: 1
    });
    
    return requestPromise;
  }
}

// React Hook
const deduplicator = new ReactDeduplicator();

function useDedupedFetch(url, options) {
  const [data, setData] = React.useState(null);
  const [loading, setLoading] = React.useState(true);
  const [error, setError] = React.useState(null);
  
  React.useEffect(() => {
    let mounted = true;
    
    deduplicator.fetch(url, options)
      .then(async response => {
        const json = await response.json();
        if (mounted) {
          setData(json);
          setLoading(false);
        }
      })
      .catch(err => {
        if (mounted) {
          setError(err);
          setLoading(false);
        }
      });
    
    return () => {
      mounted = false;
    };
  }, [url, JSON.stringify(options)]);
  
  return { data, loading, error };
}

// Usage in component
function UserProfile({ userId }) {
  const { data, loading, error } = useDedupedFetch(`/api/users/${userId}`);
  
  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error.message}</div>;
  
  return <div>{data.name}</div>;
}
```

### Deduplication with Cache Integration

Combine deduplication with caching strategies:

```javascript
class CachedDeduplicator {
  constructor(options = {}) {
    this.pendingRequests = new Map();
    this.cache = new Map();
    this.maxCacheAge = options.maxCacheAge || 60000; // 1 minute
    this.maxCacheSize = options.maxCacheSize || 100;
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    return `${method}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    
    // Check cache first
    const cached = this.cache.get(key);
    if (cached && Date.now() - cached.timestamp < this.maxCacheAge) {
      return cached.response.clone();
    }
    
    // Check pending requests
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    // Make new request
    const requestPromise = fetch(url, options)
      .then(response => {
        const cloned = response.clone();
        
        // Cache successful responses
        if (response.ok) {
          this.addToCache(key, cloned);
        }
        
        return response.clone();
      })
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
  
  addToCache(key, response) {
    // Implement LRU eviction
    if (this.cache.size >= this.maxCacheSize) {
      const oldestKey = this.cache.keys().next().value;
      this.cache.delete(oldestKey);
    }
    
    this.cache.set(key, {
      response: response.clone(),
      timestamp: Date.now()
    });
  }
  
  invalidate(url, options = {}) {
    const key = this.generateKey(url, options);
    this.cache.delete(key);
    this.pendingRequests.delete(key);
  }
  
  invalidateAll() {
    this.cache.clear();
    this.pendingRequests.clear();
  }
  
  invalidatePattern(pattern) {
    const regex = new RegExp(pattern);
    
    for (const key of this.cache.keys()) {
      if (regex.test(key)) {
        this.cache.delete(key);
      }
    }
    
    for (const key of this.pendingRequests.keys()) {
      if (regex.test(key)) {
        this.pendingRequests.delete(key);
      }
    }
  }
}

// Usage
const deduplicator = new CachedDeduplicator({
  maxCacheAge: 30000, // 30 seconds
  maxCacheSize: 50
});

// First call makes request
await deduplicator.fetch('/api/data');

// Second call returns cached response
await deduplicator.fetch('/api/data');

// Invalidate specific endpoint
deduplicator.invalidate('/api/data');

// Invalidate all user endpoints
deduplicator.invalidatePattern('/api/users/');
```

### Monitoring and Debugging

Track deduplication effectiveness:

```javascript
class MonitoredDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
    this.metrics = {
      totalRequests: 0,
      deduplicatedRequests: 0,
      uniqueRequests: 0,
      savedRequests: 0
    };
  }
  
  generateKey(url, options) {
    const method = options.method || 'GET';
    return `${method}:${url}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.generateKey(url, options);
    this.metrics.totalRequests++;
    
    if (this.pendingRequests.has(key)) {
      this.metrics.deduplicatedRequests++;
      this.metrics.savedRequests++;
      
      console.log(`[Dedup] Reusing request for ${key}`);
      console.log(`[Dedup] Saved ${this.metrics.savedRequests} requests so far`);
      
      return this.pendingRequests.get(key);
    }
    
    this.metrics.uniqueRequests++;
    console.log(`[Dedup] New request for ${key}`);
    
    const requestPromise = fetch(url, options)
      .then(response => {
        console.log(`[Dedup] Completed request for ${key}`);
        return response.clone();
      })
      .finally(() => {
        this.pendingRequests.delete(key);
      });
    
    this.pendingRequests.set(key, requestPromise);
    return requestPromise;
  }
  
  getMetrics() {
    return {
      ...this.metrics,
      deduplicationRate: this.metrics.totalRequests > 0
        ? this.metrics.deduplicatedRequests / this.metrics.totalRequests
        : 0,
      efficiency: this.metrics.uniqueRequests > 0
        ? this.metrics.savedRequests / this.metrics.uniqueRequests
        : 0
    };
  }
  
  resetMetrics() {
    this.metrics = {
      totalRequests: 0,
      deduplicatedRequests: 0,
      uniqueRequests: 0,
      savedRequests: 0
    };
  }
  
  getPendingRequests() {
    return Array.from(this.pendingRequests.keys());
  }
}

// Usage
const deduplicator = new MonitoredDeduplicator();

// Make multiple requests
await Promise.all([
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/data'),
  deduplicator.fetch('/api/users'),
  deduplicator.fetch('/api/users')
]);

console.log(deduplicator.getMetrics());
// {
//   totalRequests: 5,
//   deduplicatedRequests: 3,
//   uniqueRequests: 2,
//   savedRequests: 3,
//   deduplicationRate: 0.6,
//   efficiency: 1.5
// }
```

### Best Practices Summary

Always clone responses before returning them to multiple consumers to prevent body stream consumption issues. Implement proper cleanup of pending request maps to prevent memory leaks. Consider time-based deduplication windows for frequently changing data. Use appropriate key generation strategies that account for all request parameters affecting the response. Do not deduplicate mutation requests like POST, PUT, DELETE unless explicitly required. Handle AbortController signals properly when multiple consumers share a request. Implement invalidation mechanisms for cache coherence when data changes. Consider request priority when deciding whether to deduplicate. Monitor deduplication metrics to validate effectiveness and tune parameters. Be cautious with credentials and authentication headers in deduplication keys. Test thoroughly with concurrent request scenarios. Document deduplication behavior clearly for API consumers. Consider memory usage when caching responses alongside deduplication. Implement proper error handling for failed deduplicated requests.

---

## Parallel Requests with Promise.all()

### Core Mechanism

`Promise.all()` accepts an iterable of promises and returns a single promise that resolves when all input promises resolve, or rejects when any input promise rejects. For fetch operations, this enables concurrent network requests rather than sequential execution.

```javascript
const [users, posts, comments] = await Promise.all([
  fetch('/api/users').then(r => r.json()),
  fetch('/api/posts').then(r => r.json()),
  fetch('/api/comments').then(r => r.json())
]);
```

All three requests initiate simultaneously. Total execution time approximates the slowest request rather than the sum of all requests.

### Execution Timeline Comparison

#### Sequential Execution

```javascript
const users = await fetch('/api/users').then(r => r.json());    // 200ms
const posts = await fetch('/api/posts').then(r => r.json());    // 150ms
const comments = await fetch('/api/comments').then(r => r.json()); // 180ms
// Total: ~530ms
```

Each request waits for the previous to complete before initiating.

#### Parallel Execution

```javascript
const [users, posts, comments] = await Promise.all([
  fetch('/api/users').then(r => r.json()),    // 200ms
  fetch('/api/posts').then(r => r.json()),    // 150ms
  fetch('/api/comments').then(r => r.json())  // 180ms
]);
// Total: ~200ms (longest request)
```

All requests execute concurrently. Total time equals the slowest request plus minimal overhead.

### All-or-Nothing Resolution Behavior

`Promise.all()` rejects immediately when any input promise rejects, short-circuiting remaining operations:

```javascript
try {
  const [data1, data2, data3] = await Promise.all([
    fetch('/api/endpoint1').then(r => r.json()), // Succeeds after 100ms
    fetch('/api/endpoint2').then(r => r.json()), // Fails after 50ms
    fetch('/api/endpoint3').then(r => r.json())  // Succeeds after 150ms
  ]);
} catch (error) {
  // Catches at 50ms when endpoint2 fails
  // data1 and data3 are not accessible even though endpoint1 may have succeeded
}
```

[Inference] The successful requests complete in the background, but their results are discarded. Network resources are consumed for all requests regardless of early rejection.

### Independent Request Patterns

#### Basic Parallel Requests

```javascript
async function fetchDashboardData() {
  const [userProfile, notifications, activityFeed, settings] = await Promise.all([
    fetch('/api/user/profile').then(r => r.json()),
    fetch('/api/notifications').then(r => r.json()),
    fetch('/api/activity').then(r => r.json()),
    fetch('/api/settings').then(r => r.json())
  ]);
  
  return { userProfile, notifications, activityFeed, settings };
}
```

Appropriate when all data is independent and equally required for the operation.

#### Dynamic Request Arrays

```javascript
async function fetchMultipleUsers(userIds) {
  const requests = userIds.map(id => 
    fetch(`/api/users/${id}`).then(r => r.json())
  );
  
  return await Promise.all(requests);
}

// Usage
const users = await fetchMultipleUsers([1, 2, 3, 4, 5]);
```

Scales to arbitrary numbers of requests based on input data.

#### Mixed Request Types

```javascript
const [userData, imageBlob, csvText] = await Promise.all([
  fetch('/api/user').then(r => r.json()),
  fetch('/images/avatar.png').then(r => r.blob()),
  fetch('/data/export.csv').then(r => r.text())
]);
```

Different response processing methods can coexist within the same `Promise.all()`.

### Dependent Request Handling

When requests depend on previous results, structure dependencies carefully:

```javascript
// Anti-pattern: Sequential due to dependency
const user = await fetch('/api/user/me').then(r => r.json());
const [posts, followers] = await Promise.all([
  fetch(`/api/users/${user.id}/posts`).then(r => r.json()),
  fetch(`/api/users/${user.id}/followers`).then(r => r.json())
]);
```

The initial user fetch must complete before the parallel requests can begin. Total time: user request + max(posts, followers).

#### Nested Parallelism

```javascript
async function fetchCompleteProfile(userId) {
  // First wave: Independent initial data
  const [user, settings] = await Promise.all([
    fetch(`/api/users/${userId}`).then(r => r.json()),
    fetch(`/api/settings/${userId}`).then(r => r.json())
  ]);
  
  // Second wave: Dependent on first wave results
  const [posts, followers, following] = await Promise.all([
    fetch(`/api/users/${user.id}/posts`).then(r => r.json()),
    fetch(`/api/users/${user.id}/followers`).then(r => r.json()),
    fetch(`/api/users/${user.id}/following`).then(r => r.json())
  ]);
  
  return { user, settings, posts, followers, following };
}
```

Maximizes parallelism within dependency constraints.

### Error Handling Strategies

#### Try-Catch Around Promise.all()

```javascript
try {
  const [users, posts] = await Promise.all([
    fetch('/api/users').then(r => r.json()),
    fetch('/api/posts').then(r => r.json())
  ]);
  // Use data
} catch (error) {
  // Any rejection ends up here
  // Cannot distinguish which request failed without additional logic
  console.error('One or more requests failed:', error);
}
```

Simple but loses context about which request failed and discards successful results.

#### Individual Promise Error Handling

```javascript
const [users, posts] = await Promise.all([
  fetch('/api/users')
    .then(r => r.json())
    .catch(err => {
      console.error('Users fetch failed:', err);
      return []; // Fallback value
    }),
  fetch('/api/posts')
    .then(r => r.json())
    .catch(err => {
      console.error('Posts fetch failed:', err);
      return []; // Fallback value
    })
]);

// users and posts always have values (possibly fallbacks)
```

Each promise handles its own errors. `Promise.all()` never rejects because individual promises always resolve (with fallback values).

#### Response Status Validation

```javascript
async function fetchWithValidation(url) {
  const response = await fetch(url);
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
  }
  return response.json();
}

try {
  const [users, posts] = await Promise.all([
    fetchWithValidation('/api/users'),
    fetchWithValidation('/api/posts')
  ]);
} catch (error) {
  // Catches both network errors and non-2xx responses
  console.error('Request failed:', error);
}
```

Ensures HTTP errors trigger rejection, as `fetch()` only rejects on network failures by default.

#### Structured Error Information

```javascript
const results = await Promise.all([
  fetch('/api/users')
    .then(r => r.json())
    .then(data => ({ success: true, data }))
    .catch(error => ({ success: false, error })),
  fetch('/api/posts')
    .then(r => r.json())
    .then(data => ({ success: true, data }))
    .catch(error => ({ success: false, error }))
]);

results.forEach((result, index) => {
  if (result.success) {
    console.log(`Request ${index} succeeded:`, result.data);
  } else {
    console.error(`Request ${index} failed:`, result.error);
  }
});
```

Preserves both successful and failed results with distinguishable status.

### Promise.allSettled() Alternative

`Promise.allSettled()` waits for all promises to settle (resolve or reject) and returns their outcomes:

```javascript
const results = await Promise.allSettled([
  fetch('/api/users').then(r => r.json()),
  fetch('/api/posts').then(r => r.json()),
  fetch('/api/comments').then(r => r.json())
]);

results.forEach((result, index) => {
  if (result.status === 'fulfilled') {
    console.log(`Request ${index}:`, result.value);
  } else {
    console.error(`Request ${index} failed:`, result.reason);
  }
});
```

Advantages over `Promise.all()`:

- Never rejects; always resolves with all outcomes
- Provides detailed status for each promise
- Suitable when partial success is acceptable

Use `Promise.all()` when all requests must succeed; use `Promise.allSettled()` when partial results are useful.

### Performance Considerations

#### Browser Connection Limits

Browsers limit concurrent connections per origin (typically 6-8 for HTTP/1.1, effectively unlimited for HTTP/2):

```javascript
// HTTP/1.1: Only 6 requests execute simultaneously
const requests = Array.from({ length: 20 }, (_, i) => 
  fetch(`/api/data/${i}`).then(r => r.json())
);
await Promise.all(requests);
```

[Inference] Requests 7-20 queue until earlier requests complete. HTTP/2 multiplexing eliminates this bottleneck by allowing many requests over a single connection.

#### Memory Consumption

All response data resides in memory simultaneously:

```javascript
// Each response is ~1MB; peak memory usage ~50MB
const images = await Promise.all(
  Array.from({ length: 50 }, (_, i) => 
    fetch(`/images/${i}.jpg`).then(r => r.blob())
  )
);
```

For large datasets, consider batching:

```javascript
async function fetchInBatches(urls, batchSize = 10) {
  const results = [];
  
  for (let i = 0; i < urls.length; i += batchSize) {
    const batch = urls.slice(i, i + batchSize);
    const batchResults = await Promise.all(
      batch.map(url => fetch(url).then(r => r.json()))
    );
    results.push(...batchResults);
  }
  
  return results;
}
```

Limits concurrent requests and memory usage while maintaining parallelism within batches.

#### Server Load Implications

Parallel requests from many clients create coordinated load spikes:

```javascript
// On page load, every user makes 10 simultaneous requests
useEffect(() => {
  Promise.all([
    fetch('/api/endpoint1'),
    fetch('/api/endpoint2'),
    // ... 8 more endpoints
  ]);
}, []);
```

[Inference] This pattern can overwhelm servers during traffic surges. Stagger non-critical requests or prioritize essential data.

### Request Cancellation

#### AbortController with Promise.all()

```javascript
const controller = new AbortController();
const signal = controller.signal;

try {
  const [users, posts] = await Promise.all([
    fetch('/api/users', { signal }).then(r => r.json()),
    fetch('/api/posts', { signal }).then(r => r.json())
  ]);
} catch (error) {
  if (error.name === 'AbortError') {
    console.log('Requests cancelled');
  }
}

// Cancel all requests
controller.abort();
```

Aborting cancels all in-flight requests that share the signal. [Inference] Network resources are freed, though the browser may complete partial response downloads before fully aborting.

#### Timeout Pattern

```javascript
function fetchWithTimeout(url, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  return fetch(url, { signal: controller.signal })
    .then(r => r.json())
    .finally(() => clearTimeout(timeoutId));
}

try {
  const results = await Promise.all([
    fetchWithTimeout('/api/users', 5000),
    fetchWithTimeout('/api/posts', 5000),
    fetchWithTimeout('/api/comments', 5000)
  ]);
} catch (error) {
  console.error('Request timed out or failed:', error);
}
```

Each request has an independent timeout. The first timeout or error causes `Promise.all()` to reject.

#### Selective Cancellation

```javascript
const controllers = [new AbortController(), new AbortController()];

const [users, posts] = await Promise.all([
  fetch('/api/users', { signal: controllers[0].signal }).then(r => r.json()),
  fetch('/api/posts', { signal: controllers[1].signal }).then(r => r.json())
]);

// Cancel only the posts request
controllers[1].abort();
```

Individual controllers enable selective cancellation without affecting other requests.

### Race Conditions and Data Consistency

#### Order Dependency Issues

```javascript
// Anti-pattern: Assumes response order matches request order
const [userUpdate, accountSync] = await Promise.all([
  fetch('/api/user/update', { method: 'POST', body: userData }),
  fetch('/api/account/sync', { method: 'POST' })
]);
```

[Inference] If `accountSync` completes before `userUpdate`, it may operate on stale user data. Ensure operations are truly independent or enforce ordering.

#### State Management in React

```javascript
function Dashboard() {
  const [data, setData] = useState(null);
  
  useEffect(() => {
    let cancelled = false;
    
    Promise.all([
      fetch('/api/users').then(r => r.json()),
      fetch('/api/posts').then(r => r.json())
    ]).then(([users, posts]) => {
      if (!cancelled) {
        setData({ users, posts });
      }
    });
    
    return () => {
      cancelled = true;
    };
  }, []);
  
  return <div>{/* Render data */}</div>;
}
```

The `cancelled` flag prevents state updates if the component unmounts before requests complete, avoiding React warnings about setting state on unmounted components.

#### Concurrent Modifications

```javascript
// Potentially problematic: Concurrent writes to the same resource
await Promise.all([
  fetch('/api/user/123', { 
    method: 'PATCH', 
    body: JSON.stringify({ name: 'Alice' }) 
  }),
  fetch('/api/user/123', { 
    method: 'PATCH', 
    body: JSON.stringify({ email: 'alice@example.com' }) 
  })
]);
```

[Inference] Server-side behavior depends on implementation. Some servers process requests sequentially, others may have last-write-wins, or may merge updates. For safety, batch modifications into a single request when possible.

### Optimization Patterns

#### Conditional Request Execution

```javascript
async function fetchRequiredData(options) {
  const requests = [];
  
  if (options.includeUsers) {
    requests.push(
      fetch('/api/users').then(r => r.json()).then(data => ({ users: data }))
    );
  }
  
  if (options.includePosts) {
    requests.push(
      fetch('/api/posts').then(r => r.json()).then(data => ({ posts: data }))
    );
  }
  
  if (options.includeComments) {
    requests.push(
      fetch('/api/comments').then(r => r.json()).then(data => ({ comments: data }))
    );
  }
  
  const results = await Promise.all(requests);
  return Object.assign({}, ...results);
}

const data = await fetchRequiredData({ 
  includeUsers: true, 
  includePosts: true 
});
// Only fetches users and posts, skips comments
```

Dynamically constructs the request array based on requirements, avoiding unnecessary network calls.

#### Request Deduplication

```javascript
const requestCache = new Map();

function fetchWithCache(url) {
  if (requestCache.has(url)) {
    return requestCache.get(url);
  }
  
  const promise = fetch(url).then(r => r.json());
  requestCache.set(url, promise);
  
  return promise;
}

// Multiple calls to the same URL reuse the same promise
const [data1, data2, data3] = await Promise.all([
  fetchWithCache('/api/users'),
  fetchWithCache('/api/users'), // Reuses first request
  fetchWithCache('/api/posts')
]);
```

Prevents duplicate requests when the same URL appears multiple times. [Inference] Cache should be cleared or expire based on data freshness requirements.

#### Priority-Based Execution

```javascript
async function fetchWithPriority() {
  // High-priority requests first
  const critical = await Promise.all([
    fetch('/api/critical-data').then(r => r.json()),
    fetch('/api/user-session').then(r => r.json())
  ]);
  
  // Render critical data immediately
  renderCritical(critical);
  
  // Low-priority requests in background
  Promise.all([
    fetch('/api/analytics').then(r => r.json()),
    fetch('/api/recommendations').then(r => r.json())
  ]).then(renderSecondary);
}
```

Staggers requests by priority, allowing critical content to display before less important data loads.

### Advanced Patterns

#### Recursive Promise.all()

```javascript
async function fetchNestedData(ids, depth = 0, maxDepth = 3) {
  if (depth >= maxDepth || ids.length === 0) return [];
  
  const items = await Promise.all(
    ids.map(id => fetch(`/api/items/${id}`).then(r => r.json()))
  );
  
  // Each item contains child IDs
  const allChildIds = items.flatMap(item => item.childIds || []);
  
  const children = await fetchNestedData(allChildIds, depth + 1, maxDepth);
  
  return [...items, ...children];
}
```

Recursively fetches nested data structures with parallelism at each level.

#### Promise.all() with Generators

```javascript
async function* requestGenerator(urls) {
  for (const url of urls) {
    yield fetch(url).then(r => r.json());
  }
}

async function processInParallel(urls, parallelism = 5) {
  const gen = requestGenerator(urls);
  const results = [];
  
  while (true) {
    const batch = [];
    for (let i = 0; i < parallelism; i++) {
      const { value, done } = gen.next();
      if (done) break;
      batch.push(value);
    }
    
    if (batch.length === 0) break;
    
    const batchResults = await Promise.all(batch);
    results.push(...batchResults);
  }
  
  return results;
}
```

Controls parallelism while processing large request lists.

#### Combining with Promise.race()

```javascript
async function fetchWithFallback(primaryUrl, fallbackUrl) {
  const primary = fetch(primaryUrl).then(r => r.json());
  
  // If primary takes >1s, also try fallback
  const fallback = new Promise(resolve => {
    setTimeout(() => {
      fetch(fallbackUrl)
        .then(r => r.json())
        .then(resolve);
    }, 1000);
  });
  
  // Return whichever completes first
  return Promise.race([primary, fallback]);
}

const data = await Promise.all([
  fetchWithFallback('/api/data', '/api/data-backup'),
  fetch('/api/other').then(r => r.json())
]);
```

Combines racing and parallel patterns for resilience.

#### Throttled Parallel Execution

```javascript
async function throttledPromiseAll(tasks, limit = 5) {
  const results = [];
  const executing = [];
  
  for (const task of tasks) {
    const promise = Promise.resolve().then(task);
    results.push(promise);
    
    if (limit <= tasks.length) {
      const executing = promise.then(() => 
        executing.splice(executing.indexOf(executing), 1)
      );
      executing.push(executing);
      
      if (executing.length >= limit) {
        await Promise.race(executing);
      }
    }
  }
  
  return Promise.all(results);
}

// Usage: Limit to 5 concurrent requests
await throttledPromiseAll(
  urls.map(url => () => fetch(url).then(r => r.json())),
  5
);
```

[Inference] Implementation complexity suggests using established libraries (e.g., p-limit) for production use.

### Testing and Debugging

#### Mock Parallel Requests

```javascript
// Jest test example
test('fetches dashboard data in parallel', async () => {
  global.fetch = jest.fn()
    .mockResolvedValueOnce({ json: () => Promise.resolve({ users: [] }) })
    .mockResolvedValueOnce({ json: () => Promise.resolve({ posts: [] }) });
  
  const data = await fetchDashboardData();
  
  expect(fetch).toHaveBeenCalledTimes(2);
  expect(fetch).toHaveBeenCalledWith('/api/users');
  expect(fetch).toHaveBeenCalledWith('/api/posts');
});
```

Verify parallel execution by checking all fetch calls occur before any resolve.

#### Timing Analysis

```javascript
async function measureParallelRequests() {
  const start = performance.now();
  
  await Promise.all([
    fetch('/api/endpoint1').then(r => r.json()),
    fetch('/api/endpoint2').then(r => r.json()),
    fetch('/api/endpoint3').then(r => r.json())
  ]);
  
  const duration = performance.now() - start;
  console.log(`Parallel requests completed in ${duration}ms`);
}
```

Compare duration to sequential execution to verify parallelism benefits.

#### Network Waterfall Inspection

Browser DevTools Network tab shows request timing:

- Parallel requests appear starting at approximately the same time
- Sequential requests show staggered start times
- Connection establishment, waiting, and download phases visible

Look for:

- Requests queued due to connection limits (grey bar in Chrome)
- DNS/SSL overhead affecting first request
- Stalled requests indicating server-side bottlenecks

### Common Pitfalls

#### Mixing Await Inside Array

```javascript
// Anti-pattern: Sequential execution disguised as parallel
const results = await Promise.all([
  await fetch('/api/users').then(r => r.json()), // Wait here
  await fetch('/api/posts').then(r => r.json())  // Then wait here
]);
```

Using `await` inside the array defeats parallelism. Remove `await` from individual promises:

```javascript
// Correct: Parallel execution
const results = await Promise.all([
  fetch('/api/users').then(r => r.json()),
  fetch('/api/posts').then(r => r.json())
]);
```

#### Ignoring Empty Arrays

```javascript
const results = await Promise.all([]); // Returns []
```

Empty input resolves immediately with an empty array. Validate input length if expecting results.

#### Unhandled Rejections in Long Chains

```javascript
await Promise.all([
  fetch('/api/data')
    .then(r => r.json())
    .then(processData)
    .then(validateData) // If this throws, Promise.all() rejects
    .then(saveData)
]);
```

Errors in any step of the promise chain cause rejection. Add `.catch()` to handle errors at appropriate points in the chain.

#### Response Object Reuse

```javascript
// Anti-pattern: Response body can only be read once
const responses = await Promise.all([
  fetch('/api/data1'),
  fetch('/api/data2')
]);

const json1 = await responses[0].json();
const json2 = await responses[0].json(); // Throws: body already read
```

Response bodies are streams that can only be consumed once. Clone if needed multiple times:

```javascript
const response = await fetch('/api/data');
const clone = response.clone();

const json = await response.json();
const text = await clone.text();
```

### Framework Integration

#### React with useEffect

```javascript
function Dashboard() {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    const controller = new AbortController();
    
    Promise.all([
      fetch('/api/users', { signal: controller.signal }).then(r => r.json()),
      fetch('/api/posts', { signal: controller.signal }).then(r => r.json())
    ])
      .then(([users, posts]) => {
        setData({ users, posts });
        setLoading(false);
      })
      .catch(err => {
        if (err.name !== 'AbortError') {
          setError(err);
          setLoading(false);
        }
      });
    
    return () => controller.abort();
  }, []);
  
  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error.message}</div>;
  return <div>{/* Render data */}</div>;
}
```

#### Next.js Server Components

```javascript
// Server Component (async by default)
async function Page() {
  const [users, posts, comments] = await Promise.all([
    fetch('https://api.example.com/users').then(r => r.json()),
    fetch('https://api.example.com/posts').then(r => r.json()),
    fetch('https://api.example.com/comments').then(r => r.json())
  ]);
  
  return (
    <div>
      <UserList users={users} />
      <PostList posts={posts} />
      <CommentList comments={comments} />
    </div>
  );
}
```

Server components execute on the server; parallel fetches complete before rendering.

#### Vue Composition API

```javascript
import { ref, onMounted } from 'vue';

export default {
  setup() {
    const data = ref(null);
    const loading = ref(true);
    
    onMounted(async () => {
      const [users, posts] = await Promise.all([
        fetch('/api/users').then(r => r.json()),
        fetch('/api/posts').then(r => r.json())
      ]);
      
      data.value = { users, posts };
      loading.value = false;
    });
    
    return { data, loading };
  }
};
```

### Performance Monitoring

#### Resource Timing API

```javascript
async function trackParallelRequests() {
  const mark = `parallel-requests-${Date.now()}`;
  performance.mark(`${mark}-start`);
  
  await Promise.all([
    fetch('/api/users').then(r => r.json()),
    fetch('/api/posts').then(r => r.json())
  ]);
  
  performance.mark(`${mark}-end`);
  performance.measure(mark, `${mark}-start`, `${mark}-end`);
  
  const measure = performance.getEntriesByName(mark)[0];
  console.log(`Parallel requests took ${measure.duration}ms`);
}
```

#### Custom Metrics

```javascript
async function fetchWithMetrics(url) {
  const start = performance.now();
  
  try {
    const response = await fetch(url);
    const data = await response.json();
    
    const duration = performance.now() - start;
    
    analytics.track('fetch_success', {
      url,
      duration,
      status: response.status,
      size: JSON.stringify(data).length
    });
    
    return data;
  } catch (error) {
    const duration = performance.now() - start;
    
    analytics.track('fetch_failure', {
      url,
      duration,
      error: error.message
    });
    
    throw error;
  }
}

await Promise.all([
  fetchWithMetrics('/api/users'),
  fetchWithMetrics('/api/posts')
]);
```

Tracks individual request metrics while executing in parallel.

---

## Sequential Requests with Fetch API

### Basic Sequential Execution

Sequential requests execute one after another, where each request waits for the previous one to complete before starting.

```javascript
async function executeSequentially(urls) {
  const results = [];
  
  for (const url of urls) {
    const response = await fetch(url);
    const data = await response.json();
    results.push(data);
  }
  
  return results;
}

// Usage
const urls = [
  '/api/step1',
  '/api/step2',
  '/api/step3'
];

const results = await executeSequentially(urls);
```

### Sequential with Error Handling

```javascript
async function sequentialWithErrorHandling(urls) {
  const results = [];
  const errors = [];
  
  for (let i = 0; i < urls.length; i++) {
    try {
      const response = await fetch(urls[i]);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const data = await response.json();
      results.push({ index: i, url: urls[i], data, success: true });
    } catch (error) {
      errors.push({ index: i, url: urls[i], error: error.message });
      results.push({ index: i, url: urls[i], success: false, error: error.message });
    }
  }
  
  return { results, errors };
}
```

### Sequential with Stop-on-Error

```javascript
async function sequentialStopOnError(urls) {
  const results = [];
  
  for (const url of urls) {
    const response = await fetch(url);
    
    if (!response.ok) {
      throw new Error(`Request to ${url} failed with status ${response.status}`);
    }
    
    const data = await response.json();
    results.push(data);
  }
  
  return results;
}

// Usage
try {
  const results = await sequentialStopOnError(urls);
  console.log('All requests succeeded:', results);
} catch (error) {
  console.error('Stopped due to error:', error.message);
}
```

### Dependent Sequential Requests

Each request depends on data from the previous request.

```javascript
async function dependentSequentialRequests(userId) {
  // Step 1: Get user
  const userResponse = await fetch(`/api/users/${userId}`);
  const user = await userResponse.json();
  
  // Step 2: Get user's posts (depends on user data)
  const postsResponse = await fetch(`/api/posts?userId=${user.id}`);
  const posts = await postsResponse.json();
  
  // Step 3: Get comments for first post (depends on posts data)
  if (posts.length > 0) {
    const commentsResponse = await fetch(`/api/comments?postId=${posts[0].id}`);
    const comments = await commentsResponse.json();
    
    return { user, posts, comments };
  }
  
  return { user, posts, comments: [] };
}

// Usage
const data = await dependentSequentialRequests(123);
```

### Sequential with Dynamic URL Generation

```javascript
async function sequentialWithDynamicURLs(initialUrl, maxDepth = 5) {
  const results = [];
  let currentUrl = initialUrl;
  let depth = 0;
  
  while (currentUrl && depth < maxDepth) {
    const response = await fetch(currentUrl);
    const data = await response.json();
    
    results.push(data);
    
    // Get next URL from response (pagination, etc.)
    currentUrl = data.nextUrl || data.links?.next || null;
    depth++;
  }
  
  return results;
}

// Usage - handle pagination
const allPages = await sequentialWithDynamicURLs('/api/items?page=1');
```

### Sequential Pipeline with Transformations

```javascript
class RequestPipeline {
  constructor() {
    this.steps = [];
  }
  
  addStep(url, options, transform) {
    this.steps.push({ url, options, transform });
    return this;
  }
  
  async execute(initialData = {}) {
    let context = { ...initialData };
    const results = [];
    
    for (const step of this.steps) {
      // Resolve URL with context data
      const url = typeof step.url === 'function' 
        ? step.url(context) 
        : step.url;
      
      // Resolve options with context data
      const options = typeof step.options === 'function'
        ? step.options(context)
        : step.options || {};
      
      // Execute request
      const response = await fetch(url, options);
      const data = await response.json();
      
      // Transform data
      const transformed = step.transform 
        ? await step.transform(data, context) 
        : data;
      
      results.push(transformed);
      
      // Update context for next step
      context = { ...context, ...transformed };
    }
    
    return { results, context };
  }
}

// Usage
const pipeline = new RequestPipeline();

pipeline
  .addStep(
    '/api/authenticate',
    { method: 'POST', body: JSON.stringify({ username: 'user', password: 'pass' }) },
    (data) => ({ token: data.token })
  )
  .addStep(
    (context) => `/api/user/profile`,
    (context) => ({
      headers: { 'Authorization': `Bearer ${context.token}` }
    }),
    (data, context) => ({ profile: data, token: context.token })
  )
  .addStep(
    (context) => `/api/user/${context.profile.id}/settings`,
    (context) => ({
      headers: { 'Authorization': `Bearer ${context.token}` }
    }),
    (data) => ({ settings: data })
  );

const { results, context } = await pipeline.execute();
```

### Sequential with Rate Limiting

```javascript
async function sequentialWithRateLimit(urls, delayMs = 1000) {
  const results = [];
  
  for (let i = 0; i < urls.length; i++) {
    const response = await fetch(urls[i]);
    const data = await response.json();
    results.push(data);
    
    // Wait before next request (except after last one)
    if (i < urls.length - 1) {
      await new Promise(resolve => setTimeout(resolve, delayMs));
    }
  }
  
  return results;
}

// Usage
const results = await sequentialWithRateLimit(urls, 2000); // 2 second delay between requests
```

### Sequential with Progress Tracking

```javascript
async function sequentialWithProgress(urls, onProgress) {
  const results = [];
  const total = urls.length;
  
  for (let i = 0; i < urls.length; i++) {
    const url = urls[i];
    
    // Notify progress before request
    if (onProgress) {
      onProgress({
        current: i + 1,
        total,
        percentage: ((i + 1) / total) * 100,
        currentUrl: url,
        stage: 'requesting'
      });
    }
    
    try {
      const response = await fetch(url);
      const data = await response.json();
      
      results.push({
        url,
        success: true,
        data
      });
      
      // Notify progress after successful request
      if (onProgress) {
        onProgress({
          current: i + 1,
          total,
          percentage: ((i + 1) / total) * 100,
          currentUrl: url,
          stage: 'completed'
        });
      }
    } catch (error) {
      results.push({
        url,
        success: false,
        error: error.message
      });
      
      // Notify progress after failed request
      if (onProgress) {
        onProgress({
          current: i + 1,
          total,
          percentage: ((i + 1) / total) * 100,
          currentUrl: url,
          stage: 'failed',
          error: error.message
        });
      }
    }
  }
  
  return results;
}

// Usage
const results = await sequentialWithProgress(urls, (progress) => {
  console.log(`${progress.percentage.toFixed(2)}% - ${progress.stage} - ${progress.currentUrl}`);
  // Update UI progress bar
  document.getElementById('progress').style.width = `${progress.percentage}%`;
});
```

### Sequential with Retry Logic

```javascript
async function sequentialWithRetry(urls, maxRetries = 3, retryDelay = 1000) {
  const results = [];
  
  for (const url of urls) {
    let lastError;
    let attempt = 0;
    
    while (attempt < maxRetries) {
      try {
        const response = await fetch(url);
        
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }
        
        const data = await response.json();
        results.push({ url, success: true, data, attempts: attempt + 1 });
        break; // Success, exit retry loop
      } catch (error) {
        lastError = error;
        attempt++;
        
        if (attempt < maxRetries) {
          // Exponential backoff
          const delay = retryDelay * Math.pow(2, attempt - 1);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }
    
    // All retries failed
    if (attempt === maxRetries) {
      results.push({
        url,
        success: false,
        error: lastError.message,
        attempts: maxRetries
      });
    }
  }
  
  return results;
}

// Usage
const results = await sequentialWithRetry(urls, 3, 1000);
```

### Sequential Batch Processing

```javascript
async function sequentialBatchProcessor(items, batchSize, processor) {
  const results = [];
  
  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, i + batchSize);
    
    console.log(`Processing batch ${Math.floor(i / batchSize) + 1} of ${Math.ceil(items.length / batchSize)}`);
    
    // Process batch sequentially
    for (const item of batch) {
      const result = await processor(item);
      results.push(result);
    }
    
    // Optional: delay between batches
    if (i + batchSize < items.length) {
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }
  
  return results;
}

// Usage
const items = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

const results = await sequentialBatchProcessor(items, 3, async (item) => {
  const response = await fetch(`/api/process/${item}`);
  return response.json();
});
```

### Sequential with Conditional Execution

```javascript
async function sequentialConditional(requests) {
  const results = [];
  
  for (const request of requests) {
    const { url, options, condition, skipOnError } = request;
    
    // Check condition before executing
    if (condition && !condition(results)) {
      console.log(`Skipping ${url} due to condition`);
      continue;
    }
    
    try {
      const response = await fetch(url, options);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const data = await response.json();
      results.push({ url, success: true, data });
    } catch (error) {
      if (skipOnError) {
        console.log(`Skipping error for ${url}`);
        results.push({ url, success: false, error: error.message });
        continue;
      }
      
      throw error; // Stop execution
    }
  }
  
  return results;
}

// Usage
const requests = [
  {
    url: '/api/step1',
    options: { method: 'GET' }
  },
  {
    url: '/api/step2',
    options: { method: 'POST' },
    condition: (results) => results[0]?.success && results[0]?.data?.canProceed,
    skipOnError: true
  },
  {
    url: '/api/step3',
    options: { method: 'GET' },
    condition: (results) => results.length >= 2
  }
];

const results = await sequentialConditional(requests);
```

### Sequential State Machine

```javascript
class SequentialStateMachine {
  constructor() {
    this.states = new Map();
    this.currentState = null;
    this.context = {};
  }
  
  addState(name, handler, transitions = {}) {
    this.states.set(name, { handler, transitions });
    
    if (!this.currentState) {
      this.currentState = name;
    }
    
    return this;
  }
  
  async execute() {
    const results = [];
    const visited = new Set();
    
    while (this.currentState) {
      // Prevent infinite loops
      if (visited.has(this.currentState)) {
        throw new Error(`Infinite loop detected at state: ${this.currentState}`);
      }
      visited.add(this.currentState);
      
      const state = this.states.get(this.currentState);
      if (!state) {
        throw new Error(`Unknown state: ${this.currentState}`);
      }
      
      console.log(`Executing state: ${this.currentState}`);
      
      try {
        // Execute state handler
        const result = await state.handler(this.context);
        results.push({ state: this.currentState, result });
        
        // Update context
        this.context = { ...this.context, ...result };
        
        // Determine next state
        let nextState = null;
        
        for (const [condition, targetState] of Object.entries(state.transitions)) {
          if (condition === 'default') {
            nextState = targetState;
          } else if (typeof condition === 'function' && condition(this.context)) {
            nextState = targetState;
            break;
          } else if (this.context[condition]) {
            nextState = targetState;
            break;
          }
        }
        
        this.currentState = nextState;
      } catch (error) {
        results.push({ state: this.currentState, error: error.message });
        
        // Check for error transition
        if (state.transitions.onError) {
          this.currentState = state.transitions.onError;
        } else {
          throw error;
        }
      }
    }
    
    return { results, context: this.context };
  }
}

// Usage
const machine = new SequentialStateMachine();

machine
  .addState('authenticate', async (context) => {
    const response = await fetch('/api/auth', {
      method: 'POST',
      body: JSON.stringify({ user: 'admin', pass: 'secret' })
    });
    const data = await response.json();
    return { token: data.token, authenticated: true };
  }, {
    authenticated: 'fetchProfile',
    onError: 'failed'
  })
  .addState('fetchProfile', async (context) => {
    const response = await fetch('/api/profile', {
      headers: { 'Authorization': `Bearer ${context.token}` }
    });
    const profile = await response.json();
    return { profile, hasPermission: profile.role === 'admin' };
  }, {
    hasPermission: 'fetchAdminData',
    default: 'fetchUserData'
  })
  .addState('fetchAdminData', async (context) => {
    const response = await fetch('/api/admin/data', {
      headers: { 'Authorization': `Bearer ${context.token}` }
    });
    return { adminData: await response.json() };
  }, {
    default: 'complete'
  })
  .addState('fetchUserData', async (context) => {
    const response = await fetch('/api/user/data', {
      headers: { 'Authorization': `Bearer ${context.token}` }
    });
    return { userData: await response.json() };
  }, {
    default: 'complete'
  })
  .addState('failed', async (context) => {
    console.error('Authentication failed');
    return { failed: true };
  }, {})
  .addState('complete', async (context) => {
    console.log('Process complete');
    return { completed: true };
  }, {});

const { results, context } = await machine.execute();
```

### Sequential with Timeout per Request

```javascript
async function sequentialWithTimeouts(requests, defaultTimeout = 5000) {
  const results = [];
  
  for (const request of requests) {
    const { url, options, timeout = defaultTimeout } = request;
    
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      const data = await response.json();
      results.push({ url, success: true, data });
    } catch (error) {
      const isTimeout = error.name === 'AbortError';
      results.push({
        url,
        success: false,
        error: isTimeout ? 'Request timeout' : error.message,
        timeout: isTimeout
      });
    }
  }
  
  return results;
}

// Usage
const requests = [
  { url: '/api/fast', options: {}, timeout: 2000 },
  { url: '/api/slow', options: {}, timeout: 10000 },
  { url: '/api/medium', options: {} } // uses default timeout
];

const results = await sequentialWithTimeouts(requests, 5000);
```

### Sequential Reduce Pattern

```javascript
async function sequentialReduce(urls, reducer, initialValue) {
  let accumulator = initialValue;
  
  for (let i = 0; i < urls.length; i++) {
    const url = urls[i];
    const response = await fetch(url);
    const data = await response.json();
    
    accumulator = await reducer(accumulator, data, i, urls);
  }
  
  return accumulator;
}

// Usage - aggregate data across requests
const total = await sequentialReduce(
  ['/api/sales/jan', '/api/sales/feb', '/api/sales/mar'],
  async (acc, data) => {
    return acc + data.total;
  },
  0
);

// Usage - build nested structure
const nested = await sequentialReduce(
  ['/api/user/1', '/api/user/2', '/api/user/3'],
  async (acc, user) => {
    const postsResponse = await fetch(`/api/posts?userId=${user.id}`);
    const posts = await postsResponse.json();
    
    return {
      ...acc,
      [user.id]: { ...user, posts }
    };
  },
  {}
);
```

### Sequential with Checkpoints

```javascript
class SequentialWithCheckpoints {
  constructor() {
    this.checkpoints = new Map();
  }
  
  async execute(requests, options = {}) {
    const { saveCheckpoint = true, resumeFromCheckpoint = true } = options;
    const results = [];
    let startIndex = 0;
    
    // Try to resume from last checkpoint
    if (resumeFromCheckpoint) {
      const lastCheckpoint = this.getLastCheckpoint();
      if (lastCheckpoint) {
        startIndex = lastCheckpoint.index + 1;
        results.push(...lastCheckpoint.results);
        console.log(`Resuming from checkpoint at index ${startIndex}`);
      }
    }
    
    for (let i = startIndex; i < requests.length; i++) {
      const { url, options } = requests[i];
      
      try {
        const response = await fetch(url, options);
        const data = await response.json();
        
        results.push({ url, success: true, data });
        
        // Save checkpoint
        if (saveCheckpoint) {
          this.saveCheckpoint(i, results);
        }
      } catch (error) {
        results.push({ url, success: false, error: error.message });
        
        // Save checkpoint even on error
        if (saveCheckpoint) {
          this.saveCheckpoint(i, results);
        }
        
        throw error;
      }
    }
    
    // Clear checkpoints on successful completion
    if (saveCheckpoint) {
      this.clearCheckpoints();
    }
    
    return results;
  }
  
  saveCheckpoint(index, results) {
    const checkpoint = {
      index,
      results: [...results],
      timestamp: Date.now()
    };
    
    this.checkpoints.set(index, checkpoint);
    
    // Persist to localStorage for recovery across page reloads
    try {
      localStorage.setItem(
        'sequential_checkpoint',
        JSON.stringify(checkpoint)
      );
    } catch (e) {
      console.warn('Failed to persist checkpoint:', e);
    }
  }
  
  getLastCheckpoint() {
    try {
      const stored = localStorage.getItem('sequential_checkpoint');
      return stored ? JSON.parse(stored) : null;
    } catch (e) {
      return null;
    }
  }
  
  clearCheckpoints() {
    this.checkpoints.clear();
    localStorage.removeItem('sequential_checkpoint');
  }
}

// Usage
const sequential = new SequentialWithCheckpoints();

try {
  const results = await sequential.execute(requests, {
    saveCheckpoint: true,
    resumeFromCheckpoint: true
  });
} catch (error) {
  console.error('Process failed, checkpoint saved. Can resume later.');
}
```

---

## Request Chaining with Fetch API

### Sequential Request Patterns

#### Basic Promise Chaining

```javascript
fetch('/api/user/123')
  .then(response => response.json())
  .then(user => {
    console.log('User fetched:', user);
    return fetch(`/api/posts?userId=${user.id}`);
  })
  .then(response => response.json())
  .then(posts => {
    console.log('Posts fetched:', posts);
    return fetch(`/api/comments?postId=${posts[0].id}`);
  })
  .then(response => response.json())
  .then(comments => {
    console.log('Comments fetched:', comments);
  })
  .catch(error => {
    console.error('Chain failed:', error);
  });
```

#### Async/Await Sequential Requests

```javascript
async function fetchUserData(userId) {
  try {
    const userResponse = await fetch(`/api/user/${userId}`);
    const user = await userResponse.json();
    
    const postsResponse = await fetch(`/api/posts?userId=${user.id}`);
    const posts = await postsResponse.json();
    
    const commentsResponse = await fetch(`/api/comments?postId=${posts[0].id}`);
    const comments = await commentsResponse.json();
    
    return { user, posts, comments };
  } catch (error) {
    console.error('Failed to fetch user data:', error);
    throw error;
  }
}
```

### Dependent Request Chains

#### Data Transformation Pipeline

```javascript
async function processDataPipeline(initialId) {
  const step1 = await fetch(`/api/data/${initialId}`)
    .then(res => res.json());
  
  const step2 = await fetch('/api/transform', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(step1)
  }).then(res => res.json());
  
  const step3 = await fetch('/api/enrich', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(step2)
  }).then(res => res.json());
  
  const final = await fetch('/api/finalize', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(step3)
  }).then(res => res.json());
  
  return final;
}
```

#### Conditional Chaining

```javascript
async function conditionalFetch(userId) {
  const user = await fetch(`/api/user/${userId}`).then(r => r.json());
  
  if (user.isPremium) {
    const premiumData = await fetch(`/api/premium/${userId}`)
      .then(r => r.json());
    user.premiumFeatures = premiumData;
  }
  
  if (user.hasNotifications) {
    const notifications = await fetch(`/api/notifications/${userId}`)
      .then(r => r.json());
    user.notifications = notifications;
  }
  
  return user;
}
```

#### Nested Resource Loading

```javascript
async function fetchNestedResources(organizationId) {
  const org = await fetch(`/api/organizations/${organizationId}`)
    .then(r => r.json());
  
  const departments = await fetch(`/api/departments?orgId=${org.id}`)
    .then(r => r.json());
  
  const departmentsWithEmployees = await Promise.all(
    departments.map(async dept => {
      const employees = await fetch(`/api/employees?deptId=${dept.id}`)
        .then(r => r.json());
      
      return { ...dept, employees };
    })
  );
  
  return {
    ...org,
    departments: departmentsWithEmployees
  };
}
```

### Parallel Request Execution

#### Promise.all for Independent Requests

```javascript
async function fetchParallelData(userId) {
  const [user, posts, notifications, settings] = await Promise.all([
    fetch(`/api/user/${userId}`).then(r => r.json()),
    fetch(`/api/posts?userId=${userId}`).then(r => r.json()),
    fetch(`/api/notifications/${userId}`).then(r => r.json()),
    fetch(`/api/settings/${userId}`).then(r => r.json())
  ]);
  
  return { user, posts, notifications, settings };
}
```

#### Promise.allSettled for Fault Tolerance

```javascript
async function fetchWithFallback(userId) {
  const results = await Promise.allSettled([
    fetch(`/api/user/${userId}`).then(r => r.json()),
    fetch(`/api/posts?userId=${userId}`).then(r => r.json()),
    fetch(`/api/activity/${userId}`).then(r => r.json()),
    fetch(`/api/recommendations/${userId}`).then(r => r.json())
  ]);
  
  return {
    user: results[0].status === 'fulfilled' ? results[0].value : null,
    posts: results[1].status === 'fulfilled' ? results[1].value : [],
    activity: results[2].status === 'fulfilled' ? results[2].value : [],
    recommendations: results[3].status === 'fulfilled' ? results[3].value : []
  };
}
```

#### Promise.race for Fastest Response

```javascript
async function fetchFromMultipleSources(endpoint) {
  const sources = [
    'https://api1.example.com',
    'https://api2.example.com',
    'https://api3.example.com'
  ];
  
  const response = await Promise.race(
    sources.map(baseUrl => 
      fetch(`${baseUrl}${endpoint}`).then(r => r.json())
    )
  );
  
  return response;
}
```

### Chain Builder Pattern

#### Fluent Request API

```javascript
class RequestChain {
  constructor(baseUrl = '') {
    this.baseUrl = baseUrl;
    this.requests = [];
    this.results = [];
  }
  
  get(url, options = {}) {
    this.requests.push({
      method: 'GET',
      url,
      options
    });
    return this;
  }
  
  post(url, data, options = {}) {
    this.requests.push({
      method: 'POST',
      url,
      data,
      options
    });
    return this;
  }
  
  then(callback) {
    this.requests.push({
      type: 'transform',
      callback
    });
    return this;
  }
  
  async execute() {
    let previousResult = null;
    
    for (const request of this.requests) {
      if (request.type === 'transform') {
        previousResult = await request.callback(previousResult);
        this.results.push(previousResult);
      } else {
        const url = this.baseUrl + request.url;
        const options = {
          ...request.options,
          method: request.method
        };
        
        if (request.data) {
          options.body = JSON.stringify(request.data);
          options.headers = {
            'Content-Type': 'application/json',
            ...options.headers
          };
        }
        
        const response = await fetch(url, options);
        
        if (!response.ok) {
          throw new Error(`Request failed: ${response.status}`);
        }
        
        previousResult = await response.json();
        this.results.push(previousResult);
      }
    }
    
    return previousResult;
  }
  
  getResults() {
    return this.results;
  }
}

// Usage
const result = await new RequestChain('https://api.example.com')
  .get('/user/123')
  .then(user => ({ userId: user.id, name: user.name }))
  .get('/posts?userId=${user.id}')
  .then(posts => posts.filter(p => p.published))
  .execute();
```

#### Template String URL Builder

```javascript
class ChainedFetch {
  constructor(baseUrl = '') {
    this.baseUrl = baseUrl;
    this.context = {};
  }
  
  async fetch(url, options = {}) {
    const interpolatedUrl = this.interpolate(url);
    const fullUrl = this.baseUrl + interpolatedUrl;
    
    const response = await fetch(fullUrl, options);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }
    
    const data = await response.json();
    this.context = { ...this.context, ...data };
    
    return this;
  }
  
  interpolate(template) {
    return template.replace(/\${(\w+)}/g, (match, key) => {
      return this.context[key] || match;
    });
  }
  
  async get(url, options = {}) {
    return this.fetch(url, { ...options, method: 'GET' });
  }
  
  async post(url, data, options = {}) {
    return this.fetch(url, {
      ...options,
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      },
      body: JSON.stringify(data)
    });
  }
  
  getContext() {
    return this.context;
  }
}

// Usage
const chain = new ChainedFetch('https://api.example.com');

await chain
  .get('/user/123')
  .get('/posts?userId=${id}')  // Uses id from previous response
  .get('/comments?postId=${posts[0].id}');  // Uses posts from previous response

const data = chain.getContext();
```

### Pagination Chains

#### Cursor-Based Pagination

```javascript
async function fetchAllPages(initialUrl) {
  const allData = [];
  let nextUrl = initialUrl;
  
  while (nextUrl) {
    const response = await fetch(nextUrl);
    const data = await response.json();
    
    allData.push(...data.items);
    nextUrl = data.nextPageUrl;
  }
  
  return allData;
}
```

#### Page Number Pagination

```javascript
async function fetchPaginatedData(baseUrl, maxPages = Infinity) {
  const allItems = [];
  let page = 1;
  let hasMore = true;
  
  while (hasMore && page <= maxPages) {
    const response = await fetch(`${baseUrl}?page=${page}&limit=50`);
    const data = await response.json();
    
    allItems.push(...data.items);
    
    hasMore = data.hasMore || data.items.length === 50;
    page++;
  }
  
  return allItems;
}
```

#### Async Iterator for Pagination

```javascript
async function* paginatedFetch(url, options = {}) {
  const { pageSize = 50, maxPages = Infinity } = options;
  let page = 1;
  
  while (page <= maxPages) {
    const response = await fetch(`${url}?page=${page}&limit=${pageSize}`);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    const data = await response.json();
    
    if (data.items.length === 0) {
      break;
    }
    
    yield data.items;
    
    if (data.items.length < pageSize) {
      break;
    }
    
    page++;
  }
}

// Usage
for await (const items of paginatedFetch('/api/products')) {
  console.log(`Processing ${items.length} items`);
  items.forEach(item => processItem(item));
}
```

#### Lazy Loading Chain

```javascript
class LazyLoadChain {
  constructor(url, pageSize = 20) {
    this.url = url;
    this.pageSize = pageSize;
    this.currentPage = 0;
    this.cache = [];
    this.hasMore = true;
  }
  
  async loadNext() {
    if (!this.hasMore) {
      return null;
    }
    
    this.currentPage++;
    
    const response = await fetch(
      `${this.url}?page=${this.currentPage}&limit=${this.pageSize}`
    );
    
    const data = await response.json();
    
    this.cache.push(...data.items);
    this.hasMore = data.items.length === this.pageSize;
    
    return data.items;
  }
  
  async loadAll() {
    while (this.hasMore) {
      await this.loadNext();
    }
    return this.cache;
  }
  
  getLoaded() {
    return this.cache;
  }
}

// Usage
const loader = new LazyLoadChain('/api/items', 50);
await loader.loadNext(); // Load first page
console.log(loader.getLoaded()); // Get loaded items
```

### Batch Request Processing

#### Batched Fetch with Window

```javascript
async function batchFetchWithWindow(ids, batchSize = 10) {
  const results = [];
  
  for (let i = 0; i < ids.length; i += batchSize) {
    const batch = ids.slice(i, i + batchSize);
    
    const batchResults = await Promise.all(
      batch.map(id => 
        fetch(`/api/item/${id}`).then(r => r.json())
      )
    );
    
    results.push(...batchResults);
  }
  
  return results;
}
```

#### Batch API Request

```javascript
async function fetchBatchAPI(ids) {
  const response = await fetch('/api/batch', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      requests: ids.map(id => ({
        method: 'GET',
        url: `/api/item/${id}`
      }))
    })
  });
  
  const batchResponse = await response.json();
  return batchResponse.responses;
}
```

#### Controlled Concurrency Batch

```javascript
async function batchWithConcurrency(items, fetchFn, concurrency = 5) {
  const results = [];
  const executing = [];
  
  for (const item of items) {
    const promise = fetchFn(item).then(result => {
      executing.splice(executing.indexOf(promise), 1);
      return result;
    });
    
    results.push(promise);
    executing.push(promise);
    
    if (executing.length >= concurrency) {
      await Promise.race(executing);
    }
  }
  
  return Promise.all(results);
}

// Usage
const userIds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

const users = await batchWithConcurrency(
  userIds,
  async (id) => {
    const response = await fetch(`/api/user/${id}`);
    return response.json();
  },
  3 // Maximum 3 concurrent requests
);
```

### Waterfall Pattern

#### Sequential Data Enrichment

```javascript
async function enrichDataWaterfall(initialData) {
  let data = initialData;
  
  // Step 1: Fetch user details
  const userResponse = await fetch(`/api/user/${data.userId}`);
  data.user = await userResponse.json();
  
  // Step 2: Fetch user's organization
  const orgResponse = await fetch(`/api/organization/${data.user.orgId}`);
  data.organization = await orgResponse.json();
  
  // Step 3: Fetch organization's settings
  const settingsResponse = await fetch(`/api/settings/${data.organization.id}`);
  data.settings = await settingsResponse.json();
  
  // Step 4: Apply permissions based on settings
  const permissionsResponse = await fetch('/api/permissions', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      userId: data.user.id,
      orgId: data.organization.id,
      settingsId: data.settings.id
    })
  });
  data.permissions = await permissionsResponse.json();
  
  return data;
}
```

#### Reduce-Style Chain

```javascript
async function chainedReduce(initialValue, operations) {
  return operations.reduce(async (accPromise, operation) => {
    const acc = await accPromise;
    
    const response = await fetch(operation.url, {
      method: operation.method || 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(acc)
    });
    
    return response.json();
  }, Promise.resolve(initialValue));
}

// Usage
const result = await chainedReduce(
  { userId: 123 },
  [
    { url: '/api/validate', method: 'POST' },
    { url: '/api/enrich', method: 'POST' },
    { url: '/api/transform', method: 'POST' },
    { url: '/api/save', method: 'POST' }
  ]
);
```

### Request Queue System

#### FIFO Queue with Chain

```javascript
class RequestQueue {
  constructor(concurrency = 1) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async add(fn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ fn, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.active >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { fn, resolve, reject } = this.queue.shift();
    
    try {
      const result = await fn();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }
  
  async chain(requests) {
    const results = [];
    
    for (const request of requests) {
      const result = await this.add(request);
      results.push(result);
    }
    
    return results;
  }
}

// Usage
const queue = new RequestQueue(3);

const results = await queue.chain([
  () => fetch('/api/user/1').then(r => r.json()),
  () => fetch('/api/user/2').then(r => r.json()),
  () => fetch('/api/user/3').then(r => r.json()),
  () => fetch('/api/user/4').then(r => r.json()),
  () => fetch('/api/user/5').then(r => r.json())
]);
```

#### Priority Queue

```javascript
class PriorityRequestQueue {
  constructor(concurrency = 2) {
    this.concurrency = concurrency;
    this.queue = [];
    this.active = 0;
  }
  
  async add(fn, priority = 0) {
    return new Promise((resolve, reject) => {
      const item = { fn, priority, resolve, reject };
      
      // Insert based on priority (higher priority first)
      const insertIndex = this.queue.findIndex(q => q.priority < priority);
      
      if (insertIndex === -1) {
        this.queue.push(item);
      } else {
        this.queue.splice(insertIndex, 0, item);
      }
      
      this.process();
    });
  }
  
  async process() {
    if (this.active >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.active++;
    const { fn, resolve, reject } = this.queue.shift();
    
    try {
      const result = await fn();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.active--;
      this.process();
    }
  }
}

// Usage
const queue = new PriorityRequestQueue(2);

// High priority user data
queue.add(() => fetch('/api/user/current').then(r => r.json()), 10);

// Normal priority
queue.add(() => fetch('/api/posts').then(r => r.json()), 5);

// Low priority analytics
queue.add(() => fetch('/api/analytics').then(r => r.json()), 1);
```

### Dependent Chain with State

#### Stateful Request Chain

```javascript
class StatefulChain {
  constructor() {
    this.state = {};
    this.history = [];
  }
  
  async fetch(url, options = {}) {
    const startTime = Date.now();
    
    const response = await fetch(url, options);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }
    
    const data = await response.json();
    
    this.history.push({
      url,
      options,
      status: response.status,
      duration: Date.now() - startTime,
      timestamp: new Date().toISOString()
    });
    
    this.state = { ...this.state, ...data };
    
    return data;
  }
  
  async fetchIf(condition, url, options) {
    if (condition(this.state)) {
      return this.fetch(url, options);
    }
    return null;
  }
  
  async fetchWith(urlBuilder, options) {
    const url = urlBuilder(this.state);
    return this.fetch(url, options);
  }
  
  getState() {
    return this.state;
  }
  
  getHistory() {
    return this.history;
  }
  
  reset() {
    this.state = {};
    this.history = [];
  }
}

// Usage
const chain = new StatefulChain();

await chain.fetch('/api/user/123');

await chain.fetchIf(
  state => state.isPremium,
  '/api/premium/features'
);

await chain.fetchWith(
  state => `/api/posts?userId=${state.id}&premium=${state.isPremium}`
);

console.log(chain.getState());
console.log(chain.getHistory());
```

### Transaction-Style Chains

#### Rollback on Failure

```javascript
class TransactionalChain {
  constructor() {
    this.operations = [];
    this.completed = [];
  }
  
  add(operation) {
    this.operations.push(operation);
    return this;
  }
  
  async execute() {
    try {
      for (const op of this.operations) {
        const result = await op.execute();
        this.completed.push({ operation: op, result });
      }
      
      return this.completed.map(c => c.result);
      
    } catch (error) {
      console.error('Transaction failed, rolling back...', error);
      await this.rollback();
      throw error;
    }
  }
  
  async rollback() {
    for (const { operation, result } of this.completed.reverse()) {
      if (operation.rollback) {
        try {
          await operation.rollback(result);
        } catch (rollbackError) {
          console.error('Rollback failed:', rollbackError);
        }
      }
    }
    
    this.completed = [];
  }
}

// Usage
const transaction = new TransactionalChain();

transaction.add({
  execute: async () => {
    const response = await fetch('/api/user', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ name: 'John' })
    });
    return response.json();
  },
  rollback: async (result) => {
    await fetch(`/api/user/${result.id}`, { method: 'DELETE' });
  }
});

transaction.add({
  execute: async () => {
    const response = await fetch('/api/profile', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ userId: 'result from previous' })
    });
    return response.json();
  },
  rollback: async (result) => {
    await fetch(`/api/profile/${result.id}`, { method: 'DELETE' });
  }
});

try {
  const results = await transaction.execute();
} catch (error) {
  console.error('Transaction aborted');
}
```

### GraphQL-Style Chaining

#### Nested Resource Fetching

```javascript
async function fetchGraphLike(query) {
  const results = {};
  
  // Root query
  if (query.user) {
    const userResponse = await fetch(`/api/user/${query.user.id}`);
    results.user = await userResponse.json();
    
    // Nested queries
    if (query.user.posts) {
      const postsResponse = await fetch(`/api/posts?userId=${results.user.id}`);
      results.user.posts = await postsResponse.json();
      
      // Deep nested queries
      if (query.user.posts.comments) {
        results.user.posts = await Promise.all(
          results.user.posts.map(async post => {
            const commentsResponse = await fetch(`/api/comments?postId=${post.id}`);
            post.comments = await commentsResponse.json();
            return post;
          })
        );
      }
    }
    
    if (query.user.followers) {
      const followersResponse = await fetch(`/api/followers/${results.user.id}`);
      results.user.followers = await followersResponse.json();
    }
  }
  
  return results;
}

// Usage
const data = await fetchGraphLike({
  user: {
    id: 123,
    posts: {
      comments: true
    },
    followers: true
  }
});
```

#### Field Selection Chain

```javascript
class FieldSelector {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.fields = [];
    this.includes = [];
  }
  
  select(...fields) {
    this.fields.push(...fields);
    return this;
  }
  
  include(resource, fields = []) {
    this.includes.push({ resource, fields });
    return this;
  }
  
  async fetch() {
    const params = new URLSearchParams();
    
    if (this.fields.length > 0) {
      params.set('fields', this.fields.join(','));
    }
    
    if (this.includes.length > 0) {
      params.set('include', this.includes.map(i => i.resource).join(','));
    }
    
    const response = await fetch(`${this.baseUrl}?${params}`);
    let data = await response.json();
    
    // Fetch included resources
    for (const include of this.includes) {
      const includeResponse = await fetch(
        `/api/${include.resource}?parentId=${data.id}`
      );
      data[include.resource] = await includeResponse.json();
    }
    
    return data;
  }
}

// Usage
const user = await new FieldSelector('/api/user/123')
  .select('id', 'name', 'email')
  .include('posts', ['title', 'content'])
  .include('followers')
  .fetch();
```

### Debounced Chain Requests

#### Request Debouncing

```javascript
class DebouncedChain {
  constructor(delay = 300) {
    this.delay = delay;
    this.timeouts = new Map();
  }
  
  async fetch(key, url, options = {}) {
    return new Promise((resolve, reject) => {
      // Clear existing timeout for this key
      if (this.timeouts.has(key)) {
        clearTimeout(this.timeouts.get(key));
      }
      
      const timeoutId = setTimeout(async () => {
        try {
          const response = await fetch(url, options);
          const data = await response.json();
          this.timeouts.delete(key);
          resolve(data);
        } catch (error) {
          this.timeouts.delete(key);
          reject(error);
        }
      }, this.delay);
      
      this.timeouts.set(key, timeoutId);
    });
  }
  
  cancel(key) {
    if (this.timeouts.has(key)) {
      clearTimeout(this.timeouts.get(key));
      this.timeouts.delete(key);
    }
  }
  
  cancelAll() {
    this.timeouts.forEach(timeoutId => clearTimeout(timeoutId));
    this.timeouts.clear();
  }
}

// Usage
const debounced = new DebouncedChain(500);

// Only the last call will execute
debounced.fetch('search', '/api/search?q=hello');
debounced.fetch('search', '/api/search?q=hello world');
debounced.fetch('search', '/api/search?q=hello world!');
```

### Memoized Chain

#### Request Result Caching

```javascript
class MemoizedChain {
  constructor(ttl = 60000) {
    this.cache = new Map();
    this.ttl = ttl;
  }
  
  getCacheKey(url, options = {}) {
    const method = options.method || 'GET';
    const body = options.body || '';
    return `${method}:${url}:${body}`;
  }
  
  async fetch(url, options = {}) {
    const key = this.getCacheKey(url, options);
    const cached = this.cache.get(key);
    
    if (cached && Date.now() - cached.timestamp < this.ttl) {
      return cached.data;
    }
    
    const response = await fetch(url, options);
    const data = await response.json();
    
    this.cache.set(key, {
      data,
      timestamp: Date.now()
    });
    
    return data;
  }
  
  async chain(...requests) {
    const results = [];
    
    for (const [url, options] of requests) {
      const result = await this.fetch(url, options);
      results.push(result);
    }
    
    return results;
  }
  
  clear() {
    this.cache.clear();
  }
  
  invalidate(url, options = {}) {
    const key = this.getCacheKey(url, options);
    this.cache.delete(key);
  }
}

// Usage
const memoized = new MemoizedChain(30000);

// First call hits API
const result1 = await memoized.fetch('/api/user/123');

// Second call returns cached result
const result2 = await memoized.fetch('/api/user/123');
```

### Observable Chain Pattern

#### Event-Driven Request Chain

```javascript
class ObservableChain {
  constructor() {
    this.observers = {
      start: [],
      progress: [],
      complete: [],
      error: []
    };
  }
  
  on(event, callback) {
    if (this.observers[event]) {
      this.observers[event].push(callback);
    }
    return this;
  }
  
  emit(event, data) {
    if (this.observers[event]) {
      this.observers[event].forEach(callback => callback(data));
    }
  }
  
  async execute(requests) {
    this.emit('start', { total: requests.length });
    
    const results = [];
    
    for (let i = 0; i < requests.length; i++) {
      try {
        const [url, options] = requests[i];
        const response = await fetch(url, options);
        const data = await response.json();
        
        results.push(data);
        
        this.emit('progress', {
          index: i,
          total: requests.length,
          completed: i + 1,
          result: data
        });
      } catch (error) {
        this.emit('error', { index: i, error });
        throw error;
      }
    }
    
    this.emit('complete', { results });
    return results;
  }
}

// Usage
const chain = new ObservableChain();

chain
  .on('start', ({ total }) => {
    console.log(`Starting ${total} requests`);
  })
  .on('progress', ({ completed, total }) => {
    console.log(`Progress: ${completed}/${total}`);
  })
  .on('complete', ({ results }) => {
    console.log('All requests completed', results);
  })
  .on('error', ({ index, error }) => {
    console.error(`Request ${index} failed:`, error);
  });

await chain.execute([
  ['/api/user/1', {}],
  ['/api/user/2', {}],
  ['/api/user/3', {}]
]);
```

---

## Conditional Requests with Fetch API

### Understanding Conditional Request Mechanics

Conditional requests allow clients to request resources only when specific conditions are met, reducing bandwidth usage and improving performance. The server evaluates request headers and returns either the full resource (200) or indicates the cached version is still valid (304 Not Modified).

### ETag-Based Conditional Requests

#### Basic ETag Usage

ETags (Entity Tags) are identifiers assigned by servers to specific versions of resources. Clients include these in conditional requests to validate cached content.

```javascript
// Initial request - server returns ETag
const initialResponse = await fetch('/api/data');
const etag = initialResponse.headers.get('ETag');
// Example ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"

// Store data and ETag
const data = await initialResponse.json();
localStorage.setItem('data', JSON.stringify(data));
localStorage.setItem('data-etag', etag);
```

#### If-None-Match Header

The `If-None-Match` header sends the ETag to the server, which responds with 304 if the resource hasn't changed.

```javascript
async function fetchWithETag(url, cachedETag) {
  const headers = {};
  
  if (cachedETag) {
    headers['If-None-Match'] = cachedETag;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 304) {
    // Resource hasn't changed, use cached version
    const cachedData = localStorage.getItem('data');
    return {
      fromCache: true,
      data: JSON.parse(cachedData)
    };
  }
  
  // Resource changed, update cache
  const newETag = response.headers.get('ETag');
  const data = await response.json();
  
  localStorage.setItem('data', JSON.stringify(data));
  localStorage.setItem('data-etag', newETag);
  
  return {
    fromCache: false,
    data
  };
}

// Usage
const cachedETag = localStorage.getItem('data-etag');
const result = await fetchWithETag('/api/data', cachedETag);
```

#### Weak vs Strong ETags

```javascript
// Strong ETag - byte-for-byte identical
// "33a64df551425fcc55e4d42a148795d9f25f89d4"

// Weak ETag - semantically equivalent but may differ in bytes
// W/"33a64df551425fcc55e4d42a148795d9f25f89d4"

function parseETag(etagHeader) {
  if (!etagHeader) return null;
  
  const isWeak = etagHeader.startsWith('W/');
  const value = etagHeader.replace(/^W\//, '').replace(/"/g, '');
  
  return {
    isWeak,
    value,
    original: etagHeader
  };
}

// Server behavior consideration
async function fetchWithETagValidation(url, cachedETag) {
  const etag = parseETag(cachedETag);
  
  const response = await fetch(url, {
    headers: {
      'If-None-Match': etag.original
    }
  });
  
  return {
    status: response.status,
    modified: response.status !== 304,
    etag: response.headers.get('ETag')
  };
}
```

#### Multiple ETags in If-None-Match

```javascript
async function fetchWithMultipleETags(url, etagList) {
  // Server matches against any ETag in the list
  const etagHeader = etagList.join(', ');
  
  const response = await fetch(url, {
    headers: {
      'If-None-Match': etagHeader
    }
  });
  
  return response;
}

// Usage: Check against multiple cached versions
const etags = [
  '"v1-abc123"',
  '"v2-def456"',
  'W/"v3-ghi789"'
];

const response = await fetchWithMultipleETags('/api/resource', etags);
```

### Last-Modified Based Conditional Requests

#### If-Modified-Since Header

The `If-Modified-Since` header uses timestamps to validate cached resources.

```javascript
async function fetchIfModifiedSince(url, lastModified) {
  const headers = {};
  
  if (lastModified) {
    headers['If-Modified-Since'] = lastModified;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 304) {
    console.log('Resource not modified since', lastModified);
    return null; // Use cached version
  }
  
  // Resource was modified
  const newLastModified = response.headers.get('Last-Modified');
  const data = await response.json();
  
  // Store for future requests
  localStorage.setItem('data', JSON.stringify(data));
  localStorage.setItem('data-last-modified', newLastModified);
  
  return data;
}

// Usage
const lastModified = localStorage.getItem('data-last-modified');
// Example: "Wed, 21 Oct 2015 07:28:00 GMT"
const data = await fetchIfModifiedSince('/api/data', lastModified);
```

#### Date Format Handling

```javascript
function formatHTTPDate(date) {
  // HTTP dates must be in GMT/UTC
  return date.toUTCString();
}

function parseHTTPDate(dateString) {
  return new Date(dateString);
}

// Example usage
const cacheDate = new Date('2024-01-15T10:30:00Z');
const httpDate = formatHTTPDate(cacheDate);
// "Mon, 15 Jan 2024 10:30:00 GMT"

const response = await fetch('/api/data', {
  headers: {
    'If-Modified-Since': httpDate
  }
});
```

#### Combining ETag and Last-Modified

```javascript
async function fetchWithBothValidators(url, validators) {
  const headers = {};
  
  if (validators.etag) {
    headers['If-None-Match'] = validators.etag;
  }
  
  if (validators.lastModified) {
    headers['If-Modified-Since'] = validators.lastModified;
  }
  
  const response = await fetch(url, { headers });
  
  // Server evaluates both; typically ETag takes precedence
  if (response.status === 304) {
    return {
      modified: false,
      cached: true
    };
  }
  
  return {
    modified: true,
    cached: false,
    etag: response.headers.get('ETag'),
    lastModified: response.headers.get('Last-Modified'),
    data: await response.json()
  };
}

// Usage
const result = await fetchWithBothValidators('/api/data', {
  etag: '"abc123"',
  lastModified: 'Mon, 15 Jan 2024 10:30:00 GMT'
});
```

### Conditional PUT and POST Requests

#### If-Match for Safe Updates

The `If-Match` header ensures updates only occur if the resource hasn't changed, preventing lost updates.

```javascript
async function conditionalUpdate(url, data, currentETag) {
  const response = await fetch(url, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
      'If-Match': currentETag
    },
    body: JSON.stringify(data)
  });
  
  if (response.status === 412) {
    // Precondition Failed - resource was modified
    throw new Error('Resource was modified by another client');
  }
  
  if (response.status === 428) {
    // Precondition Required - server requires If-Match
    throw new Error('ETag required for this operation');
  }
  
  return response;
}

// Usage with optimistic locking
try {
  const etag = localStorage.getItem('resource-etag');
  await conditionalUpdate('/api/resource/123', updatedData, etag);
  console.log('Update successful');
} catch (error) {
  // Fetch latest version and retry
  const latest = await fetch('/api/resource/123');
  const latestETag = latest.headers.get('ETag');
  
  // Prompt user to merge changes or retry
  console.log('Conflict detected, manual intervention needed');
}
```

#### If-Unmodified-Since for Updates

```javascript
async function updateIfUnmodified(url, data, lastModified) {
  const response = await fetch(url, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
      'If-Unmodified-Since': lastModified
    },
    body: JSON.stringify(data)
  });
  
  if (response.status === 412) {
    return {
      success: false,
      reason: 'modified',
      message: 'Resource was modified after ' + lastModified
    };
  }
  
  return {
    success: true,
    newLastModified: response.headers.get('Last-Modified')
  };
}
```

#### Atomic Update Pattern

```javascript
async function atomicUpdate(url, updateFn, maxRetries = 3) {
  let attempts = 0;
  
  while (attempts < maxRetries) {
    // Fetch current version
    const current = await fetch(url);
    const etag = current.headers.get('ETag');
    const data = await current.json();
    
    // Apply update function
    const updated = updateFn(data);
    
    // Attempt conditional update
    const response = await fetch(url, {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        'If-Match': etag
      },
      body: JSON.stringify(updated)
    });
    
    if (response.ok) {
      return {
        success: true,
        attempts: attempts + 1,
        data: await response.json()
      };
    }
    
    if (response.status === 412) {
      attempts++;
      // Retry with fresh data
      continue;
    }
    
    throw new Error(`Update failed with status ${response.status}`);
  }
  
  throw new Error(`Failed after ${maxRetries} attempts due to conflicts`);
}

// Usage: Increment counter atomically
const result = await atomicUpdate('/api/counter', data => ({
  ...data,
  value: data.value + 1
}));
```

### Range Requests with Conditional Headers

#### Conditional Range Requests

```javascript
async function conditionalRangeRequest(url, range, etag) {
  const headers = {
    'Range': `bytes=${range.start}-${range.end}`
  };
  
  if (etag) {
    headers['If-Range'] = etag;
  }
  
  const response = await fetch(url, { headers });
  
  if (response.status === 206) {
    // Partial content returned
    const contentRange = response.headers.get('Content-Range');
    // Example: "bytes 0-1023/4096"
    
    return {
      partial: true,
      data: await response.arrayBuffer(),
      range: contentRange
    };
  }
  
  if (response.status === 200) {
    // Full content returned (ETag didn't match or no If-Range sent)
    return {
      partial: false,
      data: await response.arrayBuffer()
    };
  }
  
  throw new Error(`Unexpected status: ${response.status}`);
}

// Usage: Resume download
const etag = localStorage.getItem('download-etag');
const bytesDownloaded = parseInt(localStorage.getItem('bytes-downloaded') || '0');

const result = await conditionalRangeRequest('/large-file.zip', {
  start: bytesDownloaded,
  end: bytesDownloaded + 1024 * 1024 // Download 1MB chunk
}, etag);
```

#### If-Range with Last-Modified

```javascript
async function resumeDownload(url, lastModified, startByte) {
  const response = await fetch(url, {
    headers: {
      'Range': `bytes=${startByte}-`,
      'If-Range': lastModified // Can be ETag or Last-Modified date
    }
  });
  
  if (response.status === 206) {
    // Resource unchanged, partial content received
    return {
      resumed: true,
      data: await response.blob()
    };
  }
  
  if (response.status === 200) {
    // Resource changed, full content received (start over)
    return {
      resumed: false,
      restartRequired: true,
      data: await response.blob()
    };
  }
  
  throw new Error('Range request failed');
}
```

### Cache Validation Strategies

#### Validation with Cache API

```javascript
async function fetchWithCacheValidation(request) {
  const cache = await caches.open('validated-cache-v1');
  const cached = await cache.match(request);
  
  if (!cached) {
    // Not in cache, fetch normally
    const response = await fetch(request);
    await cache.put(request, response.clone());
    return response;
  }
  
  // Extract validators from cached response
  const cachedETag = cached.headers.get('ETag');
  const cachedLastModified = cached.headers.get('Last-Modified');
  
  // Create conditional request
  const headers = new Headers(request.headers);
  if (cachedETag) {
    headers.set('If-None-Match', cachedETag);
  }
  if (cachedLastModified) {
    headers.set('If-Modified-Since', cachedLastModified);
  }
  
  const validationRequest = new Request(request, { headers });
  const response = await fetch(validationRequest);
  
  if (response.status === 304) {
    // Not modified, return cached version
    return cached;
  }
  
  // Modified, update cache
  await cache.put(request, response.clone());
  return response;
}

// Usage in service worker
self.addEventListener('fetch', event => {
  event.respondWith(fetchWithCacheValidation(event.request));
});
```

#### Stale-While-Revalidate with Conditionals

```javascript
async function staleWhileRevalidateConditional(request) {
  const cache = await caches.open('swr-cache-v1');
  const cached = await cache.match(request);
  
  // Return stale content immediately
  const responsePromise = cached 
    ? Promise.resolve(cached.clone())
    : fetch(request);
  
  // Revalidate in background
  const revalidate = async () => {
    if (!cached) {
      const fresh = await fetch(request);
      await cache.put(request, fresh.clone());
      return;
    }
    
    const validators = {
      etag: cached.headers.get('ETag'),
      lastModified: cached.headers.get('Last-Modified')
    };
    
    const headers = new Headers(request.headers);
    if (validators.etag) {
      headers.set('If-None-Match', validators.etag);
    }
    if (validators.lastModified) {
      headers.set('If-Modified-Since', validators.lastModified);
    }
    
    const validationRequest = new Request(request, { headers });
    const response = await fetch(validationRequest);
    
    if (response.status !== 304) {
      // Update cache with fresh content
      await cache.put(request, response.clone());
    }
  };
  
  // Don't await revalidation
  revalidate().catch(err => console.error('Revalidation failed:', err));
  
  return responsePromise;
}
```

### Conditional DELETE Operations

#### Safe Resource Deletion

```javascript
async function conditionalDelete(url, etag) {
  const response = await fetch(url, {
    method: 'DELETE',
    headers: {
      'If-Match': etag
    }
  });
  
  if (response.status === 412) {
    return {
      deleted: false,
      reason: 'modified',
      message: 'Resource was modified, cannot delete'
    };
  }
  
  if (response.status === 404) {
    return {
      deleted: false,
      reason: 'not-found',
      message: 'Resource already deleted or never existed'
    };
  }
  
  if (response.status === 204 || response.status === 200) {
    return {
      deleted: true
    };
  }
  
  throw new Error(`Unexpected status: ${response.status}`);
}

// Usage: Prevent accidental deletion
const etag = localStorage.getItem('document-etag');
const result = await conditionalDelete('/api/documents/123', etag);

if (!result.deleted) {
  alert(`Cannot delete: ${result.message}`);
}
```

### Conditional Request with Custom Logic

#### Application-Level Versioning

```javascript
async function fetchWithVersionCheck(url, localVersion) {
  const response = await fetch(url, {
    headers: {
      'X-Client-Version': localVersion.toString()
    }
  });
  
  const serverVersion = parseInt(response.headers.get('X-Server-Version') || '0');
  
  if (serverVersion > localVersion) {
    // Server has newer version
    const data = await response.json();
    
    return {
      updated: true,
      version: serverVersion,
      data
    };
  }
  
  return {
    updated: false,
    version: localVersion
  };
}
```

#### Custom Conditional Headers

```javascript
async function fetchWithCustomCondition(url, conditions) {
  const headers = {};
  
  // Custom business logic conditions
  if (conditions.contentHash) {
    headers['X-Content-Hash'] = conditions.contentHash;
  }
  
  if (conditions.schemaVersion) {
    headers['X-Schema-Version'] = conditions.schemaVersion.toString();
  }
  
  if (conditions.clientTimestamp) {
    headers['X-Client-Timestamp'] = conditions.clientTimestamp;
  }
  
  const response = await fetch(url, { headers });
  
  // Custom status codes for different conditions
  if (response.status === 499) { // Custom: content hash matches
    return { useCache: true };
  }
  
  if (response.status === 498) { // Custom: schema mismatch
    return { 
      useCache: false, 
      requiresUpdate: true,
      newSchema: await response.json()
    };
  }
  
  return {
    useCache: false,
    data: await response.json()
  };
}
```

### Optimization Patterns

#### Batch Conditional Requests

```javascript
async function batchConditionalFetch(requests) {
  // Group requests by domain for efficiency
  const grouped = requests.reduce((acc, req) => {
    const domain = new URL(req.url).origin;
    if (!acc[domain]) acc[domain] = [];
    acc[domain].push(req);
    return acc;
  }, {});
  
  const results = [];
  
  for (const [domain, reqs] of Object.entries(grouped)) {
    const batchResults = await Promise.all(
      reqs.map(async req => {
        const cache = await caches.open('batch-cache');
        const cached = await cache.match(req.url);
        
        if (!cached) {
          const response = await fetch(req.url);
          await cache.put(req.url, response.clone());
          return { url: req.url, fromCache: false, response };
        }
        
        const etag = cached.headers.get('ETag');
        const validationResponse = await fetch(req.url, {
          headers: etag ? { 'If-None-Match': etag } : {}
        });
        
        if (validationResponse.status === 304) {
          return { url: req.url, fromCache: true, response: cached };
        }
        
        await cache.put(req.url, validationResponse.clone());
        return { url: req.url, fromCache: false, response: validationResponse };
      })
    );
    
    results.push(...batchResults);
  }
  
  return results;
}

// Usage
const urls = [
  '/api/users',
  '/api/posts',
  '/api/comments'
].map(url => new Request(url));

const results = await batchConditionalFetch(urls);
const cacheHits = results.filter(r => r.fromCache).length;
console.log(`Cache hit rate: ${(cacheHits / results.length * 100).toFixed(1)}%`);
```

#### Predictive Revalidation

```javascript
class ConditionalFetchManager {
  constructor(revalidationInterval = 60000) {
    this.cache = new Map();
    this.revalidationInterval = revalidationInterval;
    this.revalidationTimers = new Map();
  }
  
  async fetch(url, options = {}) {
    const cached = this.cache.get(url);
    
    if (cached) {
      // Return cached immediately
      this.scheduleRevalidation(url);
      return cached.response.clone();
    }
    
    const response = await fetch(url, options);
    
    this.cache.set(url, {
      response: response.clone(),
      etag: response.headers.get('ETag'),
      lastModified: response.headers.get('Last-Modified'),
      timestamp: Date.now()
    });
    
    this.scheduleRevalidation(url);
    
    return response;
  }
  
  scheduleRevalidation(url) {
    // Clear existing timer
    if (this.revalidationTimers.has(url)) {
      clearTimeout(this.revalidationTimers.get(url));
    }
    
    // Schedule new revalidation
    const timer = setTimeout(() => {
      this.revalidate(url);
    }, this.revalidationInterval);
    
    this.revalidationTimers.set(url, timer);
  }
  
  async revalidate(url) {
    const cached = this.cache.get(url);
    if (!cached) return;
    
    const headers = {};
    if (cached.etag) {
      headers['If-None-Match'] = cached.etag;
    }
    if (cached.lastModified) {
      headers['If-Modified-Since'] = cached.lastModified;
    }
    
    try {
      const response = await fetch(url, { headers });
      
      if (response.status !== 304) {
        // Update cache
        this.cache.set(url, {
          response: response.clone(),
          etag: response.headers.get('ETag'),
          lastModified: response.headers.get('Last-Modified'),
          timestamp: Date.now()
        });
      }
      
      // Schedule next revalidation
      this.scheduleRevalidation(url);
    } catch (error) {
      console.error('Revalidation failed:', error);
      // Retry later
      this.scheduleRevalidation(url);
    }
  }
  
  clear() {
    this.revalidationTimers.forEach(timer => clearTimeout(timer));
    this.revalidationTimers.clear();
    this.cache.clear();
  }
}

// Usage
const manager = new ConditionalFetchManager(30000); // Revalidate every 30s

const response1 = await manager.fetch('/api/data');
const response2 = await manager.fetch('/api/data'); // Instant from cache
// Automatically revalidates in background
```

### Error Handling in Conditional Requests

#### Handling Validation Failures

```javascript
async function robustConditionalFetch(url, validators, fallback) {
  const headers = {};
  
  if (validators.etag) {
    headers['If-None-Match'] = validators.etag;
  }
  if (validators.lastModified) {
    headers['If-Modified-Since'] = validators.lastModified;
  }
  
  try {
    const response = await fetch(url, { headers });
    
    if (response.status === 304) {
      // Valid cache, use fallback
      return {
        cached: true,
        data: fallback
      };
    }
    
    if (response.ok) {
      return {
        cached: false,
        data: await response.json()
      };
    }
    
    throw new Error(`HTTP ${response.status}`);
  } catch (error) {
    // Network error or server error
    if (fallback) {
      console.warn('Using fallback due to error:', error);
      return {
        cached: true,
        error: true,
        data: fallback
      };
    }
    
    throw error;
  }
}
```

#### Retry Strategy for Precondition Failures

```javascript
async function retryConditionalUpdate(url, updateFn, options = {}) {
  const {
    maxRetries = 3,
    backoffMs = 1000,
    onConflict = null
  } = options;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      // Fetch current state
      const current = await fetch(url);
      if (!current.ok) {
        throw new Error(`Fetch failed: ${current.status}`);
      }
      
      const etag = current.headers.get('ETag');
      const data = await current.json();
      
      // Apply update
      const updated = updateFn(data);
      
      // Conditional update
      const response = await fetch(url, {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
          'If-Match': etag
        },
        body: JSON.stringify(updated)
      });
      
      if (response.ok) {
        return {
          success: true,
          attempts: attempt + 1,
          data: await response.json()
        };
      }
      
      if (response.status === 412) {
        // Conflict, retry
        if (onConflict) {
          await onConflict(attempt, data, updated);
        }
        
        // Exponential backoff
        await new Promise(resolve => 
          setTimeout(resolve, backoffMs * Math.pow(2, attempt))
        );
        
        continue;
      }
      
      throw new Error(`Update failed: ${response.status}`);
    } catch (error) {
      if (attempt === maxRetries - 1) {
        throw error;
      }
    }
  }
  
  throw new Error(`Failed after ${maxRetries} attempts`);
}

// Usage
const result = await retryConditionalUpdate(
  '/api/counter',
  data => ({ ...data, count: data.count + 1 }),
  {
    maxRetries: 5,
    backoffMs: 500,
    onConflict: (attempt, current, intended) => {
      console.log(`Conflict on attempt ${attempt + 1}`);
      console.log('Current:', current);
      console.log('Intended:', intended);
    }
  }
);
```

---

## Polling Patterns with Fetch API

### Basic Polling Implementation

#### Simple Interval-Based Polling

```javascript
function startPolling(url, interval = 5000) {
  const intervalId = setInterval(async () => {
    try {
      const response = await fetch(url);
      const data = await response.json();
      console.log('Polled data:', data);
    } catch (error) {
      console.error('Polling error:', error);
    }
  }, interval);
  
  return () => clearInterval(intervalId);
}

// Usage
const stopPolling = startPolling('https://api.example.com/status', 5000);

// Stop polling when needed
stopPolling();
```

#### Polling with Immediate Execution

```javascript
async function pollWithImmediate(url, interval = 5000) {
  const poll = async () => {
    try {
      const response = await fetch(url);
      const data = await response.json();
      console.log('Polled data:', data);
      return data;
    } catch (error) {
      console.error('Polling error:', error);
    }
  };
  
  // Execute immediately
  await poll();
  
  // Then continue polling
  const intervalId = setInterval(poll, interval);
  
  return () => clearInterval(intervalId);
}
```

### Conditional Polling

#### Poll Until Condition Met

```javascript
async function pollUntilCondition(url, conditionFn, options = {}) {
  const {
    interval = 2000,
    maxAttempts = 30,
    onProgress = null
  } = options;
  
  let attempts = 0;
  
  while (attempts < maxAttempts) {
    attempts++;
    
    try {
      const response = await fetch(url);
      const data = await response.json();
      
      if (onProgress) {
        onProgress(data, attempts);
      }
      
      if (conditionFn(data)) {
        return { success: true, data, attempts };
      }
      
      await new Promise(resolve => setTimeout(resolve, interval));
    } catch (error) {
      console.error(`Polling attempt ${attempts} failed:`, error);
      await new Promise(resolve => setTimeout(resolve, interval));
    }
  }
  
  return { success: false, attempts };
}

// Usage
const result = await pollUntilCondition(
  'https://api.example.com/job/123',
  data => data.status === 'completed',
  {
    interval: 3000,
    maxAttempts: 20,
    onProgress: (data, attempt) => {
      console.log(`Attempt ${attempt}: Status is ${data.status}`);
    }
  }
);

if (result.success) {
  console.log('Job completed:', result.data);
} else {
  console.log('Job did not complete within timeout');
}
```

#### Status-Based Polling

```javascript
async function pollJobStatus(jobId, options = {}) {
  const {
    baseUrl = 'https://api.example.com',
    interval = 2000,
    timeout = 60000,
    onStatusChange = null
  } = options;
  
  const startTime = Date.now();
  let lastStatus = null;
  
  while (Date.now() - startTime < timeout) {
    try {
      const response = await fetch(`${baseUrl}/jobs/${jobId}`);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const data = await response.json();
      
      if (data.status !== lastStatus) {
        lastStatus = data.status;
        if (onStatusChange) {
          onStatusChange(data.status, data);
        }
      }
      
      // Terminal states
      if (data.status === 'completed') {
        return { success: true, data, status: 'completed' };
      }
      
      if (data.status === 'failed' || data.status === 'error') {
        return { success: false, data, status: data.status };
      }
      
      // Continue polling for pending/processing states
      await new Promise(resolve => setTimeout(resolve, interval));
    } catch (error) {
      console.error('Polling error:', error);
      await new Promise(resolve => setTimeout(resolve, interval));
    }
  }
  
  return { success: false, status: 'timeout' };
}

// Usage
const result = await pollJobStatus('job-456', {
  interval: 2000,
  timeout: 120000,
  onStatusChange: (status, data) => {
    console.log(`Status changed to: ${status}`);
    if (data.progress) {
      console.log(`Progress: ${data.progress}%`);
    }
  }
});
```

### Exponential Backoff Polling

#### Adaptive Polling Interval

```javascript
class ExponentialBackoffPoller {
  constructor(options = {}) {
    this.initialInterval = options.initialInterval || 1000;
    this.maxInterval = options.maxInterval || 30000;
    this.multiplier = options.multiplier || 2;
    this.currentInterval = this.initialInterval;
    this.isRunning = false;
    this.timeoutId = null;
  }
  
  async start(url, conditionFn, callbacks = {}) {
    this.isRunning = true;
    this.currentInterval = this.initialInterval;
    
    const poll = async () => {
      if (!this.isRunning) return;
      
      try {
        const response = await fetch(url);
        const data = await response.json();
        
        if (callbacks.onData) {
          callbacks.onData(data);
        }
        
        if (conditionFn(data)) {
          this.stop();
          if (callbacks.onComplete) {
            callbacks.onComplete(data);
          }
          return;
        }
        
        // Increase interval for next poll
        this.currentInterval = Math.min(
          this.currentInterval * this.multiplier,
          this.maxInterval
        );
        
        if (callbacks.onProgress) {
          callbacks.onProgress(data, this.currentInterval);
        }
        
      } catch (error) {
        if (callbacks.onError) {
          callbacks.onError(error);
        }
      }
      
      if (this.isRunning) {
        this.timeoutId = setTimeout(poll, this.currentInterval);
      }
    };
    
    await poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  reset() {
    this.currentInterval = this.initialInterval;
  }
}

// Usage
const poller = new ExponentialBackoffPoller({
  initialInterval: 1000,
  maxInterval: 32000,
  multiplier: 2
});

poller.start(
  'https://api.example.com/task/789',
  data => data.status === 'done',
  {
    onData: data => console.log('Received:', data),
    onProgress: (data, nextInterval) => {
      console.log(`Next poll in ${nextInterval}ms`);
    },
    onComplete: data => console.log('Task completed:', data),
    onError: error => console.error('Error:', error)
  }
);

// Stop polling when needed
poller.stop();
```

### Long Polling

#### Server-Sent Timeout Pattern

```javascript
async function longPoll(url, options = {}) {
  const {
    timeout = 30000,
    onData = null,
    onError = null,
    shouldContinue = () => true
  } = options;
  
  while (shouldContinue()) {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      const response = await fetch(url, {
        signal: controller.signal,
        headers: {
          'X-Long-Poll-Timeout': timeout.toString()
        }
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        const data = await response.json();
        
        if (onData) {
          const continuePolling = onData(data);
          if (continuePolling === false) {
            break;
          }
        }
      } else if (response.status === 304) {
        // No new data, continue polling
        continue;
      } else if (response.status >= 500) {
        // Server error, wait before retrying
        await new Promise(resolve => setTimeout(resolve, 5000));
      }
      
    } catch (error) {
      if (error.name === 'AbortError') {
        // Timeout occurred, restart poll
        continue;
      }
      
      if (onError) {
        const continuePolling = onError(error);
        if (continuePolling === false) {
          break;
        }
      }
      
      // Wait before retrying on error
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}

// Usage
let isActive = true;

longPoll('https://api.example.com/events/long-poll', {
  timeout: 60000,
  onData: data => {
    console.log('Received data:', data);
    return isActive; // Continue polling if active
  },
  onError: error => {
    console.error('Long poll error:', error);
    return isActive;
  },
  shouldContinue: () => isActive
});

// Stop long polling
// isActive = false;
```

#### Long Polling with Last Event ID

```javascript
class LongPollingClient {
  constructor(url, options = {}) {
    this.url = url;
    this.lastEventId = options.lastEventId || null;
    this.timeout = options.timeout || 45000;
    this.retryDelay = options.retryDelay || 3000;
    this.maxRetries = options.maxRetries || 5;
    this.isRunning = false;
    this.retryCount = 0;
  }
  
  async start(callbacks = {}) {
    this.isRunning = true;
    this.retryCount = 0;
    
    while (this.isRunning && this.retryCount < this.maxRetries) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), this.timeout);
        
        const url = new URL(this.url);
        if (this.lastEventId) {
          url.searchParams.set('lastEventId', this.lastEventId);
        }
        
        const response = await fetch(url.toString(), {
          signal: controller.signal,
          headers: {
            'Accept': 'application/json'
          }
        });
        
        clearTimeout(timeoutId);
        
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }
        
        const data = await response.json();
        
        if (data.eventId) {
          this.lastEventId = data.eventId;
        }
        
        if (callbacks.onMessage) {
          callbacks.onMessage(data);
        }
        
        // Reset retry count on success
        this.retryCount = 0;
        
      } catch (error) {
        if (error.name === 'AbortError') {
          // Timeout, restart immediately
          continue;
        }
        
        this.retryCount++;
        
        if (callbacks.onError) {
          callbacks.onError(error, this.retryCount);
        }
        
        if (this.retryCount >= this.maxRetries) {
          if (callbacks.onMaxRetries) {
            callbacks.onMaxRetries();
          }
          break;
        }
        
        // Exponential backoff
        const delay = this.retryDelay * Math.pow(2, this.retryCount - 1);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  stop() {
    this.isRunning = false;
  }
  
  reset() {
    this.lastEventId = null;
    this.retryCount = 0;
  }
}

// Usage
const client = new LongPollingClient('https://api.example.com/stream', {
  timeout: 60000,
  retryDelay: 2000,
  maxRetries: 10
});

client.start({
  onMessage: data => {
    console.log('Event:', data);
    // Process data
  },
  onError: (error, retryCount) => {
    console.error(`Error (retry ${retryCount}):`, error);
  },
  onMaxRetries: () => {
    console.error('Max retries reached, stopping');
  }
});

// Stop when needed
// client.stop();
```

### Smart Polling with Visibility API

#### Pause When Tab Hidden

```javascript
class VisibilityAwarePoller {
  constructor(url, options = {}) {
    this.url = url;
    this.interval = options.interval || 5000;
    this.backgroundInterval = options.backgroundInterval || 60000;
    this.onData = options.onData || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
    this.currentInterval = this.interval;
    
    this.handleVisibilityChange = this.handleVisibilityChange.bind(this);
  }
  
  start() {
    this.isRunning = true;
    this.currentInterval = document.hidden 
      ? this.backgroundInterval 
      : this.interval;
    
    document.addEventListener('visibilitychange', this.handleVisibilityChange);
    
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
    document.removeEventListener('visibilitychange', this.handleVisibilityChange);
  }
  
  handleVisibilityChange() {
    if (document.hidden) {
      console.log('Tab hidden, slowing polling');
      this.currentInterval = this.backgroundInterval;
    } else {
      console.log('Tab visible, resuming normal polling');
      this.currentInterval = this.interval;
      
      // Poll immediately when tab becomes visible
      if (this.timeoutId) {
        clearTimeout(this.timeoutId);
      }
      this.poll();
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      this.onData(data);
    } catch (error) {
      console.error('Polling error:', error);
    }
    
    if (this.isRunning) {
      this.timeoutId = setTimeout(() => this.poll(), this.currentInterval);
    }
  }
}

// Usage
const poller = new VisibilityAwarePoller('https://api.example.com/updates', {
  interval: 5000,           // 5 seconds when visible
  backgroundInterval: 60000, // 1 minute when hidden
  onData: data => {
    console.log('Update:', data);
  }
});

poller.start();
```

#### Pause Polling Completely When Hidden

```javascript
class PausablePoller {
  constructor(url, interval = 5000) {
    this.url = url;
    this.interval = interval;
    this.intervalId = null;
    this.isRunning = false;
    this.isPaused = false;
    
    this.handleVisibilityChange = this.handleVisibilityChange.bind(this);
  }
  
  start() {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.isPaused = document.hidden;
    
    document.addEventListener('visibilitychange', this.handleVisibilityChange);
    
    if (!this.isPaused) {
      this.startPolling();
    }
  }
  
  stop() {
    this.isRunning = false;
    this.stopPolling();
    document.removeEventListener('visibilitychange', this.handleVisibilityChange);
  }
  
  startPolling() {
    if (this.intervalId) return;
    
    this.poll(); // Immediate first poll
    this.intervalId = setInterval(() => this.poll(), this.interval);
  }
  
  stopPolling() {
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }
  
  handleVisibilityChange() {
    if (document.hidden) {
      this.isPaused = true;
      this.stopPolling();
      console.log('Polling paused (tab hidden)');
    } else {
      this.isPaused = false;
      if (this.isRunning) {
        this.startPolling();
        console.log('Polling resumed (tab visible)');
      }
    }
  }
  
  async poll() {
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      console.log('Polled data:', data);
    } catch (error) {
      console.error('Polling error:', error);
    }
  }
}
```

### Polling with Change Detection

#### Hash-Based Change Detection

```javascript
class ChangeDetectionPoller {
  constructor(url, options = {}) {
    this.url = url;
    this.interval = options.interval || 10000;
    this.onDataChange = options.onDataChange || (() => {});
    this.onNoChange = options.onNoChange || (() => {});
    this.lastHash = null;
    this.isRunning = false;
    this.intervalId = null;
  }
  
  async computeHash(data) {
    const str = JSON.stringify(data);
    const encoder = new TextEncoder();
    const dataBuffer = encoder.encode(str);
    const hashBuffer = await crypto.subtle.digest('SHA-256', dataBuffer);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  }
  
  start() {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.poll(); // Initial poll
    this.intervalId = setInterval(() => this.poll(), this.interval);
  }
  
  stop() {
    this.isRunning = false;
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }
  
  async poll() {
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      
      const currentHash = await this.computeHash(data);
      
      if (this.lastHash === null) {
        // First poll
        this.lastHash = currentHash;
        this.onDataChange(data, null);
      } else if (currentHash !== this.lastHash) {
        // Data changed
        this.lastHash = currentHash;
        this.onDataChange(data, currentHash);
      } else {
        // No change
        this.onNoChange();
      }
      
    } catch (error) {
      console.error('Polling error:', error);
    }
  }
  
  reset() {
    this.lastHash = null;
  }
}

// Usage
const poller = new ChangeDetectionPoller('https://api.example.com/data', {
  interval: 5000,
  onDataChange: (data, hash) => {
    console.log('Data changed:', data);
    console.log('New hash:', hash);
  },
  onNoChange: () => {
    console.log('No changes detected');
  }
});

poller.start();
```

#### ETag-Based Change Detection

```javascript
class ETagPoller {
  constructor(url, options = {}) {
    this.url = url;
    this.interval = options.interval || 10000;
    this.onChange = options.onChange || (() => {});
    this.onNoChange = options.onNoChange || (() => {});
    this.currentETag = null;
    this.isRunning = false;
    this.intervalId = null;
  }
  
  start() {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.poll();
    this.intervalId = setInterval(() => this.poll(), this.interval);
  }
  
  stop() {
    this.isRunning = false;
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }
  
  async poll() {
    try {
      const headers = {};
      if (this.currentETag) {
        headers['If-None-Match'] = this.currentETag;
      }
      
      const response = await fetch(this.url, { headers });
      
      if (response.status === 304) {
        // Not modified
        this.onNoChange();
        return;
      }
      
      if (response.ok) {
        const newETag = response.headers.get('ETag');
        const data = await response.json();
        
        if (newETag && newETag !== this.currentETag) {
          this.currentETag = newETag;
          this.onChange(data, newETag);
        }
      }
      
    } catch (error) {
      console.error('Polling error:', error);
    }
  }
  
  reset() {
    this.currentETag = null;
  }
}

// Usage
const etagPoller = new ETagPoller('https://api.example.com/resource', {
  interval: 8000,
  onChange: (data, etag) => {
    console.log('Resource changed:', data);
  },
  onNoChange: () => {
    console.log('Resource unchanged (304)');
  }
});

etagPoller.start();
```

### Adaptive Polling

#### Dynamic Interval Adjustment

```javascript
class AdaptivePoller {
  constructor(url, options = {}) {
    this.url = url;
    this.minInterval = options.minInterval || 1000;
    this.maxInterval = options.maxInterval || 60000;
    this.currentInterval = options.initialInterval || 5000;
    this.adjustmentFactor = options.adjustmentFactor || 1.5;
    this.onData = options.onData || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
    this.consecutiveNoChanges = 0;
  }
  
  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      
      const hasChanges = this.onData(data);
      
      if (hasChanges) {
        // Data changed - poll more frequently
        this.consecutiveNoChanges = 0;
        this.currentInterval = Math.max(
          this.minInterval,
          this.currentInterval / this.adjustmentFactor
        );
      } else {
        // No changes - slow down polling
        this.consecutiveNoChanges++;
        this.currentInterval = Math.min(
          this.maxInterval,
          this.currentInterval * this.adjustmentFactor
        );
      }
      
      console.log(`Next poll in ${this.currentInterval}ms (${this.consecutiveNoChanges} no-change streaks)`);
      
    } catch (error) {
      console.error('Polling error:', error);
      // On error, increase interval
      this.currentInterval = Math.min(
        this.maxInterval,
        this.currentInterval * this.adjustmentFactor
      );
    }
    
    if (this.isRunning) {
      this.timeoutId = setTimeout(() => this.poll(), this.currentInterval);
    }
  }
  
  reset() {
    this.currentInterval = 5000;
    this.consecutiveNoChanges = 0;
  }
}

// Usage
let lastData = null;

const adaptivePoller = new AdaptivePoller('https://api.example.com/feed', {
  minInterval: 2000,
  maxInterval: 30000,
  initialInterval: 5000,
  adjustmentFactor: 1.5,
  onData: data => {
    const hasChanges = JSON.stringify(data) !== JSON.stringify(lastData);
    lastData = data;
    
    if (hasChanges) {
      console.log('New data detected:', data);
    }
    
    return hasChanges;
  }
});

adaptivePoller.start();
```

### Polling Queue Manager

#### Multiple Concurrent Polls

```javascript
class PollingQueueManager {
  constructor(options = {}) {
    this.maxConcurrent = options.maxConcurrent || 5;
    this.pollers = new Map();
    this.queue = [];
    this.activeCount = 0;
  }
  
  addPoller(id, url, interval, callback) {
    if (this.pollers.has(id)) {
      console.warn(`Poller ${id} already exists`);
      return;
    }
    
    const poller = {
      id,
      url,
      interval,
      callback,
      isActive: false,
      intervalId: null,
      priority: 0
    };
    
    this.pollers.set(id, poller);
    this.queue.push(poller);
    this.processQueue();
  }
  
  removePoller(id) {
    const poller = this.pollers.get(id);
    if (!poller) return;
    
    this.stopPoller(poller);
    this.pollers.delete(id);
    this.queue = this.queue.filter(p => p.id !== id);
    this.processQueue();
  }
  
  setPriority(id, priority) {
    const poller = this.pollers.get(id);
    if (poller) {
      poller.priority = priority;
      this.queue.sort((a, b) => b.priority - a.priority);
      this.processQueue();
    }
  }
  
  processQueue() {
    while (this.activeCount < this.maxConcurrent && this.queue.length > 0) {
      const poller = this.queue.find(p => !p.isActive);
      if (!poller) break;
      
      this.startPoller(poller);
    }
  }
  
  startPoller(poller) {
    if (poller.isActive) return;
    
    poller.isActive = true;
    this.activeCount++;
    
    const poll = async () => {
      try {
        const response = await fetch(poller.url);
        const data = await response.json();
        poller.callback(data);
      } catch (error) {
        console.error(`Polling error for ${poller.id}:`, error);
      }
    };
    
    poll(); // Immediate execution
    poller.intervalId = setInterval(poll, poller.interval);
  }
  
  stopPoller(poller) {
    if (!poller.isActive) return;
    
    if (poller.intervalId) {
      clearInterval(poller.intervalId);
      poller.intervalId = null;
    }
    
    poller.isActive = false;
    this.activeCount--;
  }
  
  pauseAll() {
    this.pollers.forEach(poller => this.stopPoller(poller));
  }
  
  resumeAll() {
    this.processQueue();
  }
  
  stopAll() {
    this.pollers.forEach(poller => this.stopPoller(poller));
    this.pollers.clear();
    this.queue = [];
  }
  
  getStatus() {
    return {
      total: this.pollers.size,
      active: this.activeCount,
      queued: this.queue.filter(p => !p.isActive).length,
      pollers: Array.from(this.pollers.values()).map(p => ({
        id: p.id,
        url: p.url,
        isActive: p.isActive,
        priority: p.priority
      }))
    };
  }
}

// Usage
const manager = new PollingQueueManager({ maxConcurrent: 3 });

manager.addPoller('user-status', 'https://api.example.com/user/status', 5000, 
  data => console.log('User status:', data));

manager.addPoller('notifications', 'https://api.example.com/notifications', 10000,
  data => console.log('Notifications:', data));

manager.addPoller('messages', 'https://api.example.com/messages', 3000,
  data => console.log('Messages:', data));

// Set priorities
manager.setPriority('messages', 10); // Highest priority

// Check status
console.log(manager.getStatus());

// Pause all polling
// manager.pauseAll();

// Resume
// manager.resumeAll();
```

### Jittered Polling

#### Preventing Thundering Herd

```javascript
class JitteredPoller {
  constructor(url, options = {}) {
    this.url = url;
    this.baseInterval = options.interval || 5000;
    this.jitterPercent = options.jitterPercent || 0.1; // 10% jitter
    this.onData = options.onData || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
  }
  
  calculateInterval() {
    const jitter = this.baseInterval * this.jitterPercent;
    const min = this.baseInterval - jitter;
    const max = this.baseInterval + jitter;
    return Math.random() * (max - min) + min;
  }
  
  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      this.onData(data);
    } catch (error) {
      console.error('Polling error:', error);
    }
    
    if (this.isRunning) {
      const nextInterval = this.calculateInterval();
      console.log(`Next poll in ${nextInterval.toFixed(0)}ms`);
      this.timeoutId = setTimeout(() => this.poll(), nextInterval);
    }
  }
}

// Usage - prevents multiple clients from polling simultaneously
const jitteredPoller = new JitteredPoller('https://api.example.com/data', {
  interval: 10000,
  jitterPercent: 0.2, // ±20% jitter (8-12 seconds)
  onData: data => console.log('Data:', data)
});

jitteredPoller.start();
```

#### Full Jitter Exponential Backoff

```javascript
class FullJitterBackoffPoller {
  constructor(url, options = {}) {
    this.url = url;
    this.baseDelay = options.baseDelay || 1000;
    this.maxDelay = options.maxDelay || 60000;
    this.attempt = 0;
    this.onData = options.onData || (() => {});
    this.onError = options.onError || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
  }

  calculateDelay() {
    const exponentialDelay = Math.min(
      this.maxDelay,
      this.baseDelay * Math.pow(2, this.attempt)
    );

    // Full jitter: random value between 0 and exponentialDelay
    return Math.random() * exponentialDelay;
  }

  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.attempt = 0;
    this.poll();
  }

  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }

  async poll() {
    if (!this.isRunning) return;

    try {
      const response = await fetch(this.url);

      if (response.ok) {
        const data = await response.json();
        this.onData(data);
        this.attempt = 0; // Reset on success
      } else {
        throw new Error(`HTTP ${response.status}`);
      }

    } catch (error) {
      this.onError(error, this.attempt);
      this.attempt++;
    }

    if (this.isRunning) {
      const delay = this.calculateDelay();
      console.log(
        `Next poll in ${delay.toFixed(0)}ms (attempt ${this.attempt})`
      );
      this.timeoutId = setTimeout(() => this.poll(), delay);
    }
  }

  reset() {
    this.attempt = 0;
  }
}

````

### Cancellable Polling with AbortController

#### Graceful Cancellation

```javascript
class CancellablePoller {
  constructor(url, options = {}) {
    this.url = url;
    this.interval = options.interval || 5000;
    this.timeout = options.timeout || 10000;
    this.onData = options.onData || (() => {});
    this.onCancel = options.onCancel || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
    this.currentController = null;
  }
  
  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    
    if (this.currentController) {
      this.currentController.abort();
      this.currentController = null;
    }
    
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    this.currentController = new AbortController();
    const signal = this.currentController.signal;
    
    try {
      const timeoutId = setTimeout(() => {
        this.currentController.abort();
      }, this.timeout);
      
      const response = await fetch(this.url, { signal });
      clearTimeout(timeoutId);
      
      if (response.ok) {
        const data = await response.json();
        this.onData(data);
      }
      
      this.currentController = null;
      
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Request cancelled');
        this.onCancel();
      } else {
        console.error('Polling error:', error);
      }
      
      this.currentController = null;
    }
    
    if (this.isRunning) {
      this.timeoutId = setTimeout(() => this.poll(), this.interval);
    }
  }
}

// Usage
const cancellablePoller = new CancellablePoller('https://api.example.com/data', {
  interval: 5000,
  timeout: 8000,
  onData: data => console.log('Data:', data),
  onCancel: () => console.log('Poll cancelled')
});

cancellablePoller.start();

// Stop immediately, cancelling any in-flight request
// cancellablePoller.stop();
````

### Polling with Network Quality Adaptation

#### Adjust Based on Connection Speed

```javascript
class NetworkAwarePoller {
  constructor(url, options = {}) {
    this.url = url;
    this.baseInterval = options.baseInterval || 5000;
    this.onData = options.onData || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
    
    this.connectionInfo = this.getConnectionInfo();
    this.updateConnectionListener();
  }
  
  getConnectionInfo() {
    const connection = navigator.connection || 
                      navigator.mozConnection || 
                      navigator.webkitConnection;
    
    return {
      effectiveType: connection?.effectiveType || '4g',
      downlink: connection?.downlink || 10,
      rtt: connection?.rtt || 50,
      saveData: connection?.saveData || false
    };
  }
  
  updateConnectionListener() {
    const connection = navigator.connection || 
                      navigator.mozConnection || 
                      navigator.webkitConnection;
    
    if (connection) {
      connection.addEventListener('change', () => {
        this.connectionInfo = this.getConnectionInfo();
        console.log('Connection changed:', this.connectionInfo);
      });
    }
  }
  
  calculateInterval() {
    const { effectiveType, saveData } = this.connectionInfo;
    
    if (saveData) {
      return this.baseInterval * 4; // Much slower when data saver is on
    }
    
    switch (effectiveType) {
      case 'slow-2g':
        return this.baseInterval * 8;
      case '2g':
        return this.baseInterval * 4;
      case '3g':
        return this.baseInterval * 2;
      case '4g':
      default:
        return this.baseInterval;
    }
  }
  
  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    try {
      const response = await fetch(this.url);
      const data = await response.json();
      this.onData(data);
    } catch (error) {
      console.error('Polling error:', error);
    }
    
    if (this.isRunning) {
      const interval = this.calculateInterval();
      console.log(`Next poll in ${interval}ms (${this.connectionInfo.effectiveType})`);
      this.timeoutId = setTimeout(() => this.poll(), interval);
    }
  }
}

// Usage
const networkPoller = new NetworkAwarePoller('https://api.example.com/data', {
  baseInterval: 5000,
  onData: data => console.log('Data:', data)
});

networkPoller.start();
```

### Coordinated Multi-Resource Polling

#### Poll Multiple Endpoints in Sequence

```javascript
class CoordinatedPoller {
  constructor(endpoints, options = {}) {
    this.endpoints = endpoints; // Array of {url, key}
    this.interval = options.interval || 10000;
    this.onComplete = options.onComplete || (() => {});
    this.onError = options.onError || (() => {});
    this.isRunning = false;
    this.timeoutId = null;
  }
  
  start() {
    if (this.isRunning) return;
    this.isRunning = true;
    this.poll();
  }
  
  stop() {
    this.isRunning = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }
  
  async poll() {
    if (!this.isRunning) return;
    
    const results = {};
    const errors = {};
    
    for (const endpoint of this.endpoints) {
      try {
        const response = await fetch(endpoint.url);
        if (response.ok) {
          results[endpoint.key] = await response.json();
        } else {
          errors[endpoint.key] = `HTTP ${response.status}`;
        }
      } catch (error) {
        errors[endpoint.key] = error.message;
      }
    }
    
    if (Object.keys(errors).length > 0) {
      this.onError(errors, results);
    }
    
    this.onComplete(results, errors);
    
    if (this.isRunning) {
      this.timeoutId = setTimeout(() => this.poll(), this.interval);
    }
  }
}

// Usage
const coordinated = new CoordinatedPoller([
  { url: 'https://api.example.com/user', key: 'user' },
  { url: 'https://api.example.com/notifications', key: 'notifications' },
  { url: 'https://api.example.com/settings', key: 'settings' }
], {
  interval: 15000,
  onComplete: (results, errors) => {
    console.log('Poll complete:', results);
    if (Object.keys(errors).length > 0) {
      console.error('Some requests failed:', errors);
    }
  }
});

coordinated.start();
```

---

# Performance Optimization

## Request Batching

### Batching Multiple Requests

Request batching consolidates multiple API calls into a single HTTP request, reducing network overhead and improving performance. Instead of executing sequential fetch calls, you group them together and send them as one payload.

```javascript
const batchRequest = async (requests) => {
  const response = await fetch('/api/batch', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ requests })
  });
  return response.json();
};

const requests = [
  { method: 'GET', url: '/users/1' },
  { method: 'GET', url: '/posts/5' },
  { method: 'POST', url: '/comments', body: { text: 'Hello' } }
];

const results = await batchRequest(requests);
```

### Queue-Based Batching

Implement a queue that collects requests over a time window before sending them together. This pattern is particularly effective for high-frequency operations.

```javascript
class BatchQueue {
  constructor(batchSize = 10, flushInterval = 100) {
    this.queue = [];
    this.batchSize = batchSize;
    this.flushInterval = flushInterval;
    this.timer = null;
    this.pendingPromises = [];
  }

  add(request) {
    return new Promise((resolve, reject) => {
      this.queue.push(request);
      this.pendingPromises.push({ resolve, reject });

      if (this.queue.length >= this.batchSize) {
        this.flush();
      } else if (!this.timer) {
        this.timer = setTimeout(() => this.flush(), this.flushInterval);
      }
    });
  }

  async flush() {
    if (this.timer) {
      clearTimeout(this.timer);
      this.timer = null;
    }

    if (this.queue.length === 0) return;

    const batch = this.queue.splice(0);
    const promises = this.pendingPromises.splice(0);

    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ requests: batch })
      });

      const results = await response.json();

      results.forEach((result, index) => {
        if (result.error) {
          promises[index].reject(new Error(result.error));
        } else {
          promises[index].resolve(result.data);
        }
      });
    } catch (error) {
      promises.forEach(p => p.reject(error));
    }
  }
}

const queue = new BatchQueue();
const userData = await queue.add({ method: 'GET', url: '/users/1' });
const postData = await queue.add({ method: 'GET', url: '/posts/5' });
```

### DataLoader Pattern

DataLoader provides request batching and caching for GraphQL and REST APIs, coalescing requests within a single frame of execution.

```javascript
class DataLoader {
  constructor(batchLoadFn, options = {}) {
    this.batchLoadFn = batchLoadFn;
    this.cache = options.cache !== false;
    this.cacheMap = new Map();
    this.queue = [];
    this.scheduled = false;
  }

  load(key) {
    if (this.cache && this.cacheMap.has(key)) {
      return Promise.resolve(this.cacheMap.get(key));
    }

    return new Promise((resolve, reject) => {
      this.queue.push({ key, resolve, reject });

      if (!this.scheduled) {
        this.scheduled = true;
        process.nextTick(() => this.dispatch());
      }
    });
  }

  async dispatch() {
    this.scheduled = false;
    const queue = this.queue.splice(0);
    const keys = queue.map(q => q.key);

    try {
      const values = await this.batchLoadFn(keys);

      queue.forEach((item, index) => {
        const value = values[index];
        if (this.cache) {
          this.cacheMap.set(item.key, value);
        }
        item.resolve(value);
      });
    } catch (error) {
      queue.forEach(item => item.reject(error));
    }
  }

  clear(key) {
    this.cacheMap.delete(key);
  }

  clearAll() {
    this.cacheMap.clear();
  }
}

const userLoader = new DataLoader(async (ids) => {
  const response = await fetch('/api/users/batch', {
    method: 'POST',
    body: JSON.stringify({ ids })
  });
  return response.json();
});

const user1 = await userLoader.load(1);
const user2 = await userLoader.load(2);
const user3 = await userLoader.load(3);
```

### Promise.all for Parallel Batching

Execute multiple independent requests concurrently using Promise.all, which sends all requests simultaneously rather than sequentially.

```javascript
const fetchMultiple = async (urls) => {
  const requests = urls.map(url => 
    fetch(url).then(res => res.json())
  );
  return Promise.all(requests);
};

const [users, posts, comments] = await fetchMultiple([
  '/api/users',
  '/api/posts',
  '/api/comments'
]);
```

### Promise.allSettled for Error-Tolerant Batching

When you need all requests to complete regardless of individual failures, Promise.allSettled ensures partial success handling.

```javascript
const fetchAllSettled = async (urls) => {
  const requests = urls.map(url =>
    fetch(url)
      .then(res => res.json())
      .catch(err => ({ error: err.message }))
  );
  return Promise.allSettled(requests);
};

const results = await fetchAllSettled([
  '/api/users',
  '/api/posts',
  '/api/invalid-endpoint'
]);

results.forEach((result, index) => {
  if (result.status === 'fulfilled') {
    console.log(`Request ${index} succeeded:`, result.value);
  } else {
    console.log(`Request ${index} failed:`, result.reason);
  }
});
```

### Chunked Batching

Split large batches into smaller chunks to avoid payload size limits or timeout issues.

```javascript
const chunkArray = (array, size) => {
  const chunks = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
};

const batchWithChunking = async (items, chunkSize = 50) => {
  const chunks = chunkArray(items, chunkSize);
  const results = [];

  for (const chunk of chunks) {
    const response = await fetch('/api/batch', {
      method: 'POST',
      body: JSON.stringify({ items: chunk })
    });
    const data = await response.json();
    results.push(...data);
  }

  return results;
};

const allResults = await batchWithChunking(largeItemArray, 100);
```

### Concurrent Chunk Processing

Process multiple chunks simultaneously while limiting concurrency to prevent overwhelming the server.

```javascript
const batchWithConcurrency = async (items, chunkSize = 50, maxConcurrent = 3) => {
  const chunks = chunkArray(items, chunkSize);
  const results = [];

  for (let i = 0; i < chunks.length; i += maxConcurrent) {
    const batch = chunks.slice(i, i + maxConcurrent);
    const batchResults = await Promise.all(
      batch.map(chunk =>
        fetch('/api/batch', {
          method: 'POST',
          body: JSON.stringify({ items: chunk })
        }).then(res => res.json())
      )
    );
    results.push(...batchResults.flat());
  }

  return results;
};
```

### Debounced Batching

Delay batch execution until a quiet period occurs, useful for user-triggered actions like search queries or form inputs.

```javascript
class DebouncedBatcher {
  constructor(batchFn, delay = 300) {
    this.batchFn = batchFn;
    this.delay = delay;
    this.queue = [];
    this.timer = null;
    this.pending = [];
  }

  add(item) {
    return new Promise((resolve, reject) => {
      this.queue.push(item);
      this.pending.push({ resolve, reject });

      clearTimeout(this.timer);
      this.timer = setTimeout(() => this.execute(), this.delay);
    });
  }

  async execute() {
    if (this.queue.length === 0) return;

    const items = this.queue.splice(0);
    const promises = this.pending.splice(0);

    try {
      const results = await this.batchFn(items);
      results.forEach((result, index) => {
        promises[index].resolve(result);
      });
    } catch (error) {
      promises.forEach(p => p.reject(error));
    }
  }
}

const searchBatcher = new DebouncedBatcher(async (queries) => {
  const response = await fetch('/api/search/batch', {
    method: 'POST',
    body: JSON.stringify({ queries })
  });
  return response.json();
}, 300);

// User types quickly - only last batch executes
searchBatcher.add('ap');
searchBatcher.add('app');
searchBatcher.add('appl');
const results = await searchBatcher.add('apple');
```

### Adaptive Batching

Dynamically adjust batch size based on response times and error rates to optimize throughput.

```javascript
class AdaptiveBatcher {
  constructor(minBatch = 5, maxBatch = 100) {
    this.minBatch = minBatch;
    this.maxBatch = maxBatch;
    this.currentBatch = minBatch;
    this.queue = [];
    this.pending = [];
    this.metrics = { successes: 0, failures: 0, avgTime: 0 };
  }

  adjustBatchSize() {
    const successRate = this.metrics.successes / 
      (this.metrics.successes + this.metrics.failures);

    if (successRate > 0.95 && this.metrics.avgTime < 1000) {
      this.currentBatch = Math.min(this.currentBatch * 1.5, this.maxBatch);
    } else if (successRate < 0.8 || this.metrics.avgTime > 2000) {
      this.currentBatch = Math.max(this.currentBatch * 0.75, this.minBatch);
    }

    this.currentBatch = Math.floor(this.currentBatch);
  }

  async add(item) {
    return new Promise((resolve, reject) => {
      this.queue.push(item);
      this.pending.push({ resolve, reject });

      if (this.queue.length >= this.currentBatch) {
        this.flush();
      }
    });
  }

  async flush() {
    if (this.queue.length === 0) return;

    const batch = this.queue.splice(0, this.currentBatch);
    const promises = this.pending.splice(0, this.currentBatch);
    const startTime = Date.now();

    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        body: JSON.stringify({ items: batch })
      });

      const results = await response.json();
      const duration = Date.now() - startTime;

      this.metrics.successes++;
      this.metrics.avgTime = (this.metrics.avgTime + duration) / 2;

      results.forEach((result, index) => {
        promises[index].resolve(result);
      });
    } catch (error) {
      this.metrics.failures++;
      promises.forEach(p => p.reject(error));
    }

    this.adjustBatchSize();
  }
}
```

### Priority-Based Batching

Process high-priority requests before low-priority ones while still maintaining batching efficiency.

```javascript
class PriorityBatcher {
  constructor() {
    this.queues = {
      high: [],
      normal: [],
      low: []
    };
    this.pending = new Map();
    this.processing = false;
  }

  add(item, priority = 'normal') {
    return new Promise((resolve, reject) => {
      const id = Math.random();
      this.queues[priority].push({ id, item });
      this.pending.set(id, { resolve, reject });

      if (!this.processing) {
        this.process();
      }
    });
  }

  async process() {
    this.processing = true;

    while (this.hasItems()) {
      const batch = this.getNextBatch();
      
      try {
        const items = batch.map(b => b.item);
        const response = await fetch('/api/batch', {
          method: 'POST',
          body: JSON.stringify({ items })
        });

        const results = await response.json();

        batch.forEach((item, index) => {
          const pending = this.pending.get(item.id);
          pending.resolve(results[index]);
          this.pending.delete(item.id);
        });
      } catch (error) {
        batch.forEach(item => {
          const pending = this.pending.get(item.id);
          pending.reject(error);
          this.pending.delete(item.id);
        });
      }
    }

    this.processing = false;
  }

  hasItems() {
    return this.queues.high.length > 0 ||
           this.queues.normal.length > 0 ||
           this.queues.low.length > 0;
  }

  getNextBatch(maxSize = 10) {
    const batch = [];

    while (batch.length < maxSize && this.hasItems()) {
      if (this.queues.high.length > 0) {
        batch.push(this.queues.high.shift());
      } else if (this.queues.normal.length > 0) {
        batch.push(this.queues.normal.shift());
      } else if (this.queues.low.length > 0) {
        batch.push(this.queues.low.shift());
      }
    }

    return batch;
  }
}

const batcher = new PriorityBatcher();
await batcher.add({ action: 'update' }, 'high');
await batcher.add({ action: 'log' }, 'low');
```

### GraphQL Query Batching

Combine multiple GraphQL queries into a single HTTP request, reducing roundtrips for applications making numerous small queries.

```javascript
const batchGraphQLQueries = async (queries) => {
  const response = await fetch('/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(queries)
  });

  return response.json();
};

const queries = [
  { query: '{ user(id: 1) { name email } }' },
  { query: '{ posts(limit: 10) { title author } }' },
  { query: '{ comments(postId: 5) { text user } }' }
];

const results = await batchGraphQLQueries(queries);
```

### Retry Logic for Failed Batches

Implement exponential backoff and selective retry for failed batch requests.

```javascript
class RetryBatcher {
  constructor(maxRetries = 3, baseDelay = 1000) {
    this.maxRetries = maxRetries;
    this.baseDelay = baseDelay;
  }

  async executeBatch(items, retryCount = 0) {
    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        body: JSON.stringify({ items })
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      return await response.json();
    } catch (error) {
      if (retryCount < this.maxRetries) {
        const delay = this.baseDelay * Math.pow(2, retryCount);
        await new Promise(resolve => setTimeout(resolve, delay));
        return this.executeBatch(items, retryCount + 1);
      }
      throw error;
    }
  }

  async executeWithPartialRetry(items) {
    try {
      return await this.executeBatch(items);
    } catch (error) {
      // Retry failed items individually
      const results = [];
      for (const item of items) {
        try {
          const result = await this.executeBatch([item]);
          results.push(result[0]);
        } catch (err) {
          results.push({ error: err.message, item });
        }
      }
      return results;
    }
  }
}
```

### Response Aggregation Patterns

Handle different response formats and aggregate results appropriately.

```javascript
const aggregateBatchResponses = async (requests) => {
  const response = await fetch('/api/batch', {
    method: 'POST',
    body: JSON.stringify({ requests })
  });

  const results = await response.json();

  return {
    successful: results.filter(r => !r.error),
    failed: results.filter(r => r.error),
    byType: results.reduce((acc, r) => {
      const type = r.type || 'unknown';
      if (!acc[type]) acc[type] = [];
      acc[type].push(r);
      return acc;
    }, {}),
    summary: {
      total: results.length,
      succeeded: results.filter(r => !r.error).length,
      failed: results.filter(r => r.error).length
    }
  };
};
```

### Server-Side Batch Processing

Backend implementation to handle batched requests efficiently.

```javascript
// Express.js example
app.post('/api/batch', async (req, res) => {
  const { requests } = req.body;
  
  const results = await Promise.allSettled(
    requests.map(async (request) => {
      try {
        switch (request.method) {
          case 'GET':
            return await handleGet(request.url);
          case 'POST':
            return await handlePost(request.url, request.body);
          case 'PUT':
            return await handlePut(request.url, request.body);
          case 'DELETE':
            return await handleDelete(request.url);
          default:
            throw new Error(`Unsupported method: ${request.method}`);
        }
      } catch (error) {
        return { error: error.message };
      }
    })
  );

  const formatted = results.map(result => {
    if (result.status === 'fulfilled') {
      return { data: result.value };
    } else {
      return { error: result.reason.message };
    }
  });

  res.json(formatted);
});
```

### Cache-Aware Batching

Check cache before batching requests, only fetching uncached data.

```javascript
class CachingBatcher {
  constructor() {
    this.cache = new Map();
    this.queue = [];
    this.pending = new Map();
  }

  async get(key) {
    if (this.cache.has(key)) {
      return this.cache.get(key);
    }

    return new Promise((resolve, reject) => {
      const id = Math.random();
      this.queue.push({ id, key });
      this.pending.set(id, { resolve, reject, key });

      setTimeout(() => this.flush(), 10);
    });
  }

  async flush() {
    if (this.queue.length === 0) return;

    const batch = this.queue.splice(0);
    const keys = batch.map(b => b.key);

    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        body: JSON.stringify({ keys })
      });

      const results = await response.json();

      batch.forEach((item, index) => {
        const result = results[index];
        this.cache.set(item.key, result);
        
        const pending = this.pending.get(item.id);
        pending.resolve(result);
        this.pending.delete(item.id);
      });
    } catch (error) {
      batch.forEach(item => {
        const pending = this.pending.get(item.id);
        pending.reject(error);
        this.pending.delete(item.id);
      });
    }
  }

  invalidate(key) {
    this.cache.delete(key);
  }
}
```

---

## Payload Compression

### Request Payload Compression

#### Manual Compression

The Fetch API does not automatically compress request bodies. Compression must be implemented manually by transforming the payload before sending.

**Using CompressionStream API**

```javascript
async function compressPayload(data) {
  const blob = new Blob([JSON.stringify(data)]);
  const stream = blob.stream().pipeThrough(
    new CompressionStream('gzip')
  );
  return new Response(stream).blob();
}

const payload = { large: 'data', array: [...] };
const compressed = await compressPayload(payload);

await fetch('/api/endpoint', {
  method: 'POST',
  headers: {
    'Content-Encoding': 'gzip',
    'Content-Type': 'application/json'
  },
  body: compressed
});
```

**Compression Formats**

The CompressionStream API supports three formats:

- `gzip` - Most widely supported, good compression ratio
- `deflate` - Similar to gzip, less common
- `deflate-raw` - Raw DEFLATE without headers

#### Setting Content-Encoding Header

The `Content-Encoding` header informs the server about the compression applied to the request body.

```javascript
fetch('/api/data', {
  method: 'POST',
  headers: {
    'Content-Encoding': 'gzip',
    'Content-Type': 'application/json'
  },
  body: compressedData
});
```

**Important considerations:**

- The header value must match the actual compression algorithm used
- Multiple encodings can be specified in order of application: `Content-Encoding: gzip, br`
- The server must support the specified encoding scheme

#### Server Requirements

Server-side decompression requirements:

- Server must recognize and process `Content-Encoding` header
- Server must have decompression capabilities for the specified algorithm
- Many servers (Node.js, nginx, Apache) support automatic decompression
- Some frameworks require explicit middleware configuration

**Node.js Express example:**

```javascript
app.use(express.json({
  inflate: true  // Automatically decompress gzip/deflate
}));
```

#### When to Compress Requests

Compression trade-offs:

**Benefits:**

- Reduced bandwidth usage
- Faster transmission over slow networks
- Lower data transfer costs

**Costs:**

- CPU overhead for compression
- Processing time on both client and server
- Added complexity

**Recommended for:**

- Payloads larger than 1-2 KB
- Slow or metered network connections
- Highly compressible data (text, JSON, XML)

**Not recommended for:**

- Small payloads (< 1 KB) - overhead exceeds savings
- Already compressed data (images, videos, compressed files)
- Fast local networks
- Resource-constrained devices

### Response Payload Compression

#### Automatic Decompression

Modern browsers automatically handle response decompression when servers send compressed content.

```javascript
// Server sends: Content-Encoding: gzip
const response = await fetch('/api/data');
const data = await response.json();  // Automatically decompressed
```

The browser:

1. Reads the `Content-Encoding` response header
2. Identifies the compression algorithm(s)
3. Automatically decompresses the response body
4. Provides decompressed data to JavaScript

**No manual decompression needed** - this is handled transparently by the browser's network layer.

#### Accept-Encoding Header

The browser automatically sends `Accept-Encoding` to indicate supported compression algorithms:

```
Accept-Encoding: gzip, deflate, br
```

**Default behavior:**

- Browsers send this header automatically
- Cannot be modified via Fetch API for security reasons
- Indicates client support for `gzip`, `deflate`, and `br` (Brotli)

[Unverified: Browser-specific variations may exist in which compression algorithms are advertised]

#### Brotli Compression

Brotli (`br`) is a modern compression algorithm offering better compression ratios than gzip.

**Advantages:**

- 15-25% better compression than gzip for text content
- Supported by all modern browsers
- Particularly effective for static assets

**Server configuration:**

- Must be explicitly enabled on most servers
- Requires Brotli library installation
- Can be configured with different compression levels (0-11)

**nginx example:**

```nginx
brotli on;
brotli_comp_level 6;
brotli_types text/plain text/css application/json application/javascript;
```

**Browser support:**

- Chrome/Edge 50+
- Firefox 44+
- Safari 11+

#### Content-Encoding vs Transfer-Encoding

Two different compression mechanisms exist in HTTP:

**Content-Encoding:**

- Compression applied to the resource itself
- Persists through caching
- Specified in `Content-Encoding` header
- Examples: `gzip`, `br`, `deflate`

**Transfer-Encoding:**

- Compression applied to the message during transmission
- Not cached, removed by intermediaries
- Specified in `Transfer-Encoding` header
- Most common value: `chunked`
- `Transfer-Encoding: gzip` is deprecated

**Key differences:**

|Aspect|Content-Encoding|Transfer-Encoding|
|---|---|---|
|Purpose|Resource compression|Message framing|
|Caching|Cached compressed|Not cached|
|Visibility|Visible to application|Transparent hop-by-hop|
|Common use|Compression|Chunked streaming|

### Performance Considerations

#### Compression Ratio Analysis

Different content types achieve varying compression ratios:

**Highly compressible (70-90% reduction):**

- JSON with repetitive structure
- XML documents
- HTML pages
- Plain text
- CSV files

**Moderately compressible (40-70% reduction):**

- JavaScript source code
- CSS stylesheets
- SVG graphics

**Poorly compressible (< 20% reduction):**

- Already compressed formats (JPEG, PNG, MP4, ZIP)
- Encrypted data
- Random or binary data
- Small payloads with high entropy

#### Size Threshold Optimization

Optimal compression strategies by payload size:

**< 500 bytes:**

- Compression overhead exceeds benefits
- HTTP headers may be larger than payload
- Skip compression

**500 bytes - 1 KB:**

- Marginal benefits
- Consider only for text-heavy content
- Test actual transmission time

**1-10 KB:**

- Good candidate for compression
- Significant bandwidth savings
- Minimal CPU impact

**> 10 KB:**

- Strong candidate for compression
- Large bandwidth savings
- CPU cost amortized over size

**> 1 MB:**

- Consider streaming compression
- May want to use lower compression levels for speed
- Monitor memory usage

#### Computational Cost

Compression level impact on CPU and compression ratio:

**gzip levels (1-9):**

- Level 1: Fast compression, ~60% ratio
- Level 6 (default): Balanced, ~70% ratio
- Level 9: Slow compression, ~75% ratio

**Recommendation:** Use default levels (6 for gzip, 6-8 for Brotli) unless specific requirements exist.

**Client-side considerations:**

- Mobile devices have limited CPU
- Battery drain from compression
- May block UI if not done in worker

**Server-side considerations:**

- Pre-compress static assets at build time
- Cache compressed responses
- Use reverse proxy compression (nginx, Cloudflare)

#### Network Speed Impact

Compression effectiveness varies with network conditions:

**Slow networks (< 1 Mbps):**

- High compression recommended
- Transmission time dominates
- CPU cost negligible vs transfer time

**Medium networks (1-10 Mbps):**

- Standard compression levels optimal
- Balance compression time and transfer time

**Fast networks (> 100 Mbps):**

- Minimal benefit from compression
- May actually slow down due to compression overhead
- Consider skipping for local/fast connections

### Implementation Patterns

#### Client-Side Request Compression

```javascript
class CompressionClient {
  constructor(threshold = 1024) {
    this.threshold = threshold;
  }

  async compressIfNeeded(data) {
    const json = JSON.stringify(data);
    const size = new Blob([json]).size;
    
    if (size < this.threshold) {
      return {
        body: json,
        headers: { 'Content-Type': 'application/json' }
      };
    }

    const compressed = await this.compress(json);
    return {
      body: compressed,
      headers: {
        'Content-Type': 'application/json',
        'Content-Encoding': 'gzip'
      }
    };
  }

  async compress(text) {
    const blob = new Blob([text]);
    const stream = blob.stream().pipeThrough(
      new CompressionStream('gzip')
    );
    return new Response(stream).blob();
  }

  async post(url, data) {
    const { body, headers } = await this.compressIfNeeded(data);
    
    return fetch(url, {
      method: 'POST',
      headers,
      body
    });
  }
}

// Usage
const client = new CompressionClient(2048);
await client.post('/api/data', largePayload);
```

#### Streaming Compression

For large payloads, use streaming to avoid memory spikes:

```javascript
async function streamingCompress(readableStream) {
  return readableStream.pipeThrough(
    new CompressionStream('gzip')
  );
}

// Compress large file upload
const file = document.querySelector('input[type="file"]').files[0];
const compressed = streamingCompress(file.stream());

await fetch('/upload', {
  method: 'POST',
  headers: {
    'Content-Encoding': 'gzip',
    'Content-Type': file.type
  },
  body: compressed,
  duplex: 'half'  // Required for streaming request bodies
});
```

**Note:** The `duplex: 'half'` option is required when using streaming request bodies.

#### Conditional Compression

Compress based on runtime conditions:

```javascript
async function adaptivePost(url, data) {
  const compressed = await shouldCompress() 
    ? await compressPayload(data)
    : JSON.stringify(data);
  
  const headers = {
    'Content-Type': 'application/json'
  };
  
  if (await shouldCompress()) {
    headers['Content-Encoding'] = 'gzip';
  }
  
  return fetch(url, {
    method: 'POST',
    headers,
    body: compressed
  });
}

async function shouldCompress() {
  // Check network connection
  if ('connection' in navigator) {
    const { effectiveType, saveData } = navigator.connection;
    
    // Don't compress on fast connections
    if (effectiveType === '4g' && !saveData) {
      return false;
    }
    
    // Always compress on slow connections or data saver
    if (effectiveType === 'slow-2g' || effectiveType === '2g' || saveData) {
      return true;
    }
  }
  
  // Default: compress
  return true;
}
```

#### Server Configuration Examples

**Express.js (Node.js):**

```javascript
const compression = require('compression');

app.use(compression({
  filter: (req, res) => {
    if (req.headers['x-no-compression']) {
      return false;
    }
    return compression.filter(req, res);
  },
  level: 6,
  threshold: 1024
}));
```

**nginx:**

```nginx
http {
  gzip on;
  gzip_vary on;
  gzip_min_length 1024;
  gzip_types text/plain text/css text/xml text/javascript 
             application/json application/javascript application/xml+rss;
  gzip_comp_level 6;
  
  # Brotli (if module installed)
  brotli on;
  brotli_comp_level 6;
  brotli_types text/plain text/css application/json 
               application/javascript text/xml application/xml;
}
```

**Apache:**

```apache
<IfModule mod_deflate.c>
  AddOutputFilterByType DEFLATE text/html text/plain text/xml text/css
  AddOutputFilterByType DEFLATE application/javascript application/json
  DeflateCompressionLevel 6
  SetOutputFilter DEFLATE
</IfModule>
```

### Browser Compatibility

#### CompressionStream API

Support for client-side compression:

- Chrome/Edge 80+
- Firefox 113+
- Safari 16.4+

**Fallback detection:**

```javascript
if ('CompressionStream' in window) {
  // Use native compression
  const stream = new CompressionStream('gzip');
} else {
  // Use polyfill or skip compression
  console.warn('CompressionStream not supported');
}
```

#### Polyfills and Libraries

For older browsers:

**pako** - Pure JavaScript implementation:

```javascript
import pako from 'pako';

function compressWithPako(data) {
  const json = JSON.stringify(data);
  const compressed = pako.gzip(json);
  return new Blob([compressed]);
}
```

**fflate** - Fast alternative:

```javascript
import { gzipSync } from 'fflate';

function compressWithFflate(data) {
  const json = JSON.stringify(data);
  const uint8 = new TextEncoder().encode(json);
  const compressed = gzipSync(uint8);
  return new Blob([compressed]);
}
```

### Security Considerations

#### BREACH Attack

Compression can expose encrypted data to timing attacks when:

- Response contains both secret data and attacker-controlled input
- Response is compressed
- Response is sent over HTTPS
- Attacker can make multiple requests

**Mitigation strategies:**

- Separate secret data from user input in responses
- Add random padding to responses
- Disable compression for sensitive endpoints
- Use CSRF tokens that change per request

#### Content-Length Manipulation

Compressed payloads have unpredictable sizes:

- Content-Length header may not reflect actual size
- Can complicate rate limiting based on size
- Monitor both compressed and decompressed sizes

#### Compression Bombs

Malicious payloads that expand significantly:

```javascript
// Server-side protection
app.use(express.json({
  limit: '1mb',  // Limit decompressed size
  inflate: true
}));
```

**Defense:**

- Set maximum decompressed size limits
- Timeout decompression operations
- Monitor memory usage during decompression

### Testing and Debugging

#### Verifying Compression

**Browser DevTools:**

1. Open Network tab
2. Check request/response headers
3. Look for `Content-Encoding` header
4. Compare Size vs Transferred size

**cURL testing:**

```bash
# Test response compression
curl -H "Accept-Encoding: gzip" -I https://example.com

# Test request compression
curl -X POST https://example.com/api \
  -H "Content-Encoding: gzip" \
  -H "Content-Type: application/json" \
  --data-binary @compressed.json.gz
```

#### Measuring Compression Ratios

```javascript
async function measureCompressionRatio(data) {
  const original = new Blob([JSON.stringify(data)]);
  const compressed = await compressPayload(data);
  
  const ratio = (1 - compressed.size / original.size) * 100;
  
  console.log(`Original: ${original.size} bytes`);
  console.log(`Compressed: ${compressed.size} bytes`);
  console.log(`Ratio: ${ratio.toFixed(2)}%`);
  
  return ratio;
}
```

#### Performance Profiling

```javascript
async function profileCompression(data) {
  const start = performance.now();
  
  const compressed = await compressPayload(data);
  
  const compressionTime = performance.now() - start;
  
  const fetchStart = performance.now();
  await fetch('/api/endpoint', {
    method: 'POST',
    body: compressed,
    headers: { 'Content-Encoding': 'gzip' }
  });
  const totalTime = performance.now() - fetchStart;
  
  console.log(`Compression: ${compressionTime.toFixed(2)}ms`);
  console.log(`Total request: ${totalTime.toFixed(2)}ms`);
}
```

### Best Practices

1. **Set reasonable size thresholds** - Don't compress payloads smaller than 1-2 KB
2. **Use appropriate compression levels** - Default levels balance speed and ratio
3. **Pre-compress static assets** - Avoid runtime compression overhead
4. **Cache compressed responses** - Don't recompress the same content repeatedly
5. **Consider network conditions** - Adapt compression strategy to connection speed
6. **Test compression effectiveness** - Measure actual improvements in your use case
7. **Handle compression failures gracefully** - Fall back to uncompressed on errors
8. **Document server requirements** - Ensure backend supports your compression scheme
9. **Monitor decompression costs** - Server-side decompression uses CPU and memory
10. **Use streaming for large payloads** - Avoid loading entire payload into memory

---

## Connection Reuse in Fetch API

### HTTP Connection Mechanics

HTTP connections involve TCP handshakes and, for HTTPS, TLS negotiation. These processes add latency—typically 1-3 round trips before any application data transfers. Connection reuse (HTTP keep-alive or persistent connections) allows multiple requests to share the same TCP connection, eliminating redundant handshakes.

The fetch API doesn't provide direct control over connection reuse. The browser's underlying HTTP client manages connection pooling automatically based on the HTTP protocol version and server support.

### HTTP/1.1 Persistent Connections

HTTP/1.1 enables persistent connections by default through the `Connection: keep-alive` header. After a request completes, the TCP connection remains open for subsequent requests to the same origin.

**Connection pooling behavior:**

- Browsers maintain per-origin connection pools (typically 6-8 connections per origin in HTTP/1.1)
- Connections remain idle for a timeout period (often 60-120 seconds) before closure
- Sequential fetch requests to the same origin automatically reuse available connections

**Limitations:**

- Head-of-line blocking: requests must complete sequentially on each connection
- Connection limits constrain parallelism for HTTP/1.1

```javascript
// These requests will reuse connections from the pool
for (let i = 0; i < 10; i++) {
  fetch('https://api.example.com/data/' + i);
}
// Browser manages connection reuse automatically
```

### HTTP/2 Multiplexing

HTTP/2 fundamentally changes connection reuse through multiplexing. A single TCP connection handles multiple concurrent request/response streams.

**Key characteristics:**

- One connection per origin typically suffices
- Requests and responses interleave at the frame level
- Eliminates head-of-line blocking at the HTTP layer
- Server push capability (though rarely used with fetch)

The fetch API transparently uses HTTP/2 when both browser and server support it. No code changes are required.

```javascript
// All these concurrent requests use the same HTTP/2 connection
Promise.all([
  fetch('https://api.example.com/users'),
  fetch('https://api.example.com/posts'),
  fetch('https://api.example.com/comments')
]);
```

### HTTP/3 and QUIC

HTTP/3 runs over QUIC (UDP-based) instead of TCP. It maintains connection-oriented semantics while reducing connection establishment latency and improving resilience to network changes.

**Benefits for connection reuse:**

- 0-RTT connection resumption for subsequent connections
- Connection migration (survives IP address changes)
- No head-of-line blocking at the transport layer

Browsers automatically negotiate HTTP/3 through Alt-Svc mechanisms. Fetch API usage remains unchanged.

### Connection Pooling Implementation Details

[Inference] Browsers implement connection pools with these typical behaviors:

**Pool organization:**

- Separate pools per origin (protocol + domain + port)
- Subdomain connections don't share pools with parent domains
- Different protocols (HTTP vs HTTPS) use separate pools

**Connection lifecycle:**

- Idle timeout: connections close after inactivity
- Maximum lifetime: connections may refresh after extended use
- Server-directed closure: `Connection: close` header forces termination

**Pool limits:**

- Per-origin concurrent connection limits (HTTP/1.1)
- Global connection limits across all origins
- HTTP/2 typically uses 1 connection per origin

### Request Credentials and Connection Isolation

The `credentials` option affects connection reuse indirectly through connection isolation requirements.

```javascript
fetch('https://api.example.com/data', {
  credentials: 'include'  // Sends cookies
});
```

[Inference] Browsers may partition connection pools based on:

- Cookie state (credentialed vs non-credentialed requests)
- Third-party context isolation
- Privacy partitioning mechanisms (e.g., Firefox's network partitioning)

### Cross-Origin Connection Behavior

Connections are not shared across different origins due to security boundaries.

```javascript
// These use separate connection pools
fetch('https://api.example.com/data');
fetch('https://cdn.example.com/assets');  // Different subdomain
fetch('https://api.example.org/data');    // Different domain
```

Even with CORS-enabled resources, connection pools remain isolated per origin.

### Connection Coalescing in HTTP/2

[Inference] HTTP/2 allows connection coalescing when multiple origins resolve to the same IP address and share a valid TLS certificate covering both domains.

**Requirements for coalescing:**

- Same IP address
- Certificate validity for both origins
- Both origins use HTTPS
- Same HTTP/2 connection settings

This is transparent to fetch API usage but can improve performance for CDNs serving multiple domains from the same infrastructure.

### Keep-Alive Header Manipulation

The fetch API doesn't expose the `Connection` header for modification in requests. Browsers control this automatically.

```javascript
// This attempt is typically ignored or throws an error
fetch('https://api.example.com/data', {
  headers: {
    'Connection': 'close'  // Forbidden header - browser ignores
  }
});
```

The browser prevents direct manipulation of connection management headers to maintain protocol correctness and security.

### Connection Reuse Observability

The fetch API provides no direct visibility into connection reuse. Indirect indicators include:

**Timing information from Performance API:**

```javascript
performance.getEntriesByType('resource')
  .filter(entry => entry.initiatorType === 'fetch')
  .forEach(entry => {
    const connectTime = entry.connectEnd - entry.connectStart;
    // connectTime ≈ 0 suggests connection reuse
    console.log(`${entry.name}: ${connectTime}ms connect time`);
  });
```

A `connectEnd - connectStart` value near zero indicates an existing connection was reused (no TCP handshake occurred).

**TLS timing:**

```javascript
const entry = performance.getEntriesByName('https://api.example.com/data')[0];
const sslTime = entry.requestStart - entry.secureConnectionStart;
// Low sslTime suggests TLS session resumption or connection reuse
```

### Server-Side Connection Management

Server responses influence connection reuse through headers:

**Keep-alive parameters (HTTP/1.1):**

```
Connection: keep-alive
Keep-Alive: timeout=60, max=100
```

The `timeout` indicates how long the server keeps idle connections open; `max` limits requests per connection.

**Connection closure:**

```
Connection: close
```

Forces connection termination after the response completes. Subsequent requests establish new connections.

### Performance Implications

Connection reuse significantly impacts performance metrics:

**Latency reduction:**

- Eliminates TCP handshake (1 round trip, ~10-50ms)
- Eliminates TLS handshake (1-2 round trips, ~50-200ms)
- Cumulative savings for multiple requests

**Resource utilization:**

- Fewer file descriptors and socket buffers
- Reduced CPU overhead from handshake cryptography
- Lower network overhead (fewer SYN/ACK packets)

**Application-level considerations:**

```javascript
// Sequential requests benefit from connection reuse
async function fetchSequential(urls) {
  const results = [];
  for (const url of urls) {
    results.push(await fetch(url));  // Reuses connection
  }
  return results;
}

// Parallel requests may use connection pool
async function fetchParallel(urls) {
  return Promise.all(urls.map(url => fetch(url)));
  // HTTP/1.1: uses multiple pooled connections
  // HTTP/2: multiplexes on single connection
}
```

### Connection Reuse Failures

Connections may not be reused in several scenarios:

**Server-side reasons:**

- Server sends `Connection: close`
- Idle timeout expiration
- Server restart or configuration change
- Maximum requests per connection reached

**Client-side reasons:**

- Connection pool full (HTTP/1.1)
- Browser tab/window closure
- Network change (without HTTP/3 connection migration)
- Connection error or timeout on previous request

**Network-level issues:**

- Proxy or middlebox interference
- NAT timeout
- Firewall state expiration

### Interaction with AbortController

Aborting a fetch request doesn't necessarily close the underlying connection:

```javascript
const controller = new AbortController();

fetch('https://api.example.com/data', {
  signal: controller.signal
});

controller.abort();
// Connection may remain in pool for reuse
```

[Inference] The HTTP client typically keeps the connection alive unless the request was actively transmitting when aborted. The connection returns to the pool after cleanup.

### DNS and Connection Reuse

DNS resolution occurs before connection establishment. Connection reuse bypasses this step:

```javascript
// First request: DNS lookup + connection establishment
await fetch('https://api.example.com/data');

// Subsequent request: reuses connection (no DNS lookup needed)
await fetch('https://api.example.com/more-data');
```

DNS changes between requests don't affect existing connections—they continue to the original IP until closed. New connections use the updated DNS resolution.

### TLS Session Resumption

Separate from TCP connection reuse, TLS session resumption allows abbreviated handshakes on new connections:

**Session ID resumption:**

- Client sends previous session ID
- Server resumes if session still cached
- Reduces TLS handshake to 1 round trip

**Session tickets (RFC 5077):**

- Server sends encrypted session state to client
- Client presents ticket on reconnection
- Eliminates server-side session storage

This is distinct from connection reuse but provides similar latency benefits when connections must be re-established.

### Preconnect and DNS Prefetch

Resource hints can prime connection pools before fetch calls:

```html
<link rel="preconnect" href="https://api.example.com">
<link rel="dns-prefetch" href="https://cdn.example.com">
```

```javascript
// Connection already established from preconnect hint
fetch('https://api.example.com/data');  // Lower latency
```

These hints don't directly control connection reuse but ensure warm connections exist in the pool when fetch executes.

### Service Worker Considerations

Service workers intercept fetch requests before they reach the network layer:

```javascript
// In service worker
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request)
      .then(response => response || fetch(event.request))
  );
});
```

When a service worker calls `fetch()`, that request uses the service worker's connection pool, separate from the page's pool. [Inference] This isolation prevents interference between page and service worker network activity.

### Priority and Connection Allocation

[Inference] Browsers implement request prioritization that affects connection pool usage:

**HTTP/1.1:**

- High-priority requests may preempt connection allocation
- Lower-priority requests wait for available connections

**HTTP/2:**

- Priority frames guide server resource allocation
- All requests share the multiplexed connection

The fetch API's `priority` option (experimental) hints at this:

```javascript
fetch('https://api.example.com/critical', {
  priority: 'high'
});

fetch('https://api.example.com/background', {
  priority: 'low'
});
```

### Connection Warmth and Cold Starts

The state of connections affects performance:

**Warm connections:**

- Already in pool, immediately available
- TCP slow start already ramped up
- Optimal throughput

**Cold connections:**

- Require establishment overhead
- TCP slow start limits initial throughput
- Congestion window grows over time

Long-running applications benefit from keeping connections warm through periodic requests:

```javascript
// Keep-alive pattern
setInterval(() => {
  fetch('https://api.example.com/health', {
    method: 'HEAD'  // Minimal overhead
  }).catch(() => {});  // Ignore errors
}, 30000);  // Every 30 seconds
```

[Unverified] This pattern may help maintain persistent connections, though browsers and servers have their own timeout management that may override such attempts.

---

## DNS Prefetching

### Mechanism

DNS prefetching is a browser optimization technique that performs DNS resolution for domain names before a resource is actually requested. The browser resolves the domain name to an IP address in the background, storing the result in its DNS cache. When the actual request occurs, the DNS lookup phase is eliminated or significantly reduced, decreasing overall latency.

The process operates independently of the critical rendering path. Browsers typically initiate DNS prefetching during idle time or when parsing HTML and encountering links to external domains.

### Implementation Methods

#### Link Tag Declaration

```html
<link rel="dns-prefetch" href="//example.com">
<link rel="dns-prefetch" href="//cdn.example.com">
<link rel="dns-prefetch" href="//api.example.com">
```

The `rel="dns-prefetch"` attribute instructs the browser to resolve the specified domain. The protocol (http/https) is typically omitted, using protocol-relative URLs.

#### HTTP Header

```
Link: <https://example.com>; rel=dns-prefetch
```

DNS prefetch hints can be delivered via HTTP Link headers, useful for dynamically generated pages or when HTML modification is impractical.

#### Dynamic Injection

```javascript
const prefetchLink = document.createElement('link');
prefetchLink.rel = 'dns-prefetch';
prefetchLink.href = '//api.example.com';
document.head.appendChild(prefetchLink);
```

JavaScript can dynamically inject prefetch hints based on user behavior or application state.

### Browser Control Mechanisms

#### Disabling DNS Prefetching

```html
<meta http-equiv="x-dns-prefetch-control" content="off">
```

This meta tag disables automatic DNS prefetching for the entire page. Browsers may still honor explicit `dns-prefetch` link tags.

#### Enabling on HTTPS

```html
<meta http-equiv="x-dns-prefetch-control" content="on">
```

Some browsers disable automatic DNS prefetching on HTTPS pages for privacy reasons. This meta tag re-enables it.

### Automatic Prefetching Behavior

Browsers automatically prefetch DNS for certain elements without explicit hints:

- Anchor tag `href` attributes pointing to external domains
- Link tags for stylesheets, fonts, and other resources
- Image `src` attributes on external domains
- Script `src` attributes

The extent of automatic prefetching varies by browser and may be limited to same-origin or explicitly hinted domains on secure connections.

### Performance Characteristics

#### Latency Reduction

DNS resolution typically adds 20-120ms of latency per unique domain, varying based on:

- Geographic distance to DNS servers
- DNS server response time
- Network conditions
- Cache hit rates at various levels (browser, OS, router, ISP)

Prefetching eliminates this latency for subsequent requests to the prefetched domain.

#### Timing Considerations

DNS prefetching is most effective when:

- Performed early in page load (ideally in the `<head>`)
- Applied to domains that will be used later in the page lifecycle
- The time gap between prefetch and actual request is sufficient for DNS resolution but not so long that cache entries expire

DNS cache entries typically persist for the TTL specified by the authoritative DNS server, commonly ranging from minutes to hours.

### Relationship to fetch API

When using the fetch API to request resources from external domains:

```javascript
// DNS resolution occurs here if not prefetched
fetch('https://api.example.com/data')
  .then(response => response.json())
  .then(data => console.log(data));
```

If `api.example.com` was prefetched:

```html
<link rel="dns-prefetch" href="//api.example.com">
```

The fetch call skips or shortens the DNS resolution phase, reducing the time to first byte.

### Strategic Application Patterns

#### Third-Party Resources

```html
<link rel="dns-prefetch" href="//cdn.jsdelivr.net">
<link rel="dns-prefetch" href="//fonts.googleapis.com">
<link rel="dns-prefetch" href="//www.google-analytics.com">
```

Prefetch domains for analytics, CDNs, font providers, and other third-party services loaded on every page.

#### User Journey Prediction

```html
<!-- On homepage, prefetch likely next destination domains -->
<link rel="dns-prefetch" href="//checkout.example.com">
<link rel="dns-prefetch" href="//cdn-images.example.com">
```

Prefetch domains for pages users are likely to visit next based on analytics or user flow data.

#### Conditional Prefetching

```javascript
if (userIsLoggedIn) {
  const link = document.createElement('link');
  link.rel = 'dns-prefetch';
  link.href = '//api.example.com';
  document.head.appendChild(link);
}
```

Conditionally prefetch based on application state, user authentication status, or other runtime conditions.

#### Lazy-Loaded Content

```html
<link rel="dns-prefetch" href="//images.example.com">
<link rel="dns-prefetch" href="//video-cdn.example.com">
```

Prefetch domains for content that will be lazy-loaded as users scroll or interact.

### Privacy and Security Implications

#### Information Leakage

DNS prefetching can leak information about user intent or page content:

- DNS queries are typically unencrypted (unless using DNS-over-HTTPS/TLS)
- ISPs and network intermediaries can observe which domains are being resolved
- Prefetching domains the user never actually visits reveals potential user interests

#### HTTPS Considerations

Many browsers disable automatic DNS prefetching on HTTPS pages by default to prevent:

- Mixed content issues
- Unintended information disclosure through DNS queries
- Tracking via DNS query patterns

#### User Privacy Controls

Users can disable DNS prefetching entirely through browser settings or extensions. Developers should respect these preferences and not rely on prefetching as critical functionality.

### Interaction with Other Resource Hints

#### Preconnect

```html
<link rel="preconnect" href="https://api.example.com">
```

`preconnect` performs DNS resolution, TCP handshake, and TLS negotiation. It's more aggressive than `dns-prefetch` but more resource-intensive. Use `dns-prefetch` when the connection timing is uncertain; use `preconnect` when a connection will definitely be needed soon.

#### Prefetch

```html
<link rel="prefetch" href="https://example.com/next-page.html">
```

Resource `prefetch` downloads the actual resource. DNS prefetching is a prerequisite for prefetch but operates at a lower level.

#### Prerender

```html
<link rel="prerender" href="https://example.com/next-page.html">
```

`prerender` loads and renders an entire page in the background. DNS prefetching is one of many steps in prerendering.

### Best Practices

#### Limit Prefetch Count

Prefetch only high-priority domains. Excessive prefetching:

- Consumes bandwidth
- Increases DNS server load
- May overwhelm browser DNS resolution queues
- Provides diminishing returns

Typically, 3-6 domains per page is reasonable.

#### Early Placement

Place prefetch hints as early as possible in the `<head>` to maximize the time window for resolution:

```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <link rel="dns-prefetch" href="//cdn.example.com">
  <link rel="dns-prefetch" href="//api.example.com">
  <title>Page Title</title>
  <!-- other head elements -->
</head>
```

#### Avoid Same-Origin Prefetch

DNS prefetching the same origin is unnecessary since the browser has already resolved it. Focus on external domains.

#### Monitor Effectiveness

Use browser DevTools Network timing to measure DNS resolution time:

- Look for DNS lookup duration in the timing breakdown
- Compare pages with and without prefetching
- Verify that prefetched domains show reduced or zero DNS lookup time

### Browser Support and Fallbacks

DNS prefetching is widely supported across modern browsers (Chrome, Firefox, Safari, Edge). Browsers that don't support it simply ignore the hint, making it a progressive enhancement with no fallback required.

The feature degrades gracefully:

- Unsupported browsers perform normal DNS resolution when needed
- Users with privacy settings disabling prefetch experience standard behavior
- Network failures or timeouts don't break functionality

### Edge Cases and Limitations

#### DNS Cache Expiration

If too much time passes between prefetch and usage, the DNS cache entry may expire, negating the benefit. DNS TTLs vary widely (60 seconds to hours).

#### Shared Hosting and CDNs

Prefetching a CDN domain may resolve to one edge server, but the actual request might need a different edge server due to load balancing or geographic routing. The benefit is reduced but not eliminated.

#### Mobile Networks

Mobile networks often have higher DNS resolution latency and more variable performance. DNS prefetching provides greater benefits on mobile but also higher risk of cache expiration due to connection interruptions.

#### Browser Resource Limits

Browsers limit the number of concurrent DNS prefetch operations. Excessive hints may be queued or ignored, reducing effectiveness for lower-priority domains.

### Measurement and Validation

#### Resource Timing API

```javascript
performance.getEntriesByType('resource').forEach(entry => {
  if (entry.name.includes('api.example.com')) {
    console.log('DNS lookup time:', entry.domainLookupEnd - entry.domainLookupStart);
  }
});
```

The Resource Timing API exposes DNS lookup duration, allowing measurement of prefetch effectiveness.

#### Network Panel Analysis

Browser DevTools Network panel displays timing breakdown including:

- DNS Lookup: Time spent resolving the domain
- Initial Connection: TCP handshake time
- SSL: TLS negotiation time

Prefetched domains should show 0ms or minimal DNS lookup time.

---

## Resource Hints for Fetch API Optimization

### DNS Prefetch

DNS prefetch resolves domain names before resources are requested, reducing DNS lookup latency.

```html
<link rel="dns-prefetch" href="https://api.example.com">
```

When the browser encounters this hint, it performs DNS resolution in the background. Later fetch requests to that domain skip the DNS lookup phase.

**Impact on fetch timing:**

- Eliminates DNS lookup time (typically 20-120ms)
- Only affects the first request to a domain
- Subsequent requests use the cached DNS result

**Best practices:**

- Apply to domains used in fetch calls but not referenced in initial HTML
- Most beneficial for third-party API domains
- Low overhead—browsers queue these efficiently

**Limitations:**

- Does not establish TCP connections
- Does not perform TLS handshakes
- Only resolves DNS

### Preconnect

Preconnect performs DNS resolution, TCP handshake, and TLS negotiation before resources are requested.

```html
<link rel="preconnect" href="https://api.example.com">
<link rel="preconnect" href="https://api.example.com" crossorigin>
```

**Connection establishment stages:**

1. DNS resolution
2. TCP connection (SYN, SYN-ACK, ACK)
3. TLS handshake (for HTTPS)

**The `crossorigin` attribute:**

Without `crossorigin`: Opens a connection for same-origin or no-credentials requests.

With `crossorigin`: Opens a connection that includes credentials (cookies, auth headers). Required when fetch requests use `credentials: 'include'` or `credentials: 'same-origin'` (for cross-origin requests).

```javascript
// This fetch requires crossorigin preconnect
fetch('https://api.example.com/data', {
  credentials: 'include'
});
```

**Impact on fetch timing:**

- Eliminates connection setup time (typically 100-500ms for HTTPS)
- Most impactful for first request to a domain
- Connections remain open for reuse (HTTP keep-alive)

**Resource considerations:**

- Each preconnect consumes a socket
- Browsers limit concurrent connections per domain (typically 6)
- Unused connections time out (typically 60-120 seconds)
- More expensive than dns-prefetch

**Best practices:**

- Limit to 4-6 critical domains maximum
- Use for domains where fetch requests are highly likely (>80% probability)
- Prefer for API endpoints called during initial page load
- Consider removing hints for domains that become less critical

**Comparison to dns-prefetch:**

|Metric|dns-prefetch|preconnect|
|---|---|---|
|DNS resolution|✓|✓|
|TCP connection|✗|✓|
|TLS handshake|✗|✓|
|Resource cost|Low|Medium|
|Time saved|20-120ms|100-500ms|

### Prefetch

Prefetch downloads resources during idle time, storing them in HTTP cache for future use.

```html
<link rel="prefetch" href="https://api.example.com/data.json">
<link rel="prefetch" href="https://api.example.com/data.json" as="fetch" crossorigin>
```

**Behavior characteristics:**

- Lowest priority fetch (below all active requests)
- Executes during browser idle time
- Subject to HTTP caching rules
- Does not execute JavaScript or process responses beyond caching

**The `as` attribute:**

Specifies resource type, affecting caching and request headers:

```html
<link rel="prefetch" href="/api/user" as="fetch">
<link rel="prefetch" href="/data.json" as="fetch">
<link rel="prefetch" href="/image.jpg" as="image">
```

When `as="fetch"`, the browser:

- Uses appropriate `Accept` headers
- Respects CORS policies
- Caches according to HTTP headers

**Interaction with Cache API:**

Prefetched resources go into HTTP cache, not Cache API. To use Cache API:

```javascript
// Manual prefetch into Cache API
if ('serviceWorker' in navigator && 'caches' in window) {
  caches.open('api-cache-v1').then(cache => {
    cache.add('/api/data');
  });
}
```

**When prefetch helps fetch calls:**

1. **Navigation prefetch**: User likely to navigate to a page that fetches data

```html
<!-- On page A, prefetch data needed by page B -->
<link rel="prefetch" href="/api/profile">
```

2. **Deferred feature prefetch**: Feature will be used but not immediately

```html
<!-- Prefetch data for modal opened on user action -->
<link rel="prefetch" href="/api/product-details">
```

3. **Predictive prefetch**: Analytics indicate high probability of request

```javascript
// Add prefetch hint dynamically based on user behavior
const link = document.createElement('link');
link.rel = 'prefetch';
link.href = '/api/recommended-products';
link.as = 'fetch';
document.head.appendChild(link);
```

**Cache matching:**

When fetch executes, the browser checks:

1. Memory cache
2. HTTP disk cache (where prefetch stores data)
3. Service Worker cache (if intercepted)

The request must match:

- URL (exactly)
- HTTP method (prefetch uses GET)
- CORS mode
- Credentials mode

**Mismatch scenarios:**

```javascript
// Prefetch executed
// <link rel="prefetch" href="/api/data">

// This matches - uses cache
fetch('/api/data');

// This doesn't match - makes new request
fetch('/api/data', { method: 'POST' });

// This doesn't match - makes new request
fetch('/api/data', { credentials: 'include' });
```

**Best practices:**

- Use for resources with >50% probability of use
- Verify cache headers allow caching (check `Cache-Control`)
- Monitor actual cache hit rates
- Consider data transfer costs (mobile networks)
- Avoid prefetching authenticated endpoints without careful consideration

**Cache validation:**

Prefetched resources still respect cache validation:

```http
Cache-Control: max-age=3600, must-revalidate
ETag: "abc123"
```

Future fetch may trigger conditional request:

```http
If-None-Match: "abc123"
```

Server responds `304 Not Modified` (cache hit) or `200 OK` (cache miss).

### Combining Hints

Hints work in sequence based on resource needs:

**Pattern 1: Connect then prefetch**

```html
<!-- Establish connection first -->
<link rel="preconnect" href="https://api.example.com">
<!-- Then prefetch specific resource -->
<link rel="prefetch" href="https://api.example.com/data.json" as="fetch">
```

[Inference] The connection established by preconnect may be reused by prefetch, though timing depends on when the browser schedules the prefetch operation.

**Pattern 2: Progressive hints**

```html
<!-- For domains where you'll definitely fetch -->
<link rel="preconnect" href="https://critical-api.com" crossorigin>

<!-- For domains you might fetch from -->
<link rel="dns-prefetch" href="https://possible-api.com">

<!-- For specific resources likely needed next -->
<link rel="prefetch" href="https://critical-api.com/next-page-data" as="fetch">
```

**Pattern 3: Conditional prefetch after connection**

```javascript
// Establish connection early
const preconnect = document.createElement('link');
preconnect.rel = 'preconnect';
preconnect.href = 'https://api.example.com';
document.head.appendChild(preconnect);

// Later, based on user behavior, prefetch data
if (userLikelyToNeedData) {
  const prefetch = document.createElement('link');
  prefetch.rel = 'prefetch';
  prefetch.href = 'https://api.example.com/data';
  prefetch.as = 'fetch';
  document.head.appendChild(prefetch);
}
```

### Dynamic Hint Management

Add hints programmatically based on runtime conditions:

```javascript
function addResourceHint(rel, href, options = {}) {
  const link = document.createElement('link');
  link.rel = rel;
  link.href = href;
  
  if (options.as) link.as = options.as;
  if (options.crossorigin) link.crossOrigin = options.crossorigin;
  
  document.head.appendChild(link);
  return link;
}

// Usage
addResourceHint('preconnect', 'https://api.example.com', { 
  crossorigin: 'anonymous' 
});

addResourceHint('prefetch', '/api/next-data', { 
  as: 'fetch' 
});
```

**Removing hints:**

```javascript
// Remove hint when no longer needed
const link = document.querySelector('link[rel="preconnect"][href="https://api.example.com"]');
if (link) {
  link.remove();
}
```

[Inference] Removing a preconnect hint does not immediately close the connection; the browser manages connection lifecycle independently. Removing hints primarily prevents new connections from being opened.

**Intersection Observer pattern:**

Prefetch when user scrolls near content:

```javascript
const observer = new IntersectionObserver((entries) => {
  entries.forEach(entry => {
    if (entry.isIntersecting) {
      const url = entry.target.dataset.prefetchUrl;
      addResourceHint('prefetch', url, { as: 'fetch' });
      observer.unobserve(entry.target);
    }
  });
}, { rootMargin: '200px' });

// Observe elements that will need data
document.querySelectorAll('[data-prefetch-url]').forEach(el => {
  observer.observe(el);
});
```

### Priority Hints

Control fetch priority relative to other resources:

```html
<link rel="prefetch" href="/api/data" fetchpriority="low">
```

```javascript
fetch('/api/critical-data', {
  priority: 'high'
});

fetch('/api/background-data', {
  priority: 'low'
});
```

**Priority values:**

- `high`: Fetch before most other resources
- `low`: Fetch after more critical resources
- `auto`: Browser determines priority (default)

[Unverified] The exact prioritization algorithm and how priority values affect request scheduling varies by browser implementation and may depend on connection availability, current page state, and other factors.

**Prefetch always has low priority**, but `fetchpriority` can adjust within that constraint:

```html
<!-- Even lower priority prefetch -->
<link rel="prefetch" href="/api/data" fetchpriority="low">
```

### Monitoring and Debugging

**Performance Timeline API:**

```javascript
// Observe resource timing
const observer = new PerformanceObserver((list) => {
  list.getEntries().forEach(entry => {
    if (entry.initiatorType === 'fetch') {
      console.log('Fetch timing:', {
        name: entry.name,
        duration: entry.duration,
        dnsTime: entry.domainLookupEnd - entry.domainLookupStart,
        tcpTime: entry.connectEnd - entry.connectStart,
        tlsTime: entry.requestStart - entry.secureConnectionStart,
        waitTime: entry.responseStart - entry.requestStart,
        downloadTime: entry.responseEnd - entry.responseStart
      });
    }
  });
});

observer.observe({ entryTypes: ['resource'] });
```

**Checking cache hits:**

```javascript
fetch('/api/data')
  .then(response => {
    // Check if response came from cache
    const cacheHeader = response.headers.get('age');
    const fromCache = cacheHeader !== null;
    console.log('From cache:', fromCache);
    return response.json();
  });
```

[Inference] The presence of an `Age` header suggests the response came from cache, though this detection method depends on server configuration and may not work in all scenarios.

**Chrome DevTools:**

Network panel shows:

- Prefetch requests marked with "Prefetch" type
- Connection timing breakdown
- Whether DNS/connection was reused
- Cache status (from memory/disk cache)

**Resource Timing breakdown:**

```javascript
performance.getEntriesByType('resource')
  .filter(entry => entry.initiatorType === 'fetch')
  .forEach(entry => {
    const metrics = {
      dns: entry.domainLookupEnd - entry.domainLookupStart,
      tcp: entry.connectEnd - entry.connectStart,
      tls: entry.connectEnd - entry.secureConnectionStart,
      ttfb: entry.responseStart - entry.requestStart,
      download: entry.responseEnd - entry.responseStart,
      total: entry.duration
    };
    
    // Zero DNS/TCP time indicates connection reuse
    if (metrics.dns === 0 && metrics.tcp === 0) {
      console.log('Connection reused for', entry.name);
    }
  });
```

### Security and Privacy Considerations

**CORS requirements:**

Preconnect with credentials requires CORS:

```html
<!-- Requires CORS headers when used -->
<link rel="preconnect" href="https://api.example.com" crossorigin>
```

Server must send:

```http
Access-Control-Allow-Origin: https://your-site.com
Access-Control-Allow-Credentials: true
```

**Privacy implications:**

[Inference] Resource hints may leak information about user navigation intent:

- Prefetch hints reveal expected navigation paths
- DNS prefetch indicates domains user might visit
- Preconnect shows likely future interactions

Some browsers may limit or disable hints in private browsing mode.

**CSP (Content Security Policy):**

Resource hints must comply with CSP directives:

```http
Content-Security-Policy: connect-src 'self' https://api.example.com
```

Preconnect or fetch to other origins will be blocked.

**Timing attacks:**

[Speculation] Prefetch timing could theoretically reveal information about cache state or network topology to malicious scripts, though browsers implement mitigations to reduce timing precision.

### Browser Support and Fallbacks

**Feature detection:**

```javascript
function supportsResourceHint(rel) {
  const link = document.createElement('link');
  return link.relList && link.relList.supports(rel);
}

if (supportsResourceHint('preconnect')) {
  addResourceHint('preconnect', 'https://api.example.com');
} else if (supportsResourceHint('dns-prefetch')) {
  addResourceHint('dns-prefetch', 'https://api.example.com');
}
```

**Graceful degradation:**

Hints are performance optimizations—fetch works without them:

```html
<!-- Enhancement, not requirement -->
<link rel="preconnect" href="https://api.example.com">

<script>
  // Works regardless of hint support
  fetch('https://api.example.com/data')
    .then(response => response.json());
</script>
```

**Cross-browser considerations:**

[Unverified] Different browsers may implement resource hint prioritization, timing, and resource limits differently. Test performance in target browsers to verify benefits.

Safari has historically had more limited support for some hints compared to Chrome/Firefox.

---

## Lazy Loading

### Core Concepts

Lazy loading defers fetching resources until they're needed, reducing initial load time and bandwidth consumption. With the fetch API, this involves triggering requests based on user interaction, viewport visibility, or application state rather than on initial page load.

The primary benefits include:

- Reduced initial bundle size and faster time-to-interactive
- Lower bandwidth usage for users who don't access all content
- Improved perceived performance through progressive content loading
- Better resource prioritization for critical rendering paths

### Implementation Patterns

#### On-Demand Loading

Trigger fetch requests when users explicitly request content:

```javascript
let userData = null;

async function loadUserData() {
  if (userData) return userData;
  
  const response = await fetch('/api/user/profile');
  userData = await response.json();
  return userData;
}

// Only fetches when called
button.addEventListener('click', async () => {
  const data = await loadUserData();
  displayProfile(data);
});
```

#### Intersection Observer Pattern

Load content when elements enter the viewport:

```javascript
const observer = new IntersectionObserver((entries) => {
  entries.forEach(entry => {
    if (entry.isIntersecting) {
      const img = entry.target;
      fetch(img.dataset.src)
        .then(res => res.blob())
        .then(blob => {
          img.src = URL.createObjectURL(blob);
          observer.unobserve(img);
        });
    }
  });
}, { rootMargin: '50px' });

document.querySelectorAll('img[data-src]').forEach(img => {
  observer.observe(img);
});
```

#### Scroll-Based Pagination

Implement infinite scroll with progressive data fetching:

```javascript
let page = 1;
let loading = false;
let hasMore = true;

async function loadMoreItems() {
  if (loading || !hasMore) return;
  
  loading = true;
  const response = await fetch(`/api/items?page=${page}&limit=20`);
  const data = await response.json();
  
  if (data.items.length === 0) {
    hasMore = false;
  } else {
    appendItems(data.items);
    page++;
  }
  
  loading = false;
}

window.addEventListener('scroll', () => {
  const { scrollTop, scrollHeight, clientHeight } = document.documentElement;
  
  if (scrollTop + clientHeight >= scrollHeight - 500) {
    loadMoreItems();
  }
});
```

### Route-Based Code Splitting

#### Dynamic Imports with Fetch

Combine dynamic imports with fetch for component-level lazy loading:

```javascript
const routes = {
  '/dashboard': () => import('./Dashboard.js'),
  '/profile': () => import('./Profile.js'),
  '/settings': () => import('./Settings.js')
};

async function navigate(path) {
  const loadComponent = routes[path];
  if (!loadComponent) return;
  
  // Load component code
  const module = await loadComponent();
  
  // Fetch component data
  const response = await fetch(`/api${path}`);
  const data = await response.json();
  
  // Render with data
  module.default(data);
}
```

#### Preloading Strategies

Anticipate navigation and preload resources:

```javascript
const preloadCache = new Map();

function preloadRoute(path) {
  if (preloadCache.has(path)) return;
  
  const promise = Promise.all([
    import(`./routes${path}.js`),
    fetch(`/api${path}`).then(r => r.json())
  ]);
  
  preloadCache.set(path, promise);
}

// Preload on hover
document.querySelectorAll('a[data-route]').forEach(link => {
  link.addEventListener('mouseenter', () => {
    preloadRoute(link.dataset.route);
  }, { once: true });
});

async function navigateToRoute(path) {
  const [module, data] = await (preloadCache.get(path) || 
    Promise.all([
      import(`./routes${path}.js`),
      fetch(`/api${path}`).then(r => r.json())
    ])
  );
  
  module.default(data);
}
```

### Caching Strategies

#### Memory Caching

Prevent redundant fetches with in-memory storage:

```javascript
class LazyCache {
  constructor() {
    this.cache = new Map();
    this.pending = new Map();
  }
  
  async fetch(url, options = {}) {
    // Return cached data
    if (this.cache.has(url)) {
      return this.cache.get(url);
    }
    
    // Return pending request if already fetching
    if (this.pending.has(url)) {
      return this.pending.get(url);
    }
    
    // Create new fetch request
    const promise = fetch(url, options)
      .then(res => res.json())
      .then(data => {
        this.cache.set(url, data);
        this.pending.delete(url);
        return data;
      })
      .catch(err => {
        this.pending.delete(url);
        throw err;
      });
    
    this.pending.set(url, promise);
    return promise;
  }
  
  invalidate(url) {
    this.cache.delete(url);
  }
  
  clear() {
    this.cache.clear();
    this.pending.clear();
  }
}

const cache = new LazyCache();
```

#### Time-Based Invalidation

Implement stale-while-revalidate pattern:

```javascript
class TTLCache {
  constructor(ttl = 300000) { // 5 minutes default
    this.cache = new Map();
    this.ttl = ttl;
  }
  
  async fetch(url) {
    const cached = this.cache.get(url);
    const now = Date.now();
    
    if (cached && now - cached.timestamp < this.ttl) {
      return cached.data;
    }
    
    // Stale data available, return it while revalidating
    if (cached) {
      this.revalidate(url);
      return cached.data;
    }
    
    // No cache, fetch fresh
    return this.fetchAndCache(url);
  }
  
  async fetchAndCache(url) {
    const response = await fetch(url);
    const data = await response.json();
    
    this.cache.set(url, {
      data,
      timestamp: Date.now()
    });
    
    return data;
  }
  
  async revalidate(url) {
    try {
      await this.fetchAndCache(url);
    } catch (err) {
      console.error('Revalidation failed:', err);
    }
  }
}
```

### Progressive Enhancement

#### Skeleton Screens

Display placeholders while fetching:

```javascript
async function loadContent(containerId, url) {
  const container = document.getElementById(containerId);
  
  // Show skeleton
  container.innerHTML = `
    <div class="skeleton">
      <div class="skeleton-line"></div>
      <div class="skeleton-line"></div>
      <div class="skeleton-line short"></div>
    </div>
  `;
  
  try {
    const response = await fetch(url);
    const data = await response.json();
    
    // Replace with actual content
    container.innerHTML = renderContent(data);
  } catch (err) {
    container.innerHTML = '<div class="error">Failed to load content</div>';
  }
}
```

#### Prioritized Loading

Load critical content first, defer secondary content:

```javascript
async function loadPage() {
  // Critical: Load immediately
  const criticalPromises = [
    fetch('/api/hero').then(r => r.json()),
    fetch('/api/navigation').then(r => r.json())
  ];
  
  const [hero, nav] = await Promise.all(criticalPromises);
  renderHero(hero);
  renderNav(nav);
  
  // Secondary: Load after critical content
  requestIdleCallback(async () => {
    const [sidebar, footer] = await Promise.all([
      fetch('/api/sidebar').then(r => r.json()),
      fetch('/api/footer').then(r => r.json())
    ]);
    
    renderSidebar(sidebar);
    renderFooter(footer);
  });
  
  // Tertiary: Load on interaction
  setupLazyLoadingForBelow();
}
```

### Error Handling and Fallbacks

#### Retry Mechanisms

Implement exponential backoff for failed lazy loads:

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  let lastError;
  
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      return await response.json();
    } catch (err) {
      lastError = err;
      
      if (i < maxRetries - 1) {
        const delay = Math.min(1000 * Math.pow(2, i), 10000);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}
```

#### Graceful Degradation

Provide fallback content when lazy loading fails:

```javascript
class LazySection {
  constructor(element) {
    this.element = element;
    this.url = element.dataset.lazyUrl;
    this.fallback = element.dataset.fallback;
    this.loaded = false;
  }
  
  async load() {
    if (this.loaded) return;
    
    try {
      const response = await fetch(this.url);
      const html = await response.text();
      this.element.innerHTML = html;
      this.loaded = true;
    } catch (err) {
      console.error('Lazy load failed:', err);
      
      if (this.fallback) {
        this.element.innerHTML = this.fallback;
      } else {
        this.element.innerHTML = `
          <div class="lazy-error">
            <p>Content unavailable</p>
            <button onclick="this.parentElement.parentElement.reload()">
              Retry
            </button>
          </div>
        `;
      }
    }
  }
  
  reload() {
    this.loaded = false;
    this.load();
  }
}
```

### Performance Optimization

#### Request Batching

Combine multiple lazy-loaded requests:

```javascript
class RequestBatcher {
  constructor(delay = 50) {
    this.queue = [];
    this.delay = delay;
    this.timeout = null;
  }
  
  fetch(url) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, resolve, reject });
      
      clearTimeout(this.timeout);
      this.timeout = setTimeout(() => this.flush(), this.delay);
    });
  }
  
  async flush() {
    if (this.queue.length === 0) return;
    
    const batch = this.queue.splice(0);
    const urls = batch.map(item => item.url);
    
    try {
      const response = await fetch('/api/batch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ urls })
      });
      
      const results = await response.json();
      
      batch.forEach((item, index) => {
        if (results[index].error) {
          item.reject(new Error(results[index].error));
        } else {
          item.resolve(results[index].data);
        }
      });
    } catch (err) {
      batch.forEach(item => item.reject(err));
    }
  }
}

const batcher = new RequestBatcher();
```

#### Resource Hints

Optimize network timing with prefetch/preload:

```javascript
function addResourceHint(href, rel = 'prefetch', as = 'fetch') {
  const link = document.createElement('link');
  link.rel = rel;
  link.href = href;
  if (as) link.as = as;
  document.head.appendChild(link);
}

// Prefetch likely next navigation
function prefetchNextRoutes() {
  const currentRoute = window.location.pathname;
  const nextRoutes = predictNextRoutes(currentRoute);
  
  nextRoutes.forEach(route => {
    addResourceHint(`/api${route}`, 'prefetch');
  });
}

// Preload critical lazy resources
function preloadCriticalResources() {
  const criticalUrls = [
    '/api/user/preferences',
    '/api/critical-data'
  ];
  
  criticalUrls.forEach(url => {
    addResourceHint(url, 'preload', 'fetch');
  });
}
```

#### Connection Optimization

Minimize connection overhead for lazy loads:

```javascript
// Use keep-alive connections
const fetchWithKeepalive = (url, options = {}) => {
  return fetch(url, {
    ...options,
    keepalive: true
  });
};

// Prioritize lazy load requests
const fetchWithPriority = (url, priority = 'low') => {
  return fetch(url, {
    priority // 'high', 'low', or 'auto'
  });
};

// Combine both
async function optimizedLazyFetch(url, options = {}) {
  return fetch(url, {
    keepalive: true,
    priority: options.priority || 'low',
    ...options
  });
}
```

### Testing Strategies

#### Simulating Slow Networks

Test lazy loading under poor conditions:

```javascript
class NetworkThrottle {
  constructor(delay = 1000) {
    this.delay = delay;
    this.originalFetch = window.fetch;
  }
  
  enable() {
    window.fetch = async (...args) => {
      await new Promise(resolve => setTimeout(resolve, this.delay));
      return this.originalFetch(...args);
    };
  }
  
  disable() {
    window.fetch = this.originalFetch;
  }
}

// Usage in tests
const throttle = new NetworkThrottle(3000);
throttle.enable();
```

#### Monitoring Lazy Load Metrics

Track performance of lazy-loaded resources:

```javascript
class LazyLoadMonitor {
  constructor() {
    this.metrics = [];
  }
  
  async trackFetch(url, fetchFn) {
    const start = performance.now();
    const startMark = `lazy-start-${url}`;
    const endMark = `lazy-end-${url}`;
    
    performance.mark(startMark);
    
    try {
      const result = await fetchFn();
      performance.mark(endMark);
      
      const duration = performance.now() - start;
      
      this.metrics.push({
        url,
        duration,
        timestamp: Date.now(),
        success: true
      });
      
      performance.measure(`lazy-${url}`, startMark, endMark);
      
      return result;
    } catch (err) {
      performance.mark(endMark);
      
      this.metrics.push({
        url,
        duration: performance.now() - start,
        timestamp: Date.now(),
        success: false,
        error: err.message
      });
      
      throw err;
    }
  }
  
  getMetrics() {
    return {
      total: this.metrics.length,
      successful: this.metrics.filter(m => m.success).length,
      failed: this.metrics.filter(m => !m.success).length,
      avgDuration: this.metrics.reduce((sum, m) => sum + m.duration, 0) / this.metrics.length
    };
  }
}

const monitor = new LazyLoadMonitor();
```

### Advanced Patterns

#### Predictive Prefetching

Use machine learning or heuristics to predict and prefetch:

```javascript
class PredictivePrefetcher {
  constructor() {
    this.navHistory = [];
    this.patterns = new Map();
  }
  
  recordNavigation(from, to) {
    this.navHistory.push({ from, to, timestamp: Date.now() });
    
    // Build pattern map
    const key = from;
    if (!this.patterns.has(key)) {
      this.patterns.set(key, new Map());
    }
    
    const destinations = this.patterns.get(key);
    destinations.set(to, (destinations.get(to) || 0) + 1);
  }
  
  predictNext(current) {
    const destinations = this.patterns.get(current);
    if (!destinations) return [];
    
    // Sort by frequency
    return Array.from(destinations.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 3)
      .map(([dest]) => dest);
  }
  
  prefetchPredicted(current) {
    const predictions = this.predictNext(current);
    predictions.forEach(route => {
      fetch(`/api${route}`)
        .then(r => r.json())
        .then(data => cache.set(route, data))
        .catch(() => {}); // Silent fail for prefetch
    });
  }
}

const prefetcher = new PredictivePrefetcher();
```

#### Virtual Scrolling

Efficiently render large lists with lazy data fetching:

```javascript
class VirtualList {
  constructor(container, itemHeight, fetchData) {
    this.container = container;
    this.itemHeight = itemHeight;
    this.fetchData = fetchData;
    this.totalItems = 0;
    this.visibleItems = new Map();
    this.buffer = 5;
    
    this.setupScrolling();
  }
  
  setupScrolling() {
    this.container.addEventListener('scroll', () => {
      this.render();
    });
    
    this.render();
  }
  
  async render() {
    const scrollTop = this.container.scrollTop;
    const height = this.container.clientHeight;
    
    const start = Math.floor(scrollTop / this.itemHeight);
    const end = Math.ceil((scrollTop + height) / this.itemHeight);
    
    const startWithBuffer = Math.max(0, start - this.buffer);
    const endWithBuffer = end + this.buffer;
    
    // Fetch data for visible range
    const data = await this.fetchData(startWithBuffer, endWithBuffer);
    
    // Update visible items
    for (let i = startWithBuffer; i < endWithBuffer; i++) {
      if (!this.visibleItems.has(i) && data[i - startWithBuffer]) {
        const element = this.createItem(data[i - startWithBuffer], i);
        this.visibleItems.set(i, element);
        this.container.appendChild(element);
      }
    }
    
    // Remove items outside visible range
    for (const [index, element] of this.visibleItems) {
      if (index < startWithBuffer || index >= endWithBuffer) {
        element.remove();
        this.visibleItems.delete(index);
      }
    }
  }
  
  createItem(data, index) {
    const div = document.createElement('div');
    div.style.position = 'absolute';
    div.style.top = `${index * this.itemHeight}px`;
    div.style.height = `${this.itemHeight}px`;
    div.textContent = data.text;
    return div;
  }
}

// Usage
const list = new VirtualList(
  document.getElementById('list'),
  50,
  async (start, end) => {
    const response = await fetch(`/api/items?start=${start}&end=${end}`);
    return response.json();
  }
);
```

#### Modular Lazy Loading

Component-based lazy loading architecture:

```javascript
class LazyModule {
  constructor(name, loader) {
    this.name = name;
    this.loader = loader;
    this.instance = null;
    this.loading = null;
  }
  
  async load() {
    if (this.instance) return this.instance;
    if (this.loading) return this.loading;
    
    this.loading = Promise.all([
      this.loader.code(),
      this.loader.data?.() || Promise.resolve(null)
    ]).then(([module, data]) => {
      this.instance = new module.default(data);
      this.loading = null;
      return this.instance;
    });
    
    return this.loading;
  }
  
  unload() {
    if (this.instance?.destroy) {
      this.instance.destroy();
    }
    this.instance = null;
  }
}

// Registry
class ModuleRegistry {
  constructor() {
    this.modules = new Map();
  }
  
  register(name, codeLoader, dataLoader) {
    this.modules.set(name, new LazyModule(name, {
      code: codeLoader,
      data: dataLoader
    }));
  }
  
  async load(name) {
    const module = this.modules.get(name);
    if (!module) throw new Error(`Module ${name} not found`);
    return module.load();
  }
  
  unload(name) {
    const module = this.modules.get(name);
    if (module) module.unload();
  }
}

// Usage
const registry = new ModuleRegistry();

registry.register(
  'dashboard',
  () => import('./Dashboard.js'),
  () => fetch('/api/dashboard').then(r => r.json())
);

registry.register(
  'analytics',
  () => import('./Analytics.js'),
  () => fetch('/api/analytics').then(r => r.json())
);

// Load when needed
await registry.load('dashboard');
```

---

## Debouncing and Throttling for Fetch API

### Core Concepts

**Debouncing** delays function execution until after a specified time period has passed since the last invocation. Each new call resets the timer. This ensures the function executes only once after activity stops.

**Throttling** limits function execution to once per specified time interval, regardless of how many times it's called. The first call executes immediately, then subsequent calls are ignored until the interval expires.

### Debouncing Implementation

#### Basic Debounce Function

```javascript
function debounce(func, delay) {
  let timeoutId;
  
  return function(...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => {
      func.apply(this, args);
    }, delay);
  };
}
```

#### Immediate Execution Variant

```javascript
function debounce(func, delay, immediate = false) {
  let timeoutId;
  
  return function(...args) {
    const callNow = immediate && !timeoutId;
    
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => {
      timeoutId = null;
      if (!immediate) {
        func.apply(this, args);
      }
    }, delay);
    
    if (callNow) {
      func.apply(this, args);
    }
  };
}
```

#### Cancelable Debounce

```javascript
function debounce(func, delay) {
  let timeoutId;
  
  const debounced = function(...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => {
      func.apply(this, args);
    }, delay);
  };
  
  debounced.cancel = function() {
    clearTimeout(timeoutId);
  };
  
  return debounced;
}
```

### Throttling Implementation

#### Basic Throttle Function

```javascript
function throttle(func, limit) {
  let inThrottle;
  
  return function(...args) {
    if (!inThrottle) {
      func.apply(this, args);
      inThrottle = true;
      setTimeout(() => {
        inThrottle = false;
      }, limit);
    }
  };
}
```

#### Leading and Trailing Edge Control

```javascript
function throttle(func, limit, options = {}) {
  let timeoutId;
  let lastRan;
  const { leading = true, trailing = true } = options;
  
  return function(...args) {
    const now = Date.now();
    
    if (!lastRan && !leading) {
      lastRan = now;
    }
    
    const remaining = limit - (now - lastRan);
    
    if (remaining <= 0 || remaining > limit) {
      if (timeoutId) {
        clearTimeout(timeoutId);
        timeoutId = null;
      }
      lastRan = now;
      func.apply(this, args);
    } else if (!timeoutId && trailing) {
      timeoutId = setTimeout(() => {
        lastRan = leading ? Date.now() : 0;
        timeoutId = null;
        func.apply(this, args);
      }, remaining);
    }
  };
}
```

### Fetch API Integration Patterns

#### Debounced Search Request

```javascript
const searchAPI = async (query) => {
  const response = await fetch(`/api/search?q=${encodeURIComponent(query)}`);
  return response.json();
};

const debouncedSearch = debounce(searchAPI, 300);

// Usage
searchInput.addEventListener('input', (e) => {
  debouncedSearch(e.target.value)
    .then(results => displayResults(results))
    .catch(err => console.error(err));
});
```

#### Throttled Infinite Scroll

```javascript
const loadMoreItems = async () => {
  const response = await fetch(`/api/items?page=${currentPage}`);
  const items = await response.json();
  appendItems(items);
  currentPage++;
};

const throttledLoad = throttle(loadMoreItems, 1000);

window.addEventListener('scroll', () => {
  if (window.innerHeight + window.scrollY >= document.body.offsetHeight - 500) {
    throttledLoad();
  }
});
```

#### Debounced Autocomplete

```javascript
const fetchSuggestions = async (input) => {
  if (input.length < 2) return [];
  
  const response = await fetch(`/api/autocomplete?q=${encodeURIComponent(input)}`);
  return response.json();
};

const debouncedFetchSuggestions = debounce(async (input) => {
  try {
    const suggestions = await fetchSuggestions(input);
    updateSuggestionsList(suggestions);
  } catch (error) {
    console.error('Autocomplete error:', error);
  }
}, 250);
```

### AbortController Integration

#### Debounced Fetch with Cancellation

```javascript
function createDebouncedFetch(delay) {
  let timeoutId;
  let controller;
  
  return function(url, options = {}) {
    clearTimeout(timeoutId);
    
    if (controller) {
      controller.abort();
    }
    
    controller = new AbortController();
    
    return new Promise((resolve, reject) => {
      timeoutId = setTimeout(async () => {
        try {
          const response = await fetch(url, {
            ...options,
            signal: controller.signal
          });
          resolve(response);
        } catch (error) {
          if (error.name === 'AbortError') {
            reject(new Error('Request cancelled'));
          } else {
            reject(error);
          }
        }
      }, delay);
    });
  };
}

// Usage
const debouncedFetch = createDebouncedFetch(300);

searchInput.addEventListener('input', async (e) => {
  try {
    const response = await debouncedFetch(`/api/search?q=${e.target.value}`);
    const data = await response.json();
    displayResults(data);
  } catch (error) {
    if (error.message !== 'Request cancelled') {
      console.error(error);
    }
  }
});
```

#### Throttled Fetch with Request Queuing

```javascript
function createThrottledFetch(limit) {
  let lastRequest = 0;
  let pendingRequest = null;
  
  return async function(url, options = {}) {
    const now = Date.now();
    const timeSinceLastRequest = now - lastRequest;
    
    if (timeSinceLastRequest >= limit) {
      lastRequest = now;
      return fetch(url, options);
    }
    
    if (pendingRequest) {
      return pendingRequest;
    }
    
    pendingRequest = new Promise((resolve) => {
      setTimeout(() => {
        lastRequest = Date.now();
        pendingRequest = null;
        resolve(fetch(url, options));
      }, limit - timeSinceLastRequest);
    });
    
    return pendingRequest;
  };
}
```

### Advanced Patterns

#### Promise-Aware Debounce

```javascript
function debounceAsync(func, delay) {
  let timeoutId;
  let latestResolve;
  let latestReject;
  
  return function(...args) {
    clearTimeout(timeoutId);
    
    return new Promise((resolve, reject) => {
      latestResolve = resolve;
      latestReject = reject;
      
      timeoutId = setTimeout(async () => {
        try {
          const result = await func.apply(this, args);
          latestResolve(result);
        } catch (error) {
          latestReject(error);
        }
      }, delay);
    });
  };
}

// Usage
const searchAPI = debounceAsync(async (query) => {
  const response = await fetch(`/api/search?q=${query}`);
  return response.json();
}, 300);

// All rapid calls share the same promise result
searchAPI('test').then(data => console.log('Result:', data));
```

#### Rate Limiting with Token Bucket

```javascript
class RateLimitedFetch {
  constructor(tokensPerInterval, interval) {
    this.tokens = tokensPerInterval;
    this.maxTokens = tokensPerInterval;
    this.interval = interval;
    this.queue = [];
    this.refillInterval = setInterval(() => this.refill(), interval);
  }
  
  refill() {
    this.tokens = this.maxTokens;
    this.processQueue();
  }
  
  async fetch(url, options = {}) {
    if (this.tokens > 0) {
      this.tokens--;
      return fetch(url, options);
    }
    
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
    });
  }
  
  processQueue() {
    while (this.tokens > 0 && this.queue.length > 0) {
      this.tokens--;
      const { url, options, resolve, reject } = this.queue.shift();
      fetch(url, options)
        .then(resolve)
        .catch(reject);
    }
  }
  
  destroy() {
    clearInterval(this.refillInterval);
  }
}

// Usage: 5 requests per second
const rateLimitedFetch = new RateLimitedFetch(5, 1000);
```

#### Adaptive Throttling

```javascript
class AdaptiveThrottle {
  constructor(initialDelay, minDelay, maxDelay) {
    this.delay = initialDelay;
    this.minDelay = minDelay;
    this.maxDelay = maxDelay;
    this.successCount = 0;
    this.errorCount = 0;
    this.lastCall = 0;
  }
  
  async fetch(url, options = {}) {
    const now = Date.now();
    const timeSinceLastCall = now - this.lastCall;
    
    if (timeSinceLastCall < this.delay) {
      await new Promise(resolve => 
        setTimeout(resolve, this.delay - timeSinceLastCall)
      );
    }
    
    this.lastCall = Date.now();
    
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        this.onSuccess();
      } else if (response.status === 429) {
        this.onRateLimit();
      } else {
        this.onError();
      }
      
      return response;
    } catch (error) {
      this.onError();
      throw error;
    }
  }
  
  onSuccess() {
    this.successCount++;
    this.errorCount = 0;
    
    if (this.successCount >= 10) {
      this.delay = Math.max(this.minDelay, this.delay * 0.9);
      this.successCount = 0;
    }
  }
  
  onError() {
    this.errorCount++;
    this.successCount = 0;
    
    if (this.errorCount >= 3) {
      this.delay = Math.min(this.maxDelay, this.delay * 1.5);
      this.errorCount = 0;
    }
  }
  
  onRateLimit() {
    this.delay = Math.min(this.maxDelay, this.delay * 2);
    this.errorCount = 0;
    this.successCount = 0;
  }
}
```

### Retry Logic with Exponential Backoff

```javascript
async function fetchWithRetry(url, options = {}, retries = 3) {
  let lastError;
  
  for (let i = 0; i < retries; i++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok || response.status === 404) {
        return response;
      }
      
      if (response.status === 429) {
        const retryAfter = response.headers.get('Retry-After');
        const delay = retryAfter ? parseInt(retryAfter) * 1000 : Math.pow(2, i) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
      
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    } catch (error) {
      lastError = error;
      
      if (i < retries - 1) {
        const delay = Math.pow(2, i) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}

const debouncedFetchWithRetry = debounce(
  (query) => fetchWithRetry(`/api/search?q=${query}`),
  300
);
```

### Handling Concurrent Requests

#### Request Deduplication

```javascript
class RequestDeduplicator {
  constructor() {
    this.pendingRequests = new Map();
  }
  
  async fetch(url, options = {}) {
    const key = this.getKey(url, options);
    
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }
    
    const promise = fetch(url, options)
      .then(response => {
        this.pendingRequests.delete(key);
        return response;
      })
      .catch(error => {
        this.pendingRequests.delete(key);
        throw error;
      });
    
    this.pendingRequests.set(key, promise);
    return promise;
  }
  
  getKey(url, options) {
    return `${options.method || 'GET'}:${url}:${JSON.stringify(options.body || '')}`;
  }
}

const deduplicator = new RequestDeduplicator();
const debouncedFetch = debounce((query) => {
  return deduplicator.fetch(`/api/search?q=${query}`);
}, 300);
```

#### Batching Requests

```javascript
class RequestBatcher {
  constructor(batchFn, delay) {
    this.batchFn = batchFn;
    this.delay = delay;
    this.queue = [];
    this.timeoutId = null;
  }
  
  add(item) {
    return new Promise((resolve, reject) => {
      this.queue.push({ item, resolve, reject });
      
      if (!this.timeoutId) {
        this.timeoutId = setTimeout(() => this.flush(), this.delay);
      }
    });
  }
  
  async flush() {
    if (this.queue.length === 0) return;
    
    const batch = this.queue.splice(0);
    this.timeoutId = null;
    
    try {
      const results = await this.batchFn(batch.map(b => b.item));
      
      batch.forEach((b, index) => {
        b.resolve(results[index]);
      });
    } catch (error) {
      batch.forEach(b => b.reject(error));
    }
  }
}

// Usage
const userBatcher = new RequestBatcher(async (ids) => {
  const response = await fetch('/api/users', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ ids })
  });
  return response.json();
}, 50);

// Multiple calls get batched together
const user1Promise = userBatcher.add(1);
const user2Promise = userBatcher.add(2);
const user3Promise = userBatcher.add(3);
```

### Testing Considerations

#### Mocking Time-Dependent Functions

```javascript
// Using Jest fake timers
jest.useFakeTimers();

test('debounce delays execution', () => {
  const mockFn = jest.fn();
  const debounced = debounce(mockFn, 1000);
  
  debounced('test1');
  debounced('test2');
  debounced('test3');
  
  expect(mockFn).not.toHaveBeenCalled();
  
  jest.advanceTimersByTime(1000);
  
  expect(mockFn).toHaveBeenCalledTimes(1);
  expect(mockFn).toHaveBeenCalledWith('test3');
});

test('throttle limits execution rate', () => {
  const mockFn = jest.fn();
  const throttled = throttle(mockFn, 1000);
  
  throttled('call1');
  throttled('call2');
  throttled('call3');
  
  expect(mockFn).toHaveBeenCalledTimes(1);
  expect(mockFn).toHaveBeenCalledWith('call1');
  
  jest.advanceTimersByTime(1000);
  
  throttled('call4');
  expect(mockFn).toHaveBeenCalledTimes(2);
  expect(mockFn).toHaveBeenCalledWith('call4');
});
```

### Performance Optimization

#### Memory Management

```javascript
function debounce(func, delay) {
  let timeoutId;
  
  const debounced = function(...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => {
      timeoutId = null; // Allow garbage collection
      func.apply(this, args);
    }, delay);
  };
  
  debounced.cancel = function() {
    clearTimeout(timeoutId);
    timeoutId = null;
  };
  
  debounced.flush = function() {
    if (timeoutId) {
      clearTimeout(timeoutId);
      timeoutId = null;
      func.apply(this, arguments);
    }
  };
  
  return debounced;
}
```

#### WeakMap for Instance Methods

```javascript
const debounceMap = new WeakMap();

function debounceMethod(delay) {
  return function(target, propertyKey, descriptor) {
    const originalMethod = descriptor.value;
    
    descriptor.value = function(...args) {
      if (!debounceMap.has(this)) {
        debounceMap.set(this, new Map());
      }
      
      const instanceMap = debounceMap.get(this);
      
      if (!instanceMap.has(propertyKey)) {
        instanceMap.set(propertyKey, debounce(originalMethod.bind(this), delay));
      }
      
      const debouncedFn = instanceMap.get(propertyKey);
      return debouncedFn(...args);
    };
    
    return descriptor;
  };
}

// Usage
class SearchComponent {
  @debounceMethod(300)
  async search(query) {
    const response = await fetch(`/api/search?q=${query}`);
    return response.json();
  }
}
```

### Common Pitfalls

#### Loss of Context

```javascript
// Incorrect: loses 'this' context
class Component {
  constructor() {
    this.name = 'MyComponent';
    this.search = debounce(this.search, 300); // Wrong
  }
  
  search(query) {
    console.log(this.name); // 'this' may be undefined
  }
}

// Correct: preserves 'this' context
class Component {
  constructor() {
    this.name = 'MyComponent';
    this.search = debounce(this.search.bind(this), 300);
  }
  
  search(query) {
    console.log(this.name); // Works correctly
  }
}
```

#### Race Conditions

```javascript
// Problematic: can display stale results
const debouncedSearch = debounce(async (query) => {
  const response = await fetch(`/api/search?q=${query}`);
  const data = await response.json();
  displayResults(data); // May display results out of order
}, 300);

// Better: use abort controller
let currentController = null;

const debouncedSearch = debounce(async (query) => {
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  
  try {
    const response = await fetch(`/api/search?q=${query}`, {
      signal: currentController.signal
    });
    const data = await response.json();
    displayResults(data);
  } catch (error) {
    if (error.name !== 'AbortError') {
      console.error(error);
    }
  }
}, 300);
```

### Library Integration

#### Using Lodash

```javascript
import { debounce, throttle } from 'lodash';

const debouncedFetch = debounce(async (query) => {
  const response = await fetch(`/api/search?q=${query}`);
  return response.json();
}, 300, {
  leading: false,
  trailing: true,
  maxWait: 1000
});

const throttledScroll = throttle(() => {
  loadMoreItems();
}, 1000, {
  leading: true,
  trailing: false
});
```

#### Custom Hook for React

```javascript
function useDebouncedFetch(url, delay) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  
  const debouncedFetch = useMemo(
    () => debounce(async (fetchUrl) => {
      setLoading(true);
      setError(null);
      
      try {
        const response = await fetch(fetchUrl);
        const result = await response.json();
        setData(result);
      } catch (err) {
        setError(err);
      } finally {
        setLoading(false);
      }
    }, delay),
    [delay]
  );
  
  useEffect(() => {
    if (url) {
      debouncedFetch(url);
    }
    
    return () => {
      debouncedFetch.cancel();
    };
  }, [url, debouncedFetch]);
  
  return { data, loading, error };
}
```

---

## Request Prioritization

### Priority Queue Management

The fetch API processes requests through the browser's internal priority queue system. Browsers assign priority levels based on resource type, timing, and explicitly set priority hints. High-priority requests execute before low-priority ones when network connections reach their limit.

### Priority Levels

Modern browsers recognize three explicit priority levels through the `priority` option:

- **high**: Critical resources needed immediately for initial render or user interaction
- **low**: Deferrable resources that don't block rendering or interaction
- **auto**: Browser determines priority based on resource type and context (default)

```javascript
fetch('/critical-api', { priority: 'high' });
fetch('/analytics', { priority: 'low' });
```

### Default Priority Assignment

[Inference] Without explicit priority hints, browsers typically assign priorities based on these patterns:

- **Highest**: HTML documents, synchronous XHR, early fetch requests
- **High**: CSS, fonts requested early, images in viewport
- **Medium**: Scripts, deferred/async scripts
- **Low**: Prefetch requests, images outside viewport
- **Lowest**: Beacon requests, late-discovered resources

### Browser Preconnection and Prefetch

Browsers maintain connection pools with limits per domain (typically 6-8 connections per host). Priority affects which requests consume these limited connections first. Lower-priority requests queue until connections become available.

```javascript
// Preconnect for anticipated high-priority requests
const link = document.createElement('link');
link.rel = 'preconnect';
link.href = 'https://api.example.com';
document.head.appendChild(link);
```

### Priority Hints Standard

The Priority Hints API (`fetchpriority` attribute for HTML elements, `priority` for fetch) provides explicit control:

```javascript
// Boost a critical API call
fetch('/user-session', { 
  priority: 'high',
  credentials: 'include'
});

// Defer non-critical data
fetch('/recommendations', { 
  priority: 'low' 
}).then(response => {
  // Process when bandwidth available
});
```

### Request Ordering Strategies

#### Sequential Critical Path

Execute high-priority requests first, then trigger dependent requests:

```javascript
async function loadCriticalThenDeferred() {
  // Critical data first
  const session = await fetch('/session', { priority: 'high' });
  const userData = await session.json();
  
  // Then lower-priority enhancements
  fetch('/preferences', { priority: 'low' });
  fetch('/suggestions', { priority: 'low' });
}
```

#### Parallel with Priority

Launch multiple requests simultaneously but with different priorities:

```javascript
Promise.all([
  fetch('/essential-data', { priority: 'high' }),
  fetch('/supplemental-data', { priority: 'low' }),
  fetch('/metrics', { priority: 'low' })
]);
```

### Bandwidth-Aware Prioritization

[Inference] Combine Network Information API with priority hints to adapt request strategies:

```javascript
async function adaptiveFetch(url, data) {
  const connection = navigator.connection;
  
  // On slow connections, prioritize more aggressively
  const priority = connection?.effectiveType === '4g' ? 'auto' : 'high';
  
  return fetch(url, {
    priority,
    body: JSON.stringify(data),
    method: 'POST'
  });
}
```

**Disclaimer**: [Unverified] Browser behavior regarding network-aware priority adjustment is not guaranteed and varies by implementation.

### AbortController for Dynamic Prioritization

Cancel lower-priority requests when higher-priority ones arrive:

```javascript
let currentRequest = null;

async function fetchWithCancellation(url, priority) {
  // Cancel previous low-priority request if new high-priority arrives
  if (currentRequest && priority === 'high') {
    currentRequest.abort();
  }
  
  const controller = new AbortController();
  currentRequest = controller;
  
  try {
    return await fetch(url, {
      signal: controller.signal,
      priority
    });
  } catch (err) {
    if (err.name === 'AbortError') {
      console.log('Request cancelled for higher priority');
    }
    throw err;
  }
}
```

### Queue Management Patterns

#### Manual Request Queue

```javascript
class RequestQueue {
  constructor() {
    this.highPriority = [];
    this.lowPriority = [];
    this.active = 0;
    this.maxConcurrent = 6;
  }
  
  async add(url, options = {}) {
    const request = { url, options };
    const queue = options.priority === 'high' 
      ? this.highPriority 
      : this.lowPriority;
    
    queue.push(request);
    return this.process();
  }
  
  async process() {
    if (this.active >= this.maxConcurrent) return;
    
    // Process high-priority first
    const request = this.highPriority.shift() || this.lowPriority.shift();
    if (!request) return;
    
    this.active++;
    
    try {
      const response = await fetch(request.url, request.options);
      return response;
    } finally {
      this.active--;
      this.process(); // Process next queued request
    }
  }
}
```

### Preload and Priority

Combine `<link rel="preload">` with fetchpriority for early resource hints:

```html
<link rel="preload" 
      href="/critical-api-data" 
      as="fetch" 
      fetchpriority="high"
      crossorigin>
```

Then fetch with matching priority:

```javascript
fetch('/critical-api-data', { 
  priority: 'high',
  credentials: 'include' 
});
```

### Service Worker Interception

Service workers can reorder or modify request priorities:

```javascript
// In service worker
self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  // Boost priority for specific endpoints
  if (url.pathname.startsWith('/api/critical')) {
    const modifiedRequest = new Request(event.request, {
      priority: 'high'
    });
    event.respondWith(fetch(modifiedRequest));
    return;
  }
  
  event.respondWith(fetch(event.request));
});
```

**Disclaimer**: [Unverified] Service worker ability to modify request priority may vary by browser implementation.

### Priority Inversion Avoidance

Prevent low-priority requests from blocking high-priority ones:

```javascript
async function fetchWithTimeout(url, options = {}) {
  const timeout = options.priority === 'low' ? 10000 : 5000;
  const controller = new AbortController();
  
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  try {
    return await fetch(url, {
      ...options,
      signal: controller.signal
    });
  } finally {
    clearTimeout(timeoutId);
  }
}
```

### HTTP/2 and HTTP/3 Prioritization

HTTP/2 provides stream prioritization at protocol level. Browsers map fetch priority hints to HTTP/2 stream weights and dependencies:

- High priority: Higher stream weight (e.g., 256)
- Low priority: Lower stream weight (e.g., 16)
- Dependencies: Chain requests to ensure critical resources load first

HTTP/3 (QUIC) uses similar prioritization with extensible priority frames.

### Request Coalescing

Batch multiple low-priority requests to reduce overhead:

```javascript
class RequestBatcher {
  constructor(delay = 100) {
    this.queue = [];
    this.timer = null;
    this.delay = delay;
  }
  
  add(url, options) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      
      if (!this.timer) {
        this.timer = setTimeout(() => this.flush(), this.delay);
      }
    });
  }
  
  async flush() {
    const batch = this.queue.splice(0);
    this.timer = null;
    
    const results = await Promise.allSettled(
      batch.map(({ url, options }) => fetch(url, options))
    );
    
    results.forEach((result, i) => {
      if (result.status === 'fulfilled') {
        batch[i].resolve(result.value);
      } else {
        batch[i].reject(result.reason);
      }
    });
  }
}
```

### Browser Compatibility

Priority hints support varies:

- Chrome/Edge: Full support for `priority` option (Chrome 101+)
- Safari: Partial support (Safari 17.2+)
- Firefox: Under development

[Unverified] Feature detection recommended:

```javascript
const supportsPriority = 'priority' in Request.prototype;

fetch(url, supportsPriority ? { priority: 'high' } : {});
```

### Performance Monitoring

Track how prioritization affects load times:

```javascript
async function fetchWithMetrics(url, options = {}) {
  const start = performance.now();
  const priority = options.priority || 'auto';
  
  try {
    const response = await fetch(url, options);
    const duration = performance.now() - start;
    
    // Log timing by priority
    console.log(`[${priority}] ${url}: ${duration.toFixed(2)}ms`);
    
    return response;
  } catch (err) {
    const duration = performance.now() - start;
    console.error(`[${priority}] ${url} failed after ${duration.toFixed(2)}ms`);
    throw err;
  }
}
```

### Resource Hints Interaction

Priority hints work alongside other resource hints:

```html
<!-- Preconnect with priority -->
<link rel="preconnect" href="https://api.example.com">

<!-- DNS prefetch for low-priority domains -->
<link rel="dns-prefetch" href="https://cdn.example.com">

<!-- Preload critical resources -->
<link rel="preload" href="/api/init" as="fetch" fetchpriority="high">
```

Fetch requests inherit or override these hints:

```javascript
// Uses preconnected socket with high priority
fetch('https://api.example.com/data', { priority: 'high' });
```

---

# Security

## XSS Prevention in Fetch API Contexts

### Response Content Handling

When receiving data through fetch, the primary XSS risk occurs during **output rendering**, not during the fetch operation itself. The fetch API retrieves data as-is; vulnerabilities emerge when that data is inserted into the DOM.

**Critical principle**: Never use `innerHTML`, `outerHTML`, or `document.write()` with fetch responses containing user-generated or untrusted content.

```javascript
// Vulnerable
const response = await fetch('/api/comments');
const data = await response.json();
document.getElementById('container').innerHTML = data.comment; // XSS risk

// Safe
document.getElementById('container').textContent = data.comment;
```

### Content-Type Validation

Always verify response Content-Type headers before processing. Attackers may attempt to serve malicious content types.

```javascript
const response = await fetch('/api/data');
const contentType = response.headers.get('content-type');

if (!contentType || !contentType.includes('application/json')) {
  throw new Error('Invalid content type');
}

const data = await response.json();
```

### DOM Manipulation Strategies

**Safe text insertion**:

- `textContent` - Treats all content as plain text
- `createTextNode()` - Creates text nodes explicitly
- `setAttribute()` - For attribute values (with caveats)

**Controlled HTML rendering**:

```javascript
const data = await fetch('/api/content').then(r => r.json());

// Using DOMParser for HTML responses
const parser = new DOMParser();
const doc = parser.parseFromString(data.html, 'text/html');

// Sanitize before insertion
const sanitized = DOMPurify.sanitize(doc.body.innerHTML);
container.innerHTML = sanitized;
```

### URL Construction and Injection

Fetch URLs constructed from user input require validation:

```javascript
// Vulnerable
const userId = getUserInput();
fetch(`/api/users/${userId}`); // Path traversal or injection risk

// Protected
const userId = getUserInput();
if (!/^[a-zA-Z0-9_-]+$/.test(userId)) {
  throw new Error('Invalid user ID format');
}
fetch(`/api/users/${encodeURIComponent(userId)}`);
```

**URL parameter encoding**:

```javascript
const params = new URLSearchParams();
params.append('search', userInput); // Automatically encodes
params.append('filter', userFilter);

fetch(`/api/search?${params.toString()}`);
```

### JSON Response Processing

JSON responses are inherently safe from XSS **during parsing**, but require sanitization before DOM insertion:

```javascript
const response = await fetch('/api/user');
const user = await response.json();

// Safe: Structured rendering
const nameElement = document.createElement('span');
nameElement.textContent = user.name; // Escaped automatically
container.appendChild(nameElement);

// Unsafe: Direct HTML injection
container.innerHTML = `<span>${user.name}</span>`; // XSS if user.name contains HTML
```

### Template Literal Risks

Template literals in HTML contexts are high-risk:

```javascript
// Vulnerable
const data = await fetch('/api/message').then(r => r.json());
element.innerHTML = `<div class="message">${data.text}</div>`;

// Safe alternatives
const template = document.createElement('template');
template.innerHTML = '<div class="message"></div>';
const messageDiv = template.content.firstChild.cloneNode(true);
messageDiv.textContent = data.text;
element.appendChild(messageDiv);
```

### Sanitization Libraries

For scenarios requiring HTML rendering:

```javascript
// Using DOMPurify
import DOMPurify from 'dompurify';

const response = await fetch('/api/rich-content');
const data = await response.json();

const clean = DOMPurify.sanitize(data.html, {
  ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'a'],
  ALLOWED_ATTR: ['href']
});

container.innerHTML = clean;
```

### Event Handler Attributes

Never construct event handlers from fetch data:

```javascript
// Extremely vulnerable
const response = await fetch('/api/config');
const config = await response.json();
element.setAttribute('onclick', config.handler); // Direct XSS vector

// Safe: Attach listeners programmatically
element.addEventListener('click', () => {
  // Predefined, safe logic only
  handleClick(config.data);
});
```

### CSP Headers Integration

Content Security Policy provides defense-in-depth. When using fetch, ensure your CSP headers are configured:

```javascript
// Server should send:
// Content-Security-Policy: default-src 'self'; script-src 'self'

// Client-side verification (informational only)
const response = await fetch('/api/data');
const csp = response.headers.get('content-security-policy');
console.log('CSP active:', csp);
```

### Dynamic Script Loading Prevention

[Unverified - depends on specific CSP and execution context]: Fetch cannot directly execute scripts, but improper handling can enable script injection:

```javascript
// Vulnerable pattern
const scriptContent = await fetch('/api/script').then(r => r.text());
const script = document.createElement('script');
script.textContent = scriptContent; // Executes arbitrary code
document.body.appendChild(script);

// This pattern should never be used with untrusted sources
```

### Response Type Restrictions

Limit accepted response types:

```javascript
async function safeFetch(url, expectedType = 'json') {
  const response = await fetch(url);
  const contentType = response.headers.get('content-type');
  
  const typeMap = {
    'json': 'application/json',
    'text': 'text/plain',
    'html': 'text/html'
  };
  
  if (!contentType?.includes(typeMap[expectedType])) {
    throw new Error(`Expected ${expectedType}, got ${contentType}`);
  }
  
  return response[expectedType]();
}
```

### Framework-Specific Protections

**React**:

```javascript
function CommentDisplay() {
  const [comment, setComment] = useState('');
  
  useEffect(() => {
    fetch('/api/comment')
      .then(r => r.json())
      .then(data => setComment(data.text));
  }, []);
  
  // React escapes by default
  return <div>{comment}</div>; // Safe
  
  // Dangerous
  // return <div dangerouslySetInnerHTML={{__html: comment}} />; // Requires sanitization
}
```

**Vue**:

```javascript
// Template
<div>{{ comment }}</div> <!-- Safe: auto-escaped -->
<div v-html="comment"></div> <!-- Unsafe: requires sanitization -->

// Script
async mounted() {
  const response = await fetch('/api/comment');
  this.comment = await response.json();
}
```

### Blob and ObjectURL Handling

When creating object URLs from fetched data:

```javascript
const response = await fetch('/api/image');
const blob = await response.blob();
const url = URL.createObjectURL(blob);

// Safe for images
img.src = url;

// Dangerous for HTML blobs in iframes
// iframe.src = url; // Could execute scripts if blob contains HTML
```

### Credential and CORS Implications

While not directly XSS-related, improper credential handling can compound vulnerabilities:

```javascript
// Include credentials only when necessary
fetch('/api/data', {
  credentials: 'include' // Sends cookies - increases impact of XSS
});

// Prefer token-based auth in headers when possible
fetch('/api/data', {
  headers: {
    'Authorization': `Bearer ${token}` // Doesn't auto-send like cookies
  }
});
```

### Response Streaming Considerations

When processing streams, maintain the same sanitization discipline:

```javascript
const response = await fetch('/api/stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  
  // Still requires safe insertion
  const textNode = document.createTextNode(chunk);
  container.appendChild(textNode); // Safe
  
  // container.innerHTML += chunk; // Unsafe
}
```

### Subresource Integrity

For fetching external resources, verify integrity:

```javascript
// When loading third-party content
const response = await fetch('https://cdn.example.com/library.js');
const content = await response.text();

// Verify hash before executing
const hash = await crypto.subtle.digest('SHA-384', 
  new TextEncoder().encode(content));
const base64Hash = btoa(String.fromCharCode(...new Uint8Array(hash)));

if (base64Hash !== expectedHash) {
  throw new Error('Integrity check failed');
}
```

### Input Validation Before Fetch

Validate data before sending to prevent reflected XSS:

```javascript
function validateSearchTerm(term) {
  // Whitelist approach
  if (!/^[a-zA-Z0-9\s-]+$/.test(term)) {
    throw new Error('Invalid search term');
  }
  return term;
}

const searchTerm = validateSearchTerm(userInput);
const response = await fetch(`/api/search?q=${encodeURIComponent(searchTerm)}`);
```

---

## CSRF Protection for Fetch API

### Token-Based Protection

#### Synchronizer Token Pattern

The most common CSRF protection mechanism involves including a unique token in each request that the server validates. When using fetch, tokens are typically embedded in the page and sent with each state-changing request.

```javascript
// Token from meta tag
const csrfToken = document.querySelector('meta[name="csrf-token"]').content;

fetch('/api/resource', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'X-CSRF-Token': csrfToken
  },
  body: JSON.stringify(data)
});
```

#### Token Storage Locations

**Meta Tags**: Most frameworks inject tokens into HTML meta tags for easy JavaScript access.

```html
<meta name="csrf-token" content="abc123xyz">
```

**Hidden Form Fields**: Traditional approach that can be read for fetch requests.

```javascript
const token = document.querySelector('input[name="_csrf"]').value;
```

**Response Headers**: Tokens can be retrieved from initial page load responses and cached.

```javascript
const response = await fetch('/api/init');
const token = response.headers.get('X-CSRF-Token');
// Store for subsequent requests
```

#### Token Rotation

Implementing token rotation requires handling token updates after each request or after specific intervals.

```javascript
let currentToken = document.querySelector('meta[name="csrf-token"]').content;

async function protectedFetch(url, options = {}) {
  const response = await fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-CSRF-Token': currentToken
    }
  });
  
  // Update token if server provides new one
  const newToken = response.headers.get('X-New-CSRF-Token');
  if (newToken) {
    currentToken = newToken;
    document.querySelector('meta[name="csrf-token"]').content = newToken;
  }
  
  return response;
}
```

### Cookie-Based Protection

#### Double Submit Cookie Pattern

The server sets a CSRF token in a cookie, and the client reads it and sends it back in a header. The server compares both values.

```javascript
function getCookie(name) {
  const value = `; ${document.cookie}`;
  const parts = value.split(`; ${name}=`);
  if (parts.length === 2) return parts.pop().split(';').shift();
}

fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': getCookie('csrf_token')
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

#### Encrypted Double Submit

Enhanced security through encryption where the cookie value is encrypted differently from the header value, but both derive from the same secret.

```javascript
// Server sets: csrf_cookie=encryptedValue1
// Client sends: X-CSRF-Token=encryptedValue2
// Server decrypts both and verifies they match the same underlying token

fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': getCookie('xsrf-token')
  },
  credentials: 'include'
});
```

### SameSite Cookie Attribute

Modern browsers support the SameSite attribute which provides built-in CSRF protection by controlling when cookies are sent with cross-site requests.

#### SameSite=Strict

Cookies are only sent with same-site requests, providing strong CSRF protection but potentially breaking legitimate cross-site navigation.

```javascript
// Cookies with SameSite=Strict won't be sent with this fetch from another origin
fetch('https://api.example.com/resource', {
  method: 'POST',
  credentials: 'include'
});
```

#### SameSite=Lax

Cookies are sent with top-level navigation GET requests but not with cross-site POST, PUT, DELETE, or embedded requests.

```javascript
// From different origin:
// GET navigation: cookies sent
// POST via fetch: cookies NOT sent (CSRF protection)

fetch('https://api.example.com/resource', {
  method: 'POST',
  credentials: 'include'
  // Cookies won't be included if SameSite=Lax
});
```

#### SameSite=None with Secure

Required for legitimate cross-site requests. Must be paired with Secure attribute (HTTPS only).

```javascript
// Allow cross-origin requests with cookies
fetch('https://api.example.com/resource', {
  method: 'POST',
  credentials: 'include',
  // Server must set: Set-Cookie: session=abc; SameSite=None; Secure
});
```

### Custom Request Headers

Leveraging the browser's CORS preflight mechanism provides CSRF protection by requiring custom headers that simple forms cannot send.

#### Custom Header Verification

```javascript
fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-Requested-With': 'XMLHttpRequest',
    'Content-Type': 'application/json'
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

The server verifies the presence of the custom header, which cannot be set by a simple HTML form submission from another origin.

#### CORS Preflight Protection

Non-simple requests trigger a preflight, which attackers cannot forge from victim browsers.

```javascript
// This triggers preflight due to custom header
fetch('https://api.example.com/resource', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'X-Custom-Header': 'value'
  },
  credentials: 'include'
});
```

### Origin and Referer Validation

#### Origin Header Checking

The Origin header is automatically added by browsers for cross-origin requests and cannot be modified by JavaScript.

```javascript
// Browser automatically adds Origin header
fetch('https://api.example.com/resource', {
  method: 'POST',
  credentials: 'include'
});

// Server-side validation:
// if (origin !== 'https://trusted-domain.com') reject()
```

#### Referer Header Validation

Less reliable than Origin due to privacy policies that may strip it, but can provide additional verification.

```javascript
fetch('/api/resource', {
  method: 'POST',
  referrerPolicy: 'strict-origin-when-cross-origin'
});

// Server checks Referer matches expected domain
```

### Credential Modes and CSRF

#### credentials: 'same-origin'

Default behavior that prevents cookies from being sent cross-origin, providing inherent CSRF protection for cross-origin scenarios.

```javascript
// Cookies only sent if request is same-origin
fetch('/api/resource', {
  method: 'POST',
  credentials: 'same-origin'
});
```

#### credentials: 'include'

Explicitly includes cookies in cross-origin requests, requiring additional CSRF protection mechanisms.

```javascript
// Vulnerable if no additional CSRF protection
fetch('https://api.example.com/resource', {
  method: 'POST',
  credentials: 'include',
  headers: {
    'X-CSRF-Token': token  // Required!
  }
});
```

#### credentials: 'omit'

Never sends cookies, eliminating CSRF risk but also authentication context.

```javascript
// No CSRF risk, but no authentication
fetch('/api/public-resource', {
  method: 'POST',
  credentials: 'omit'
});
```

### Framework-Specific Implementations

#### Express.js with csurf

```javascript
// Client-side
const csrfToken = document.querySelector('meta[name="csrf-token"]').content;

async function secureRequest(url, data) {
  return fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'CSRF-Token': csrfToken
    },
    credentials: 'same-origin',
    body: JSON.stringify(data)
  });
}
```

#### Django

Django expects the token in the X-CSRFToken header by default.

```javascript
function getCSRFToken() {
  return document.querySelector('[name=csrfmiddlewaretoken]').value ||
         getCookie('csrftoken');
}

fetch('/api/resource/', {
  method: 'POST',
  headers: {
    'X-CSRFToken': getCSRFToken(),
    'Content-Type': 'application/json'
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

#### Rails

Rails uses a token in the meta tag and expects it in the X-CSRF-Token header.

```javascript
const token = document.querySelector('meta[name="csrf-token"]').content;

fetch('/resources', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': token,
    'Content-Type': 'application/json'
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

#### Spring Security

```javascript
const token = document.querySelector('meta[name="_csrf"]').content;
const header = document.querySelector('meta[name="_csrf_header"]').content;

fetch('/api/resource', {
  method: 'POST',
  headers: {
    [header]: token,
    'Content-Type': 'application/json'
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

### Interceptor Patterns

#### Global Fetch Wrapper

Creating a wrapper function that automatically handles CSRF tokens for all requests.

```javascript
const originalFetch = window.fetch;

window.fetch = function(url, options = {}) {
  const csrfToken = document.querySelector('meta[name="csrf-token"]').content;
  
  // Only add CSRF token for state-changing methods
  if (options.method && ['POST', 'PUT', 'PATCH', 'DELETE'].includes(options.method.toUpperCase())) {
    options.headers = {
      ...options.headers,
      'X-CSRF-Token': csrfToken
    };
  }
  
  return originalFetch(url, options);
};
```

#### Fetch Interceptor Class

Object-oriented approach for managing CSRF protection.

```javascript
class FetchInterceptor {
  constructor() {
    this.token = null;
    this.refreshToken();
  }
  
  refreshToken() {
    this.token = document.querySelector('meta[name="csrf-token"]')?.content;
  }
  
  async fetch(url, options = {}) {
    const needsToken = options.method && 
                       ['POST', 'PUT', 'PATCH', 'DELETE'].includes(options.method.toUpperCase());
    
    if (needsToken) {
      options.headers = {
        ...options.headers,
        'X-CSRF-Token': this.token
      };
    }
    
    const response = await fetch(url, options);
    
    // Handle token expiration
    if (response.status === 403) {
      const error = await response.json();
      if (error.code === 'CSRF_TOKEN_INVALID') {
        this.refreshToken();
        // Retry once with new token
        options.headers['X-CSRF-Token'] = this.token;
        return fetch(url, options);
      }
    }
    
    return response;
  }
}

const secureFetch = new FetchInterceptor();
```

### Error Handling

#### CSRF Token Validation Failures

```javascript
async function protectedRequest(url, data) {
  try {
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'X-CSRF-Token': getToken(),
        'Content-Type': 'application/json'
      },
      credentials: 'same-origin',
      body: JSON.stringify(data)
    });
    
    if (response.status === 403) {
      const error = await response.json();
      
      if (error.code === 'CSRF_TOKEN_MISSING') {
        console.error('CSRF token not included in request');
        // Refresh page to get new token
        window.location.reload();
      } else if (error.code === 'CSRF_TOKEN_INVALID') {
        console.error('CSRF token is invalid or expired');
        // Attempt to fetch new token
        await refreshCSRFToken();
        // Retry request
        return protectedRequest(url, data);
      }
    }
    
    return response;
  } catch (error) {
    console.error('Request failed:', error);
    throw error;
  }
}
```

#### Token Expiration Handling

```javascript
async function refreshCSRFToken() {
  const response = await fetch('/api/csrf-token', {
    method: 'GET',
    credentials: 'same-origin'
  });
  
  const { token } = await response.json();
  document.querySelector('meta[name="csrf-token"]').content = token;
  return token;
}

async function fetchWithTokenRefresh(url, options) {
  let response = await fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-CSRF-Token': getToken()
    }
  });
  
  // If token expired, refresh and retry
  if (response.status === 403) {
    await refreshCSRFToken();
    response = await fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'X-CSRF-Token': getToken()
      }
    });
  }
  
  return response;
}
```

### Multi-Tab Synchronization

When users have multiple tabs open, token updates in one tab need to be synchronized with others.

#### localStorage Synchronization

```javascript
// Tab 1: Updates token
function updateCSRFToken(newToken) {
  localStorage.setItem('csrf-token', newToken);
  document.querySelector('meta[name="csrf-token"]').content = newToken;
  
  // Trigger storage event for other tabs
  window.dispatchEvent(new Event('storage'));
}

// All tabs: Listen for updates
window.addEventListener('storage', (e) => {
  if (e.key === 'csrf-token') {
    document.querySelector('meta[name="csrf-token"]').content = e.newValue;
  }
});
```

#### BroadcastChannel API

```javascript
const csrfChannel = new BroadcastChannel('csrf-token-updates');

// Send token update to other tabs
function broadcastTokenUpdate(newToken) {
  csrfChannel.postMessage({ token: newToken });
  document.querySelector('meta[name="csrf-token"]').content = newToken;
}

// Receive token updates from other tabs
csrfChannel.onmessage = (event) => {
  document.querySelector('meta[name="csrf-token"]').content = event.data.token;
};
```

### Testing CSRF Protection

#### Verifying Token Presence

```javascript
// Test helper to verify CSRF token is included
function verifyCSRFProtection(url, options) {
  const headers = new Headers(options.headers);
  const hasCSRFToken = headers.has('X-CSRF-Token') || 
                        headers.has('CSRF-Token');
  
  if (!hasCSRFToken && ['POST', 'PUT', 'PATCH', 'DELETE'].includes(options.method)) {
    console.warn(`CSRF token missing for ${options.method} request to ${url}`);
  }
  
  return fetch(url, options);
}
```

#### Simulating CSRF Attacks

```javascript
// Attempt request without token to verify protection
async function testCSRFProtection() {
  try {
    const response = await fetch('/api/protected-resource', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
        // Intentionally omit CSRF token
      },
      credentials: 'same-origin',
      body: JSON.stringify({ test: 'data' })
    });
    
    if (response.ok) {
      console.error('CSRF protection not working! Request succeeded without token');
    } else if (response.status === 403) {
      console.log('CSRF protection working correctly');
    }
  } catch (error) {
    console.error('Test failed:', error);
  }
}
```

### Security Considerations

#### Token Generation Requirements

CSRF tokens must be cryptographically random, unpredictable, and unique per session or request. Weak token generation undermines the entire protection mechanism.

```javascript
// Client cannot generate secure tokens
// Server must generate: crypto.randomBytes(32).toString('hex')
```

#### Token Lifetime Management

Tokens should expire after a reasonable period or after logout to limit the window of vulnerability.

```javascript
async function checkTokenExpiry() {
  const tokenTimestamp = localStorage.getItem('csrf-token-timestamp');
  const maxAge = 3600000; // 1 hour
  
  if (Date.now() - tokenTimestamp > maxAge) {
    await refreshCSRFToken();
    localStorage.setItem('csrf-token-timestamp', Date.now());
  }
}
```

#### Subdomain Considerations

CSRF protection must account for subdomain attacks where an attacker controls a subdomain of the target domain.

```javascript
// Verify origin matches exactly, not just domain
fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': token
  },
  credentials: 'same-origin'
});

// Server must validate origin precisely:
// Not just: origin.endsWith('example.com')
// But: origin === 'https://app.example.com'
```

#### HTTPS Requirement

CSRF protection relies on secure transmission of tokens. Mixed content or insecure connections can expose tokens to interception.

```javascript
// Ensure all fetch requests use HTTPS in production
const apiUrl = process.env.NODE_ENV === 'production' 
  ? 'https://api.example.com'
  : 'http://localhost:3000';
```

### Integration with Authentication

#### Bearer Tokens vs CSRF

APIs using bearer tokens in Authorization headers are inherently protected from CSRF since attackers cannot access the token.

```javascript
// Bearer token approach - CSRF protection not needed
fetch('/api/resource', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${accessToken}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify(data)
  // Note: credentials: 'same-origin' or 'omit', NOT 'include'
});
```

#### Session Cookies Requiring CSRF

When authentication relies on cookies, CSRF protection is essential.

```javascript
// Cookie-based auth - CSRF protection required
fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': csrfToken,
    'Content-Type': 'application/json'
  },
  credentials: 'include',  // Sends session cookie
  body: JSON.stringify(data)
});
```

#### Hybrid Approaches

Systems using both cookies and tokens need careful design.

```javascript
// Session cookie for auth + CSRF token for protection
fetch('/api/resource', {
  method: 'POST',
  headers: {
    'X-CSRF-Token': csrfToken,
    'Content-Type': 'application/json'
  },
  credentials: 'same-origin',
  body: JSON.stringify(data)
});
```

### Performance Optimization

#### Token Caching

Cache tokens in memory to avoid repeated DOM queries.

```javascript
class CSRFTokenCache {
  constructor() {
    this.token = null;
    this.lastRefresh = 0;
    this.cacheDuration = 300000; // 5 minutes
  }
  
  getToken() {
    const now = Date.now();
    if (!this.token || (now - this.lastRefresh) > this.cacheDuration) {
      this.token = document.querySelector('meta[name="csrf-token"]')?.content;
      this.lastRefresh = now;
    }
    return this.token;
  }
  
  invalidate() {
    this.token = null;
    this.lastRefresh = 0;
  }
}

const tokenCache = new CSRFTokenCache();
```

#### Batch Request Handling

For multiple simultaneous requests, ensure token is read once and reused.

```javascript
async function batchRequests(urls, data) {
  const token = getToken(); // Read once
  
  const requests = urls.map(url => 
    fetch(url, {
      method: 'POST',
      headers: {
        'X-CSRF-Token': token,  // Reuse for all
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
    })
  );
  
  return Promise.all(requests);
}
```

---

## Content Security Policy and Fetch API

### CSP Directives Affecting Fetch

#### connect-src

The `connect-src` directive controls which URLs can be loaded using script interfaces including `fetch()`, `XMLHttpRequest`, `WebSocket`, `EventSource`, and `Navigator.sendBeacon()`.

```http
Content-Security-Policy: connect-src 'self' https://api.example.com
```

When a fetch request violates `connect-src`, the browser blocks the request and returns a network error. The Promise returned by `fetch()` rejects with a `TypeError`.

```javascript
// Allowed if connect-src includes https://api.example.com
fetch('https://api.example.com/data')
  .then(response => response.json())
  .catch(error => {
    // TypeError: Failed to fetch (CSP violation)
  });
```

#### default-src Fallback

If `connect-src` is not specified, the `default-src` directive serves as a fallback for all fetch directives.

```http
Content-Security-Policy: default-src 'self'
```

This policy restricts fetch requests to same-origin URLs only.

### CSP and CORS Interaction

CSP evaluation occurs before CORS checks. A request must satisfy CSP requirements before the browser even initiates the network request that would trigger CORS preflight.

```javascript
// CSP blocks this before CORS preflight is sent
fetch('https://blocked-by-csp.example.com/api', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' }
});
```

### Special Source Values

#### 'self'

Restricts connections to the same origin (same scheme, host, and port).

```http
Content-Security-Policy: connect-src 'self'
```

```javascript
// Allowed on https://example.com
fetch('/api/data');
fetch('https://example.com/api/data');

// Blocked
fetch('https://api.example.com/data'); // Different subdomain
fetch('http://example.com/data'); // Different scheme
```

#### 'none'

Blocks all fetch requests.

```http
Content-Security-Policy: connect-src 'none'
```

All `fetch()` calls will fail with a CSP violation.

#### Scheme Sources

Allow connections to any URL with specified schemes.

```http
Content-Security-Policy: connect-src https: wss:
```

```javascript
// Allowed - any HTTPS URL
fetch('https://any-domain.com/api');

// Blocked - HTTP not allowed
fetch('http://insecure.com/api');
```

#### Host Sources

Specify allowed hosts with optional wildcards.

```http
Content-Security-Policy: connect-src https://*.example.com https://api.partner.com
```

```javascript
// Allowed
fetch('https://api.example.com/data');
fetch('https://cdn.example.com/resource');
fetch('https://api.partner.com/endpoint');

// Blocked
fetch('https://example.com'); // Subdomain required by wildcard
fetch('https://malicious.com/api');
```

### Reporting CSP Violations

#### report-uri (Deprecated)

```http
Content-Security-Policy: connect-src 'self'; report-uri /csp-violation-report
```

#### report-to (Modern)

```http
Content-Security-Policy: connect-src 'self'; report-to csp-endpoint
Report-To: {"group":"csp-endpoint","max_age":10886400,"endpoints":[{"url":"/csp-report"}]}
```

Violation reports include:

- `blocked-uri`: The URI that was blocked
- `violated-directive`: The directive that was violated
- `effective-directive`: The specific directive that caused the block
- `original-policy`: The full CSP policy

```json
{
  "csp-report": {
    "document-uri": "https://example.com/page",
    "violated-directive": "connect-src",
    "effective-directive": "connect-src",
    "original-policy": "connect-src 'self'",
    "blocked-uri": "https://malicious.com/api",
    "status-code": 0
  }
}
```

### Report-Only Mode

CSP can be deployed in report-only mode using the `Content-Security-Policy-Report-Only` header. Violations are reported but not enforced.

```http
Content-Security-Policy-Report-Only: connect-src 'self'; report-uri /csp-violations
```

```javascript
// This fetch executes normally but violation is reported
fetch('https://external-api.com/data');
```

This mode is useful for testing CSP policies before enforcement.

### Nonce and Hash Sources

[Inference] While `'nonce-'` and `'sha256-'` sources are commonly used with `script-src` and `style-src` directives, they are not applicable to `connect-src` or fetch requests. These sources control inline script/style execution, not network requests.

### Multiple Policies

When multiple CSP headers or meta tags are present, all policies must be satisfied (intersection of allowed sources).

```http
Content-Security-Policy: connect-src https://api1.example.com
Content-Security-Policy: connect-src https://api2.example.com
```

Result: No fetch requests are allowed because no origin satisfies both policies simultaneously.

```javascript
// Both blocked - violate one of the two policies
fetch('https://api1.example.com/data');
fetch('https://api2.example.com/data');
```

### CSP in Meta Tags

CSP can be specified via HTML meta tags, but with limitations.

```html
<meta http-equiv="Content-Security-Policy" 
      content="connect-src 'self' https://api.example.com">
```

Limitations:

- `report-uri` and `report-to` directives are not supported in meta tags
- Meta tag CSP is parsed after the document starts loading
- HTTP header CSP is preferred for reliability

### Dynamic Import and Worker CSP

#### Worker Scripts

Workers inherit the CSP of the document that created them, but `connect-src` applies to fetch requests made within the worker.

```javascript
// In worker.js
fetch('https://api.example.com/data'); // Subject to CSP connect-src
```

#### Import Scripts in Workers

The `importScripts()` function in workers is controlled by `script-src` (or `script-src-elem`), not `connect-src`.

### Upgrade-Insecure-Requests

The `upgrade-insecure-requests` directive automatically upgrades HTTP URLs to HTTPS.

```http
Content-Security-Policy: upgrade-insecure-requests
```

```javascript
// Automatically upgraded to https://api.example.com/data
fetch('http://api.example.com/data');
```

[Inference] This upgrade happens before CSP evaluation, so `connect-src` policies evaluate against the upgraded URL.

### Block-All-Mixed-Content

[Unverified] The `block-all-mixed-content` directive was previously used to prevent mixed content (HTTPS page loading HTTP resources), but modern browsers block mixed content by default. This directive is now largely obsolete.

### CSP Level 3 Features

#### Embedded Enforcement

Parent documents can enforce CSP on embedded iframes using the `csp` attribute.

```html
<iframe src="https://embed.example.com" 
        csp="connect-src 'self'">
</iframe>
```

Fetch requests within the iframe must satisfy both the iframe's own CSP and the embedded enforcement policy.

#### Strict Dynamic

While `'strict-dynamic'` is primarily for script execution control, understanding its behavior is important when loading scripts that make fetch requests.

```http
Content-Security-Policy: script-src 'nonce-abc123' 'strict-dynamic'; connect-src 'self'
```

Scripts loaded with the correct nonce can execute, but their fetch requests still must satisfy `connect-src`.

### CSP Evaluation Flow for Fetch

1. Browser receives fetch request from JavaScript
2. Browser checks `connect-src` directive (or `default-src` fallback)
3. If policy allows the URL:
    - Browser initiates network request
    - CORS checks apply if cross-origin
    - Request proceeds normally
4. If policy blocks the URL:
    - Browser blocks request immediately
    - Network request never occurs
    - `fetch()` Promise rejects with `TypeError`
    - Violation reported if reporting configured

### Debugging CSP Violations

Browser DevTools provide CSP violation information:

**Console Messages:**

```
Refused to connect to 'https://blocked.example.com/api' 
because it violates the following Content Security Policy directive: 
"connect-src 'self' https://api.example.com"
```

**Network Tab:**

- Blocked requests appear with "blocked:csp" status
- No actual network traffic occurs

**Security Tab:**

- Shows active CSP policies
- Lists violated directives
- [Inference] Available in Chrome/Edge DevTools

### Best Practices

#### Start Restrictive

Begin with strict policies and relax as needed:

```http
Content-Security-Policy: default-src 'none'; connect-src 'self'
```

#### Use Report-Only for Testing

Deploy new policies in report-only mode first:

```http
Content-Security-Policy-Report-Only: connect-src 'self' https://new-api.example.com
```

Monitor violation reports before enforcing.

#### Avoid Wildcards

Specify exact hosts when possible:

```http
# Less secure
Content-Security-Policy: connect-src https://*

# More secure
Content-Security-Policy: connect-src 'self' https://api.example.com https://cdn.example.com
```

#### Separate API Domains

Host APIs on dedicated subdomains for granular control:

```http
Content-Security-Policy: connect-src 'self' https://api.example.com
```

#### Monitor Violations

Set up violation reporting and monitoring infrastructure:

```http
Content-Security-Policy: connect-src 'self'; report-to csp-endpoint
```

Analyze reports regularly to detect:

- Configuration errors
- Malicious injection attempts
- Required policy adjustments

### Common Pitfalls

#### Forgetting About Redirects

CSP checks apply to the final URL after redirects, but [Inference] browsers may also check intermediate redirect URLs.

```javascript
// Initial URL allowed, but redirect destination blocked
fetch('https://api.example.com/redirect'); // Redirects to https://blocked.com
```

#### WebSocket Connections

WebSocket connections are also controlled by `connect-src`:

```http
Content-Security-Policy: connect-src 'self' wss://ws.example.com
```

```javascript
// Blocked if wss://external.com not in connect-src
const ws = new WebSocket('wss://external.com/socket');
```

#### ServiceWorker Fetch Events

Fetch requests made in ServiceWorker `fetch` event handlers are subject to the page's CSP, not the ServiceWorker script's CSP.

```javascript
// In service-worker.js
self.addEventListener('fetch', event => {
  // This fetch subject to page CSP, not SW CSP
  event.respondWith(
    fetch('https://api.example.com/data')
  );
});
```

#### Data URLs

Data URLs in fetch are blocked by most CSP configurations:

```http
Content-Security-Policy: connect-src 'self'
```

```javascript
// Blocked - data: scheme not allowed
fetch('data:text/plain,Hello');
```

To allow data URLs explicitly:

```http
Content-Security-Policy: connect-src 'self' data:
```

#### Blob URLs

Blob URLs created with `URL.createObjectURL()` are considered same-origin for CSP purposes when `'self'` is allowed.

```javascript
const blob = new Blob(['{"key": "value"}'], { type: 'application/json' });
const blobUrl = URL.createObjectURL(blob);

// Allowed if connect-src includes 'self'
fetch(blobUrl);
```

### Framework-Specific Considerations

#### React/Vue/Angular SPAs

Single-page applications making frequent API calls need carefully configured CSP:

```http
Content-Security-Policy: 
  default-src 'self'; 
  connect-src 'self' https://api.example.com https://analytics.example.com;
  script-src 'self' 'unsafe-inline' 'unsafe-eval';
```

Note: `'unsafe-inline'` and `'unsafe-eval'` weaken CSP security and should be avoided when possible using nonces or hashes.

#### API Gateways

When using API gateways, allow the gateway domain:

```http
Content-Security-Policy: connect-src 'self' https://gateway.example.com
```

Backend service URLs behind the gateway don't need to be whitelisted.

### Performance Implications

CSP evaluation is performed synchronously before network requests. [Inference] The performance impact is negligible as it involves simple string matching against policy directives, occurring in microseconds.

### Browser Support

CSP Level 2 (`connect-src`) is supported by all modern browsers. Legacy browsers without CSP support ignore the header, providing no protection but not breaking functionality.

[Unverified] Specific CSP Level 3 features like embedded enforcement may have varying support across browsers. Check compatibility tables for cutting-edge features.

---

## Subresource Integrity

### Core Concept and Purpose

Subresource Integrity (SRI) is a security feature that enables browsers to verify that files fetched from external sources (particularly CDNs) have not been tampered with or unexpectedly modified. It works by allowing developers to provide a cryptographic hash that the browser must match against the fetched resource before executing or applying it.

When a resource is fetched, the browser computes the hash of the received content and compares it against the integrity attribute value. If the hashes match, the resource is deemed safe and is used. If they don't match, the browser refuses to execute the script, apply the stylesheet, or use the resource, and fires an error event instead.

The primary security concern SRI addresses is the risk of compromised third-party resources. CDNs, while convenient and performant, represent potential attack vectors. If an attacker gains access to a CDN or performs a man-in-the-middle attack, they could inject malicious code into resources served to millions of websites. SRI provides a defense mechanism against such supply chain attacks.

### Hash Generation and Format

#### Supported Hash Algorithms

SRI supports multiple cryptographic hash functions, with varying levels of security:

**SHA-256**

- 256-bit hash function
- Minimum recommended strength
- Widely supported across all browsers
- Format: `sha256-[base64-encoded-hash]`

**SHA-384**

- 384-bit hash function
- Stronger security than SHA-256
- Recommended for high-security scenarios
- Format: `sha384-[base64-encoded-hash]`

**SHA-512**

- 512-bit hash function
- Highest security level
- Largest hash size and computational overhead
- Format: `sha512-[base64-encoded-hash]`

The hash algorithm prefix (sha256, sha384, sha512) is case-insensitive, though lowercase is conventional.

#### Generating Hash Values

**Using OpenSSL**

```bash
# Generate SHA-384 hash
openssl dgst -sha384 -binary script.js | openssl base64 -A

# Generate SHA-512 hash
openssl dgst -sha512 -binary style.css | openssl base64 -A

# For multiple files
for file in *.js; do
  echo "$file: sha384-$(openssl dgst -sha384 -binary "$file" | openssl base64 -A)"
done
```

**Using Node.js**

```javascript
const crypto = require('crypto');
const fs = require('fs');

function generateSRI(filePath, algorithm = 'sha384') {
  const fileContent = fs.readFileSync(filePath);
  const hash = crypto.createHash(algorithm).update(fileContent).digest('base64');
  return `${algorithm}-${hash}`;
}

// Usage
const integrity = generateSRI('script.js', 'sha384');
console.log(integrity);
// Output: sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC
```

**Using Python**

```python
import hashlib
import base64

def generate_sri(file_path, algorithm='sha384'):
    with open(file_path, 'rb') as f:
        content = f.read()
    
    if algorithm == 'sha256':
        hash_obj = hashlib.sha256(content)
    elif algorithm == 'sha384':
        hash_obj = hashlib.sha384(content)
    elif algorithm == 'sha512':
        hash_obj = hashlib.sha512(content)
    
    hash_base64 = base64.b64encode(hash_obj.digest()).decode()
    return f"{algorithm}-{hash_base64}"

# Usage
integrity = generate_sri('script.js', 'sha384')
print(integrity)
```

**Using PowerShell**

```powershell
# Generate SHA-384 hash
$fileContent = Get-Content -Path "script.js" -Raw -Encoding Byte
$hash = [System.Security.Cryptography.SHA384]::Create().ComputeHash($fileContent)
$base64 = [System.Convert]::ToBase64String($hash)
Write-Output "sha384-$base64"
```

**Online Tools**

Several online SRI hash generators exist for quick generation:

- https://www.srihash.org/
- Browser DevTools can also compute hashes

#### Multiple Hash Values

SRI supports specifying multiple hash values in a single integrity attribute, separated by whitespace. This allows for algorithm agility and fallback options:

```html
<script src="https://cdn.example.com/library.js"
        integrity="sha256-abc123... sha384-def456... sha512-ghi789..."
        crossorigin="anonymous"></script>
```

The browser will validate against the strongest algorithm it supports. If the resource matches any of the provided hashes using any supported algorithm, it passes validation.

**Priority Order**

- The browser selects the strongest algorithm from those it supports
- SHA-512 > SHA-384 > SHA-256
- At least one hash must match using the selected algorithm

### Implementation Syntax

#### Script Elements

```html
<!-- Basic SRI implementation -->
<script src="https://cdn.example.com/jquery-3.6.0.min.js"
        integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We"
        crossorigin="anonymous"></script>

<!-- Multiple integrity values -->
<script src="https://cdn.example.com/library.js"
        integrity="sha256-abc123def456... sha384-ghi789jkl012..."
        crossorigin="anonymous"></script>

<!-- Inline scripts (not protected by SRI) -->
<script>
  // SRI does not apply to inline scripts
  console.log('This cannot be protected by SRI');
</script>
```

#### Link Elements (Stylesheets)

```html
<!-- Stylesheet with SRI -->
<link rel="stylesheet" 
      href="https://cdn.example.com/bootstrap-5.3.0.min.css"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous">

<!-- Preload with SRI -->
<link rel="preload"
      href="https://cdn.example.com/font.woff2"
      as="font"
      type="font/woff2"
      integrity="sha384-abc123..."
      crossorigin="anonymous">
```

#### Module Scripts

```html
<!-- ES6 modules with SRI -->
<script type="module"
        src="https://cdn.example.com/module.js"
        integrity="sha384-def456..."
        crossorigin="anonymous"></script>

<!-- Module with import maps -->
<script type="importmap">
{
  "imports": {
    "library": "https://cdn.example.com/library.js"
  }
}
</script>
<script type="module">
  // Note: Import maps don't support SRI directly
  import library from 'library';
</script>
```

#### Link Prefetch and Preload

```html
<!-- Prefetch with SRI -->
<link rel="prefetch"
      href="https://cdn.example.com/next-page-script.js"
      as="script"
      integrity="sha384-xyz789..."
      crossorigin="anonymous">

<!-- DNS prefetch (SRI not applicable) -->
<link rel="dns-prefetch" href="https://cdn.example.com">

<!-- Preconnect (SRI not applicable) -->
<link rel="preconnect" href="https://cdn.example.com" crossorigin>
```

### CORS Requirements

Subresource Integrity requires Cross-Origin Resource Sharing (CORS) to function properly with cross-origin resources. This requirement exists because SRI needs access to the raw resource bytes to compute the hash, which CORS restrictions would normally prevent.

#### The `crossorigin` Attribute

The `crossorigin` attribute is mandatory when using SRI with cross-origin resources. It has two valid values:

**anonymous**

```html
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>
```

- Sends requests without credentials (no cookies, HTTP authentication, or client-side certificates)
- Most common and recommended for public CDN resources
- Server must respond with `Access-Control-Allow-Origin: *` or the specific origin

**use-credentials**

```html
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."
        crossorigin="use-credentials"></script>
```

- Sends requests with credentials (cookies, authentication headers)
- Requires server to explicitly allow the origin (cannot use wildcard)
- Server must respond with `Access-Control-Allow-Origin: https://yourdomain.com` and `Access-Control-Allow-Credentials: true`

#### Server Configuration

**CDN/Server Requirements**

For SRI to work with cross-origin resources, the server must send appropriate CORS headers:

```http
Access-Control-Allow-Origin: *
```

Or for credential-based requests:

```http
Access-Control-Allow-Origin: https://yourdomain.com
Access-Control-Allow-Credentials: true
```

**Apache Configuration**

```apache
<IfModule mod_headers.c>
    # Allow all origins for public resources
    Header set Access-Control-Allow-Origin "*"
    
    # Or specific origin
    # Header set Access-Control-Allow-Origin "https://yourdomain.com"
</IfModule>
```

**Nginx Configuration**

```nginx
location ~* \.(js|css|woff2?)$ {
    add_header Access-Control-Allow-Origin "*";
    # Or specific origin
    # add_header Access-Control-Allow-Origin "https://yourdomain.com";
}
```

**Express.js (Node.js)**

```javascript
const express = require('express');
const app = express();

// Allow all origins
app.use((req, res, next) => {
  res.setHeader('Access-Control-Allow-Origin', '*');
  next();
});

// Or specific origin
app.use((req, res, next) => {
  res.setHeader('Access-Control-Allow-Origin', 'https://yourdomain.com');
  next();
});
```

#### Same-Origin Resources

For same-origin resources, the `crossorigin` attribute is optional but recommended:

```html
<!-- Same-origin without crossorigin (works) -->
<script src="/assets/script.js" integrity="sha384-..."></script>

<!-- Same-origin with crossorigin (recommended) -->
<script src="/assets/script.js" 
        integrity="sha384-..." 
        crossorigin="anonymous"></script>
```

Including `crossorigin` for same-origin resources ensures consistent behavior and allows for potential CDN migration without code changes.

### Fetch API Integration

When using the Fetch API, SRI can be specified through the `integrity` option in the request configuration.

#### Basic Fetch with SRI

```javascript
fetch('https://cdn.example.com/data.json', {
  integrity: 'sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC',
  mode: 'cors',
  credentials: 'omit' // or 'include' for credentials
})
.then(response => {
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  return response.json();
})
.then(data => {
  console.log('Data fetched and verified:', data);
})
.catch(error => {
  console.error('Fetch failed or integrity check failed:', error);
});
```

#### Integrity Validation Behavior

When integrity checking fails with the Fetch API:

- The promise rejects with a `TypeError`
- The response is not made available to the caller
- Network error is reported (indistinguishable from other network errors)

```javascript
async function fetchWithIntegrity(url, expectedHash) {
  try {
    const response = await fetch(url, {
      integrity: expectedHash,
      mode: 'cors'
    });
    
    // If we reach here, integrity check passed
    return await response.text();
  } catch (error) {
    // Could be network error OR integrity mismatch
    console.error('Fetch failed:', error.message);
    throw error;
  }
}
```

#### Multiple Resource Fetching

```javascript
const resources = [
  {
    url: 'https://cdn.example.com/library1.js',
    integrity: 'sha384-abc123...'
  },
  {
    url: 'https://cdn.example.com/library2.js',
    integrity: 'sha384-def456...'
  }
];

async function fetchAllResources(resources) {
  const promises = resources.map(resource =>
    fetch(resource.url, {
      integrity: resource.integrity,
      mode: 'cors',
      credentials: 'omit'
    }).then(r => r.text())
  );
  
  try {
    const results = await Promise.all(promises);
    console.log('All resources fetched and verified');
    return results;
  } catch (error) {
    console.error('One or more resources failed integrity check');
    throw error;
  }
}
```

#### Dynamic Script Loading

```javascript
async function loadScriptWithIntegrity(url, integrity) {
  try {
    // Fetch and verify
    const response = await fetch(url, {
      integrity: integrity,
      mode: 'cors',
      credentials: 'omit'
    });
    
    const scriptContent = await response.text();
    
    // Create and execute script
    const script = document.createElement('script');
    script.textContent = scriptContent;
    document.head.appendChild(script);
    
    console.log('Script loaded and executed successfully');
  } catch (error) {
    console.error('Failed to load script:', error);
  }
}

// Usage
loadScriptWithIntegrity(
  'https://cdn.example.com/library.js',
  'sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC'
);
```

#### Service Worker Implementation

```javascript
// service-worker.js
self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  // Define resources with integrity hashes
  const integrityMap = {
    'https://cdn.example.com/library.js': 'sha384-abc123...',
    'https://cdn.example.com/style.css': 'sha384-def456...'
  };
  
  const integrity = integrityMap[event.request.url];
  
  if (integrity) {
    event.respondWith(
      fetch(event.request.url, {
        integrity: integrity,
        mode: 'cors',
        credentials: 'omit'
      }).catch(error => {
        console.error('Integrity check failed for:', event.request.url);
        // Return fallback or cached version
        return caches.match(event.request);
      })
    );
  }
});
```

### Browser Support and Fallbacks

#### Current Browser Support

Subresource Integrity is widely supported in modern browsers:

- **Chrome/Edge**: Version 45+ (2015)
- **Firefox**: Version 43+ (2015)
- **Safari**: Version 11.1+ (2018)
- **Opera**: Version 32+ (2015)
- **iOS Safari**: Version 11.3+ (2018)
- **Android Browser**: Version 45+ (2015)

Notably, Internet Explorer does not support SRI at all.

#### Feature Detection

```javascript
// Check if SRI is supported
function isSRISupported() {
  return 'integrity' in document.createElement('script');
}

if (isSRISupported()) {
  console.log('SRI is supported');
} else {
  console.warn('SRI is not supported by this browser');
}
```

#### Graceful Degradation Strategies

**Progressive Enhancement Approach**

```html
<!-- Browser will load with or without SRI support -->
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>

<!-- Fallback to local copy if CDN fails -->
<script>
  window.Library || document.write('<script src="/local/library.js"><\/script>');
</script>
```

**Conditional Loading Based on Support**

```javascript
function loadScript(url, integrity) {
  const script = document.createElement('script');
  script.src = url;
  script.crossOrigin = 'anonymous';
  
  // Only set integrity if supported
  if ('integrity' in script) {
    script.integrity = integrity;
  } else {
    console.warn('SRI not supported, loading without integrity check');
  }
  
  script.onerror = function() {
    console.error('Failed to load script');
    // Fallback to local version
    loadLocalScript();
  };
  
  document.head.appendChild(script);
}
```

**Multiple Fallback Strategy**

```html
<!-- Primary CDN with SRI -->
<script src="https://cdn1.example.com/library.js"
        integrity="sha384-primary..."
        crossorigin="anonymous"
        onerror="loadFromBackupCDN()"></script>

<script>
function loadFromBackupCDN() {
  const script = document.createElement('script');
  script.src = 'https://cdn2.example.com/library.js';
  script.integrity = 'sha384-backup...';
  script.crossOrigin = 'anonymous';
  script.onerror = loadFromLocal;
  document.head.appendChild(script);
}

function loadFromLocal() {
  const script = document.createElement('script');
  script.src = '/local/library.js';
  // No integrity check for local version
  document.head.appendChild(script);
}
</script>
```

#### Polyfill Considerations

There is no true polyfill for SRI because:

- The security guarantees cannot be replicated in JavaScript
- By the time JavaScript executes, potentially malicious code has already loaded
- The hash verification must happen at the browser level before execution

However, a detection and warning system can be implemented:

```javascript
// Warning system for browsers without SRI
(function() {
  if (!('integrity' in document.createElement('script'))) {
    console.warn('⚠️ SRI not supported. Resources may be vulnerable to tampering.');
    
    // Optionally notify server or analytics
    if (navigator.sendBeacon) {
      navigator.sendBeacon('/api/sri-not-supported', JSON.stringify({
        userAgent: navigator.userAgent,
        timestamp: Date.now()
      }));
    }
  }
})();
```

### Content Security Policy Integration

Subresource Integrity works in conjunction with Content Security Policy (CSP) to provide defense-in-depth security.

#### require-sri-for Directive

The `require-sri-for` CSP directive mandates SRI for specified resource types:

```http
Content-Security-Policy: require-sri-for script style;
```

This directive forces all script and style resources to have valid integrity attributes. Without them, the browser will refuse to load the resource.

**HTML Meta Tag**

```html
<meta http-equiv="Content-Security-Policy" 
      content="require-sri-for script style;">
```

**Server Header Examples**

Apache:

```apache
Header set Content-Security-Policy "require-sri-for script style;"
```

Nginx:

```nginx
add_header Content-Security-Policy "require-sri-for script style;";
```

Express.js:

```javascript
app.use((req, res, next) => {
  res.setHeader('Content-Security-Policy', 'require-sri-for script style;');
  next();
});
```

#### Combining CSP Directives

```http
Content-Security-Policy: 
  default-src 'self'; 
  script-src 'self' https://cdn.example.com; 
  style-src 'self' https://cdn.example.com; 
  require-sri-for script style;
```

This policy:

- Restricts scripts and styles to same-origin and specific CDN
- Requires all scripts and styles to have SRI
- Provides multiple layers of protection

#### CSP with Nonces and SRI

When using CSP nonces for inline scripts while requiring SRI for external resources:

```html
<!-- CSP Header -->
<!-- Content-Security-Policy: script-src 'nonce-random123'; require-sri-for script; -->

<!-- Inline script with nonce (SRI not applicable) -->
<script nonce="random123">
  console.log('Inline script allowed by nonce');
</script>

<!-- External script requires SRI -->
<script src="https://cdn.example.com/library.js"
        nonce="random123"
        integrity="sha384-..."
        crossorigin="anonymous"></script>
```

#### Violation Reporting

CSP violations, including SRI failures, can be reported:

```http
Content-Security-Policy: 
  require-sri-for script; 
  report-uri /csp-violation-report;
```

Report format for SRI violation:

```json
{
  "csp-report": {
    "document-uri": "https://example.com/page",
    "violated-directive": "require-sri-for",
    "effective-directive": "require-sri-for",
    "original-policy": "require-sri-for script;",
    "blocked-uri": "https://cdn.example.com/library.js",
    "status-code": 200,
    "source-file": "https://example.com/page",
    "line-number": 42,
    "column-number": 12
  }
}
```

### Security Considerations

#### Protection Scope

**What SRI Protects Against**

- Compromised CDN serving modified files
- Man-in-the-middle attacks modifying resources in transit
- Accidental file corruption during transmission
- BGP hijacking affecting CDN routes
- DNS spoofing attacks redirecting to malicious servers

**What SRI Does Not Protect Against**

- Vulnerabilities in the library itself
- Malicious code intentionally included in the original library version
- Inline scripts (not subject to SRI)
- Resources loaded dynamically without integrity checks
- XSS attacks injecting code directly into the page
- Compromised website serving malicious inline content

#### Hash Algorithm Selection

**SHA-256**

- Minimum acceptable security level
- Faster computation
- Smaller hash size (44 characters base64)
- Suitable for most use cases

**SHA-384**

- Recommended balance of security and performance
- 128-bit security level
- Moderate hash size (64 characters base64)
- Industry standard for SRI

**SHA-512**

- Highest security level
- 256-bit security level
- Largest hash size (88 characters base64)
- Overkill for most scenarios but useful for critical applications

**Algorithm Agility**

Specifying multiple algorithms provides future-proofing:

```html
<script src="https://cdn.example.com/library.js"
        integrity="sha384-current... sha512-future..."
        crossorigin="anonymous"></script>
```

If a vulnerability is discovered in SHA-384, browsers can fall back to SHA-512 without requiring code changes.

#### Hash Update Management

**Challenges**

- Library updates change file content, invalidating hashes
- Automated updates break SRI-protected resources
- Manual hash regeneration required for each version

**Version Pinning Strategy**

```html
<!-- Pin to specific version -->
<script src="https://cdn.example.com/library@3.6.0/library.min.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>

<!-- Avoid version ranges that auto-update -->
<!-- BAD: This will break when the file updates -->
<script src="https://cdn.example.com/library@3/library.min.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>
```

**Automated Hash Management**

Build tool integration:

```javascript
// Webpack plugin
const SriPlugin = require('webpack-subresource-integrity');

module.exports = {
  plugins: [
    new SriPlugin({
      hashFuncNames: ['sha384'],
      enabled: process.env.NODE_ENV === 'production'
    })
  ]
};
```

```javascript
// Gulp task
const gulp = require('gulp');
const sri = require('gulp-sri');

gulp.task('sri', () => {
  return gulp.src('dist/index.html')
    .pipe(sri({
      algorithms: ['sha384']
    }))
    .pipe(gulp.dest('dist'));
});
```

**Version Tracking System**

```javascript
// sri-config.json
{
  "resources": [
    {
      "url": "https://cdn.example.com/jquery-3.6.0.min.js",
      "integrity": "sha384-...",
      "version": "3.6.0",
      "lastUpdated": "2024-01-15"
    },
    {
      "url": "https://cdn.example.com/bootstrap-5.3.0.min.css",
      "integrity": "sha384-...",
      "version": "5.3.0",
      "lastUpdated": "2024-01-15"
    }
  ]
}
```

#### Privacy Implications

**Timing Attacks**

SRI validation timing could theoretically leak information:

- Hash computation time varies with file size
- Network timing patterns might reveal resource identity
- Cache status might be inferred from timing differences

In practice, these are minimal concerns as:

- Timing variations are small and noisy
- Other factors dominate timing (network latency, server response time)
- Browsers implement timing attack mitigations

**Cache Partitioning**

Modern browsers implement cache partitioning, which affects SRI-protected resources:

- Resources are cached per-origin
- Same CDN resource loaded by different sites requires separate cache entries
- SRI doesn't change this behavior but is compatible with partitioned caches

#### Error Handling Security

**Information Disclosure**

SRI failures should not leak sensitive information:

```javascript
// POOR: Reveals internal URLs
fetch(url, { integrity: hash })
  .catch(error => {
    console.error('Failed to load: ' + url, error);
  });

// BETTER: Generic error message
fetch(url, { integrity: hash })
  .catch(error => {
    console.error('Resource integrity check failed');
    // Log details server-side for debugging
    logToServer({ type: 'sri-failure', timestamp: Date.now() });
  });
```

**Graceful Degradation**

Avoid cascade failures:

```javascript
async function loadCriticalResource(url, integrity) {
  try {
    const response = await fetch(url, {
      integrity: integrity,
      mode: 'cors'
    });
    return await response.text();
  } catch (error) {
    // Don't let SRI failure break entire application
    console.error('SRI check failed, using fallback');
    return loadFallbackResource();
  }
}
```

### Performance Implications

#### Hash Computation Overhead

**Browser-Side Performance**

The browser must compute hashes for integrity checking:

- Hash computation is fast (milliseconds for typical resources)
- Happens during resource download (parallel processing)
- Negligible impact on page load time
- Cached resources skip recomputation

**Benchmark Example**

```javascript
// Measuring hash computation time
async function benchmarkHashComputation(url) {
  const start = performance.now();
  
  const response = await fetch(url);
  const buffer = await response.arrayBuffer();
  
  const hashBuffer = await crypto.subtle.digest('SHA-384', buffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode.apply(null, hashArray));
  
  const end = performance.now();
  console.log(`Hash computation took ${end - start}ms`);
  console.log(`File size: ${buffer.byteLength} bytes`);
  console.log(`Hash: sha384-${hashBase64}`);
}
```

Typical results:

- Small file (10 KB): < 1ms
- Medium file (100 KB): 1-3ms
- Large file (1 MB): 5-15ms

#### Network Performance

**Additional Bytes**

Integrity attributes add to HTML document size:

- SHA-256: ~44 characters
- SHA-384: ~64 characters
- SHA-512: ~88 characters
- Plus attribute name and quotes: ~80-110 bytes total per resource

For a page with 10 external resources using SHA-384:

- Additional size: ~800 bytes
- Negligible impact compared to typical HTML size
- Well worth the security benefit

**Caching Behavior**

SRI affects caching positively:

- Resources with integrity hashes can be aggressively cached
- No need to revalidate if integrity matches
- Reduces unnecessary network requests

```html
<!-- Browser can cache confidently -->
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>

<!-- Cache-Control header can be more aggressive -->
```

Server header:

```http
Cache-Control: public, max-age=31536000, immutable
```

The `immutable` directive works well with SRI, as the integrity hash guarantees the content hasn't changed.

#### CDN Considerations

**Multiple CDN Strategy**

Using multiple CDN providers with SRI:

```html
<script src="https://cdn1.example.com/library.js"
        integrity="sha384-..."
        crossorigin="anonymous"
        onerror="this.onerror=null; this.src='https://cdn2.example.com/library.js'"></script>
```

This provides:

- Redundancy if primary CDN fails
- Same integrity hash works across CDNs (same file)
- Automatic fallback with maintained security

**CDN Best Practices**

- Use CDNs that support CORS properly
- Verify CDN sends correct `Access-Control-Allow-Origin` headers
- Choose CDNs with good uptime records
- Test fallback chains before production deployment

### Build Pipeline Integration

#### Webpack Configuration

```javascript
// webpack.config.js
const HtmlWebpackPlugin = require('html-webpack-plugin');
const SubresourceIntegrityPlugin = require('webpack-subresource-integrity');

module.exports = {
  output: {
    filename: '[name].[contenthash].js',
    crossOriginLoading: 'anonymous'
  },
  plugins: [
    new HtmlWebpackPlugin({
      template: 'src/index.html'
    }),
    new SubresourceIntegrityPlugin({
      hashFuncNames: ['sha384', 'sha512'],
      enabled: process.env.NODE_ENV === 'production'
    })
  ]
};
```

Generated HTML:

```html
<script src="/main.a1b2c3d4.js" 
        integrity="sha384-... sha512-..." 
        crossorigin="anonymous"></script>
```

#### Gulp Integration

```javascript
const gulp = require('gulp');
const sri = require('gulp-sri-hash');

gulp.task('generate-sri', () => {
  return gulp.src('dist/**/*.html')
    .pipe(sri({
      algo: 'sha384',
      crossOrigin: 'anonymous'
    }))
    .pipe(gulp.dest('dist'));
});
```

#### Grunt Integration

```javascript
module.exports = function(grunt) {
  grunt.loadNpmTasks('grunt-sri');
  
  grunt.initConfig({
    sri: {
      generate: {
        src: ['dist/**/*.html'],
        options: {
          algorithms: ['sha384'],
          crossorigin: 'anonymous'
        }
      }
    }
  });
  
  grunt.registerTask('default', ['sri']);
};
```

#### NPM Scripts

```json
{
  "scripts": {
    "build": "webpack --mode production",
    "postbuild": "node scripts/generate-sri.js",
    "verify-sri": "node scripts/verify-sri.js"
  }
}
```

```javascript
// scripts/generate-sri.js
const fs = require('fs');
const crypto = require('crypto');
const glob = require('glob');

function generateSRI(filePath) {
  const content = fs.readFileSync(filePath);
  const hash = crypto
    .createHash('sha384')
    .update(content)
    .digest('base64');

  return `sha384-${hash}`;
}

// Find all HTML files
glob('dist/**/*.html', (err, files) => {
  if (err) {
    throw err;
  }

  files.forEach((file) => {
    let html = fs.readFileSync(file, 'utf8');

    // Find script and link tags, add integrity
    html = html.replace(
      /<(script|link)[^>]+src=["']([^"']+)["'][^>]*>/g,
      (match, tag, src) => {
        if (src.startsWith('http')) {
          // External resources – integrity should be pre-generated
          return match;
        }

        // Local resources
        const integrity = generateSRI(`dist/${src}`);
        return match.replace(
          '>',
          ` integrity="${integrity}" crossorigin="anonymous">`
        );
      }
    );

    fs.writeFileSync(file, html);
  });
});

````

#### Continuous Integration

```yaml
# .github/workflows/build.yml
name: Build and Deploy

on:
  push:
    branches: [main]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Install dependencies
        run: npm install
      
      - name: Build
        run: npm run build
      
      - name: Generate SRI
        run: npm run generate-sri
      
      - name: Verify SRI
        run: npm run verify-sri
      
      - name: Deploy
        run: npm run deploy
````

### Testing and Validation

#### Manual Verification

**Browser DevTools**

Testing SRI in browser console:

```javascript
// Check if element has integrity attribute
const script = document.querySelector('script[src*="cdn"]');
console.log('Integrity:', script.integrity);
console.log('Crossorigin:', script.crossOrigin);

// Test integrity with Fetch API
async function testIntegrity(url, integrity) {
  try {
    const response = await fetch(url, {
      integrity: integrity,
      mode: 'cors'
    });
    console.log('✓ Integrity check passed');
    return true;
  } catch (error) {
    console.error('✗ Integrity check failed:', error);
    return false;
  }
}

// Usage
testIntegrity(
  'https://cdn.example.com/library.js',
  'sha384-...'
);
```

**Network Panel Verification**

In browser DevTools Network panel:

1. Load page with SRI-protected resources
2. Check each resource:
    - Status should be 200 OK
    - No console errors about integrity
    - Response headers include CORS headers
3. Modify integrity hash to incorrect value
4. Reload page
5. Verify resource fails to load with integrity error

#### Automated Testing

**Jest Test Suite**

```javascript
// sri.test.js
const fs = require('fs');
const crypto = require('crypto');
const { JSDOM } = require('jsdom');

describe('Subresource Integrity Tests', () => {
  let dom;
  
  beforeAll(() => {
    const html = fs.readFileSync('dist/index.html', 'utf8');
    dom = new JSDOM(html);
  });
  
  test('All external scripts have integrity attribute', () => {
    const scripts = dom.window.document.querySelectorAll('script[src^="http"]');
    scripts.forEach(script => {
      expect(script.integrity).toBeTruthy();
      expect(script.integrity).toMatch(/^sha(256|384|512)-/);
    });
  });
  
  test('All external stylesheets have integrity attribute', () => {
    const links = dom.window.document.querySelectorAll('link[rel="stylesheet"][href^="http"]');
    links.forEach(link => {
      expect(link.integrity).toBeTruthy();
      expect(link.integrity).toMatch(/^sha(256|384|512)-/);
    });
  });
  
  test('All external resources have crossorigin attribute', () => {
    const elements = dom.window.document.querySelectorAll('[src^="http"][integrity], [href^="http"][integrity]');
    elements.forEach(element => {
      expect(element.crossOrigin).toBe('anonymous');
    });
  });
  
  test('Local file integrity hashes are correct', () => {
    const scripts = dom.window.document.querySelectorAll('script[src^="/"]');
    scripts.forEach(script => {
      if (script.integrity) {
        const filePath = `dist${script.src}`;
        const content = fs.readFileSync(filePath);
        const [algo, expectedHash] = script.integrity.split('-');
        const actualHash = crypto.createHash(algo).update(content).digest('base64');
        expect(actualHash).toBe(expectedHash);
      }
    });
  });
});
```

**Playwright E2E Tests**

```javascript
// e2e/sri.spec.js
const { test, expect } = require('@playwright/test');

test.describe('SRI Protection', () => {
  test('should load page successfully with valid SRI', async ({ page }) => {
    await page.goto('https://example.com');
    
    // Check no console errors
    const errors = [];
    page.on('console', msg => {
      if (msg.type() === 'error') {
        errors.push(msg.text());
      }
    });
    
    await page.waitForLoadState('networkidle');
    expect(errors).toHaveLength(0);
  });
  
  test('should fail to load resource with incorrect SRI', async ({ page }) => {
    // Intercept and modify integrity hash
    await page.route('**/*.js', route => {
      const response = route.fetch();
      // In real test, modify HTML to have wrong hash
    });
    
    const errors = [];
    page.on('console', msg => {
      if (msg.type() === 'error' && msg.text().includes('integrity')) {
        errors.push(msg.text());
      }
    });
    
    await page.goto('https://example.com');
    expect(errors.length).toBeGreaterThan(0);
  });
});
```

#### Security Audit Tools

**Lighthouse Audit**

```javascript
// Run Lighthouse with SRI checks
const lighthouse = require('lighthouse');
const chromeLauncher = require('chrome-launcher');

async function auditSRI(url) {
  const chrome = await chromeLauncher.launch({ chromeFlags: ['--headless'] });
  
  const options = {
    logLevel: 'info',
    output: 'json',
    onlyCategories: ['best-practices'],
    port: chrome.port
  };
  
  const runnerResult = await lighthouse(url, options);
  const audits = runnerResult.lhr.audits;
  
  // Check external scripts audit
  const externalScripts = audits['external-anchors-use-rel-noopener'];
  console.log('SRI Status:', externalScripts);
  
  await chrome.kill();
}
```

**Custom SRI Validator**

```javascript
const https = require('https');
const crypto = require('crypto');

async function validateSRI(url, expectedIntegrity) {
  return new Promise((resolve, reject) => {
    https.get(url, response => {
      const chunks = [];
      
      response.on('data', chunk => chunks.push(chunk));
      
      response.on('end', () => {
        const content = Buffer.concat(chunks);
        const [algo, expectedHash] = expectedIntegrity.split('-');
        const actualHash = crypto.createHash(algo).update(content).digest('base64');
        
        if (actualHash === expectedHash) {
          resolve({ valid: true, url, integrity: expectedIntegrity });
        } else {
          reject({
            valid: false,
            url,
            expected: expectedIntegrity,
            actual: `${algo}-${actualHash}`
          });
        }
      });
    }).on('error', reject);
  });
}

// Usage
validateSRI(
  'https://cdn.example.com/library.js',
  'sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC'
)
.then(result => console.log('✓ Valid:', result))
.catch(error => console.error('✗ Invalid:', error));
```

### Real-World Implementation Examples

#### Bootstrap CDN

```html
<!-- Bootstrap CSS -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" 
      rel="stylesheet" 
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" 
      crossorigin="anonymous">

<!-- Bootstrap JS Bundle -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js" 
        integrity="sha384-geWF76RCwLtnZ8qwWowPQNguL3RmwHVBC9FhGdlKrxdiJJigb/j/68SIy3Te4Bkz" 
        crossorigin="anonymous"></script>
```

#### jQuery CDN

```html
<!-- jQuery Core -->
<script src="https://code.jquery.com/jquery-3.7.1.min.js"
        integrity="sha384-1H217gwSVyLSIfaLxHbE7dRb3v4mYCKbpQvzx0cegeju1MVsGrX5xXxAvs/HgeFs"
        crossorigin="anonymous"></script>

<!-- jQuery UI -->
<link rel="stylesheet" 
      href="https://code.jquery.com/ui/1.13.2/themes/base/jquery-ui.css"
      integrity="sha384-TbH77 േhJR3SvZCxMSp9aWkJn5KfVqZ/c6xOEjJkCDEbY+1o9oHPyKODYE9U5xE"
      crossorigin="anonymous">

<script src="https://code.jquery.com/ui/1.13.2/jquery-ui.min.js"
        integrity="sha384-aumgKJp8vMwUCqQwi8wWnfJDJ9tPvHJQm1LJzQwZhLCQx4A0xJPHI0c9AKpWqv3f"
        crossorigin="anonymous"></script>
```

#### Font Awesome

```html
<!-- Font Awesome CSS -->
<link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
      integrity="sha384-iw3OoTErCYJq0xO0E++TqC1FvP4r+kFI3WuLFLGwLZfXm05F2ZLDlKkTSqmQdJHy"
      crossorigin="anonymous">

<!-- Font Awesome Webfonts (preload) -->
<link rel="preload"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/webfonts/fa-solid-900.woff2"
      as="font"
      type="font/woff2"
      integrity="sha384-EvSTjfC1Z7XFznXBL2fxvRLLZ6YdQqRpMQcMvnz7RK7m9E5jt0DfXJMxGPdUqXh9"
      crossorigin="anonymous">
```

#### React from CDN

```html
<!-- React Development -->
<script crossorigin 
        src="https://unpkg.com/react@18/umd/react.development.js"
        integrity="sha384-..."></script>
<script crossorigin 
        src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"
        integrity="sha384-..."></script>

<!-- React Production -->
<script crossorigin 
        src="https://unpkg.com/react@18/umd/react.production.min.js"
        integrity="sha384-KxEF3FJ3JxqG7DvCXQ8T1F5Q6yJ8b9YxNk6yI8N8G5mR6Kj2Lq4JQ7C5Sw8M9Tn"
        crossorigin="anonymous"></script>
<script crossorigin 
        src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"
        integrity="sha384-J9YXuB8bCzqS2xqJ9c4eJYQp1nLqF6YvPbCzBnXq2nJqF6YvPbCzBnXq2nJq6Yv"
        crossorigin="anonymous"></script>
```

#### Google Fonts (Limited SRI Support)

Google Fonts don't provide SRI hashes because fonts may be served differently based on browser capabilities. Alternative approach:

```html
<!-- Self-host fonts with SRI -->
<link rel="preload"
      href="/fonts/roboto-v30-latin-regular.woff2"
      as="font"
      type="font/woff2"
      integrity="sha384-abc123..."
      crossorigin="anonymous">

<style>
@font-face {
  font-family: 'Roboto';
  src: url('/fonts/roboto-v30-latin-regular.woff2') format('woff2');
}
</style>
```

### Advanced Patterns and Techniques

#### Dynamic Integrity Generation

For applications that generate HTML dynamically:

```javascript
// Server-side (Node.js/Express)
const crypto = require('crypto');
const fs = require('fs');

function generateIntegrityHash(filePath, algorithm = 'sha384') {
  const content = fs.readFileSync(filePath);
  const hash = crypto.createHash(algorithm).update(content).digest('base64');
  return `${algorithm}-${hash}`;
}

app.get('/', (req, res) => {
  const scriptHash = generateIntegrityHash('./public/app.js');
  const styleHash = generateIntegrityHash('./public/style.css');
  
  res.send(`
    <!DOCTYPE html>
    <html>
    <head>
      <link rel="stylesheet" 
            href="/style.css" 
            integrity="${styleHash}"
            crossorigin="anonymous">
    </head>
    <body>
      <script src="/app.js" 
              integrity="${scriptHash}"
              crossorigin="anonymous"></script>
    </body>
    </html>
  `);
});
```

#### Subresource Integrity with Service Workers

Advanced caching strategy with SRI:

```javascript
// service-worker.js
const RESOURCE_CACHE = 'resources-v1';

const resources = [
  {
    url: 'https://cdn.example.com/library.js',
    integrity: 'sha384-abc123...'
  },
  {
    url: 'https://cdn.example.com/style.css',
    integrity: 'sha384-def456...'
  }
];

// Install event - prefetch and verify
self.addEventListener('install', event => {
  event.waitUntil(
    Promise.all(
      resources.map(resource =>
        fetch(resource.url, {
          integrity: resource.integrity,
          mode: 'cors'
        })
        .then(response => {
          if (response.ok) {
            return caches.open(RESOURCE_CACHE)
              .then(cache => cache.put(resource.url, response));
          }
          throw new Error(`Failed to fetch ${resource.url}`);
        })
      )
    )
  );
});

// Fetch event - serve from cache with integrity verification
self.addEventListener('fetch', event => {
  const resource = resources.find(r => r.url === event.request.url);
  
  if (resource) {
    event.respondWith(
      caches.match(event.request)
        .then(cachedResponse => {
          if (cachedResponse) {
            // Verify cached response still matches integrity
            return cachedResponse.clone().arrayBuffer()
              .then(buffer => {
                return crypto.subtle.digest('SHA-384', buffer)
                  .then(hashBuffer => {
                    const hashArray = Array.from(new Uint8Array(hashBuffer));
                    const hashBase64 = btoa(String.fromCharCode.apply(null, hashArray));
                    const computedIntegrity = `sha384-${hashBase64}`;
                    
                    if (computedIntegrity === resource.integrity) {
                      return cachedResponse;
                    } else {
                      // Cache corruption detected, fetch fresh copy
                      console.warn('Cache integrity mismatch, refetching');
                      return fetch(event.request, {
                        integrity: resource.integrity,
                        mode: 'cors'
                      });
                    }
                  });
              });
          }
          
          // Not in cache, fetch with integrity check
          return fetch(event.request, {
            integrity: resource.integrity,
            mode: 'cors'
          });
        })
    );
  }
});
```

#### Conditional SRI Based on Environment

```javascript
// config.js
const environment = process.env.NODE_ENV || 'development';

const cdnConfig = {
  development: {
    useIntegrity: false, // Easier debugging
    useCDN: false // Local files
  },
  staging: {
    useIntegrity: true,
    useCDN: true
  },
  production: {
    useIntegrity: true,
    useCDN: true
  }
};

function generateScriptTag(src, localSrc, integrity) {
  const config = cdnConfig[environment];
  const url = config.useCDN ? src : localSrc;
  const integrityAttr = config.useIntegrity && integrity 
    ? ` integrity="${integrity}"` 
    : '';
  const crossoriginAttr = config.useCDN ? ' crossorigin="anonymous"' : '';
  
  return `<script src="${url}"${integrityAttr}${crossoriginAttr}></script>`;
}

// Usage
const scriptTag = generateScriptTag(
  'https://cdn.example.com/library.js',
  '/local/library.js',
  'sha384-abc123...'
);
```

#### Progressive Enhancement with SRI

```html
<!DOCTYPE html>
<html>
<head>
  <!-- Critical CSS inline (no SRI) -->
  <style>
    /* Critical above-the-fold styles */
  </style>
  
  <!-- Async load full CSS with SRI -->
  <link rel="preload"
        href="https://cdn.example.com/style.css"
        as="style"
        integrity="sha384-..."
        crossorigin="anonymous"
        onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for no-JS -->
  <noscript>
    <link rel="stylesheet" 
          href="https://cdn.example.com/style.css"
          integrity="sha384-..."
          crossorigin="anonymous">
  </noscript>
</head>
<body>
  <!-- Content -->
  
  <!-- Async scripts with SRI -->
  <script async
          src="https://cdn.example.com/analytics.js"
          integrity="sha384-..."
          crossorigin="anonymous"></script>
  
  <!-- Critical scripts defer with SRI -->
  <script defer
          src="https://cdn.example.com/app.js"
          integrity="sha384-..."
          crossorigin="anonymous"></script>
</body>
</html>
```

### Troubleshooting Common Issues

#### Integrity Mismatch Errors

**Symptom**: Resource fails to load with console error

```
Failed to find a valid digest in the 'integrity' attribute for resource 'https://cdn.example.com/library.js'
```

**Causes and Solutions**:

1. **Incorrect Hash**
    
    - Regenerate hash from actual file
    - Ensure no whitespace or encoding issues
    - Verify you're hashing the correct file version
2. **File Modified**
    
    - CDN updated the file
    - Pin to specific version in URL
    - Regenerate hash for new version
3. **Encoding Issues**
    
    - File served with different encoding
    - Check Content-Encoding headers
    - Generate hash from actual transmitted bytes

**Debug Script**:

```javascript
async function debugIntegrity(url, expectedIntegrity) {
  const response = await fetch(url);
  const buffer = await response.arrayBuffer();
  
  const [algo, expectedHash] = expectedIntegrity.split('-');
  const hashBuffer = await crypto.subtle.digest(
    algo.toUpperCase().replace('SHA', 'SHA-'),
    buffer
  );
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const actualHash = btoa(String.fromCharCode.apply(null, hashArray));
  
  console.log('Expected:', expectedIntegrity);
  console.log('Actual:', `${algo}-${actualHash}`);
  console.log('Match:', expectedHash === actualHash);
  console.log('File size:', buffer.byteLength);
  console.log('Content-Type:', response.headers.get('Content-Type'));
  console.log('Content-Encoding:', response.headers.get('Content-Encoding'));
}
```

#### CORS Issues

**Symptom**: Resource loads without SRI or throws CORS error

```
Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource
```

**Solutions**:

1. **Add crossorigin attribute**

```html
<!-- Before (doesn't work) -->
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."></script>

<!-- After (works) -->
<script src="https://cdn.example.com/library.js"
        integrity="sha384-..."
        crossorigin="anonymous"></script>
```

2. **Verify server CORS headers**

```bash
curl -I https://cdn.example.com/library.js
```

Should include:

```http
Access-Control-Allow-Origin: *
```

3. **Contact CDN provider** if headers missing

#### Browser Compatibility Issues

**Symptom**: SRI works in some browsers but not others

**Solutions**:

1. **Feature detection and fallback**

```javascript
if ('integrity' in document.createElement('script')) {
  // Use SRI
  loadWithIntegrity(url, hash);
} else {
  // Fallback without SRI
  console.warn('SRI not supported');
  loadWithoutIntegrity(url);
}
```

2. **Polyfill alternatives** (limited effectiveness)

```javascript
// Warning system for old browsers
if (!window.crypto || !window.crypto.subtle) {
  console.error('Crypto API not available - SRI may not work');
}
```

#### Performance Degradation

**Symptom**: Page load slower with SRI

**Investigation**:

1. **Measure actual impact**

```javascript
performance.mark('sri-start');

const script = document.createElement('script');
script.src = url;
script.integrity = hash;
script.crossOrigin = 'anonymous';
script.onload = () => {
  performance.mark('sri-end');
  performance.measure('sri-load', 'sri-start', 'sri-end');
  const measure = performance.getEntriesByName('sri-load')[0];
  console.log(`SRI load took: ${measure.duration}ms`);
};

document.head.appendChild(script);
```

2. **Optimize hash algorithm**

```html
<!-- Use SHA-384 instead of SHA-512 for better performance -->
<script src="..."
        integrity="sha384-..."
        crossorigin="anonymous"></script>
```

3. **Preload resources**

```html
<link rel="preload"
      href="https://cdn.example.com/library.js"
      as="script"
      integrity="sha384-..."
      crossorigin="anonymous">
```

#### Cache-Related Issues

**Symptom**: Updated file with old integrity hash

**Solutions**:

1. **Cache busting**

```html
<!-- Add version or hash to filename -->
<script src="https://cdn.example.com/library-v2.0.1.js"
        integrity="sha384-new-hash..."
        crossorigin="anonymous"></script>

<!-- Or query parameter -->
<script src="https://cdn.example.com/library.js?v=2.0.1"
        integrity="sha384-new-hash..."
        crossorigin="anonymous"></script>
```

2. **Clear service worker cache**

```javascript
// In service worker
self.addEventListener('activate', event => {
  event.waitUntil(
    caches.keys().then(cacheNames => {
      return Promise.all(
        cacheNames.map(cacheName => {
          if (cacheName !== CURRENT_CACHE) {
            return caches.delete(cacheName);
          }
        })
      );
    })
  );
});
```

3. **Update process**

```javascript
// Deployment script
const updateIntegrity = async () => {
  // 1. Generate new hash
  const newHash = await generateHash('library.js');
  
  // 2. Update HTML
  updateHTML(newHash);
  
  // 3. Clear CDN cache
  await purgeCDNCache();
  
  // 4. Increment service worker version
  bumpServiceWorkerVersion();
};
```

Subresource Integrity provides robust protection against compromised third-party resources through cryptographic verification. While it adds minimal overhead and requires careful hash management, the security benefits—particularly against supply chain attacks—make it an essential practice for modern web applications relying on CDN-hosted resources. Proper implementation requires attention to CORS configuration, hash generation workflows, and integration with build pipelines, but these investments pay dividends in enhanced security and user trust.

---

## Secure Headers

### Content Security Policy (CSP)

Content Security Policy restricts resource loading sources to prevent XSS attacks, clickjacking, and code injection. Configure CSP through headers returned by the server.

```javascript
const response = await fetch('/api/data', {
  method: 'POST',
  headers: {
    'Content-Security-Policy': "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; connect-src 'self' https://api.example.com"
  },
  body: JSON.stringify({ data })
});
```

CSP directives control specific resource types:

```javascript
const cspDirectives = {
  'default-src': "'self'",
  'script-src': "'self' 'unsafe-eval' https://cdn.example.com",
  'style-src': "'self' 'unsafe-inline' https://fonts.googleapis.com",
  'img-src': "'self' data: blob: https:",
  'font-src': "'self' https://fonts.gstatic.com",
  'connect-src': "'self' https://api.example.com wss://socket.example.com",
  'media-src': "'self' https://media.example.com",
  'object-src': "'none'",
  'frame-ancestors': "'none'",
  'base-uri': "'self'",
  'form-action': "'self'",
  'upgrade-insecure-requests': ''
};

const cspHeader = Object.entries(cspDirectives)
  .map(([key, value]) => `${key} ${value}`)
  .join('; ');
```

### Strict Transport Security (HSTS)

HSTS forces browsers to use HTTPS connections exclusively, preventing protocol downgrade attacks and cookie hijacking.

```javascript
// Server-side header configuration
const hstsHeader = 'max-age=31536000; includeSubDomains; preload';

// Client-side verification
const checkHSTS = (response) => {
  const hsts = response.headers.get('Strict-Transport-Security');
  if (!hsts) {
    console.warn('HSTS header missing');
    return false;
  }
  
  const hasMaxAge = /max-age=\d+/.test(hsts);
  const hasSubDomains = hsts.includes('includeSubDomains');
  const hasPreload = hsts.includes('preload');
  
  return { hasMaxAge, hasSubDomains, hasPreload };
};

const response = await fetch('https://api.example.com/data');
const hstsStatus = checkHSTS(response);
```

### X-Frame-Options

X-Frame-Options prevents clickjacking by controlling whether pages can be embedded in frames or iframes.

```javascript
// Three possible values:
// DENY - cannot be framed at all
// SAMEORIGIN - can only be framed by same origin
// ALLOW-FROM uri - can be framed by specific URI (deprecated)

const secureFetch = async (url, options = {}) => {
  const response = await fetch(url, options);
  
  const xFrameOptions = response.headers.get('X-Frame-Options');
  if (!xFrameOptions || xFrameOptions === 'ALLOW-FROM') {
    console.warn('Weak or missing X-Frame-Options header');
  }
  
  return response;
};
```

Modern alternative using CSP:

```javascript
const framingProtection = {
  'Content-Security-Policy': "frame-ancestors 'none'", // equivalent to DENY
  // or
  'Content-Security-Policy': "frame-ancestors 'self'", // equivalent to SAMEORIGIN
  // or
  'Content-Security-Policy': "frame-ancestors https://trusted.example.com"
};
```

### X-Content-Type-Options

X-Content-Type-Options prevents MIME type sniffing, forcing browsers to respect declared content types.

```javascript
const response = await fetch('/api/file', {
  headers: {
    'X-Content-Type-Options': 'nosniff'
  }
});

// Verify the header is present
const verifyNoSniff = (response) => {
  const noSniff = response.headers.get('X-Content-Type-Options');
  if (noSniff !== 'nosniff') {
    console.warn('X-Content-Type-Options not set to nosniff');
    return false;
  }
  return true;
};

verifyNoSniff(response);
```

### Referrer-Policy

Referrer-Policy controls how much referrer information is sent with requests, protecting user privacy and preventing information leakage.

```javascript
const referrerPolicies = [
  'no-referrer',                    // Never send referrer
  'no-referrer-when-downgrade',     // Default, no referrer on HTTPS->HTTP
  'origin',                         // Send only origin
  'origin-when-cross-origin',       // Full URL for same-origin, origin only for cross-origin
  'same-origin',                    // Send referrer for same-origin only
  'strict-origin',                  // Send origin, but not on HTTPS->HTTP
  'strict-origin-when-cross-origin', // Full URL same-origin, origin cross-origin, none on downgrade
  'unsafe-url'                      // Always send full URL (avoid this)
];

const response = await fetch('/api/data', {
  referrerPolicy: 'strict-origin-when-cross-origin'
});

// Or set via header
const response2 = await fetch('/api/data', {
  headers: {
    'Referrer-Policy': 'no-referrer'
  }
});
```

### Permissions-Policy

Permissions-Policy (formerly Feature-Policy) controls which browser features and APIs can be used.

```javascript
const permissionsPolicy = [
  'camera=()',                    // Disable camera
  'microphone=()',                // Disable microphone
  'geolocation=(self)',           // Allow geolocation for same-origin only
  'payment=(self "https://trusted.com")', // Allow payment for specific origins
  'usb=()',                       // Disable USB access
  'fullscreen=(self)',            // Allow fullscreen for same-origin
  'autoplay=()',                  // Disable autoplay
  'accelerometer=()',             // Disable accelerometer
  'gyroscope=()',                 // Disable gyroscope
  'magnetometer=()',              // Disable magnetometer
  'picture-in-picture=(self)'     // Allow PiP for same-origin
].join(', ');

// Server sets this header
// Client can verify it
const checkPermissionsPolicy = (response) => {
  const policy = response.headers.get('Permissions-Policy');
  return policy || 'No Permissions-Policy set';
};
```

### Cross-Origin-Embedder-Policy (COEP)

COEP prevents documents from loading cross-origin resources that don't explicitly grant permission.

```javascript
// require-corp: requires explicit CORP header from cross-origin resources
// credentialless: loads cross-origin resources without credentials
// unsafe-none: no enforcement (default)

const coepHeaders = {
  'Cross-Origin-Embedder-Policy': 'require-corp',
  'Cross-Origin-Resource-Policy': 'same-origin'
};

const response = await fetch('/api/resource', {
  headers: coepHeaders
});

// Verify COEP is enabled
const verifyCoep = (response) => {
  const coep = response.headers.get('Cross-Origin-Embedder-Policy');
  return coep === 'require-corp' || coep === 'credentialless';
};
```

### Cross-Origin-Opener-Policy (COOP)

COOP isolates browsing context groups, preventing cross-origin documents from interacting with popup windows.

```javascript
const coopValues = [
  'unsafe-none',           // Default, no isolation
  'same-origin',           // Isolates from cross-origin documents
  'same-origin-allow-popups' // Allows popups to stay in same group
];

const secureWindowOpen = async () => {
  // Fetch with COOP header
  const response = await fetch('/secure-page', {
    headers: {
      'Cross-Origin-Opener-Policy': 'same-origin'
    }
  });
  
  return response;
};

// Check if cross-origin isolation is enabled
const checkCrossOriginIsolation = () => {
  if (window.crossOriginIsolated) {
    console.log('Cross-origin isolation is active');
    // Can use SharedArrayBuffer and high-precision timers
    return true;
  }
  return false;
};
```

### Cross-Origin-Resource-Policy (CORP)

CORP protects resources from being loaded by cross-origin pages, preventing Spectre-style attacks.

```javascript
const corpValues = {
  'same-origin': 'same-origin',     // Only same-origin can load
  'same-site': 'same-site',         // Same-site can load
  'cross-origin': 'cross-origin'    // Anyone can load
};

const protectedResourceFetch = async (url) => {
  const response = await fetch(url, {
    headers: {
      'Cross-Origin-Resource-Policy': 'same-origin'
    }
  });
  
  const corp = response.headers.get('Cross-Origin-Resource-Policy');
  if (!corp) {
    console.warn('CORP header missing - resource may be vulnerable');
  }
  
  return response;
};
```

### Authorization Headers

Proper handling of authorization tokens in requests.

```javascript
// Bearer token authentication
const authenticatedFetch = async (url, token, options = {}) => {
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    }
  });
};

// Basic authentication (avoid in production, use OAuth/Bearer tokens)
const basicAuthFetch = async (url, username, password) => {
  const credentials = btoa(`${username}:${password}`);
  return fetch(url, {
    headers: {
      'Authorization': `Basic ${credentials}`
    }
  });
};

// API key authentication
const apiKeyFetch = async (url, apiKey) => {
  return fetch(url, {
    headers: {
      'X-API-Key': apiKey,
      // or
      'Authorization': `ApiKey ${apiKey}`
    }
  });
};
```

### Custom Security Headers

Application-specific security headers for additional protection.

```javascript
const customSecurityHeaders = {
  'X-Request-ID': crypto.randomUUID(),           // Request tracking
  'X-Correlation-ID': crypto.randomUUID(),       // Cross-service tracking
  'X-CSRF-Token': getCsrfToken(),                // CSRF protection
  'X-API-Version': '2.0',                        // API versioning
  'X-Client-ID': getClientId(),                  // Client identification
  'X-Request-Signature': generateSignature(),    // Request signing
  'X-Timestamp': Date.now().toString()           // Timestamp for replay protection
};

const secureRequest = async (url, data) => {
  return fetch(url, {
    method: 'POST',
    headers: {
      ...customSecurityHeaders,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
  });
};
```

### CSRF Token Handling

Cross-Site Request Forgery protection through token validation.

```javascript
// Retrieve CSRF token from meta tag or cookie
const getCsrfToken = () => {
  // From meta tag
  const metaToken = document.querySelector('meta[name="csrf-token"]')?.content;
  if (metaToken) return metaToken;
  
  // From cookie
  const cookieMatch = document.cookie.match(/XSRF-TOKEN=([^;]+)/);
  return cookieMatch ? decodeURIComponent(cookieMatch[1]) : null;
};

// Include CSRF token in requests
const csrfProtectedFetch = async (url, options = {}) => {
  const csrfToken = getCsrfToken();
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-CSRF-Token': csrfToken,
      // Some frameworks use X-XSRF-Token instead
      'X-XSRF-Token': csrfToken
    },
    credentials: 'same-origin' // Required for cookie-based CSRF
  });
};

// Double-submit cookie pattern
const doubleSubmitFetch = async (url, options = {}) => {
  const token = getCsrfToken();
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-CSRF-Token': token
    },
    credentials: 'include'
  });
};
```

### Rate Limiting Headers

Headers that communicate rate limit status to clients.

```javascript
const checkRateLimits = (response) => {
  return {
    limit: response.headers.get('X-RateLimit-Limit'),
    remaining: response.headers.get('X-RateLimit-Remaining'),
    reset: response.headers.get('X-RateLimit-Reset'),
    retryAfter: response.headers.get('Retry-After')
  };
};

const rateLimitAwareFetch = async (url, options = {}) => {
  const response = await fetch(url, options);
  
  if (response.status === 429) {
    const limits = checkRateLimits(response);
    const retryAfter = parseInt(limits.retryAfter || '60', 10);
    
    console.warn(`Rate limited. Retry after ${retryAfter} seconds`);
    
    // Wait and retry
    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
    return rateLimitAwareFetch(url, options);
  }
  
  const limits = checkRateLimits(response);
  if (limits.remaining && parseInt(limits.remaining) < 10) {
    console.warn(`Low rate limit remaining: ${limits.remaining}`);
  }
  
  return response;
};
```

### Security Headers Validation

Comprehensive validation of security headers in responses.

```javascript
class SecurityHeaderValidator {
  constructor() {
    this.requiredHeaders = {
      'Strict-Transport-Security': /max-age=\d+/,
      'X-Content-Type-Options': /nosniff/,
      'X-Frame-Options': /DENY|SAMEORIGIN/,
      'Referrer-Policy': /.+/,
      'Content-Security-Policy': /.+/
    };
    
    this.recommendedHeaders = {
      'Permissions-Policy': /.+/,
      'Cross-Origin-Embedder-Policy': /require-corp|credentialless/,
      'Cross-Origin-Opener-Policy': /same-origin/,
      'Cross-Origin-Resource-Policy': /same-origin|same-site/
    };
  }
  
  validate(response) {
    const results = {
      passed: [],
      failed: [],
      missing: [],
      warnings: []
    };
    
    // Check required headers
    for (const [header, pattern] of Object.entries(this.requiredHeaders)) {
      const value = response.headers.get(header);
      
      if (!value) {
        results.failed.push({ header, reason: 'Missing' });
      } else if (!pattern.test(value)) {
        results.failed.push({ header, reason: 'Invalid value', value });
      } else {
        results.passed.push(header);
      }
    }
    
    // Check recommended headers
    for (const [header, pattern] of Object.entries(this.recommendedHeaders)) {
      const value = response.headers.get(header);
      
      if (!value) {
        results.warnings.push({ header, reason: 'Missing (recommended)' });
      } else if (!pattern.test(value)) {
        results.warnings.push({ header, reason: 'Weak value', value });
      } else {
        results.passed.push(header);
      }
    }
    
    return results;
  }
  
  report(results) {
    console.group('Security Headers Validation');
    
    if (results.passed.length > 0) {
      console.log('✓ Passed:', results.passed.join(', '));
    }
    
    if (results.failed.length > 0) {
      console.error('✗ Failed:');
      results.failed.forEach(f => 
        console.error(`  - ${f.header}: ${f.reason}`, f.value || '')
      );
    }
    
    if (results.warnings.length > 0) {
      console.warn('⚠ Warnings:');
      results.warnings.forEach(w => 
        console.warn(`  - ${w.header}: ${w.reason}`, w.value || '')
      );
    }
    
    console.groupEnd();
    
    return results.failed.length === 0;
  }
}

const validator = new SecurityHeaderValidator();
const response = await fetch('/api/data');
const results = validator.validate(response);
const isSecure = validator.report(results);
```

### Cache-Control Security

Cache-Control directives that affect security and privacy.

```javascript
const sensitiveDataFetch = async (url) => {
  return fetch(url, {
    headers: {
      'Cache-Control': 'no-store, no-cache, must-revalidate, private',
      'Pragma': 'no-cache',
      'Expires': '0'
    }
  });
};

// Different cache policies for different data types
const cacheStrategies = {
  sensitive: {
    'Cache-Control': 'no-store, no-cache, must-revalidate, private',
    'Pragma': 'no-cache'
  },
  
  authenticated: {
    'Cache-Control': 'private, max-age=0, must-revalidate'
  },
  
  public: {
    'Cache-Control': 'public, max-age=31536000, immutable'
  },
  
  api: {
    'Cache-Control': 'private, no-cache, no-store, must-revalidate'
  }
};

const fetchWithCachePolicy = async (url, dataType = 'sensitive') => {
  return fetch(url, {
    headers: cacheStrategies[dataType]
  });
};
```

### Request Signing

Cryptographic signing of requests for integrity and authentication.

```javascript
const signRequest = async (method, url, body, secretKey) => {
  const timestamp = Date.now().toString();
  const nonce = crypto.randomUUID();
  
  // Create signature payload
  const payload = [
    method,
    url,
    timestamp,
    nonce,
    body ? JSON.stringify(body) : ''
  ].join('\n');
  
  // Generate HMAC signature
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secretKey);
  const messageData = encoder.encode(payload);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  const signatureHex = Array.from(new Uint8Array(signature))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  return {
    signature: signatureHex,
    timestamp,
    nonce
  };
};

const signedFetch = async (url, options = {}, secretKey) => {
  const { signature, timestamp, nonce } = await signRequest(
    options.method || 'GET',
    url,
    options.body,
    secretKey
  );
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Timestamp': timestamp,
      'X-Nonce': nonce
    }
  });
};
```

### Origin Validation

Validating origin headers to prevent unauthorized cross-origin requests.

```javascript
const validateOrigin = (response, expectedOrigin) => {
  const origin = response.headers.get('Access-Control-Allow-Origin');
  const vary = response.headers.get('Vary');
  
  // Check if origin matches expected
  if (origin !== expectedOrigin && origin !== '*') {
    console.warn(`Unexpected origin: ${origin}`);
    return false;
  }
  
  // Ensure Vary header includes Origin for proper caching
  if (origin !== '*' && (!vary || !vary.includes('Origin'))) {
    console.warn('Vary header should include Origin');
  }
  
  return true;
};

const originAwareFetch = async (url, expectedOrigin) => {
  const response = await fetch(url, {
    headers: {
      'Origin': window.location.origin
    }
  });
  
  validateOrigin(response, expectedOrigin);
  return response;
};
```

### Security Header Middleware

Utility for consistently applying security headers to all fetch requests.

```javascript
class SecureFetchMiddleware {
  constructor(config = {}) {
    this.defaultHeaders = {
      'X-Content-Type-Options': 'nosniff',
      'X-Frame-Options': 'DENY',
      'Referrer-Policy': 'strict-origin-when-cross-origin',
      ...config.headers
    };
    
    this.csrfEnabled = config.csrf !== false;
    this.authToken = config.authToken;
    this.apiKey = config.apiKey;
  }
  
  async fetch(url, options = {}) {
    const headers = {
      ...this.defaultHeaders,
      ...options.headers
    };
    
    // Add CSRF token if enabled
    if (this.csrfEnabled) {
      const csrfToken = getCsrfToken();
      if (csrfToken) {
        headers['X-CSRF-Token'] = csrfToken;
      }
    }
    
    // Add authentication
    if (this.authToken) {
      headers['Authorization'] = `Bearer ${this.authToken}`;
    }
    
    if (this.apiKey) {
      headers['X-API-Key'] = this.apiKey;
    }
    
    // Add request ID for tracking
    headers['X-Request-ID'] = crypto.randomUUID();
    
    const response = await fetch(url, {
      ...options,
      headers
    });
    
    // Validate response headers
    this.validateResponse(response);
    
    return response;
  }
  
  validateResponse(response) {
    const requiredHeaders = [
      'X-Content-Type-Options',
      'X-Frame-Options'
    ];
    
    const missing = requiredHeaders.filter(
      header => !response.headers.get(header)
    );
    
    if (missing.length > 0) {
      console.warn('Missing security headers:', missing);
    }
  }
  
  setAuthToken(token) {
    this.authToken = token;
  }
  
  setApiKey(key) {
    this.apiKey = key;
  }
}

// Usage
const secureFetch = new SecureFetchMiddleware({
  csrf: true,
  authToken: 'your-jwt-token',
  headers: {
    'Custom-Security-Header': 'value'
  }
});

const response = await secureFetch.fetch('/api/data', {
  method: 'POST',
  body: JSON.stringify({ data: 'value' })
});
```

---

## Input Validation

### URL Validation

#### URL Format Validation

The Fetch API accepts various URL formats, but not all inputs are valid:

```javascript
// Valid URLs
fetch('https://example.com');
fetch('http://example.com/api');
fetch('/api/endpoint');  // Relative URL
fetch('//cdn.example.com/file.js');  // Protocol-relative

// Invalid URLs - throw TypeError
fetch('not a url');
fetch('ht!tp://invalid');
fetch('javascript:alert(1)');  // Blocked for security
```

**Validation approaches:**

```javascript
function isValidURL(string) {
  try {
    new URL(string, window.location.origin);
    return true;
  } catch (e) {
    return false;
  }
}

// Usage
if (isValidURL(userInput)) {
  await fetch(userInput);
} else {
  throw new Error('Invalid URL format');
}
```

**URL constructor validation:**

```javascript
function validateAndNormalize(url) {
  try {
    const parsed = new URL(url, window.location.origin);
    
    // Additional checks
    if (!['http:', 'https:'].includes(parsed.protocol)) {
      throw new Error('Only HTTP/HTTPS protocols allowed');
    }
    
    return parsed.href;
  } catch (e) {
    throw new Error(`Invalid URL: ${e.message}`);
  }
}
```

#### Protocol Restrictions

Fetch has built-in protocol restrictions for security:

**Allowed protocols:**

- `http:`
- `https:`
- `data:` (with limitations)
- `blob:`
- `file:` (limited context)

**Blocked protocols:**

- `javascript:` - XSS vector
- `vbscript:` - XSS vector
- `data:text/html` - Can execute scripts
- `file:` - Usually blocked in web contexts

```javascript
function validateProtocol(url) {
  const parsed = new URL(url, window.location.origin);
  const allowed = ['http:', 'https:'];
  
  if (!allowed.includes(parsed.protocol)) {
    throw new Error(`Protocol ${parsed.protocol} not allowed`);
  }
  
  return url;
}
```

#### Domain Whitelisting

Restrict requests to trusted domains:

```javascript
class DomainValidator {
  constructor(allowedDomains) {
    this.allowedDomains = new Set(allowedDomains);
  }
  
  validate(url) {
    const parsed = new URL(url, window.location.origin);
    
    // Check exact domain match
    if (this.allowedDomains.has(parsed.hostname)) {
      return true;
    }
    
    // Check subdomain wildcards
    for (const domain of this.allowedDomains) {
      if (domain.startsWith('*.')) {
        const baseDomain = domain.slice(2);
        if (parsed.hostname.endsWith(baseDomain)) {
          return true;
        }
      }
    }
    
    return false;
  }
  
  async fetch(url, options) {
    if (!this.validate(url)) {
      throw new Error(`Domain not allowed: ${new URL(url).hostname}`);
    }
    return fetch(url, options);
  }
}

// Usage
const validator = new DomainValidator([
  'api.example.com',
  '*.cdn.example.com',
  'example.com'
]);

await validator.fetch('https://api.example.com/data');
```

#### Path Traversal Prevention

Prevent directory traversal attacks in URL paths:

```javascript
function sanitizePath(path) {
  // Remove path traversal sequences
  const normalized = path
    .replace(/\\/g, '/')  // Normalize slashes
    .replace(/\/+/g, '/')  // Remove duplicate slashes
    .replace(/\/\.\.\//g, '/')  // Remove ../
    .replace(/\/\.\//g, '/')  // Remove ./
    .replace(/^\.\.\//, '');  // Remove leading ../
  
  // Ensure no traversal attempts remain
  if (normalized.includes('..')) {
    throw new Error('Path traversal detected');
  }
  
  return normalized;
}

// Usage
const userPath = sanitizePath(userInput);
await fetch(`/api/files/${userPath}`);
```

**More robust validation:**

```javascript
function validatePath(basePath, userPath) {
  const path = require('path');  // Node.js
  const normalized = path.normalize(userPath);
  const absolute = path.resolve(basePath, normalized);
  
  // Ensure path stays within base directory
  if (!absolute.startsWith(path.resolve(basePath))) {
    throw new Error('Path traversal attempt detected');
  }
  
  return absolute;
}
```

#### Query Parameter Validation

Validate and sanitize query parameters:

```javascript
function validateQueryParams(params) {
  const allowedParams = new Set(['page', 'limit', 'sort', 'filter']);
  const validated = {};
  
  for (const [key, value] of Object.entries(params)) {
    // Check if parameter is allowed
    if (!allowedParams.has(key)) {
      throw new Error(`Parameter '${key}' not allowed`);
    }
    
    // Validate parameter value
    switch (key) {
      case 'page':
      case 'limit':
        const num = parseInt(value, 10);
        if (isNaN(num) || num < 1 || num > 1000) {
          throw new Error(`Invalid ${key} value`);
        }
        validated[key] = num;
        break;
        
      case 'sort':
        if (!/^[a-zA-Z_]+$/.test(value)) {
          throw new Error('Invalid sort field');
        }
        validated[key] = value;
        break;
        
      case 'filter':
        // Sanitize filter value
        validated[key] = value.replace(/[^\w\s-]/g, '');
        break;
    }
  }
  
  return validated;
}

// Usage
const params = validateQueryParams({ page: '1', limit: '50' });
const query = new URLSearchParams(params);
await fetch(`/api/data?${query}`);
```

### Header Validation

#### Header Name Validation

Fetch API enforces header name restrictions:

**Forbidden header names (controlled by browser):**

- `Accept-Charset`
- `Accept-Encoding`
- `Access-Control-Request-Headers`
- `Access-Control-Request-Method`
- `Connection`
- `Content-Length`
- `Cookie`
- `Cookie2`
- `Date`
- `DNT`
- `Expect`
- `Host`
- `Keep-Alive`
- `Origin`
- `Referer`
- `TE`
- `Trailer`
- `Transfer-Encoding`
- `Upgrade`
- `Via`
- Headers starting with `Proxy-` or `Sec-`

```javascript
function isValidHeaderName(name) {
  // Forbidden headers
  const forbidden = new Set([
    'accept-charset', 'accept-encoding', 'access-control-request-headers',
    'access-control-request-method', 'connection', 'content-length',
    'cookie', 'cookie2', 'date', 'dnt', 'expect', 'host',
    'keep-alive', 'origin', 'referer', 'te', 'trailer',
    'transfer-encoding', 'upgrade', 'via'
  ]);
  
  const lower = name.toLowerCase();
  
  if (forbidden.has(lower)) {
    return false;
  }
  
  if (lower.startsWith('proxy-') || lower.startsWith('sec-')) {
    return false;
  }
  
  // Valid header name pattern
  return /^[a-zA-Z0-9!#$%&'*+\-.^_`|~]+$/.test(name);
}

// Usage
if (isValidHeaderName(userHeaderName)) {
  await fetch(url, {
    headers: { [userHeaderName]: value }
  });
}
```

#### Header Value Validation

Header values must follow HTTP field-value format:

```javascript
function validateHeaderValue(value) {
  // Convert to string
  const str = String(value);
  
  // Check for invalid characters
  // Header values can contain visible ASCII and whitespace
  if (!/^[\x20-\x7E\t]*$/.test(str)) {
    throw new Error('Invalid header value characters');
  }
  
  // Check for CRLF injection
  if (str.includes('\r') || str.includes('\n')) {
    throw new Error('CRLF injection attempt detected');
  }
  
  return str.trim();
}

// Usage
const safeValue = validateHeaderValue(userInput);
await fetch(url, {
  headers: { 'X-Custom-Header': safeValue }
});
```

#### Content-Type Validation

Validate Content-Type headers for API requests:

```javascript
function validateContentType(contentType) {
  const allowed = new Set([
    'application/json',
    'application/x-www-form-urlencoded',
    'multipart/form-data',
    'text/plain',
    'application/xml',
    'text/xml'
  ]);
  
  // Extract MIME type without parameters
  const mimeType = contentType.split(';')[0].trim().toLowerCase();
  
  if (!allowed.has(mimeType)) {
    throw new Error(`Content-Type '${mimeType}' not allowed`);
  }
  
  return contentType;
}

// Usage
const contentType = validateContentType(userContentType);
await fetch(url, {
  method: 'POST',
  headers: { 'Content-Type': contentType },
  body: data
});
```

#### Authorization Header Validation

Validate authorization tokens:

```javascript
function validateBearerToken(token) {
  // Basic format check
  if (typeof token !== 'string' || token.length === 0) {
    throw new Error('Invalid token format');
  }
  
  // Check for JWT format (if using JWTs)
  const jwtPattern = /^[A-Za-z0-9-_]+\.[A-Za-z0-9-_]+\.[A-Za-z0-9-_]+$/;
  if (!jwtPattern.test(token)) {
    throw new Error('Invalid JWT token format');
  }
  
  // Length validation
  if (token.length > 4096) {
    throw new Error('Token too long');
  }
  
  return token;
}

// Usage
const token = validateBearerToken(userToken);
await fetch(url, {
  headers: {
    'Authorization': `Bearer ${token}`
  }
});
```

#### Custom Header Validation Wrapper

```javascript
class HeaderValidator {
  constructor(rules) {
    this.rules = rules;
  }
  
  validate(headers) {
    const validated = {};
    
    for (const [name, value] of Object.entries(headers)) {
      const lower = name.toLowerCase();
      
      // Check if header is allowed
      if (!this.rules[lower]) {
        throw new Error(`Header '${name}' not allowed`);
      }
      
      // Apply validation rule
      const rule = this.rules[lower];
      const validatedValue = rule(value);
      
      validated[name] = validatedValue;
    }
    
    return validated;
  }
}

// Define rules
const validator = new HeaderValidator({
  'content-type': (v) => {
    const allowed = ['application/json', 'text/plain'];
    if (!allowed.includes(v.split(';')[0].trim())) {
      throw new Error('Invalid Content-Type');
    }
    return v;
  },
  'x-api-key': (v) => {
    if (!/^[a-zA-Z0-9]{32}$/.test(v)) {
      throw new Error('Invalid API key format');
    }
    return v;
  },
  'authorization': (v) => {
    if (!v.startsWith('Bearer ')) {
      throw new Error('Authorization must use Bearer scheme');
    }
    return v;
  }
});

// Usage
const headers = validator.validate({
  'Content-Type': 'application/json',
  'X-API-Key': 'abcd1234...'
});

await fetch(url, { headers });
```

### Body Validation

#### JSON Payload Validation

Validate JSON structure before sending:

```javascript
function validateJSON(data, schema) {
  // Type checking
  if (typeof data !== 'object' || data === null) {
    throw new Error('Payload must be an object');
  }
  
  // Required fields
  for (const field of schema.required || []) {
    if (!(field in data)) {
      throw new Error(`Missing required field: ${field}`);
    }
  }
  
  // Field validation
  for (const [key, value] of Object.entries(data)) {
    const fieldSchema = schema.properties?.[key];
    
    if (!fieldSchema) {
      if (!schema.additionalProperties) {
        throw new Error(`Unexpected field: ${key}`);
      }
      continue;
    }
    
    // Type validation
    const actualType = Array.isArray(value) ? 'array' : typeof value;
    if (fieldSchema.type && actualType !== fieldSchema.type) {
      throw new Error(`Field '${key}' must be ${fieldSchema.type}`);
    }
    
    // String validation
    if (fieldSchema.type === 'string') {
      if (fieldSchema.minLength && value.length < fieldSchema.minLength) {
        throw new Error(`Field '${key}' too short`);
      }
      if (fieldSchema.maxLength && value.length > fieldSchema.maxLength) {
        throw new Error(`Field '${key}' too long`);
      }
      if (fieldSchema.pattern && !new RegExp(fieldSchema.pattern).test(value)) {
        throw new Error(`Field '${key}' invalid format`);
      }
    }
    
    // Number validation
    if (fieldSchema.type === 'number') {
      if (fieldSchema.minimum !== undefined && value < fieldSchema.minimum) {
        throw new Error(`Field '${key}' below minimum`);
      }
      if (fieldSchema.maximum !== undefined && value > fieldSchema.maximum) {
        throw new Error(`Field '${key}' above maximum`);
      }
    }
    
    // Array validation
    if (fieldSchema.type === 'array') {
      if (fieldSchema.minItems && value.length < fieldSchema.minItems) {
        throw new Error(`Field '${key}' needs at least ${fieldSchema.minItems} items`);
      }
      if (fieldSchema.maxItems && value.length > fieldSchema.maxItems) {
        throw new Error(`Field '${key}' has too many items`);
      }
    }
  }
  
  return data;
}

// Schema definition
const userSchema = {
  required: ['username', 'email'],
  properties: {
    username: {
      type: 'string',
      minLength: 3,
      maxLength: 20,
      pattern: '^[a-zA-Z0-9_]+$'
    },
    email: {
      type: 'string',
      pattern: '^[\\w.-]+@[\\w.-]+\\.\\w+$'
    },
    age: {
      type: 'number',
      minimum: 13,
      maximum: 120
    }
  },
  additionalProperties: false
};

// Usage
try {
  const validated = validateJSON(userData, userSchema);
  await fetch('/api/users', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(validated)
  });
} catch (e) {
  console.error('Validation error:', e.message);
}
```

#### Size Limits

Enforce payload size restrictions:

```javascript
function validateSize(data, maxSize = 1024 * 1024) { // 1MB default
  let size;
  
  if (typeof data === 'string') {
    size = new Blob([data]).size;
  } else if (data instanceof Blob || data instanceof File) {
    size = data.size;
  } else if (data instanceof ArrayBuffer) {
    size = data.byteLength;
  } else if (ArrayBuffer.isView(data)) {
    size = data.byteLength;
  } else if (data instanceof FormData) {
    // FormData size is harder to determine exactly
    // Estimate or reject if too uncertain
    throw new Error('Cannot validate FormData size client-side');
  } else {
    // For objects, stringify first
    size = new Blob([JSON.stringify(data)]).size;
  }
  
  if (size > maxSize) {
    throw new Error(`Payload too large: ${size} bytes (max: ${maxSize})`);
  }
  
  return data;
}

// Usage
const maxSize = 5 * 1024 * 1024; // 5MB
validateSize(requestBody, maxSize);
await fetch(url, {
  method: 'POST',
  body: requestBody
});
```

#### Data Sanitization

Remove potentially dangerous content:

```javascript
function sanitizeObject(obj, maxDepth = 5, currentDepth = 0) {
  if (currentDepth > maxDepth) {
    throw new Error('Object too deeply nested');
  }
  
  if (obj === null || typeof obj !== 'object') {
    return sanitizeValue(obj);
  }
  
  if (Array.isArray(obj)) {
    return obj.map(item => sanitizeObject(item, maxDepth, currentDepth + 1));
  }
  
  const sanitized = {};
  for (const [key, value] of Object.entries(obj)) {
    // Sanitize key
    const safeKey = sanitizeKey(key);
    
    // Recursively sanitize value
    sanitized[safeKey] = sanitizeObject(value, maxDepth, currentDepth + 1);
  }
  
  return sanitized;
}

function sanitizeKey(key) {
  // Remove potentially dangerous characters from keys
  return key.replace(/[^\w.-]/g, '_');
}

function sanitizeValue(value) {
  if (typeof value === 'string') {
    // Remove control characters
    return value.replace(/[\x00-\x1F\x7F]/g, '');
  }
  return value;
}

// Usage
const sanitized = sanitizeObject(userInput);
await fetch(url, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(sanitized)
});
```

#### FormData Validation

Validate multipart form data:

```javascript
function validateFormData(formData, schema) {
  const validated = new FormData();
  
  for (const [name, value] of formData.entries()) {
    const fieldSchema = schema[name];
    
    if (!fieldSchema) {
      throw new Error(`Unexpected field: ${name}`);
    }
    
    if (value instanceof File) {
      // File validation
      if (fieldSchema.type !== 'file') {
        throw new Error(`Field '${name}' should not be a file`);
      }
      
      // File size
      if (fieldSchema.maxSize && value.size > fieldSchema.maxSize) {
        throw new Error(`File '${name}' too large`);
      }
      
      // File type
      if (fieldSchema.accept) {
        const allowedTypes = fieldSchema.accept.split(',').map(t => t.trim());
        const matches = allowedTypes.some(type => {
          if (type.endsWith('/*')) {
            return value.type.startsWith(type.slice(0, -1));
          }
          return value.type === type;
        });
        
        if (!matches) {
          throw new Error(`File '${name}' has invalid type: ${value.type}`);
        }
      }
      
      validated.append(name, value);
    } else {
      // Text field validation
      const str = String(value);
      
      if (fieldSchema.maxLength && str.length > fieldSchema.maxLength) {
        throw new Error(`Field '${name}' too long`);
      }
      
      if (fieldSchema.pattern && !new RegExp(fieldSchema.pattern).test(str)) {
        throw new Error(`Field '${name}' invalid format`);
      }
      
      validated.append(name, str);
    }
  }
  
  // Check required fields
  for (const [name, schema] of Object.entries(schema)) {
    if (schema.required && !formData.has(name)) {
      throw new Error(`Missing required field: ${name}`);
    }
  }
  
  return validated;
}

// Schema
const formSchema = {
  username: {
    type: 'text',
    required: true,
    maxLength: 50,
    pattern: '^[a-zA-Z0-9_]+$'
  },
  avatar: {
    type: 'file',
    required: false,
    maxSize: 5 * 1024 * 1024, // 5MB
    accept: 'image/jpeg,image/png,image/webp'
  }
};

// Usage
const validated = validateFormData(formData, formSchema);
await fetch('/api/upload', {
  method: 'POST',
  body: validated
});
```

### Method Validation

#### HTTP Method Validation

Ensure valid HTTP methods:

```javascript
function validateMethod(method) {
  const validMethods = new Set([
    'GET', 'POST', 'PUT', 'DELETE', 'PATCH',
    'HEAD', 'OPTIONS', 'CONNECT', 'TRACE'
  ]);
  
  const upper = method.toUpperCase();
  
  if (!validMethods.has(upper)) {
    throw new Error(`Invalid HTTP method: ${method}`);
  }
  
  return upper;
}

// With restrictions
function validateMethodWithPolicy(method, allowedMethods) {
  const upper = method.toUpperCase();
  const allowed = new Set(allowedMethods.map(m => m.toUpperCase()));
  
  if (!allowed.has(upper)) {
    throw new Error(`Method '${upper}' not allowed`);
  }
  
  return upper;
}

// Usage
const method = validateMethodWithPolicy(userMethod, ['GET', 'POST']);
await fetch(url, { method });
```

#### Method-Body Consistency

Validate that method and body are consistent:

```javascript
function validateMethodBodyConsistency(method, body) {
  const upper = method.toUpperCase();
  const methodsWithoutBody = new Set(['GET', 'HEAD', 'OPTIONS']);
  
  if (methodsWithoutBody.has(upper) && body !== null && body !== undefined) {
    throw new Error(`${upper} requests cannot have a body`);
  }
  
  const methodsWithBody = new Set(['POST', 'PUT', 'PATCH']);
  if (methodsWithBody.has(upper) && (body === null || body === undefined)) {
    console.warn(`${upper} request typically requires a body`);
  }
}

// Usage
validateMethodBodyConsistency('GET', requestBody); // Throws
validateMethodBodyConsistency('POST', requestBody); // OK
```

### Options Validation

#### Credentials Validation

Validate credentials mode:

```javascript
function validateCredentials(credentials) {
  const valid = new Set(['omit', 'same-origin', 'include']);
  
  if (!valid.has(credentials)) {
    throw new Error(`Invalid credentials mode: ${credentials}`);
  }
  
  return credentials;
}

// Context-aware validation
function validateCredentialsForURL(credentials, url) {
  const parsed = new URL(url, window.location.origin);
  
  if (credentials === 'include' && parsed.origin !== window.location.origin) {
    console.warn('Using credentials: include for cross-origin request');
  }
  
  return credentials;
}
```

#### Mode Validation

Validate request mode:

```javascript
function validateMode(mode) {
  const valid = new Set(['cors', 'no-cors', 'same-origin', 'navigate']);
  
  if (!valid.has(mode)) {
    throw new Error(`Invalid mode: ${mode}`);
  }
  
  return mode;
}

// With restrictions
function validateModeRestrictions(mode, method, hasCustomHeaders) {
  if (mode === 'no-cors') {
    const allowedMethods = new Set(['GET', 'HEAD', 'POST']);
    if (!allowedMethods.has(method.toUpperCase())) {
      throw new Error(`Method ${method} not allowed in no-cors mode`);
    }
    
    if (hasCustomHeaders) {
      throw new Error('Custom headers not allowed in no-cors mode');
    }
  }
  
  return mode;
}
```

#### Cache Validation

Validate cache mode:

```javascript
function validateCache(cache) {
  const valid = new Set([
    'default', 'no-store', 'reload', 'no-cache',
    'force-cache', 'only-if-cached'
  ]);
  
  if (!valid.has(cache)) {
    throw new Error(`Invalid cache mode: ${cache}`);
  }
  
  return cache;
}

// Mode-specific validation
function validateCacheForMode(cache, mode) {
  if (cache === 'only-if-cached' && mode !== 'same-origin') {
    throw new Error('only-if-cached requires same-origin mode');
  }
  
  return cache;
}
```

#### Redirect Validation

Validate redirect mode:

```javascript
function validateRedirect(redirect) {
  const valid = new Set(['follow', 'error', 'manual']);
  
  if (!valid.has(redirect)) {
    throw new Error(`Invalid redirect mode: ${redirect}`);
  }
  
  return redirect;
}
```

### Comprehensive Validation Wrapper

#### Request Validator Class

```javascript
class RequestValidator {
  constructor(config = {}) {
    this.config = {
      maxUrlLength: 2048,
      maxHeaderSize: 8192,
      maxBodySize: 10 * 1024 * 1024, // 10MB
      allowedDomains: null,
      allowedMethods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
      allowedHeaders: null, // null = all allowed
      requireHTTPS: false,
      ...config
    };
  }
  
  validateURL(url) {
    // Length check
    if (url.length > this.config.maxUrlLength) {
      throw new Error('URL too long');
    }
    
    // Parse and validate
    let parsed;
    try {
      parsed = new URL(url, window.location.origin);
    } catch (e) {
      throw new Error(`Invalid URL: ${e.message}`);
    }
    
    // Protocol check
    if (!['http:', 'https:'].includes(parsed.protocol)) {
      throw new Error('Only HTTP/HTTPS protocols allowed');
    }
    
    // HTTPS requirement
    if (this.config.requireHTTPS && parsed.protocol !== 'https:') {
      throw new Error('HTTPS required');
    }
    
    // Domain whitelist
    if (this.config.allowedDomains) {
      const allowed = this.config.allowedDomains.some(domain => {
        if (domain.startsWith('*.')) {
          return parsed.hostname.endsWith(domain.slice(2));
        }
        return parsed.hostname === domain;
      });
      
      if (!allowed) {
        throw new Error(`Domain not allowed: ${parsed.hostname}`);
      }
    }
    
    return parsed.href;
  }
  
  validateMethod(method) {
    const upper = method.toUpperCase();
    
    if (!this.config.allowedMethods.includes(upper)) {
      throw new Error(`Method not allowed: ${upper}`);
    }
    
    return upper;
  }
  
  validateHeaders(headers) {
    if (!headers) return {};
    
    const validated = {};
    let totalSize = 0;
    
    for (const [name, value] of Object.entries(headers)) {
      // Header name validation
      if (!/^[a-zA-Z0-9!#$%&'*+\-.^_`|~]+$/.test(name)) {
        throw new Error(`Invalid header name: ${name}`);
      }
      
      // Whitelist check
      if (this.config.allowedHeaders) {
        if (!this.config.allowedHeaders.includes(name.toLowerCase())) {
          throw new Error(`Header not allowed: ${name}`);
        }
      }
      
      // Value validation
      const str = String(value);
      if (str.includes('\r') || str.includes('\n')) {
        throw new Error('Header value contains CRLF');
      }
      
      totalSize += name.length + str.length + 4; // +4 for ": " and "\r\n"
      validated[name] = str;
    }
    
    // Total header size check
    if (totalSize > this.config.maxHeaderSize) {
      throw new Error('Headers too large');
    }
    
    return validated;
  }
  
  validateBody(body) {
    if (body === null || body === undefined) {
      return body;
    }
    
    let size;
    
    if (typeof body === 'string') {
      size = new Blob([body]).size;
    } else if (body instanceof Blob || body instanceof File) {
      size = body.size;
    } else if (body instanceof ArrayBuffer) {
      size = body.byteLength;
    } else if (ArrayBuffer.isView(body)) {
      size = body.byteLength;
    } else {
      // Estimate for other types
      size = new Blob([JSON.stringify(body)]).size;
    }
    
    if (size > this.config.maxBodySize) {
      throw new Error(`Body too large: ${size} bytes`);
    }
    
    return body;
  }
  
  validateOptions(options) {
    const validated = { ...options };
    
    // Validate mode
    if (options.mode) {
      const validModes = new Set(['cors', 'no-cors', 'same-origin']);
      if (!validModes.has(options.mode)) {
        throw new Error(`Invalid mode: ${options.mode}`);
      }
    }
    
    // Validate credentials
    if (options.credentials) {
      const validCreds = new Set(['omit', 'same-origin', 'include']);
      if (!validCreds.has(options.credentials)) {
        throw new Error(`Invalid credentials: ${options.credentials}`);
      }
    }
    
    // Validate cache
    if (options.cache) {
      const validCache = new Set([
        'default', 'no-store', 'reload', 'no-cache',
        'force-cache', 'only-if-cached'
      ]);
      if (!validCache.has(options.cache)) {
        throw new Error(`Invalid cache: ${options.cache}`);
      }
      
      // only-if-cached requires same-origin
      if (options.cache === 'only-if-cached' && options.mode !== 'same-origin') {
        throw new Error('only-if-cached requires same-origin mode');
      }
    }
    
    // Validate redirect
    if (options.redirect) {
      const validRedirect = new Set(['follow', 'error', 'manual']);
      if (!validRedirect.has(options.redirect)) {
        throw new Error(`Invalid redirect: ${options.redirect}`);
      }
    }
    
    return validated;
  }
  
  async fetch(url, options = {}) {
    // Validate all components
    const validURL = this.validateURL(url);
    const validMethod = this.validateMethod(options.method || 'GET');
    const validHeaders = this.validateHeaders(options.headers);
    const validBody = this.validateBody(options.body);
    const validOptions = this.validateOptions(options);
    
    // Method-body consistency
    const methodsWithoutBody = new Set(['GET', 'HEAD', 'OPTIONS']);
    if (methodsWithoutBody.has(validMethod) && validBody) {
      throw new Error(`${validMethod} requests cannot have a body`);
    }
    
    // Execute request
    return fetch(validURL, {
      ...validOptions,
      method: validMethod,
      headers: validHeaders,
      body: validBody
    });
  }
}

// Usage
const validator = new RequestValidator({
  allowedDomains: ['api.example.com', '*.cdn.example.com'],
  maxBodySize: 5 * 1024 * 1024,
  requireHTTPS: true
});

await validator.fetch('https://api.example.com/data', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(data)
});
```

### Security-Focused Validation

#### XSS Prevention in URLs

```javascript
function preventXSSInURL(url) {
  const parsed = new URL(url, window.location.origin);
  
  // Check for javascript: protocol
  if (parsed.protocol === 'javascript:') {
    throw new Error('JavaScript URLs not allowed');
  }
  
  // Check for data URLs with HTML
  if (parsed.protocol === 'data:') {
    const [mediaType] = parsed.pathname.split(',');
    if (mediaType.toLowerCase().includes('text/html')) {
      throw new Error('data: URLs with HTML not allowed');
  }
  }
  
  // Check for encoded javascript:
  const decoded = decodeURIComponent(url);
  if (decoded.toLowerCase().startsWith('javascript:')) {
    throw new Error('Encoded JavaScript URLs not allowed');
  }
  
  return url;
}
```

#### SQL Injection Prevention

When building URLs with user input:

```javascript
function sanitizeForURL(value) {
  // Remove SQL-like keywords and characters
  const dangerous = [
    "'", '"', ';', '--', '/*', '*/', 'xp_', 'sp_',
    'exec', 'execute', 'select', 'insert', 'update', 'delete',
    'drop', 'create', 'alter', 'union', 'script'
  ];
  
  let sanitized = String(value);
  
  for (const pattern of dangerous) {
    const regex = new RegExp(pattern, 'gi');
    sanitized = sanitized.replace(regex, '');
  }
  
  // Also encode for URL
  return encodeURIComponent(sanitized);
}

// Usage
const userId = sanitizeForURL(userInput);
await fetch(`/api/users/${userId}`);
```

**Note:** This client-side sanitization is not a complete defense. [Inference] Server-side parameterized queries or prepared statements are necessary for SQL injection protection.

#### SSRF Prevention

Prevent Server-Side Request Forgery by blocking internal addresses:

```javascript
function preventSSRF(url) {
  const parsed = new URL(url);
  const hostname = parsed.hostname.toLowerCase();
  
  // Block localhost
  if (hostname === 'localhost' || hostname === '127.0.0.1') {
    throw new Error('Localhost not allowed');
  }
  
  // Block loopback range
  if (hostname.startsWith('127.')) {
    throw new Error('Loopback addresses not allowed');
  }
  
  // Block private IP ranges
  const privateRanges = [
    /^10\./,
    /^172\.(1[6-9]|2[0-9]|3[0-1])\./,
    /^192\.168\./,
    /^169\.254\./ // Link-local
  ];
  
  for (const range of privateRanges) {
    if (range.test(hostname)) {
      throw new Error('Private IP addresses not allowed');
    }
  }
  
  // Block IPv6 localhost
  if (hostname === '::1' || hostname === '[::1]') {
    throw new Error('IPv6 localhost not allowed');
  }
  
  // Block metadata endpoints (cloud providers)
  const metadataHosts = [
    '169.254.169.254', // AWS, Azure, GCP
    'metadata.google.internal'
  ];
  
  if (metadataHosts.includes(hostname)) {
    throw new Error('Metadata endpoints not allowed');
  }
  
  return url;
}
```

**Important:** [Inference] Client-side SSRF prevention provides minimal security. Server-side validation is essential as attackers can bypass client-side checks.

#### CRLF Injection Prevention

Prevent header injection attacks:

```javascript
function preventCRLFInjection(value) {
  const str = String(value);
  
  // Check for CRLF sequences
  if (/\r|\n/.test(str)) {
    throw new Error('CRLF injection attempt detected');
  }
  
  // Check for encoded CRLF
  const decoded = decodeURIComponent(str);
  if (/\r|\n|%0d|%0a/i.test(decoded)) {
    throw new Error('Encoded CRLF injection attempt detected');
  }
  
  return str;
}

// Usage in headers
const safeValue = preventCRLFInjection(userInput);
await fetch(url, {
  headers: { 'X-Custom-Header': safeValue }
});
```

### Type-Safe Validation

#### TypeScript Integration

```typescript
interface ValidationSchema {
  type: 'string' | 'number' | 'boolean' | 'array' | 'object';
  required?: boolean;
  minLength?: number;
  maxLength?: number;
  minimum?: number;
  maximum?: number;
  pattern?: string;
  properties?: Record<string, ValidationSchema>;
  items?: ValidationSchema;
}

interface ValidatedRequest {
  url: string;
  method: string;
  headers: Record<string, string>;
  body?: any;
}

class TypedRequestValidator {
  validate<T>(data: unknown, schema: ValidationSchema): T {
    this.validateValue(data, schema, 'root');
    return data as T;
  }
  
  private validateValue(value: unknown, schema: ValidationSchema, path: string): void {
    // Null/undefined check
    if (value === null || value === undefined) {
      if (schema.required) {
        throw new Error(`${path} is required`);
      }
      return;
    }
    
    // Type check
    const actualType = Array.isArray(value) ? 'array' : typeof value;
    if (actualType !== schema.type) {
      throw new Error(`${path} must be ${schema.type}, got ${actualType}`);
    }
    
    // Type-specific validation
    switch (schema.type) {
      case 'string':
        this.validateString(value as string, schema, path);
        break;
      case 'number':
        this.validateNumber(value as number, schema, path);
        break;
      case 'array':
        this.validateArray(value as unknown[], schema, path);
        break;
      case 'object':
        this.validateObject(value as Record<string, unknown>, schema, path);
        break;
    }
  }
  
  private validateString(value: string, schema: ValidationSchema, path: string): void {
    if (schema.minLength && value.length < schema.minLength) {
      throw new Error(`${path} must be at least ${schema.minLength} characters`);
    }
    if (schema.maxLength && value.length > schema.maxLength) {
      throw new Error(`${path} must be at most ${schema.maxLength} characters`);
    }
    if (schema.pattern && !new RegExp(schema.pattern).test(value)) {
      throw new Error(`${path} does not match required pattern`);
    }
  }
  
  private validateNumber(value: number, schema: ValidationSchema, path: string): void {
    if (schema.minimum !== undefined && value < schema.minimum) {
      throw new Error(`${path} must be at least ${schema.minimum}`);
    }
    if (schema.maximum !== undefined && value > schema.maximum) {
      throw new Error(`${path} must be at most ${schema.maximum}`);
    }
  }
  
  private validateArray(value: unknown[], schema: ValidationSchema, path: string): void {
    if (schema.items) {
      value.forEach((item, index) => {
        this.validateValue(item, schema.items!, `${path}[${index}]`);
      });
    }
  }
  
  private validateObject(
    value: Record<string, unknown>,
    schema: ValidationSchema,
    path: string
  ): void {
    if (schema.properties) {
      for (const [key, propSchema] of Object.entries(schema.properties)) {
        this.validateValue(value[key], propSchema, `${path}.${key}`);
      }
    }
  }
}

// Usage
interface User {
  username: string;
  email: string;
  age?: number;
}

const userSchema: ValidationSchema = {
  type: 'object',
  properties: {
    username: {
      type: 'string',
      required: true,
      minLength: 3,
      maxLength: 20,
      pattern: '^[a-zA-Z0-9_]+
    },
    email: {
      type: 'string',
      required: true,
      pattern: '^[\\w.-]+@[\\w.-]+\\.\\w+
    },
    age: {
      type: 'number',
      minimum: 13,
      maximum: 120
    }
  }
};

const validator = new TypedRequestValidator();
const user = validator.validate<User>(userData, userSchema);

await fetch('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify(user)
});
```

### Testing Validation

#### Unit Tests for Validators

```javascript
// Example test suite
describe('URL Validation', () => {
  const validator = new RequestValidator();
  
  test('accepts valid HTTPS URLs', () => {
    expect(() => {
      validator.validateURL('https://api.example.com/data');
    }).not.toThrow();
  });
  
  test('rejects javascript: protocol', () => {
    expect(() => {
      validator.validateURL('javascript:alert(1)');
    }).toThrow('Only HTTP/HTTPS protocols allowed');
  });
  
  test('rejects URLs exceeding length limit', () => {
    const longURL = 'https://example.com/' + 'a'.repeat(3000);
    expect(() => {
      validator.validateURL(longURL);
    }).toThrow('URL too long');
  });
  
  test('enforces domain whitelist', () => {
    const restrictedValidator = new RequestValidator({
      allowedDomains: ['example.com']
    });
    
    expect(() => {
      restrictedValidator.validateURL('https://evil.com');
    }).toThrow('Domain not allowed');
  });
});

describe('Header Validation', () => {
  const validator = new RequestValidator();
  
  test('accepts valid headers', () => {
    const headers = { 'Content-Type': 'application/json' };
    expect(() => {
      validator.validateHeaders(headers);
    }).not.toThrow();
  });
  
  test('rejects headers with CRLF', () => {
    const headers = { 'X-Custom': 'value\r\nX-Injected: evil' };
    expect(() => {
      validator.validateHeaders(headers);
    }).toThrow('Header value contains CRLF');
  });
  
  test('enforces header size limit', () => {
    const largeValue = 'x'.repeat(10000);
    const headers = { 'X-Large': largeValue };
    expect(() => {
      validator.validateHeaders(headers);
    }).toThrow('Headers too large');
  });
});
```

### Error Handling

#### Validation Error Class

```javascript
class ValidationError extends Error {
  constructor(message, field, value) {
    super(message);
    this.name = 'ValidationError';
    this.field = field;
    this.value = value;
    this.timestamp = new Date();
  }
  
  toJSON() {
    return {
      error: this.name,
      message: this.message,
      field: this.field,
      timestamp: this.timestamp.toISOString()
    };
  }
}

// Usage
function validateEmail(email) {
  const pattern = /^[\w.-]+@[\w.-]+\.\w+$/;
  if (!pattern.test(email)) {
    throw new ValidationError(
      'Invalid email format',
      'email',
      email
    );
  }
  return email;
}

try {
  const email = validateEmail(userInput);
  await fetch('/api/users', {
    method: 'POST',
    body: JSON.stringify({ email })
  });
} catch (error) {
  if (error instanceof ValidationError) {
    console.error('Validation failed:', error.toJSON());
    // Show user-friendly error message
  } else {
    throw error;
  }
}
```

#### Graceful Degradation

```javascript
async function safeFetch(url, options = {}) {
  const validator = new RequestValidator();
  
  try {
    // Attempt validation
    return await validator.fetch(url, options);
  } catch (error) {
    if (error instanceof ValidationError) {
      // Log validation error
      console.error('Validation failed:', error.message);
      
      // Optionally: attempt request anyway with logging
      console.warn('Attempting request despite validation failure');
      return fetch(url, options);
    }
    throw error;
  }
}
```

### Best Practices

1. **Validate early** - Check inputs before constructing requests
2. **Use whitelists over blacklists** - Explicitly allow known-good values
3. **Layer validation** - Client-side validation improves UX, but server-side is essential for security
4. **Provide clear error messages** - Help developers identify validation failures quickly
5. **Log validation failures** - Track attempted invalid requests for security monitoring
6. **Test edge cases** - Include boundary values, empty strings, null, undefined, special characters
7. **Consider performance** - Complex validation on every request can impact performance
8. **Keep validators reusable** - Design validation functions for multiple contexts
9. **Document validation rules** - Make requirements clear to API consumers
10. **Version validation schemas** - Allow evolution without breaking existing clients

[Inference] These client-side validation patterns improve user experience and catch errors early, but should never be the sole security mechanism. Server-side validation remains essential for security.

---

## Output Encoding

### Response Body Types

The fetch API provides multiple methods to decode response bodies, each handling encoding differently. The `Response` object exposes methods that interpret the raw byte stream according to specific encoding rules.

**Available decoding methods:**

- `response.text()` - Decodes as text using charset
- `response.json()` - Parses as JSON after text decoding
- `response.arrayBuffer()` - Returns raw bytes
- `response.blob()` - Returns binary data with MIME type
- `response.formData()` - Parses as form data
- `response.bytes()` - Returns Uint8Array (newer API)

Each method consumes the response body stream, making it unavailable for subsequent reads.

### Text Encoding Detection

The `text()` method determines character encoding through a priority hierarchy:

**Encoding detection order:**

1. BOM (Byte Order Mark) in response body
2. `charset` parameter in `Content-Type` header
3. [Inference] Default fallback (UTF-8)

```javascript
const response = await fetch('https://api.example.com/data');
const text = await response.text();
// Decoding uses Content-Type charset or UTF-8
```

**Content-Type header example:**

```
Content-Type: text/html; charset=ISO-8859-1
```

The `text()` method uses ISO-8859-1 to decode the byte stream in this case.

### UTF-8 Handling

UTF-8 is the dominant encoding on the web and the de facto default for fetch API responses without explicit charset declarations.

**UTF-8 characteristics:**

- Variable-length encoding (1-4 bytes per character)
- ASCII-compatible (first 128 characters)
- Self-synchronizing (error recovery possible)

```javascript
const response = await fetch('https://api.example.com/utf8-data');
const text = await response.text();
// Handles multi-byte UTF-8 sequences correctly
console.log(text);  // "Hello 世界 🌍"
```

Invalid UTF-8 sequences typically decode to the replacement character (U+FFFD �).

### JSON Encoding Requirements

The `json()` method first decodes the response as text, then parses it as JSON. JSON specification (RFC 8259) mandates UTF-8 encoding:

```javascript
const response = await fetch('https://api.example.com/data.json');
const data = await response.json();
```

**Process:**

1. Decode bytes to string using charset detection
2. Parse string as JSON
3. Return JavaScript object

[Inference] If the response claims a non-UTF-8 charset in `Content-Type`, the `text()` decoding step uses that charset, potentially causing JSON parsing errors if the actual encoding differs.

### Binary Data Preservation

The `arrayBuffer()` and `blob()` methods preserve raw bytes without text interpretation:

```javascript
const response = await fetch('https://cdn.example.com/image.png');
const buffer = await response.arrayBuffer();
// buffer contains exact bytes from response, no encoding applied
```

**Use cases for binary methods:**

- Images, audio, video
- Binary file formats (PDF, ZIP, etc.)
- Custom binary protocols
- Cryptographic operations requiring exact byte sequences

### Blob Encoding Metadata

Blobs carry MIME type metadata from the response's `Content-Type` header:

```javascript
const response = await fetch('https://api.example.com/document.pdf');
const blob = await response.blob();
console.log(blob.type);  // "application/pdf"
```

This metadata doesn't affect encoding but provides type information for subsequent processing:

```javascript
const url = URL.createObjectURL(blob);
// Browser uses blob.type to render correctly
```

### Form Data Encoding

The `formData()` method decodes `multipart/form-data` or `application/x-www-form-urlencoded` responses:

```javascript
const response = await fetch('https://api.example.com/form');
const form = await response.formData();

for (const [key, value] of form.entries()) {
  console.log(`${key}: ${value}`);
}
```

**Encoding handling:**

- Text fields decode using charset from Content-Type
- File fields preserve binary data as Blob objects
- URL-encoded forms decode percent-encoded sequences

### Manual Encoding Control

For precise encoding control, use `arrayBuffer()` with `TextDecoder`:

```javascript
const response = await fetch('https://api.example.com/legacy-data');
const buffer = await response.arrayBuffer();

const decoder = new TextDecoder('windows-1252');
const text = decoder.decode(buffer);
```

**TextDecoder options:**

- Supports numerous legacy encodings
- `fatal` option throws on invalid sequences instead of replacing
- `ignoreBOM` option controls BOM handling

```javascript
const decoder = new TextDecoder('utf-8', {
  fatal: true,      // Throw on invalid UTF-8
  ignoreBOM: false  // Respect BOM if present
});
```

### Encoding Mismatch Scenarios

When declared encoding doesn't match actual encoding, corruption occurs:

```javascript
// Server sends UTF-8 but declares ISO-8859-1
const response = await fetch('https://api.example.com/wrong-charset');
// Content-Type: text/plain; charset=ISO-8859-1
// Actual data: UTF-8 encoded "Café"

const text = await response.text();
console.log(text);  // "CafÃ©" (mojibake - double-encoded)
```

**Recovery strategy:**

```javascript
const buffer = await response.arrayBuffer();
const utf8Decoder = new TextDecoder('utf-8');
const corrected = utf8Decoder.decode(buffer);
console.log(corrected);  // "Café"
```

### Base64 Encoding

Binary data embedded in JSON typically uses Base64 encoding:

```javascript
const response = await fetch('https://api.example.com/data');
const data = await response.json();
// data.imageData = "iVBORw0KGgoAAAANSUhEUgA..." (Base64 string)

// Decode Base64 to binary
const binaryString = atob(data.imageData);
const bytes = Uint8Array.from(binaryString, c => c.charCodeAt(0));
```

**Modern alternative using Uint8Array:**

```javascript
const bytes = Uint8Array.from(atob(data.imageData), c => c.charCodeAt(0));
const blob = new Blob([bytes], { type: 'image/png' });
```

### Streaming Text Decoding

The Response body is a ReadableStream. Text can be decoded incrementally:

```javascript
const response = await fetch('https://api.example.com/large-text');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, { stream: true });
  console.log(chunk);  // Process text incrementally
}

// Final chunk without stream flag
const final = decoder.decode();
```

The `stream: true` option handles multi-byte characters split across chunks correctly.

### Content-Encoding vs Character Encoding

`Content-Encoding` (compression) is distinct from character encoding:

```
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
```

The fetch API automatically decompresses `gzip`, `deflate`, and `br` (Brotli) content:

```javascript
const response = await fetch('https://api.example.com/compressed');
// Response body already decompressed by browser
const text = await response.text();  // Then character-decoded
```

This decompression happens transparently before any decoding method executes.

### Headers and Encoding

Response headers themselves use ISO-8859-1 (Latin-1) encoding per HTTP specification:

```javascript
const response = await fetch('https://api.example.com/data');
const header = response.headers.get('X-Custom-Header');
// Header values limited to ISO-8859-1 characters
```

Non-ASCII data in headers requires encoding schemes:

- RFC 2047 for older headers: `=?UTF-8?B?...?=`
- RFC 8187 for newer headers: `filename*=UTF-8''%E4%B8%AD%E6%96%87.txt`

### JSON Text Sequences

JSON Text Sequences (RFC 7464) use record separator characters:

```javascript
const response = await fetch('https://api.example.com/json-seq');
const text = await response.text();

const records = text.split('\x1E')  // ASCII RS (Record Separator)
  .filter(Boolean)
  .map(record => JSON.parse(record.replace(/^\x1E/, '')));
```

This format allows streaming JSON objects with clear delimiters.

### Character Reference Decoding

HTML/XML character references require explicit decoding:

```javascript
const response = await fetch('https://api.example.com/html-encoded');
const text = await response.text();
// text = "Hello &amp; goodbye &#x1F600;"

const parser = new DOMParser();
const doc = parser.parseFromString(text, 'text/html');
const decoded = doc.documentElement.textContent;
// decoded = "Hello & goodbye 😀"
```

The `text()` method doesn't decode HTML entities—they remain as literal strings.

### Encoding Detection Failures

[Inference] When encoding detection fails or produces incorrect results:

**Symptoms:**

- Replacement characters (�) appear in text
- Mojibake (garbled characters)
- Truncated text at invalid byte sequences

**Diagnostic approach:**

```javascript
const response = await fetch('https://api.example.com/data');

// Check declared encoding
const contentType = response.headers.get('Content-Type');
console.log('Declared:', contentType);

// Inspect raw bytes
const buffer = await response.arrayBuffer();
const bytes = new Uint8Array(buffer);
console.log('First bytes:', bytes.slice(0, 20));

// Try different decoders
const encodings = ['utf-8', 'iso-8859-1', 'windows-1252'];
encodings.forEach(encoding => {
  const decoder = new TextDecoder(encoding, { fatal: false });
  console.log(`${encoding}:`, decoder.decode(buffer).substring(0, 100));
});
```

### Unicode Normalization

Unicode characters can have multiple representations. Normalization ensures consistency:

```javascript
const response = await fetch('https://api.example.com/unicode');
const text = await response.text();

// Normalize to canonical composition (NFC)
const normalized = text.normalize('NFC');
```

**Normalization forms:**

- `NFC` - Canonical composition (most compact)
- `NFD` - Canonical decomposition
- `NFKC` - Compatibility composition
- `NFKD` - Compatibility decomposition

This is particularly important for comparing strings or using them as object keys.

### Response Cloning and Encoding

Cloning responses allows multiple decoding attempts:

```javascript
const response = await fetch('https://api.example.com/data');
const clone = response.clone();

// Try JSON first
try {
  const data = await response.json();
  return data;
} catch {
  // Fall back to text
  const text = await clone.text();
  return text;
}
```

Each clone maintains an independent stream, allowing different encoding strategies.

### Error Handling in Decoding

Decoding methods can fail for various reasons:

```javascript
const response = await fetch('https://api.example.com/data');

try {
  const data = await response.json();
} catch (error) {
  if (error instanceof SyntaxError) {
    console.error('Invalid JSON:', error.message);
    // Attempt text decode for diagnostic
    const text = await response.clone().text();
    console.log('Raw text:', text.substring(0, 100));
  }
}
```

**Common failures:**

- Invalid JSON syntax in `json()`
- Invalid UTF-8 sequences with fatal TextDecoder
- Malformed multipart data in `formData()`

### Encoding in Request Bodies

When sending data, explicit encoding may be necessary:

```javascript
const text = "Hello 世界";
const encoder = new TextEncoder();  // Always produces UTF-8
const bytes = encoder.encode(text);

await fetch('https://api.example.com/data', {
  method: 'POST',
  body: bytes,
  headers: {
    'Content-Type': 'text/plain; charset=utf-8'
  }
});
```

The `TextEncoder` API only supports UTF-8 output.

### Data URLs and Encoding

Data URLs embed encoded content directly:

```javascript
const text = "Hello 世界";
const encoded = encodeURIComponent(text);
const dataUrl = `data:text/plain;charset=utf-8,${encoded}`;

const response = await fetch(dataUrl);
const decoded = await response.text();
console.log(decoded);  // "Hello 世界"
```

**Base64 data URLs:**

```javascript
const bytes = new TextEncoder().encode(text);
const base64 = btoa(String.fromCharCode(...bytes));
const dataUrl = `data:text/plain;charset=utf-8;base64,${base64}`;
```

### CSV Encoding Considerations

CSV files often use various encodings:

```javascript
const response = await fetch('https://api.example.com/data.csv');

// Check for BOM
const buffer = await response.arrayBuffer();
const view = new Uint8Array(buffer);

let encoding = 'utf-8';
if (view[0] === 0xEF && view[1] === 0xBB && view[2] === 0xBF) {
  encoding = 'utf-8';  // UTF-8 BOM
} else if (view[0] === 0xFF && view[1] === 0xFE) {
  encoding = 'utf-16le';  // UTF-16 LE BOM
}

const decoder = new TextDecoder(encoding);
const text = decoder.decode(buffer);
```

### Encoding Performance Implications

Different decoding methods have varying performance characteristics:

[Inference] **Performance hierarchy (fastest to slowest):**

1. `arrayBuffer()` - No decoding overhead
2. `text()` - Single-pass UTF-8 decoding
3. `json()` - Text decoding + parsing
4. `formData()` - Complex multipart parsing

For large responses, streaming with manual decoding allows progressive processing:

```javascript
const response = await fetch('https://api.example.com/huge-file');
const reader = response.body.getReader();
const decoder = new TextDecoder();

let processedSize = 0;
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  processedSize += value.length;
  const chunk = decoder.decode(value, { stream: true });
  // Process chunk immediately, reducing memory footprint
}
```

### Charset in Requests vs Responses

The charset parameter behaves differently for requests and responses:

**Responses (covered above):**

- Server declares charset in Content-Type
- Client decodes accordingly

**Requests:**

```javascript
await fetch('https://api.example.com/data', {
  method: 'POST',
  headers: {
    'Content-Type': 'text/plain; charset=utf-8'
  },
  body: 'Hello 世界'
});
```

When sending a string body, the fetch API encodes it as UTF-8 regardless of declared charset. [Unverified] The charset declaration in request headers may not affect actual encoding—it primarily informs the server about the encoding used.

---



---


# Testing

## Mocking Fetch Requests

### Manual Mock Implementation

Replace global fetch with a custom function:

```javascript
// Store original fetch
const originalFetch = window.fetch;

// Create mock
window.fetch = function(url, options) {
  if (url === '/api/users') {
    return Promise.resolve({
      ok: true,
      status: 200,
      json: async () => ({ users: ['Alice', 'Bob'] }),
      text: async () => JSON.stringify({ users: ['Alice', 'Bob'] }),
      headers: new Headers({
        'content-type': 'application/json'
      })
    });
  }
  
  // Fall back to original for unmocked URLs
  return originalFetch(url, options);
};

// Restore after tests
window.fetch = originalFetch;
```

**Complete Response object mock:**

```javascript
function createMockResponse(body, init = {}) {
  const {
    status = 200,
    statusText = 'OK',
    headers = {},
    url = ''
  } = init;
  
  return {
    ok: status >= 200 && status < 300,
    status,
    statusText,
    url,
    headers: new Headers(headers),
    redirected: false,
    type: 'basic',
    
    // Body methods
    json: async () => JSON.parse(body),
    text: async () => body,
    blob: async () => new Blob([body]),
    arrayBuffer: async () => new TextEncoder().encode(body).buffer,
    formData: async () => {
      const fd = new FormData();
      // Parse body as needed
      return fd;
    },
    
    // Body can only be read once
    bodyUsed: false,
    
    // Clone method
    clone: function() {
      return createMockResponse(body, init);
    }
  };
}

// Usage
window.fetch = async function(url) {
  if (url === '/api/data') {
    return createMockResponse(
      JSON.stringify({ data: 'test' }),
      { status: 200, headers: { 'content-type': 'application/json' } }
    );
  }
};
```

### Spy Pattern

Track fetch calls while optionally passing through:

```javascript
class FetchSpy {
  constructor() {
    this.calls = [];
    this.originalFetch = window.fetch;
    this.mockResponses = new Map();
  }
  
  install() {
    window.fetch = async (url, options) => {
      this.calls.push({ url, options, timestamp: Date.now() });
      
      // Check for mock response
      const mockKey = this.getMockKey(url, options);
      if (this.mockResponses.has(mockKey)) {
        return this.mockResponses.get(mockKey);
      }
      
      // Pass through to real fetch
      return this.originalFetch(url, options);
    };
  }
  
  uninstall() {
    window.fetch = this.originalFetch;
  }
  
  reset() {
    this.calls = [];
    this.mockResponses.clear();
  }
  
  getMockKey(url, options = {}) {
    return `${options.method || 'GET'}:${url}`;
  }
  
  mockResponse(url, response, options = {}) {
    const key = this.getMockKey(url, options);
    this.mockResponses.set(key, response);
  }
  
  getCalls(url) {
    if (!url) return this.calls;
    return this.calls.filter(call => call.url === url);
  }
  
  wasCalledWith(url, options = {}) {
    return this.calls.some(call => {
      if (call.url !== url) return false;
      if (options.method && call.options?.method !== options.method) return false;
      return true;
    });
  }
}

// Usage
const spy = new FetchSpy();
spy.install();

spy.mockResponse('/api/users', createMockResponse(
  JSON.stringify({ users: [] })
));

await fetch('/api/users'); // Uses mock
await fetch('/api/other'); // Passes through

console.log(spy.getCalls()); // All calls
console.log(spy.wasCalledWith('/api/users')); // true

spy.uninstall();
```

### Conditional Mocking

Mock based on request properties:

```javascript
function createConditionalMock() {
  const originalFetch = window.fetch;
  const matchers = [];
  
  window.fetch = async function(url, options = {}) {
    for (const matcher of matchers) {
      if (matcher.condition(url, options)) {
        return matcher.response(url, options);
      }
    }
    return originalFetch(url, options);
  };
  
  return {
    when: (condition) => ({
      thenReturn: (response) => {
        matchers.push({ condition, response });
      }
    }),
    reset: () => {
      window.fetch = originalFetch;
      matchers.length = 0;
    }
  };
}

// Usage
const mock = createConditionalMock();

// Mock all POST requests
mock.when((url, options) => options.method === 'POST')
  .thenReturn(async () => createMockResponse(JSON.stringify({ success: true })));

// Mock specific URL pattern
mock.when((url) => url.includes('/api/users/'))
  .thenReturn(async (url) => {
    const id = url.split('/').pop();
    return createMockResponse(JSON.stringify({ id, name: 'User ' + id }));
  });

// Mock with delay
mock.when((url) => url === '/api/slow')
  .thenReturn(async () => {
    await new Promise(resolve => setTimeout(resolve, 2000));
    return createMockResponse(JSON.stringify({ data: 'delayed' }));
  });
```

### Request Matching

Match requests by various criteria:

```javascript
class RequestMatcher {
  constructor() {
    this.expectations = [];
  }
  
  expect(pattern) {
    const expectation = {
      pattern,
      responses: [],
      calls: [],
      times: null
    };
    this.expectations.push(expectation);
    
    return {
      times: (n) => {
        expectation.times = n;
        return this;
      },
      toReturn: (...responses) => {
        expectation.responses = responses;
        return this;
      },
      toReturnOnce: (response) => {
        expectation.responses = [response];
        expectation.times = 1;
        return this;
      }
    };
  }
  
  match(url, options) {
    for (const exp of this.expectations) {
      if (this.isMatch(url, options, exp.pattern)) {
        exp.calls.push({ url, options, timestamp: Date.now() });
        
        if (exp.times !== null && exp.calls.length > exp.times) {
          throw new Error(`Expected ${exp.times} calls but got ${exp.calls.length}`);
        }
        
        const responseIndex = Math.min(
          exp.calls.length - 1,
          exp.responses.length - 1
        );
        return exp.responses[responseIndex];
      }
    }
    return null;
  }
  
  isMatch(url, options, pattern) {
    if (typeof pattern === 'string') {
      return url === pattern;
    }
    if (pattern instanceof RegExp) {
      return pattern.test(url);
    }
    if (typeof pattern === 'function') {
      return pattern(url, options);
    }
    if (typeof pattern === 'object') {
      return this.matchObject(url, options, pattern);
    }
    return false;
  }
  
  matchObject(url, options, pattern) {
    if (pattern.url) {
      if (typeof pattern.url === 'string' && url !== pattern.url) return false;
      if (pattern.url instanceof RegExp && !pattern.url.test(url)) return false;
    }
    if (pattern.method && options?.method !== pattern.method) return false;
    if (pattern.headers) {
      for (const [key, value] of Object.entries(pattern.headers)) {
        if (options?.headers?.[key] !== value) return false;
      }
    }
    return true;
  }
  
  verify() {
    const failures = [];
    for (const exp of this.expectations) {
      if (exp.times !== null && exp.calls.length !== exp.times) {
        failures.push(
          `Expected ${exp.times} calls to ${JSON.stringify(exp.pattern)} ` +
          `but got ${exp.calls.length}`
        );
      }
    }
    if (failures.length > 0) {
      throw new Error('Mock verification failed:\n' + failures.join('\n'));
    }
  }
}

// Usage
const matcher = new RequestMatcher();

matcher.expect('/api/users')
  .times(2)
  .toReturn(
    createMockResponse(JSON.stringify({ users: ['Alice'] })),
    createMockResponse(JSON.stringify({ users: ['Alice', 'Bob'] }))
  );

matcher.expect({ url: /\/api\/posts\/\d+/, method: 'GET' })
  .toReturn(createMockResponse(JSON.stringify({ post: 'content' })));

// Install mock
const originalFetch = window.fetch;
window.fetch = async (url, options) => {
  const response = matcher.match(url, options);
  if (response) return response;
  return originalFetch(url, options);
};

// After tests
matcher.verify(); // Throws if expectations not met
```

### Network Error Simulation

Mock network failures and errors:

```javascript
function createErrorMock() {
  const mocks = new Map();
  
  const errorTypes = {
    network: () => Promise.reject(new TypeError('Failed to fetch')),
    timeout: () => new Promise((_, reject) => 
      setTimeout(() => reject(new TypeError('Network timeout')), 100)
    ),
    abort: () => Promise.reject(new DOMException('Aborted', 'AbortError')),
    serverError: (status = 500) => Promise.resolve(
      createMockResponse('Internal Server Error', { 
        status, 
        statusText: 'Internal Server Error' 
      })
    ),
    clientError: (status = 400) => Promise.resolve(
      createMockResponse('Bad Request', { 
        status, 
        statusText: 'Bad Request' 
      })
    ),
    malformedJSON: () => Promise.resolve({
      ok: true,
      status: 200,
      json: async () => { throw new SyntaxError('Unexpected token'); },
      text: async () => 'not valid json {',
      headers: new Headers({ 'content-type': 'application/json' })
    })
  };
  
  return {
    mockNetworkError: (url) => {
      mocks.set(url, errorTypes.network);
    },
    mockTimeout: (url) => {
      mocks.set(url, errorTypes.timeout);
    },
    mockAbort: (url) => {
      mocks.set(url, errorTypes.abort);
    },
    mockServerError: (url, status) => {
      mocks.set(url, () => errorTypes.serverError(status));
    },
    mockClientError: (url, status) => {
      mocks.set(url, () => errorTypes.clientError(status));
    },
    mockMalformedJSON: (url) => {
      mocks.set(url, errorTypes.malformedJSON);
    },
    install: () => {
      const original = window.fetch;
      window.fetch = async (url, options) => {
        if (mocks.has(url)) {
          return mocks.get(url)();
        }
        return original(url, options);
      };
      return () => { window.fetch = original; };
    }
  };
}

// Usage
const errorMock = createErrorMock();

errorMock.mockNetworkError('/api/unreachable');
errorMock.mockTimeout('/api/slow');
errorMock.mockServerError('/api/broken', 503);
errorMock.mockMalformedJSON('/api/bad-json');

const restore = errorMock.install();

// Test error handling
try {
  await fetch('/api/unreachable');
} catch (error) {
  console.log(error.message); // 'Failed to fetch'
}

restore();
```

### Streaming Response Mocking

Mock streamed responses:

```javascript
function createStreamMock(chunks, delay = 100) {
  const stream = new ReadableStream({
    async start(controller) {
      for (const chunk of chunks) {
        await new Promise(resolve => setTimeout(resolve, delay));
        controller.enqueue(new TextEncoder().encode(chunk));
      }
      controller.close();
    }
  });
  
  return {
    ok: true,
    status: 200,
    headers: new Headers({ 'content-type': 'text/plain' }),
    body: stream,
    bodyUsed: false
  };
}

// Usage
window.fetch = async function(url) {
  if (url === '/api/stream') {
    return createStreamMock([
      'chunk 1\n',
      'chunk 2\n',
      'chunk 3\n'
    ], 500);
  }
};

// Consume stream
const response = await fetch('/api/stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  console.log(decoder.decode(value));
}
```

**Server-Sent Events (SSE) mock:**

```javascript
function createSSEMock(events, delay = 1000) {
  const chunks = events.map(event => 
    `data: ${JSON.stringify(event)}\n\n`
  );
  
  return createStreamMock(chunks, delay);
}

// Usage
window.fetch = async function(url) {
  if (url === '/api/events') {
    return createSSEMock([
      { type: 'message', data: 'Hello' },
      { type: 'message', data: 'World' },
      { type: 'close', data: null }
    ]);
  }
};
```

### Testing Framework Integration

#### Jest

```javascript
// Using jest.fn()
global.fetch = jest.fn();

// Mock single response
fetch.mockResolvedValueOnce({
  ok: true,
  json: async () => ({ data: 'test' })
});

// Mock multiple responses
fetch
  .mockResolvedValueOnce({ ok: true, json: async () => ({ page: 1 }) })
  .mockResolvedValueOnce({ ok: true, json: async () => ({ page: 2 }) })
  .mockRejectedValueOnce(new Error('Network error'));

// Verify calls
expect(fetch).toHaveBeenCalledTimes(1);
expect(fetch).toHaveBeenCalledWith('/api/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'Alice' })
});

// Mock implementation
fetch.mockImplementation(async (url) => {
  if (url.includes('/users/')) {
    const id = url.split('/').pop();
    return {
      ok: true,
      json: async () => ({ id, name: `User ${id}` })
    };
  }
  throw new Error('Not found');
});
```

**Custom matcher:**

```javascript
expect.extend({
  toHaveBeenFetchedWith(received, url, options) {
    const calls = received.mock.calls;
    const match = calls.find(call => {
      const [callUrl, callOptions] = call;
      return callUrl === url && 
        (!options || JSON.stringify(callOptions) === JSON.stringify(options));
    });
    
    return {
      pass: !!match,
      message: () => 
        match
          ? `Expected fetch not to be called with ${url}`
          : `Expected fetch to be called with ${url}, but it wasn't`
    };
  }
});

// Usage
expect(fetch).toHaveBeenFetchedWith('/api/users', { method: 'GET' });
```

#### Vitest

```javascript
import { vi } from 'vitest';

// Mock fetch
global.fetch = vi.fn();

// Mock resolved value
fetch.mockResolvedValue({
  ok: true,
  json: async () => ({ data: 'test' })
});

// Spy on fetch
const fetchSpy = vi.spyOn(global, 'fetch');
fetchSpy.mockResolvedValue({
  ok: true,
  json: async () => ({ data: 'test' })
});

// Restore
fetchSpy.mockRestore();
```

#### Mocha/Chai with Sinon

```javascript
import sinon from 'sinon';

// Stub fetch
const fetchStub = sinon.stub(global, 'fetch');

// Configure stub
fetchStub.withArgs('/api/users').resolves({
  ok: true,
  json: async () => ({ users: [] })
});

fetchStub.withArgs('/api/posts').rejects(new Error('Not found'));

// Verify
sinon.assert.calledOnce(fetchStub);
sinon.assert.calledWith(fetchStub, '/api/users');

// Restore
fetchStub.restore();
```

### Mock Service Worker (MSW)

Setup request handlers:

```javascript
import { setupWorker, rest } from 'msw';

const worker = setupWorker(
  // GET request
  rest.get('/api/users', (req, res, ctx) => {
    return res(
      ctx.status(200),
      ctx.json({ users: ['Alice', 'Bob'] })
    );
  }),
  
  // POST request with body access
  rest.post('/api/users', async (req, res, ctx) => {
    const body = await req.json();
    return res(
      ctx.status(201),
      ctx.json({ id: '123', ...body })
    );
  }),
  
  // Query parameters
  rest.get('/api/search', (req, res, ctx) => {
    const query = req.url.searchParams.get('q');
    return res(
      ctx.json({ results: [`Result for ${query}`] })
    );
  }),
  
  // Headers
  rest.get('/api/protected', (req, res, ctx) => {
    const auth = req.headers.get('Authorization');
    if (!auth) {
      return res(ctx.status(401));
    }
    return res(ctx.json({ data: 'protected' }));
  }),
  
  // Delay response
  rest.get('/api/slow', (req, res, ctx) => {
    return res(
      ctx.delay(2000),
      ctx.json({ data: 'delayed' })
    );
  }),
  
  // Network error
  rest.get('/api/error', (req, res) => {
    return res.networkError('Failed to connect');
  })
);

// Start worker
worker.start();

// Stop worker
worker.stop();
```

**Request matching patterns:**

```javascript
// Exact path
rest.get('/api/users', handler);

// Path parameters
rest.get('/api/users/:id', (req, res, ctx) => {
  const { id } = req.params;
  return res(ctx.json({ id, name: 'User' }));
});

// Wildcard
rest.get('/api/*', handler);

// RegExp
rest.get(/\/api\/posts\/\d+/, handler);

// Multiple methods
rest.all('/api/resource', handler);
```

**Context utilities:**

```javascript
rest.get('/api/data', (req, res, ctx) => {
  return res(
    ctx.status(200),
    ctx.set('X-Custom-Header', 'value'),
    ctx.cookie('session', 'abc123'),
    ctx.delay(100),
    ctx.json({ data: 'test' })
  );
});
```

**One-time override:**

```javascript
// Temporary handler for single request
worker.use(
  rest.get('/api/users', (req, res, ctx) => {
    return res.once(
      ctx.json({ users: ['Override'] })
    );
  })
);
```

**Runtime handlers:**

```javascript
// Add handler at runtime
worker.use(
  rest.post('/api/dynamic', (req, res, ctx) => {
    return res(ctx.json({ dynamic: true }));
  })
);

// Reset to original handlers
worker.resetHandlers();

// Replace all handlers
worker.resetHandlers(
  rest.get('/api/new', (req, res, ctx) => {
    return res(ctx.json({ replaced: true }));
  })
);
```

### Node.js Environment Mocking

Mock in Node.js tests where global fetch may not exist:

```javascript
// Using node-fetch or undici
import fetch from 'node-fetch';

// Mock with jest
jest.mock('node-fetch');
const { Response } = jest.requireActual('node-fetch');

fetch.mockResolvedValue(
  new Response(JSON.stringify({ data: 'test' }), {
    status: 200,
    headers: { 'Content-Type': 'application/json' }
  })
);
```

**Polyfill for testing:**

```javascript
// Make fetch available globally in Node
import fetch from 'node-fetch';
global.fetch = fetch;

// Now your code can use fetch
const response = await fetch('/api/data');
```

**Using MSW in Node:**

```javascript
import { setupServer } from 'msw/node';
import { rest } from 'msw';

const server = setupServer(
  rest.get('/api/users', (req, res, ctx) => {
    return res(ctx.json({ users: [] }));
  })
);

// Enable before tests
beforeAll(() => server.listen());

// Reset handlers after each test
afterEach(() => server.resetHandlers());

// Cleanup after tests
afterAll(() => server.close());
```

### Interceptor Libraries

#### fetch-mock

```javascript
import fetchMock from 'fetch-mock';

// Mock specific URL
fetchMock.get('/api/users', { users: ['Alice'] });

// Mock with matcher function
fetchMock.get((url) => url.includes('/api/'), { data: 'matched' });

// Mock with delay
fetchMock.get('/api/slow', { data: 'test' }, { delay: 1000 });

// Mock POST with body matching
fetchMock.post('/api/users', 
  { success: true },
  { body: { name: 'Alice' } }
);

// Spy mode (pass through + log)
fetchMock.spy();

// Restore
fetchMock.restore();

// Get call history
console.log(fetchMock.calls('/api/users'));
console.log(fetchMock.lastCall('/api/users'));
```

**Advanced matching:**

```javascript
// Match by headers
fetchMock.get('/api/data', { data: 'test' }, {
  headers: { 'Authorization': 'Bearer token' }
});

// Match by query string
fetchMock.get('express:/api/search?query=:term', 
  (url, opts) => ({ results: [url.query.term] })
);

// Conditional response
fetchMock.get('/api/data', (url, opts) => {
  if (opts.headers.Auth) {
    return { status: 200, body: { data: 'authorized' } };
  }
  return { status: 401 };
});

// Multiple responses
fetchMock
  .getOnce('/api/data', { page: 1 })
  .getOnce('/api/data', { page: 2 })
  .get('/api/data', { page: 3 }); // All subsequent calls
```

#### nock (for Node.js)

```javascript
import nock from 'nock';

// Intercept HTTP requests
const scope = nock('https://api.example.com')
  .get('/users')
  .reply(200, { users: ['Alice'] });

// Multiple requests
nock('https://api.example.com')
  .get('/users/1')
  .reply(200, { id: 1, name: 'Alice' })
  .get('/users/2')
  .reply(200, { id: 2, name: 'Bob' });

// Request body matching
nock('https://api.example.com')
  .post('/users', { name: 'Charlie' })
  .reply(201, { id: 3, name: 'Charlie' });

// Delay
nock('https://api.example.com')
  .get('/slow')
  .delay(2000)
  .reply(200, { data: 'slow' });

// Network error
nock('https://api.example.com')
  .get('/error')
  .replyWithError('Network failure');

// Clean up
nock.cleanAll();
```

### Isolating Fetch in Code

Dependency injection pattern:

```javascript
// Instead of direct fetch usage
async function getUsers() {
  const response = await fetch('/api/users');
  return response.json();
}

// Inject fetch dependency
async function getUsers(fetcher = fetch) {
  const response = await fetcher('/api/users');
  return response.json();
}

// Test with mock
const mockFetch = async () => ({
  ok: true,
  json: async () => ({ users: ['Alice'] })
});

const users = await getUsers(mockFetch);
```

**Factory pattern:**

```javascript
function createAPIClient(fetcher = fetch) {
  return {
    async getUsers() {
      const response = await fetcher('/api/users');
      return response.json();
    },
    async createUser(data) {
      const response = await fetcher('/api/users', {
        method: 'POST',
        body: JSON.stringify(data)
      });
      return response.json();
    }
  };
}

// Production
const api = createAPIClient();

// Testing
const mockFetcher = jest.fn().mockResolvedValue({
  ok: true,
  json: async () => ({ success: true })
});
const testAPI = createAPIClient(mockFetcher);
```

### Assertion Helpers

Create reusable assertions:

```javascript
function assertFetchCall(fetchMock, index, expected) {
  const call = fetchMock.mock.calls[index];
  if (!call) {
    throw new Error(`No fetch call at index ${index}`);
  }
  
  const [url, options] = call;
  
  if (expected.url && url !== expected.url) {
    throw new Error(`Expected URL ${expected.url} but got ${url}`);
  }
  
  if (expected.method) {
    const method = options?.method || 'GET';
    if (method !== expected.method) {
      throw new Error(`Expected method ${expected.method} but got ${method}`);
    }
  }
  
  if (expected.body) {
    const body = options?.body;
    const expectedBody = JSON.stringify(expected.body);
    if (body !== expectedBody) {
      throw new Error(`Expected body ${expectedBody} but got ${body}`);
    }
  }
  
  if (expected.headers) {
    for (const [key, value] of Object.entries(expected.headers)) {
      const actualValue = options?.headers?.[key];
      if (actualValue !== value) {
        throw new Error(
          `Expected header ${key}: ${value} but got ${actualValue}`
        );
      }
    }
  }
}

// Usage
assertFetchCall(fetch, 0, {
  url: '/api/users',
  method: 'POST',
  body: { name: 'Alice' },
  headers: { 'Content-Type': 'application/json' }
});
```

**Async assertion helper:**

```javascript
async function waitForFetch(fetchMock, url, timeout = 5000) {
  const start = Date.now();
  
  while (Date.now() - start < timeout) {
    const calls = fetchMock.mock.calls;
    if (calls.some(call => call[0] === url)) {
      return true;
    }
    await new Promise(resolve => setTimeout(resolve, 50));
  }
  
  throw new Error(`Fetch to ${url} was not called within ${timeout}ms`);
}

// Usage in tests
await waitForFetch(fetch, '/api/users');
expect(fetch).toHaveBeenCalledWith('/api/users');
```

### Best Practices

**Reset between tests:**

```javascript
beforeEach(() => {
  // Clear mock calls and responses
  jest.clearAllMocks();
  
  // Or reset completely
  jest.resetAllMocks();
  
  // Restore original implementation
  jest.restoreAllMocks();
});
```

**Avoid over-mocking:**

```javascript
// Bad: Mock too granularly
fetch.mockImplementation((url) => {
  if (url === '/api/users/1') return { json: () => ({ id: 1 }) };
  if (url === '/api/users/2') return { json: () => ({ id: 2 }) };
  // ... dozens more
});

// Better: Use patterns or real API in integration tests
fetch.mockImplementation((url) => {
  const match = url.match(/\/api\/users\/(\d+)/);
  if (match) {
    return { 
      ok: true,
      json: async () => ({ id: match[1] }) 
    };
  }
});
```

**Mock at the right level:**

```javascript
// Unit test: Mock fetch
test('getUsers calls fetch', async () => {
  fetch.mockResolvedValue({ json: async () => ({ users: [] }) });
  await getUsers();
  expect(fetch).toHaveBeenCalledWith('/api/users');
});

// Integration test: Use MSW or real backend
test('user flow', async () => {
  // MSW intercepts at network level
  // Tests entire request/response cycle
});
```

**Type safety with TypeScript:**

```typescript
import { rest } from 'msw';

interface User {
  id: string;
  name: string;
}

rest.get<never, never, User[]>('/api/users', (req, res, ctx) => {
  return res(
    ctx.json([
      { id: '1', name: 'Alice' },
      { id: '2', name: 'Bob' }
    ])
  );
});
```

---

## Jest and Testing Libraries

### Mocking fetch API

#### Basic Mock Setup

Jest doesn't include a native fetch implementation, requiring manual mocking:

```javascript
// setupTests.js
global.fetch = jest.fn();

beforeEach(() => {
  fetch.mockClear();
});
```

For more robust testing, use dedicated mocking libraries:

```javascript
// Using jest-fetch-mock
import fetchMock from 'jest-fetch-mock';

fetchMock.enableMocks();

beforeEach(() => {
  fetchMock.resetMocks();
});
```

#### Response Mocking Patterns

Mock successful responses:

```javascript
test('fetches user data', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    status: 200,
    json: async () => ({ id: 1, name: 'John' })
  });

  const data = await fetchUser(1);
  
  expect(fetch).toHaveBeenCalledWith('/api/users/1');
  expect(data).toEqual({ id: 1, name: 'John' });
});
```

Mock error responses:

```javascript
test('handles fetch errors', async () => {
  fetch.mockResolvedValueOnce({
    ok: false,
    status: 404,
    statusText: 'Not Found',
    json: async () => ({ error: 'User not found' })
  });

  await expect(fetchUser(999)).rejects.toThrow('User not found');
});
```

Mock network failures:

```javascript
test('handles network errors', async () => {
  fetch.mockRejectedValueOnce(new Error('Network error'));

  await expect(fetchUser(1)).rejects.toThrow('Network error');
  expect(fetch).toHaveBeenCalledTimes(1);
});
```

#### Sequential Mock Responses

Test multiple fetch calls with different responses:

```javascript
test('handles pagination', async () => {
  fetch
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ items: [1, 2, 3], hasMore: true })
    })
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ items: [4, 5, 6], hasMore: false })
    });

  const page1 = await fetchPage(1);
  const page2 = await fetchPage(2);

  expect(page1.items).toHaveLength(3);
  expect(page2.items).toHaveLength(3);
  expect(fetch).toHaveBeenCalledTimes(2);
});
```

### Testing React Components

#### React Testing Library Integration

Test components that fetch data on mount:

```javascript
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';

test('displays user profile after loading', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({ name: 'Alice', email: 'alice@example.com' })
  });

  render(<UserProfile userId={1} />);

  // Check loading state
  expect(screen.getByText(/loading/i)).toBeInTheDocument();

  // Wait for data to load
  await waitFor(() => {
    expect(screen.getByText('Alice')).toBeInTheDocument();
  });

  expect(screen.getByText('alice@example.com')).toBeInTheDocument();
  expect(screen.queryByText(/loading/i)).not.toBeInTheDocument();
});
```

Test user-triggered fetches:

```javascript
test('loads data on button click', async () => {
  const user = userEvent.setup();
  
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({ results: ['Item 1', 'Item 2'] })
  });

  render(<SearchComponent />);

  const button = screen.getByRole('button', { name: /search/i });
  await user.click(button);

  await waitFor(() => {
    expect(screen.getByText('Item 1')).toBeInTheDocument();
  });

  expect(fetch).toHaveBeenCalledWith('/api/search', expect.any(Object));
});
```

#### Testing Error States

Verify error handling in components:

```javascript
test('displays error message on fetch failure', async () => {
  fetch.mockRejectedValueOnce(new Error('API Error'));

  render(<DataComponent />);

  await waitFor(() => {
    expect(screen.getByText(/error/i)).toBeInTheDocument();
  });

  expect(screen.getByText(/api error/i)).toBeInTheDocument();
});

test('allows retry after error', async () => {
  const user = userEvent.setup();
  
  fetch
    .mockRejectedValueOnce(new Error('Failed'))
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ data: 'Success' })
    });

  render(<DataComponent />);

  await waitFor(() => {
    expect(screen.getByText(/error/i)).toBeInTheDocument();
  });

  const retryButton = screen.getByRole('button', { name: /retry/i });
  await user.click(retryButton);

  await waitFor(() => {
    expect(screen.getByText('Success')).toBeInTheDocument();
  });

  expect(fetch).toHaveBeenCalledTimes(2);
});
```

#### Testing Loading States

Verify loading indicators appear correctly:

```javascript
test('shows loading spinner during fetch', async () => {
  let resolvePromise;
  const promise = new Promise(resolve => {
    resolvePromise = resolve;
  });

  fetch.mockReturnValueOnce(promise);

  render(<AsyncComponent />);

  // Loading state should be visible
  expect(screen.getByTestId('loading-spinner')).toBeInTheDocument();

  // Resolve the fetch
  resolvePromise({
    ok: true,
    json: async () => ({ data: 'Loaded' })
  });

  await waitFor(() => {
    expect(screen.queryByTestId('loading-spinner')).not.toBeInTheDocument();
  });

  expect(screen.getByText('Loaded')).toBeInTheDocument();
});
```

### Advanced Mock Strategies

#### Request Interception

Inspect request details:

```javascript
test('sends correct headers and body', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({ success: true })
  });

  await createUser({ name: 'Bob', role: 'admin' });

  expect(fetch).toHaveBeenCalledWith(
    '/api/users',
    expect.objectContaining({
      method: 'POST',
      headers: expect.objectContaining({
        'Content-Type': 'application/json',
        'Authorization': expect.stringMatching(/^Bearer /)
      }),
      body: JSON.stringify({ name: 'Bob', role: 'admin' })
    })
  );
});
```

Validate request URLs with query parameters:

```javascript
test('includes query parameters', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({ items: [] })
  });

  await searchItems({ query: 'test', page: 2, limit: 20 });

  const [url] = fetch.mock.calls[0];
  const urlObj = new URL(url, 'http://localhost');

  expect(urlObj.pathname).toBe('/api/search');
  expect(urlObj.searchParams.get('query')).toBe('test');
  expect(urlObj.searchParams.get('page')).toBe('2');
  expect(urlObj.searchParams.get('limit')).toBe('20');
});
```

#### Conditional Mocking

Create dynamic mock responses based on request:

```javascript
test('returns user-specific data', async () => {
  fetch.mockImplementation((url) => {
    const userId = url.split('/').pop();
    
    const users = {
      '1': { id: 1, name: 'Alice' },
      '2': { id: 2, name: 'Bob' }
    };

    return Promise.resolve({
      ok: true,
      json: async () => users[userId] || { error: 'Not found' }
    });
  });

  const alice = await fetchUser(1);
  const bob = await fetchUser(2);

  expect(alice.name).toBe('Alice');
  expect(bob.name).toBe('Bob');
});
```

Mock based on request method:

```javascript
test('handles different HTTP methods', async () => {
  fetch.mockImplementation((url, options) => {
    const method = options?.method || 'GET';

    if (method === 'GET') {
      return Promise.resolve({
        ok: true,
        json: async () => ({ items: [1, 2, 3] })
      });
    }

    if (method === 'POST') {
      return Promise.resolve({
        ok: true,
        status: 201,
        json: async () => ({ id: 4, created: true })
      });
    }

    return Promise.resolve({ ok: false, status: 405 });
  });

  const getResult = await getData();
  const postResult = await createData({ value: 'new' });

  expect(getResult.items).toHaveLength(3);
  expect(postResult.created).toBe(true);
});
```

#### Mock Response Builders

Create reusable mock response factories:

```javascript
const mockResponse = (data, options = {}) => ({
  ok: options.ok ?? true,
  status: options.status ?? 200,
  statusText: options.statusText ?? 'OK',
  headers: new Headers(options.headers || {}),
  json: async () => data,
  text: async () => JSON.stringify(data),
  blob: async () => new Blob([JSON.stringify(data)]),
  arrayBuffer: async () => new ArrayBuffer(8),
  ...options
});

test('uses response builder', async () => {
  fetch.mockResolvedValueOnce(
    mockResponse({ id: 1, name: 'Test' })
  );

  const data = await fetchData();
  expect(data.id).toBe(1);
});

test('mocks error response', async () => {
  fetch.mockResolvedValueOnce(
    mockResponse(
      { error: 'Unauthorized' },
      { ok: false, status: 401 }
    )
  );

  await expect(fetchData()).rejects.toThrow();
});
```

### MSW (Mock Service Worker)

#### Setup and Configuration

Install and configure MSW for browser-like mocking:

```javascript
// src/mocks/handlers.js
import { http, HttpResponse } from 'msw';

export const handlers = [
  http.get('/api/users/:id', ({ params }) => {
    const { id } = params;
    return HttpResponse.json({
      id: Number(id),
      name: `User ${id}`
    });
  }),

  http.post('/api/users', async ({ request }) => {
    const body = await request.json();
    return HttpResponse.json(
      { id: 123, ...body },
      { status: 201 }
    );
  }),

  http.delete('/api/users/:id', () => {
    return new HttpResponse(null, { status: 204 });
  })
];
```

Setup for Jest tests:

```javascript
// src/mocks/server.js
import { setupServer } from 'msw/node';
import { handlers } from './handlers';

export const server = setupServer(...handlers);

// setupTests.js
import { server } from './mocks/server';

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());
```

#### Dynamic Response Handling

Override handlers per test:

```javascript
import { http, HttpResponse } from 'msw';
import { server } from './mocks/server';

test('handles server error', async () => {
  server.use(
    http.get('/api/users/:id', () => {
      return new HttpResponse(null, { status: 500 });
    })
  );

  await expect(fetchUser(1)).rejects.toThrow();
});

test('handles network error', async () => {
  server.use(
    http.get('/api/users/:id', () => {
      return HttpResponse.error();
    })
  );

  await expect(fetchUser(1)).rejects.toThrow('Network error');
});
```

Delay responses to simulate latency:

```javascript
import { delay, http, HttpResponse } from 'msw';

test('shows loading state during slow request', async () => {
  server.use(
    http.get('/api/data', async () => {
      await delay(100);
      return HttpResponse.json({ data: 'slow' });
    })
  );

  render(<AsyncComponent />);

  expect(screen.getByText(/loading/i)).toBeInTheDocument();

  await waitFor(() => {
    expect(screen.getByText('slow')).toBeInTheDocument();
  }, { timeout: 200 });
});
```

#### Request Validation

Verify request details with MSW:

```javascript
test('sends authentication token', async () => {
  let capturedHeaders;

  server.use(
    http.get('/api/protected', ({ request }) => {
      capturedHeaders = Object.fromEntries(request.headers.entries());
      return HttpResponse.json({ data: 'protected' });
    })
  );

  await fetchProtectedData('token123');

  expect(capturedHeaders.authorization).toBe('Bearer token123');
});

test('validates request body', async () => {
  let capturedBody;

  server.use(
    http.post('/api/items', async ({ request }) => {
      capturedBody = await request.json();
      return HttpResponse.json({ success: true });
    })
  );

  await createItem({ name: 'New Item', quantity: 5 });

  expect(capturedBody).toEqual({
    name: 'New Item',
    quantity: 5
  });
});
```

#### GraphQL Support

Mock GraphQL endpoints:

```javascript
import { graphql, HttpResponse } from 'msw';

const handlers = [
  graphql.query('GetUser', ({ variables }) => {
    return HttpResponse.json({
      data: {
        user: {
          id: variables.id,
          name: 'GraphQL User'
        }
      }
    });
  }),

  graphql.mutation('CreateUser', ({ variables }) => {
    return HttpResponse.json({
      data: {
        createUser: {
          id: '123',
          name: variables.name
        }
      }
    });
  })
];

test('fetches user via GraphQL', async () => {
  const user = await fetchUserGraphQL('1');
  expect(user.name).toBe('GraphQL User');
});
```

### Testing Async Patterns

#### Polling and Intervals

Test functions that poll repeatedly:

```javascript
jest.useFakeTimers();

test('polls until condition met', async () => {
  let callCount = 0;

  fetch.mockImplementation(() => {
    callCount++;
    return Promise.resolve({
      ok: true,
      json: async () => ({
        status: callCount >= 3 ? 'complete' : 'pending'
      })
    });
  });

  const promise = pollUntilComplete('/api/job/123');

  // Fast-forward through polling intervals
  await jest.advanceTimersByTimeAsync(5000);

  const result = await promise;

  expect(result.status).toBe('complete');
  expect(fetch).toHaveBeenCalledTimes(3);
});

jest.useRealTimers();
```

Test timeout handling:

```javascript
jest.useFakeTimers();

test('times out after max attempts', async () => {
  fetch.mockResolvedValue({
    ok: true,
    json: async () => ({ status: 'pending' })
  });

  const promise = pollUntilComplete('/api/job/123', {
    timeout: 3000,
    interval: 1000
  });

  await jest.advanceTimersByTimeAsync(3000);

  await expect(promise).rejects.toThrow('Timeout');
});

jest.useRealTimers();
```

#### Race Conditions

Test concurrent fetch handling:

```javascript
test('handles concurrent requests', async () => {
  fetch
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ id: 1, data: 'first' })
    })
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ id: 2, data: 'second' })
    });

  const [first, second] = await Promise.all([
    fetchData(1),
    fetchData(2)
  ]);

  expect(first.data).toBe('first');
  expect(second.data).toBe('second');
  expect(fetch).toHaveBeenCalledTimes(2);
});
```

Test request deduplication:

```javascript
test('deduplicates simultaneous requests', async () => {
  let resolvePromise;
  const mockPromise = new Promise(resolve => {
    resolvePromise = resolve;
  });

  fetch.mockReturnValueOnce(mockPromise);

  // Start multiple requests simultaneously
  const promise1 = fetchWithCache('/api/data');
  const promise2 = fetchWithCache('/api/data');
  const promise3 = fetchWithCache('/api/data');

  // Resolve after all requests started
  resolvePromise({
    ok: true,
    json: async () => ({ value: 42 })
  });

  const [result1, result2, result3] = await Promise.all([
    promise1,
    promise2,
    promise3
  ]);

  expect(result1).toEqual({ value: 42 });
  expect(result1).toBe(result2); // Same reference
  expect(result2).toBe(result3);
  expect(fetch).toHaveBeenCalledTimes(1); // Only one actual fetch
});
```

#### Retry Logic

Test exponential backoff:

```javascript
jest.useFakeTimers();

test('retries with exponential backoff', async () => {
  fetch
    .mockRejectedValueOnce(new Error('Fail 1'))
    .mockRejectedValueOnce(new Error('Fail 2'))
    .mockResolvedValueOnce({
      ok: true,
      json: async () => ({ success: true })
    });

  const promise = fetchWithRetry('/api/data', { maxRetries: 3 });

  // First retry after 1s
  await jest.advanceTimersByTimeAsync(1000);

  // Second retry after 2s
  await jest.advanceTimersByTimeAsync(2000);

  const result = await promise;

  expect(result.success).toBe(true);
  expect(fetch).toHaveBeenCalledTimes(3);
});

jest.useRealTimers();
```

Test max retry limit:

```javascript
test('stops after max retries', async () => {
  fetch.mockRejectedValue(new Error('Persistent error'));

  await expect(
    fetchWithRetry('/api/data', { maxRetries: 3 })
  ).rejects.toThrow('Persistent error');

  expect(fetch).toHaveBeenCalledTimes(3);
});
```

### Integration Testing

#### End-to-End Flows

Test complete user workflows:

```javascript
test('complete checkout flow', async () => {
  const user = userEvent.setup();

  // Mock cart fetch
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({
      items: [
        { id: 1, name: 'Product A', price: 10 }
      ]
    })
  });

  render(<CheckoutPage />);

  await waitFor(() => {
    expect(screen.getByText('Product A')).toBeInTheDocument();
  });

  // Fill shipping info
  const nameInput = screen.getByLabelText(/name/i);
  await user.type(nameInput, 'John Doe');

  // Mock checkout submission
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({
      orderId: 'ORD-123',
      status: 'confirmed'
    })
  });

  const submitButton = screen.getByRole('button', { name: /submit/i });
  await user.click(submitButton);

  await waitFor(() => {
    expect(screen.getByText(/order confirmed/i)).toBeInTheDocument();
    expect(screen.getByText('ORD-123')).toBeInTheDocument();
  });

  // Verify checkout request
  expect(fetch).toHaveBeenLastCalledWith(
    '/api/checkout',
    expect.objectContaining({
      method: 'POST',
      body: expect.stringContaining('John Doe')
    })
  );
});
```

#### API Contract Testing

Verify request/response structure:

```javascript
const userSchema = {
  id: expect.any(Number),
  name: expect.any(String),
  email: expect.stringMatching(/^[\w-\.]+@([\w-]+\.)+[\w-]{2,4}$/),
  createdAt: expect.any(String)
};

test('API returns valid user structure', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({
      id: 1,
      name: 'Alice',
      email: 'alice@example.com',
      createdAt: '2024-01-01T00:00:00Z'
    })
  });

  const user = await fetchUser(1);

  expect(user).toMatchObject(userSchema);
});

test('validates error response structure', async () => {
  fetch.mockResolvedValueOnce({
    ok: false,
    status: 400,
    json: async () => ({
      error: 'Validation failed',
      details: [
        { field: 'email', message: 'Invalid format' }
      ]
    })
  });

  try {
    await createUser({ email: 'invalid' });
  } catch (err) {
    expect(err.details).toEqual([
      expect.objectContaining({
        field: expect.any(String),
        message: expect.any(String)
      })
    ]);
  }
});
```

### Snapshot Testing

#### Response Snapshots

Capture and verify API response structures:

```javascript
test('matches user response snapshot', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({
      id: 1,
      name: 'Test User',
      profile: {
        avatar: 'https://example.com/avatar.jpg',
        bio: 'Test bio'
      },
      settings: {
        notifications: true,
        theme: 'dark'
      }
    })
  });

  const user = await fetchUser(1);

  expect(user).toMatchSnapshot();
});
```

#### Component Snapshots

Test rendered output with fetched data:

```javascript
test('renders user profile correctly', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({
      name: 'Alice',
      email: 'alice@example.com',
      role: 'admin'
    })
  });

  const { container } = render(<UserProfile userId={1} />);

  await waitFor(() => {
    expect(screen.getByText('Alice')).toBeInTheDocument();
  });

  expect(container).toMatchSnapshot();
});
```

### Performance Testing

#### Request Timing

Measure fetch performance:

```javascript
test('completes within performance budget', async () => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => ({ data: 'test' })
  });

  const start = performance.now();
  await fetchData();
  const duration = performance.now() - start;

  expect(duration).toBeLessThan(100);
});
```

#### Memory Leak Detection

Test for proper cleanup:

```javascript
test('cleans up pending requests on unmount', async () => {
  let rejectRequest;
  const promise = new Promise((_, reject) => {
    rejectRequest = reject;
  });

  fetch.mockReturnValueOnce(promise);

  const { unmount } = render(<DataComponent />);

  // Unmount before request completes
  unmount();

  // Reject the pending request
  rejectRequest(new Error('Cancelled'));

  // Should not cause warnings or errors
  await new Promise(resolve => setTimeout(resolve, 0));
});
```

### Custom Test Utilities

#### Fetch Mock Helpers

Create reusable testing utilities:

```javascript
// test-utils.js
export const mockFetchSuccess = (data) => {
  fetch.mockResolvedValueOnce({
    ok: true,
    status: 200,
    json: async () => data
  });
};

export const mockFetchError = (status, message) => {
  fetch.mockResolvedValueOnce({
    ok: false,
    status,
    json: async () => ({ error: message })
  });
};

export const mockFetchSequence = (...responses) => {
  responses.forEach(response => {
    if (response.error) {
      fetch.mockRejectedValueOnce(new Error(response.error));
    } else {
      fetch.mockResolvedValueOnce({
        ok: true,
        json: async () => response.data
      });
    }
  });
};

// Usage
test('uses mock helpers', async () => {
  mockFetchSuccess({ id: 1, name: 'Test' });

  const data = await fetchData();
  expect(data.id).toBe(1);
});

test('tests error sequence', async () => {
  mockFetchSequence(
    { error: 'First attempt failed' },
    { error: 'Second attempt failed' },
    { data: { success: true } }
  );

  const result = await fetchWithRetry();
  expect(result.success).toBe(true);
});
```

#### Component Test Wrappers

Create wrapper functions for common test scenarios:

```javascript
// test-utils.js
export const renderWithFetch = (
  Component,
  mockData,
  renderOptions = {}
) => {
  fetch.mockResolvedValueOnce({
    ok: true,
    json: async () => mockData
  });

  return render(Component, renderOptions);
};

export const waitForFetchComplete = async () => {
  await waitFor(() => {
    expect(fetch).toHaveBeenCalled();
  });
  
  // Wait for state updates
  await screen.findByTestId('loaded-content', {}, { timeout: 2000 });
};

// Usage
test('renders with fetched data', async () => {
  renderWithFetch(
    <UserList />,
    { users: [{ id: 1, name: 'Alice' }] }
  );

  await waitForFetchComplete();

  expect(screen.getByText('Alice')).toBeInTheDocument();
});
```

---

## Mock Service Worker (MSW)

### Architecture

MSW intercepts network requests at the network level using Service Workers in browsers and native Node.js modules in Node environments. This approach allows mocking without modifying application code or HTTP clients.

**Browser**: Requests are intercepted by a Service Worker registered by MSW, which matches them against defined handlers and returns mock responses.

**Node.js**: MSW patches native HTTP/HTTPS modules to intercept requests before they reach the network layer.

### Installation and Setup

#### Installation

```bash
npm install msw --save-dev
# or
yarn add msw --dev
# or
pnpm add -D msw
```

#### Browser Setup

```bash
# Generate service worker file in public directory
npx msw init public/ --save
```

This creates `mockServiceWorker.js` in your public directory and adds it to `.gitignore`.

#### Basic Configuration

```javascript
// src/mocks/handlers.js
import { http, HttpResponse } from 'msw';

export const handlers = [
  http.get('/api/user', () => {
    return HttpResponse.json({
      id: 1,
      name: 'John Doe',
      email: 'john@example.com'
    });
  }),
  
  http.post('/api/login', async ({ request }) => {
    const { username, password } = await request.json();
    
    if (username === 'admin' && password === 'password') {
      return HttpResponse.json({
        token: 'mock-jwt-token',
        user: { username: 'admin' }
      });
    }
    
    return HttpResponse.json(
      { error: 'Invalid credentials' },
      { status: 401 }
    );
  })
];
```

```javascript
// src/mocks/browser.js
import { setupWorker } from 'msw/browser';
import { handlers } from './handlers';

export const worker = setupWorker(...handlers);
```

```javascript
// src/main.jsx (or entry point)
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';

async function enableMocking() {
  if (process.env.NODE_ENV !== 'development') {
    return;
  }
  
  const { worker } = await import('./mocks/browser');
  return worker.start();
}

enableMocking().then(() => {
  ReactDOM.createRoot(document.getElementById('root')).render(
    <React.StrictMode>
      <App />
    </React.StrictMode>
  );
});
```

#### Node.js Setup

```javascript
// src/mocks/node.js
import { setupServer } from 'msw/node';
import { handlers } from './handlers';

export const server = setupServer(...handlers);
```

```javascript
// tests/setup.js
import { beforeAll, afterEach, afterAll } from 'vitest';
import { server } from '../src/mocks/node';

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());
```

### Request Handlers

#### HTTP Methods

```javascript
import { http, HttpResponse } from 'msw';

export const handlers = [
  // GET request
  http.get('/api/products', () => {
    return HttpResponse.json([
      { id: 1, name: 'Product 1' },
      { id: 2, name: 'Product 2' }
    ]);
  }),
  
  // POST request
  http.post('/api/products', async ({ request }) => {
    const product = await request.json();
    return HttpResponse.json(
      { ...product, id: Date.now() },
      { status: 201 }
    );
  }),
  
  // PUT request
  http.put('/api/products/:id', async ({ params, request }) => {
    const { id } = params;
    const updates = await request.json();
    return HttpResponse.json({ id, ...updates });
  }),
  
  // PATCH request
  http.patch('/api/products/:id', async ({ params, request }) => {
    const { id } = params;
    const updates = await request.json();
    return HttpResponse.json({ id, ...updates });
  }),
  
  // DELETE request
  http.delete('/api/products/:id', ({ params }) => {
    return new HttpResponse(null, { status: 204 });
  }),
  
  // HEAD request
  http.head('/api/health', () => {
    return new HttpResponse(null, {
      status: 200,
      headers: {
        'X-Service-Status': 'healthy'
      }
    });
  }),
  
  // OPTIONS request
  http.options('/api/*', () => {
    return new HttpResponse(null, {
      status: 200,
      headers: {
        'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE',
        'Access-Control-Allow-Headers': 'Content-Type, Authorization'
      }
    });
  })
];
```

#### Path Parameters

```javascript
http.get('/api/users/:userId', ({ params }) => {
  const { userId } = params;
  
  return HttpResponse.json({
    id: userId,
    name: `User ${userId}`
  });
}),

http.get('/api/users/:userId/posts/:postId', ({ params }) => {
  const { userId, postId } = params;
  
  return HttpResponse.json({
    id: postId,
    userId: userId,
    title: 'Post title'
  });
}),

// Wildcard matching
http.get('/api/files/*', ({ params }) => {
  const filepath = params[0]; // captures everything after /files/
  
  return HttpResponse.json({
    path: filepath
  });
})
```

#### Query Parameters

```javascript
http.get('/api/search', ({ request }) => {
  const url = new URL(request.url);
  const query = url.searchParams.get('q');
  const page = url.searchParams.get('page') || '1';
  const limit = url.searchParams.get('limit') || '10';
  
  return HttpResponse.json({
    query,
    page: parseInt(page),
    limit: parseInt(limit),
    results: []
  });
}),

// Multiple values for same parameter
http.get('/api/products', ({ request }) => {
  const url = new URL(request.url);
  const categories = url.searchParams.getAll('category');
  
  return HttpResponse.json({
    categories,
    products: []
  });
})
```

#### Request Headers

```javascript
http.get('/api/protected', ({ request }) => {
  const authHeader = request.headers.get('Authorization');
  
  if (!authHeader || !authHeader.startsWith('Bearer ')) {
    return HttpResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    );
  }
  
  const token = authHeader.substring(7);
  
  // Validate token logic here
  
  return HttpResponse.json({ data: 'protected content' });
}),

http.post('/api/data', ({ request }) => {
  const contentType = request.headers.get('Content-Type');
  
  if (contentType !== 'application/json') {
    return HttpResponse.json(
      { error: 'Content-Type must be application/json' },
      { status: 415 }
    );
  }
  
  return HttpResponse.json({ success: true });
})
```

#### Request Body

```javascript
// JSON body
http.post('/api/users', async ({ request }) => {
  const user = await request.json();
  
  return HttpResponse.json({
    id: Date.now(),
    ...user,
    createdAt: new Date().toISOString()
  });
}),

// Text body
http.post('/api/logs', async ({ request }) => {
  const logMessage = await request.text();
  
  console.log('Log received:', logMessage);
  
  return new HttpResponse(null, { status: 204 });
}),

// FormData
http.post('/api/upload', async ({ request }) => {
  const formData = await request.formData();
  const file = formData.get('file');
  const description = formData.get('description');
  
  return HttpResponse.json({
    filename: file.name,
    size: file.size,
    description
  });
}),

// ArrayBuffer
http.post('/api/binary', async ({ request }) => {
  const buffer = await request.arrayBuffer();
  
  return HttpResponse.json({
    byteLength: buffer.byteLength
  });
})
```

#### Request Cookies

```javascript
http.get('/api/profile', ({ cookies }) => {
  const sessionId = cookies.sessionId;
  
  if (!sessionId) {
    return HttpResponse.json(
      { error: 'No session' },
      { status: 401 }
    );
  }
  
  return HttpResponse.json({
    user: 'John Doe',
    sessionId
  });
})
```

### Response Types

#### JSON Response

```javascript
http.get('/api/data', () => {
  return HttpResponse.json(
    { message: 'Success' },
    {
      status: 200,
      headers: {
        'X-Custom-Header': 'value'
      }
    }
  );
})
```

#### Text Response

```javascript
http.get('/api/text', () => {
  return HttpResponse.text('Plain text response');
}),

http.get('/api/html', () => {
  return HttpResponse.html('<h1>Hello World</h1>');
}),

http.get('/api/xml', () => {
  return HttpResponse.xml('<?xml version="1.0"?><root></root>');
})
```

#### Binary Response

```javascript
http.get('/api/image', () => {
  const buffer = new ArrayBuffer(8);
  
  return HttpResponse.arrayBuffer(buffer, {
    headers: {
      'Content-Type': 'image/png'
    }
  });
}),

http.get('/api/download', () => {
  const blob = new Blob(['file content'], { type: 'text/plain' });
  
  return new HttpResponse(blob, {
    headers: {
      'Content-Disposition': 'attachment; filename="file.txt"'
    }
  });
})
```

#### Streaming Response

```javascript
http.get('/api/stream', () => {
  const stream = new ReadableStream({
    start(controller) {
      controller.enqueue('chunk 1\n');
      
      setTimeout(() => {
        controller.enqueue('chunk 2\n');
      }, 1000);
      
      setTimeout(() => {
        controller.enqueue('chunk 3\n');
        controller.close();
      }, 2000);
    }
  });
  
  return new HttpResponse(stream, {
    headers: {
      'Content-Type': 'text/plain',
      'Transfer-Encoding': 'chunked'
    }
  });
})
```

#### Empty Response

```javascript
http.delete('/api/resource/:id', () => {
  return new HttpResponse(null, { status: 204 });
})
```

### Response Modifiers

#### Status Codes

```javascript
http.post('/api/create', () => {
  return HttpResponse.json(
    { id: 1, created: true },
    { status: 201 }
  );
}),

http.get('/api/not-found', () => {
  return HttpResponse.json(
    { error: 'Not found' },
    { status: 404 }
  );
}),

http.post('/api/error', () => {
  return HttpResponse.json(
    { error: 'Internal server error' },
    { status: 500 }
  );
})
```

#### Headers

```javascript
http.get('/api/data', () => {
  return HttpResponse.json(
    { data: 'value' },
    {
      headers: {
        'Cache-Control': 'no-cache',
        'X-RateLimit-Remaining': '99',
        'X-Request-ID': crypto.randomUUID()
      }
    }
  );
})
```

#### Cookies

```javascript
http.post('/api/login', () => {
  return HttpResponse.json(
    { success: true },
    {
      headers: {
        'Set-Cookie': 'sessionId=abc123; HttpOnly; Secure; SameSite=Strict'
      }
    }
  );
}),

// Multiple cookies
http.post('/api/auth', () => {
  return HttpResponse.json(
    { success: true },
    {
      headers: [
        ['Set-Cookie', 'sessionId=abc123; HttpOnly'],
        ['Set-Cookie', 'userId=user123; Path=/']
      ]
    }
  );
})
```

### Delays and Network Conditions

#### Response Delay

```javascript
import { http, HttpResponse, delay } from 'msw';

http.get('/api/slow', async () => {
  await delay(2000); // 2 second delay
  
  return HttpResponse.json({ message: 'Slow response' });
}),

// Random delay
http.get('/api/variable', async () => {
  await delay(Math.random() * 1000); // 0-1 second
  
  return HttpResponse.json({ data: 'value' });
}),

// Realistic network delay
http.get('/api/realistic', async () => {
  await delay('real'); // Simulates realistic network delay
  
  return HttpResponse.json({ data: 'value' });
})
```

#### Network Errors

```javascript
http.get('/api/network-error', () => {
  return HttpResponse.error();
}),

http.get('/api/timeout', async () => {
  await delay(30000); // Simulate timeout
  return HttpResponse.json({ data: 'too late' });
})
```

### Conditional Responses

#### Based on Request Data

```javascript
http.get('/api/users/:id', ({ params }) => {
  const { id } = params;
  
  if (id === '404') {
    return HttpResponse.json(
      { error: 'User not found' },
      { status: 404 }
    );
  }
  
  return HttpResponse.json({
    id,
    name: `User ${id}`
  });
}),

http.post('/api/validate', async ({ request }) => {
  const { email } = await request.json();
  
  const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
  
  if (!emailRegex.test(email)) {
    return HttpResponse.json(
      { error: 'Invalid email format' },
      { status: 400 }
    );
  }
  
  return HttpResponse.json({ valid: true });
})
```

#### Based on Headers

```javascript
http.get('/api/content', ({ request }) => {
  const acceptLanguage = request.headers.get('Accept-Language');
  
  if (acceptLanguage?.includes('es')) {
    return HttpResponse.json({ message: 'Hola' });
  }
  
  return HttpResponse.json({ message: 'Hello' });
}),

http.get('/api/versioned', ({ request }) => {
  const apiVersion = request.headers.get('X-API-Version');
  
  if (apiVersion === '2') {
    return HttpResponse.json({ version: 2, data: [] });
  }
  
  return HttpResponse.json({ version: 1, items: [] });
})
```

#### Based on Environment

```javascript
http.get('/api/config', () => {
  const isProduction = process.env.NODE_ENV === 'production';
  
  return HttpResponse.json({
    debug: !isProduction,
    apiUrl: isProduction ? 'https://api.prod.com' : 'http://localhost:3000'
  });
})
```

### Stateful Handlers

#### In-Memory Database

```javascript
// Mock database
const db = {
  users: [
    { id: 1, name: 'Alice', email: 'alice@example.com' },
    { id: 2, name: 'Bob', email: 'bob@example.com' }
  ],
  nextId: 3
};

export const handlers = [
  http.get('/api/users', () => {
    return HttpResponse.json(db.users);
  }),
  
  http.get('/api/users/:id', ({ params }) => {
    const user = db.users.find(u => u.id === parseInt(params.id));
    
    if (!user) {
      return HttpResponse.json(
        { error: 'User not found' },
        { status: 404 }
      );
    }
    
    return HttpResponse.json(user);
  }),
  
  http.post('/api/users', async ({ request }) => {
    const newUser = await request.json();
    const user = {
      id: db.nextId++,
      ...newUser
    };
    
    db.users.push(user);
    
    return HttpResponse.json(user, { status: 201 });
  }),
  
  http.put('/api/users/:id', async ({ params, request }) => {
    const id = parseInt(params.id);
    const updates = await request.json();
    const index = db.users.findIndex(u => u.id === id);
    
    if (index === -1) {
      return HttpResponse.json(
        { error: 'User not found' },
        { status: 404 }
      );
    }
    
    db.users[index] = { ...db.users[index], ...updates };
    
    return HttpResponse.json(db.users[index]);
  }),
  
  http.delete('/api/users/:id', ({ params }) => {
    const id = parseInt(params.id);
    const index = db.users.findIndex(u => u.id === id);
    
    if (index === -1) {
      return HttpResponse.json(
        { error: 'User not found' },
        { status: 404 }
      );
    }
    
    db.users.splice(index, 1);
    
    return new HttpResponse(null, { status: 204 });
  })
];
```

#### Session Management

```javascript
const sessions = new Map();

http.post('/api/login', async ({ request }) => {
  const { username, password } = await request.json();
  
  if (username === 'admin' && password === 'password') {
    const sessionId = crypto.randomUUID();
    
    sessions.set(sessionId, {
      username,
      createdAt: Date.now()
    });
    
    return HttpResponse.json(
      { success: true },
      {
        headers: {
          'Set-Cookie': `sessionId=${sessionId}; HttpOnly; Path=/`
        }
      }
    );
  }
  
  return HttpResponse.json(
    { error: 'Invalid credentials' },
    { status: 401 }
  );
}),

http.get('/api/profile', ({ cookies }) => {
  const sessionId = cookies.sessionId;
  const session = sessions.get(sessionId);
  
  if (!session) {
    return HttpResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    );
  }
  
  return HttpResponse.json({
    username: session.username
  });
}),

http.post('/api/logout', ({ cookies }) => {
  const sessionId = cookies.sessionId;
  sessions.delete(sessionId);
  
  return HttpResponse.json(
    { success: true },
    {
      headers: {
        'Set-Cookie': 'sessionId=; Max-Age=0; Path=/'
      }
    }
  );
})
```

### Runtime Handler Manipulation

#### Adding Handlers

```javascript
import { worker } from './mocks/browser';
import { http, HttpResponse } from 'msw';

// Add handler at runtime
worker.use(
  http.get('/api/new-endpoint', () => {
    return HttpResponse.json({ message: 'New endpoint' });
  })
);
```

#### Overriding Handlers

```javascript
// Override existing handler
worker.use(
  http.get('/api/users', () => {
    return HttpResponse.json(
      { error: 'Service unavailable' },
      { status: 503 }
    );
  })
);
```

#### Resetting Handlers

```javascript
// Reset to original handlers
worker.resetHandlers();

// Reset with new handlers
worker.resetHandlers(
  http.get('/api/users', () => {
    return HttpResponse.json([]);
  })
);
```

#### One-Time Handlers

```javascript
worker.use(
  http.get('/api/special', () => {
    return HttpResponse.json({ special: true });
  }, { once: true })
);

// After first call, this handler is removed
```

### Testing Patterns

#### Basic Test Setup

```javascript
import { describe, it, expect, beforeAll, afterEach, afterAll } from 'vitest';
import { server } from '../mocks/node';
import { http, HttpResponse } from 'msw';

describe('API Tests', () => {
  beforeAll(() => server.listen());
  afterEach(() => server.resetHandlers());
  afterAll(() => server.close());
  
  it('fetches user data', async () => {
    const response = await fetch('/api/user');
    const data = await response.json();
    
    expect(data).toEqual({
      id: 1,
      name: 'John Doe',
      email: 'john@example.com'
    });
  });
  
  it('handles authentication failure', async () => {
    server.use(
      http.post('/api/login', () => {
        return HttpResponse.json(
          { error: 'Invalid credentials' },
          { status: 401 }
        );
      })
    );
    
    const response = await fetch('/api/login', {
      method: 'POST',
      body: JSON.stringify({ username: 'wrong', password: 'wrong' })
    });
    
    expect(response.status).toBe(401);
  });
});
```

#### Testing Error States

```javascript
it('handles network errors', async () => {
  server.use(
    http.get('/api/data', () => {
      return HttpResponse.error();
    })
  );
  
  await expect(fetch('/api/data')).rejects.toThrow();
});

it('handles timeout', async () => {
  server.use(
    http.get('/api/slow', async () => {
      await delay(10000);
      return HttpResponse.json({ data: 'too slow' });
    })
  );
  
  const controller = new AbortController();
  setTimeout(() => controller.abort(), 1000);
  
  await expect(
    fetch('/api/slow', { signal: controller.signal })
  ).rejects.toThrow('aborted');
});
```

#### Testing with React Testing Library

```javascript
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import { server } from '../mocks/node';
import { http, HttpResponse } from 'msw';
import UserProfile from './UserProfile';

describe('UserProfile', () => {
  it('displays user data', async () => {
    render(<UserProfile userId={1} />);
    
    await waitFor(() => {
      expect(screen.getByText('John Doe')).toBeInTheDocument();
    });
  });
  
  it('displays error message on failure', async () => {
    server.use(
      http.get('/api/users/:id', () => {
        return HttpResponse.json(
          { error: 'User not found' },
          { status: 404 }
        );
      })
    );
    
    render(<UserProfile userId={999} />);
    
    await waitFor(() => {
      expect(screen.getByText(/not found/i)).toBeInTheDocument();
    });
  });
});
```

#### Asserting Request Details

```javascript
it('sends correct request body', async () => {
  let receivedData = null;
  
  server.use(
    http.post('/api/users', async ({ request }) => {
      receivedData = await request.json();
      return HttpResponse.json({ success: true });
    })
  );
  
  await fetch('/api/users', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ name: 'Test User' })
  });
  
  expect(receivedData).toEqual({ name: 'Test User' });
});

it('sends authorization header', async () => {
  let authHeader = null;
  
  server.use(
    http.get('/api/protected', ({ request }) => {
      authHeader = request.headers.get('Authorization');
      return HttpResponse.json({ data: 'protected' });
    })
  );
  
  await fetch('/api/protected', {
    headers: { 'Authorization': 'Bearer token123' }
  });
  
  expect(authHeader).toBe('Bearer token123');
});
```

### GraphQL Support

#### Basic GraphQL Handler

```javascript
import { graphql, HttpResponse } from 'msw';

export const handlers = [
  graphql.query('GetUser', ({ query, variables }) => {
    return HttpResponse.json({
      data: {
        user: {
          id: variables.id,
          name: 'John Doe',
          email: 'john@example.com'
        }
      }
    });
  }),
  
  graphql.mutation('CreateUser', ({ query, variables }) => {
    return HttpResponse.json({
      data: {
        createUser: {
          id: Date.now(),
          name: variables.name,
          email: variables.email
        }
      }
    });
  })
];
```

#### GraphQL with Multiple Operations

```javascript
graphql.query('GetUserAndPosts', ({ variables }) => {
  return HttpResponse.json({
    data: {
      user: {
        id: variables.userId,
        name: 'John Doe',
        posts: [
          { id: 1, title: 'First Post' },
          { id: 2, title: 'Second Post' }
        ]
      }
    }
  });
}),

graphql.mutation('UpdateUser', ({ variables }) => {
  return HttpResponse.json({
    data: {
      updateUser: {
        id: variables.id,
        ...variables.input
      }
    }
  });
})
```

#### GraphQL Error Responses

```javascript
graphql.query('GetUser', ({ variables }) => {
  if (variables.id === '404') {
    return HttpResponse.json({
      errors: [
        {
          message: 'User not found',
          extensions: {
            code: 'USER_NOT_FOUND'
          }
        }
      ]
    });
  }
  
  return HttpResponse.json({
    data: {
      user: { id: variables.id, name: 'User' }
    }
  });
})
```

### Advanced Patterns

#### Request Interception Logging

```javascript
import { http, HttpResponse, passthrough } from 'msw';

http.get('/api/*', ({ request }) => {
  console.log('Request intercepted:', {
    method: request.method,
    url: request.url,
    headers: Object.fromEntries(request.headers.entries())
  });
  
  return passthrough(); // Let request go through to real server
})
```

#### Passthrough for Specific URLs

```javascript
http.get('/api/external/*', () => {
  return passthrough();
}),

// Conditional passthrough
http.get('/api/users/:id', ({ params }) => {
  if (params.id === 'real') {
    return passthrough();
  }
  
  return HttpResponse.json({ id: params.id, mocked: true });
})
```

#### Request Timing Analysis

```javascript
http.get('/api/analytics', async ({ request }) => {
  const startTime = Date.now();
  
  // Simulate processing
  await delay(100);
  
  const duration = Date.now() - startTime;
  
  return HttpResponse.json(
    { data: 'result' },
    {
      headers: {
        'X-Response-Time': `${duration}ms`
      }
    }
  );
})
```

#### Rate Limiting Simulation

```javascript
const requestCounts = new Map();

http.get('/api/limited', ({ request }) => {
  const clientId = request.headers.get('X-Client-ID') || 'anonymous';
  const count = requestCounts.get(clientId) || 0;
  
  if (count >= 10) {
    return HttpResponse.json(
      { error: 'Rate limit exceeded' },
      {
        status: 429,
        headers: {
          'X-RateLimit-Remaining': '0',
          'Retry-After': '60'
        }
      }
    );
  }
  
  requestCounts.set(clientId, count + 1);
  
  // Reset after 60 seconds
  setTimeout(() => {
    requestCounts.delete(clientId);
  }, 60000);
  
  return HttpResponse.json(
    { data: 'success' },
    {
      headers: {
        'X-RateLimit-Remaining': String(10 - count - 1)
      }
    }
  );
})
```

#### Pagination Support

```javascript
const allItems = Array.from({ length: 100 }, (_, i) => ({
  id: i + 1,
  name: `Item ${i + 1}`
}));

http.get('/api/items', ({ request }) => {
  const url = new URL(request.url);
  const page = parseInt(url.searchParams.get('page') || '1');
  const limit = parseInt(url.searchParams.get('limit') || '10');
  
  const start = (page - 1) * limit;
  const end = start + limit;
  const items = allItems.slice(start, end);
  
  return HttpResponse.json({
    items,
    pagination: {
      page,
      limit,
      total: allItems.length,
      totalPages: Math.ceil(allItems.length / limit)
    }
  });
})
```

#### File Upload Simulation

```javascript
http.post('/api/upload', async ({ request }) => {
  const formData = await request.formData();
  const file = formData.get('file');
  
  if (!file) {
    return HttpResponse.json(
      { error: 'No file provided' },
      { status: 400 }
    );
  }
  
  // Simulate upload progress
  await delay(1000);
  
  return HttpResponse.json({
    id: crypto.randomUUID(),
    filename: file.name,
    size: file.size,
    type: file.type,
    url: `/uploads/${file.name}`
  });
})
```

### Performance Optimization

#### Handler Organization

```javascript
// handlers/users.js
export const userHandlers = [
  http.get('/api/users', () => { /* ... */ }),
  http.post('/api/users', () => { /* ... */ })
];

// handlers/products.js
export const productHandlers = [
  http.get('/api/products', () => { /* ... */ }),
  http.post('/api/products', () => { /* ... */ })
];

// handlers/index.js
import { userHandlers } from './users';
import { productHandlers } from './products';

export const handlers = [
  ...userHandlers,
  ...productHandlers
];
```

#### Lazy Loading Handlers

```javascript
// main.jsx
async function enableMocking() {
  if (process.env.NODE_ENV !== 'development') {
    return;
  }
  
  const { worker } = await import('./mocks/browser');
  
  // Only load specific handlers based on feature flags
  const { handlers } = await import('./mocks/handlers');
  
  if (import.meta.env.VITE_FEATURE_PRODUCTS) {
    const { productHandlers } = await import('./mocks/handlers/products');
    worker.use(...productHandlers);
  }
  
  return worker.start();
}
```

#### Response Caching

```javascript
const cache = new Map();

http.get('/api/expensive', async ({ request }) => {
  const url = request.url;
  
  if (cache.has(url)) {
    return HttpResponse.json(cache.get(url));
  }
  
  // Simulate expensive operation
  await delay(2000);
  
  const data = {
    timestamp: Date.now(),
    result: 'expensive computation'
  };
  
  cache.set(url, data);
  
  // Clear cache after 5 minutes
  setTimeout(() => cache.delete(url), 300000);
  
  return HttpResponse.json(data);
})
```

### Browser DevTools Integration

#### Logging Intercepted Requests

```javascript
// src/mocks/browser.js
import { setupWorker } from 'msw/browser';
import { handlers } from './handlers';

export const worker = setupWorker(...handlers);

worker.events.on('request:start', ({ request }) => {
  console.log('[MSW] Request:', request.method, request.url);
});

worker.events.on('request:match', ({ request }) => {
  console.log('[MSW] Matched:', request.method, request.url);
});

worker.events.on('request:unhandled', ({ request }) => {
  console.log('[MSW] Unhandled:', request.method, request.url);
});

worker.events.on('response:mocked', ({ request, response }) => {
  console.log('[MSW] Mocked response:', request.method, request.url, response.status);
});
```

#### Start Options

```javascript
// Quiet mode - no console warnings
worker.start({
  quiet: true
});

// Custom service worker URL
worker.start({
  serviceWorker: {
    url: '/custom-sw.js'
  }
});

// Only warn about specific unhandled requests
worker.start({
  onUnhandledRequest: 'warn' // 'warn' | 'error' | 'bypass'
});

// Custom unhandled request handler
worker.start({
  onUnhandledRequest(request, print) {
    if (request.url.includes('/analytics')) {
      return; // Ignore analytics requests
    }
    print.warning();
  }
});
```

### TypeScript Integration

#### Typed Handlers

```typescript
import { http, HttpResponse } from 'msw';

interface User {
  id: number;
  name: string;
  email: string;
}

interface CreateUserRequest {
  name: string;
  email: string;
}

export const handlers = [
  http.get<never, never, User>('/api/user', () => {
    return HttpResponse.json<User>({
      id: 1,
      name: 'John Doe',
      email: 'john@example.com'
    });
  }),
  
  http.post<never, CreateUserRequest, User>('/api/users', async ({ request }) => {
    const body = await request.json();
    
    return HttpResponse.json<User>({
      id: Date.now(),
      name: body.name,
      email: body.email
    });
  })
];
```

#### Typed Path Parameters

```typescript
interface UserParams {
  userId: string;
}

http.get<UserParams>('/api/users/:userId', ({ params }) => {
  const { userId } = params; // userId is typed as string
  
  return HttpResponse.json({
    id: parseInt(userId),
    name: 'User'
  });
})
```

#### Generic Response Helper

```typescript
function createJsonResponse<T>(data: T, status = 200) {
  return HttpResponse.json<T>(data, { status });
}

http.get('/api/users', () => {
  return createJsonResponse<User[]>([
    { id: 1, name: 'Alice', email: 'alice@example.com' }
  ]);
})
```

### Environment-Specific Configuration

#### Feature Flags

```javascript
// config/features.js
export const features = {
  enableMocking: import.meta.env.DEV,
  enableNetworkDelay: import.meta.env.VITE_SLOW_NETWORK === 'true',
  enableErrors: import.meta.env.VITE_TEST_ERRORS === 'true'
};

// handlers/index.js
import { features } from '../config/features';
import { delay } from 'msw';

http.get('/api/data', async () => {
  if (features.enableNetworkDelay) {
    await delay(2000);
  }
  
  if (features.enableErrors && Math.random() < 0.3) {
    return HttpResponse.error();
  }
  
  return HttpResponse.json({ data: 'value' });
})
```

#### Multiple Environments

```javascript
// mocks/scenarios/success.js
export const successHandlers = [
  http.get('/api/users', () => {
    return HttpResponse.json([{ id: 1, name: 'User' }]);
  })
];

// mocks/scenarios/error.js
export const errorHandlers = [
  http.get('/api/users', () => {
    return HttpResponse.json(
      { error: 'Server error' },
      { status: 500 }
    );
  })
];

// mocks/browser.js
import { successHandlers } from './scenarios/success';
import { errorHandlers } from './scenarios/error';

const scenario = new URLSearchParams(window.location.search).get('scenario');

const handlers = scenario === 'error' ? errorHandlers : successHandlers;

export const worker = setupWorker(...handlers);
```

### Common Patterns and Recipes

#### Authentication Flow

```javascript
let currentToken = null;

http.post('/api/login', async ({ request }) => {
  const { username, password } = await request.json();
  
  if (username === 'admin' && password === 'password') {
    currentToken = `token-${Date.now()}`;
    
    return HttpResponse.json({
      token: currentToken,
      user: { username }
    });
  }
  
  return HttpResponse.json(
    { error: 'Invalid credentials' },
    { status: 401 }
  );
}),

http.get('/api/profile', ({ request }) => {
  const authHeader = request.headers.get('Authorization');
  const token = authHeader?.replace('Bearer ', '');
  
  if (token !== currentToken) {
    return HttpResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    );
  }
  
  return HttpResponse.json({
    username: 'admin',
    email: 'admin@example.com'
  });
}),

http.post('/api/logout', ({ request }) => {
  const authHeader = request.headers.get('Authorization');
  const token = authHeader?.replace('Bearer ', '');
  
  if (token === currentToken) {
    currentToken = null;
  }
  
  return HttpResponse.json({ success: true });
})
```

#### Optimistic Updates

```javascript
const posts = [
  { id: 1, title: 'Post 1', likes: 0 },
  { id: 2, title: 'Post 2', likes: 0 }
];

http.post('/api/posts/:id/like', async ({ params }) => {
  const post = posts.find(p => p.id === parseInt(params.id));
  
  if (!post) {
    return HttpResponse.json(
      { error: 'Post not found' },
      { status: 404 }
    );
  }
  
  // Simulate network delay
  await delay(500);
  
  post.likes++;
  
  return HttpResponse.json(post);
})
```

#### Filtering and Sorting

```javascript
const products = [
  { id: 1, name: 'Product A', category: 'electronics', price: 100 },
  { id: 2, name: 'Product B', category: 'books', price: 20 },
  { id: 3, name: 'Product C', category: 'electronics', price: 200 }
];

http.get('/api/products', ({ request }) => {
  const url = new URL(request.url);
  const category = url.searchParams.get('category');
  const sortBy = url.searchParams.get('sort');
  const order = url.searchParams.get('order') || 'asc';
  
  let filtered = [...products];
  
  if (category) {
    filtered = filtered.filter(p => p.category === category);
  }
  
  if (sortBy) {
    filtered.sort((a, b) => {
      const aVal = a[sortBy];
      const bVal = b[sortBy];
      
      if (order === 'desc') {
        return bVal > aVal ? 1 : -1;
      }
      return aVal > bVal ? 1 : -1;
    });
  }
  
  return HttpResponse.json(filtered);
})
```

#### WebSocket Simulation

[Inference] MSW does not natively support WebSocket mocking in the same way it handles HTTP requests. For WebSocket testing, alternative approaches or libraries would typically be used.

### Debugging Tips

#### Handler Not Matching

```javascript
// Add catch-all handler to debug
http.all('*', ({ request }) => {
  console.log('Unhandled request:', request.method, request.url);
  return passthrough();
})
```

#### Request Body Not Parsing

```javascript
http.post('/api/data', async ({ request }) => {
  try {
    const body = await request.json();
    return HttpResponse.json({ received: body });
  } catch (error) {
    console.error('Failed to parse body:', error);
    return HttpResponse.json(
      { error: 'Invalid JSON' },
      { status: 400 }
    );
  }
})
```

#### Handler Execution Order

```javascript
// Specific handlers should come before generic ones
export const handlers = [
  http.get('/api/users/me', () => {
    return HttpResponse.json({ username: 'current-user' });
  }),
  
  http.get('/api/users/:id', ({ params }) => {
    return HttpResponse.json({ id: params.id });
  }),
  
  // Catch-all should be last
  http.get('/api/*', () => {
    return HttpResponse.json({ fallback: true });
  })
];
```

### Migration from Other Tools

#### From fetch-mock

```javascript
// fetch-mock
fetchMock.get('/api/users', { body: [{ id: 1 }] });

// MSW equivalent
http.get('/api/users', () => {
  return HttpResponse.json([{ id: 1 }]);
})
```

#### From nock

```javascript
// nock
nock('https://api.example.com')
  .get('/users')
  .reply(200, { id: 1 });

// MSW equivalent
http.get('https://api.example.com/users', () => {
  return HttpResponse.json({ id: 1 });
})
```

#### From mirage.js

```javascript
// Mirage
this.get('/api/users', () => {
  return { users: [{ id: 1 }] };
});

// MSW equivalent
http.get('/api/users', () => {
  return HttpResponse.json({
    users: [{ id: 1 }]
  });
})
```

### Best Practices

**Handler Organization**: Group handlers by domain or feature. Keep handlers focused and single-purpose.

**Response Realism**: Match production API responses including status codes, headers, and error formats.

**State Management**: Use in-memory databases for stateful scenarios. Reset state between tests.

**Error Scenarios**: Test both success and failure paths. Include network errors, timeouts, and edge cases.

**Type Safety**: Use TypeScript for type-safe request/response contracts.

**Performance**: Avoid expensive operations in handlers. Cache computed responses when appropriate.

**Testing**: Reset handlers after each test. Use test-specific handlers to avoid affecting other tests.

**Documentation**: Document handler behavior, especially for complex scenarios or stateful operations.

---

## Fixture Data Management

### Loading Strategies

Fixture data can be loaded through multiple approaches depending on application architecture and testing requirements. Direct fetch calls retrieve static JSON files from the file system or test servers, while dynamic imports enable code-splitting and lazy loading of fixtures.

```javascript
// Static fetch
const userData = await fetch('/fixtures/users.json').then(r => r.json());

// Dynamic import
const { default: products } = await import('./fixtures/products.json');
```

### File Organization

Structure fixture files by domain, feature, or test scope:

```
fixtures/
├── users/
│   ├── admin.json
│   ├── regular.json
│   └── guest.json
├── products/
│   ├── catalog.json
│   └── inventory.json
└── transactions/
    ├── pending.json
    └── completed.json
```

Reference fixtures with path-based conventions:

```javascript
async function loadFixture(path) {
  const response = await fetch(`/fixtures/${path}.json`);
  return response.json();
}

const admin = await loadFixture('users/admin');
const catalog = await loadFixture('products/catalog');
```

### Fixture Factories

Generate fixture data programmatically for variation and customization:

```javascript
class FixtureFactory {
  static user(overrides = {}) {
    return {
      id: Math.random().toString(36).substr(2, 9),
      email: `user${Date.now()}@example.com`,
      name: 'Test User',
      role: 'user',
      createdAt: new Date().toISOString(),
      ...overrides
    };
  }
  
  static product(overrides = {}) {
    return {
      id: Math.random().toString(36).substr(2, 9),
      name: 'Sample Product',
      price: 99.99,
      stock: 100,
      category: 'general',
      ...overrides
    };
  }
}

// Usage
const admin = FixtureFactory.user({ role: 'admin' });
const premiumProduct = FixtureFactory.product({ price: 299.99 });
```

### Fixture Registry

Centralize fixture management with a registry pattern:

```javascript
class FixtureRegistry {
  constructor() {
    this.cache = new Map();
    this.baseUrl = '/fixtures';
  }
  
  async load(name) {
    if (this.cache.has(name)) {
      return this.cache.get(name);
    }
    
    const response = await fetch(`${this.baseUrl}/${name}.json`);
    const data = await response.json();
    this.cache.set(name, data);
    
    return data;
  }
  
  register(name, data) {
    this.cache.set(name, data);
  }
  
  clear(name) {
    if (name) {
      this.cache.delete(name);
    } else {
      this.cache.clear();
    }
  }
  
  async loadMultiple(names) {
    return Promise.all(names.map(name => this.load(name)));
  }
}

const fixtures = new FixtureRegistry();

// Load and cache
const users = await fixtures.load('users/admin');

// Register programmatic fixtures
fixtures.register('current-user', FixtureFactory.user({ role: 'admin' }));
```

### Fixture Templating

Use placeholder substitution for dynamic fixture content:

```javascript
class FixtureTemplate {
  constructor(template) {
    this.template = template;
  }
  
  render(context = {}) {
    const rendered = JSON.stringify(this.template);
    
    return JSON.parse(
      rendered.replace(/\{\{(\w+)\}\}/g, (match, key) => {
        return context[key] !== undefined ? context[key] : match;
      })
    );
  }
}

// Template fixture
const userTemplate = {
  id: '{{userId}}',
  email: '{{email}}',
  name: '{{name}}',
  createdAt: '{{timestamp}}'
};

const template = new FixtureTemplate(userTemplate);
const user = template.render({
  userId: '123',
  email: 'alice@example.com',
  name: 'Alice',
  timestamp: new Date().toISOString()
});
```

### Fixture Composition

Combine multiple fixtures to build complex test scenarios:

```javascript
class FixtureComposer {
  constructor(registry) {
    this.registry = registry;
  }
  
  async compose(spec) {
    const result = {};
    
    for (const [key, fixtureName] of Object.entries(spec)) {
      if (typeof fixtureName === 'string') {
        result[key] = await this.registry.load(fixtureName);
      } else if (Array.isArray(fixtureName)) {
        result[key] = await this.registry.loadMultiple(fixtureName);
      }
    }
    
    return result;
  }
}

const composer = new FixtureComposer(fixtures);

const scenario = await composer.compose({
  user: 'users/admin',
  products: ['products/featured', 'products/seasonal'],
  orders: 'orders/recent'
});
```

### Fixture Variants

Manage multiple versions of the same fixture:

```javascript
class FixtureVariants {
  constructor(base) {
    this.base = base;
    this.variants = new Map();
  }
  
  addVariant(name, modifications) {
    this.variants.set(name, modifications);
  }
  
  get(variantName = null) {
    if (!variantName) {
      return structuredClone(this.base);
    }
    
    const modifications = this.variants.get(variantName);
    if (!modifications) {
      throw new Error(`Variant '${variantName}' not found`);
    }
    
    return {
      ...structuredClone(this.base),
      ...modifications
    };
  }
}

const baseUser = {
  id: '1',
  email: 'user@example.com',
  role: 'user',
  verified: false
};

const userVariants = new FixtureVariants(baseUser);
userVariants.addVariant('admin', { role: 'admin' });
userVariants.addVariant('verified', { verified: true });
userVariants.addVariant('premium', { role: 'user', subscription: 'premium' });

const admin = userVariants.get('admin');
const verified = userVariants.get('verified');
```

### Fixture Relationships

Model relationships between fixtures:

```javascript
class FixtureRelations {
  constructor() {
    this.entities = new Map();
  }
  
  define(type, id, data) {
    if (!this.entities.has(type)) {
      this.entities.set(type, new Map());
    }
    this.entities.get(type).set(id, data);
  }
  
  get(type, id) {
    return this.entities.get(type)?.get(id);
  }
  
  resolve(entity) {
    if (!entity || typeof entity !== 'object') {
      return entity;
    }
    
    const resolved = Array.isArray(entity) ? [] : {};
    
    for (const [key, value] of Object.entries(entity)) {
      if (value && typeof value === 'object' && value.$ref) {
        const [type, id] = value.$ref.split('/');
        resolved[key] = this.get(type, id);
      } else if (typeof value === 'object') {
        resolved[key] = this.resolve(value);
      } else {
        resolved[key] = value;
      }
    }
    
    return resolved;
  }
}

const relations = new FixtureRelations();

relations.define('users', '1', { id: '1', name: 'Alice' });
relations.define('orders', 'order1', {
  id: 'order1',
  user: { $ref: 'users/1' },
  total: 150
});

const order = relations.resolve(relations.get('orders', 'order1'));
// order.user now contains full user object
```

### Fixture Seeding

Populate mock APIs or test databases with fixture data:

```javascript
class FixtureSeeder {
  constructor(apiClient) {
    this.api = apiClient;
  }
  
  async seed(fixtures) {
    const results = [];
    
    for (const [endpoint, data] of Object.entries(fixtures)) {
      try {
        const response = await this.api.post(endpoint, data);
        results.push({ endpoint, status: 'success', data: response });
      } catch (error) {
        results.push({ endpoint, status: 'error', error: error.message });
      }
    }
    
    return results;
  }
  
  async seedMultiple(endpoint, items) {
    return Promise.all(
      items.map(item => this.api.post(endpoint, item))
    );
  }
}

// Usage
const seeder = new FixtureSeeder(apiClient);

await seeder.seed({
  '/api/users': await fixtures.load('users/admin'),
  '/api/products': await fixtures.load('products/catalog')
});
```

### Fixture State Management

Track and restore fixture state across tests:

```javascript
class FixtureState {
  constructor() {
    this.snapshots = [];
    this.current = new Map();
  }
  
  set(key, value) {
    this.current.set(key, structuredClone(value));
  }
  
  get(key) {
    return structuredClone(this.current.get(key));
  }
  
  snapshot() {
    this.snapshots.push(new Map(this.current));
  }
  
  restore() {
    if (this.snapshots.length === 0) {
      throw new Error('No snapshot to restore');
    }
    this.current = this.snapshots.pop();
  }
  
  reset() {
    this.current.clear();
    this.snapshots = [];
  }
}

const state = new FixtureState();

// Set initial state
state.set('users', await fixtures.load('users/all'));
state.snapshot();

// Modify state
const users = state.get('users');
users.push(FixtureFactory.user());
state.set('users', users);

// Restore to snapshot
state.restore();
```

### Lazy Loading

Defer fixture loading until needed:

```javascript
class LazyFixture {
  constructor(loader) {
    this.loader = loader;
    this.loaded = false;
    this.data = null;
  }
  
  async get() {
    if (!this.loaded) {
      this.data = await this.loader();
      this.loaded = true;
    }
    return this.data;
  }
  
  invalidate() {
    this.loaded = false;
    this.data = null;
  }
}

const lazyUsers = new LazyFixture(
  () => fetch('/fixtures/users/large-dataset.json').then(r => r.json())
);

// Only loads when first accessed
const users = await lazyUsers.get();
```

### Fixture Validation

Validate fixture data against schemas:

```javascript
class FixtureValidator {
  constructor(schemas) {
    this.schemas = schemas;
  }
  
  validate(type, data) {
    const schema = this.schemas[type];
    if (!schema) {
      throw new Error(`No schema defined for type: ${type}`);
    }
    
    const errors = [];
    
    for (const [field, rules] of Object.entries(schema)) {
      if (rules.required && !(field in data)) {
        errors.push(`Missing required field: ${field}`);
      }
      
      if (field in data && rules.type) {
        const actualType = typeof data[field];
        if (actualType !== rules.type) {
          errors.push(`Invalid type for ${field}: expected ${rules.type}, got ${actualType}`);
        }
      }
    }
    
    return {
      valid: errors.length === 0,
      errors
    };
  }
}

const validator = new FixtureValidator({
  user: {
    id: { type: 'string', required: true },
    email: { type: 'string', required: true },
    role: { type: 'string', required: true }
  }
});

const result = validator.validate('user', userData);
if (!result.valid) {
  console.error('Validation errors:', result.errors);
}
```

### Fixture Middleware

Transform fixtures during loading:

```javascript
class FixtureMiddleware {
  constructor() {
    this.transforms = [];
  }
  
  use(transform) {
    this.transforms.push(transform);
  }
  
  async apply(data) {
    let result = data;
    
    for (const transform of this.transforms) {
      result = await transform(result);
    }
    
    return result;
  }
}

const middleware = new FixtureMiddleware();

// Add timestamp to all fixtures
middleware.use(data => ({
  ...data,
  _loadedAt: new Date().toISOString()
}));

// Deep freeze for immutability
middleware.use(data => Object.freeze(structuredClone(data)));

const processed = await middleware.apply(rawFixture);
```

### Fixture Overrides

Apply environment-specific or test-specific overrides:

```javascript
class FixtureOverrides {
  constructor(baseFixtures) {
    this.base = baseFixtures;
    this.overrides = new Map();
  }
  
  override(path, value) {
    this.overrides.set(path, value);
  }
  
  async resolve(name) {
    let data = await this.base.load(name);
    
    for (const [path, value] of this.overrides.entries()) {
      if (path.startsWith(name)) {
        const keys = path.split('.').slice(1);
        data = this.applyOverride(data, keys, value);
      }
    }
    
    return data;
  }
  
  applyOverride(obj, keys, value) {
    if (keys.length === 0) return value;
    
    const result = structuredClone(obj);
    let current = result;
    
    for (let i = 0; i < keys.length - 1; i++) {
      current = current[keys[i]];
    }
    
    current[keys[keys.length - 1]] = value;
    return result;
  }
}

const overrides = new FixtureOverrides(fixtures);
overrides.override('users/admin.email', 'override@example.com');

const admin = await overrides.resolve('users/admin');
// admin.email is now 'override@example.com'
```

### Fixture Sampling

Extract subsets of large fixture datasets:

```javascript
class FixtureSampler {
  static random(array, count) {
    const shuffled = [...array].sort(() => Math.random() - 0.5);
    return shuffled.slice(0, count);
  }
  
  static first(array, count) {
    return array.slice(0, count);
  }
  
  static filter(array, predicate) {
    return array.filter(predicate);
  }
  
  static paginate(array, page, pageSize) {
    const start = (page - 1) * pageSize;
    return array.slice(start, start + pageSize);
  }
}

const allUsers = await fixtures.load('users/complete');

const sample = FixtureSampler.random(allUsers, 10);
const admins = FixtureSampler.filter(allUsers, u => u.role === 'admin');
const page1 = FixtureSampler.paginate(allUsers, 1, 20);
```

### Fixture Dependencies

Manage loading order for dependent fixtures:

```javascript
class FixtureDependencies {
  constructor(loader) {
    this.loader = loader;
    this.loaded = new Map();
    this.loading = new Set();
  }
  
  async load(name, deps = []) {
    if (this.loaded.has(name)) {
      return this.loaded.get(name);
    }
    
    if (this.loading.has(name)) {
      throw new Error(`Circular dependency detected: ${name}`);
    }
    
    this.loading.add(name);
    
    // Load dependencies first
    for (const dep of deps) {
      await this.load(dep);
    }
    
    const data = await this.loader(name);
    this.loaded.set(name, data);
    this.loading.delete(name);
    
    return data;
  }
}

const deps = new FixtureDependencies(
  name => fetch(`/fixtures/${name}.json`).then(r => r.json())
);

// Load orders (depends on users and products)
const orders = await deps.load('orders', ['users', 'products']);
```

### Fixture Versioning

Manage multiple versions of fixtures for backward compatibility:

```javascript
class FixtureVersioning {
  constructor(basePath) {
    this.basePath = basePath;
  }
  
  async load(name, version = 'latest') {
    const path = version === 'latest' 
      ? `${this.basePath}/${name}.json`
      : `${this.basePath}/${name}.v${version}.json`;
    
    const response = await fetch(path);
    return response.json();
  }
  
  async loadWithFallback(name, preferredVersion) {
    try {
      return await this.load(name, preferredVersion);
    } catch {
      return await this.load(name, 'latest');
    }
  }
}

const versioned = new FixtureVersioning('/fixtures');

const v2Data = await versioned.load('users', 2);
const latestData = await versioned.load('users');
```

---

## Integration Testing with Fetch API

### Test Environment Setup

Integration tests for fetch require simulating network requests and responses. The standard approach uses mock servers or request interceptors.

**MSW (Mock Service Worker)**:

```javascript
import { setupServer } from 'msw/node';
import { rest } from 'msw';

const server = setupServer(
  rest.get('/api/users', (req, res, ctx) => {
    return res(
      ctx.status(200),
      ctx.json({ users: [{ id: 1, name: 'Alice' }] })
    );
  })
);

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());
```

**fetch-mock**:

```javascript
import fetchMock from 'fetch-mock';

beforeEach(() => {
  fetchMock.reset();
});

test('fetches user data', async () => {
  fetchMock.get('/api/users', {
    status: 200,
    body: { users: [] }
  });
  
  const response = await fetch('/api/users');
  const data = await response.json();
  
  expect(data.users).toEqual([]);
});
```

### Request Verification

Test that requests contain correct data, headers, and configuration:

```javascript
test('sends authentication header', async () => {
  fetchMock.post('/api/data', 200);
  
  await fetch('/api/data', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer token123',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ value: 42 })
  });
  
  const [url, options] = fetchMock.lastCall();
  expect(options.headers['Authorization']).toBe('Bearer token123');
  expect(JSON.parse(options.body)).toEqual({ value: 42 });
});
```

### Response Handling Tests

Verify correct processing of various response types and statuses:

```javascript
describe('response handling', () => {
  test('processes JSON responses', async () => {
    server.use(
      rest.get('/api/data', (req, res, ctx) => {
        return res(ctx.json({ message: 'success' }));
      })
    );
    
    const response = await fetch('/api/data');
    const data = await response.json();
    
    expect(data.message).toBe('success');
  });
  
  test('handles text responses', async () => {
    server.use(
      rest.get('/api/text', (req, res, ctx) => {
        return res(ctx.text('plain text content'));
      })
    );
    
    const response = await fetch('/api/text');
    const text = await response.text();
    
    expect(text).toBe('plain text content');
  });
  
  test('processes blob responses', async () => {
    const imageBuffer = new ArrayBuffer(8);
    
    server.use(
      rest.get('/api/image', (req, res, ctx) => {
        return res(
          ctx.set('Content-Type', 'image/png'),
          ctx.body(imageBuffer)
        );
      })
    );
    
    const response = await fetch('/api/image');
    const blob = await response.blob();
    
    expect(blob.type).toBe('image/png');
  });
});
```

### Error Scenario Testing

Test network failures, timeouts, and error responses:

```javascript
test('handles network errors', async () => {
  fetchMock.get('/api/data', {
    throws: new Error('Network error')
  });
  
  await expect(fetch('/api/data')).rejects.toThrow('Network error');
});

test('handles HTTP error statuses', async () => {
  server.use(
    rest.get('/api/resource', (req, res, ctx) => {
      return res(
        ctx.status(404),
        ctx.json({ error: 'Not found' })
      );
    })
  );
  
  const response = await fetch('/api/resource');
  
  expect(response.ok).toBe(false);
  expect(response.status).toBe(404);
  
  const data = await response.json();
  expect(data.error).toBe('Not found');
});

test('handles timeout scenarios', async () => {
  server.use(
    rest.get('/api/slow', (req, res, ctx) => {
      return res(ctx.delay(5000));
    })
  );
  
  const controller = new AbortController();
  setTimeout(() => controller.abort(), 1000);
  
  await expect(
    fetch('/api/slow', { signal: controller.signal })
  ).rejects.toThrow('aborted');
});
```

### Query Parameter Testing

Verify correct URL construction and parameter encoding:

```javascript
test('constructs URLs with query parameters', async () => {
  fetchMock.get('begin:/api/search', 200);
  
  const params = new URLSearchParams({
    q: 'test query',
    filter: 'active',
    page: '2'
  });
  
  await fetch(`/api/search?${params}`);
  
  const calledUrl = fetchMock.lastUrl();
  expect(calledUrl).toContain('q=test+query');
  expect(calledUrl).toContain('filter=active');
  expect(calledUrl).toContain('page=2');
});

test('encodes special characters in parameters', async () => {
  fetchMock.get('begin:/api/search', 200);
  
  const searchTerm = 'test & special <chars>';
  const params = new URLSearchParams({ q: searchTerm });
  
  await fetch(`/api/search?${params}`);
  
  const calledUrl = fetchMock.lastUrl();
  expect(calledUrl).toContain(encodeURIComponent(searchTerm));
});
```

### Header Validation Tests

Test request and response header handling:

```javascript
test('sends custom headers', async () => {
  server.use(
    rest.post('/api/data', (req, res, ctx) => {
      expect(req.headers.get('X-Custom-Header')).toBe('custom-value');
      expect(req.headers.get('Content-Type')).toBe('application/json');
      return res(ctx.json({ received: true }));
    })
  );
  
  await fetch('/api/data', {
    method: 'POST',
    headers: {
      'X-Custom-Header': 'custom-value',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ test: true })
  });
});

test('reads response headers', async () => {
  server.use(
    rest.get('/api/data', (req, res, ctx) => {
      return res(
        ctx.set('X-Rate-Limit', '100'),
        ctx.set('X-Rate-Remaining', '95'),
        ctx.json({ data: 'value' })
      );
    })
  );
  
  const response = await fetch('/api/data');
  
  expect(response.headers.get('X-Rate-Limit')).toBe('100');
  expect(response.headers.get('X-Rate-Remaining')).toBe('95');
});
```

### Request Body Validation

Test different body types and serialization:

```javascript
describe('request body handling', () => {
  test('sends JSON body', async () => {
    server.use(
      rest.post('/api/users', async (req, res, ctx) => {
        const body = await req.json();
        expect(body.name).toBe('Alice');
        expect(body.age).toBe(30);
        return res(ctx.json({ id: 1, ...body }));
      })
    );
    
    const response = await fetch('/api/users', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ name: 'Alice', age: 30 })
    });
    
    const data = await response.json();
    expect(data.id).toBe(1);
  });
  
  test('sends FormData', async () => {
    server.use(
      rest.post('/api/upload', async (req, res, ctx) => {
        const formData = await req.formData();
        expect(formData.get('username')).toBe('testuser');
        return res(ctx.json({ success: true }));
      })
    );
    
    const formData = new FormData();
    formData.append('username', 'testuser');
    formData.append('file', new Blob(['content']), 'test.txt');
    
    await fetch('/api/upload', {
      method: 'POST',
      body: formData
    });
  });
  
  test('sends URLSearchParams', async () => {
    server.use(
      rest.post('/api/form', async (req, res, ctx) => {
        const text = await req.text();
        expect(text).toContain('field1=value1');
        expect(text).toContain('field2=value2');
        return res(ctx.json({ received: true }));
      })
    );
    
    const params = new URLSearchParams({
      field1: 'value1',
      field2: 'value2'
    });
    
    await fetch('/api/form', {
      method: 'POST',
      body: params
    });
  });
});
```

### Retry Logic Testing

Test retry mechanisms and exponential backoff:

```javascript
test('retries failed requests', async () => {
  let attemptCount = 0;
  
  server.use(
    rest.get('/api/unstable', (req, res, ctx) => {
      attemptCount++;
      if (attemptCount < 3) {
        return res(ctx.status(503));
      }
      return res(ctx.json({ success: true }));
    })
  );
  
  async function fetchWithRetry(url, maxRetries = 3) {
    for (let i = 0; i < maxRetries; i++) {
      const response = await fetch(url);
      if (response.ok) return response;
      if (i < maxRetries - 1) await new Promise(r => setTimeout(r, 100));
    }
    throw new Error('Max retries exceeded');
  }
  
  const response = await fetchWithRetry('/api/unstable');
  const data = await response.json();
  
  expect(attemptCount).toBe(3);
  expect(data.success).toBe(true);
});
```

### Concurrent Request Testing

Test parallel request handling:

```javascript
test('handles concurrent requests', async () => {
  server.use(
    rest.get('/api/resource/:id', (req, res, ctx) => {
      const { id } = req.params;
      return res(
        ctx.delay(Math.random() * 100),
        ctx.json({ id, data: `Resource ${id}` })
      );
    })
  );
  
  const ids = [1, 2, 3, 4, 5];
  const promises = ids.map(id => 
    fetch(`/api/resource/${id}`).then(r => r.json())
  );
  
  const results = await Promise.all(promises);
  
  expect(results).toHaveLength(5);
  results.forEach((result, index) => {
    expect(result.id).toBe(String(ids[index]));
  });
});

test('limits concurrent requests', async () => {
  let activeRequests = 0;
  let maxConcurrent = 0;
  
  server.use(
    rest.get('/api/item/:id', async (req, res, ctx) => {
      activeRequests++;
      maxConcurrent = Math.max(maxConcurrent, activeRequests);
      await new Promise(resolve => setTimeout(resolve, 50));
      activeRequests--;
      return res(ctx.json({ id: req.params.id }));
    })
  );
  
  async function fetchWithLimit(urls, limit) {
    const results = [];
    const executing = [];
    
    for (const url of urls) {
      const promise = fetch(url).then(r => r.json());
      results.push(promise);
      
      if (limit <= urls.length) {
        const e = promise.then(() => {
          executing.splice(executing.indexOf(e), 1);
        });
        executing.push(e);
        
        if (executing.length >= limit) {
          await Promise.race(executing);
        }
      }
    }
    
    return Promise.all(results);
  }
  
  const urls = Array.from({ length: 10 }, (_, i) => `/api/item/${i}`);
  await fetchWithLimit(urls, 3);
  
  expect(maxConcurrent).toBeLessThanOrEqual(3);
});
```

### Cache Control Testing

Test cache behavior and headers:

```javascript
test('respects cache headers', async () => {
  let callCount = 0;
  
  server.use(
    rest.get('/api/cached', (req, res, ctx) => {
      callCount++;
      return res(
        ctx.set('Cache-Control', 'max-age=3600'),
        ctx.json({ timestamp: Date.now() })
      );
    })
  );
  
  const response1 = await fetch('/api/cached');
  const data1 = await response1.json();
  
  const response2 = await fetch('/api/cached', { cache: 'force-cache' });
  const data2 = await response2.json();
  
  // [Inference]: Actual cache behavior depends on browser/environment
  expect(response1.headers.get('Cache-Control')).toBe('max-age=3600');
});

test('bypasses cache when requested', async () => {
  fetchMock.get('/api/data', { value: 1 });
  
  await fetch('/api/data', { cache: 'no-store' });
  
  const options = fetchMock.lastOptions();
  expect(options.cache).toBe('no-store');
});
```

### Authentication Flow Testing

Test authentication token handling and refresh:

```javascript
describe('authentication flows', () => {
  test('includes auth token in requests', async () => {
    const token = 'test-token-123';
    
    server.use(
      rest.get('/api/protected', (req, res, ctx) => {
        const auth = req.headers.get('Authorization');
        expect(auth).toBe(`Bearer ${token}`);
        return res(ctx.json({ data: 'protected content' }));
      })
    );
    
    await fetch('/api/protected', {
      headers: {
        'Authorization': `Bearer ${token}`
      }
    });
  });
  
  test('handles token refresh flow', async () => {
    let accessToken = 'expired-token';
    const refreshToken = 'refresh-token';
    
    server.use(
      rest.get('/api/data', (req, res, ctx) => {
        const auth = req.headers.get('Authorization');
        if (auth === 'Bearer expired-token') {
          return res(ctx.status(401), ctx.json({ error: 'Token expired' }));
        }
        return res(ctx.json({ data: 'success' }));
      }),
      rest.post('/api/refresh', (req, res, ctx) => {
        return res(ctx.json({ accessToken: 'new-token' }));
      })
    );
    
    async function fetchWithAuth(url) {
      let response = await fetch(url, {
        headers: { 'Authorization': `Bearer ${accessToken}` }
      });
      
      if (response.status === 401) {
        const refreshResponse = await fetch('/api/refresh', {
          method: 'POST',
          headers: { 'Authorization': `Bearer ${refreshToken}` }
        });
        const { accessToken: newToken } = await refreshResponse.json();
        accessToken = newToken;
        
        response = await fetch(url, {
          headers: { 'Authorization': `Bearer ${accessToken}` }
        });
      }
      
      return response;
    }
    
    const response = await fetchWithAuth('/api/data');
    const data = await response.json();
    
    expect(data.data).toBe('success');
    expect(accessToken).toBe('new-token');
  });
});
```

### CORS Testing

Test cross-origin request handling:

```javascript
test('handles CORS preflight', async () => {
  server.use(
    rest.options('/api/data', (req, res, ctx) => {
      return res(
        ctx.set('Access-Control-Allow-Origin', '*'),
        ctx.set('Access-Control-Allow-Methods', 'GET, POST, PUT'),
        ctx.set('Access-Control-Allow-Headers', 'Content-Type, Authorization'),
        ctx.status(204)
      );
    }),
    rest.post('/api/data', (req, res, ctx) => {
      return res(
        ctx.set('Access-Control-Allow-Origin', '*'),
        ctx.json({ success: true })
      );
    })
  );
  
  const response = await fetch('http://localhost:3000/api/data', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer token'
    },
    body: JSON.stringify({ data: 'test' })
  });
  
  expect(response.headers.get('Access-Control-Allow-Origin')).toBe('*');
});
```

### Abort Signal Testing

Test request cancellation:

```javascript
test('cancels request with abort signal', async () => {
  server.use(
    rest.get('/api/slow', (req, res, ctx) => {
      return res(ctx.delay(5000), ctx.json({ data: 'slow' }));
    })
  );
  
  const controller = new AbortController();
  
  const fetchPromise = fetch('/api/slow', {
    signal: controller.signal
  });
  
  setTimeout(() => controller.abort(), 100);
  
  await expect(fetchPromise).rejects.toThrow();
});

test('handles multiple requests with shared abort signal', async () => {
  server.use(
    rest.get('/api/endpoint1', (req, res, ctx) => {
      return res(ctx.delay(1000), ctx.json({ id: 1 }));
    }),
    rest.get('/api/endpoint2', (req, res, ctx) => {
      return res(ctx.delay(1000), ctx.json({ id: 2 }));
    })
  );
  
  const controller = new AbortController();
  
  const promise1 = fetch('/api/endpoint1', { signal: controller.signal });
  const promise2 = fetch('/api/endpoint2', { signal: controller.signal });
  
  setTimeout(() => controller.abort(), 100);
  
  await expect(Promise.all([promise1, promise2])).rejects.toThrow();
});
```

### Stream Processing Testing

Test response stream handling:

```javascript
test('processes response stream', async () => {
  const chunks = ['chunk1', 'chunk2', 'chunk3'];
  let chunkIndex = 0;
  
  server.use(
    rest.get('/api/stream', (req, res, ctx) => {
      const stream = new ReadableStream({
        start(controller) {
          chunks.forEach(chunk => {
            controller.enqueue(new TextEncoder().encode(chunk));
          });
          controller.close();
        }
      });
      
      return res(ctx.body(stream));
    })
  );
  
  const response = await fetch('/api/stream');
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  const received = [];
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    received.push(decoder.decode(value));
  }
  
  expect(received).toEqual(chunks);
});
```

### Response Validation Testing

Test response data validation and schema checking:

```javascript
test('validates response schema', async () => {
  server.use(
    rest.get('/api/user', (req, res, ctx) => {
      return res(ctx.json({
        id: 1,
        name: 'Alice',
        email: 'alice@example.com',
        age: 30
      }));
    })
  );
  
  const response = await fetch('/api/user');
  const user = await response.json();
  
  expect(user).toHaveProperty('id');
  expect(user).toHaveProperty('name');
  expect(user).toHaveProperty('email');
  expect(typeof user.id).toBe('number');
  expect(typeof user.name).toBe('string');
  expect(user.email).toMatch(/^[^\s@]+@[^\s@]+\.[^\s@]+$/);
});
```

### Integration with Application State

Test fetch integration with state management:

```javascript
// Redux integration example
test('dispatches actions on fetch success', async () => {
  const mockDispatch = jest.fn();
  
  server.use(
    rest.get('/api/users', (req, res, ctx) => {
      return res(ctx.json({ users: [{ id: 1, name: 'Alice' }] }));
    })
  );
  
  async function fetchUsers(dispatch) {
    dispatch({ type: 'FETCH_USERS_REQUEST' });
    
    try {
      const response = await fetch('/api/users');
      const data = await response.json();
      dispatch({ type: 'FETCH_USERS_SUCCESS', payload: data.users });
    } catch (error) {
      dispatch({ type: 'FETCH_USERS_FAILURE', error: error.message });
    }
  }
  
  await fetchUsers(mockDispatch);
  
  expect(mockDispatch).toHaveBeenCalledWith({ type: 'FETCH_USERS_REQUEST' });
  expect(mockDispatch).toHaveBeenCalledWith({
    type: 'FETCH_USERS_SUCCESS',
    payload: [{ id: 1, name: 'Alice' }]
  });
});
```

### Performance Testing

Test request timing and performance characteristics:

```javascript
test('measures request duration', async () => {
  server.use(
    rest.get('/api/data', (req, res, ctx) => {
      return res(ctx.delay(200), ctx.json({ value: 42 }));
    })
  );
  
  const start = performance.now();
  const response = await fetch('/api/data');
  await response.json();
  const duration = performance.now() - start;
  
  expect(duration).toBeGreaterThan(200);
  expect(duration).toBeLessThan(300);
});
```

---

## Error Scenario Testing for Fetch API

### Network Failure Testing

#### Connection Refused

Simulating scenarios where the server is unreachable or refuses the connection.

```javascript
async function testConnectionRefused() {
  try {
    // Port 9999 likely has nothing listening
    await fetch('http://localhost:9999/api/endpoint');
    console.error('Expected connection refused error');
  } catch (error) {
    console.log('✓ Connection refused handled:', error.message);
    assert(error instanceof TypeError);
    assert(error.message.includes('Failed to fetch'));
  }
}
```

#### DNS Resolution Failure

Testing behavior when domain names cannot be resolved.

```javascript
async function testDNSFailure() {
  try {
    await fetch('https://nonexistent-domain-12345.invalid/api/data');
    console.error('Expected DNS failure');
  } catch (error) {
    console.log('✓ DNS failure handled:', error.message);
    assert(error instanceof TypeError);
  }
}
```

#### Network Timeout

Simulating slow or unresponsive servers using AbortController.

```javascript
async function testNetworkTimeout() {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 5000);
  
  try {
    // Simulate slow endpoint
    await fetch('https://httpstat.us/200?sleep=10000', {
      signal: controller.signal
    });
    console.error('Expected timeout error');
  } catch (error) {
    console.log('✓ Timeout handled:', error.name);
    assert(error.name === 'AbortError');
  } finally {
    clearTimeout(timeoutId);
  }
}
```

#### Intermittent Connectivity

Testing behavior during sporadic network availability.

```javascript
async function testIntermittentConnectivity() {
  let attemptCount = 0;
  const maxRetries = 3;
  
  async function fetchWithRetry(url) {
    while (attemptCount < maxRetries) {
      try {
        const response = await fetch(url);
        console.log(`✓ Succeeded on attempt ${attemptCount + 1}`);
        return response;
      } catch (error) {
        attemptCount++;
        if (attemptCount >= maxRetries) {
          console.log('✓ Failed after max retries');
          throw error;
        }
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
  }
  
  await fetchWithRetry('https://example.com/flaky-endpoint');
}
```

#### Network Change During Request

Simulating network switching (WiFi to cellular, etc.).

```javascript
async function testNetworkChange() {
  const controller = new AbortController();
  
  // Listen for network changes
  window.addEventListener('offline', () => {
    console.log('Network went offline during request');
    controller.abort();
  });
  
  try {
    await fetch('https://example.com/large-file', {
      signal: controller.signal
    });
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('✓ Request aborted due to network change');
    }
  }
}
```

### HTTP Status Code Testing

#### 4xx Client Errors

Testing various client error responses.

```javascript
async function test4xxErrors() {
  const testCases = [
    { status: 400, url: 'https://httpstat.us/400', description: 'Bad Request' },
    { status: 401, url: 'https://httpstat.us/401', description: 'Unauthorized' },
    { status: 403, url: 'https://httpstat.us/403', description: 'Forbidden' },
    { status: 404, url: 'https://httpstat.us/404', description: 'Not Found' },
    { status: 409, url: 'https://httpstat.us/409', description: 'Conflict' },
    { status: 422, url: 'https://httpstat.us/422', description: 'Unprocessable Entity' },
    { status: 429, url: 'https://httpstat.us/429', description: 'Too Many Requests' }
  ];
  
  for (const test of testCases) {
    const response = await fetch(test.url);
    assert(!response.ok);
    assert(response.status === test.status);
    console.log(`✓ ${test.status} ${test.description} handled correctly`);
  }
}
```

#### 5xx Server Errors

Testing server error responses.

```javascript
async function test5xxErrors() {
  const testCases = [
    { status: 500, url: 'https://httpstat.us/500', description: 'Internal Server Error' },
    { status: 502, url: 'https://httpstat.us/502', description: 'Bad Gateway' },
    { status: 503, url: 'https://httpstat.us/503', description: 'Service Unavailable' },
    { status: 504, url: 'https://httpstat.us/504', description: 'Gateway Timeout' }
  ];
  
  for (const test of testCases) {
    const response = await fetch(test.url);
    assert(!response.ok);
    assert(response.status >= 500);
    console.log(`✓ ${test.status} ${test.description} handled correctly`);
  }
}
```

#### Edge Case Status Codes

Testing uncommon but valid status codes.

```javascript
async function testEdgeCaseStatuses() {
  const testCases = [
    { status: 204, description: 'No Content (empty response)' },
    { status: 206, description: 'Partial Content' },
    { status: 304, description: 'Not Modified' },
    { status: 418, description: "I'm a teapot" },
    { status: 451, description: 'Unavailable For Legal Reasons' }
  ];
  
  for (const test of testCases) {
    const response = await fetch(`https://httpstat.us/${test.status}`);
    assert(response.status === test.status);
    
    // 204 should have no body
    if (test.status === 204) {
      const text = await response.text();
      assert(text === '');
      console.log(`✓ ${test.status} has empty body as expected`);
    }
  }
}
```

### Response Parsing Errors

#### Invalid JSON

Testing handling of malformed JSON responses.

```javascript
async function testInvalidJSON() {
  // Mock server returning invalid JSON
  const mockResponse = new Response('{ invalid json }', {
    headers: { 'Content-Type': 'application/json' }
  });
  
  try {
    await mockResponse.json();
    console.error('Expected JSON parsing error');
  } catch (error) {
    console.log('✓ Invalid JSON handled:', error.message);
    assert(error instanceof SyntaxError);
  }
}

async function testPartialJSON() {
  const mockResponse = new Response('{"data": "incomplete"', {
    headers: { 'Content-Type': 'application/json' }
  });
  
  try {
    await mockResponse.json();
    console.error('Expected JSON parsing error');
  } catch (error) {
    console.log('✓ Partial JSON handled:', error.message);
  }
}
```

#### Content-Type Mismatch

Testing mismatches between declared and actual content types.

```javascript
async function testContentTypeMismatch() {
  // Server claims JSON but sends HTML
  const mockResponse = new Response('<html><body>Error</body></html>', {
    headers: { 'Content-Type': 'application/json' }
  });
  
  try {
    const data = await mockResponse.json();
    console.error('Expected parsing to fail');
  } catch (error) {
    console.log('✓ Content-Type mismatch detected');
  }
}

async function testMissingContentType() {
  const mockResponse = new Response('some data', {
    headers: {} // No Content-Type
  });
  
  const text = await mockResponse.text();
  console.log('✓ Missing Content-Type handled, text:', text);
}
```

#### Binary Data Corruption

Testing handling of corrupted binary responses.

```javascript
async function testCorruptedBinary() {
  // Simulate corrupted image
  const corruptedData = new Uint8Array([0xFF, 0xD8, 0xFF]); // Invalid JPEG
  const mockResponse = new Response(corruptedData, {
    headers: { 'Content-Type': 'image/jpeg' }
  });
  
  try {
    const blob = await mockResponse.blob();
    const img = new Image();
    
    img.onerror = () => {
      console.log('✓ Corrupted image detected');
    };
    
    img.src = URL.createObjectURL(blob);
  } catch (error) {
    console.log('✓ Binary corruption handled:', error.message);
  }
}
```

#### Empty Response Body

Testing scenarios where response body is unexpectedly empty.

```javascript
async function testEmptyResponseBody() {
  const testCases = [
    { status: 200, expectEmpty: false },
    { status: 204, expectEmpty: true },
    { status: 304, expectEmpty: true }
  ];
  
  for (const test of testCases) {
    const response = new Response(test.expectEmpty ? null : '{"data": "value"}', {
      status: test.status,
      headers: test.expectEmpty ? {} : { 'Content-Type': 'application/json' }
    });
    
    const text = await response.text();
    
    if (test.expectEmpty) {
      assert(text === '');
      console.log(`✓ ${test.status} correctly has empty body`);
    } else {
      assert(text !== '');
      console.log(`✓ ${test.status} correctly has body`);
    }
  }
}
```

### CORS Error Testing

#### Missing CORS Headers

Testing requests to servers without proper CORS configuration.

```javascript
async function testMissingCORSHeaders() {
  try {
    // Request to server without CORS headers
    await fetch('https://example.com/no-cors-endpoint', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' }
    });
    console.error('Expected CORS error');
  } catch (error) {
    console.log('✓ Missing CORS headers blocked:', error.message);
    assert(error instanceof TypeError);
  }
}
```

#### Preflight Failure

Testing scenarios where preflight OPTIONS requests fail.

```javascript
async function testPreflightFailure() {
  try {
    // Custom header triggers preflight
    await fetch('https://example.com/api', {
      method: 'POST',
      headers: {
        'X-Custom-Header': 'value',
        'Content-Type': 'application/json'
      }
    });
    console.error('Expected preflight failure');
  } catch (error) {
    console.log('✓ Preflight failure handled:', error.message);
  }
}
```

#### Credentials Mode Mismatch

Testing credential inclusion with misconfigured CORS.

```javascript
async function testCredentialsMismatch() {
  try {
    // credentials: 'include' requires specific CORS headers
    await fetch('https://api.example.com/endpoint', {
      method: 'GET',
      credentials: 'include'
      // Server must respond with:
      // Access-Control-Allow-Credentials: true
      // Access-Control-Allow-Origin: specific-origin (not *)
    });
  } catch (error) {
    console.log('✓ Credentials mismatch handled:', error.message);
  }
}
```

#### Wildcard Origin with Credentials

Testing the invalid combination of wildcard origin and credentials.

```javascript
async function testWildcardWithCredentials() {
  // This should fail - wildcard (*) not allowed with credentials
  const mockHeaders = new Headers({
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Credentials': 'true'
  });
  
  try {
    // Browser will reject this combination
    const response = new Response('{}', { headers: mockHeaders });
    console.log('✓ Wildcard with credentials prevented');
  } catch (error) {
    console.log('✓ Invalid CORS configuration detected');
  }
}
```

### Timeout and Abort Testing

#### Request Cancellation

Testing explicit request cancellation via AbortController.

```javascript
async function testRequestCancellation() {
  const controller = new AbortController();
  
  const fetchPromise = fetch('https://httpstat.us/200?sleep=5000', {
    signal: controller.signal
  });
  
  // Cancel after 100ms
  setTimeout(() => controller.abort(), 100);
  
  try {
    await fetchPromise;
    console.error('Expected abort error');
  } catch (error) {
    console.log('✓ Request cancelled:', error.name);
    assert(error.name === 'AbortError');
    assert(error.message.includes('aborted'));
  }
}
```

#### Multiple Simultaneous Cancellations

Testing cancellation of parallel requests.

```javascript
async function testMultipleCancellations() {
  const controller = new AbortController();
  
  const requests = [
    fetch('https://httpstat.us/200?sleep=5000', { signal: controller.signal }),
    fetch('https://httpstat.us/201?sleep=5000', { signal: controller.signal }),
    fetch('https://httpstat.us/202?sleep=5000', { signal: controller.signal })
  ];
  
  setTimeout(() => controller.abort(), 100);
  
  const results = await Promise.allSettled(requests);
  
  const allAborted = results.every(r => 
    r.status === 'rejected' && r.reason.name === 'AbortError'
  );
  
  assert(allAborted);
  console.log('✓ All parallel requests cancelled');
}
```

#### Already Aborted Signal

Testing behavior when signal is aborted before fetch is called.

```javascript
async function testAlreadyAbortedSignal() {
  const controller = new AbortController();
  controller.abort(); // Abort immediately
  
  try {
    await fetch('https://example.com/api', {
      signal: controller.signal
    });
    console.error('Expected immediate abort');
  } catch (error) {
    console.log('✓ Already-aborted signal handled:', error.name);
    assert(error.name === 'AbortError');
  }
}
```

#### Abort Reason Handling

Testing custom abort reasons (modern browsers).

```javascript
async function testAbortReason() {
  const controller = new AbortController();
  
  const fetchPromise = fetch('https://httpstat.us/200?sleep=5000', {
    signal: controller.signal
  });
  
  setTimeout(() => {
    controller.abort(new Error('Custom timeout reason'));
  }, 100);
  
  try {
    await fetchPromise;
  } catch (error) {
    console.log('✓ Abort reason:', error.message);
    assert(error.message === 'Custom timeout reason');
  }
}
```

### Request Body Errors

#### Invalid JSON in Request Body

Testing sending malformed JSON data.

```javascript
async function testInvalidRequestJSON() {
  try {
    // Create circular reference (not JSON-serializable)
    const circular = {};
    circular.self = circular;
    
    await fetch('https://example.com/api', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(circular)
    });
    console.error('Expected serialization error');
  } catch (error) {
    console.log('✓ Circular reference detected:', error.message);
    assert(error instanceof TypeError);
  }
}
```

#### Large Payload Handling

Testing behavior with oversized request bodies.

```javascript
async function testLargePayload() {
  // Generate 10MB payload
  const largeData = 'x'.repeat(10 * 1024 * 1024);
  
  try {
    const response = await fetch('https://example.com/api/upload', {
      method: 'POST',
      body: largeData
    });
    
    if (response.status === 413) {
      console.log('✓ Payload too large handled by server');
    }
  } catch (error) {
    console.log('✓ Large payload error:', error.message);
  }
}
```

#### FormData Errors

Testing FormData construction and transmission errors.

```javascript
async function testFormDataErrors() {
  const formData = new FormData();
  
  // Attempt to append non-serializable value
  try {
    formData.append('data', { complex: { nested: { object: true } } });
    
    const response = await fetch('https://example.com/api/form', {
      method: 'POST',
      body: formData
    });
    
    // FormData will convert to "[object Object]"
    console.log('✓ FormData auto-conversion behavior verified');
  } catch (error) {
    console.log('✓ FormData error:', error.message);
  }
}
```

#### Stream Errors

Testing errors during request body streaming.

```javascript
async function testStreamErrors() {
  const stream = new ReadableStream({
    start(controller) {
      controller.enqueue(new TextEncoder().encode('data'));
      controller.error(new Error('Stream error'));
    }
  });
  
  try {
    await fetch('https://example.com/api', {
      method: 'POST',
      body: stream,
      duplex: 'half'
    });
    console.error('Expected stream error');
  } catch (error) {
    console.log('✓ Stream error handled:', error.message);
  }
}
```

### Authentication Errors

#### Missing Authentication Token

Testing requests without required authentication.

```javascript
async function testMissingAuth() {
  const response = await fetch('https://api.example.com/protected', {
    method: 'GET'
    // Missing Authorization header
  });
  
  assert(response.status === 401);
  console.log('✓ Missing auth returns 401');
}
```

#### Expired Token

Testing behavior with expired authentication tokens.

```javascript
async function testExpiredToken() {
  const expiredToken = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MDAwMDAwMDB9.xxx';
  
  const response = await fetch('https://api.example.com/protected', {
    headers: {
      'Authorization': `Bearer ${expiredToken}`
    }
  });
  
  assert(response.status === 401);
  const body = await response.json();
  assert(body.error === 'Token expired');
  console.log('✓ Expired token handled');
}
```

#### Invalid Token Format

Testing malformed authentication tokens.

```javascript
async function testInvalidTokenFormat() {
  const testCases = [
    'invalid-token',
    'Bearer',
    'Bearer ',
    'Bearer not-a-jwt',
    ''
  ];
  
  for (const token of testCases) {
    const response = await fetch('https://api.example.com/protected', {
      headers: {
        'Authorization': token
      }
    });
    
    assert(response.status === 401 || response.status === 400);
    console.log(`✓ Invalid token format rejected: "${token}"`);
  }
}
```

#### Token Refresh During Request

Testing scenarios where token expires mid-request.

```javascript
async function testTokenRefreshScenario() {
  let accessToken = 'valid-token';
  
  async function fetchWithTokenRefresh(url, options = {}) {
    let response = await fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${accessToken}`
      }
    });
    
    // Token expired during request
    if (response.status === 401) {
      const body = await response.json();
      if (body.error === 'Token expired') {
        console.log('Token expired, refreshing...');
        
        // Refresh token
        const refreshResponse = await fetch('https://api.example.com/refresh', {
          method: 'POST',
          body: JSON.stringify({ refreshToken: 'refresh-token' })
        });
        
        const { accessToken: newToken } = await refreshResponse.json();
        accessToken = newToken;
        
        // Retry original request
        response = await fetch(url, {
          ...options,
          headers: {
            ...options.headers,
            'Authorization': `Bearer ${accessToken}`
          }
        });
      }
    }
    
    return response;
  }
  
  const response = await fetchWithTokenRefresh('https://api.example.com/data');
  console.log('✓ Token refresh scenario handled');
}
```

### Rate Limiting Testing

#### 429 Too Many Requests

Testing rate limit response handling.

```javascript
async function testRateLimiting() {
  const response = await fetch('https://httpstat.us/429');
  
  assert(response.status === 429);
  
  const retryAfter = response.headers.get('Retry-After');
  if (retryAfter) {
    const waitTime = parseInt(retryAfter) * 1000;
    console.log(`✓ Rate limited, retry after ${retryAfter}s`);
  }
}
```

#### Exponential Backoff Testing

Testing retry logic with exponential backoff.

```javascript
async function testExponentialBackoff() {
  let attempt = 0;
  const maxAttempts = 5;
  
  async function fetchWithBackoff(url) {
    while (attempt < maxAttempts) {
      const response = await fetch(url);
      
      if (response.status !== 429) {
        return response;
      }
      
      attempt++;
      const delay = Math.pow(2, attempt) * 1000; // 2s, 4s, 8s, 16s, 32s
      console.log(`Rate limited, waiting ${delay}ms before retry ${attempt}`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
    
    throw new Error('Max retry attempts reached');
  }
  
  try {
    await fetchWithBackoff('https://httpstat.us/429');
  } catch (error) {
    console.log('✓ Exponential backoff exhausted:', error.message);
  }
}
```

#### Concurrent Request Limiting

Testing client-side request throttling.

```javascript
async function testConcurrentLimiting() {
  const maxConcurrent = 3;
  let activeRequests = 0;
  const queue = [];
  
  async function throttledFetch(url) {
    if (activeRequests >= maxConcurrent) {
      await new Promise(resolve => queue.push(resolve));
    }
    
    activeRequests++;
    console.log(`Active requests: ${activeRequests}`);
    
    try {
      const response = await fetch(url);
      return response;
    } finally {
      activeRequests--;
      if (queue.length > 0) {
        const resolve = queue.shift();
        resolve();
      }
    }
  }
  
  // Fire 10 concurrent requests
  const requests = Array(10).fill(null).map((_, i) => 
    throttledFetch(`https://httpstat.us/200?index=${i}`)
  );
  
  await Promise.all(requests);
  console.log('✓ Concurrent request limiting verified');
}
```

### Redirect Errors

#### Redirect Loop Detection

Testing behavior with circular redirects.

```javascript
async function testRedirectLoop() {
  try {
    // Most browsers limit to 20 redirects
    await fetch('https://httpstat.us/301', {
      redirect: 'follow'
    });
    console.error('Expected redirect loop error');
  } catch (error) {
    console.log('✓ Redirect loop detected:', error.message);
  }
}
```

#### Manual Redirect Handling

Testing manual redirect mode.

```javascript
async function testManualRedirect() {
  const response = await fetch('https://httpstat.us/302', {
    redirect: 'manual'
  });
  
  assert(response.type === 'opaqueredirect');
  assert(response.status === 0);
  console.log('✓ Manual redirect handled, location:', response.headers.get('Location'));
}
```

#### Cross-Origin Redirect

Testing redirects to different origins.

```javascript
async function testCrossOriginRedirect() {
  try {
    // Redirect from one domain to another
    const response = await fetch('https://example.com/redirect-to-other-domain', {
      redirect: 'follow'
    });
    
    // Check if credentials were properly handled
    assert(response.url !== 'https://example.com/redirect-to-other-domain');
    console.log('✓ Cross-origin redirect handled, final URL:', response.url);
  } catch (error) {
    console.log('✓ Cross-origin redirect error:', error.message);
  }
}
```

#### Too Many Redirects

Testing redirect limit enforcement.

```javascript
async function testTooManyRedirects() {
  let redirectCount = 0;
  
  // Simulate redirect chain
  async function followRedirects(url, maxRedirects = 20) {
    while (redirectCount < maxRedirects) {
      const response = await fetch(url, { redirect: 'manual' });
      
      if (response.type === 'opaqueredirect') {
        redirectCount++;
        const location = response.headers.get('Location');
        if (!location) break;
        url = location;
      } else {
        return response;
      }
    }
    
    throw new Error('Too many redirects');
  }
  
  try {
    await followRedirects('https://httpstat.us/301');
  } catch (error) {
    console.log('✓ Too many redirects:', redirectCount);
  }
}
```

### SSL/TLS Errors

#### Self-Signed Certificate

Testing behavior with untrusted certificates (development environments).

```javascript
async function testSelfSignedCert() {
  try {
    // In production, this should fail
    await fetch('https://self-signed.badssl.com/');
    console.error('Expected SSL error');
  } catch (error) {
    console.log('✓ Self-signed certificate rejected:', error.message);
    assert(error instanceof TypeError);
  }
}
```

#### Expired Certificate

Testing expired SSL certificate handling.

```javascript
async function testExpiredCert() {
  try {
    await fetch('https://expired.badssl.com/');
    console.error('Expected SSL error');
  } catch (error) {
    console.log('✓ Expired certificate rejected:', error.message);
  }
}
```

#### Hostname Mismatch

Testing certificate hostname validation.

```javascript
async function testHostnameMismatch() {
  try {
    await fetch('https://wrong.host.badssl.com/');
    console.error('Expected hostname mismatch error');
  } catch (error) {
    console.log('✓ Hostname mismatch detected:', error.message);
  }
}
```

#### Mixed Content

Testing HTTPS pages loading HTTP resources.

```javascript
async function testMixedContent() {
  // If page is served over HTTPS
  if (window.location.protocol === 'https:') {
    try {
      await fetch('http://example.com/api'); // HTTP on HTTPS page
      console.error('Expected mixed content error');
    } catch (error) {
      console.log('✓ Mixed content blocked:', error.message);
    }
  }
}
```

### Content Encoding Errors

#### Unsupported Encoding

Testing responses with unsupported content encodings.

```javascript
async function testUnsupportedEncoding() {
  const response = new Response('data', {
    headers: {
      'Content-Encoding': 'unsupported-algorithm'
    }
  });
  
  try {
    await response.text();
    console.error('Expected encoding error');
  } catch (error) {
    console.log('✓ Unsupported encoding handled:', error.message);
  }
}
```

#### Corrupted Gzip

Testing corrupted compressed responses.

```javascript
async function testCorruptedGzip() {
  // Create corrupted gzip data
  const corruptedData = new Uint8Array([0x1f, 0x8b, 0x08, 0x00, 0xff]);
  
  const response = new Response(corruptedData, {
    headers: {
      'Content-Encoding': 'gzip'
    }
  });
  
  try {
    await response.text();
    console.error('Expected decompression error');
  } catch (error) {
    console.log('✓ Corrupted gzip detected:', error.message);
  }
}
```

### Comprehensive Error Test Suite

#### Complete Test Runner

Combining all error scenarios into a comprehensive test suite.

```javascript
class FetchErrorTestSuite {
  constructor() {
    this.results = {
      passed: 0,
      failed: 0,
      errors: []
    };
  }
  
  async runTest(name, testFn) {
    try {
      await testFn();
      this.results.passed++;
      console.log(`✓ ${name} passed`);
    } catch (error) {
      this.results.failed++;
      this.results.errors.push({ name, error: error.message });
      console.error(`✗ ${name} failed:`, error.message);
    }
  }
  
  async runAll() {
    console.log('Running comprehensive error test suite...\n');
    
    // Network errors
    await this.runTest('Connection Refused', testConnectionRefused);
    await this.runTest('DNS Failure', testDNSFailure);
    await this.runTest('Network Timeout', testNetworkTimeout);
    
    // HTTP status errors
    await this.runTest('4xx Errors', test4xxErrors);
    await this.runTest('5xx Errors', test5xxErrors);
    
    // Parsing errors
    await this.runTest('Invalid JSON', testInvalidJSON);
    await this.runTest('Content-Type Mismatch', testContentTypeMismatch);
    
    // CORS errors
    await this.runTest('Missing CORS Headers', testMissingCORSHeaders);
    await this.runTest('Preflight Failure', testPreflightFailure);
    
    // Timeout/Abort
    await this.runTest('Request Cancellation', testRequestCancellation);
    await this.runTest('Multiple Cancellations', testMultipleCancellations);
    
    // Auth errors
    await this.runTest('Missing Auth', testMissingAuth);
    await this.runTest('Expired Token', testExpiredToken);
    
    // Rate limiting
    await this.runTest('Rate Limiting', testRateLimiting);
    await this.runTest('Exponential Backoff', testExponentialBackoff);
    
    // Redirects
    await this.runTest('Redirect Loop', testRedirectLoop);
    await this.runTest('Manual Redirect', testManualRedirect);
    
    // SSL/TLS
    await this.runTest('Self-Signed Cert', testSelfSignedCert);
    await this.runTest
```

---

## Network Condition Simulation and Fetch API

### Browser DevTools Network Throttling

#### Chrome DevTools

Chrome provides built-in network throttling in the Network panel.

**Preset Profiles:**

- Fast 3G: 1.6 Mbps down, 750 Kbps up, 562.5 ms RTT
- Slow 3G: 400 Kbps down, 400 Kbps up, 2000 ms RTT
- Offline: Complete network disconnection

**Custom Throttling:**

```
Download: Custom Kbps
Upload: Custom Kbps
Latency: Custom ms
```

Throttling affects all network requests including fetch, XHR, WebSocket, and resource loading.

**Programmatic Detection:** [Inference] DevTools throttling cannot be detected programmatically. The browser reports throttled speeds as actual connection speeds.

#### Firefox DevTools

Firefox offers similar throttling in the Network Monitor.

**Preset Profiles:**

- GPRS: 50 Kbps, 500 ms latency
- Regular 2G: 250 Kbps, 300 ms latency
- Good 2G: 450 Kbps, 150 ms latency
- Regular 3G: 750 Kbps, 100 ms latency
- Good 3G: 1.5 Mbps, 40 ms latency
- Regular 4G: 4 Mbps, 20 ms latency
- DSL: 2 Mbps, 5 ms latency
- Wi-Fi: 30 Mbps, 2 ms latency

#### Safari/WebKit

Safari provides throttling through the Network Link Conditioner preference pane (macOS).

Profiles include:

- 3G
- DSL
- Edge
- High Latency DNS
- LTE
- Wi-Fi

### Network Information API

The Network Information API provides information about the connection, but does not simulate conditions.

```javascript
if ('connection' in navigator) {
  const connection = navigator.connection || 
                     navigator.mozConnection || 
                     navigator.webkitConnection;
  
  console.log('Effective Type:', connection.effectiveType); // '4g', '3g', '2g', 'slow-2g'
  console.log('Downlink:', connection.downlink, 'Mbps');
  console.log('RTT:', connection.rtt, 'ms');
  console.log('Save Data:', connection.saveData);
}
```

**Monitoring Changes:**

```javascript
connection.addEventListener('change', () => {
  console.log('Connection changed to:', connection.effectiveType);
  // Adapt fetch behavior based on connection quality
});
```

**Adaptive Fetch Strategy:**

```javascript
function adaptiveFetch(url, options = {}) {
  const connection = navigator.connection;
  
  if (connection) {
    if (connection.saveData) {
      // User has data saver enabled
      options.priority = 'low';
    }
    
    if (connection.effectiveType === 'slow-2g' || 
        connection.effectiveType === '2g') {
      // Reduce quality or quantity of data
      url += '?quality=low';
    }
  }
  
  return fetch(url, options);
}
```

[Unverified] Browser support for the Network Information API varies. Chrome and Edge support it fully, while Firefox and Safari have limited or no support.

### Manual Simulation Techniques

#### Delay Wrapper Function

Create a wrapper that adds artificial delays:

```javascript
function delayedFetch(url, options = {}, delayMs = 1000) {
  return new Promise((resolve, reject) => {
    setTimeout(() => {
      fetch(url, options)
        .then(resolve)
        .catch(reject);
    }, delayMs);
  });
}

// Simulate 2-second network delay
delayedFetch('/api/data', {}, 2000)
  .then(response => response.json())
  .then(data => console.log(data));
```

#### Random Latency Simulation

Simulate variable latency:

```javascript
function fetchWithRandomLatency(url, options = {}, minMs = 100, maxMs = 3000) {
  const delay = Math.random() * (maxMs - minMs) + minMs;
  
  return new Promise((resolve, reject) => {
    setTimeout(() => {
      fetch(url, options)
        .then(resolve)
        .catch(reject);
    }, delay);
  });
}
```

#### Bandwidth Throttling Simulation

Simulate slow downloads by reading response in chunks:

```javascript
async function throttledFetch(url, bytesPerSecond = 50000) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const contentLength = +response.headers.get('Content-Length');
  
  let receivedBytes = 0;
  const chunks = [];
  const startTime = Date.now();
  
  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    receivedBytes += value.length;
    
    // Calculate how long we should have taken
    const expectedTime = (receivedBytes / bytesPerSecond) * 1000;
    const actualTime = Date.now() - startTime;
    const delay = expectedTime - actualTime;
    
    if (delay > 0) {
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  const blob = new Blob(chunks);
  return new Response(blob, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}

// Throttle to 50KB/s
throttledFetch('/large-file.zip', 50000)
  .then(response => response.blob())
  .then(blob => console.log('Downloaded:', blob.size, 'bytes'));
```

#### Packet Loss Simulation

Simulate unreliable connections with random failures:

```javascript
function unreliableFetch(url, options = {}, failureRate = 0.3) {
  if (Math.random() < failureRate) {
    return Promise.reject(new TypeError('Network request failed'));
  }
  
  return fetch(url, options);
}

// 30% chance of failure
unreliableFetch('/api/data', {}, 0.3)
  .then(response => response.json())
  .catch(error => console.error('Request failed:', error));
```

#### Progressive Degradation

Simulate progressive network degradation:

```javascript
class NetworkSimulator {
  constructor() {
    this.latency = 0;
    this.bandwidth = Infinity;
    this.failureRate = 0;
  }
  
  setConditions(latency, bandwidth, failureRate = 0) {
    this.latency = latency;
    this.bandwidth = bandwidth;
    this.failureRate = failureRate;
  }
  
  async fetch(url, options = {}) {
    // Simulate packet loss
    if (Math.random() < this.failureRate) {
      throw new TypeError('Simulated network failure');
    }
    
    // Simulate initial latency
    await new Promise(resolve => setTimeout(resolve, this.latency));
    
    const response = await fetch(url, options);
    
    // Simulate bandwidth throttling if reading body
    if (this.bandwidth !== Infinity) {
      return this.throttleResponse(response);
    }
    
    return response;
  }
  
  async throttleResponse(response) {
    const reader = response.body.getReader();
    const chunks = [];
    const startTime = Date.now();
    let receivedBytes = 0;
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      chunks.push(value);
      receivedBytes += value.length;
      
      const expectedTime = (receivedBytes / this.bandwidth) * 1000;
      const actualTime = Date.now() - startTime;
      const delay = expectedTime - actualTime;
      
      if (delay > 0) {
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
    
    const blob = new Blob(chunks);
    return new Response(blob, {
      status: response.status,
      statusText: response.statusText,
      headers: response.headers
    });
  }
}

// Usage
const simulator = new NetworkSimulator();
simulator.setConditions(500, 50000, 0.1); // 500ms latency, 50KB/s, 10% failure

simulator.fetch('/api/data')
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => console.error(error));
```

### Service Worker Simulation

Service Workers provide powerful network interception for realistic simulation.

```javascript
// sw.js
self.addEventListener('fetch', event => {
  const url = new URL(event.request.url);
  
  // Only simulate for API requests
  if (url.pathname.startsWith('/api/')) {
    event.respondWith(simulateNetworkConditions(event.request));
  }
});

async function simulateNetworkConditions(request) {
  const conditions = {
    latency: 1000,      // 1 second delay
    bandwidth: 100000,  // 100KB/s
    failureRate: 0.05   // 5% failure rate
  };
  
  // Simulate packet loss
  if (Math.random() < conditions.failureRate) {
    return new Response(null, {
      status: 0,
      statusText: 'Network simulation: packet loss'
    });
  }
  
  // Simulate initial latency
  await new Promise(resolve => setTimeout(resolve, conditions.latency));
  
  // Fetch actual response
  const response = await fetch(request);
  
  // Simulate bandwidth throttling
  return throttleResponse(response, conditions.bandwidth);
}

async function throttleResponse(response, bytesPerSecond) {
  const reader = response.body.getReader();
  const stream = new ReadableStream({
    async start(controller) {
      const startTime = Date.now();
      let totalBytes = 0;
      
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          controller.close();
          break;
        }
        
        totalBytes += value.length;
        const expectedTime = (totalBytes / bytesPerSecond) * 1000;
        const actualTime = Date.now() - startTime;
        const delay = expectedTime - actualTime;
        
        if (delay > 0) {
          await new Promise(resolve => setTimeout(resolve, delay));
        }
        
        controller.enqueue(value);
      }
    }
  });
  
  return new Response(stream, {
    status: response.status,
    statusText: response.statusText,
    headers: response.headers
  });
}
```

**Registering the Service Worker:**

```javascript
if ('serviceWorker' in navigator) {
  navigator.serviceWorker.register('/sw.js')
    .then(registration => {
      console.log('Network simulator registered');
    });
}
```

### Timeout Simulation

#### AbortController with Timeout

```javascript
function fetchWithTimeout(url, options = {}, timeoutMs = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
  
  return fetch(url, {
    ...options,
    signal: controller.signal
  }).finally(() => clearTimeout(timeoutId));
}

// Abort after 3 seconds
fetchWithTimeout('/api/slow-endpoint', {}, 3000)
  .then(response => response.json())
  .catch(error => {
    if (error.name === 'AbortError') {
      console.error('Request timed out');
    }
  });
```

#### Configurable Timeout Simulator

```javascript
class TimeoutSimulator {
  constructor(defaultTimeout = 10000) {
    this.defaultTimeout = defaultTimeout;
  }
  
  fetch(url, options = {}, timeout = this.defaultTimeout) {
    const controller = new AbortController();
    
    const timeoutId = setTimeout(() => {
      controller.abort();
    }, timeout);
    
    return fetch(url, {
      ...options,
      signal: controller.signal
    }).finally(() => {
      clearTimeout(timeoutId);
    });
  }
}

const simulator = new TimeoutSimulator(5000);

// Fast timeout for testing
simulator.fetch('/api/data', {}, 1000)
  .catch(error => console.error('Timed out'));
```

### Offline Simulation

#### Manual Offline Mode

```javascript
class OfflineSimulator {
  constructor() {
    this.isOffline = false;
  }
  
  setOffline(offline) {
    this.isOffline = offline;
  }
  
  fetch(url, options = {}) {
    if (this.isOffline) {
      return Promise.reject(new TypeError('Failed to fetch'));
    }
    
    return fetch(url, options);
  }
}

const simulator = new OfflineSimulator();

// Simulate going offline
simulator.setOffline(true);

simulator.fetch('/api/data')
  .catch(error => console.error('Network is offline'));

// Back online
simulator.setOffline(false);
```

#### Detecting Online/Offline

```javascript
// Check current status
console.log('Online:', navigator.onLine);

// Listen for changes
window.addEventListener('online', () => {
  console.log('Connection restored');
  // Retry failed requests
});

window.addEventListener('offline', () => {
  console.log('Connection lost');
  // Queue requests for later
});

// Fetch with offline handling
async function resilientFetch(url, options = {}) {
  if (!navigator.onLine) {
    throw new Error('Network is offline');
  }
  
  try {
    return await fetch(url, options);
  } catch (error) {
    if (!navigator.onLine) {
      throw new Error('Lost connection during request');
    }
    throw error;
  }
}
```

### Request Queueing for Offline

```javascript
class OfflineQueue {
  constructor() {
    this.queue = [];
    this.isOnline = navigator.onLine;
    
    window.addEventListener('online', () => {
      this.isOnline = true;
      this.processQueue();
    });
    
    window.addEventListener('offline', () => {
      this.isOnline = false;
    });
  }
  
  async fetch(url, options = {}) {
    if (this.isOnline) {
      try {
        return await fetch(url, options);
      } catch (error) {
        // Queue if failed
        return this.enqueue(url, options);
      }
    } else {
      return this.enqueue(url, options);
    }
  }
  
  enqueue(url, options) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
    });
  }
  
  async processQueue() {
    while (this.queue.length > 0 && this.isOnline) {
      const { url, options, resolve, reject } = this.queue.shift();
      
      try {
        const response = await fetch(url, options);
        resolve(response);
      } catch (error) {
        reject(error);
        // Re-queue if failed
        this.queue.unshift({ url, options, resolve, reject });
        break;
      }
    }
  }
}

const queue = new OfflineQueue();

// Will queue if offline, execute when online
queue.fetch('/api/data')
  .then(response => response.json())
  .then(data => console.log(data));
```

### Proxy-Based Simulation

#### Local Proxy Server

Use tools like Toxiproxy or custom proxy servers to simulate network conditions at the network layer.

**Toxiproxy Example (external tool, not JavaScript):**

```bash
# Add latency
toxiproxy-cli toxic add -t latency -a latency=1000 myapi

# Add bandwidth limit
toxiproxy-cli toxic add -t bandwidth -a rate=100 myapi

# Simulate slow close
toxiproxy-cli toxic add -t slow_close -a delay=5000 myapi
```

[Inference] Proxy-based simulation provides more realistic results than client-side simulation because it affects the actual network stack.

#### Custom Node.js Proxy

```javascript
// proxy-server.js (Node.js)
const http = require('http');
const httpProxy = require('http-proxy');

const proxy = httpProxy.createProxyServer({});

const config = {
  latency: 500,
  bandwidth: 50000, // bytes per second
  failureRate: 0.1
};

const server = http.createServer((req, res) => {
  // Simulate packet loss
  if (Math.random() < config.failureRate) {
    res.writeHead(503);
    res.end('Simulated network failure');
    return;
  }
  
  // Add latency
  setTimeout(() => {
    proxy.web(req, res, {
      target: 'http://localhost:3000'
    });
  }, config.latency);
});

// Throttle response bandwidth
proxy.on('proxyRes', (proxyRes, req, res) => {
  const originalWrite = res.write;
  const originalEnd = res.end;
  let sentBytes = 0;
  const startTime = Date.now();
  
  res.write = function(chunk) {
    sentBytes += chunk.length;
    const expectedTime = (sentBytes / config.bandwidth) * 1000;
    const actualTime = Date.now() - startTime;
    const delay = expectedTime - actualTime;
    
    if (delay > 0) {
      setTimeout(() => {
        originalWrite.call(res, chunk);
      }, delay);
    } else {
      originalWrite.call(res, chunk);
    }
  };
});

server.listen(8080);
```

### Testing Strategies

#### Automated Testing with Simulation

```javascript
describe('API requests under poor network', () => {
  let simulator;
  
  beforeEach(() => {
    simulator = new NetworkSimulator();
  });
  
  it('should handle slow connections', async () => {
    simulator.setConditions(2000, 10000); // 2s latency, 10KB/s
    
    const start = Date.now();
    const response = await simulator.fetch('/api/data');
    const duration = Date.now() - start;
    
    expect(duration).toBeGreaterThan(2000);
    expect(response.ok).toBe(true);
  });
  
  it('should retry on network failure', async () => {
    simulator.setConditions(0, Infinity, 0.5); // 50% failure
    
    let attempts = 0;
    let success = false;
    
    while (attempts < 5 && !success) {
      try {
        await simulator.fetch('/api/data');
        success = true;
      } catch (error) {
        attempts++;
      }
    }
    
    expect(success || attempts === 5).toBe(true);
  });
});
```

#### Load Testing with Varied Conditions

```javascript
async function loadTest(url, concurrency = 10, conditions = {}) {
  const simulator = new NetworkSimulator();
  simulator.setConditions(
    conditions.latency || 0,
    conditions.bandwidth || Infinity,
    conditions.failureRate || 0
  );
  
  const requests = Array(concurrency).fill(null).map((_, i) => 
    simulator.fetch(url)
      .then(() => ({ success: true, index: i }))
      .catch(error => ({ success: false, index: i, error }))
  );
  
  const results = await Promise.all(requests);
  
  const successful = results.filter(r => r.success).length;
  const failed = results.filter(r => !r.success).length;
  
  return {
    total: concurrency,
    successful,
    failed,
    successRate: successful / concurrency
  };
}

// Test with 3G conditions
loadTest('/api/data', 50, {
  latency: 100,
  bandwidth: 750000,
  failureRate: 0.05
}).then(results => console.log(results));
```

### Progressive Enhancement Patterns

#### Adaptive Resource Loading

```javascript
async function loadImage(url, quality = 'high') {
  const connection = navigator.connection;
  
  if (connection) {
    if (connection.effectiveType === 'slow-2g' || 
        connection.effectiveType === '2g') {
      quality = 'low';
    } else if (connection.effectiveType === '3g') {
      quality = 'medium';
    }
    
    if (connection.saveData) {
      quality = 'low';
    }
  }
  
  const qualityMap = {
    low: '?w=400&q=50',
    medium: '?w=800&q=75',
    high: '?w=1600&q=90'
  };
  
  return fetch(url + qualityMap[quality]);
}
```

#### Prefetching with Network Awareness

```javascript
async function intelligentPrefetch(urls) {
  const connection = navigator.connection;
  
  // Don't prefetch on slow or metered connections
  if (connection) {
    if (connection.saveData || 
        connection.effectiveType === 'slow-2g' || 
        connection.effectiveType === '2g') {
      console.log('Skipping prefetch due to network conditions');
      return;
    }
  }
  
  // Prefetch in batches
  const batchSize = connection?.effectiveType === '4g' ? 5 : 2;
  
  for (let i = 0; i < urls.length; i += batchSize) {
    const batch = urls.slice(i, i + batchSize);
    await Promise.all(
      batch.map(url => 
        fetch(url, { priority: 'low' })
          .catch(error => console.warn('Prefetch failed:', url))
      )
    );
  }
}
```

### Monitoring and Metrics

#### Performance Monitoring

```javascript
class NetworkMonitor {
  constructor() {
    this.metrics = [];
  }
  
  async fetch(url, options = {}) {
    const start = performance.now();
    const startBytes = this.getTransferredBytes();
    
    try {
      const response = await fetch(url, options);
      const duration = performance.now() - start;
      const bytes = this.getTransferredBytes() - startBytes;
      
      this.metrics.push({
        url,
        duration,
        bytes,
        speed: bytes / (duration / 1000), // bytes per second
        status: response.status,
        success: true,
        timestamp: Date.now()
      });
      
      return response;
    } catch (error) {
      const duration = performance.now() - start;
      
      this.metrics.push({
        url,
        duration,
        success: false,
        error: error.message,
        timestamp: Date.now()
      });
      
      throw error;
    }
  }
  
  getTransferredBytes() {
    // [Inference] This is a simplified approximation
    if (performance.getEntriesByType) {
      const entries = performance.getEntriesByType('resource');
      return entries.reduce((total, entry) => 
        total + (entry.transferSize || 0), 0
      );
    }
    return 0;
  }
  
  getAverageSpeed() {
    const successfulRequests = this.metrics.filter(m => m.success && m.speed);
    if (successfulRequests.length === 0) return 0;
    
    const totalSpeed = successfulRequests.reduce((sum, m) => sum + m.speed, 0);
    return totalSpeed / successfulRequests.length;
  }
  
  getFailureRate() {
    if (this.metrics.length === 0) return 0;
    const failures = this.metrics.filter(m => !m.success).length;
    return failures / this.metrics.length;
  }
}

const monitor = new NetworkMonitor();

monitor.fetch('/api/data')
  .then(response => response.json())
  .then(() => {
    console.log('Average speed:', monitor.getAverageSpeed(), 'bytes/s');
    console.log('Failure rate:', monitor.getFailureRate());
  });
```

### Browser-Specific Considerations

#### Chrome Network Conditions API

[Unverified] Chrome exposes network condition emulation through DevTools Protocol, which can be controlled programmatically via Puppeteer:

```javascript
// Using Puppeteer
const puppeteer = require('puppeteer');

const browser = await puppeteer.launch();
const page = await browser.newPage();

// Emulate slow 3G
const client = await page.target().createCDPSession();
await client.send('Network.emulateNetworkConditions', {
  offline: false,
  downloadThroughput: 400 * 1024 / 8, // 400 Kbps in bytes/s
  uploadThroughput: 400 * 1024 / 8,
  latency: 2000
});

await page.goto('https://example.com');
```

[Inference] This approach is primarily useful for automated testing rather than runtime simulation in production applications.

---

## Test Coverage Strategies

### Fundamentals of Test Coverage

Test coverage measures the degree to which source code is executed during testing. It provides quantitative metrics indicating which parts of the codebase have been tested and, equally importantly, which parts remain untested. Coverage serves as both a quality indicator and a tool for identifying gaps in test suites.

Coverage analysis operates by instrumenting code to track execution paths during test runs. The instrumentation records which statements, branches, functions, or conditions execute, then generates reports showing tested versus untested code. Modern coverage tools integrate seamlessly with testing frameworks, build pipelines, and continuous integration systems.

**Purpose and Limitations**

Coverage metrics serve several purposes:

- Identifying untested code paths requiring attention
- Preventing regression by ensuring critical paths remain tested
- Guiding test development toward neglected areas
- Providing objective quality metrics for teams and stakeholders
- Establishing baseline quality standards for contributions

However, coverage has significant limitations:

- High coverage does not guarantee absence of bugs
- Tests may execute code without meaningful assertions
- Coverage metrics can be gamed through superficial tests
- 100% coverage is often impractical or unnecessary
- Coverage says nothing about test quality or correctness

### Coverage Types and Metrics

#### Statement Coverage

Statement coverage measures the percentage of executable statements executed during testing. It represents the most basic coverage metric, tracking whether each line of code runs at least once.

**Calculation**:

```
Statement Coverage = (Executed Statements / Total Statements) × 100%
```

**Example**:

```javascript
function calculateDiscount(price, isPremium) {
  let discount = 0;                    // Statement 1
  
  if (isPremium) {                     // Statement 2
    discount = price * 0.2;            // Statement 3
  } else {                             // Statement 4
    discount = price * 0.1;            // Statement 5
  }
  
  return price - discount;             // Statement 6
}

// Test covering only premium path
test('premium discount', () => {
  expect(calculateDiscount(100, true)).toBe(80);
});

// Coverage: 5/6 statements = 83.3%
// Statement 5 not executed
```

**Achieving Full Statement Coverage**:

```javascript
test('premium discount', () => {
  expect(calculateDiscount(100, true)).toBe(80);
});

test('standard discount', () => {
  expect(calculateDiscount(100, false)).toBe(90);
});

// Coverage: 6/6 statements = 100%
```

**Strengths**:

- Simple to understand and implement
- Provides baseline coverage metric
- Quickly identifies completely untested code
- Low computational overhead

**Weaknesses**:

- Doesn't verify all logical branches
- Misses decision outcomes
- Can show high coverage with inadequate testing
- Doesn't detect missing error handling

#### Branch Coverage

Branch coverage measures whether each possible branch from decision points executes. Every conditional statement creates at least two branches (true and false), and branch coverage ensures both execute during testing.

**Example**:

```javascript
function processOrder(order, inventory) {
  if (order.quantity <= inventory.available) {    // Branch point 1
    inventory.available -= order.quantity;
    return { success: true, message: 'Order processed' };
  }
  
  if (inventory.restockDate) {                    // Branch point 2
    return { success: false, message: `Available ${inventory.restockDate}` };
  }
  
  return { success: false, message: 'Out of stock' };
}

// Insufficient tests - only covers happy path
test('processes valid order', () => {
  const result = processOrder(
    { quantity: 5 },
    { available: 10 }
  );
  expect(result.success).toBe(true);
});

// Branch coverage: 1/4 branches = 25%
// Branches covered: quantity <= available (true)
// Branches not covered: 
//   - quantity > available (false)
//   - restockDate exists (true)
//   - restockDate doesn't exist (false)
```

**Comprehensive Branch Coverage**:

```javascript
describe('processOrder', () => {
  test('processes valid order', () => {
    const result = processOrder(
      { quantity: 5 },
      { available: 10 }
    );
    expect(result.success).toBe(true);
  });
  
  test('rejects insufficient inventory with restock date', () => {
    const result = processOrder(
      { quantity: 15 },
      { available: 10, restockDate: '2025-01-15' }
    );
    expect(result.success).toBe(false);
    expect(result.message).toContain('2025-01-15');
  });
  
  test('rejects insufficient inventory without restock date', () => {
    const result = processOrder(
      { quantity: 15 },
      { available: 10 }
    );
    expect(result.success).toBe(false);
    expect(result.message).toBe('Out of stock');
  });
});

// Branch coverage: 4/4 branches = 100%
```

**Complex Branch Scenarios**:

```javascript
function validateUser(user) {
  // Multiple conditions create multiple branches
  if (user && user.age >= 18 && user.verified) {
    return { valid: true };
  }
  return { valid: false };
}

// Branch possibilities:
// 1. user is falsy
// 2. user exists, age < 18
// 3. user exists, age >= 18, not verified
// 4. user exists, age >= 18, verified

// Full branch coverage requires all scenarios
describe('validateUser', () => {
  test('null user', () => {
    expect(validateUser(null).valid).toBe(false);
  });
  
  test('underage user', () => {
    expect(validateUser({ age: 16, verified: true }).valid).toBe(false);
  });
  
  test('unverified adult', () => {
    expect(validateUser({ age: 25, verified: false }).valid).toBe(false);
  });
  
  test('verified adult', () => {
    expect(validateUser({ age: 25, verified: true }).valid).toBe(true);
  });
});
```

#### Function Coverage

Function coverage tracks whether each function in the codebase executes at least once during testing. It provides a high-level view of which functions remain completely untested.

**Example**:

```javascript
// utils.js
export function add(a, b) {
  return a + b;
}

export function subtract(a, b) {
  return a - b;
}

export function multiply(a, b) {
  return a * b;
}

export function divide(a, b) {
  if (b === 0) throw new Error('Division by zero');
  return a / b;
}

// Partial test coverage
describe('Math utilities', () => {
  test('addition', () => {
    expect(add(2, 3)).toBe(5);
  });
  
  test('multiplication', () => {
    expect(multiply(4, 5)).toBe(20);
  });
});

// Function coverage: 2/4 = 50%
// Tested: add, multiply
// Untested: subtract, divide
```

**Function Coverage Patterns**:

```javascript
class UserService {
  constructor(database) {
    this.db = database;
  }
  
  async createUser(userData) {          // Function 1
    return await this.db.insert(userData);
  }
  
  async getUser(id) {                   // Function 2
    return await this.db.findById(id);
  }
  
  async updateUser(id, updates) {       // Function 3
    return await this.db.update(id, updates);
  }
  
  async deleteUser(id) {                // Function 4
    return await this.db.delete(id);
  }
  
  async listUsers(filters) {            // Function 5
    return await this.db.find(filters);
  }
}

// Minimal function coverage test suite
describe('UserService', () => {
  let service;
  let mockDb;
  
  beforeEach(() => {
    mockDb = {
      insert: jest.fn(),
      findById: jest.fn(),
      update: jest.fn(),
      delete: jest.fn(),
      find: jest.fn()
    };
    service = new UserService(mockDb);
  });
  
  test('createUser calls database', async () => {
    await service.createUser({ name: 'John' });
    expect(mockDb.insert).toHaveBeenCalled();
  });
  
  test('getUser calls database', async () => {
    await service.getUser(1);
    expect(mockDb.findById).toHaveBeenCalled();
  });
  
  test('updateUser calls database', async () => {
    await service.updateUser(1, { name: 'Jane' });
    expect(mockDb.update).toHaveBeenCalled();
  });
  
  test('deleteUser calls database', async () => {
    await service.deleteUser(1);
    expect(mockDb.delete).toHaveBeenCalled();
  });
  
  test('listUsers calls database', async () => {
    await service.listUsers({ active: true });
    expect(mockDb.find).toHaveBeenCalled();
  });
});

// Function coverage: 5/5 = 100%
// Note: High function coverage but minimal assertion quality
```

#### Condition Coverage

Condition coverage examines individual boolean sub-expressions within decision statements. It ensures each boolean condition evaluates to both true and false independently.

**Example**:

```javascript
function canPurchase(user, product) {
  // Compound condition with two sub-expressions
  if (user.balance >= product.price && user.verified) {
    return true;
  }
  return false;
}

// Branch coverage achieved but not condition coverage
test('verified user with sufficient balance', () => {
  expect(canPurchase(
    { balance: 100, verified: true },
    { price: 50 }
  )).toBe(true);
});

// This test achieves:
// - Branch coverage: true branch covered
// - Condition coverage: incomplete
//   - balance >= price: true (covered), false (not covered)
//   - verified: true (covered), false (not covered)
```

**Full Condition Coverage**:

```javascript
describe('canPurchase', () => {
  // Test 1: Both conditions true
  test('verified user with sufficient balance', () => {
    expect(canPurchase(
      { balance: 100, verified: true },
      { price: 50 }
    )).toBe(true);
  });
  
  // Test 2: First condition false, second true
  test('verified user with insufficient balance', () => {
    expect(canPurchase(
      { balance: 30, verified: true },
      { price: 50 }
    )).toBe(false);
  });
  
  // Test 3: First condition true, second false
  test('unverified user with sufficient balance', () => {
    expect(canPurchase(
      { balance: 100, verified: false },
      { price: 50 }
    )).toBe(false);
  });
  
  // Test 4: Both conditions false
  test('unverified user with insufficient balance', () => {
    expect(canPurchase(
      { balance: 30, verified: false },
      { price: 50 }
    )).toBe(false);
  });
});

// Full condition coverage achieved
// Each sub-expression evaluated to both true and false
```

**Modified Condition/Decision Coverage (MC/DC)**:

MC/DC is a stricter criterion requiring that each condition independently affects the decision outcome:

```javascript
function isEligible(age, citizenship, criminalRecord) {
  return age >= 18 && citizenship === 'US' && !criminalRecord;
}

// MC/DC test cases
describe('isEligible MC/DC', () => {
  // Base case: all conditions true
  test('eligible candidate', () => {
    expect(isEligible(25, 'US', false)).toBe(true);
  });
  
  // Toggle age while keeping others constant
  test('age affects outcome', () => {
    expect(isEligible(16, 'US', false)).toBe(false);
  });
  
  // Toggle citizenship while keeping others constant
  test('citizenship affects outcome', () => {
    expect(isEligible(25, 'CA', false)).toBe(false);
  });
  
  // Toggle criminal record while keeping others constant
  test('criminal record affects outcome', () => {
    expect(isEligible(25, 'US', true)).toBe(false);
  });
});

// Each condition independently shown to affect the outcome
```

#### Path Coverage

Path coverage ensures every possible execution path through the code executes at least once. This is the most comprehensive coverage metric but also the most difficult to achieve, as the number of paths grows exponentially with code complexity.

**Example**:

```javascript
function processPayment(amount, paymentMethod, loyaltyPoints) {
  let finalAmount = amount;
  
  // Path 1-2: Loyalty points discount
  if (loyaltyPoints > 100) {
    finalAmount = amount * 0.9;  // 10% discount
  }
  
  // Path 3-6: Payment method processing
  if (paymentMethod === 'credit') {
    finalAmount += 2.50;  // Processing fee
  } else if (paymentMethod === 'debit') {
    finalAmount += 1.00;  // Lower fee
  }
  
  return finalAmount;
}

// Possible paths:
// 1. loyaltyPoints <= 100, paymentMethod === 'credit'
// 2. loyaltyPoints <= 100, paymentMethod === 'debit'
// 3. loyaltyPoints <= 100, paymentMethod === other
// 4. loyaltyPoints > 100, paymentMethod === 'credit'
// 5. loyaltyPoints > 100, paymentMethod === 'debit'
// 6. loyaltyPoints > 100, paymentMethod === other

describe('processPayment paths', () => {
  test('path 1: no discount, credit card', () => {
    expect(processPayment(100, 'credit', 50)).toBe(102.50);
  });
  
  test('path 2: no discount, debit card', () => {
    expect(processPayment(100, 'debit', 50)).toBe(101.00);
  });
  
  test('path 3: no discount, cash', () => {
    expect(processPayment(100, 'cash', 50)).toBe(100);
  });
  
  test('path 4: with discount, credit card', () => {
    expect(processPayment(100, 'credit', 150)).toBe(92.50);
  });
  
  test('path 5: with discount, debit card', () => {
    expect(processPayment(100, 'debit', 150)).toBe(91.00);
  });
  
  test('path 6: with discount, cash', () => {
    expect(processPayment(100, 'cash', 150)).toBe(90);
  });
});

// Full path coverage: 6/6 paths
```

**Cyclomatic Complexity and Path Explosion**:

```javascript
function complexRouting(a, b, c, d) {
  let result = 0;
  
  if (a > 0) result += 1;      // 2 branches
  if (b > 0) result += 2;      // 2 branches
  if (c > 0) result += 4;      // 2 branches
  if (d > 0) result += 8;      // 2 branches
  
  return result;
}

// Total possible paths: 2^4 = 16 paths
// Path coverage requires 16 distinct test cases

// This demonstrates why 100% path coverage is often impractical
// for complex functions with high cyclomatic complexity
```

#### Line Coverage

Line coverage measures the percentage of code lines executed during testing. It's similar to statement coverage but counts physical lines rather than logical statements.

**Distinction from Statement Coverage**:

```javascript
// Multiple statements per line
function compact(x, y, z) { return x || y || z; }

// Single statement across multiple lines
function verbose(x, y, z) {
  return x ||
         y ||
         z;
}

// Line coverage vs statement coverage may differ
```

### Coverage Tools and Configuration

#### JavaScript/TypeScript Coverage Tools

**Istanbul/NYC**

Istanbul is the most widely-used JavaScript coverage tool, with NYC as its command-line interface:

```bash
# Installation
npm install --save-dev nyc

# Basic usage
nyc npm test

# With specific reporters
nyc --reporter=html --reporter=text npm test

# Configuration in package.json
```

```json
{
  "nyc": {
    "reporter": ["text", "html", "lcov"],
    "include": ["src/**/*.js"],
    "exclude": [
      "**/*.test.js",
      "**/*.spec.js",
      "**/node_modules/**",
      "**/test/**"
    ],
    "all": true,
    "check-coverage": true,
    "lines": 80,
    "functions": 80,
    "branches": 75,
    "statements": 80
  }
}
```

**Jest Built-in Coverage**

Jest includes integrated coverage reporting:

```javascript
// jest.config.js
module.exports = {
  collectCoverage: true,
  collectCoverageFrom: [
    'src/**/*.{js,jsx,ts,tsx}',
    '!src/**/*.test.{js,jsx,ts,tsx}',
    '!src/**/*.spec.{js,jsx,ts,tsx}',
    '!src/index.{js,ts}',
    '!**/node_modules/**',
    '!**/vendor/**'
  ],
  coverageDirectory: 'coverage',
  coverageReporters: ['text', 'html', 'lcov', 'json'],
  coverageThresholds: {
    global: {
      branches: 75,
      functions: 80,
      lines: 80,
      statements: 80
    },
    './src/core/': {
      branches: 90,
      functions: 95,
      lines: 95,
      statements: 95
    }
  }
};
```

```bash
# Run tests with coverage
npm test -- --coverage

# Coverage for specific files
npm test -- --coverage --collectCoverageFrom="src/utils/**/*.js"

# Watch mode with coverage
npm test -- --coverage --watchAll
```

**Coverage Report Formats**:

```javascript
// jest.config.js
module.exports = {
  coverageReporters: [
    'text',           // Console output
    'text-summary',   // Brief console summary
    'html',           // Interactive HTML report
    'lcov',           // LCOV format for CI tools
    'json',           // JSON format for custom processing
    'json-summary',   // Summary in JSON
    'cobertura',      // Cobertura XML (for Jenkins, etc.)
    'clover'          // Clover XML format
  ]
};
```

**Vitest Coverage**

```javascript
// vitest.config.js
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    coverage: {
      provider: 'v8', // or 'istanbul'
      reporter: ['text', 'json', 'html'],
      include: ['src/**/*.{js,ts}'],
      exclude: [
        'node_modules/',
        'src/**/*.test.{js,ts}',
        'src/**/*.spec.{js,ts}'
      ],
      thresholds: {
        lines: 80,
        functions: 80,
        branches: 75,
        statements: 80
      },
      all: true
    }
  }
});
```

#### Python Coverage Tools

**Coverage.py**

```bash
# Installation
pip install coverage

# Run tests with coverage
coverage run -m pytest

# Generate report
coverage report

# Generate HTML report
coverage html

# Configuration in .coveragerc or pyproject.toml
```

```ini
# .coveragerc
[run]
source = src
omit =
    */tests/*
    */test_*.py
    */__pycache__/*
    */site-packages/*

[report]
precision = 2
show_missing = True
skip_covered = False

exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod

[html]
directory = htmlcov
```

```toml
# pyproject.toml
[tool.coverage.run]
source = ["src"]
omit = ["*/tests/*", "*/test_*.py"]

[tool.coverage.report]
precision = 2
show_missing = true
fail_under = 80

[tool.coverage.html]
directory = "htmlcov"
```

**Pytest-cov Plugin**

```bash
# Installation
pip install pytest-cov

# Run with coverage
pytest --cov=src --cov-report=html --cov-report=term

# With branch coverage
pytest --cov=src --cov-branch --cov-report=term-missing
```

```ini
# pytest.ini or setup.cfg
[tool:pytest]
addopts =
    --cov=src
    --cov-branch
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
```

#### Java Coverage Tools

**JaCoCo**

```xml
<!-- Maven pom.xml -->
<plugin>
    <groupId>org.jacoco</groupId>
    <artifactId>jacoco-maven-plugin</artifactId>
    <version>0.8.11</version>
    <executions>
        <execution>
            <id>prepare-agent</id>
            <goals>
                <goal>prepare-agent</goal>
            </goals>
        </execution>
        <execution>
            <id>report</id>
            <phase>test</phase>
            <goals>
                <goal>report</goal>
            </goals>
        </execution>
        <execution>
            <id>check</id>
            <goals>
                <goal>check</goal>
            </goals>
            <configuration>
                <rules>
                    <rule>
                        <element>PACKAGE</element>
                        <limits>
                            <limit>
                                <counter>LINE</counter>
                                <value>COVEREDRATIO</value>
                                <minimum>0.80</minimum>
                            </limit>
                            <limit>
                                <counter>BRANCH</counter>
                                <value>COVEREDRATIO</value>
                                <minimum>0.75</minimum>
                            </limit>
                        </limits>
                    </rule>
                </rules>
            </configuration>
        </execution>
    </executions>
</plugin>
```

```gradle
// Gradle build.gradle
plugins {
    id 'jacoco'
}

jacoco {
    toolVersion = "0.8.11"
}

jacocoTestReport {
    reports {
        xml.required = true
        html.required = true
        csv.required = false
    }
}

jacocoTestCoverageVerification {
    violationRules {
        rule {
            limit {
                minimum = 0.80
            }
        }
        rule {
            element = 'CLASS'
            limit {
                counter = 'BRANCH'
                value = 'COVEREDRATIO'
                minimum = 0.75
            }
        }
    }
}

test {
    finalizedBy jacocoTestReport
}

check {
    dependsOn jacocoTestCoverageVerification
}
```

### Strategic Coverage Approaches

#### Risk-Based Coverage Prioritization

Not all code requires equal coverage. Risk-based prioritization focuses testing efforts where they provide maximum value:

**High-Priority Areas (90-100% coverage)**:

- Security-critical code (authentication, authorization, cryptography)
- Financial calculations and transactions
- Data persistence and integrity operations
- Public APIs and interfaces
- Core business logic
- Error handling and recovery mechanisms

**Medium-Priority Areas (75-90% coverage)**:

- User input validation
- Data transformations
- Integration points
- Configuration management
- Utility functions
- Common workflows

**Lower-Priority Areas (50-75% coverage)**:

- UI presentation logic (covered by E2E tests)
- Simple getters/setters
- Configuration files
- Generated code
- Deprecated features

**Example Configuration**:

```javascript
// jest.config.js with differentiated thresholds
module.exports = {
  coverageThresholds: {
    // Global minimum
    global: {
      branches: 70,
      functions: 75,
      lines: 75,
      statements: 75
    },
    // Critical authentication module
    './src/auth/': {
      branches: 95,
      functions: 100,
      lines: 95,
      statements: 95
    },
    // Payment processing
    './src/payment/': {
      branches: 90,
      functions: 95,
      lines: 90,
      statements: 90
    },
    // Core business logic
    './src/core/': {
      branches: 85,
      functions: 90,
      lines: 85,
      statements: 85
    },
    // UI components (lower threshold)
    './src/components/': {
      branches: 60,
      functions: 65,
      lines: 65,
      statements: 65
    }
  }
};
```

#### Mutation Testing

Mutation testing evaluates test suite effectiveness by introducing deliberate bugs (mutations) and verifying tests catch them:

**Stryker Mutation Testing**:

```bash
# Installation
npm install --save-dev @stryker-mutator/core @stryker-mutator/jest-runner

# Initialize configuration
npx stryker init

# Run mutation testing
npx stryker run
```

```javascript
// stryker.conf.json
{
  "mutator": "javascript",
  "packageManager": "npm",
  "reporters": ["html", "clear-text", "progress", "dashboard"],
  "testRunner": "jest",
  "coverageAnalysis": "perTest",
  "mutate": [
    "src/**/*.js",
    "!src/**/*.test.js",
    "!src/**/*.spec.js"
  ],
  "thresholds": {
    "high": 80,
    "low": 60,
    "break": 50
  }
}
```

**Example Mutations**:

```javascript
// Original code
function isAdult(age) {
  return age >= 18;
}

// Mutation 1: Change operator
function isAdult(age) {
  return age > 18;  // >= changed to >
}

// Mutation 2: Change constant
function isAdult(age) {
  return age >= 19;  // 18 changed to 19
}

// Mutation 3: Negate condition
function isAdult(age) {
  return age < 18;  // >= changed to 
}

// If tests don't catch these mutations, they're insufficient
```

**Mutation Score Interpretation**:

```javascript
// Strong test suite
test('isAdult boundary cases', () => {
  expect(isAdult(17)).toBe(false);  // Catches boundary mutations
  expect(isAdult(18)).toBe(true);   // Catches constant mutations
  expect(isAdult(19)).toBe(true);   // Catches operator mutations
});

// Mutation Score: 100% (all mutations detected)
```

#### Differential Coverage

Differential coverage focuses on changes rather than absolute coverage, useful for large legacy codebases:

**Git-Based Differential Coverage**:

```javascript
// coverage-diff.js
const { execSync } = require('child_process');
const fs = require('fs');

function getModifiedFiles() {
  const output = execSync('git diff --name-only HEAD~1').toString();
  return output.split('\n').filter(f => f.endsWith('.js'));
}

function getCoverageForFiles(files) {
  const coverageData = JSON.parse(
    fs.readFileSync('./coverage/coverage-summary.json')
  );
  
  const results = {};
  files.forEach(file => {
    const fullPath = `./${file}`;
    if (coverageData[fullPath]) {
      results[file] = coverageData[fullPath];
    }
  });
  
  return results;
}

function checkDifferentialCoverage() {
  const modifiedFiles = getModifiedFiles();
  const coverage = getCoverageForFiles(modifiedFiles);
  
  let passed = true;
  Object.entries(coverage).forEach(([file, metrics]) => {
    console.log(`\n${file}:`);
    console.log(`  Lines: ${metrics.lines.pct}%`);
    console.log(`  Branches: ${metrics.branches.pct}%`);
    
    if (metrics.lines.pct < 80 || metrics.branches.pct < 75) {
      console.log(`  ❌ Below threshold`);
      passed = false;
    } else {
      console.log(`  ✓ Meets threshold`);
    }
  });
  
  if (!passed) {
    process.exit(1);
  }
}

checkDifferentialCoverage();
```

**CI Integration**:

```yaml
# .github/workflows/test.yml
name: Test with Differential Coverage

on: [pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 2
      
      - name: Install dependencies
        run: npm install
      
      - name: Run tests with coverage
        run: npm test -- --coverage
      
      - name: Check differential coverage
        run: node scripts/coverage-diff.js
      
      - name: Comment PR with coverage
        uses: romeovs/lcov-reporter-action@v0.3.1
        with:
          lcov-file: ./coverage/lcov.info
          github-token: ${{ secrets.GITHUB_TOKEN }}
```

#### Incremental Coverage Improvement

Strategies for improving coverage in existing codebases:

**Baseline and Ratcheting**:

```javascript
// coverage-ratchet.js
const fs = require('fs');

function readBaseline() {
  if (fs.existsSync('./coverage-baseline.json')) {
    return JSON.parse(fs.readFileSync('./coverage-baseline.json'));
  }
  return { lines: 0, branches: 0, functions: 0, statements: 0 };
}

function getCurrentCoverage() {
  const summary = JSON.parse(
    fs.readFileSync('./coverage/coverage-summary.json')
  );
  return summary.total;
}

function updateBaseline(current) {
  const baseline = readBaseline();
  
  const updated = {
    lines: Math.max(baseline.lines, current.lines.pct),
    branches: Math.max(baseline.branches, current.branches.pct),
    functions: Math.max(baseline.functions, current.functions.pct),
    statements: Math.max(baseline.statements, current.statements.pct)
  };
  
  fs.writeFileSync(
    './coverage-baseline.json',
    JSON.stringify(updated, null, 2)
  );
  
  return updated;
}

function checkRatchet() {
  const baseline = readBaseline();
  const current = getCurrentCoverage();
  
  console.log('Coverage Ratchet Check:');
  console.log(`Lines: ${current.lines.pct}% (baseline: ${baseline.lines}%)`);
  console.log(`Branches: ${current.branches.pct}% (baseline: ${baseline.branches}%)`);
  console.log(`Functions: ${current.functions.pct}% (baseline: ${baseline.functions}%)`);
  console.log(`Statements: ${current.statements.pct}% (baseline: ${baseline.statements}%)`);
  
  const passed = 
    current.lines.pct >= baseline.lines &&
    current.branches.pct >= baseline.branches &&
    current.functions.pct >= baseline.functions &&
    current.statements.pct >= baseline.statements;
  
  if (passed) {
    updateBaseline(current);
    console.log('\n✓ Coverage maintained or improved. Baseline updated.');
    process.exit(0);
  } else {
    console.log('\n✗ Coverage decreased below baseline.');
    process.exit(1);
  }
}

checkRatchet();
```

**Focused Coverage Campaigns**:

```javascript
// coverage-gap-analysis.js
const fs = require('fs');
const path = require('path');

function analyzeCoverageGaps() {
  const coverageData = JSON.parse(
    fs.readFileSync('./coverage/coverage-final.json')
  );
  
  const gaps = [];
  
  for (const [filePath, fileData] of Object.entries(coverageData)) {
    const coverage = fileData.s; // statement coverage
    const uncoveredLines = Object.entries(coverage)
      .filter(([_, count]) => count === 0)
      .map(([line]) => parseInt(line));
    
    if (uncoveredLines.length > 0) {
      gaps.push({
        file: filePath,
        uncoveredLines: uncoveredLines.length,
        totalLines: Object.keys(coverage).length,
        percentage: (uncoveredLines.length / Object.keys(coverage).length) * 100,
        lines: uncoveredLines
      });
    }
  }
  
  // Prioritize by business impact
  gaps.sort((a, b) => {
    const criticalPaths = ['auth', 'payment', 'security'];
    const aIsCritical = criticalPaths.some(p => a.file.includes(p));
    const bIsCritical = criticalPaths.some(p => b.file.includes(p));
    
    if (aIsCritical && !bIsCritical) return -1;
    if (!aIsCritical && bIsCritical) return 1;
    return b.percentage - a.percentage;
  });
  
  return gaps;
}

function generateCoverageReport() {
  const gaps = analyzeCoverageGaps();
  
  console.log('Coverage Gap Analysis\n');
  console.log('Priority Files to Test:\n');
  
  gaps.slice(0, 10).forEach((gap, index) => {
    console.log(`${index + 1}. ${gap.file}`);
    console.log(`   Uncovered: ${gap.uncoveredLines} lines (${gap.percentage.toFixed(1)}%)`);
    console.log(`   Lines: ${gap.lines.join(', ')}\n`);
  });
  
  // Generate focused test file template
  const topGap = gaps[0];
  if (topGap) {
    const testTemplate = generateTestTemplate(topGap);
    console.log('\nSuggested Test Template:\n');
    console.log(testTemplate);
  }
}

function generateTestTemplate(gap) {
  const fileName = path.basename(gap.file, '.js');
  return `
// ${fileName}.test.js
describe('${fileName}', () => {
  // Focus on uncovered lines: ${gap.lines.join(', ')}
  
  describe('Edge cases', () => {
    it('should handle error conditions', () => {
      // Test error paths
    });
    
    it('should handle boundary conditions', () => {
      // Test edge cases
    });
  });
  
  describe('Integration scenarios', () => {
    it('should work in production-like scenarios', () => {
      // Test realistic use cases
    });
  });
});
`;
}

generateCoverageReport();
```

**Legacy Code Coverage Strategy**:

```javascript
// characterization-test.js
const fs = require('fs');

class CharacterizationTestGenerator {
  constructor(targetFile) {
    this.targetFile = targetFile;
    this.observations = [];
  }
  
  observe(input, output, description) {
    this.observations.push({ input, output, description });
  }
  
  generateTests() {
    const testCode = `
// Characterization tests for ${this.targetFile}
// These tests document current behavior before refactoring

const { ${this.getFunctionNames()} } = require('${this.targetFile}');

describe('Characterization Tests - ${this.targetFile}', () => {
  // WARNING: These tests document CURRENT behavior, not CORRECT behavior
  // Review and update assertions if behavior should change
  
${this.observations.map(obs => `
  it('${obs.description}', () => {
    const result = ${this.generateFunctionCall(obs.input)};
    expect(result).toEqual(${JSON.stringify(obs.output)});
  });
`).join('\n')}
  
  describe('Boundary conditions', () => {
    it('should handle null input', () => {
      // Add test after observing behavior
    });
    
    it('should handle undefined input', () => {
      // Add test after observing behavior
    });
    
    it('should handle empty input', () => {
      // Add test after observing behavior
    });
  });
  
  describe('Error conditions', () => {
    it('should handle invalid data types', () => {
      // Add test after observing behavior
    });
    
    it('should handle out-of-range values', () => {
      // Add test after observing behavior
    });
  });
});
`;
    return testCode;
  }
  
  getFunctionNames() {
    // [Inference] Simplified extraction
    return 'legacyFunction';
  }
  
  generateFunctionCall(input) {
    return `legacyFunction(${JSON.stringify(input)})`;
  }
}

// Usage example
const generator = new CharacterizationTestGenerator('./legacy-module.js');

// Observe current behavior
generator.observe({ id: 1 }, { result: 'success' }, 'handles valid ID');
generator.observe({ id: -1 }, { error: 'invalid' }, 'rejects negative ID');
generator.observe({}, null, 'returns null for empty object');

console.log(generator.generateTests());
```

#### Coverage for Different Code Types

**API Endpoint Coverage**:

```javascript
// api-coverage-test.js
const request = require('supertest');
const app = require('../app');

describe('API Coverage Tests', () => {
  describe('GET /api/users/:id', () => {
    it('should cover success path (200)', async () => {
      const response = await request(app)
        .get('/api/users/1')
        .expect(200);
      
      expect(response.body).toHaveProperty('id');
      expect(response.body).toHaveProperty('name');
    });
    
    it('should cover not found path (404)', async () => {
      await request(app)
        .get('/api/users/999999')
        .expect(404);
    });
    
    it('should cover invalid ID path (400)', async () => {
      await request(app)
        .get('/api/users/invalid')
        .expect(400);
    });
    
    it('should cover authentication failure (401)', async () => {
      await request(app)
        .get('/api/users/1')
        .set('Authorization', 'Bearer invalid-token')
        .expect(401);
    });
    
    it('should cover authorization failure (403)', async () => {
      await request(app)
        .get('/api/users/1')
        .set('Authorization', 'Bearer valid-but-insufficient-token')
        .expect(403);
    });
    
    it('should cover server error path (500)', async () => {
      // Mock database failure
      jest.spyOn(db, 'query').mockRejectedValue(new Error('DB Error'));
      
      await request(app)
        .get('/api/users/1')
        .expect(500);
    });
    
    it('should cover rate limiting (429)', async () => {
      // Make multiple requests to trigger rate limit
      for (let i = 0; i < 100; i++) {
        await request(app).get('/api/users/1');
      }
      
      await request(app)
        .get('/api/users/1')
        .expect(429);
    });
  });
  
  describe('POST /api/users', () => {
    it('should cover valid creation (201)', async () => {
      const newUser = {
        name: 'Test User',
        email: 'test@example.com',
        age: 25
      };
      
      const response = await request(app)
        .post('/api/users')
        .send(newUser)
        .expect(201);
      
      expect(response.body).toHaveProperty('id');
    });
    
    it('should cover validation errors (400)', async () => {
      const invalidUser = {
        name: '', // Empty name
        email: 'not-an-email', // Invalid email
        age: -5 // Invalid age
      };
      
      const response = await request(app)
        .post('/api/users')
        .send(invalidUser)
        .expect(400);
      
      expect(response.body).toHaveProperty('errors');
      expect(response.body.errors).toHaveLength(3);
    });
    
    it('should cover duplicate entry (409)', async () => {
      const user = {
        name: 'Existing User',
        email: 'existing@example.com'
      };
      
      await request(app).post('/api/users').send(user);
      
      await request(app)
        .post('/api/users')
        .send(user)
        .expect(409);
    });
    
    it('should cover malformed JSON (400)', async () => {
      await request(app)
        .post('/api/users')
        .set('Content-Type', 'application/json')
        .send('{ invalid json }')
        .expect(400);
    });
  });
});
```

**Async/Promise Coverage**:


```javascript
// async-coverage-test.js

describe('Async Operation Coverage', () => {
  describe('Promise-based operations', () => {
    it('should cover successful resolution', async () => {
      const result = await fetchData('valid-id');
      expect(result).toBeDefined();
    });
    
    it('should cover rejection', async () => {
      await expect(fetchData('invalid-id')).rejects.toThrow('Not found');
    });
    
    it('should cover timeout', async () => {
      jest.setTimeout(1000);
      await expect(fetchData('slow-id')).rejects.toThrow('Timeout');
    });
    
    it('should cover pending state handling', () => {
      const promise = fetchData('test-id');
      expect(promise).toBeInstanceOf(Promise);
      // Don't await - testing pending state
    });
  });
  
  describe('Callback-based operations', () => {
    it('should cover success callback', (done) => {
      fetchDataCallback('valid-id', (err, data) => {
        expect(err).toBeNull();
        expect(data).toBeDefined();
        done();
      });
    });
    
    it('should cover error callback', (done) => {
      fetchDataCallback('invalid-id', (err, data) => {
        expect(err).toBeDefined();
        expect(data).toBeUndefined();
        done();
      });
    });
  });
  
  describe('Async/await error handling', () => {
    it('should cover try-catch blocks', async () => {
      try {
        await fetchData('invalid-id');
        fail('Should have thrown');
      } catch (error) {
        expect(error.message).toBe('Not found');
      }
    });
    
    it('should cover finally blocks', async () => {
      const cleanup = jest.fn();
      try {
        await fetchData('valid-id');
      } finally {
        cleanup();
      }
      expect(cleanup).toHaveBeenCalled();
    });
    
    it('should cover nested async operations', async () => {
      const result1 = await fetchData('id-1');
      const result2 = await fetchData(result1.nextId);
      expect(result2).toBeDefined();
    });
  });
  
  describe('Concurrent async operations', () => {
    it('should cover Promise.all success', async () => {
      const results = await Promise.all([
        fetchData('id-1'),
        fetchData('id-2'),
        fetchData('id-3')
      ]);
      expect(results).toHaveLength(3);
    });
    
    it('should cover Promise.all failure', async () => {
      await expect(
        Promise.all([
          fetchData('id-1'),
          fetchData('invalid-id'),
          fetchData('id-3')
        ])
      ).rejects.toThrow();
    });
    
    it('should cover Promise.allSettled', async () => {
      const results = await Promise.allSettled([
        fetchData('id-1'),
        fetchData('invalid-id'),
        fetchData('id-3')
      ]);
      expect(results[0].status).toBe('fulfilled');
      expect(results[1].status).toBe('rejected');
      expect(results[2].status).toBe('fulfilled');
    });
    
    it('should cover Promise.race', async () => {
      const result = await Promise.race([
        fetchData('fast-id'),
        fetchData('slow-id')
      ]);
      expect(result).toBeDefined();
    });
  });
  
  describe('Async generator coverage', () => {
    it('should cover async iteration', async () => {
      const results = [];
      for await (const item of fetchDataStream()) {
        results.push(item);
      }
      expect(results.length).toBeGreaterThan(0);
    });
    
    it('should cover early break in async iteration', async () => {
      const results = [];
      for await (const item of fetchDataStream()) {
        results.push(item);
        if (results.length === 2) break;
      }
      expect(results).toHaveLength(2);
    });
  });
});
```

#### Error Boundary Coverage

```javascript
// error-boundary-coverage-test.js
describe('Error Boundary Coverage', () => {
  describe('Network errors', () => {
    it('should cover network timeout', async () => {
      fetchMock.mockAbortOnce();
      await expect(fetchWithTimeout('/api/data', 1000))
        .rejects.toThrow('Request timeout');
    });
    
    it('should cover network failure', async () => {
      fetchMock.mockRejectOnce(new Error('Network error'));
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Network error');
    });
    
    it('should cover DNS resolution failure', async () => {
      fetchMock.mockRejectOnce(new TypeError('Failed to fetch'));
      await expect(fetchData('http://invalid.domain'))
        .rejects.toThrow('Failed to fetch');
    });
  });
  
  describe('HTTP error responses', () => {
    it('should cover 4xx client errors', async () => {
      fetchMock.mockResponseOnce('', { status: 400 });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Bad Request');
      
      fetchMock.mockResponseOnce('', { status: 401 });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Unauthorized');
      
      fetchMock.mockResponseOnce('', { status: 404 });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Not Found');
    });
    
    it('should cover 5xx server errors', async () => {
      fetchMock.mockResponseOnce('', { status: 500 });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Internal Server Error');
      
      fetchMock.mockResponseOnce('', { status: 503 });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Service Unavailable');
    });
  });
  
  describe('Response parsing errors', () => {
    it('should cover JSON parse errors', async () => {
      fetchMock.mockResponseOnce('invalid json');
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Invalid JSON');
    });
    
    it('should cover empty response', async () => {
      fetchMock.mockResponseOnce('');
      const result = await fetchData('/api/data');
      expect(result).toBeNull();
    });
    
    it('should cover malformed content-type', async () => {
      fetchMock.mockResponseOnce('data', {
        headers: { 'content-type': 'invalid' }
      });
      await expect(fetchData('/api/data'))
        .rejects.toThrow('Unsupported content type');
    });
  });
  
  describe('Retry logic coverage', () => {
    it('should cover successful retry', async () => {
      fetchMock
        .mockRejectOnce(new Error('Network error'))
        .mockRejectOnce(new Error('Network error'))
        .mockResponseOnce(JSON.stringify({ data: 'success' }));
      
      const result = await fetchWithRetry('/api/data', { maxRetries: 3 });
      expect(result.data).toBe('success');
      expect(fetchMock).toHaveBeenCalledTimes(3);
    });
    
    it('should cover retry exhaustion', async () => {
      fetchMock
        .mockReject(new Error('Network error'));
      
      await expect(fetchWithRetry('/api/data', { maxRetries: 3 }))
        .rejects.toThrow('Max retries exceeded');
      expect(fetchMock).toHaveBeenCalledTimes(3);
    });
    
    it('should cover exponential backoff', async () => {
      const delays = [];
      const mockDelay = jest.spyOn(global, 'setTimeout')
        .mockImplementation((cb, delay) => {
          delays.push(delay);
          cb();
          return 0;
        });
      
      fetchMock
        .mockRejectOnce(new Error('Error'))
        .mockRejectOnce(new Error('Error'))
        .mockResponseOnce(JSON.stringify({ data: 'success' }));
      
      await fetchWithRetry('/api/data', { 
        maxRetries: 3,
        backoff: 'exponential'
      });
      
      expect(delays[0]).toBe(1000);
      expect(delays[1]).toBe(2000);
      mockDelay.mockRestore();
    });
  });
  
  describe('Abort signal coverage', () => {
    it('should cover manual abort', async () => {
      const controller = new AbortController();
      const promise = fetchData('/api/data', { 
        signal: controller.signal 
      });
      
      controller.abort();
      
      await expect(promise).rejects.toThrow('The operation was aborted');
    });
    
    it('should cover timeout abort', async () => {
      fetchMock.mockResponseOnce(
        () => new Promise(resolve => setTimeout(resolve, 2000))
      );
      
      await expect(
        fetchWithTimeout('/api/data', 1000)
      ).rejects.toThrow('Request timeout');
    });
  });
});
```

#### Request/Response Coverage

```javascript
// request-response-coverage-test.js
describe('Request/Response Coverage', () => {
  describe('Request methods', () => {
    it('should cover GET requests', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({ data: 'test' }));
      
      const response = await fetch('/api/data');
      const data = await response.json();
      
      expect(fetchMock).toHaveBeenCalledWith('/api/data', {
        method: 'GET'
      });
      expect(data).toEqual({ data: 'test' });
    });

    it('should cover POST requests with body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({ id: 1 }));
      
      const payload = { name: 'test' };
      const response = await fetch('/api/users', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });
      
      expect(fetchMock).toHaveBeenCalledWith('/api/users', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });
    });

    it('should cover PUT requests', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({ updated: true }));
      
      await fetch('/api/users/1', {
        method: 'PUT',
        body: JSON.stringify({ name: 'updated' })
      });
      
      expect(fetchMock).toHaveBeenCalledWith(
        expect.stringContaining('/api/users/1'),
        expect.objectContaining({ method: 'PUT' })
      );
    });

    it('should cover DELETE requests', async () => {
      fetchMock.mockResponseOnce('', { status: 204 });
      
      const response = await fetch('/api/users/1', {
        method: 'DELETE'
      });
      
      expect(response.status).toBe(204);
      expect(fetchMock).toHaveBeenCalledWith(
        '/api/users/1',
        expect.objectContaining({ method: 'DELETE' })
      );
    });

    it('should cover PATCH requests', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({ patched: true }));
      
      await fetch('/api/users/1', {
        method: 'PATCH',
        body: JSON.stringify({ email: 'new@example.com' })
      });
      
      expect(fetchMock).toHaveBeenCalledWith(
        '/api/users/1',
        expect.objectContaining({ method: 'PATCH' })
      );
    });
  });

  describe('Request headers', () => {
    it('should cover various header combinations', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      await fetch('/api/data', {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer token123',
          'X-Custom-Header': 'custom-value',
          'Accept': 'application/json'
        }
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.headers).toEqual({
        'Content-Type': 'application/json',
        'Authorization': 'Bearer token123',
        'X-Custom-Header': 'custom-value',
        'Accept': 'application/json'
      });
    });

    it('should cover Headers object usage', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const headers = new Headers();
      headers.append('Content-Type', 'application/json');
      headers.append('Authorization', 'Bearer token');
      
      await fetch('/api/data', { headers });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.headers).toBeInstanceOf(Headers);
    });

    it('should cover missing headers', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      await fetch('/api/data'); // No headers
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options?.headers).toBeUndefined();
    });
  });

  describe('Request body types', () => {
    it('should cover JSON body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const body = { key: 'value', nested: { data: 'test' } };
      await fetch('/api/data', {
        method: 'POST',
        body: JSON.stringify(body)
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(JSON.parse(options.body)).toEqual(body);
    });

    it('should cover FormData body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const formData = new FormData();
      formData.append('file', new Blob(['content']), 'test.txt');
      formData.append('name', 'test');
      
      await fetch('/api/upload', {
        method: 'POST',
        body: formData
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.body).toBeInstanceOf(FormData);
    });

    it('should cover URLSearchParams body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const params = new URLSearchParams();
      params.append('key1', 'value1');
      params.append('key2', 'value2');
      
      await fetch('/api/data', {
        method: 'POST',
        body: params
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.body).toBeInstanceOf(URLSearchParams);
    });

    it('should cover Blob body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const blob = new Blob(['binary data'], { type: 'application/octet-stream' });
      await fetch('/api/upload', {
        method: 'POST',
        body: blob
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.body).toBeInstanceOf(Blob);
    });

    it('should cover ArrayBuffer body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      const buffer = new ArrayBuffer(8);
      await fetch('/api/binary', {
        method: 'POST',
        body: buffer
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.body).toBeInstanceOf(ArrayBuffer);
    });

    it('should cover plain text body', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}));
      
      await fetch('/api/data', {
        method: 'POST',
        body: 'plain text content'
      });
      
      const [, options] = fetchMock.mock.calls[0];
      expect(options.body).toBe('plain text content');
    });
  });

  describe('Response status codes', () => {
    it('should cover 2xx success responses', async () => {
      const successCodes = [200, 201, 202, 203, 204, 205, 206];
      
      for (const code of successCodes) {
        fetchMock.mockResponseOnce('', { status: code });
        const response = await fetch('/api/data');
        expect(response.status).toBe(code);
        expect(response.ok).toBe(true);
      }
    });

    it('should cover 3xx redirection responses', async () => {
      const redirectCodes = [300, 301, 302, 303, 304, 307, 308];
      
      for (const code of redirectCodes) {
        fetchMock.mockResponseOnce('', { 
          status: code,
          headers: { 'Location': '/new-location' }
        });
        const response = await fetch('/api/data');
        expect(response.status).toBe(code);
        expect(response.ok).toBe(false);
      }
    });

    it('should cover 4xx client error responses', async () => {
      const clientErrors = [400, 401, 403, 404, 405, 406, 408, 409, 410, 415, 422, 429];
      
      for (const code of clientErrors) {
        fetchMock.mockResponseOnce(JSON.stringify({ error: 'Client error' }), { 
          status: code 
        });
        const response = await fetch('/api/data');
        expect(response.status).toBe(code);
        expect(response.ok).toBe(false);
      }
    });

    it('should cover 5xx server error responses', async () => {
      const serverErrors = [500, 501, 502, 503, 504, 505];
      
      for (const code of serverErrors) {
        fetchMock.mockResponseOnce(JSON.stringify({ error: 'Server error' }), { 
          status: code 
        });
        const response = await fetch('/api/data');
        expect(response.status).toBe(code);
        expect(response.ok).toBe(false);
      }
    });

    it('should cover edge case status codes', async () => {
      const edgeCases = [
        { code: 100, description: 'Continue' },
        { code: 101, description: 'Switching Protocols' },
        { code: 418, description: "I'm a teapot" },
        { code: 451, description: 'Unavailable For Legal Reasons' },
        { code: 511, description: 'Network Authentication Required' }
      ];
      
      for (const { code } of edgeCases) {
        fetchMock.mockResponseOnce('', { status: code });
        const response = await fetch('/api/data');
        expect(response.status).toBe(code);
      }
    });
  });

  describe('Response headers', () => {
    it('should cover standard response headers', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}), {
        headers: {
          'Content-Type': 'application/json',
          'Cache-Control': 'no-cache',
          'ETag': '"abc123"',
          'Last-Modified': 'Wed, 21 Oct 2015 07:28:00 GMT',
          'Content-Length': '1234',
          'Content-Encoding': 'gzip',
          'X-RateLimit-Limit': '100',
          'X-RateLimit-Remaining': '99'
        }
      });
      
      const response = await fetch('/api/data');
      expect(response.headers.get('Content-Type')).toBe('application/json');
      expect(response.headers.get('Cache-Control')).toBe('no-cache');
      expect(response.headers.get('ETag')).toBe('"abc123"');
      expect(response.headers.get('X-RateLimit-Limit')).toBe('100');
    });

    it('should cover CORS headers', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}), {
        headers: {
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE',
          'Access-Control-Allow-Headers': 'Content-Type, Authorization',
          'Access-Control-Max-Age': '86400',
          'Access-Control-Expose-Headers': 'X-Custom-Header'
        }
      });
      
      const response = await fetch('/api/data');
      expect(response.headers.get('Access-Control-Allow-Origin')).toBe('*');
      expect(response.headers.get('Access-Control-Allow-Methods')).toContain('POST');
    });

    it('should cover security headers', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}), {
        headers: {
          'Strict-Transport-Security': 'max-age=31536000; includeSubDomains',
          'X-Content-Type-Options': 'nosniff',
          'X-Frame-Options': 'DENY',
          'X-XSS-Protection': '1; mode=block',
          'Content-Security-Policy': "default-src 'self'"
        }
      });
      
      const response = await fetch('/api/data');
      expect(response.headers.get('Strict-Transport-Security')).toContain('max-age');
      expect(response.headers.get('X-Content-Type-Options')).toBe('nosniff');
    });

    it('should cover custom headers', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}), {
        headers: {
          'X-Request-ID': 'req-123456',
          'X-Server-Version': '1.0.0',
          'X-Processing-Time': '123ms',
          'X-Custom-Data': 'custom-value'
        }
      });
      
      const response = await fetch('/api/data');
      expect(response.headers.get('X-Request-ID')).toBe('req-123456');
      expect(response.headers.get('X-Server-Version')).toBe('1.0.0');
    });

    it('should cover headers iteration', async () => {
      fetchMock.mockResponseOnce(JSON.stringify({}), {
        headers: {
          'X-A': '1',
          'X-B': '2'
        }
      });
      
      const response = await fetch('/api/data');
      const entries = [];
      for (const [name, value] of response.headers.entries()) {
        entries.push([name, value]);
      }
      
      expect(entries).toContainEqual(['x-a', '1']);
      expect(entries).toContainEqual(['x-b', '2']);
    });
  });

  describe('Error handling and edge cases', () => {
    it('should cover network failures (TypeError)', async () => {
      fetchMock.mockReject(new TypeError('Failed to fetch'));
      
      await expect(fetch('/api/data')).rejects.toThrow(TypeError);
    });

    it('should cover AbortController signaling', async () => {
      const controller = new AbortController();
      fetchMock.mockAbort();
      
      const fetchPromise = fetch('/api/data', { signal: controller.signal });
      controller.abort();
      
      await expect(fetchPromise).rejects.toThrow();
    });

    it('should cover timeout simulations', async () => {
      fetchMock.mockResponseOnce(
        () => new Promise(resolve => setTimeout(() => resolve({ body: 'ok' }), 100))
      );
      
      const response = await fetch('/api/data');
      expect(await response.text()).toBe('ok');
    });
  });
});
```

## Advanced Fetch API Coverage Strategies

**Fundamentals of Test Coverage** in the context of asynchronous network operations, coverage extends beyond line execution to state verification. When testing Fetch API implementations, Statement Coverage ensures every fetch() call and .then()/.catch() block is reached. However, for robust networking, Branch Coverage is paramount to ensure that both the if (response.ok) and the subsequent error-handling else paths are validated. High-quality coverage in Fetch logic must account for the fact that a resolved promise does not inherently mean a successful business operation (e.g., 404 and 500 status codes resolve the promise).

**Coverage Types and Metrics**
- **Path Coverage:** Essential for complex request lifecycles involving interceptors, authentication retries (401 handling), and refresh token logic.
- **Data Flow Coverage:** Tracks the transformation of the `Response` object from a raw stream to parsed JSON or Blobs.
- **Boundary Value Analysis (BVA):** Applied to pagination parameters in query strings or payload size limits.
- **Condition Coverage:** Specifically targets logical combinations in request headers, such as ensuring coverage for cases where `Authorization` is present versus when it is expired or malformed.

**Coverage Tools and Configuration**

Modern JavaScript environments utilize Istanbul/C8 for coverage reporting. To effectively cover Fetch logic:

- **jest-fetch-mock:** Ideal for unit testing individual functions that use fetch.
- **Mock Service Worker (MSW):** The industry standard for integration-level coverage. MSW intercepts requests at the network level, allowing tests to cover real-world scenarios like slow networks or intermittent disconnections without changing the application code.
- **Configuration:** Ensure `collectCoverageFrom` includes utility folders where API wrappers reside, as these often contain the most critical branch logic (e.g., global error handlers).

**Strategic Coverage Approaches**

**Risk-Based Coverage Prioritization** Prioritize coverage for Idempotent vs. Non-Idempotent operations. A failure in a GET request (idempotent) results in a UI error, but a failure in a POST or DELETE request (non-idempotent) can lead to data corruption or orphaned records. Coverage should be weighted toward state-changing operations and critical paths like checkout or authentication.

**Mutation Testing** Mutation testing for Fetch involves introducing "mutants" into the request configuration.

> **Example:** If a test passes when the `method` is changed from `POST` to `GET` by a mutation tool (like Stryker), your test suite has a "survived mutant," indicating that your assertions are not strictly validating the request intent.

**Differential Coverage** This strategy compares coverage across different environments (e.g., Browser vs. Node.js). Since the Fetch API has slight variations in implementation (like the behavior of ReadableStream or AbortSignal in older environments), differential coverage identifies environment-specific bugs that standard unit tests might miss.

**Incremental Coverage Improvement** Use Coverage Thresholds in CI/CD pipelines to prevent regressions. For API-heavy applications, set a higher threshold (e.g., 95%) specifically for the services/ or api/ directory. This ensures that every new endpoint added includes its corresponding success and failure test cases.

**Coverage for Different Code Types**

- **Service Workers:** Requires specialized coverage to test the `fetch` event listener and cache-falling-back-to-network strategies.
- **Hooks (React/Vue):** Focus coverage on the "Loading/Error/Success" state transitions triggered by the fetch lifecycle.
- **Middleware:** Ensure coverage for header injection (e.g., adding `X-Correlation-ID`) across all outgoing requests.

**Error Boundary Coverage** Standard coverage often misses the "Hard Failures."
- **Network Loss:** Testing how the app behaves when `fetch` throws a `TypeError`.
- **Malformed JSON:** Ensuring the `catch` block handles `SyntaxError` during `response.json()` parsing.
- **CORS Violations:** Simulating opaque responses or pre-flight failures to ensure the UI provides meaningful feedback rather than a silent failure.

**Request/Response Coverage** This is often referred to as Contract Testing. It ensures that the "shape" of the data remains consistent.

- **Request Schema:** Validating that the `body` and `headers` sent to the fetch call match the API specification.
    
- **Response Schema:** Using tools like **Zod** or **Joi** within tests to validate that the mocked response matches the expected structure, ensuring that coverage is not just passing but is also semantically correct.

---

# Browser Compatibility

## Feature Detection

### Basic Detection

The simplest detection checks for `fetch` on the global object:

```javascript
if ('fetch' in window) {
  // fetch is available
}

// Or with typeof
if (typeof fetch === 'function') {
  // fetch is available
}
```

This confirms the API exists but doesn't verify specific capabilities or proper implementation.

### Request Constructor Detection

Detecting `Request` constructor availability:

```javascript
if (typeof Request !== 'undefined') {
  // Request constructor available
}

// Check both fetch and Request
if ('fetch' in window && 'Request' in window) {
  // Both available
}
```

The `Request` constructor may be absent in partial implementations or polyfills.

### Response Constructor Detection

```javascript
if (typeof Response !== 'undefined') {
  // Response constructor available
}
```

### Headers Detection

```javascript
if (typeof Headers !== 'undefined') {
  // Headers API available
}
```

### Signal and AbortController Detection

For abort functionality:

```javascript
if ('signal' in Request.prototype && 'AbortController' in window) {
  // Abort API is available
  const controller = new AbortController();
  fetch(url, { signal: controller.signal });
}
```

**[Inference]**: Checking both `signal` in `Request.prototype` and `AbortController` existence increases confidence that abort functionality works properly, though implementation bugs could still exist.

### Streams Detection

Detecting readable stream support in responses:

```javascript
if ('body' in Response.prototype && 'ReadableStream' in window) {
  // Response body streams are likely supported
}

// More thorough check
async function detectStreamSupport() {
  try {
    const response = new Response('test');
    return 'body' in response && response.body instanceof ReadableStream;
  } catch (e) {
    return false;
  }
}
```

### Credentials Mode Detection

```javascript
function detectCredentialsMode() {
  try {
    const req = new Request('/', { credentials: 'include' });
    return req.credentials === 'include';
  } catch (e) {
    return false;
  }
}
```

### Cache Mode Detection

```javascript
function detectCacheMode() {
  try {
    const req = new Request('/', { cache: 'no-cache' });
    return req.cache === 'no-cache';
  } catch (e) {
    return false;
  }
}
```

### Redirect Mode Detection

```javascript
function detectRedirectMode() {
  try {
    const req = new Request('/', { redirect: 'manual' });
    return req.redirect === 'manual';
  } catch (e) {
    return false;
  }
}
```

### Referrer Policy Detection

```javascript
function detectReferrerPolicy() {
  try {
    const req = new Request('/', { referrerPolicy: 'no-referrer' });
    return req.referrerPolicy === 'no-referrer';
  } catch (e) {
    return false;
  }
}
```

### Integrity Detection

Subresource Integrity (SRI) support:

```javascript
function detectIntegrity() {
  try {
    const req = new Request('/', { 
      integrity: 'sha256-test' 
    });
    return 'integrity' in req;
  } catch (e) {
    return false;
  }
}
```

### Keepalive Detection

```javascript
function detectKeepalive() {
  try {
    const req = new Request('/', { keepalive: true });
    return req.keepalive === true;
  } catch (e) {
    return false;
  }
}
```

### Priority Detection

For resource priority hints:

```javascript
function detectPriority() {
  try {
    const req = new Request('/', { priority: 'high' });
    return 'priority' in req;
  } catch (e) {
    return false;
  }
}
```

### Request Duplex Detection

For streaming request bodies:

```javascript
function detectDuplex() {
  try {
    const req = new Request('/', { 
      method: 'POST',
      body: new ReadableStream(),
      duplex: 'half'
    });
    return true;
  } catch (e) {
    return false;
  }
}
```

**[Unverified]**: This detection approach may not reliably indicate full duplex streaming support across all environments.

### Response Type Detection

Checking for opaque response types:

```javascript
async function detectResponseTypes() {
  try {
    const response = new Response('test', { 
      status: 200,
      statusText: 'OK'
    });
    
    return {
      basic: response.type === 'basic',
      hasType: 'type' in response
    };
  } catch (e) {
    return { basic: false, hasType: false };
  }
}
```

### FormData Body Detection

```javascript
function detectFormDataBody() {
  if (typeof FormData === 'undefined') return false;
  
  try {
    const formData = new FormData();
    const req = new Request('/', { 
      method: 'POST',
      body: formData 
    });
    return true;
  } catch (e) {
    return false;
  }
}
```

### Blob Body Detection

```javascript
function detectBlobBody() {
  if (typeof Blob === 'undefined') return false;
  
  try {
    const blob = new Blob(['test']);
    const req = new Request('/', { 
      method: 'POST',
      body: blob 
    });
    return true;
  } catch (e) {
    return false;
  }
}
```

### ArrayBuffer Body Detection

```javascript
function detectArrayBufferBody() {
  try {
    const buffer = new ArrayBuffer(8);
    const req = new Request('/', { 
      method: 'POST',
      body: buffer 
    });
    return true;
  } catch (e) {
    return false;
  }
}
```

### Response Body Methods Detection

```javascript
async function detectBodyMethods() {
  const response = new Response('{"test": true}');
  
  return {
    json: typeof response.json === 'function',
    text: typeof response.text === 'function',
    blob: typeof response.blob === 'function',
    arrayBuffer: typeof response.arrayBuffer === 'function',
    formData: typeof response.formData === 'function'
  };
}
```

### Clone Detection

```javascript
function detectClone() {
  try {
    const req = new Request('/');
    const cloned = req.clone();
    return cloned instanceof Request;
  } catch (e) {
    return false;
  }
}
```

### Comprehensive Feature Matrix

```javascript
async function getFetchFeatureMatrix() {
  const features = {
    core: {
      fetch: typeof fetch === 'function',
      Request: typeof Request !== 'undefined',
      Response: typeof Response !== 'undefined',
      Headers: typeof Headers !== 'undefined'
    },
    abort: {
      signal: 'signal' in Request.prototype,
      AbortController: typeof AbortController !== 'undefined'
    },
    streams: {
      ReadableStream: typeof ReadableStream !== 'undefined',
      responseBody: false
    },
    requestOptions: {},
    bodyTypes: {},
    responseMethods: {}
  };

  // Test response body stream
  try {
    const response = new Response('test');
    features.streams.responseBody = response.body instanceof ReadableStream;
  } catch (e) {}

  // Test request options
  const options = [
    'credentials', 'cache', 'redirect', 
    'referrerPolicy', 'integrity', 'keepalive', 'priority'
  ];
  
  for (const option of options) {
    try {
      const testValue = option === 'credentials' ? 'include' :
                       option === 'cache' ? 'no-cache' :
                       option === 'redirect' ? 'manual' :
                       option === 'referrerPolicy' ? 'no-referrer' :
                       option === 'integrity' ? 'sha256-test' :
                       option === 'keepalive' ? true :
                       option === 'priority' ? 'high' : null;
      
      const req = new Request('/', { [option]: testValue });
      features.requestOptions[option] = option in req;
    } catch (e) {
      features.requestOptions[option] = false;
    }
  }

  // Test body types
  const bodyTests = [
    { name: 'string', value: 'test' },
    { name: 'FormData', value: typeof FormData !== 'undefined' ? new FormData() : null },
    { name: 'Blob', value: typeof Blob !== 'undefined' ? new Blob(['test']) : null },
    { name: 'ArrayBuffer', value: new ArrayBuffer(8) },
    { name: 'URLSearchParams', value: typeof URLSearchParams !== 'undefined' ? new URLSearchParams() : null }
  ];

  for (const test of bodyTests) {
    if (test.value === null) {
      features.bodyTypes[test.name] = false;
      continue;
    }
    
    try {
      new Request('/', { method: 'POST', body: test.value });
      features.bodyTypes[test.name] = true;
    } catch (e) {
      features.bodyTypes[test.name] = false;
    }
  }

  // Test response methods
  try {
    const response = new Response('test');
    const methods = ['json', 'text', 'blob', 'arrayBuffer', 'formData'];
    
    for (const method of methods) {
      features.responseMethods[method] = typeof response[method] === 'function';
    }
  } catch (e) {}

  return features;
}
```

### Detection Patterns for Polyfills

When using polyfills, detect whether native or polyfilled:

```javascript
function isNativeFetch() {
  if (typeof fetch !== 'function') return false;
  
  // Check for native code string
  return /native code/.test(fetch.toString());
}

function getFetchImplementation() {
  if (typeof fetch !== 'function') {
    return 'none';
  }
  
  if (/native code/.test(fetch.toString())) {
    return 'native';
  }
  
  return 'polyfill';
}
```

**[Unverified]**: The `native code` string check may not be reliable across all JavaScript engines or when code is minified/transformed.

### Service Worker Context Detection

```javascript
function isFetchAvailableInServiceWorker() {
  return typeof self !== 'undefined' && 
         'ServiceWorkerGlobalScope' in self &&
         typeof fetch === 'function';
}
```

### Worker Context Detection

```javascript
function isFetchAvailableInWorker() {
  return typeof self !== 'undefined' &&
         typeof WorkerGlobalScope !== 'undefined' &&
         typeof fetch === 'function';
}
```

### CORS Detection

**[Inference]**: CORS behavior cannot be directly detected through feature detection; it depends on server configuration and runtime behavior.

```javascript
// Cannot reliably detect CORS support through feature detection
// CORS is determined by:
// - Server response headers
// - Request mode
// - Runtime environment

async function testCORSCapability(url) {
  try {
    const response = await fetch(url, { mode: 'cors' });
    return response.ok;
  } catch (e) {
    return false;
  }
}
```

### Combined Detection Strategy

```javascript
class FetchCapabilities {
  constructor() {
    this.features = null;
  }

  async detect() {
    this.features = {
      available: typeof fetch === 'function',
      implementation: this.getImplementation(),
      core: this.detectCore(),
      advanced: this.detectAdvanced(),
      bodySupport: this.detectBodySupport(),
      streamSupport: await this.detectStreamSupport()
    };
    
    return this.features;
  }

  getImplementation() {
    if (typeof fetch !== 'function') return 'none';
    return /native code/.test(fetch.toString()) ? 'native' : 'polyfill';
  }

  detectCore() {
    return {
      fetch: typeof fetch === 'function',
      Request: typeof Request !== 'undefined',
      Response: typeof Response !== 'undefined',
      Headers: typeof Headers !== 'undefined',
      AbortController: typeof AbortController !== 'undefined'
    };
  }

  detectAdvanced() {
    const features = {};
    
    const tests = [
      { name: 'signal', test: () => 'signal' in Request.prototype },
      { name: 'keepalive', test: () => {
        const req = new Request('/', { keepalive: true });
        return req.keepalive === true;
      }},
      { name: 'priority', test: () => {
        const req = new Request('/', { priority: 'high' });
        return 'priority' in req;
      }},
      { name: 'integrity', test: () => {
        const req = new Request('/', { integrity: 'sha256-test' });
        return 'integrity' in req;
      }}
    ];

    for (const { name, test } of tests) {
      try {
        features[name] = test();
      } catch (e) {
        features[name] = false;
      }
    }

    return features;
  }

  detectBodySupport() {
    const types = ['string', 'FormData', 'Blob', 'ArrayBuffer', 'URLSearchParams'];
    const support = {};

    for (const type of types) {
      try {
        let body;
        switch (type) {
          case 'string': body = 'test'; break;
          case 'FormData': body = new FormData(); break;
          case 'Blob': body = new Blob(['test']); break;
          case 'ArrayBuffer': body = new ArrayBuffer(8); break;
          case 'URLSearchParams': body = new URLSearchParams(); break;
        }
        
        new Request('/', { method: 'POST', body });
        support[type] = true;
      } catch (e) {
        support[type] = false;
      }
    }

    return support;
  }

  async detectStreamSupport() {
    try {
      const response = new Response('test');
      return {
        available: 'body' in response && response.body instanceof ReadableStream,
        ReadableStream: typeof ReadableStream !== 'undefined'
      };
    } catch (e) {
      return { available: false, ReadableStream: false };
    }
  }

  hasMinimumSupport() {
    return this.features?.available && 
           this.features.core.Request && 
           this.features.core.Response;
  }

  hasModernSupport() {
    return this.hasMinimumSupport() &&
           this.features.advanced.signal &&
           this.features.core.AbortController &&
           this.features.streamSupport.available;
  }
}

// Usage
const capabilities = new FetchCapabilities();
const features = await capabilities.detect();

if (capabilities.hasModernSupport()) {
  // Use fetch with modern features
} else if (capabilities.hasMinimumSupport()) {
  // Use fetch with basic features
} else {
  // Load polyfill or use XMLHttpRequest
}
```

### Browser-Specific Quirks Detection

**[Inference]**: Some browsers have partial or buggy implementations that standard feature detection may not catch.

```javascript
function detectKnownQuirks() {
  const quirks = {
    // Some versions have issues with certain features
    hasStreamingQuirks: false,
    hasAbortQuirks: false,
    hasCredentialsQuirks: false
  };

  // These would need specific version/UA testing
  // which is generally discouraged in favor of capability testing
  
  return quirks;
}
```

### Fallback Strategy

```javascript
async function fetchWithFallback(url, options = {}) {
  // Check for fetch support
  if (typeof fetch !== 'function') {
    throw new Error('Fetch not available and no fallback configured');
  }

  // Check for required features
  const needsAbort = 'signal' in (options || {});
  const hasAbort = 'AbortController' in window && 'signal' in Request.prototype;

  if (needsAbort && !hasAbort) {
    // Remove signal and warn
    console.warn('AbortController not supported, removing signal');
    const { signal, ...restOptions } = options;
    return fetch(url, restOptions);
  }

  return fetch(url, options);
}
```

---

## Fetch API Polyfills

### Purpose and Need

Polyfills provide fetch API functionality in environments where it's not natively supported. Primary targets include Internet Explorer 11, older versions of Safari, and Node.js versions prior to 18.0.0.

### whatwg-fetch

The canonical polyfill maintained by GitHub, implementing the WHATWG Fetch specification.

**Installation:**

```bash
npm install whatwg-fetch --save
```

**Basic Usage:**

```javascript
import 'whatwg-fetch';

// fetch is now available globally
fetch('/api/data')
  .then(response => response.json())
  .then(data => console.log(data));
```

**Features:**

- Implements the complete Fetch API surface including Request, Response, Headers
- Requires a Promise polyfill (e.g., `promise-polyfill`) for IE11
- Does not support streaming responses in older browsers
- Handles URL normalization and encoding
- Respects CORS behavior based on browser capabilities

**Limitations:**

- Cannot polyfill streaming in environments without ReadableStream support
- Does not implement request abortion in IE11 (no AbortController)
- File upload progress tracking unavailable
- Service Worker integration limited by browser capabilities

### node-fetch

Brings fetch API to Node.js environments, closely matching browser behavior.

**Installation:**

```bash
npm install node-fetch
```

**Usage:**

```javascript
import fetch from 'node-fetch';

const response = await fetch('https://api.example.com/data');
const data = await response.json();
```

**Node.js Specific Behaviors:**

- Supports both CommonJS and ESM
- Handles Node.js streams for request/response bodies
- Respects `http_proxy` and `https_proxy` environment variables
- Provides custom Agent support for connection pooling
- Implements `response.buffer()` method for binary data

**Version Differences:**

- v2.x: CommonJS, requires Node.js 4+
- v3.x: Pure ESM, requires Node.js 12.20+
- Node.js 18+: Native fetch available, polyfill unnecessary

**Advanced Configuration:**

```javascript
import fetch from 'node-fetch';
import https from 'https';

const agent = new https.Agent({
  rejectUnauthorized: false
});

const response = await fetch('https://self-signed.example.com', {
  agent
});
```

### cross-fetch

Universal polyfill working in both browser and Node.js environments.

**Installation:**

```bash
npm install cross-fetch
```

**Usage:**

```javascript
import fetch from 'cross-fetch';

// Works identically in browser and Node.js
fetch('https://api.example.com')
  .then(res => res.json())
  .then(data => console.log(data));
```

**Implementation:**

- Browser: Uses whatwg-fetch
- Node.js: Uses node-fetch
- Provides unified API across platforms
- Automatic environment detection
- No configuration needed for basic usage

### isomorphic-fetch

Another universal solution combining whatwg-fetch and node-fetch.

**Installation:**

```bash
npm install isomorphic-fetch
```

**Usage:**

```javascript
require('isomorphic-fetch');

// fetch now available globally in both environments
fetch('https://api.example.com')
  .then(res => res.json());
```

**Characteristics:**

- Automatically polyfills global fetch
- Older alternative to cross-fetch
- Less actively maintained
- Heavier bundle size compared to cross-fetch

### unfetch

Minimal fetch polyfill optimized for size.

**Installation:**

```bash
npm install unfetch
```

**Usage:**

```javascript
import fetch from 'unfetch';

fetch('/api')
  .then(r => r.json())
  .then(data => console.log(data));
```

**Tradeoffs:**

- Only ~1KB minified and gzipped
- Implements core fetch functionality only
- Missing advanced features:
    - No streaming support
    - No Request/Response constructors
    - No Headers manipulation
    - Limited error handling
- Best for simple GET/POST requests in size-constrained applications

### Implementation Considerations

**Dependency Requirements:**

[Inference] Most fetch polyfills require a Promise polyfill for IE11:

```javascript
import 'promise-polyfill/src/polyfill';
import 'whatwg-fetch';
```

**Conditional Loading:**

```javascript
// Only load polyfill if fetch is unavailable
if (!window.fetch) {
  require('whatwg-fetch');
}
```

**Webpack Configuration:**

```javascript
// webpack.config.js
module.exports = {
  entry: ['whatwg-fetch', './src/index.js'],
  // ...
};
```

**Feature Detection Pattern:**

```javascript
const fetchAPI = window.fetch || require('node-fetch');

fetchAPI('https://api.example.com')
  .then(response => response.json());
```

### AbortController Polyfill

Fetch abortion requires separate polyfilling:

**Installation:**

```bash
npm install abortcontroller-polyfill
```

**Usage:**

```javascript
import 'abortcontroller-polyfill/dist/polyfill-patch-fetch';

const controller = new AbortController();
const signal = controller.signal;

fetch('/api/data', { signal })
  .then(response => response.json())
  .catch(err => {
    if (err.name === 'AbortError') {
      console.log('Request aborted');
    }
  });

// Abort the request
controller.abort();
```

### Streams Polyfill

For environments lacking ReadableStream support:

**Installation:**

```bash
npm install web-streams-polyfill
```

**Usage:**

```javascript
import 'web-streams-polyfill';
import 'whatwg-fetch';

fetch('/large-file')
  .then(response => {
    const reader = response.body.getReader();
    return reader.read();
  });
```

### Testing Considerations

**Mocking Polyfilled Fetch:**

```javascript
// Using jest
global.fetch = require('jest-fetch-mock');

// Using sinon
const fetchStub = sinon.stub(window, 'fetch');
fetchStub.returns(Promise.resolve(new Response('{"data": "test"}')));
```

**Node.js Test Setup:**

```javascript
// test-setup.js
import fetch from 'node-fetch';

if (!globalThis.fetch) {
  globalThis.fetch = fetch;
  globalThis.Headers = fetch.Headers;
  globalThis.Request = fetch.Request;
  globalThis.Response = fetch.Response;
}
```

### Migration Paths

**From XMLHttpRequest Libraries:**

Gradual migration approach using adapter pattern:

```javascript
function fetchAdapter(config) {
  return fetch(config.url, {
    method: config.method,
    headers: config.headers,
    body: config.data
  }).then(response => {
    return {
      data: response.json(),
      status: response.status,
      statusText: response.statusText
    };
  });
}
```

**Removing Polyfills:**

When dropping legacy browser support:

```javascript
// Before
import 'whatwg-fetch';

// After (modern browsers only)
// Remove polyfill import entirely
```

### Bundle Size Impact

Approximate sizes (minified + gzipped):

- whatwg-fetch: ~3KB
- node-fetch: ~4KB (Node.js only)
- cross-fetch: ~1.5KB (wrapper)
- unfetch: ~1KB
- isomorphic-fetch: ~5KB

**Tree Shaking:**

[Inference] Modern bundlers can eliminate unused polyfill code when targeting environments with native fetch:

```javascript
// babel.config.js
module.exports = {
  presets: [
    ['@babel/preset-env', {
      targets: '> 0.5%, not dead',
      useBuiltIns: 'usage',
      corejs: 3
    }]
  ]
};
```

### Browser Compatibility Strategy

**Differential Serving:**

```javascript
// modern.js (no polyfills)
fetch('/api/data').then(r => r.json());

// legacy.js (with polyfills)
import 'whatwg-fetch';
fetch('/api/data').then(r => r.json());
```

**HTML Loading:**

```html
<script type="module" src="modern.js"></script>
<script nomodule src="legacy.js"></script>
```

This approach sends smaller bundles to modern browsers while maintaining compatibility with older environments.

---

## Fallback Strategies

### Retry Logic

#### Basic Retry Implementation

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  let lastError;
  
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      return response;
    } catch (error) {
      lastError = error;
      if (i < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
      }
    }
  }
  
  throw lastError;
}
```

#### Exponential Backoff

Exponential backoff progressively increases wait times between retries to reduce server load and improve success rates:

```javascript
async function fetchWithExponentialBackoff(url, options = {}, config = {}) {
  const {
    maxRetries = 5,
    baseDelay = 1000,
    maxDelay = 32000,
    backoffFactor = 2,
    jitter = true
  } = config;
  
  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      return response;
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries - 1) {
        let delay = Math.min(baseDelay * Math.pow(backoffFactor, attempt), maxDelay);
        
        if (jitter) {
          delay = delay * (0.5 + Math.random() * 0.5);
        }
        
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}
```

#### Conditional Retry

Not all errors should trigger retries. Implement selective retry logic based on error types:

```javascript
function isRetriableError(error, response) {
  // Network errors
  if (error.name === 'TypeError' || error.message.includes('Failed to fetch')) {
    return true;
  }
  
  // Timeout errors
  if (error.name === 'AbortError') {
    return true;
  }
  
  // Server errors (5xx)
  if (response && response.status >= 500 && response.status < 600) {
    return true;
  }
  
  // Rate limiting
  if (response && response.status === 429) {
    return true;
  }
  
  // Client errors (4xx) should not retry
  if (response && response.status >= 400 && response.status < 500) {
    return false;
  }
  
  return false;
}

async function fetchWithConditionalRetry(url, options = {}, maxRetries = 3) {
  let lastError;
  let lastResponse;
  
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      lastResponse = response;
      
      if (!response.ok) {
        const error = new Error(`HTTP ${response.status}`);
        if (!isRetriableError(error, response)) {
          throw error;
        }
        lastError = error;
      } else {
        return response;
      }
    } catch (error) {
      if (!isRetriableError(error, lastResponse)) {
        throw error;
      }
      lastError = error;
    }
    
    if (i < maxRetries - 1) {
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
  
  throw lastError;
}
```

### Multiple Endpoint Fallback

#### Sequential Fallback

Try multiple endpoints in order until one succeeds:

```javascript
async function fetchWithEndpointFallback(endpoints, options = {}) {
  const errors = [];
  
  for (const endpoint of endpoints) {
    try {
      const response = await fetch(endpoint, options);
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      return response;
    } catch (error) {
      errors.push({ endpoint, error });
    }
  }
  
  throw new Error(`All endpoints failed: ${errors.map(e => e.endpoint).join(', ')}`);
}

// Usage
const endpoints = [
  'https://api.primary.com/data',
  'https://api.backup.com/data',
  'https://api.fallback.com/data'
];

fetchWithEndpointFallback(endpoints);
```

#### Race Strategy

Request from multiple sources simultaneously and use the first successful response:

```javascript
async function fetchWithRace(urls, options = {}) {
  const promises = urls.map(url => 
    fetch(url, options).then(response => {
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      return response;
    })
  );
  
  return Promise.race(promises);
}
```

#### Parallel with Priority

Request from multiple endpoints with prioritization:

```javascript
async function fetchWithPriorityFallback(endpoints, options = {}) {
  const priorityGroups = endpoints.reduce((groups, endpoint) => {
    const priority = endpoint.priority || 0;
    if (!groups[priority]) groups[priority] = [];
    groups[priority].push(endpoint.url);
    return groups;
  }, {});
  
  const sortedPriorities = Object.keys(priorityGroups).sort((a, b) => b - a);
  
  for (const priority of sortedPriorities) {
    try {
      return await fetchWithRace(priorityGroups[priority], options);
    } catch (error) {
      continue;
    }
  }
  
  throw new Error('All endpoint groups failed');
}

// Usage
const endpoints = [
  { url: 'https://cdn1.example.com/data', priority: 3 },
  { url: 'https://cdn2.example.com/data', priority: 3 },
  { url: 'https://backup.example.com/data', priority: 2 },
  { url: 'https://archive.example.com/data', priority: 1 }
];
```

### Cache-Based Fallback

#### Cache-First Strategy

Attempt to use cached data before making network requests:

```javascript
async function fetchWithCache(url, options = {}, cacheName = 'api-cache') {
  try {
    const cache = await caches.open(cacheName);
    const cachedResponse = await cache.match(url);
    
    if (cachedResponse) {
      // Optionally revalidate in background
      fetch(url, options).then(response => {
        if (response.ok) {
          cache.put(url, response.clone());
        }
      });
      
      return cachedResponse;
    }
    
    const response = await fetch(url, options);
    if (response.ok) {
      cache.put(url, response.clone());
    }
    return response;
  } catch (error) {
    const cache = await caches.open(cacheName);
    const cachedResponse = await cache.match(url);
    if (cachedResponse) {
      return cachedResponse;
    }
    throw error;
  }
}
```

#### Stale-While-Revalidate

Return cached content immediately while updating cache in background:

```javascript
async function fetchStaleWhileRevalidate(url, options = {}, config = {}) {
  const { cacheName = 'swr-cache', maxAge = 3600000 } = config;
  
  const cache = await caches.open(cacheName);
  const cachedResponse = await cache.match(url);
  
  const fetchAndCache = async () => {
    try {
      const response = await fetch(url, options);
      if (response.ok) {
        const responseToCache = response.clone();
        const headers = new Headers(responseToCache.headers);
        headers.set('sw-cache-timestamp', Date.now().toString());
        
        const cachedResponseWithTimestamp = new Response(
          await responseToCache.blob(),
          {
            status: responseToCache.status,
            statusText: responseToCache.statusText,
            headers: headers
          }
        );
        
        cache.put(url, cachedResponseWithTimestamp);
      }
      return response;
    } catch (error) {
      return null;
    }
  };
  
  if (cachedResponse) {
    const timestamp = cachedResponse.headers.get('sw-cache-timestamp');
    const age = Date.now() - parseInt(timestamp || '0');
    
    if (age < maxAge) {
      fetchAndCache();
      return cachedResponse;
    }
  }
  
  return fetchAndCache() || cachedResponse || Promise.reject(new Error('No cached response available'));
}
```

#### Network-First with Cache Fallback

```javascript
async function fetchNetworkFirstWithCache(url, options = {}, config = {}) {
  const { cacheName = 'network-first-cache', timeout = 5000 } = config;
  
  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (response.ok) {
      const cache = await caches.open(cacheName);
      cache.put(url, response.clone());
      return response;
    }
    
    throw new Error(`HTTP ${response.status}`);
  } catch (error) {
    const cache = await caches.open(cacheName);
    const cachedResponse = await cache.match(url);
    
    if (cachedResponse) {
      return cachedResponse;
    }
    
    throw error;
  }
}
```

### Local Storage Fallback

Use localStorage or IndexedDB as a fallback when both network and cache fail:

```javascript
async function fetchWithLocalStorageFallback(url, options = {}, config = {}) {
  const { storageKey = `fetch_${url}`, maxAge = 86400000 } = config;
  
  try {
    const response = await fetch(url, options);
    
    if (response.ok) {
      const data = await response.json();
      localStorage.setItem(storageKey, JSON.stringify({
        data,
        timestamp: Date.now()
      }));
      
      return new Response(JSON.stringify(data), {
        status: 200,
        headers: { 'Content-Type': 'application/json' }
      });
    }
    
    throw new Error(`HTTP ${response.status}`);
  } catch (error) {
    const stored = localStorage.getItem(storageKey);
    
    if (stored) {
      const { data, timestamp } = JSON.parse(stored);
      const age = Date.now() - timestamp;
      
      if (age < maxAge) {
        return new Response(JSON.stringify(data), {
          status: 200,
          headers: { 
            'Content-Type': 'application/json',
            'X-From-Cache': 'localStorage'
          }
        });
      }
    }
    
    throw error;
  }
}
```

### Timeout Handling

#### Basic Timeout

```javascript
async function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    clearTimeout(timeoutId);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    if (error.name === 'AbortError') {
      throw new Error(`Request timeout after ${timeout}ms`);
    }
    throw error;
  }
}
```

#### Progressive Timeout

Increase timeout on retries:

```javascript
async function fetchWithProgressiveTimeout(url, options = {}, config = {}) {
  const { 
    maxRetries = 3, 
    initialTimeout = 3000,
    timeoutMultiplier = 1.5 
  } = config;
  
  let lastError;
  
  for (let i = 0; i < maxRetries; i++) {
    const timeout = initialTimeout * Math.pow(timeoutMultiplier, i);
    
    try {
      return await fetchWithTimeout(url, options, timeout);
    } catch (error) {
      lastError = error;
      if (i < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
  }
  
  throw lastError;
}
```

### Degraded Mode

Provide reduced functionality when primary service fails:

```javascript
async function fetchWithDegradedMode(url, options = {}, config = {}) {
  const { degradedEndpoint, degradedTransform } = config;
  
  try {
    const response = await fetch(url, options);
    if (!response.ok) throw new Error(`HTTP ${response.status}`);
    return response;
  } catch (error) {
    if (degradedEndpoint) {
      try {
        const degradedResponse = await fetch(degradedEndpoint, options);
        
        if (degradedResponse.ok && degradedTransform) {
          const data = await degradedResponse.json();
          const transformedData = degradedTransform(data);
          
          return new Response(JSON.stringify(transformedData), {
            status: 200,
            headers: { 
              'Content-Type': 'application/json',
              'X-Degraded-Mode': 'true'
            }
          });
        }
        
        return degradedResponse;
      } catch (degradedError) {
        throw error;
      }
    }
    throw error;
  }
}

// Usage
fetchWithDegradedMode('https://api.example.com/full-data', {}, {
  degradedEndpoint: 'https://api.example.com/minimal-data',
  degradedTransform: (minimalData) => ({
    ...minimalData,
    limited: true,
    message: 'Operating in reduced functionality mode'
  })
});
```

### Circuit Breaker Pattern

Temporarily stop requests to failing services:

```javascript
class CircuitBreaker {
  constructor(config = {}) {
    this.failureThreshold = config.failureThreshold || 5;
    this.resetTimeout = config.resetTimeout || 60000;
    this.monitoringPeriod = config.monitoringPeriod || 10000;
    
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failures = 0;
    this.successes = 0;
    this.nextAttempt = Date.now();
    this.failureTimestamps = [];
  }
  
  async execute(url, options = {}) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }
    
    try {
      const response = await fetch(url, options);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      this.onSuccess();
      return response;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failures = 0;
    this.failureTimestamps = [];
    
    if (this.state === 'HALF_OPEN') {
      this.successes++;
      if (this.successes >= 2) {
        this.state = 'CLOSED';
        this.successes = 0;
      }
    }
  }
  
  onFailure() {
    const now = Date.now();
    this.failures++;
    this.failureTimestamps.push(now);
    
    // Remove old timestamps outside monitoring period
    this.failureTimestamps = this.failureTimestamps.filter(
      timestamp => now - timestamp < this.monitoringPeriod
    );
    
    if (this.failureTimestamps.length >= this.failureThreshold) {
      this.state = 'OPEN';
      this.nextAttempt = now + this.resetTimeout;
      this.successes = 0;
    } else if (this.state === 'HALF_OPEN') {
      this.state = 'OPEN';
      this.nextAttempt = now + this.resetTimeout;
      this.successes = 0;
    }
  }
  
  getState() {
    return {
      state: this.state,
      failures: this.failures,
      failureTimestamps: this.failureTimestamps.length,
      nextAttempt: this.state === 'OPEN' ? new Date(this.nextAttempt) : null
    };
  }
}

// Usage
const breaker = new CircuitBreaker({
  failureThreshold: 5,
  resetTimeout: 30000,
  monitoringPeriod: 10000
});

async function fetchWithCircuitBreaker(url, options = {}) {
  try {
    return await breaker.execute(url, options);
  } catch (error) {
    if (error.message === 'Circuit breaker is OPEN') {
      // Use cached data or show error message
      return getCachedData(url);
    }
    throw error;
  }
}
```

### Composite Strategy

Combine multiple fallback strategies:

```javascript
async function fetchWithCompositeFallback(url, options = {}, config = {}) {
  const {
    maxRetries = 3,
    timeout = 5000,
    fallbackEndpoints = [],
    cacheName = 'composite-cache',
    useCircuitBreaker = true,
    circuitBreaker = null
  } = config;
  
  const allEndpoints = [url, ...fallbackEndpoints];
  
  for (const endpoint of allEndpoints) {
    // Try with retries and timeout
    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        let response;
        
        if (useCircuitBreaker && circuitBreaker) {
          response = await circuitBreaker.execute(endpoint, options);
        } else {
          response = await fetchWithTimeout(endpoint, options, timeout);
        }
        
        if (response.ok) {
          // Cache successful response
          const cache = await caches.open(cacheName);
          cache.put(url, response.clone());
          return response;
        }
      } catch (error) {
        if (attempt === maxRetries - 1) {
          continue; // Try next endpoint
        }
        await new Promise(resolve => 
          setTimeout(resolve, 1000 * Math.pow(2, attempt))
        );
      }
    }
  }
  
  // All endpoints failed, try cache
  try {
    const cache = await caches.open(cacheName);
    const cachedResponse = await cache.match(url);
    if (cachedResponse) {
      return cachedResponse;
    }
  } catch (cacheError) {
    // Cache also failed
  }
  
  // Try localStorage as last resort
  const storageKey = `fetch_${url}`;
  const stored = localStorage.getItem(storageKey);
  if (stored) {
    const { data } = JSON.parse(stored);
    return new Response(JSON.stringify(data), {
      status: 200,
      headers: { 
        'Content-Type': 'application/json',
        'X-From-Storage': 'localStorage'
      }
    });
  }
  
  throw new Error('All fallback strategies exhausted');
}
```

### Error Recovery Queue

Queue failed requests for later retry:

```javascript
class FetchQueue {
  constructor() {
    this.queue = [];
    this.processing = false;
    this.retryInterval = 30000;
  }
  
  async add(url, options = {}) {
    const id = Date.now() + Math.random();
    this.queue.push({ id, url, options, attempts: 0 });
    
    if (!this.processing) {
      this.processQueue();
    }
    
    return id;
  }
  
  async processQueue() {
    this.processing = true;
    
    while (this.queue.length > 0) {
      const item = this.queue[0];
      
      try {
        const response = await fetch(item.url, item.options);
        
        if (response.ok) {
          this.queue.shift();
          continue;
        }
      } catch (error) {
        item.attempts++;
      }
      
      if (item.attempts >= 5) {
        this.queue.shift();
      } else {
        await new Promise(resolve => setTimeout(resolve, this.retryInterval));
      }
    }
    
    this.processing = false;
  }
  
  remove(id) {
    this.queue = this.queue.filter(item => item.id !== id);
  }
  
  getStatus() {
    return {
      queueLength: this.queue.length,
      processing: this.processing,
      items: this.queue.map(({ id, url, attempts }) => ({ id, url, attempts }))
    };
  }
}

const fetchQueue = new FetchQueue();

async function fetchWithQueue(url, options = {}) {
  try {
    const response = await fetch(url, options);
    if (!response.ok) throw new Error(`HTTP ${response.status}`);
    return response;
  } catch (error) {
    // Add to queue for later retry
    await fetchQueue.add(url, options);
    throw error;
  }
}
```

---

## Progressive Enhancement

### Core Strategy

Progressive enhancement builds fetch-based features as layers, starting with basic functionality and adding capabilities based on browser support and network conditions. The baseline uses standard HTTP semantics, with enhancements added through feature detection.

### Feature Detection Patterns

```javascript
// Basic fetch availability
const hasFetch = typeof fetch !== 'undefined';

// Streaming support
const hasStreaming = hasFetch && 
  typeof ReadableStream !== 'undefined' &&
  typeof Response.prototype.body !== 'undefined';

// Request cloning
const hasCloning = hasFetch && 
  typeof Request.prototype.clone === 'function';

// AbortController
const hasAbort = typeof AbortController !== 'undefined';

// Network Information API
const hasNetworkInfo = 'connection' in navigator;

// Service Worker
const hasServiceWorker = 'serviceWorker' in navigator;
```

### Graceful Degradation Hierarchy

#### Level 1: XMLHttpRequest Fallback

When fetch is unavailable, fall back to XMLHttpRequest with similar interface:

```javascript
function request(url, options = {}) {
  if (typeof fetch !== 'undefined') {
    return fetch(url, options);
  }
  
  // XHR fallback
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open(options.method || 'GET', url);
    
    // Set headers
    if (options.headers) {
      Object.entries(options.headers).forEach(([key, value]) => {
        xhr.setRequestHeader(key, value);
      });
    }
    
    xhr.onload = () => {
      resolve({
        ok: xhr.status >= 200 && xhr.status < 300,
        status: xhr.status,
        statusText: xhr.statusText,
        headers: parseHeaders(xhr.getAllResponseHeaders()),
        text: () => Promise.resolve(xhr.responseText),
        json: () => Promise.resolve(JSON.parse(xhr.responseText)),
        blob: () => Promise.resolve(new Blob([xhr.response]))
      });
    };
    
    xhr.onerror = () => reject(new Error('Network error'));
    xhr.send(options.body);
  });
}

function parseHeaders(headerString) {
  const headers = new Map();
  headerString.split('\r\n').forEach(line => {
    const [key, value] = line.split(': ');
    if (key) headers.set(key.toLowerCase(), value);
  });
  return headers;
}
```

#### Level 2: Basic Fetch

Simplest fetch operations with minimal options:

```javascript
async function basicFetch(url) {
  try {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    return await response.json();
  } catch (error) {
    console.error('Fetch failed:', error);
    throw error;
  }
}
```

#### Level 3: Enhanced Fetch with Timeouts

Add timeout support where AbortController is available:

```javascript
async function fetchWithTimeout(url, options = {}, timeout = 5000) {
  if (typeof AbortController !== 'undefined') {
    const controller = new AbortController();
    const id = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(id);
      return response;
    } catch (error) {
      clearTimeout(id);
      if (error.name === 'AbortError') {
        throw new Error('Request timeout');
      }
      throw error;
    }
  }
  
  // Fallback: no timeout support
  return fetch(url, options);
}
```

#### Level 4: Streaming Response Handling

Process response streams when supported:

```javascript
async function fetchWithProgress(url, onProgress) {
  const response = await fetch(url);
  
  // Check streaming support
  if (!response.body || typeof ReadableStream === 'undefined') {
    // Fallback: load entire response
    const data = await response.arrayBuffer();
    onProgress?.(data.byteLength, data.byteLength);
    return data;
  }
  
  const reader = response.body.getReader();
  const contentLength = +response.headers.get('Content-Length');
  
  let receivedLength = 0;
  const chunks = [];
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) break;
    
    chunks.push(value);
    receivedLength += value.length;
    onProgress?.(receivedLength, contentLength);
  }
  
  // Concatenate chunks
  const chunksAll = new Uint8Array(receivedLength);
  let position = 0;
  for (const chunk of chunks) {
    chunksAll.set(chunk, position);
    position += chunk.length;
  }
  
  return chunksAll.buffer;
}
```

### Network-Aware Enhancement

Adapt behavior based on connection quality:

```javascript
function getNetworkStrategy() {
  if (!('connection' in navigator)) {
    return 'default';
  }
  
  const conn = navigator.connection;
  const effectiveType = conn.effectiveType;
  
  // [Inference] These thresholds represent common categorizations
  if (effectiveType === 'slow-2g' || effectiveType === '2g') {
    return 'minimal';
  }
  
  if (effectiveType === '3g') {
    return 'moderate';
  }
  
  if (conn.saveData) {
    return 'minimal';
  }
  
  return 'full';
}

async function adaptiveFetch(url, options = {}) {
  const strategy = getNetworkStrategy();
  
  switch (strategy) {
    case 'minimal':
      // Reduce payload, increase timeout
      return fetchWithTimeout(url, {
        ...options,
        headers: {
          ...options.headers,
          'Accept-Encoding': 'gzip, deflate',
          'X-Network-Quality': 'low'
        }
      }, 15000);
      
    case 'moderate':
      return fetchWithTimeout(url, options, 10000);
      
    case 'full':
    default:
      return fetchWithTimeout(url, options, 5000);
  }
}
```

### Retry with Exponential Backoff

Layer retry logic when network is unreliable:

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      // Don't retry on client errors
      if (response.status >= 400 && response.status < 500) {
        return response;
      }
      
      if (response.ok) {
        return response;
      }
      
      // Server error: might be temporary
      if (attempt === maxRetries) {
        return response;
      }
      
    } catch (error) {
      lastError = error;
      
      // Don't retry on abort
      if (error.name === 'AbortError') {
        throw error;
      }
      
      if (attempt === maxRetries) {
        throw error;
      }
    }
    
    // Exponential backoff: 1s, 2s, 4s
    const delay = Math.pow(2, attempt) * 1000;
    await new Promise(resolve => setTimeout(resolve, delay));
  }
  
  throw lastError;
}
```

### Service Worker Enhancement

Cache responses when Service Worker is available:

```javascript
// In main thread
async function fetchWithCacheFirst(url, options = {}) {
  if ('serviceWorker' in navigator && navigator.serviceWorker.controller) {
    // Service worker is active, will handle caching
    return fetch(url, options);
  }
  
  // No service worker: direct fetch only
  return fetch(url, options);
}

// In service worker
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request).then(cached => {
      // Return cached or fetch new
      return cached || fetch(event.request).then(response => {
        // Cache successful GET requests
        if (event.request.method === 'GET' && response.ok) {
          const responseClone = response.clone();
          caches.open('v1').then(cache => {
            cache.put(event.request, responseClone);
          });
        }
        return response;
      });
    })
  );
});
```

### Request Deduplication

Avoid duplicate concurrent requests:

```javascript
class FetchDeduplicator {
  constructor() {
    this.pending = new Map();
  }
  
  async fetch(url, options = {}) {
    const key = this.createKey(url, options);
    
    if (this.pending.has(key)) {
      // Return existing promise
      return this.pending.get(key);
    }
    
    const promise = fetch(url, options)
      .then(response => {
        // Clone for multiple consumers if supported
        if (typeof response.clone === 'function') {
          return response;
        }
        return response;
      })
      .finally(() => {
        this.pending.delete(key);
      });
    
    this.pending.set(key, promise);
    return promise;
  }
  
  createKey(url, options) {
    return `${options.method || 'GET'}:${url}`;
  }
}

const deduplicator = new FetchDeduplicator();
```

### Request Prioritization

Queue and prioritize requests based on importance:

```javascript
class FetchQueue {
  constructor(concurrency = 6) {
    this.concurrency = concurrency;
    this.running = 0;
    this.queue = [];
  }
  
  async fetch(url, options = {}, priority = 0) {
    return new Promise((resolve, reject) => {
      this.queue.push({
        url,
        options,
        priority,
        resolve,
        reject
      });
      
      // Sort by priority (higher first)
      this.queue.sort((a, b) => b.priority - a.priority);
      
      this.processQueue();
    });
  }
  
  async processQueue() {
    while (this.running < this.concurrency && this.queue.length > 0) {
      const task = this.queue.shift();
      this.running++;
      
      try {
        const response = await fetch(task.url, task.options);
        task.resolve(response);
      } catch (error) {
        task.reject(error);
      } finally {
        this.running--;
        this.processQueue();
      }
    }
  }
}

const queue = new FetchQueue();

// Usage
queue.fetch('/critical', {}, 10); // High priority
queue.fetch('/analytics', {}, 1); // Low priority
```

### Response Type Negotiation

Request appropriate formats based on support:

```javascript
async function fetchWithFormatNegotiation(url, options = {}) {
  const supportedFormats = [];
  
  // Check modern format support
  if (typeof WebP !== 'undefined' || 
      document.createElement('canvas').toDataURL('image/webp').indexOf('data:image/webp') === 0) {
    supportedFormats.push('image/webp');
  }
  
  if (typeof AVIF !== 'undefined') {
    supportedFormats.push('image/avif');
  }
  
  supportedFormats.push('image/jpeg', 'image/png');
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Accept': supportedFormats.join(', ')
    }
  });
}
```

### Bandwidth-Aware Loading

Adjust quality based on available bandwidth:

```javascript
function getImageQuality() {
  if (!('connection' in navigator)) {
    return 'high';
  }
  
  const conn = navigator.connection;
  
  // [Inference] These mappings represent common quality tiers
  if (conn.saveData) {
    return 'low';
  }
  
  if (conn.effectiveType === '4g' && conn.downlink > 5) {
    return 'high';
  }
  
  if (conn.effectiveType === '3g' || conn.effectiveType === '4g') {
    return 'medium';
  }
  
  return 'low';
}

async function fetchImage(baseUrl) {
  const quality = getImageQuality();
  const url = `${baseUrl}?quality=${quality}`;
  
  return fetch(url);
}
```

### Offline Support with Background Sync

Queue requests when offline, sync when online:

```javascript
class OfflineQueue {
  constructor(dbName = 'offline-queue') {
    this.dbName = dbName;
    this.init();
  }
  
  async init() {
    if (typeof indexedDB === 'undefined') {
      this.fallbackQueue = [];
      return;
    }
    
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, 1);
      
      request.onerror = () => reject(request.error);
      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };
      
      request.onupgradeneeded = (event) => {
        const db = event.target.result;
        if (!db.objectStoreNames.contains('requests')) {
          db.createObjectStore('requests', { autoIncrement: true });
        }
      };
    });
  }
  
  async add(url, options) {
    if (!this.db) {
      this.fallbackQueue.push({ url, options });
      return;
    }
    
    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction(['requests'], 'readwrite');
      const store = transaction.objectStore('requests');
      const request = store.add({ url, options, timestamp: Date.now() });
      
      request.onsuccess = () => resolve();
      request.onerror = () => reject(request.error);
    });
  }
  
  async processQueue() {
    if (!navigator.onLine) return;
    
    // Process fallback queue
    if (this.fallbackQueue && this.fallbackQueue.length > 0) {
      for (const item of this.fallbackQueue) {
        try {
          await fetch(item.url, item.options);
        } catch (error) {
          console.error('Failed to sync:', error);
        }
      }
      this.fallbackQueue = [];
      return;
    }
    
    if (!this.db) return;
    
    const transaction = this.db.transaction(['requests'], 'readonly');
    const store = transaction.objectStore('requests');
    const request = store.getAll();
    
    request.onsuccess = async () => {
      const items = request.result;
      
      for (const item of items) {
        try {
          await fetch(item.url, item.options);
          // Remove from queue on success
          const deleteTransaction = this.db.transaction(['requests'], 'readwrite');
          const deleteStore = deleteTransaction.objectStore('requests');
          deleteStore.delete(item.id);
        } catch (error) {
          console.error('Failed to sync:', error);
        }
      }
    };
  }
}

const offlineQueue = new OfflineQueue();

window.addEventListener('online', () => {
  offlineQueue.processQueue();
});

async function resilientFetch(url, options = {}) {
  if (!navigator.onLine) {
    await offlineQueue.add(url, options);
    throw new Error('Offline: queued for later');
  }
  
  try {
    return await fetch(url, options);
  } catch (error) {
    if (!navigator.onLine) {
      await offlineQueue.add(url, options);
      throw new Error('Offline: queued for later');
    }
    throw error;
  }
}
```

### Progressive Response Processing

Start rendering before complete response:

```javascript
async function fetchAndRenderProgressive(url, onChunk) {
  const response = await fetch(url);
  
  // Check for streaming support
  if (!response.body || typeof ReadableStream === 'undefined') {
    const data = await response.text();
    onChunk(data, true);
    return;
  }
  
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  
  while (true) {
    const {done, value} = await reader.read();
    
    if (done) {
      if (buffer) {
        onChunk(buffer, true);
      }
      break;
    }
    
    buffer += decoder.decode(value, {stream: true});
    
    // Process complete lines
    const lines = buffer.split('\n');
    buffer = lines.pop(); // Keep incomplete line
    
    for (const line of lines) {
      if (line.trim()) {
        onChunk(line, false);
      }
    }
  }
}
```

### Prefetch Strategies

Intelligently prefetch based on user behavior:

```javascript
class PrefetchManager {
  constructor() {
    this.prefetched = new Set();
    this.observer = null;
    
    if ('IntersectionObserver' in window) {
      this.setupIntersectionObserver();
    }
  }
  
  setupIntersectionObserver() {
    this.observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          const url = entry.target.dataset.prefetch;
          if (url && !this.prefetched.has(url)) {
            this.prefetch(url);
          }
        }
      });
    }, { rootMargin: '50px' });
  }
  
  async prefetch(url) {
    if (this.prefetched.has(url)) return;
    
    this.prefetched.add(url);
    
    // Use low priority if supported
    const options = {};
    if ('priority' in Request.prototype) {
      options.priority = 'low';
    }
    
    try {
      const response = await fetch(url, options);
      
      // Cache if service worker available
      if ('caches' in window) {
        const cache = await caches.open('prefetch-v1');
        cache.put(url, response.clone());
      }
    } catch (error) {
      console.warn('Prefetch failed:', url);
      this.prefetched.delete(url);
    }
  }
  
  observe(element) {
    if (this.observer) {
      this.observer.observe(element);
    } else {
      // Fallback: prefetch on hover
      element.addEventListener('mouseenter', () => {
        const url = element.dataset.prefetch;
        if (url) this.prefetch(url);
      }, { once: true });
    }
  }
}

const prefetcher = new PrefetchManager();
```

### Coordinated Multi-Request Loading

Load related resources efficiently:

```javascript
async function fetchDependencies(urls, options = {}) {
  // Check if we can use parallel loading
  const canParallel = typeof Promise.all === 'function';
  
  if (canParallel) {
    // Modern: parallel requests
    return Promise.all(urls.map(url => fetch(url, options)));
  }
  
  // Fallback: sequential
  const results = [];
  for (const url of urls) {
    results.push(await fetch(url, options));
  }
  return results;
}

async function fetchWithDependencies(primaryUrl, dependencyUrls = []) {
  // Start primary request
  const primaryPromise = fetch(primaryUrl);
  
  // Start dependencies with lower priority if supported
  const dependencyOptions = {};
  if ('priority' in Request.prototype) {
    dependencyOptions.priority = 'low';
  }
  
  const dependencyPromises = dependencyUrls.map(url => 
    fetch(url, dependencyOptions)
  );
  
  // Wait for primary first
  const primary = await primaryPromise;
  
  // Then wait for dependencies
  const dependencies = await Promise.all(dependencyPromises);
  
  return { primary, dependencies };
}
```

### Complete Progressive Enhancement Wrapper

Combine all layers into unified interface:

```javascript
class EnhancedFetch {
  constructor(config = {}) {
    this.config = {
      timeout: 5000,
      retries: 3,
      deduplicate: true,
      queue: true,
      offline: true,
      concurrency: 6,
      ...config
    };
    
    if (this.config.deduplicate) {
      this.deduplicator = new FetchDeduplicator();
    }
    
    if (this.config.queue) {
      this.queue = new FetchQueue(this.config.concurrency);
    }
    
    if (this.config.offline) {
      this.offlineQueue = new OfflineQueue();
    }
  }
  
  async fetch(url, options = {}) {
    // Layer 1: Check basic fetch support
    if (typeof fetch === 'undefined') {
      return this.xhrFallback(url, options);
    }
    
    // Layer 2: Offline handling
    if (this.config.offline && !navigator.onLine) {
      await this.offlineQueue.add(url, options);
      throw new Error('Offline: request queued');
    }
    
    // Layer 3: Deduplication
    if (this.config.deduplicate && options.method !== 'POST') {
      return this.deduplicator.fetch(url, options);
    }
    
    // Layer 4: Queue management
    if (this.config.queue) {
      return this.queue.fetch(url, options, options.priority || 0);
    }
    
    // Layer 5: Network-aware with retry and timeout
    return this.enhancedFetch(url, options);
  }
  
  async enhancedFetch(url, options) {
    const strategy = getNetworkStrategy();
    const timeout = this.getTimeoutForStrategy(strategy);
    
    return fetchWithRetry(
      url,
      options,
      this.config.retries
    ).then(response => 
      this.addTimeoutToResponse(response, timeout)
    );
  }
  
  getTimeoutForStrategy(strategy) {
    const timeouts = {
      minimal: 15000,
      moderate: 10000,
      full: this.config.timeout
    };
    return timeouts[strategy] || this.config.timeout;
  }
  
  async addTimeoutToResponse(response, timeout) {
    if (typeof AbortController === 'undefined') {
      return response;
    }
    
    // Wrap response body with timeout
    if (response.body && typeof ReadableStream !== 'undefined') {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      const reader = response.body.getReader();
      const stream = new ReadableStream({
        async start(controller) {
          try {
            while (true) {
              const {done, value} = await reader.read();
              if (done) break;
              controller.enqueue(value);
            }
            controller.close();
          } catch (error) {
            controller.error(error);
          } finally {
            clearTimeout(timeoutId);
          }
        }
      });
      
      return new Response(stream, {
        headers: response.headers,
        status: response.status,
        statusText: response.statusText
      });
    }
    
    return response;
  }
  
  xhrFallback(url, options) {
    return request(url, options);
  }
}

// Usage
const client = new EnhancedFetch({
  timeout: 5000,
  retries: 3,
  deduplicate: true,
  queue: true,
  offline: true
});

await client.fetch('/api/data');
```

---

## Fetch API Browser-Specific Issues

### Internet Explorer Compatibility

Internet Explorer 11 and earlier versions lack native fetch support. Polyfills like `whatwg-fetch` or `unfetch` are required for compatibility. These polyfills translate fetch calls into XMLHttpRequest operations under the hood.

```javascript
// Polyfill detection
if (!window.fetch) {
  // Load polyfill
  import('whatwg-fetch');
}
```

### Safari and Webkit-Specific Behaviors

#### Credential Handling

Safari historically had stricter same-origin policies for credentials. The `credentials` option behaves differently:

```javascript
// May require explicit credentials mode in Safari
fetch('/api/data', {
  credentials: 'same-origin' // or 'include'
});
```

Safari versions before 10.1 didn't support `credentials: 'same-origin'` properly, defaulting to `'omit'`.

#### CORS Preflight Caching

Safari caches CORS preflight responses more aggressively than other browsers. The `Access-Control-Max-Age` header may be ignored or capped at lower values (typically 600 seconds vs 86400 in Chrome).

#### Service Worker Limitations

Older Safari versions (before 11.1) had no Service Worker support, making fetch-based caching strategies impossible. Versions 11.1-13 had partial implementations with bugs around `fetch()` event handling.

### Firefox Peculiarities

#### Request Body Streaming

Firefox had delayed support for streaming request bodies. Versions before 105 couldn't stream `ReadableStream` bodies:

```javascript
// May not work in Firefox < 105
const stream = new ReadableStream({
  start(controller) {
    controller.enqueue(new Uint8Array([1, 2, 3]));
    controller.close();
  }
});

fetch('/upload', {
  method: 'POST',
  body: stream
});
```

#### Network Error Details

Firefox provides less detailed error information for network failures compared to Chrome DevTools. Failed fetches often return generic `TypeError: NetworkError` without specific status codes or reasons.

### Chrome/Chromium Edge Issues

#### Memory Management for Large Responses

Chrome can exhibit memory bloat when repeatedly fetching large responses without proper cleanup. Explicitly calling `.blob()` or `.arrayBuffer()` and releasing references is important:

```javascript
async function fetchLargeFile() {
  const response = await fetch('/large-file');
  const blob = await response.blob();
  // Use blob
  // Blob will be GC'd when reference is lost
}
```

#### Credential Behavior in Private Mode

Chrome's Incognito mode handles cookies and credentials differently. Fetch requests may silently fail or omit credentials even with `credentials: 'include'` if third-party cookies are blocked.

#### Request Abortion Edge Cases

Chrome versions before 90 had race conditions where aborting a fetch with `AbortController` could leave the connection in an inconsistent state, particularly with HTTP/2 multiplexed streams.

### Cross-Browser CORS Inconsistencies

#### Opaque Response Handling

Browsers differ in how they expose information about opaque responses (from `no-cors` mode):

```javascript
const response = await fetch('https://external.com/resource', {
  mode: 'no-cors'
});

// response.ok is always false
// response.status is always 0
// response.type is 'opaque'
// Body cannot be read
```

Safari may cache opaque responses differently than Chrome, leading to inconsistent behavior across page reloads.

#### Redirect Handling

Firefox and Safari historically handled redirects with method changes differently:

- POST requests redirected with 301/302 should preserve method per modern specs
- Older implementations changed POST to GET on redirect
- The `redirect: 'follow'` option behavior varies between browsers for cross-origin redirects

### Mobile Browser Constraints

#### iOS Safari Background Limitations

iOS Safari suspends fetch requests when the app enters background mode. Long-running fetches may fail with timeout errors:

```javascript
// May fail if app is backgrounded
fetch('/long-operation', {
  signal: AbortSignal.timeout(30000) // 30 second timeout
});
```

#### Android WebView Variations

Android WebView implementations vary by OS version:

- Android 4.4-5.0: No native fetch, requires polyfill
- Android 5.0-7.0: Partial implementation with bugs
- Android 8.0+: Full support but may have vendor-specific customizations

Chrome Custom Tabs and WebView use different JavaScript engines, leading to inconsistent behavior in hybrid apps.

### Headers API Differences

#### Case Sensitivity

While HTTP headers are case-insensitive by spec, browser implementations differ:

```javascript
const headers = new Headers();
headers.append('Content-Type', 'application/json');

// Chrome normalizes to lowercase
headers.get('content-type'); // Works in all browsers

// Some browsers preserve original casing internally
headers.forEach((value, name) => {
  console.log(name); // Casing may differ
});
```

#### Forbidden Headers

Browsers restrict setting certain headers for security. The list varies slightly:

- `Host`, `Connection`, `Origin` - universally forbidden
- `Referer` - forbidden in most browsers, but some allow partial control
- `User-Agent` - forbidden in Chrome/Safari, allowed in Firefox (deprecated)

### TLS/SSL Certificate Issues

#### Self-Signed Certificates

Chrome and Firefox handle self-signed certificates differently in development:

- Chrome: Shows warning, allows bypass with user action
- Firefox: Similar warning but different bypass mechanism
- Safari: Stricter, may require certificate installation in keychain

Fetch requests to HTTPS endpoints with invalid certificates fail silently without detailed errors in production builds.

### Request Timeout Handling

No native timeout support exists in the Fetch API. The `AbortSignal.timeout()` method is a recent addition:

```javascript
// Modern approach (Chrome 103+, Firefox 100+, Safari 16+)
try {
  const response = await fetch('/api', {
    signal: AbortSignal.timeout(5000)
  });
} catch (error) {
  if (error.name === 'TimeoutError') {
    // Handle timeout
  }
}
```

Older browsers require manual timeout implementation:

```javascript
// Legacy approach
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 5000);

try {
  const response = await fetch('/api', {
    signal: controller.signal
  });
} finally {
  clearTimeout(timeoutId);
}
```

### Cookie and Storage Quota Limits

#### Cookie Size Limitations

Browsers impose different cookie size limits affecting fetch with credentials:

- Chrome: 4096 bytes per cookie
- Firefox: 4097 bytes per cookie
- Safari: 4093 bytes per cookie

Exceeding limits causes cookies to be silently truncated or rejected, affecting authentication state.

#### Cache API Quota

Browser storage quotas for Cache API (used with fetch caching) vary:

- Chrome: ~60% of available disk space
- Firefox: ~50% of available disk space, 2GB limit per origin
- Safari: More restrictive, often 50MB-1GB depending on device

### HTTP/2 and HTTP/3 Support

#### Protocol Version Inconsistencies

Browser support for newer HTTP versions affects fetch performance:

- HTTP/2: Universal support, but server push handling differs
- HTTP/3 (QUIC): Chrome 87+, Edge 87+, Firefox 88+, Safari 14+
- Fallback behavior varies when HTTP/3 is unavailable

#### Server Push Handling

Chrome's implementation of HTTP/2 server push differs from Firefox. Fetch requests may receive pushed resources differently:

```javascript
// Chrome caches pushed resources more aggressively
// Firefox may re-request resources despite server push
```

### Blob and File Upload Differences

#### Multipart Form Data

Browsers construct multipart/form-data boundaries differently:

```javascript
const formData = new FormData();
formData.append('file', blob, 'filename.txt');

// Boundary generation algorithm varies
// Content-Type header format may differ slightly
fetch('/upload', {
  method: 'POST',
  body: formData
});
```

Chrome, Firefox, and Safari use different boundary string formats, though all are spec-compliant.

### Developer Tools Integration

#### Network Panel Information

Browser DevTools expose different levels of detail:

- Chrome: Full request/response timing, protocol info, push events
- Firefox: Similar detail, different UI organization
- Safari: Less detailed timing information, especially for cached responses

#### Request Body Inspection

DevTools differ in how they display request bodies:

- Chrome: Shows formatted JSON, preserves FormData structure
- Firefox: Shows raw payload, may not decode binary data
- Safari: Limited formatting, especially for streaming bodies

### Feature Detection Patterns

[Inference] Reliable feature detection helps manage browser differences:

```javascript
// Check for streaming body support
const supportsRequestStreams = (() => {
  try {
    new Request('', {
      body: new ReadableStream(),
      method: 'POST'
    });
    return true;
  } catch {
    return false;
  }
})();

// Check for AbortSignal.timeout
const supportsTimeoutSignal = 'timeout' in AbortSignal;

// Check for response.blob() streaming
const supportsResponseStreaming = (() => {
  const response = new Response('');
  return typeof response.body?.getReader === 'function';
})();
```

### Proxy and VPN Complications

#### Corporate Proxies

Enterprise proxies may interfere with fetch requests:

- CONNECT method tunneling varies
- SSL interception affects certificate validation
- Custom headers may be stripped or modified

Chrome and Firefox handle proxy authentication prompts differently, with Chrome showing system-level dialogs and Firefox using in-browser prompts.

#### VPN and Network Switching

Mobile browsers exhibit different behaviors when network switches occur mid-request:

- iOS Safari: Typically aborts in-flight requests
- Chrome Mobile: Attempts to retry on new network
- Firefox Mobile: May hang indefinitely until timeout

### Response Type Handling

#### JSON Parsing Differences

While `response.json()` is standardized, error handling differs:

```javascript
try {
  const data = await response.json();
} catch (error) {
  // Chrome: SyntaxError with detailed message
  // Firefox: SyntaxError with less detail
  // Safari: May throw different error types for encoding issues
}
```

#### Streaming Response Processing

Chrome and Firefox differ in how they handle backpressure in response streams:

```javascript
const reader = response.body.getReader();
while (true) {
  const {done, value} = await reader.read();
  if (done) break;
  // Chrome applies backpressure more aggressively
  // Firefox may buffer more data in memory
  processChunk(value);
}
```

### CSP (Content Security Policy) Interactions

Browsers enforce CSP `connect-src` directive differently for fetch:

- Chrome: Strict enforcement, blocks on violation
- Firefox: Similar enforcement with better error messages
- Safari: May allow data: URIs even when not in policy

### Service Worker Fetch Event Quirks

#### Navigation Preload

Chrome supports navigation preload, Firefox and Safari have limited or no support:

```javascript
// Chrome only (as of recent versions)
self.addEventListener('activate', event => {
  event.waitUntil(self.registration.navigationPreload.enable());
});
```

#### Request Interception Timing

Safari's Service Worker implementation has timing issues where fetch events may be fired inconsistently compared to Chrome/Firefox, particularly during page navigation.

---

## Fetch API: Mobile Browser Considerations

### Network Connectivity Variations

#### Cellular Network Transitions

Mobile devices frequently transition between network types (4G/5G, WiFi, airplane mode). Active fetch requests may fail mid-transfer during these transitions. Implement retry logic with exponential backoff:

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      return response;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, i) * 1000));
    }
  }
}
```

#### Connection Quality Detection

Mobile networks exhibit variable latency and bandwidth. The Network Information API provides connection characteristics:

```javascript
if ('connection' in navigator) {
  const connection = navigator.connection;
  const effectiveType = connection.effectiveType; // '4g', '3g', '2g', 'slow-2g'
  
  if (effectiveType === 'slow-2g' || effectiveType === '2g') {
    // Reduce payload size, increase timeout
  }
}
```

**[Inference]** Connection quality metrics suggest appropriate timeout values, though actual performance varies by location and carrier.

#### Offline-First Patterns

Mobile devices lose connectivity regularly. Service Workers combined with fetch enable offline operation:

```javascript
self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request)
      .then(cached => cached || fetch(event.request))
      .catch(() => caches.match('/offline.html'))
  );
});
```

Background Sync API queues fetch requests when offline:

```javascript
// Register sync when offline
if ('serviceWorker' in navigator && 'sync' in self.registration) {
  await self.registration.sync.register('sync-posts');
}

// Execute when connection restored
self.addEventListener('sync', (event) => {
  if (event.tag === 'sync-posts') {
    event.waitUntil(syncPendingPosts());
  }
});
```

### Memory Constraints

#### Streaming Large Responses

Mobile devices have limited RAM compared to desktop systems. Stream large responses rather than loading entirely into memory:

```javascript
const response = await fetch('/large-file.json');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, { stream: true });
  processChunk(chunk); // Process incrementally
}
```

#### Request Body Streaming

Uploading large files consumes memory. Stream request bodies when supported:

```javascript
async function* fileChunkGenerator(file) {
  const chunkSize = 64 * 1024; // 64KB chunks
  let offset = 0;
  
  while (offset < file.size) {
    const chunk = file.slice(offset, offset + chunkSize);
    yield await chunk.arrayBuffer();
    offset += chunkSize;
  }
}

const stream = new ReadableStream({
  async start(controller) {
    for await (const chunk of fileChunkGenerator(file)) {
      controller.enqueue(new Uint8Array(chunk));
    }
    controller.close();
  }
});

await fetch('/upload', {
  method: 'POST',
  body: stream,
  duplex: 'half' // Required for request streaming
});
```

#### Response Cloning Caution

Cloning responses duplicates data in memory. Avoid unless necessary:

```javascript
// Problematic on mobile
const response = await fetch('/data');
const clone = response.clone();
const data1 = await response.json();
const data2 = await clone.json();

// Better approach
const response = await fetch('/data');
const data = await response.json();
// Use data for multiple purposes
```

### Battery and Power Management

#### Request Batching

Frequent small requests drain battery by keeping radio active. Batch operations:

```javascript
// Instead of multiple requests
for (const id of ids) {
  await fetch(`/api/item/${id}`);
}

// Batch into single request
await fetch('/api/items', {
  method: 'POST',
  body: JSON.stringify({ ids })
});
```

#### Request Prioritization

The Priority Hints API influences browser scheduling:

```javascript
// Critical data fetch
fetch('/api/user', { priority: 'high' });

// Background analytics
fetch('/analytics', { priority: 'low' });

// Preload resources
fetch('/future-data', { priority: 'low' });
```

**[Unverified]** Browser adherence to priority hints varies across mobile browsers and may not consistently affect power consumption.

#### Background Fetch API

Large downloads continue when app is backgrounded or closed:

```javascript
if ('BackgroundFetchManager' in self) {
  const registration = await navigator.serviceWorker.ready;
  await registration.backgroundFetch.fetch('download-id', ['/large-file.zip'], {
    title: 'Downloading content',
    icons: [{ src: '/icon.png', sizes: '300x300', type: 'image/png' }],
    downloadTotal: 50 * 1024 * 1024 // 50MB
  });
}
```

### Browser-Specific Limitations

#### iOS Safari Restrictions

iOS Safari implements stricter fetch behavior than other mobile browsers.

##### Request Limitations in Background

Fetch requests in background tabs or when app is inactive face aggressive termination. Requests typically timeout after 30 seconds when backgrounded.

**[Inference]** This appears designed to conserve battery and system resources, though Apple doesn't document specific timeouts.

##### Private Browsing Mode

Private browsing restricts persistent storage. Service Worker caching and IndexedDB may be unavailable:

```javascript
try {
  await caches.open('my-cache');
} catch (error) {
  // Handle private browsing mode
  console.warn('Caching unavailable');
}
```

##### WebKit Cookie Restrictions

iOS Safari's Intelligent Tracking Prevention affects fetch with credentials:

```javascript
// May not send cookies in cross-origin requests
fetch('https://api.example.com/data', {
  credentials: 'include'
});
```

#### Android Chrome Considerations

##### Data Saver Mode

When Data Saver is enabled, Chrome may proxy requests through Google servers, compressing responses and potentially modifying headers.

##### Lite Mode Warnings

Chrome Lite Mode optimizes resources. Requests may be delayed or modified for bandwidth reduction.

#### Samsung Internet

Samsung Internet includes enhanced tracking protection and ad blocking that may affect fetch requests to third-party domains.

### Request Timeout Handling

#### Mobile-Appropriate Timeouts

Mobile networks have higher latency than desktop broadband. Implement longer, adaptive timeouts:

```javascript
const controller = new AbortController();
const timeout = connection?.effectiveType === '2g' ? 30000 : 10000;

const timeoutId = setTimeout(() => controller.abort(), timeout);

try {
  const response = await fetch(url, { signal: controller.signal });
  clearTimeout(timeoutId);
  return response;
} catch (error) {
  if (error.name === 'AbortError') {
    // Handle timeout
  }
}
```

#### Progressive Timeout Strategy

Increase timeout duration for retries:

```javascript
async function fetchWithProgressiveTimeout(url, baseTimeout = 5000) {
  let attempt = 0;
  
  while (attempt < 3) {
    const controller = new AbortController();
    const timeout = baseTimeout * Math.pow(2, attempt);
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    try {
      const response = await fetch(url, { signal: controller.signal });
      clearTimeout(timeoutId);
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      if (attempt === 2 || error.name !== 'AbortError') throw error;
      attempt++;
    }
  }
}
```

### CORS and Mobile-Specific Issues

#### Preflight Request Overhead

Mobile networks have higher latency, making CORS preflight requests costly. Minimize by using simple requests when possible:

```javascript
// Simple request (no preflight)
fetch('https://api.example.com/data', {
  method: 'GET',
  headers: {
    'Accept': 'application/json'
  }
});

// Triggers preflight
fetch('https://api.example.com/data', {
  method: 'GET',
  headers: {
    'X-Custom-Header': 'value',
    'Accept': 'application/json'
  }
});
```

#### Mixed Content Blocking

Mobile browsers strictly enforce HTTPS requirements. Fetch to HTTP resources from HTTPS pages fails:

```javascript
// Fails on HTTPS page
fetch('http://insecure-api.com/data');

// Upgrade to HTTPS
fetch('https://insecure-api.com/data');
```

### Headers and Mobile Optimization

#### Compression Headers

Explicitly request compression to reduce mobile data usage:

```javascript
fetch(url, {
  headers: {
    'Accept-Encoding': 'gzip, deflate, br'
  }
});
```

Most browsers send this automatically, but explicit inclusion ensures consistency.

#### Accept Headers for Mobile Content

Request mobile-optimized content variants:

```javascript
fetch('/api/content', {
  headers: {
    'Accept': 'application/json',
    'X-Requested-With': 'XMLHttpRequest',
    'Viewport-Width': window.innerWidth.toString()
  }
});
```

**[Inference]** Server-side adaptation based on viewport requires custom implementation; this isn't standardized behavior.

### Cache Strategies for Mobile

#### Cache-Control Directives

Leverage browser caching aggressively on mobile to reduce network usage:

```javascript
fetch('/static/data.json', {
  headers: {
    'Cache-Control': 'max-age=3600, stale-while-revalidate=86400'
  }
});
```

**Note:** Cache-Control in request headers suggests preferences but doesn't override server directives.

#### Service Worker Caching Strategies

Implement different strategies based on resource type:

```javascript
self.addEventListener('fetch', (event) => {
  const url = new URL(event.request.url);
  
  // Cache-first for static assets
  if (url.pathname.startsWith('/static/')) {
    event.respondWith(
      caches.match(event.request)
        .then(cached => cached || fetch(event.request))
    );
  }
  
  // Network-first for API calls
  if (url.pathname.startsWith('/api/')) {
    event.respondWith(
      fetch(event.request)
        .catch(() => caches.match(event.request))
    );
  }
  
  // Stale-while-revalidate for dynamic content
  if (url.pathname.startsWith('/content/')) {
    event.respondWith(
      caches.match(event.request)
        .then(cached => {
          const fetchPromise = fetch(event.request)
            .then(response => {
              caches.open('dynamic-v1').then(cache => {
                cache.put(event.request, response.clone());
              });
              return response;
            });
          return cached || fetchPromise;
        })
    );
  }
});
```

### Debugging Mobile Fetch Issues

#### Remote Debugging

Use remote debugging tools for real device testing:

- Chrome DevTools for Android via USB debugging
- Safari Web Inspector for iOS via cable connection

#### Network Throttling Simulation

Simulate mobile network conditions in desktop DevTools:

```javascript
// Add artificial delays for testing
async function fetchWithSimulatedLatency(url, latency = 1000) {
  await new Promise(resolve => setTimeout(resolve, latency));
  return fetch(url);
}
```

#### Logging Connection State

Monitor network changes during fetch operations:

```javascript
let currentConnection = navigator.connection?.effectiveType;

navigator.connection?.addEventListener('change', () => {
  console.log('Connection changed:', {
    from: currentConnection,
    to: navigator.connection.effectiveType
  });
  currentConnection = navigator.connection.effectiveType;
});

fetch('/api/data')
  .then(response => {
    console.log('Fetch completed on:', currentConnection);
  });
```

### Performance Monitoring

#### Navigation Timing API

Measure fetch performance in context:

```javascript
const observer = new PerformanceObserver((list) => {
  for (const entry of list.getEntries()) {
    if (entry.initiatorType === 'fetch') {
      console.log({
        url: entry.name,
        duration: entry.duration,
        transferSize: entry.transferSize,
        decodedBodySize: entry.decodedBodySize
      });
    }
  }
});

observer.observe({ entryTypes: ['resource'] });
```

#### Custom Metrics Collection

Track fetch success rates and performance:

```javascript
const fetchMetrics = {
  attempts: 0,
  successes: 0,
  failures: 0,
  totalDuration: 0
};

async function monitoredFetch(url, options) {
  fetchMetrics.attempts++;
  const startTime = performance.now();
  
  try {
    const response = await fetch(url, options);
    fetchMetrics.successes++;
    return response;
  } catch (error) {
    fetchMetrics.failures++;
    throw error;
  } finally {
    fetchMetrics.totalDuration += performance.now() - startTime;
  }
}
```

### Security Considerations

#### Certificate Pinning Limitations

Mobile browsers don't support HTTP certificate pinning via fetch. Use platform-specific solutions for certificate validation in native wrappers.

#### Content Security Policy

CSP violations affect fetch differently on mobile. Test CSP directives across devices:

```javascript
// CSP may block this
fetch('https://third-party.com/api')
  .catch(error => {
    if (error.message.includes('CSP')) {
      console.error('CSP blocked request');
    }
  });
```

#### User Agent Spoofing Detection

Mobile environments may have inconsistent User-Agent strings. Avoid relying on UA for feature detection:

```javascript
// Bad practice
if (navigator.userAgent.includes('Mobile')) {
  // Mobile-specific code
}

// Better approach
if ('ontouchstart' in window && window.innerWidth < 768) {
  // Touch-enabled narrow viewport
}
```

### Progressive Web App Integration

#### Install Prompts and Fetch

PWA installation affects fetch behavior through Service Workers:

```javascript
window.addEventListener('beforeinstallprompt', (e) => {
  e.preventDefault();
  
  // After installation, Service Worker handles fetches
  window.addEventListener('appinstalled', () => {
    console.log('PWA installed - fetch now routed through SW');
  });
});
```

#### Add to Home Screen Caching

Pre-cache critical resources when PWA is installed:

```javascript
self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open('pwa-v1').then((cache) => {
      return cache.addAll([
        '/',
        '/styles/main.css',
        '/scripts/app.js',
        '/api/initial-data'
      ]);
    })
  );
});
```

### Browser Feature Detection

#### Capabilities Testing

Check feature availability before using advanced fetch capabilities:

```javascript
const capabilities = {
  streams: 'ReadableStream' in window,
  requestStreaming: 'duplex' in Request.prototype,
  backgroundFetch: 'BackgroundFetchManager' in self,
  priorityHints: 'priority' in Request.prototype,
  abortController: 'AbortController' in window
};

// Adapt behavior based on capabilities
if (!capabilities.abortController) {
  // Fallback for timeout handling
}
```

#### Polyfill Strategies

Load polyfills conditionally for older mobile browsers:

```javascript
if (!window.fetch) {
  // Load fetch polyfill
  await import('whatwg-fetch');
}

if (!window.AbortController) {
  await import('abortcontroller-polyfill');
}
```

### Data Usage Optimization

#### Conditional Requests

Use ETags and Last-Modified headers to avoid re-downloading unchanged data:

```javascript
const cachedETag = localStorage.getItem('data-etag');

const response = await fetch('/api/data', {
  headers: cachedETag ? { 'If-None-Match': cachedETag } : {}
});

if (response.status === 304) {
  // Use cached data
  return JSON.parse(localStorage.getItem('data'));
}

localStorage.setItem('data-etag', response.headers.get('ETag'));
const data = await response.json();
localStorage.setItem('data', JSON.stringify(data));
return data;
```

#### Range Requests

Download large files in chunks:

```javascript
async function fetchInRanges(url, chunkSize = 1024 * 1024) { // 1MB chunks
  const headResponse = await fetch(url, { method: 'HEAD' });
  const fileSize = parseInt(headResponse.headers.get('Content-Length'));
  
  const chunks = [];
  for (let start = 0; start < fileSize; start += chunkSize) {
    const end = Math.min(start + chunkSize - 1, fileSize - 1);
    const response = await fetch(url, {
      headers: { 'Range': `bytes=${start}-${end}` }
    });
    chunks.push(await response.blob());
  }
  
  return new Blob(chunks);
}
```

#### Delta Updates

Fetch only changed portions of data:

```javascript
const lastSync = localStorage.getItem('last-sync');

const response = await fetch(`/api/updates?since=${lastSync}`);
const updates = await response.json();

// Merge updates with existing data
const existingData = JSON.parse(localStorage.getItem('data'));
const mergedData = applyUpdates(existingData, updates);

localStorage.setItem('data', JSON.stringify(mergedData));
localStorage.setItem('last-sync', new Date().toISOString());
```

---

## Legacy Browser Support

### Polyfills and Shims

The Fetch API is not natively supported in Internet Explorer (any version) or older versions of Safari, Chrome, Firefox, and Edge. A polyfill provides the necessary functionality for these browsers.

The most widely used polyfill is `whatwg-fetch` (GitHub's fetch polyfill):

```javascript
// Installation via npm
npm install whatwg-fetch

// Usage
import 'whatwg-fetch';

// Or via CDN
<script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.js"></script>
```

Alternative polyfills include `unfetch` (lighter weight) and `isomorphic-fetch` (for Node.js compatibility).

### Browser Support Matrix

**Native Support:**

- Chrome 42+ (April 2015)
- Firefox 39+ (July 2015)
- Safari 10.1+ (March 2017)
- Edge 14+ (August 2016)
- Opera 29+ (April 2015)

**No Native Support:**

- Internet Explorer (all versions)
- Safari < 10.1
- Android Browser < 4.4

### Polyfill Limitations

Polyfills cannot perfectly replicate all Fetch API features:

**Streaming Responses:** The `ReadableStream` interface used by `response.body` is difficult to polyfill. Most polyfills do not support streaming and must buffer the entire response.

**Request Abortion:** While modern polyfills support `AbortController`, older polyfills may not handle abortion correctly, particularly with XMLHttpRequest limitations.

**Upload Progress:** The Fetch API does not provide native upload progress events. Polyfills cannot add this functionality without additional APIs.

**Credentials Behavior:** Some polyfills may have subtle differences in how `credentials: 'include'` or `credentials: 'same-origin'` behave across domains.

### Feature Detection

Always check for fetch support before relying on it:

```javascript
if (window.fetch) {
  // Use fetch
  fetch('/api/data')
    .then(response => response.json())
    .then(data => console.log(data));
} else {
  // Fallback to XMLHttpRequest
  var xhr = new XMLHttpRequest();
  xhr.open('GET', '/api/data');
  xhr.onload = function() {
    console.log(JSON.parse(xhr.responseText));
  };
  xhr.send();
}
```

### XMLHttpRequest Fallback

For environments where polyfills are not suitable, XMLHttpRequest remains the fallback:

```javascript
function fetchWithFallback(url, options = {}) {
  if (window.fetch) {
    return fetch(url, options);
  }
  
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open(options.method || 'GET', url);
    
    // Set headers
    if (options.headers) {
      Object.keys(options.headers).forEach(key => {
        xhr.setRequestHeader(key, options.headers[key]);
      });
    }
    
    xhr.onload = () => {
      resolve({
        ok: xhr.status >= 200 && xhr.status < 300,
        status: xhr.status,
        statusText: xhr.statusText,
        json: () => Promise.resolve(JSON.parse(xhr.responseText)),
        text: () => Promise.resolve(xhr.responseText)
      });
    };
    
    xhr.onerror = () => reject(new Error('Network error'));
    xhr.send(options.body || null);
  });
}
```

### Polyfill Dependencies

Fetch polyfills typically require additional polyfills for older browsers:

**Promise:** Fetch returns promises, so a Promise polyfill is required for IE11 and older browsers.

```javascript
npm install promise-polyfill
```

**URL API:** Some fetch operations require the URL constructor.

```javascript
npm install url-polyfill
```

**AbortController:** For request cancellation in older browsers.

```javascript
npm install abortcontroller-polyfill
```

**Symbol:** Some polyfills use ES6 Symbols.

```javascript
npm install core-js
```

### Implementation Strategy

**Progressive Enhancement:**

```javascript
// Load polyfills conditionally
if (!window.fetch) {
  // Dynamically load polyfill
  const script = document.createElement('script');
  script.src = '/polyfills/fetch.js';
  document.head.appendChild(script);
}
```

**Bundler Configuration:**

With Webpack, use `@babel/preset-env` with `useBuiltIns: 'usage'`:

```javascript
// babel.config.js
module.exports = {
  presets: [
    ['@babel/preset-env', {
      useBuiltIns: 'usage',
      corejs: 3,
      targets: {
        ie: '11'
      }
    }]
  ]
};
```

**Polyfill Service:**

Use polyfill.io to serve polyfills based on user agent:

```html
<script src="https://polyfill.io/v3/polyfill.min.js?features=fetch"></script>
```

### CORS Considerations

Older browsers have stricter CORS implementations. The `mode` option may behave differently:

**IE11 CORS:** Does not support `credentials: 'include'` for cross-origin requests in the same way modern browsers do. Use `xhr.withCredentials = true` in XMLHttpRequest fallbacks.

**Safari CORS:** Older Safari versions (< 10.1) may have issues with preflight requests and custom headers.

### Testing Legacy Support

Test in actual legacy browsers or use services:

**BrowserStack:** Provides real browser testing environments including IE11.

**Sauce Labs:** Cloud-based cross-browser testing.

**Local VMs:** Set up virtual machines with older Windows versions and IE11.

### Performance Implications

Polyfills add bundle size overhead:

- `whatwg-fetch`: ~6KB minified
- Promise polyfill: ~3KB minified
- AbortController polyfill: ~4KB minified

Consider code-splitting to serve polyfills only to browsers that need them.

### Headers API Compatibility

The Headers constructor has limited support in polyfills:

```javascript
// This may not work in all polyfilled environments
const headers = new Headers();
headers.append('Content-Type', 'application/json');

// Use plain objects for better compatibility
const headers = {
  'Content-Type': 'application/json'
};
```

### FormData and File Uploads

Older polyfills may have issues with `FormData`:

```javascript
// Modern approach
const formData = new FormData();
formData.append('file', fileInput.files[0]);

fetch('/upload', {
  method: 'POST',
  body: formData
});

// May need special handling in IE11
```

### Response Type Handling

Not all response types are well-supported:

**Blob Support:** `response.blob()` may not work correctly in polyfills. Buffer the response as an ArrayBuffer instead.

**ArrayBuffer Support:** `response.arrayBuffer()` has better support than streaming alternatives.

**FormData Response:** `response.formData()` is rarely supported in polyfills.

### HTTP/2 and Protocol Considerations

Legacy browsers may not support HTTP/2, affecting:

- Request multiplexing benefits
- Server push features
- Header compression

The fetch polyfill will work but won't provide HTTP/2 advantages on older browsers.

### Deprecation Timeline

**[Inference]** Most organizations have dropped IE11 support as of 2022-2023, following Microsoft's official end of support in June 2022. Polyfill usage is decreasing as the minimum supported browser versions increase.

---

# Debugging

## Network Tab Analysis

### Request Headers

#### Standard Headers

Request headers provide metadata about the HTTP request being made. The `Accept` header specifies which content types the client can process, such as `application/json` or `text/html`. The `Accept-Encoding` header indicates supported compression algorithms like `gzip`, `deflate`, or `brotli`. The `Accept-Language` header communicates preferred languages for the response content.

The `User-Agent` header identifies the client application, browser version, and operating system. The `Referer` header indicates the URL of the page that initiated the request, useful for tracking navigation flows and identifying request origins.

#### Authentication Headers

The `Authorization` header carries credentials for authenticating requests. Common schemes include `Bearer` for token-based authentication, `Basic` for username/password combinations, and custom schemes for API keys. The `Cookie` header transmits stored cookies to the server, maintaining session state across requests.

#### Content Negotiation

The `Cache-Control` header directs caching behavior with values like `no-cache`, `no-store`, `max-age`, or `must-revalidate`. The `If-None-Match` header contains an ETag value for conditional requests, allowing servers to return 304 Not Modified when content hasn't changed. The `If-Modified-Since` header performs similar conditional requests based on timestamps.

#### CORS Headers

The `Origin` header identifies the domain making a cross-origin request. The `Access-Control-Request-Method` and `Access-Control-Request-Headers` headers appear in preflight OPTIONS requests, indicating the intended method and custom headers for the actual request.

### Response Headers

#### Status Information

The `Status` line contains the HTTP version, status code, and reason phrase. Status codes in the 2xx range indicate success, 3xx indicate redirects, 4xx indicate client errors, and 5xx indicate server errors.

The `Content-Type` header specifies the media type of the response body, including charset information like `application/json; charset=utf-8`. The `Content-Length` header indicates the size of the response body in bytes.

#### Caching Directives

The `Cache-Control` response header instructs clients and intermediary caches on how to handle the response. Values include `public` (cacheable by any cache), `private` (cacheable only by browser cache), `no-cache` (must revalidate before use), and `max-age` (seconds until expiration).

The `ETag` header provides a unique identifier for a specific version of a resource, enabling efficient caching through conditional requests. The `Expires` header specifies an absolute expiration date, though `Cache-Control: max-age` takes precedence when both exist.

The `Last-Modified` header indicates when the resource was last changed, supporting conditional requests via `If-Modified-Since`.

#### Security Headers

The `Strict-Transport-Security` header enforces HTTPS connections for a specified duration. The `Content-Security-Policy` header restricts resource loading to prevent XSS attacks. The `X-Frame-Options` header prevents clickjacking by controlling iframe embedding.

The `X-Content-Type-Options: nosniff` header prevents MIME type sniffing. The `Referrer-Policy` header controls how much referrer information is included with requests.

#### CORS Headers

The `Access-Control-Allow-Origin` header specifies which origins can access the response. The `Access-Control-Allow-Methods` header lists permitted HTTP methods. The `Access-Control-Allow-Headers` header indicates which request headers are allowed. The `Access-Control-Allow-Credentials` header determines whether credentials can be included in cross-origin requests.

The `Access-Control-Max-Age` header specifies how long preflight results can be cached.

### Timing Breakdown

#### Connection Phase

**Queueing** represents the time a request waits in the browser's queue before starting. Browsers limit concurrent connections per domain (typically 6), causing subsequent requests to queue. Service worker startup and priority-based scheduling also contribute to queueing time.

**Stalled** time occurs when a request is blocked from proceeding due to connection limits, proxy negotiation, or disk cache operations. High stalled time indicates connection pool saturation or resource contention.

**DNS Lookup** measures the time to resolve the domain name to an IP address. First requests to a domain show DNS lookup time, while subsequent requests use cached DNS entries. Slow DNS lookups suggest resolver issues or geographic distance to DNS servers.

**Initial Connection** tracks the time to establish a TCP connection with the server, including the TCP three-way handshake. This appears only on the first request to a domain or after connection closure.

**SSL/TLS Negotiation** measures the time for the TLS handshake, including certificate validation and cipher negotiation. This occurs on the first HTTPS request to a domain. Slow SSL times may indicate certificate chain complexity or weak server configuration.

#### Request Phase

**Request Sent** represents the time to transmit the request to the server. Large request payloads or slow upload speeds increase this metric.

**Waiting (TTFB)** measures Time To First Byte—the duration from completing the request transmission until receiving the first byte of the response. This encompasses server processing time, database queries, backend API calls, and network latency. High TTFB indicates server-side performance issues or network delays.

#### Response Phase

**Content Download** tracks the time to receive the complete response body. This depends on response size, network bandwidth, and compression. Large payloads or slow connections extend download time.

### Performance Metrics

#### Total Request Time

The sum of all timing phases represents the complete request duration. Comparing total times across requests identifies slow endpoints and resource bottlenecks.

#### Waterfall Analysis

The waterfall view displays requests chronologically, revealing loading patterns and dependencies. Parallel requests indicate efficient resource loading, while sequential chains suggest opportunities for optimization.

**Critical path analysis** identifies the sequence of dependent requests blocking page rendering. Resources on the critical path directly impact load time and should be optimized first.

**Request prioritization** shows how browsers schedule resource fetching. High-priority requests (HTML, CSS, critical scripts) load before low-priority requests (images, analytics). Improper prioritization delays critical resources.

#### Size Metrics

**Transferred size** indicates bytes sent over the network, including compression and headers. **Resource size** shows the uncompressed content size. The ratio between these reveals compression effectiveness.

Cumulative transferred size across all requests measures total bandwidth consumption. High totals suggest opportunities for asset optimization, lazy loading, or code splitting.

### Filtering and Analysis Techniques

#### Request Filtering

Filter by **resource type** (XHR, JS, CSS, Img, Media, Font, Doc, WS, Manifest, Other) to isolate specific categories. XHR filters show API requests, while JS filters reveal script loading patterns.

Filter by **status code** to identify failed requests (4xx, 5xx) or redirects (3xx). The "has-response-header" filter finds requests with specific response headers.

Domain filtering isolates requests to particular origins, useful for analyzing third-party resource impact or identifying CDN usage.

#### Pattern Recognition

**Duplicate requests** indicate caching failures or unnecessary redundancy. Identical URLs appearing multiple times suggest missing cache headers or cache-busting issues.

**Failed requests** (status 4xx, 5xx, or "failed") reveal broken endpoints, missing resources, or CORS issues. Examining failed request details exposes the root cause.

**Redirect chains** appear as sequential 3xx responses. Multiple redirects increase latency and should be minimized or eliminated.

**Large payloads** stand out in the size column. Unusually large responses may benefit from pagination, compression, or data optimization.

#### Timing Patterns

**Long TTFB** across multiple requests indicates server-side performance issues, database bottlenecks, or network latency. Isolated long TTFB suggests specific endpoint optimization needs.

**Extended queueing** reveals connection pool exhaustion. Increasing concurrent connections, using HTTP/2, or implementing resource hints can reduce queueing.

**Prolonged download times** for small resources suggest bandwidth limitations or compression issues. Large downloads taking excessive time indicate network constraints or missing compression.

### Common Issues and Diagnostics

#### CORS Errors

CORS failures appear as failed requests in the network tab, often with no response data visible. The console shows specific CORS error messages indicating missing headers or origin mismatches.

Preflight OPTIONS requests failing indicate the server doesn't properly handle CORS preflight. Missing `Access-Control-Allow-Origin`, `Access-Control-Allow-Methods`, or `Access-Control-Allow-Headers` in responses causes CORS rejection.

Credentials issues occur when `credentials: 'include'` is used but `Access-Control-Allow-Credentials: true` is missing, or when `Access-Control-Allow-Origin: *` is combined with credentials.

#### Mixed Content

Requests blocked due to mixed content appear as failed with a security warning. HTTPS pages loading HTTP resources trigger browser blocks unless specifically allowed. The security indicator changes to reflect mixed content presence.

#### Cache Issues

**Cache misses** on repeated requests indicate missing or incorrect cache headers. The `Cache-Control` and `Expires` headers determine cacheability. `no-store` prevents caching entirely, while missing headers default to heuristic caching.

**Stale content** persists when cache headers allow long-lived caching without validation. Implementing ETags or `must-revalidate` directives ensures freshness.

**Disk cache** vs **memory cache** distinctions appear in the "Size" column. Memory cache indicates the resource was cached in RAM, while disk cache indicates persistent storage. Understanding cache sources helps diagnose caching behavior.

#### Size Discrepancies

Transferred size significantly smaller than resource size indicates effective compression. When transferred size equals or exceeds resource size, compression is absent or ineffective.

Response headers lacking `Content-Encoding: gzip` or `Content-Encoding: br` explain missing compression. Server configuration or CDN settings control compression application.

#### Connection Issues

**Stalled connections** exceeding several seconds suggest connection pool saturation, proxy issues, or network problems. Monitoring concurrent connections reveals whether browser limits cause stalling.

**Failed connections** display generic error messages like "net::ERR_CONNECTION_REFUSED" or "net::ERR_NAME_NOT_RESOLVED". These indicate server unavailability, DNS failures, or network connectivity issues.

**SSL errors** show certificate validation failures or protocol negotiation problems. Examining SSL certificate details reveals expiration, domain mismatches, or chain validation errors.

### Advanced Analysis

#### Request Initiator

The initiator column identifies what triggered each request. **Parser** indicates the browser's HTML parser discovered the resource. **Script** shows JavaScript-initiated requests, with specific line numbers linking to the source.

**Other** requests come from browser features like favicon loading or navigation. Understanding initiators clarifies dependencies and loading sequences.

#### Priority and Rendering Impact

Resource priority (Highest, High, Medium, Low, Lowest) determines loading order. Critical rendering resources receive higher priority. Observing priority assignments reveals whether important resources load promptly.

**Render-blocking resources** delay first paint. CSS in the document head and synchronous scripts block rendering until loaded. Identifying render-blocking resources guides optimization efforts.

#### Protocol Analysis

The protocol column shows HTTP version (HTTP/1.1, h2, h3). HTTP/2 enables multiplexing, header compression, and server push. HTTP/3 uses QUIC for improved performance over unreliable networks.

**Connection reuse** appears when multiple requests share a single connection. HTTP/1.1 requires sequential request processing per connection, while HTTP/2 allows concurrent multiplexing. Examining connection IDs reveals reuse patterns.

#### Request Payload Analysis

POST, PUT, and PATCH requests include payload data visible in the request body viewer. Examining payload structure, size, and encoding reveals data transmission efficiency.

**FormData** appears for multipart uploads. **JSON payloads** show structured data. **URL-encoded** data uses `application/x-www-form-urlencoded` format. Choosing appropriate encoding reduces payload size and improves transmission efficiency.

#### Response Preview and Content

The preview tab renders responses according to content type. JSON responses display formatted, collapsible structures. HTML previews render as interpreted by the browser. Images show visual previews.

The response tab displays raw response data. Comparing preview and response views helps verify content integrity and identify parsing issues.

### Performance Optimization Insights

#### Identifying Bottlenecks

**Longest requests** dominate total load time. Sorting by duration highlights optimization targets. Focusing on the slowest 20% of requests yields the greatest performance gains.

**Largest resources** consume bandwidth and increase load time. Sorting by size identifies optimization opportunities through compression, minification, or lazy loading.

**Request count** impacts performance through connection overhead and parsing time. High request counts suggest bundling, inlining, or resource consolidation opportunities.

#### Compression Validation

Comparing transferred vs. resource size validates compression effectiveness. Ideal ratios vary by content type: text resources (HTML, CSS, JS, JSON) should achieve 60-80% size reduction with gzip, 70-85% with Brotli.

Missing `Content-Encoding` headers on compressible resources indicate server misconfiguration. Enabling gzip or Brotli compression on text resources yields immediate size reductions.

#### Caching Strategy Validation

Repeated requests to identical URLs should load from cache. `200 (from disk cache)` or `200 (from memory cache)` status messages confirm successful caching.

**Fingerprinted resources** (containing hashes in filenames) should use long-lived caching (`max-age=31536000`) since content changes produce new URLs. Dynamic content requires shorter cache durations with validation.

`304 Not Modified` responses confirm conditional request success. These indicate the client validated cached content and received confirmation of freshness without retransmitting the body.

#### Parallel Loading Optimization

**Request concurrency** appears in the waterfall view as overlapping bars. HTTP/1.1 limits concurrent connections per domain to approximately 6, while HTTP/2 multiplexes unlimited requests over a single connection.

**Domain sharding** (spreading resources across multiple domains) increases HTTP/1.1 parallelism but adds DNS lookup and connection overhead. HTTP/2 makes domain sharding counterproductive.

**Resource hints** (`dns-prefetch`, `preconnect`, `prefetch`, `preload`) appear as early requests in the waterfall. These optimize loading by establishing connections or fetching resources before they're needed.

---

## Chrome DevTools Features for Fetch API

### Network Panel Core Features

#### Request Filtering and Inspection

The Network panel provides dedicated filtering for fetch/XHR requests through the resource type buttons in the filter bar. Multiple type filters can be selected simultaneously by holding Control (Windows/Linux) or Command (Mac) while clicking. The panel displays all network activity in the Network Log, with each row representing a resource request.

Request details are accessible by clicking any entry in the Network Log. The interface provides multiple tabs for examining different aspects of each request:

- **Headers tab**: Displays HTTP request/response headers, general information including status codes with human-readable descriptions, and the complete header chain
- **Preview tab**: Renders basic HTML or displays formatted JSON responses, particularly useful when APIs return errors in HTML format
- **Response tab**: Shows raw response content with a Format button for minified content readability
- **Initiator tab**: Presents a tree visualization of the request initiator chain, showing what triggered the request and what resources it initiated
- **Timing tab**: Breaks down network activity timing for the resource, showing phases like DNS lookup, connection establishment, waiting time, and content download

#### Request Information Columns

The Network Log displays comprehensive information across multiple columns (customizable via right-click on header):

- **Name**: Resource filename or identifier
- **Status**: HTTP status code (200, 404, etc.) or error states like CORS failures and blocked requests
- **Type**: MIME type of the requested resource
- **Initiator**: Object or process that initiated the request (Parser, Redirect, Script, Other)
- **Size**: Combined size of response headers and body, with uncompressed size when using big request rows
- **Time**: Total duration from request start to final byte receipt
- **Waterfall**: Visual breakdown of request activity phases
- **Priority**: Both initial (bottom value) and final (top value) fetch priority when using big request rows
- **Protocol**: HTTP protocol version used (h2, h3, http/1.1)
- **Domain**: Request domain
- **Path**: Request path
- **Method**: HTTP method used
- **Remote Address**: Server IP address
- **Connection ID**: Identifies which server connection was used

#### Advanced Filtering

The filter bar supports multiple filtering methods:

**Property-based filters** use syntax like `domain:`, `status-code:`, `method:`, `mime-type:`, `has-response-header:`, `set-cookie-value:`, and `url:`. DevTools provides autocomplete suggestions populated from encountered values.

**Regular expression filters** enable complex pattern matching. For example, `/css|woff2/` shows both CSS and font files.

**Time-range filtering** involves dragging left or right on the Overview timeline to display only requests active during the selected timeframe.

**Extension URL filtering** can be enabled through the "Hide extension URLs" option in the More filters dropdown, preventing requests to `chrome-extension://` URLs from cluttering the view.

#### Search Capabilities

The Network panel includes full-text search across all request response bodies. Accessing search involves clicking the magnifying glass icon to the left of "Preserve log." Search supports regular expressions and provides a list of matches across all captured requests.

The "Copy" submenu accessible via right-click on any request provides search-related options to find all instances of specific headers, cookies, or response content patterns.

### Request Replication and Export

#### Copy Request Options

Right-clicking any request in the Network Log and hovering over "Copy" provides multiple options for replicating requests:

**Copy as fetch**: Generates browser-compatible fetch API code including all headers, referrer policy, body, method, mode, and credentials. The generated code can be executed directly in the DevTools Console.

**Copy as fetch (Node.js)**: Similar to standard fetch but includes the cookie header, essential for Node.js environments where cookies aren't automatically managed.

**Copy as cURL**: Generates a cURL command that can be executed in terminal environments, useful for sharing requests with backend developers or testing outside the browser.

**Copy as PowerShell**: Creates PowerShell-compatible request code for Windows environments.

**Copy URL**: Copies the request URL to clipboard.

**Copy response**: Copies the complete response body to clipboard.

**Copy stack trace**: Copies the request's stack trace to clipboard, showing the call chain that led to the request.

#### Batch Export Options

The "Copy" submenu also provides bulk operations for exporting multiple requests:

**Copy all as fetch (Node.js)**: Generates a chain of Node.js fetch calls for all filtered requests.

**Copy all as cURL**: Creates a chain of cURL commands for all filtered requests.

**Copy all as PowerShell**: Generates PowerShell commands for all filtered requests.

**Copy all URLs**: Copies URLs of all filtered requests to clipboard.

#### HAR File Export and Import

The Network panel supports exporting network activity as HAR (HTTP Archive) files, a JSON-based format used by HTTP session tools:

**Export options**:
- Click the Export HAR button in the action bar
- Right-click any request and select "Copy > Save all as HAR (sanitized)" or "Save all as HAR (with sensitive data)"
- Sanitized exports exclude Cookie, Set-Cookie, and Authorization headers by default

**Import capabilities**:
- Drag-and-drop HAR files directly into the Requests table
- Click the Import HAR button in the action bar
- The Network panel reads and displays initiators for imported requests

HAR files contain complete request/response data including headers, timing information, content, and the full waterfall breakdown. They're valuable for sharing debugging information with team members or support personnel who can then analyze the captured data in their own DevTools instance.

### Request Overriding and Mocking

#### Local Overrides System

Chrome DevTools (since version 117) enables overriding both web content and HTTP response headers for fetch/XHR requests without requiring access to backend servers. This functionality requires setting up a local folder where DevTools stores override files.

**Setup process**:
1. Navigate to Network panel
2. Right-click a request
3. Select "Override content" or "Override headers"
4. Select a folder to store override files when prompted
5. Grant DevTools access permissions

Once configured, DevTools saves modified files and serves them instead of the actual network responses on subsequent page loads. The system works by intercepting requests and checking if an override exists before fetching from the network.

#### Content Overriding

After selecting "Override content" for a fetch/XHR request, DevTools automatically:
- Opens the Sources > Overrides > Editor panel
- Creates a local file with the current response content
- Enables the override system if it was disabled

Developers can then edit the response content directly in the Sources panel. Changes are saved with Ctrl+S (Windows/Linux) or Cmd+S (Mac), and subsequent requests to the same URL receive the modified content.

Overridden resources are indicated with a purple icon in the Network panel. Hovering over this icon displays what's been overridden. The Response tab also shows a purple dot icon with a tooltip for requests with overridden content.

#### Response Header Overriding

Response header overrides work similarly but focus on modifying HTTP headers without changing response content. This is valuable for testing scenarios like:
- Changing Cache-Control headers to simulate different caching policies
- Adjusting Access-Control-Allow-Origin for CORS testing
- Modifying Content-Security-Policy headers for security testing
- Testing different Content-Type or Content-Encoding values

Headers can be edited by:
1. Opening the Headers tab for a request
2. Hovering over a response header value
3. Clicking the Edit button that appears
4. Modifying the value and saving

#### Override Management

The Sources > Overrides panel provides centralized management:
- Lists all override files in a tree structure
- Allows enabling/disabling overrides via checkbox
- Provides "Clear" button to delete all overrides
- Supports deleting individual override files or folders via right-click

The Changes drawer tab tracks all modifications made to web content in one location, showing exactly what changed between the original and overridden versions.

### Network Throttling

#### Global Throttling Profiles

The Network panel includes throttling capabilities to simulate degraded network conditions. The Throttling dropdown (set to "No throttling" by default) provides preset profiles:

- **Slow 3G**: 400 Kbps download, 400 Kbps upload, 2000ms minimum latency
- **Fast 3G**: 1.6 Mbps download, 750 Kbps upload, 562.5ms minimum latency
- **Slow 4G**: 4 Mbps download, 3 Mbps upload, 165ms minimum latency
- **Fast 4G**: 9 Mbps download, 9 Mbps upload, 85ms minimum latency
- **Offline**: Completely blocks network connectivity

Custom profiles can be created by:
1. Selecting "Custom" from the throttling dropdown
2. Configuring download/upload throughput (bytes/sec)
3. Setting latency (milliseconds)
4. Optionally specifying packet loss percentage for WebSocket connections

When throttling is enabled, a warning triangle appears on the Network panel tab with a tooltip indicating network modification is active.

#### Throttling Characteristics

[Inference] DevTools throttling uses request-level implementation rather than connection-level simulation. This means:
- The initial connection establishes at normal speed
- Response times are artificially delayed to simulate slower connections
- The minimum response time (TTFB) is extended to compensate for the fast initial connection
- Subsequent requests on the same connection are slowed proportionally

This approach differs from actual slow networks but provides reasonable approximation for testing purposes. For accurate testing, the connection cache should be cleared between loads.

#### Individual Request Throttling

Chrome 144 introduced Individual Request Throttling through the Request conditions drawer. This feature allows applying specific network conditions to individual requests rather than globally throttling all traffic.

**Usage**:
1. Right-click any request in the Network panel
2. Select "Throttle request" or "Block request"
3. Choose to apply to the exact URL or entire domain
4. Select a throttling profile (standard presets or custom)
5. DevTools automatically opens Request conditions drawer and applies the constraint

**Visual indicators**:
- Throttled requests display in yellow/gold with a clock icon in the Time column
- Hovering over the clock icon shows the applied network condition
- The Timings sub-panel displays throttling details
- A warning icon appears on the Network panel tab when requests are being modified

**Request conditions management**:
- URL patterns support wildcards (*) for matching dynamic resources
- Multiple patterns can be created
- When a request matches multiple patterns, the first rule is applied
- Individual rules can be enabled/disabled without deletion

#### WebSocket Throttling

Network throttling extends to WebSocket connections (since Chrome 99). Testing involves:
1. Establishing a WebSocket connection with throttling disabled
2. Sending a message and noting the timing
3. Creating a slow custom throttling profile (e.g., 10 kbit/s)
4. Applying throttling and sending another message
5. Comparing message round-trip times in the Messages tab under the WS filter

#### Network Conditions Drawer

The Network conditions drawer provides an alternative interface for throttling accessible from other DevTools panels. Opening it involves clicking the network conditions icon or running "Show Network Conditions" from the Command Menu.

Beyond throttling, this drawer enables:
- User-Agent string customization affecting both the User-Agent HTTP header and `navigator.userAgent` value
- Network connectivity simulation
- Testing with predefined browser User-Agent strings

### Request Blocking

#### Block Request Functionality

DevTools provides request blocking to test application behavior when specific resources are unavailable. The feature is accessible through:

**Command Menu method**:
1. Press Control+Shift+P or Command+Shift+P (Mac)
2. Type "block"
3. Select "Show Request Blocking"
4. Click "Add Pattern"
5. Enter URL pattern (supports wildcards)

**Network panel method**:
1. Right-click any request
2. Select "Block request URL" or "Block request domain"
3. DevTools opens Request conditions drawer with the block rule created

Blocked requests appear in red in the Network Log with status "(blocked:devtools)" in the Status column. This helps identify which resources failed due to blocking rather than actual network issues.

Request blocking patterns support wildcards for flexible matching:
- `*.js` blocks all JavaScript files
- `*/analytics/*` blocks paths containing "analytics"
- `https://example.com/*` blocks all requests to a domain

### Timing and Performance Analysis

#### Waterfall Visualization

The Waterfall column provides visual breakdown of network request phases, color-coded by activity type:

**Connection phases** (visible on first request to a domain):
- DNS Lookup (resolving IP address)
- Initial connection (TCP handshakes, SSL negotiation)
- Proxy negotiation (if applicable)

**Request/response phases**:
- Queueing (waiting for available connection)
- Stalled (delayed after connection start)
- Request sent
- Waiting (TTFB - Time To First Byte)
- Content Download

**Service Worker phases**:
- ServiceWorker Preparation (starting up worker)
- Request to ServiceWorker (sending request to worker)

Hovering over the waterfall bar displays detailed timing breakdown with millisecond precision for each phase. The total time is displayed in the Time column.

#### Priority Tracking

The Priority column (visible with Big request rows enabled) displays both initial and final fetch priority. This helps identify when browser changes request priority during loading:

- Initial Priority (bottom value): The priority assigned when the request was initiated
- Final Priority (top value): The priority when the request completed

[Inference] Priority changes can occur based on factors like resource type discovery, viewport visibility, and browser heuristics. Monitoring priority changes helps optimize resource loading order and identify opportunities for using the Fetch Priority API's `fetchpriority` attribute.

#### Performance Integration

The Performance panel's Network track shows network requests alongside other performance metrics. This provides context about how network activity relates to:
- JavaScript execution
- Rendering and painting
- User interactions
- Core Web Vitals

Network requests in the Performance track display the same priority information as the Network panel, enabling correlation between fetch priority and overall page performance.

### EventStream and Server-Sent Events

#### EventStream Tab

The Network panel includes an EventStream tab for debugging Server-Sent Events (SSE) and streams from Fetch API and EventSource API. This tab appears when viewing requests that stream events.

**Features**:
- Displays events in real-time as they arrive
- Shows event type and data for each event
- Includes filtering capability via regular expression filter bar
- Provides "Clear" button to reset captured events
- Updates live during active connections

**Limitations** [Unverified]:
- The EventStream tab only populates when using native EventSource API
- Polyfills or custom fetch-based SSE implementations may not populate the tab
- Third-party Chrome extensions like "SSE Viewer" can provide additional EventStream debugging for fetch-based implementations

#### Server-Sent Events Debugging

When debugging SSE connections:

1. Record network requests while events are streaming
2. Locate the SSE request in the Network Log (typically shows `text/event-stream` content type)
3. Click the request to open details
4. Select the EventStream tab to view messages

The Headers tab displays the SSE-specific headers:
- `Content-Type: text/event-stream`
- Connection headers indicating persistent connection
- Cache-Control headers (typically set to no-cache for SSE)

The Timing tab shows the persistent connection duration, which remains open as long as the SSE connection is active.

### WebSocket Debugging

#### WebSocket Request Inspection

WebSocket connections appear in the Network Log with type "WS (WebSocket)". The WS filter button enables showing only WebSocket traffic.

**Connection details**:
- Status column shows 101 (Switching Protocols) for successful WebSocket upgrades
- Headers tab displays the WebSocket handshake including Upgrade and Connection headers
- The Sec-WebSocket-* headers show protocol negotiation details

#### Messages Tab

The Messages tab (available for WebSocket requests) displays bidirectional communication:
- Shows each message with timestamp
- Indicates message direction (sent/received)
- Displays message payload (text or binary)
- Color-codes messages for visual distinction
- Provides length information for each message

Messages can be filtered using the filter bar within the Messages tab, supporting regular expressions for complex filtering needs.

### Initiator Chain Visualization

#### Request Initiator Information

The Initiator column and tab provide critical information about what caused each request:

**Initiator types**:
- **Parser**: Chrome's HTML parser encountered a resource reference
- **Redirect**: HTTP redirect initiated the request
- **Script**: JavaScript function triggered the request
- **Preload**: Resource hint (preload, prefetch) initiated the request
- **Other**: User action like clicking a link or entering URL

For script-initiated requests (including fetch calls), clicking the initiator link opens the Sources panel at the exact line of code that made the request. Hovering displays the full call stack leading to the request.

#### Initiator Chain Tree

The Initiator tab presents a nested tree view showing:
- Resources above the inspected request that initiated it (green highlight)
- Resources below the inspected request that it initiated (red highlight)
- The inspected resource in bold

This visualization helps understand request dependencies and loading sequences, crucial for optimizing resource loading and identifying unnecessary cascading requests.

#### Shift+Hover Visualization

Holding Shift while hovering over any request in the Network Log highlights:
- The request's initiator in green
- Requests it initiated in red

This provides quick visual understanding of request relationships without opening the Initiator tab.

### Chrome DevTools Protocol Access

#### Programmatic Network Access

The Chrome DevTools Protocol (CDP) provides programmatic access to network data through the Fetch and Network domains:

**chrome.devtools.network API** (for extensions):
- `getHAR()`: Returns complete HAR log of all network requests
- `onRequestFinished`: Event fired when requests complete with HAR entry data
- `onNavigated`: Event fired on page navigation

**CDP Fetch domain** enables:
- Request interception and modification
- Response body retrieval
- Authentication handling
- Request patterns for selective interception

**CDP Network domain** provides:
- `Network.enable`: Start capturing network events
- `Network.setBlockedURLs`: Block specific URLs
- `Network.replayXHR`: Replay XMLHttpRequest with identical parameters
- `Network.emulateNetworkConditions`: Programmatic throttling
- `Network.searchInResponseBody`: Search response content

#### Protocol Monitor

The Protocol monitor (Settings > Experiments > Protocol Monitor) displays all CDP requests and responses made by DevTools. This helps developers:
- Understand how DevTools uses CDP internally
- Debug CDP-based tools and extensions
- Learn CDP command syntax and parameters

The Protocol monitor includes a command editor (Chrome 117+) that:
- Suggests CDP commands as you type
- Displays parameter documentation and types
- Provides structured form for editing parameters
- Supports sending commands via button or Ctrl/Cmd+Enter

### Network Log Persistence

#### Preserve Log Setting

The "Preserve log" checkbox prevents clearing the Network Log during page navigations. When enabled:
- Requests from previous pages remain visible
- New requests are appended rather than replacing existing entries
- Navigation boundaries are indicated in the log

This is essential for debugging:
- Form submissions that redirect
- Multi-step authentication flows
- POST-redirect-GET patterns
- Cross-page resource loading issues

#### Recording Control

The Network panel includes a record button (red circle) that controls whether network activity is captured. When recording is paused:
- No new requests appear in the Network Log
- Existing requests remain visible
- The button turns gray to indicate inactive state

Recording automatically starts when DevTools opens and typically remains enabled. Manual control is useful for:
- Reducing clutter when only specific requests matter
- Preserving a specific set of requests for comparison
- Managing performance impact of logging large numbers of requests

### Status Code and Error Handling

#### Enhanced Status Display

The Status column and Headers > General section display HTTP status codes with human-readable descriptions. For example:
- `200 OK`
- `404 Not Found`
- `500 Internal Server Error`
- `301 Moved Permanently`

Hovering over status codes in the Network Log displays the same descriptive text, improving comprehension without opening request details.

#### Error State Indicators

Beyond standard HTTP status codes, the Network panel indicates various error states:

**(blocked:origin)**: CORS policy blocked the request. The Console displays specific CORS error messages with the Access-Control-* headers involved.

**(blocked:devtools)**: Request blocked by DevTools request blocking or Request conditions.

**(blocked:client)**: Browser blocked the request (e.g., Content Security Policy violation, mixed content, etc.).

**(failed)**: Network failure occurred (connection refused, DNS failure, etc.).

**Provisional headers warning**: The Headers tab may show "Provisional headers are shown..." indicating:
- Request served from cache without network access (headers may be incomplete)
- Invalid network resource attempted
- Request hasn't been sent yet

#### CORS Debugging

For CORS errors, the Console provides detailed information including:
- The specific CORS policy violation
- Expected vs. actual Access-Control-* headers
- Origin that was rejected
- Credentials mode that caused the issue

The Network panel's Headers tab displays both the request's Origin header and the response's Access-Control-* headers, enabling verification of proper CORS configuration.

### Response Content Analysis

#### Content Type Handling

The Response tab handles different content types appropriately:

**JSON responses**: DevTools detects JSON including subtypes (application/ld+json, application/hal+json) and provides:
- Syntax highlighting
- Collapsible tree structure for objects/arrays
- Pretty-print formatting button

**HTML responses**: Shows source code with syntax highlighting and provides format button for minified content.

**Binary responses**: Displays hex dump or indicates binary content that cannot be rendered as text.

**Images**: The Preview tab renders images at actual size with dimensions displayed.

**Fonts**: Preview tab shows font name and basic specimen.

#### Content Size Information

The Size column displays two values (in big request rows mode):
- **Top value**: Transferred size including compression and headers
- **Bottom value**: Uncompressed content size

This distinction helps identify:
- Compression effectiveness (comparing compressed vs. uncompressed size)
- Header overhead (difference between transferred and content size)
- Cache behavior (displays "from cache" instead of size for cached resources)

The Network panel footer displays total transferred size and total resource count, updating as requests complete.

### Advanced Features

#### Connection Information

The Connection ID column identifies which TCP/HTTP connection was used for each request. This information helps:
- Verify connection reuse (same ID across multiple requests)
- Identify connection limits being reached (max 6 connections per domain for HTTP/1.1)
- Optimize for HTTP/2 multiplexing (h2 protocol allows unlimited concurrent requests per connection)

#### Screenshots Timeline

The Screenshots feature captures how the page appears at different loading stages:

**Enabling screenshots**:
1. Click Network Settings (gear icon)
2. Enable Screenshots checkbox
3. Reload the page

**Using screenshots**:
- Click any screenshot thumbnail to see network state at that moment
- A yellow line appears in the waterfall showing the screenshot timing
- Helps correlate visual rendering with specific network requests
- Useful for identifying render-blocking resources

#### Frame Grouping

When pages use iframes extensively, the "Group by frame" setting organizes requests by their originating frame. Enabling this option:
1. Open Network Settings
2. Check "Group by frame"
3. Requests are organized under frame headers in the Network Log

This organization clarifies which frame generated each request, valuable for debugging complex applications using multiple iframes.

#### Request Replay

The Network domain's `replayXHR` CDP method enables replaying XHR requests with identical parameters (method, URL, body, headers, credentials). This is valuable for:
- Testing server response variations
- Debugging intermittent issues
- Verifying fixes without page reload

[Unverified] The Network panel UI doesn't expose replay functionality directly, but extensions or CDP-based tools can implement this feature using the protocol.

### Performance Considerations

#### Big Request Rows

The "Big request rows" setting (Network Settings > Big request rows) increases row height to display additional information:
- Both transferred and uncompressed sizes in Size column
- Both initial and final priorities in Priority column
- More whitespace for improved readability

This setting improves information density at the cost of requiring more scrolling for long request lists.

#### Overview Timeline

The Overview timeline at the top of the Network panel provides visual summary of:
- Request loading sequence over time
- DOMContentLoaded event (blue vertical line)
- Load event (red vertical line)
- Request density and timing patterns

This visualization helps identify:
- Periods of network congestion
- Gaps where no requests are active
- Front-loaded vs. spread-out loading patterns

The Overview can be hidden via Network Settings > Show overview checkbox to reclaim vertical space.

#### Resource Timing API

[Inference] The Network panel's timing information is based on the Resource Timing API (window.performance.getEntriesByType('resource')). This means:
- Timing accuracy matches the API's precision (millisecond resolution)
- Same data is accessible programmatically via JavaScript
- Performance marks and measures integrate with network timing

Developers can access programmatic timing data that correlates with DevTools display, enabling automated performance monitoring that matches DevTools measurements.

---

## Firefox Developer Tools for Fetch API

### Network Monitor

#### Request Inspection

The Network Monitor displays all fetch requests in a tabular format with columns for status, method, domain, file, cause, type, transferred size, and time. Click any request to open the detailed inspection panel.

The Headers tab shows complete request and response headers. Toggle between Raw and Parsed views to see headers as sent over the wire or in structured format. Click the Edit and Resend button to modify and resubmit the request with different headers, body, or parameters.

#### Request/Response Body Analysis

The Response tab displays the returned data with automatic formatting based on content type. JSON responses are syntax-highlighted and collapsible. The Preview tab renders HTML responses or displays images. For fetch requests, both tabs handle binary data, text, and structured formats.

The Request tab shows the payload sent via fetch's body option. POST, PUT, and PATCH requests display form data, JSON payloads, or raw body content. Use the params tab to view parsed query string parameters.

#### Timing Breakdown

The Timings tab provides granular performance metrics for each fetch request:

- **Blocked**: Time spent in browser queue before connection
- **DNS Resolution**: Time to resolve the domain name
- **Connecting**: TCP handshake duration
- **TLS Setup**: SSL/TLS negotiation time (for HTTPS)
- **Sending**: Time to upload request data
- **Waiting**: Server processing time (TTFB)
- **Receiving**: Time to download response body

These metrics help identify bottlenecks in network performance, particularly useful when optimizing fetch call sequences.

#### Security Analysis

The Security tab shows TLS/SSL certificate details, protocol version, cipher suite, and certificate chain. For fetch requests to HTTPS endpoints, verify certificate validity and security posture. Warning indicators appear for weak cryptography or certificate issues.

#### Filtering and Search

Filter requests by type (XHR, Fetch, WS), domain, or status code using the filter bar. The search function highlights matching requests across URL, headers, and body content. Use negative filters with `-fetch` to exclude fetch requests when debugging other network activity.

#### Request Blocking

Right-click any fetch request and select "Block URL" to prevent that specific endpoint from loading. Useful for testing error handling, offline scenarios, or removing third-party dependencies during development. Manage blocked patterns in the Network Monitor settings.

### Console Integration

#### Fetch Request Logging

The Console automatically logs fetch requests when they initiate. Each entry shows the HTTP method, URL, and returns a Promise object. Click the Promise disclosure triangle to inspect its resolved value once the fetch completes.

```javascript
// Console displays:
// Promise { <state>: "fulfilled", <value>: Response }
```

Expand the Response object to examine status, headers, body, and other properties directly in the Console.

#### Network Log Persistence

Enable "Persist Logs" to retain network activity across page navigations. Essential when debugging fetch calls that trigger redirects or occur during page transitions. The Console preserves both logged fetch requests and their responses.

#### CORS Error Details

When fetch encounters CORS issues, the Console displays detailed error messages identifying the specific header or configuration problem. Unlike the Network Monitor (which may show the request succeeded at the network level), the Console reveals JavaScript-level CORS blocking with actionable error messages.

### Debugger

#### Breakpoint on Fetch

Set breakpoints in code that calls fetch to pause execution before the request initiates. Inspect variables containing URLs, headers objects, and request options. Step through async/await or Promise chains to trace fetch behavior.

#### XHR/Fetch Breakpoints

Enable "Pause on any URL" in the Debugger's Breakpoints panel to halt execution on all fetch calls automatically. Filter by URL pattern to break only on specific endpoints. This feature intercepts requests without modifying source code.

#### Async Stack Traces

The Debugger maintains call stacks across async boundaries. When a fetch Promise rejects or throws, trace back through await points to identify the originating call site. Enable "Show Async Stack Traces" in Debugger settings for complete execution history.

#### Source Mapping

When using bundlers or transpilers, Firefox maps minified fetch calls back to original source files. Set breakpoints in TypeScript or ES6+ source code that compiles to fetch calls, and the Debugger resolves them correctly.

### Storage Inspector

#### Cache Storage Inspection

Navigate to the Storage tab and expand "Cache Storage" to view Service Worker caches populated by fetch requests. Each cache entry shows the request URL, response status, and stored data. Right-click entries to delete individual cached responses.

The Storage Inspector displays cache metadata including creation time and size. Useful for verifying fetch requests utilize caching strategies correctly, especially when implementing offline-first applications.

#### IndexedDB and Fetch

When fetch responses are stored in IndexedDB, inspect the database structure, object stores, and individual entries. The Storage Inspector provides a tree view of all databases, with expandable records showing stored response data from fetch calls.

### Performance Tools

#### Profiler Analysis

Record a performance profile while executing fetch requests to identify JavaScript execution costs. The Profiler shows time spent in fetch initialization, response parsing (JSON, text, blob methods), and promise chain resolution.

Flame charts reveal whether fetch-related code blocks the main thread. Look for long bars representing synchronous response processing that should be optimized or moved off-thread.

#### Network Waterfall

The Performance panel's network waterfall visualizes fetch request timing alongside JavaScript execution, rendering, and other browser activities. Identify whether network requests are serialized unnecessarily or if request queueing causes delays.

Color-coded bars distinguish fetch requests from other resource types. Overlapping bars indicate parallel requests, while sequential patterns suggest opportunities for request optimization or resource bundling.

#### Memory Profiling

Use the Memory tool to detect leaks from fetch-related objects. Take heap snapshots before and after fetch operations to identify retained Response objects, unread streams, or abandoned promise chains. Filter by "Response" or "ReadableStream" to isolate fetch-related allocations.

### Network Throttling

Access throttling presets (3G, 4G, WiFi) or create custom profiles in the Network Monitor settings. Test fetch behavior under constrained bandwidth and high latency to validate timeout handling, progress indicators, and retry logic.

Throttling applies to all network requests including fetch, allowing realistic testing of mobile network conditions. Combine with offline mode to simulate complete network failure and verify error handling.

### Request Context Menu

Right-click any fetch request in the Network Monitor to access:

- **Copy as cURL**: Generate command-line equivalent with headers
- **Copy as Fetch**: Create JavaScript fetch code replicating the request
- **Open in New Tab**: Execute the request in a browser tab
- **Resend**: Replay the exact request without modification
- **Block URL**: Prevent this endpoint from loading

The "Copy as Fetch" option generates code including headers, method, and body, useful for replicating requests in different contexts or sharing with team members.

### HAR Export

Export network activity as HTTP Archive (HAR) format from the Network Monitor. HAR files contain complete request/response data for all fetch calls, enabling offline analysis, performance auditing, or sharing with external tools.

Import HAR files back into Firefox to replay network sessions and compare performance across different builds or network conditions.

### Response Override

Use the "Edit and Resend" feature to modify fetch responses during development. Change response status codes, headers, or body content to test error handling without requiring server changes. Useful for simulating edge cases like rate limiting, authentication failures, or partial content delivery.

### WebSocket and Fetch API Integration

While WebSockets appear separately, the Network Monitor's unified view helps debug applications using both fetch and WebSocket connections. Filter between technologies to isolate specific communication patterns or verify fallback mechanisms from WebSocket to HTTP fetch.

### Developer Tools Settings

Configure Network Monitor behavior in Settings (F1):

- **Disable Cache**: Force fresh fetch requests on every load
- **Throttling**: Set default throttling profile
- **Enable persistent logs**: Retain requests across navigation
- **Show original size**: Display pre-compression response sizes

These settings apply globally to all tabs and persist across browser sessions.

---

## Request/Response Inspection

### Inspecting Request Objects

#### Accessing Request Properties

Request objects expose several properties for inspection:

```javascript
const request = new Request('https://api.example.com/data', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer token123'
  },
  body: JSON.stringify({ key: 'value' })
});

console.log(request.url);           // "https://api.example.com/data"
console.log(request.method);        // "POST"
console.log(request.mode);          // "cors"
console.log(request.credentials);   // "same-origin"
console.log(request.cache);         // "default"
console.log(request.redirect);      // "follow"
console.log(request.referrer);      // about:client
console.log(request.referrerPolicy); // ""
console.log(request.integrity);     // ""
```

#### Reading Request Headers

Headers can be inspected using the Headers interface methods:

```javascript
// Check if header exists
request.headers.has('Content-Type'); // true

// Get header value
request.headers.get('Authorization'); // "Bearer token123"

// Iterate over headers
for (const [key, value] of request.headers) {
  console.log(`${key}: ${value}`);
}

// Get all values for a header (for multi-value headers)
request.headers.getSetCookie(); // Returns array of Set-Cookie values
```

#### Reading Request Body

The request body can only be read once due to the body being a stream. Multiple read attempts require cloning:

```javascript
const request = new Request('https://api.example.com', {
  method: 'POST',
  body: JSON.stringify({ data: 'test' })
});

// Clone before reading if you need to read multiple times
const clonedRequest = request.clone();

// Read as JSON
const jsonData = await request.json();

// Read as text
const textData = await clonedRequest.text();

// Other body reading methods:
// await request.blob()
// await request.arrayBuffer()
// await request.formData()
```

#### Body Stream Status

```javascript
console.log(request.bodyUsed); // false initially, true after reading

// Check if body is disturbed
if (!request.bodyUsed) {
  const data = await request.json();
}
```

### Inspecting Response Objects

#### Accessing Response Properties

```javascript
const response = await fetch('https://api.example.com/data');

console.log(response.status);       // 200
console.log(response.statusText);   // "OK"
console.log(response.ok);          // true (status 200-299)
console.log(response.type);        // "cors", "basic", "opaque", etc.
console.log(response.url);         // Final URL after redirects
console.log(response.redirected);  // true if redirected
console.log(response.headers);     // Headers object
```

#### Response Type Meanings

```javascript
// "basic" - same-origin response
// "cors" - valid CORS response
// "opaque" - no-cors response (very limited access)
// "opaqueredirect" - redirect mode set to "manual"
// "error" - network error occurred
```

#### Reading Response Headers

```javascript
// Access specific headers
const contentType = response.headers.get('Content-Type');
const contentLength = response.headers.get('Content-Length');
const lastModified = response.headers.get('Last-Modified');

// Check for header existence
if (response.headers.has('Cache-Control')) {
  console.log('Cache control is set');
}

// Iterate all headers
response.headers.forEach((value, key) => {
  console.log(`${key}: ${value}`);
});

// Convert to plain object (for logging/debugging)
const headersObj = Object.fromEntries(response.headers.entries());
```

#### Reading Response Body

Similar to requests, response bodies are streams that can only be read once:

```javascript
const response = await fetch('https://api.example.com/data');

// Clone if multiple reads needed
const clone = response.clone();

// JSON parsing
const jsonData = await response.json();

// Text parsing
const textData = await clone.text();

// Blob (for binary data)
const blobData = await response.blob();

// ArrayBuffer (for raw binary)
const bufferData = await response.arrayBuffer();

// FormData (for form submissions)
const formData = await response.formData();
```

### Advanced Inspection Techniques

#### Intercepting and Logging Requests

```javascript
const originalFetch = window.fetch;

window.fetch = async function(...args) {
  const [resource, config] = args;
  
  console.log('Request:', {
    url: resource,
    method: config?.method || 'GET',
    headers: config?.headers,
    body: config?.body
  });
  
  const response = await originalFetch(...args);
  
  console.log('Response:', {
    status: response.status,
    statusText: response.statusText,
    headers: Object.fromEntries(response.headers.entries())
  });
  
  return response;
};
```

#### Inspecting Body Without Consuming

Using `Response.clone()` or `Request.clone()` allows inspection while preserving the original:

```javascript
async function inspectResponse(response) {
  const clone = response.clone();
  const body = await clone.text();
  
  console.log('Response body preview:', body.substring(0, 200));
  
  return response; // Original still readable
}

const response = await fetch('https://api.example.com/data');
const inspected = await inspectResponse(response);
const data = await inspected.json(); // Still works
```

#### Creating Response Inspector

```javascript
class ResponseInspector {
  constructor(response) {
    this.response = response;
    this.clone = response.clone();
  }
  
  async getMetadata() {
    return {
      status: this.response.status,
      statusText: this.response.statusText,
      ok: this.response.ok,
      type: this.response.type,
      url: this.response.url,
      redirected: this.response.redirected,
      headers: Object.fromEntries(this.response.headers.entries())
    };
  }
  
  async getBodyPreview(length = 500) {
    const text = await this.clone.text();
    return text.substring(0, length);
  }
  
  getOriginal() {
    return this.response;
  }
}

// Usage
const response = await fetch('https://api.example.com/data');
const inspector = new ResponseInspector(response);

console.log(await inspector.getMetadata());
console.log(await inspector.getBodyPreview());

const data = await inspector.getOriginal().json();
```

### Debugging Headers

#### Examining CORS Headers

```javascript
const response = await fetch('https://api.example.com/data');

const corsHeaders = {
  'Access-Control-Allow-Origin': response.headers.get('Access-Control-Allow-Origin'),
  'Access-Control-Allow-Methods': response.headers.get('Access-Control-Allow-Methods'),
  'Access-Control-Allow-Headers': response.headers.get('Access-Control-Allow-Headers'),
  'Access-Control-Expose-Headers': response.headers.get('Access-Control-Expose-Headers'),
  'Access-Control-Allow-Credentials': response.headers.get('Access-Control-Allow-Credentials')
};

console.log('CORS Configuration:', corsHeaders);
```

#### Inspecting Cache Headers

```javascript
const cacheHeaders = {
  'Cache-Control': response.headers.get('Cache-Control'),
  'ETag': response.headers.get('ETag'),
  'Expires': response.headers.get('Expires'),
  'Last-Modified': response.headers.get('Last-Modified'),
  'Age': response.headers.get('Age')
};

console.log('Cache Information:', cacheHeaders);
```

#### Content Negotiation Headers

```javascript
const contentHeaders = {
  'Content-Type': response.headers.get('Content-Type'),
  'Content-Encoding': response.headers.get('Content-Encoding'),
  'Content-Length': response.headers.get('Content-Length'),
  'Content-Language': response.headers.get('Content-Language'),
  'Content-Location': response.headers.get('Content-Location')
};
```

### Stream Inspection

#### Reading Body as Stream

```javascript
const response = await fetch('https://api.example.com/large-file');
const reader = response.body.getReader();
const decoder = new TextDecoder();

let receivedLength = 0;
let chunks = [];

while (true) {
  const { done, value } = await reader.read();
  
  if (done) break;
  
  chunks.push(value);
  receivedLength += value.length;
  
  console.log(`Received ${receivedLength} bytes`);
}

// Concatenate chunks
const allChunks = new Uint8Array(receivedLength);
let position = 0;

for (const chunk of chunks) {
  allChunks.set(chunk, position);
  position += chunk.length;
}

const result = decoder.decode(allChunks);
```

#### Monitoring Download Progress

```javascript
async function fetchWithProgress(url, onProgress) {
  const response = await fetch(url);
  const contentLength = response.headers.get('Content-Length');
  const total = parseInt(contentLength, 10);
  
  let loaded = 0;
  const reader = response.body.getReader();
  const stream = new ReadableStream({
    async start(controller) {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          controller.close();
          break;
        }
        
        loaded += value.length;
        onProgress({ loaded, total, percentage: (loaded / total) * 100 });
        controller.enqueue(value);
      }
    }
  });
  
  return new Response(stream, {
    headers: response.headers,
    status: response.status,
    statusText: response.statusText
  });
}

// Usage
const response = await fetchWithProgress(
  'https://example.com/large-file.zip',
  ({ loaded, total, percentage }) => {
    console.log(`Progress: ${percentage.toFixed(2)}% (${loaded}/${total})`);
  }
);

const blob = await response.blob();
```

### Error Response Inspection

#### Detailed Error Information

```javascript
async function fetchWithDetailedErrors(url, options) {
  try {
    const response = await fetch(url, options);
    
    if (!response.ok) {
      const errorDetails = {
        status: response.status,
        statusText: response.statusText,
        url: response.url,
        headers: Object.fromEntries(response.headers.entries()),
        body: null
      };
      
      // Try to read error body
      try {
        const contentType = response.headers.get('Content-Type');
        if (contentType?.includes('application/json')) {
          errorDetails.body = await response.json();
        } else {
          errorDetails.body = await response.text();
        }
      } catch (e) {
        errorDetails.body = 'Unable to read error body';
      }
      
      throw new Error(`HTTP Error: ${JSON.stringify(errorDetails, null, 2)}`);
    }
    
    return response;
  } catch (error) {
    if (error instanceof TypeError) {
      console.error('Network error or CORS issue:', error);
    }
    throw error;
  }
}
```

#### Inspecting Network Failures

```javascript
async function fetchWithNetworkInspection(url) {
  const startTime = performance.now();
  
  try {
    const response = await fetch(url);
    const endTime = performance.now();
    
    console.log('Request completed:', {
      duration: `${(endTime - startTime).toFixed(2)}ms`,
      status: response.status,
      type: response.type,
      redirected: response.redirected
    });
    
    return response;
  } catch (error) {
    const endTime = performance.now();
    
    console.error('Request failed:', {
      duration: `${(endTime - startTime).toFixed(2)}ms`,
      error: error.message,
      type: error.name
    });
    
    throw error;
  }
}
```

### Browser DevTools Integration

#### Performance Timing

```javascript
// Using Resource Timing API
async function fetchWithTiming(url) {
  const response = await fetch(url);
  
  // Get timing information
  const perfEntries = performance.getEntriesByName(url, 'resource');
  const timing = perfEntries[perfEntries.length - 1];
  
  if (timing) {
    console.log('Timing breakdown:', {
      dns: timing.domainLookupEnd - timing.domainLookupStart,
      tcp: timing.connectEnd - timing.connectStart,
      request: timing.responseStart - timing.requestStart,
      response: timing.responseEnd - timing.responseStart,
      total: timing.duration
    });
  }
  
  return response;
}
```

#### Request ID Tracking

```javascript
let requestId = 0;

async function fetchWithTracking(url, options = {}) {
  const id = ++requestId;
  const startTime = Date.now();
  
  console.group(`Request #${id}`);
  console.log('URL:', url);
  console.log('Options:', options);
  
  try {
    const response = await fetch(url, options);
    
    console.log('Response:', {
      status: response.status,
      duration: `${Date.now() - startTime}ms`
    });
    console.groupEnd();
    
    return response;
  } catch (error) {
    console.error('Error:', error);
    console.groupEnd();
    throw error;
  }
}
```

---

## Performance Profiling

### Basic Timing Measurement

Using `performance.now()` for high-resolution timing:

```javascript
const start = performance.now();

const response = await fetch('https://api.example.com/data');
const data = await response.json();

const end = performance.now();
const duration = end - start;

console.log(`Request completed in ${duration.toFixed(2)}ms`);
```

### Breaking Down Request Phases

```javascript
async function profileFetchPhases(url, options = {}) {
  const timings = {
    start: performance.now(),
    fetchStart: 0,
    responseStart: 0,
    responseEnd: 0,
    parseStart: 0,
    parseEnd: 0
  };

  timings.fetchStart = performance.now();
  const response = await fetch(url, options);
  timings.responseStart = performance.now();

  const data = await response.json();
  timings.responseEnd = performance.now();
  timings.parseStart = timings.responseEnd;
  timings.parseEnd = performance.now();

  return {
    data,
    phases: {
      fetch: timings.responseStart - timings.fetchStart,
      download: timings.responseEnd - timings.responseStart,
      parse: timings.parseEnd - timings.parseStart,
      total: timings.parseEnd - timings.start
    }
  };
}

// Usage
const result = await profileFetchPhases('https://api.example.com/data');
console.log('Timing phases:', result.phases);
```

### Resource Timing API Integration

The Resource Timing API provides detailed performance data for fetched resources:

```javascript
async function fetchWithResourceTiming(url, options = {}) {
  const startMark = `fetch-start-${Date.now()}`;
  performance.mark(startMark);

  const response = await fetch(url, options);
  const data = await response.json();

  const endMark = `fetch-end-${Date.now()}`;
  performance.mark(endMark);

  // Get resource timing entry
  const entries = performance.getEntriesByType('resource');
  const entry = entries.find(e => e.name === url);

  return {
    data,
    timing: entry ? {
      duration: entry.duration,
      fetchStart: entry.fetchStart,
      domainLookupStart: entry.domainLookupStart,
      domainLookupEnd: entry.domainLookupEnd,
      connectStart: entry.connectStart,
      connectEnd: entry.connectEnd,
      secureConnectionStart: entry.secureConnectionStart,
      requestStart: entry.requestStart,
      responseStart: entry.responseStart,
      responseEnd: entry.responseEnd,
      transferSize: entry.transferSize,
      encodedBodySize: entry.encodedBodySize,
      decodedBodySize: entry.decodedBodySize
    } : null
  };
}
```

### Calculating Detailed Metrics

```javascript
function analyzeResourceTiming(entry) {
  if (!entry) return null;

  return {
    // DNS lookup time
    dns: entry.domainLookupEnd - entry.domainLookupStart,
    
    // TCP connection time
    tcp: entry.connectEnd - entry.connectStart,
    
    // TLS negotiation time (HTTPS only)
    tls: entry.secureConnectionStart > 0 
      ? entry.connectEnd - entry.secureConnectionStart 
      : 0,
    
    // Time to first byte (TTFB)
    ttfb: entry.responseStart - entry.requestStart,
    
    // Content download time
    download: entry.responseEnd - entry.responseStart,
    
    // Total request time
    total: entry.responseEnd - entry.fetchStart,
    
    // Size metrics
    transferSize: entry.transferSize,
    encodedBodySize: entry.encodedBodySize,
    decodedBodySize: entry.decodedBodySize,
    
    // Compression ratio
    compressionRatio: entry.encodedBodySize > 0
      ? (entry.decodedBodySize / entry.encodedBodySize).toFixed(2)
      : 1
  };
}

// Usage
const result = await fetchWithResourceTiming('https://api.example.com/data');
const metrics = analyzeResourceTiming(result.timing);
console.log('Detailed metrics:', metrics);
```

### Performance Observer for Continuous Monitoring

```javascript
class FetchPerformanceMonitor {
  constructor() {
    this.metrics = [];
    this.observer = null;
  }

  start() {
    if (!('PerformanceObserver' in window)) {
      console.warn('PerformanceObserver not supported');
      return;
    }

    this.observer = new PerformanceObserver((list) => {
      for (const entry of list.getEntries()) {
        if (entry.initiatorType === 'fetch' || entry.initiatorType === 'xmlhttprequest') {
          this.metrics.push({
            url: entry.name,
            timestamp: entry.startTime,
            duration: entry.duration,
            transferSize: entry.transferSize,
            protocol: entry.nextHopProtocol,
            details: this.analyzeEntry(entry)
          });
        }
      }
    });

    this.observer.observe({ entryTypes: ['resource'] });
  }

  stop() {
    if (this.observer) {
      this.observer.disconnect();
      this.observer = null;
    }
  }

  analyzeEntry(entry) {
    return {
      dns: entry.domainLookupEnd - entry.domainLookupStart,
      tcp: entry.connectEnd - entry.connectStart,
      tls: entry.secureConnectionStart > 0 
        ? entry.connectEnd - entry.secureConnectionStart 
        : 0,
      ttfb: entry.responseStart - entry.requestStart,
      download: entry.responseEnd - entry.responseStart
    };
  }

  getMetrics() {
    return this.metrics;
  }

  getAverages() {
    if (this.metrics.length === 0) return null;

    const sum = this.metrics.reduce((acc, m) => ({
      duration: acc.duration + m.duration,
      transferSize: acc.transferSize + (m.transferSize || 0),
      dns: acc.dns + (m.details.dns || 0),
      tcp: acc.tcp + (m.details.tcp || 0),
      ttfb: acc.ttfb + (m.details.ttfb || 0),
      download: acc.download + (m.details.download || 0)
    }), { duration: 0, transferSize: 0, dns: 0, tcp: 0, ttfb: 0, download: 0 });

    const count = this.metrics.length;

    return {
      duration: sum.duration / count,
      transferSize: sum.transferSize / count,
      dns: sum.dns / count,
      tcp: sum.tcp / count,
      ttfb: sum.ttfb / count,
      download: sum.download / count,
      count
    };
  }

  clear() {
    this.metrics = [];
  }
}

// Usage
const monitor = new FetchPerformanceMonitor();
monitor.start();

// Make requests...
await fetch('https://api.example.com/data1');
await fetch('https://api.example.com/data2');

// Later...
const averages = monitor.getAverages();
console.log('Average metrics:', averages);
monitor.stop();
```

### Performance Marks and Measures

```javascript
async function fetchWithMarks(url, options = {}) {
  const markId = `fetch-${Date.now()}`;
  
  performance.mark(`${markId}-start`);
  
  const response = await fetch(url, options);
  performance.mark(`${markId}-response-received`);
  
  const data = await response.json();
  performance.mark(`${markId}-parsed`);
  
  // Create measures
  performance.measure(
    `${markId}-network`,
    `${markId}-start`,
    `${markId}-response-received`
  );
  
  performance.measure(
    `${markId}-parsing`,
    `${markId}-response-received`,
    `${markId}-parsed`
  );
  
  performance.measure(
    `${markId}-total`,
    `${markId}-start`,
    `${markId}-parsed`
  );
  
  // Retrieve measures
  const network = performance.getEntriesByName(`${markId}-network`)[0];
  const parsing = performance.getEntriesByName(`${markId}-parsing`)[0];
  const total = performance.getEntriesByName(`${markId}-total`)[0];
  
  // Cleanup
  performance.clearMarks(`${markId}-start`);
  performance.clearMarks(`${markId}-response-received`);
  performance.clearMarks(`${markId}-parsed`);
  performance.clearMeasures(`${markId}-network`);
  performance.clearMeasures(`${markId}-parsing`);
  performance.clearMeasures(`${markId}-total`);
  
  return {
    data,
    timings: {
      network: network.duration,
      parsing: parsing.duration,
      total: total.duration
    }
  };
}
```

### Memory Profiling

**[Inference]**: Memory usage tracking through `performance.memory` is Chrome-specific and may not be available or accurate in all browsers.

```javascript
class FetchMemoryProfiler {
  constructor() {
    this.hasMemoryAPI = 'memory' in performance;
  }

  getMemorySnapshot() {
    if (!this.hasMemoryAPI) {
      return null;
    }

    return {
      usedJSHeapSize: performance.memory.usedJSHeapSize,
      totalJSHeapSize: performance.memory.totalJSHeapSize,
      jsHeapSizeLimit: performance.memory.jsHeapSizeLimit
    };
  }

  async profileFetchMemory(url, options = {}) {
    if (!this.hasMemoryAPI) {
      console.warn('Memory API not available');
      return { data: null, memory: null };
    }

    const before = this.getMemorySnapshot();
    
    const response = await fetch(url, options);
    const data = await response.json();
    
    const after = this.getMemorySnapshot();
    
    return {
      data,
      memory: {
        before,
        after,
        delta: after.usedJSHeapSize - before.usedJSHeapSize,
        percentage: ((after.usedJSHeapSize - before.usedJSHeapSize) / before.usedJSHeapSize * 100).toFixed(2)
      }
    };
  }
}
```

### Profiling Streaming Responses

```javascript
async function profileStreamingFetch(url, options = {}) {
  const timings = {
    start: performance.now(),
    firstChunk: null,
    chunks: [],
    end: null
  };

  const response = await fetch(url, options);
  const reader = response.body.getReader();
  
  let firstChunk = true;
  let totalBytes = 0;

  try {
    while (true) {
      const chunkStart = performance.now();
      const { done, value } = await reader.read();
      
      if (done) break;
      
      const chunkEnd = performance.now();
      
      if (firstChunk) {
        timings.firstChunk = chunkEnd - timings.start;
        firstChunk = false;
      }
      
      totalBytes += value.length;
      
      timings.chunks.push({
        size: value.length,
        duration: chunkEnd - chunkStart,
        timestamp: chunkEnd - timings.start
      });
    }
  } finally {
    reader.releaseLock();
  }
  
  timings.end = performance.now();
  
  return {
    totalBytes,
    totalDuration: timings.end - timings.start,
    firstChunkTime: timings.firstChunk,
    avgChunkSize: totalBytes / timings.chunks.length,
    avgChunkDuration: timings.chunks.reduce((sum, c) => sum + c.duration, 0) / timings.chunks.length,
    chunks: timings.chunks,
    throughput: (totalBytes / ((timings.end - timings.start) / 1000)).toFixed(2) // bytes per second
  };
}
```

### Profiling Concurrent Requests

```javascript
async function profileConcurrentFetches(urls, options = {}) {
  const startTime = performance.now();
  const results = [];

  const promises = urls.map(async (url, index) => {
    const requestStart = performance.now();
    
    try {
      const response = await fetch(url, options);
      const responseReceived = performance.now();
      
      const data = await response.json();
      const parseComplete = performance.now();
      
      return {
        url,
        index,
        success: true,
        timings: {
          queue: requestStart - startTime,
          network: responseReceived - requestStart,
          parse: parseComplete - responseReceived,
          total: parseComplete - requestStart
        },
        size: JSON.stringify(data).length,
        data
      };
    } catch (error) {
      return {
        url,
        index,
        success: false,
        error: error.message,
        timings: {
          total: performance.now() - requestStart
        }
      };
    }
  });

  const allResults = await Promise.all(promises);
  const endTime = performance.now();

  return {
    results: allResults,
    summary: {
      total: endTime - startTime,
      successful: allResults.filter(r => r.success).length,
      failed: allResults.filter(r => !r.success).length,
      avgNetworkTime: allResults
        .filter(r => r.success)
        .reduce((sum, r) => sum + r.timings.network, 0) / allResults.filter(r => r.success).length,
      maxTime: Math.max(...allResults.map(r => r.timings.total)),
      minTime: Math.min(...allResults.map(r => r.timings.total))
    }
  };
}
```

### Cache Performance Analysis

```javascript
async function profileCachePerformance(url, options = {}) {
  const profiles = [];

  // First request (likely cache miss)
  const firstStart = performance.now();
  await fetch(url, { ...options, cache: 'default' });
  const firstDuration = performance.now() - firstStart;
  
  profiles.push({
    attempt: 1,
    cacheStatus: 'miss',
    duration: firstDuration
  });

  // Wait briefly
  await new Promise(resolve => setTimeout(resolve, 100));

  // Second request (likely cache hit)
  const secondStart = performance.now();
  await fetch(url, { ...options, cache: 'default' });
  const secondDuration = performance.now() - secondStart;
  
  profiles.push({
    attempt: 2,
    cacheStatus: 'hit',
    duration: secondDuration
  });

  // Force reload (cache miss)
  const reloadStart = performance.now();
  await fetch(url, { ...options, cache: 'reload' });
  const reloadDuration = performance.now() - reloadStart;
  
  profiles.push({
    attempt: 3,
    cacheStatus: 'forced-miss',
    duration: reloadDuration
  });

  return {
    profiles,
    analysis: {
      cacheSpeedup: ((firstDuration - secondDuration) / firstDuration * 100).toFixed(2) + '%',
      cachedRequestTime: secondDuration,
      uncachedRequestTime: firstDuration
    }
  };
}
```

### Network Throttling Detection

**[Inference]**: Network conditions cannot be directly detected but can be inferred from timing patterns.

```javascript
class NetworkPerformanceAnalyzer {
  constructor() {
    this.samples = [];
  }

  async measureConnectionQuality(testUrl, sampleCount = 5) {
    const samples = [];

    for (let i = 0; i < sampleCount; i++) {
      const start = performance.now();
      
      try {
        const response = await fetch(testUrl, { cache: 'no-store' });
        await response.blob();
        
        const duration = performance.now() - start;
        samples.push({ success: true, duration });
      } catch (error) {
        samples.push({ success: false, duration: null });
      }
      
      // Brief delay between samples
      if (i < sampleCount - 1) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    const successful = samples.filter(s => s.success);
    const durations = successful.map(s => s.duration);
    
    if (durations.length === 0) {
      return { quality: 'unknown', samples };
    }

    const avg = durations.reduce((a, b) => a + b, 0) / durations.length;
    const variance = durations.reduce((sum, d) => sum + Math.pow(d - avg, 2), 0) / durations.length;
    const stdDev = Math.sqrt(variance);

    return {
      quality: this.classifyQuality(avg, stdDev),
      stats: {
        average: avg,
        min: Math.min(...durations),
        max: Math.max(...durations),
        stdDev,
        variance,
        successRate: (successful.length / samples.length * 100).toFixed(2) + '%'
      },
      samples
    };
  }

  classifyQuality(avg, stdDev) {
    // [Inference]: These thresholds are approximate classifications
    if (avg < 100 && stdDev < 50) return 'excellent';
    if (avg < 300 && stdDev < 100) return 'good';
    if (avg < 1000 && stdDev < 300) return 'fair';
    return 'poor';
  }
}
```

### Waterfall Visualization Data

```javascript
class FetchWaterfallProfiler {
  constructor() {
    this.requests = [];
  }

  async profileRequest(url, options = {}, label = '') {
    const id = `req-${this.requests.length}`;
    const startTime = performance.now();
    
    const entry = {
      id,
      label: label || url,
      url,
      startTime,
      phases: {}
    };

    try {
      const responseStart = performance.now();
      const response = await fetch(url, options);
      const responseReceived = performance.now();
      
      const data = await response.json();
      const parseComplete = performance.now();
      
      entry.phases = {
        queued: { start: 0, duration: 0 },
        dns: { start: 0, duration: 0 },
        tcp: { start: 0, duration: 0 },
        request: { start: 0, duration: responseReceived - responseStart },
        download: { start: responseReceived - startTime, duration: parseComplete - responseReceived }
      };
      
      entry.endTime = parseComplete;
      entry.totalDuration = parseComplete - startTime;
      entry.success = true;
      entry.status = response.status;
      
      // Try to get resource timing for more detail
      const resourceEntry = performance.getEntriesByName(url)[0];
      if (resourceEntry) {
        this.enhanceWithResourceTiming(entry, resourceEntry, startTime);
      }
      
    } catch (error) {
      entry.endTime = performance.now();
      entry.totalDuration = entry.endTime - startTime;
      entry.success = false;
      entry.error = error.message;
    }
    
    this.requests.push(entry);
    return entry;
  }

  enhanceWithResourceTiming(entry, resourceEntry, baseTime) {
    entry.phases = {
      dns: {
        start: resourceEntry.domainLookupStart,
        duration: resourceEntry.domainLookupEnd - resourceEntry.domainLookupStart
      },
      tcp: {
        start: resourceEntry.connectStart,
        duration: resourceEntry.connectEnd - resourceEntry.connectStart
      },
      tls: {
        start: resourceEntry.secureConnectionStart,
        duration: resourceEntry.secureConnectionStart > 0 
          ? resourceEntry.connectEnd - resourceEntry.secureConnectionStart 
          : 0
      },
      request: {
        start: resourceEntry.requestStart,
        duration: resourceEntry.responseStart - resourceEntry.requestStart
      },
      download: {
        start: resourceEntry.responseStart,
        duration: resourceEntry.responseEnd - resourceEntry.responseStart
      }
    };
  }

  getWaterfallData() {
    if (this.requests.length === 0) return null;

    const minStart = Math.min(...this.requests.map(r => r.startTime));
    
    return {
      requests: this.requests.map(req => ({
        ...req,
        relativeStart: req.startTime - minStart,
        relativeEnd: req.endTime - minStart
      })),
      totalSpan: Math.max(...this.requests.map(r => r.endTime)) - minStart
    };
  }

  clear() {
    this.requests = [];
  }
}

// Usage
const profiler = new FetchWaterfallProfiler();

await profiler.profileRequest('https://api.example.com/users', {}, 'Users API');
await profiler.profileRequest('https://api.example.com/posts', {}, 'Posts API');
await profiler.profileRequest('https://api.example.com/comments', {}, 'Comments API');

const waterfall = profiler.getWaterfallData();
console.log('Waterfall data:', waterfall);
```

### Custom Performance Budget

```javascript
class PerformanceBudget {
  constructor(budgets) {
    this.budgets = budgets; // e.g., { dns: 50, tcp: 100, ttfb: 200, download: 500 }
    this.violations = [];
  }

  async checkFetch(url, options = {}) {
    const start = performance.now();
    const response = await fetch(url, options);
    await response.json();
    
    // Get resource timing
    const entries = performance.getEntriesByName(url);
    const entry = entries[entries.length - 1];
    
    if (!entry) {
      return { passed: false, reason: 'No timing data available' };
    }

    const metrics = {
      dns: entry.domainLookupEnd - entry.domainLookupStart,
      tcp: entry.connectEnd - entry.connectStart,
      ttfb: entry.responseStart - entry.requestStart,
      download: entry.responseEnd - entry.responseStart,
      total: entry.responseEnd - entry.fetchStart
    };

    const violations = [];
    
    for (const [metric, budget] of Object.entries(this.budgets)) {
      if (metrics[metric] > budget) {
        violations.push({
          metric,
          actual: metrics[metric],
          budget,
          exceeded: metrics[metric] - budget
        });
      }
    }

    if (violations.length > 0) {
      this.violations.push({ url, violations, timestamp: Date.now() });
    }

    return {
      passed: violations.length === 0,
      metrics,
      violations
    };
  }

  getViolations() {
    return this.violations;
  }

  clear() {
    this.violations = [];
  }
}

// Usage
const budget = new PerformanceBudget({
  dns: 50,
  tcp: 100,
  ttfb: 200,
  download: 500,
  total: 1000
});

const result = await budget.checkFetch('https://api.example.com/data');
if (!result.passed) {
  console.warn('Performance budget violations:', result.violations);
}
```

### Comprehensive Performance Suite

```javascript
class FetchPerformanceSuite {
  constructor() {
    this.monitor = new FetchPerformanceMonitor();
    this.waterfallProfiler = new FetchWaterfallProfiler();
    this.results = [];
  }

  async profile(url, options = {}, config = {}) {
    const {
      measureMemory = false,
      measureCache = false,
      label = url
    } = config;

    const result = {
      url,
      label,
      timestamp: Date.now(),
      timings: {},
      resourceTiming: null,
      memory: null,
      cache: null
    };

    // Basic timing
    const start = performance.now();
    const response = await fetch(url, options);
    const responseTime = performance.now();
    const data = await response.json();
    const parseTime = performance.now();

    result.timings = {
      network: responseTime - start,
      parse: parseTime - responseTime,
      total: parseTime - start
    };

    // Resource timing
    const entries = performance.getEntriesByName(url);
    if (entries.length > 0) {
      const entry = entries[entries.length - 1];
      result.resourceTiming = analyzeResourceTiming(entry);
    }

    // Memory profiling
    if (measureMemory && 'memory' in performance) {
      const memProfiler = new FetchMemoryProfiler();
      result.memory = memProfiler.getMemorySnapshot();
    }

    // Cache performance
    if (measureCache) {
      result.cache = await profileCachePerformance(url, options);
    }

    this.results.push(result);
    
    return {
      data,
      performance: result
    };
  }

  getReport() {
    if (this.results.length === 0) {
      return { error: 'No profiling data available' };
    }

    const timings = this.results.map(r => r.timings);
    
    return {
      count: this.results.length,
      averages: {
        network: timings.reduce((sum, t) => sum + t.network, 0) / timings.length,
        parse: timings.reduce((sum, t) => sum + t.parse, 0) / timings.length,
        total: timings.reduce((sum, t) => sum + t.total, 0) / timings.length
      },
      min: {
        network: Math.min(...timings.map(t => t.network)),
        parse: Math.min(...timings.map(t => t.parse)),
        total: Math.min(...timings.map(t => t.total))
      },
      max: {
        network: Math.max(...timings.map(t => t.network)),
        parse: Math.max(...timings.map(t => t.parse)),
        total: Math.max(...timings.map(t => t.total))
      },
      results: this.results
    };
  }

  exportData(format = 'json') {
    const report = this.getReport();
    
    if (format === 'json') {
      return JSON.stringify(report, null, 2);
    }
    
    if (format === 'csv') {
      // Simple CSV export
      const headers = ['URL', 'Label', 'Network (ms)', 'Parse (ms)', 'Total (ms)'];
      const rows = this.results.map(r => [
        r.url,
        r.label,
        r.timings.network.toFixed(2),
        r.timings.parse.toFixed(2),
        r.timings.total.toFixed(2)
      ]);
      
      return [headers, ...rows].map(row => row.join(',')).join('\n');
    }
    
    return report;
  }

  clear() {
    this.results = [];
  }
}

// Usage
const suite = new FetchPerformanceSuite();

await suite.profile('https://api.example.com/users', {}, { 
  label: 'Users API',
  measureMemory: true,
  measureCache: true
});

await suite.profile('https://api.example.com/posts', {}, { 
  label: 'Posts API'
});

const report = suite.getReport();
console.log('Performance Report:', report);

// Export as CSV
const csv = suite.exportData('csv');
console.log(csv);
```

---

## HAR File Analysis

### Structure and Components

HAR (HTTP Archive) files use JSON format conforming to the HAR 1.2 specification. The root structure contains metadata and an array of page loads with their associated network requests.

**Root Structure:**

```json
{
  "log": {
    "version": "1.2",
    "creator": {
      "name": "Browser DevTools",
      "version": "1.0"
    },
    "browser": {
      "name": "Chrome",
      "version": "120.0.0"
    },
    "pages": [],
    "entries": []
  }
}
```

### Pages Array

Contains metadata about page loads and navigation events.

**Page Object:**

```json
{
  "startedDateTime": "2024-01-15T10:30:00.000Z",
  "id": "page_1",
  "title": "Example Page",
  "pageTimings": {
    "onContentLoad": 1240,
    "onLoad": 2350
  }
}
```

**Key Fields:**

- `startedDateTime`: ISO 8601 timestamp of page load initiation
- `id`: Unique identifier linking entries to pages
- `pageTimings.onContentLoad`: DOMContentLoaded event timing (milliseconds)
- `pageTimings.onLoad`: Window load event timing (milliseconds)

### Entries Array

Core component containing individual HTTP request/response pairs.

**Entry Structure:**

```json
{
  "pageref": "page_1",
  "startedDateTime": "2024-01-15T10:30:00.123Z",
  "time": 245.67,
  "request": {},
  "response": {},
  "cache": {},
  "timings": {},
  "serverIPAddress": "93.184.216.34",
  "connection": "443"
}
```

**Entry Fields:**

- `pageref`: Links entry to specific page load
- `time`: Total request duration in milliseconds
- `serverIPAddress`: Resolved IP address of the server
- `connection`: Port number or connection identifier

### Request Object

**Complete Structure:**

```json
{
  "method": "GET",
  "url": "https://example.com/api/data",
  "httpVersion": "HTTP/2",
  "headers": [
    {
      "name": "User-Agent",
      "value": "Mozilla/5.0..."
    }
  ],
  "queryString": [
    {
      "name": "id",
      "value": "123"
    }
  ],
  "cookies": [
    {
      "name": "session",
      "value": "abc123",
      "path": "/",
      "domain": ".example.com",
      "expires": "2024-12-31T23:59:59.000Z",
      "httpOnly": true,
      "secure": true
    }
  ],
  "headersSize": 432,
  "bodySize": 0,
  "postData": {
    "mimeType": "application/json",
    "text": "{\"key\":\"value\"}"
  }
}
```

**Headers Analysis:**

- Array of name-value pairs
- Case-insensitive header names
- Multiple headers with same name possible
- `headersSize`: Total bytes of headers including HTTP line

**Query Parameters:**

- Parsed from URL query string
- Decoded values
- Preserves parameter order

**POST Data:**

- `mimeType`: Content-Type of request body
- `text`: Request body as string
- `params`: Form data parsed into name-value pairs (for application/x-www-form-urlencoded)

### Response Object

**Complete Structure:**

```json
{
  "status": 200,
  "statusText": "OK",
  "httpVersion": "HTTP/2",
  "headers": [
    {
      "name": "Content-Type",
      "value": "application/json"
    }
  ],
  "cookies": [],
  "content": {
    "size": 1234,
    "compression": 800,
    "mimeType": "application/json",
    "text": "{\"data\":\"value\"}",
    "encoding": "base64"
  },
  "redirectURL": "",
  "headersSize": 256,
  "bodySize": 1234,
  "_transferSize": 434
}
```

**Content Object:**

- `size`: Uncompressed response body size in bytes
- `compression`: Bytes saved through compression (size - bodySize)
- `text`: Response body content
- `encoding`: Encoding of text field (typically "base64" for binary content)
- `mimeType`: Content-Type from response headers

**Transfer Metrics:**

- `headersSize`: Bytes of response headers
- `bodySize`: Compressed response body size
- `_transferSize`: Actual bytes transferred over network (non-standard field)

### Timing Object

Detailed breakdown of request phases following Resource Timing API specification.

**Complete Timing Structure:**

```json
{
  "blocked": 2.34,
  "dns": 15.67,
  "connect": 45.23,
  "send": 0.12,
  "wait": 120.45,
  "receive": 62.11,
  "ssl": 30.89
}
```

**Timing Phases:**

1. **blocked** (`-1` or positive milliseconds)
    
    - Time spent in browser queue before request starts
    - Includes waiting for available connection slot
    - `-1` indicates timing not available
2. **dns** (`-1` or ≥0 milliseconds)
    
    - DNS lookup duration
    - `0` for cached DNS entries
    - `-1` if already resolved or not applicable
3. **connect** (`-1` or ≥0 milliseconds)
    
    - TCP connection establishment time
    - Includes TCP handshake
    - `0` for reused connections
    - Includes `ssl` time when HTTPS
4. **ssl** (`-1` or ≥0 milliseconds)
    
    - TLS/SSL handshake duration
    - Only present for HTTPS connections
    - `-1` for HTTP or reused SSL sessions
5. **send** (≥0 milliseconds)
    
    - Time to transmit request to server
    - Typically very small for GET requests
    - Larger for POST/PUT with request bodies
6. **wait** (≥0 milliseconds)
    
    - Time from last byte sent until first byte received (TTFB - Time To First Byte)
    - Server processing time
    - Most critical metric for backend performance
7. **receive** (≥0 milliseconds)
    
    - Time to download response body
    - From first byte to last byte received
    - Affected by bandwidth and payload size

**Total Time Calculation:**

```
time = blocked + dns + connect + send + wait + receive
```

### Cache Object

**Structure:**

```json
{
  "beforeRequest": {
    "lastAccess": "2024-01-15T10:25:00.000Z",
    "eTag": "\"abc123\"",
    "hitCount": 5
  },
  "afterRequest": {
    "lastAccess": "2024-01-15T10:30:00.000Z",
    "eTag": "\"abc123\"",
    "hitCount": 6
  }
}
```

**Cache States:**

- Both objects empty: Cache miss, resource fetched from server
- `beforeRequest` populated: Resource was in cache before request
- `afterRequest` populated: Resource cached after request
- `eTag` matching: Cache validation occurred

### Performance Analysis Techniques

**Waterfall Generation:**

Calculate start time relative to first request:

```javascript
function generateWaterfall(entries) {
  const firstStart = new Date(entries[0].startedDateTime).getTime();
  
  return entries.map(entry => {
    const start = new Date(entry.startedDateTime).getTime();
    const relativeStart = start - firstStart;
    
    return {
      url: entry.request.url,
      start: relativeStart,
      duration: entry.time,
      timings: entry.timings
    };
  });
}
```

**Identifying Bottlenecks:**

```javascript
function findSlowRequests(entries, threshold = 1000) {
  return entries
    .filter(entry => entry.time > threshold)
    .map(entry => ({
      url: entry.request.url,
      duration: entry.time,
      wait: entry.timings.wait,
      size: entry.response.content.size
    }))
    .sort((a, b) => b.duration - a.duration);
}
```

**DNS Performance:**

```javascript
function analyzeDNS(entries) {
  const dnsLookups = entries
    .filter(entry => entry.timings.dns > 0)
    .map(entry => ({
      domain: new URL(entry.request.url).hostname,
      duration: entry.timings.dns
    }));
  
  const byDomain = dnsLookups.reduce((acc, lookup) => {
    if (!acc[lookup.domain]) {
      acc[lookup.domain] = [];
    }
    acc[lookup.domain].push(lookup.duration);
    return acc;
  }, {});
  
  return Object.entries(byDomain).map(([domain, durations]) => ({
    domain,
    count: durations.length,
    avgDuration: durations.reduce((a, b) => a + b) / durations.length
  }));
}
```

**Connection Reuse Analysis:**

```javascript
function analyzeConnectionReuse(entries) {
  const connections = entries.reduce((acc, entry) => {
    const key = `${entry.serverIPAddress}:${entry.connection}`;
    if (!acc[key]) {
      acc[key] = {
        ip: entry.serverIPAddress,
        port: entry.connection,
        requests: [],
        newConnections: 0
      };
    }
    
    acc[key].requests.push(entry);
    if (entry.timings.connect > 0) {
      acc[key].newConnections++;
    }
    
    return acc;
  }, {});
  
  return Object.values(connections).map(conn => ({
    ...conn,
    reuseRatio: 1 - (conn.newConnections / conn.requests.length)
  }));
}
```

### Resource Type Classification

**By MIME Type:**

```javascript
function classifyResources(entries) {
  const types = {
    html: [],
    css: [],
    javascript: [],
    images: [],
    fonts: [],
    api: [],
    other: []
  };
  
  entries.forEach(entry => {
    const mimeType = entry.response.content.mimeType.toLowerCase();
    
    if (mimeType.includes('text/html')) {
      types.html.push(entry);
    } else if (mimeType.includes('text/css')) {
      types.css.push(entry);
    } else if (mimeType.includes('javascript')) {
      types.javascript.push(entry);
    } else if (mimeType.includes('image/')) {
      types.images.push(entry);
    } else if (mimeType.includes('font')) {
      types.fonts.push(entry);
    } else if (mimeType.includes('application/json') || mimeType.includes('application/xml')) {
      types.api.push(entry);
    } else {
      types.other.push(entry);
    }
  });
  
  return types;
}
```

**Size Analysis by Type:**

```javascript
function analyzeSizeByType(entries) {
  const classified = classifyResources(entries);
  
  return Object.entries(classified).map(([type, resources]) => {
    const totalSize = resources.reduce((sum, r) => sum + r.response.content.size, 0);
    const transferSize = resources.reduce((sum, r) => sum + r.response.bodySize, 0);
    const compressionRatio = totalSize > 0 ? (1 - transferSize / totalSize) : 0;
    
    return {
      type,
      count: resources.length,
      totalSize,
      transferSize,
      compressionRatio: compressionRatio.toFixed(2)
    };
  });
}
```

### HTTP Version Analysis

```javascript
function analyzeHTTPVersions(entries) {
  const versions = entries.reduce((acc, entry) => {
    const version = entry.request.httpVersion;
    if (!acc[version]) {
      acc[version] = {
        count: 0,
        totalTime: 0,
        avgTime: 0
      };
    }
    
    acc[version].count++;
    acc[version].totalTime += entry.time;
    
    return acc;
  }, {});
  
  Object.values(versions).forEach(v => {
    v.avgTime = v.totalTime / v.count;
  });
  
  return versions;
}
```

### Cache Hit Analysis

**Identifying Cache Behavior:**

```javascript
function analyzeCacheHits(entries) {
  const cacheStats = {
    hits: 0,
    misses: 0,
    validations: 0,
    fromCache: []
  };
  
  entries.forEach(entry => {
    // Cache hit: 304 Not Modified
    if (entry.response.status === 304) {
      cacheStats.validations++;
    }
    // Served from cache: no network time
    else if (entry.timings.send === -1 && entry.timings.wait === -1) {
      cacheStats.hits++;
      cacheStats.fromCache.push(entry.request.url);
    }
    // Cache validation with beforeRequest data
    else if (entry.cache.beforeRequest && Object.keys(entry.cache.beforeRequest).length > 0) {
      cacheStats.validations++;
    }
    // Cache miss
    else {
      cacheStats.misses++;
    }
  });
  
  cacheStats.hitRate = cacheStats.hits / entries.length;
  
  return cacheStats;
}
```

### Third-Party Domain Analysis

```javascript
function analyzeThirdPartyDomains(entries, primaryDomain) {
  const domains = entries.reduce((acc, entry) => {
    const url = new URL(entry.request.url);
    const domain = url.hostname;
    const isThirdParty = !domain.includes(primaryDomain);
    
    if (!acc[domain]) {
      acc[domain] = {
        domain,
        isThirdParty,
        requests: [],
        totalSize: 0,
        totalTime: 0
      };
    }
    
    acc[domain].requests.push(entry);
    acc[domain].totalSize += entry.response.content.size;
    acc[domain].totalTime += entry.time;
    
    return acc;
  }, {});
  
  return Object.values(domains)
    .sort((a, b) => b.totalSize - a.totalSize);
}
```

### Response Header Analysis

**Security Headers:**

```javascript
function analyzeSecurityHeaders(entries) {
  const securityHeaders = [
    'strict-transport-security',
    'content-security-policy',
    'x-frame-options',
    'x-content-type-options',
    'referrer-policy',
    'permissions-policy'
  ];
  
  return entries.map(entry => {
    const headers = entry.response.headers.reduce((acc, h) => {
      acc[h.name.toLowerCase()] = h.value;
      return acc;
    }, {});
    
    const missing = securityHeaders.filter(h => !headers[h]);
    
    return {
      url: entry.request.url,
      presentHeaders: securityHeaders.filter(h => headers[h]),
      missingHeaders: missing
    };
  });
}
```

**Caching Headers:**

```javascript
function analyzeCachingHeaders(entries) {
  return entries.map(entry => {
    const headers = entry.response.headers.reduce((acc, h) => {
      acc[h.name.toLowerCase()] = h.value;
      return acc;
    }, {});
    
    const cacheControl = headers['cache-control'] || '';
    const expires = headers['expires'] || '';
    const etag = headers['etag'] || '';
    const lastModified = headers['last-modified'] || '';
    
    return {
      url: entry.request.url,
      cacheControl,
      expires,
      etag,
      lastModified,
      isCacheable: cacheControl.includes('max-age') || expires !== ''
    };
  });
}
```

### Compression Analysis

```javascript
function analyzeCompression(entries) {
  return entries
    .filter(entry => entry.response.content.compression !== undefined)
    .map(entry => {
      const content = entry.response.content;
      const originalSize = content.size;
      const compressedSize = entry.response.bodySize;
      const savings = originalSize - compressedSize;
      const ratio = originalSize > 0 ? (savings / originalSize) : 0;
      
      const encoding = entry.response.headers
        .find(h => h.name.toLowerCase() === 'content-encoding')?.value || 'none';
      
      return {
        url: entry.request.url,
        mimeType: content.mimeType,
        originalSize,
        compressedSize,
        savings,
        ratio: ratio.toFixed(2),
        encoding
      };
    })
    .sort((a, b) => b.savings - a.savings);
}
```

### Request Priority Analysis

Many browsers include priority hints in HAR files (non-standard field).

```javascript
function analyzePriorities(entries) {
  const withPriority = entries.filter(e => e._priority);
  
  const byPriority = withPriority.reduce((acc, entry) => {
    const priority = entry._priority;
    if (!acc[priority]) {
      acc[priority] = {
        count: 0,
        resources: []
      };
    }
    
    acc[priority].count++;
    acc[priority].resources.push({
      url: entry.request.url,
      type: entry.response.content.mimeType,
      startTime: entry.startedDateTime
    });
    
    return acc;
  }, {});
  
  return byPriority;
}
```

### Cookie Analysis

**Size and Count:**

```javascript
function analyzeCookies(entries) {
  const cookieStats = entries.map(entry => {
    const requestCookies = entry.request.cookies;
    const responseCookies = entry.response.cookies;
    
    const requestCookieSize = requestCookies.reduce((sum, c) => {
      return sum + c.name.length + c.value.length;
    }, 0);
    
    return {
      url: entry.request.url,
      requestCookieCount: requestCookies.length,
      requestCookieSize,
      responseCookieCount: responseCookies.length,
      setCookies: responseCookies.map(c => ({
        name: c.name,
        httpOnly: c.httpOnly,
        secure: c.secure,
        sameSite: c.sameSite
      }))
    };
  });
  
  return cookieStats;
}
```

### Redirect Chain Analysis

```javascript
function analyzeRedirects(entries) {
  const chains = [];
  const processed = new Set();
  
  entries.forEach((entry, index) => {
    if (processed.has(index)) return;
    
    const status = entry.response.status;
    if (status >= 300 && status < 400) {
      const chain = [entry];
      processed.add(index);
      
      let redirectURL = entry.response.redirectURL;
      while (redirectURL) {
        const nextEntry = entries.find((e, i) => {
          if (processed.has(i)) return false;
          if (e.request.url === redirectURL) {
            processed.add(i);
            return true;
          }
          return false;
        });
        
        if (nextEntry) {
          chain.push(nextEntry);
          redirectURL = nextEntry.response.redirectURL;
        } else {
          break;
        }
      }
      
      if (chain.length > 1) {
        chains.push({
          length: chain.length,
          totalTime: chain.reduce((sum, e) => sum + e.time, 0),
          urls: chain.map(e => e.request.url),
          statuses: chain.map(e => e.response.status)
        });
      }
    }
  });
  
  return chains;
}
```

### Failed Request Analysis

```javascript
function analyzeFailures(entries) {
  const failures = entries.filter(entry => {
    const status = entry.response.status;
    return status >= 400 || status === 0;
  });
  
  return failures.map(entry => ({
    url: entry.request.url,
    status: entry.response.status,
    statusText: entry.response.statusText,
    method: entry.request.method,
    time: entry.time,
    errorDetails: entry._error || null
  }));
}
```

### Custom Fields

HAR files often contain browser-specific or tool-specific fields prefixed with underscore.

**Common Custom Fields:**

- `_priority`: Resource loading priority (Chrome)
- `_initiator`: What triggered the request (Chrome)
- `_resourceType`: Resource category (Chrome)
- `_transferSize`: Actual network transfer size
- `_error`: Error details for failed requests

**Parsing Custom Fields:**

```javascript
function extractCustomFields(entry) {
  const custom = {};
  
  Object.keys(entry).forEach(key => {
    if (key.startsWith('_')) {
      custom[key] = entry[key];
    }
  });
  
  return custom;
}
```

### Reading HAR Files

**Browser-based Parsing:**

```javascript
async function parseHAR(file) {
  const text = await file.text();
  const har = JSON.parse(text);
  
  return {
    version: har.log.version,
    creator: har.log.creator,
    browser: har.log.browser,
    pages: har.log.pages,
    entries: har.log.entries
  };
}
```

**Node.js Parsing:**

```javascript
const fs = require('fs').promises;

async function loadHAR(filepath) {
  const content = await fs.readFile(filepath, 'utf-8');
  const har = JSON.parse(content);
  return har.log;
}
```

### Generating HAR Files Programmatically

**Using Puppeteer:**

```javascript
const puppeteer = require('puppeteer');

async function captureHAR(url) {
  const browser = await puppeteer.launch();
  const page = await browser.newPage();
  
  await page.tracing.start({
    path: 'trace.json',
    screenshots: false
  });
  
  const client = await page.target().createCDPSession();
  await client.send('Network.enable');
  
  const entries = [];
  
  client.on('Network.requestWillBeSent', (params) => {
    // Capture request details
  });
  
  client.on('Network.responseReceived', (params) => {
    // Capture response details
  });
  
  await page.goto(url, { waitUntil: 'networkidle0' });
  
  await browser.close();
  
  return {
    log: {
      version: '1.2',
      creator: { name: 'Puppeteer', version: '1.0' },
      entries
    }
  };
}
```

### Validation

**Schema Validation:**

```javascript
function validateHAR(har) {
  const errors = [];
  
  if (!har.log) {
    errors.push('Missing log object');
    return errors;
  }
  
  if (!har.log.version) {
    errors.push('Missing version');
  }
  
  if (!har.log.creator) {
    errors.push('Missing creator');
  }
  
  if (!Array.isArray(har.log.entries)) {
    errors.push('Entries must be an array');
  }
  
  har.log.entries.forEach((entry, index) => {
    if (!entry.request) {
      errors.push(`Entry ${index}: Missing request object`);
    }
    
    if (!entry.response) {
      errors.push(`Entry ${index}: Missing response object`);
    }
    
    if (typeof entry.time !== 'number') {
      errors.push(`Entry ${index}: Invalid time value`);
    }
  });
  
  return errors;
}
```

### Performance Metrics Calculation

**Web Vitals from HAR:**

```javascript
function calculateWebVitals(entries, pages) {
  const page = pages[0];
  const navigationEntry = entries[0];
  
  // First Contentful Paint estimation
  const fcpEntry = entries.find(e => 
    e.response.content.mimeType.includes('html')
  );
  
  // Largest Contentful Paint estimation
  const imageEntries = entries
    .filter(e => e.response.content.mimeType.includes('image'))
    .sort((a, b) => b.response.content.size - a.response.content.size);
  
  const lcpEntry = imageEntries[0];
  
  return {
    // Time to First Byte
    ttfb: navigationEntry.timings.wait,
    
    // First Contentful Paint (approximation)
    fcp: fcpEntry ? 
      (new Date(fcpEntry.startedDateTime) - new Date(navigationEntry.startedDateTime)) + fcpEntry.time : 
      null,
    
    // DOM Content Loaded
    dcl: page.pageTimings.onContentLoad,
    
    // Load Event
    load: page.pageTimings.onLoad,
    
    // Largest Contentful Paint (approximation)
    lcp: lcpEntry ?
      (new Date(lcpEntry.startedDateTime) - new Date(navigationEntry.startedDateTime)) + lcpEntry.time :
      null
  };
}
```

---

## Proxy Tools for Development

### Charles Proxy

#### Installation and Setup

Charles Proxy is a cross-platform HTTP debugging proxy that captures network traffic between applications and the internet.

**Basic Configuration:**

- Download from https://www.charlesproxy.com
- Install SSL certificates for HTTPS inspection
- Configure system proxy: automatically sets to `127.0.0.1:8888`
- Trust Charles root certificate in system keychain

**SSL Certificate Installation:**

1. Help → SSL Proxying → Install Charles Root Certificate
2. Trust certificate for SSL proxying
3. Enable SSL Proxying: Proxy → SSL Proxying Settings
4. Add location: `*:443` or specific domains

#### Inspecting Fetch Requests

**View Request Details:**

- Structure view: organized by domain hierarchy
- Sequence view: chronological request order
- Request tab: headers, parameters, body
- Response tab: status, headers, content

**Key Information Visible:**

- Request method, URL, protocol
- Request/response headers
- Query parameters and form data
- Request/response body (JSON, XML, binary)
- Timing information (DNS, Connect, Request, Response)
- WebSocket frames

#### Breakpoints

Set breakpoints to pause and modify requests/responses:

**Request Breakpoints:**

```
Proxy → Breakpoint Settings → Add
- Host: api.example.com
- Port: 443
- Path: /users/*
```

When breakpoint triggers:

- Edit URL parameters
- Modify request headers
- Change request body
- Add authentication tokens
- Cancel or execute request

**Response Breakpoints:**

- Modify response status code
- Edit response headers
- Change response body
- Simulate different data structures

**Practical Example:**

```javascript
// Original fetch request
fetch('https://api.example.com/users/123')
  .then(r => r.json())
  .then(data => console.log(data));

// With Charles breakpoint:
// 1. Request pauses at breakpoint
// 2. Change URL to /users/456
// 3. Add header: X-Debug: true
// 4. Execute to continue
```

#### Throttling and Bandwidth Simulation

Simulate slow connections to test fetch behavior:

**Throttle Settings:**

```
Proxy → Throttle Settings
- Enable throttling
- Throttle preset: 3G, 4G, LTE, Custom
- Bandwidth: upload/download speeds
- Utilisation: percentage of bandwidth
- Round-trip latency
- MTU (Maximum Transmission Unit)
```

**Common Presets:**

- 3G: 780 kbps down, 330 kbps up, 100ms latency
- 4G: 9 Mbps down, 9 Mbps up, 50ms latency
- Edge: 240 kbps down, 200 kbps up, 840ms latency

**Testing Fetch Timeouts:**

```javascript
// Test with throttling enabled
const controller = new AbortController();
setTimeout(() => controller.abort(), 3000);

fetch('https://api.example.com/large-file', {
  signal: controller.signal
}).catch(err => {
  // Timeout will trigger with slow throttling
  console.log('Request timeout:', err);
});
```

#### Map Local and Map Remote

**Map Local:** Redirect network requests to local files:

```
Tools → Map Local
- Map From: https://api.example.com/config.json
- Map To: /Users/dev/mock-data/config.json
```

Use cases:

- Test with mock data without backend changes
- Develop offline with cached responses
- Test different response scenarios

**Map Remote:** Redirect requests to different endpoints:

```
Tools → Map Remote
- Map From: https://api.staging.com
- Map To: https://api.production.com
```

Use cases:

- Test production API from staging environment
- Switch between API versions
- Route to local development server

#### Rewrite Tool

Modify requests/responses automatically:

**Rewrite Rules:**

```
Tools → Rewrite
- Type: Modify Header
- Where: Request
- Match: Authorization
- Replace: Bearer new-token-here
```

**Rule Types:**

- Add/Modify/Remove header
- Add/Modify/Remove query parameter
- Modify path
- Modify host
- Modify URL
- Modify body
- Modify response status

**Example Scenarios:**

```javascript
// Rewrite Rule: Add CORS headers to any response
// Response Header: Access-Control-Allow-Origin: *

fetch('https://third-party-api.com/data')
  .then(r => r.json())
  // CORS header automatically added by Charles
  .then(data => console.log(data));
```

#### Recording and Sessions

**Session Management:**

- Record automatically on startup
- Save session: File → Save Session
- Export formats: .chls (Charles), .har (HTTP Archive)
- Import previous sessions for analysis

**Filtering:**

```
Proxy → Recording Settings
- Include: specific domains
- Exclude: analytics, ads, tracking
```

**Session Analysis:**

- Total requests/responses
- Failed requests
- Average response time
- Total data transferred
- Request distribution by domain

#### Repeat and Compose

**Repeat Tool:** Right-click request → Repeat

- Repeat once
- Repeat advanced (specify count)
- Useful for testing rate limiting
- Test load handling

**Compose Tool:** Create requests from scratch:

```
Tools → Compose
- Set method: GET, POST, PUT, DELETE
- Enter URL
- Add headers
- Add body (raw, form, multipart)
- Execute request
```

**Testing Custom Fetch Configurations:**

```javascript
// Test this fetch configuration in Charles Compose:
fetch('https://api.example.com/data', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer token123'
  },
  body: JSON.stringify({ key: 'value' })
});

// Use Compose to verify:
// - Correct headers sent
// - Body formatted properly
// - Authentication working
// - Response as expected
```

#### Mirror Tool

Duplicate traffic to another server:

```
Tools → Mirror
- Mirror To: https://backup-server.com
```

Use cases:

- Send production traffic to staging
- Duplicate requests for testing
- Load testing parallel servers

### Fiddler

#### Installation and Setup

Fiddler is a Windows-focused HTTP debugging proxy (Fiddler Classic) with cross-platform Fiddler Everywhere.

**Basic Configuration:**

- Download from https://www.telerik.com/fiddler
- Default proxy: `127.0.0.1:8888`
- Enable HTTPS decryption: Tools → Options → HTTPS
- Install Fiddler root certificate

**Fiddler Everywhere:**

- Modern cross-platform version (Windows, Mac, Linux)
- Cloud-based collaboration features
- Similar core functionality to Classic

#### Inspecting Traffic

**Session List:**

- Left panel: chronological list of requests
- Columns: Result, Protocol, Host, URL, Body, Caching
- Color coding: 200s (green), 300s (blue), 400s/500s (red)

**Inspectors:**

- Headers: raw headers, formatted view
- TextView: response as text
- WebForms: POST data, query strings
- JSON: formatted JSON viewer
- XML: structured XML view
- Raw: unprocessed request/response

**Request Details:**

```javascript
// Fetch request
fetch('https://api.example.com/users', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'John' })
});

// Fiddler shows:
// - Raw HTTP request/response
// - Timing information
// - Request/response sizes
// - Compression details
```

#### AutoResponder

Automatically respond to requests with custom responses:

**Creating Rules:**

```
AutoResponder tab → Add Rule
- Rule: EXACT:https://api.example.com/users
- Response: C:\mock-data\users.json

OR

- Rule: regex:(?inx)^https://api\.example\.com/.*
- Response: *404
```

**Response Types:**

- Local file path
- HTTP status code (404, 500, 302)
- Built-in responses (*bpafter, *delay:ms)
- Another captured session

**Latency Simulation:**

```
Rule: REGEX:api.example.com
Response: *delay:2000 *bpafter
```

**Testing Scenarios:**

```javascript
// Test error handling
fetch('https://api.example.com/data')
  .then(r => {
    if (!r.ok) throw new Error('API Error');
    return r.json();
  })
  .catch(err => console.error(err));

// AutoResponder rule: respond with 500 status
// Test if error handling works correctly
```

#### Breakpoints

**Setting Breakpoints:**

- Before requests: Rules → Automatic Breakpoints → Before Requests
- After responses: Rules → Automatic Breakpoints → After Responses
- Specific requests: Right-click session → Breakpoint

**Request Modification:** When paused at breakpoint:

- Edit raw request text
- Modify headers in Inspector
- Change request body
- Edit URL
- Click "Run to Completion" or "Break on Response"

**Response Modification:**

- Change status code
- Edit response headers
- Modify response body
- Test different content types

#### FiddlerScript

Customize Fiddler behavior with JScript:

**Common Scripts:**

```javascript
// Rules → Customize Rules (FiddlerScript editor)

// Highlight specific requests
static function OnBeforeRequest(oSession: Session) {
    if (oSession.uriContains("api.example.com")) {
        oSession["ui-color"] = "orange";
        oSession["ui-bold"] = "true";
    }
}

// Add custom header to all requests
static function OnBeforeRequest(oSession: Session) {
    oSession.oRequest["X-Custom-Header"] = "DebugMode";
}

// Log specific request data
static function OnBeforeResponse(oSession: Session) {
    if (oSession.uriContains("/api/")) {
        FiddlerApplication.Log.LogString(
            oSession.responseCode + " - " + oSession.fullUrl
        );
    }
}

// Modify response status
static function OnBeforeResponse(oSession: Session) {
    if (oSession.uriContains("/test-error")) {
        oSession.responseCode = 500;
    }
}

// Delay specific requests
static function OnBeforeRequest(oSession: Session) {
    if (oSession.uriContains("slow-endpoint")) {
        oSession["request-trickle-delay"] = "3000";
    }
}
```

**Testing Fetch with Scripts:**

```javascript
// Your fetch code
async function getData() {
    const response = await fetch('https://api.example.com/data');
    return response.json();
}

// FiddlerScript to test different scenarios:
// 1. Add authentication header automatically
// 2. Delay response to test loading states
// 3. Return mock data for specific endpoints
// 4. Log all API calls for debugging
```

#### Composer

Build and send custom requests:

**Request Builder:**

```
Composer tab
- HTTP Method: GET, POST, PUT, DELETE, PATCH
- URL: https://api.example.com/endpoint
- Request Headers:
    Content-Type: application/json
    Authorization: Bearer token
- Request Body:
    {"key": "value"}
- Execute
```

**Upload Files:**

```
- Method: POST
- Body format: multipart/form-data
- Add files: Upload File section
- Add form fields
```

**Save Requests:**

- Save as .saz file
- Import saved requests
- Share with team members

#### Filters

Focus on relevant traffic:

**Hosts Filter:**

```
Filters tab
- Show only: api.example.com, cdn.example.com
- Hide: google-analytics.com, facebook.com
```

**Request Headers Filter:**

```
- Flag requests with header: Authorization
- Delete request header: Cookie
- Set request header: X-Debug-Mode: true
```

**Response Headers Filter:**

```
- Delete response header: Set-Cookie
- Set response header: Access-Control-Allow-Origin: *
```

**Breakpoint Filters:**

```
- Break on POST requests only
- Break on requests to specific domain
- Break on responses with status 400+
```

#### Connection Simulation

**Modem Speeds:**

```
Rules → Performance → Simulate Modem Speeds
```

Options:

- No simulation
- 56K modem: 56 kbps
- ISDN: 128 kbps
- 300 baud: extremely slow

**Custom Delays:**

```javascript
// FiddlerScript
static function OnBeforeRequest(oSession: Session) {
    if (oSession.uriContains("api")) {
        oSession["request-trickle-delay"] = "1000";  // 1 second delay
        oSession["response-trickle-delay"] = "2000"; // 2 second delay
    }
}
```

#### Export and Reporting

**Export Formats:**

- HTTPArchive (.har): industry standard
- Fiddler Session Archive (.saz)
- Raw text
- CSV
- XML

**Session Statistics:**

```
Statistics tab
- Total requests
- Response codes distribution
- Content types
- Bytes sent/received
- Time charts
```

**Timeline View:**

```
Timeline tab (Fiddler Everywhere)
- Waterfall chart
- Request timing breakdown
- DNS lookup time
- Connection time
- SSL handshake time
- Time to first byte
- Download time
```

### Comparison: Charles vs Fiddler

#### Feature Comparison

**Charles Advantages:**

- Better macOS integration
- Cleaner, more intuitive UI
- Built-in bandwidth throttling presets
- Better WebSocket support
- Map Local/Remote features more polished
- Easier SSL certificate setup on macOS

**Fiddler Advantages:**

- Free (Classic version)
- More powerful scripting with FiddlerScript
- Better Windows integration
- AutoResponder more flexible
- Composer more feature-rich
- Larger user community and extensions

**Cross-Platform:**

- Charles: Windows, macOS, Linux (mature)
- Fiddler Classic: Windows only
- Fiddler Everywhere: Windows, macOS, Linux (newer)

#### Use Case Recommendations

**Choose Charles for:**

- macOS-centric development
- Teams using Apple ecosystem
- Simpler UI preference
- Built-in bandwidth profiles
- WebSocket heavy applications

**Choose Fiddler for:**

- Windows-centric development
- Complex custom scripting needs
- Budget constraints (Classic is free)
- Advanced AutoResponder scenarios
- Integration with .NET applications

### Common Workflows

#### Testing Fetch Error Handling

**Scenario: Test 404 response**

Charles:

```
1. Tools → Rewrite
2. Add rule: Modify Response Status → 404
3. Apply to specific URL pattern
4. Run fetch request
5. Verify error handling
```

Fiddler:

```
1. AutoResponder → Enable
2. Add rule: url matches → *404
3. Save rule
4. Run fetch request
5. Check error handling
```

#### Testing Timeout Behavior

**Scenario: Simulate slow network**

Charles:

```
1. Proxy → Throttle Settings
2. Enable throttling
3. Select 3G preset or custom
4. Set high latency (500ms+)
5. Test fetch timeout logic
```

Fiddler:

```
1. Rules → Performance → Simulate Modem Speeds
2. OR FiddlerScript: add delays
3. Test timeout handling
```

#### Mock API Responses

**Scenario: Develop with mock data**

Charles:

```
1. Tools → Map Local
2. Map endpoint to local JSON file
3. Update JSON as needed
4. Fetch receives mock data
5. No backend required
```

Fiddler:

```
1. AutoResponder → Enable
2. Add rule matching API endpoint
3. Point to local mock file
4. Edit file to change responses
5. Automatic reload
```

#### Debug CORS Issues

**Scenario: Test cross-origin requests**

Charles:

```
1. Tools → Rewrite
2. Add Response Header rule
3. Header: Access-Control-Allow-Origin: *
4. Apply to failing endpoint
5. Verify fetch succeeds
```

Fiddler:

```
1. Rules → Customize Rules
2. Add CORS headers in OnBeforeResponse
3. OR use Filters to add response headers
4. Test cross-origin fetch
```

#### Capture Mobile App Traffic

**Scenario: Debug fetch in mobile app**

Charles:

```
1. Get computer IP address
2. Configure mobile device proxy:
   - iOS: Settings → Wi-Fi → Proxy → Manual
   - Android: Wi-Fi → Modify Network → Proxy
3. Set proxy to computer_ip:8888
4. Install Charles certificate on device
5. Trust certificate in device settings
6. Capture mobile app traffic
```

Fiddler:

```
1. Tools → Options → Connections
2. Allow remote computers to connect
3. Configure mobile device proxy to computer_ip:8888
4. Install Fiddler certificate on mobile device
5. Capture and inspect mobile traffic
```

### Advanced Techniques

#### Request Chaining

Test dependent fetch calls:

Charles:

```
1. Capture first request response
2. Tools → Rewrite
3. Extract value from first response
4. Inject into second request header
5. Verify chain works
```

Fiddler:

```javascript
// FiddlerScript
static function OnBeforeRequest(oSession: Session) {
    if (oSession.uriContains("second-endpoint")) {
        var firstResponse = getFirstResponseValue();
        oSession.oRequest["X-Previous-Data"] = firstResponse;
    }
}
```

#### Performance Profiling

Identify slow fetch requests:

Both Tools:

1. Record full session
2. Sort by duration
3. Identify slowest requests
4. Check timing breakdown:
    - DNS resolution
    - TCP connection
    - SSL handshake
    - Time to first byte
    - Content download
5. Optimize accordingly

#### Security Testing

Test authentication and authorization:

1. Capture authenticated request
2. Save session/request
3. Compose new request with:
    - Missing auth header
    - Expired token
    - Modified token
    - Different user credentials
4. Verify server validates properly

#### Load Testing Simulation

Test multiple concurrent requests:

Charles:

```
1. Capture request
2. Right-click → Repeat Advanced
3. Set iterations: 100
4. Set concurrency: 10
5. Monitor server responses
```

Fiddler:

```
1. Capture request
2. Right-click → Clone Session
3. Use Composer to send multiple times
4. OR script automatic repeats
5. Check for rate limiting
```

---

## Console Logging Strategies

### Basic Request/Response Logging

```javascript
async function loggedFetch(url, options = {}) {
  const startTime = performance.now();
  const requestId = Math.random().toString(36).substr(2, 9);
  
  console.log(`[${requestId}] → ${options.method || 'GET'} ${url}`);
  
  if (options.body) {
    console.log(`[${requestId}] Body:`, options.body);
  }
  
  if (options.headers) {
    console.log(`[${requestId}] Headers:`, options.headers);
  }
  
  try {
    const response = await fetch(url, options);
    const duration = (performance.now() - startTime).toFixed(2);
    
    console.log(
      `[${requestId}] ← ${response.status} ${response.statusText} (${duration}ms)`
    );
    
    return response;
  } catch (error) {
    const duration = (performance.now() - startTime).toFixed(2);
    console.error(`[${requestId}] ✗ ${error.message} (${duration}ms)`);
    throw error;
  }
}
```

### Structured Logging with Levels

```javascript
const LogLevel = {
  DEBUG: 0,
  INFO: 1,
  WARN: 2,
  ERROR: 3,
  NONE: 4
};

class FetchLogger {
  constructor(level = LogLevel.INFO) {
    this.level = level;
    this.requestCounter = 0;
  }
  
  setLevel(level) {
    this.level = level;
  }
  
  shouldLog(level) {
    return level >= this.level;
  }
  
  debug(...args) {
    if (this.shouldLog(LogLevel.DEBUG)) {
      console.debug(...args);
    }
  }
  
  info(...args) {
    if (this.shouldLog(LogLevel.INFO)) {
      console.info(...args);
    }
  }
  
  warn(...args) {
    if (this.shouldLog(LogLevel.WARN)) {
      console.warn(...args);
    }
  }
  
  error(...args) {
    if (this.shouldLog(LogLevel.ERROR)) {
      console.error(...args);
    }
  }
  
  async fetch(url, options = {}) {
    const requestId = ++this.requestCounter;
    const method = options.method || 'GET';
    const startTime = performance.now();
    
    this.info(`[REQ ${requestId}] ${method} ${url}`);
    this.debug(`[REQ ${requestId}] Options:`, options);
    
    try {
      const response = await fetch(url, options);
      const duration = (performance.now() - startTime).toFixed(2);
      
      if (response.ok) {
        this.info(
          `[RES ${requestId}] ${response.status} ${response.statusText} (${duration}ms)`
        );
      } else {
        this.warn(
          `[RES ${requestId}] ${response.status} ${response.statusText} (${duration}ms)`
        );
      }
      
      this.debug(`[RES ${requestId}] Headers:`, 
        Object.fromEntries(response.headers.entries())
      );
      
      return response;
    } catch (error) {
      const duration = (performance.now() - startTime).toFixed(2);
      this.error(
        `[ERR ${requestId}] ${error.name}: ${error.message} (${duration}ms)`
      );
      throw error;
    }
  }
}

// Usage
const logger = new FetchLogger(LogLevel.INFO);
await logger.fetch('/api/data');

// Enable debug mode
logger.setLevel(LogLevel.DEBUG);
```

### Grouped Console Logs

```javascript
async function fetchWithGroupedLogs(url, options = {}) {
  const method = options.method || 'GET';
  const groupLabel = `${method} ${url}`;
  
  console.group(groupLabel);
  
  const startTime = performance.now();
  
  console.log('Started:', new Date().toISOString());
  
  if (options.headers) {
    console.group('Request Headers');
    Object.entries(options.headers).forEach(([key, value]) => {
      console.log(`${key}:`, value);
    });
    console.groupEnd();
  }
  
  if (options.body) {
    console.log('Request Body:', options.body);
  }
  
  try {
    const response = await fetch(url, options);
    const duration = (performance.now() - startTime).toFixed(2);
    
    console.log(
      `%cStatus: ${response.status} ${response.statusText}`,
      response.ok ? 'color: green' : 'color: red'
    );
    console.log(`Duration: ${duration}ms`);
    
    console.group('Response Headers');
    response.headers.forEach((value, key) => {
      console.log(`${key}:`, value);
    });
    console.groupEnd();
    
    console.groupEnd();
    return response;
  } catch (error) {
    const duration = (performance.now() - startTime).toFixed(2);
    console.error('Error:', error);
    console.log(`Duration: ${duration}ms`);
    console.groupEnd();
    throw error;
  }
}
```

### Styled Console Output

```javascript
const styles = {
  request: 'color: #0066cc; font-weight: bold',
  success: 'color: #00cc66; font-weight: bold',
  error: 'color: #cc0000; font-weight: bold',
  warning: 'color: #ff9900; font-weight: bold',
  info: 'color: #666666',
  duration: 'color: #9966cc; font-style: italic'
};

async function styledFetch(url, options = {}) {
  const method = options.method || 'GET';
  const requestId = Math.random().toString(36).substr(2, 6).toUpperCase();
  const startTime = performance.now();
  
  console.log(
    `%c[${requestId}] →%c ${method} %c${url}`,
    styles.info,
    styles.request,
    styles.info
  );
  
  try {
    const response = await fetch(url, options);
    const duration = (performance.now() - startTime).toFixed(2);
    
    const statusStyle = response.ok ? styles.success : 
                       response.status >= 400 ? styles.error : 
                       styles.warning;
    
    console.log(
      `%c[${requestId}] ←%c ${response.status} ${response.statusText} %c${duration}ms`,
      styles.info,
      statusStyle,
      styles.duration
    );
    
    return response;
  } catch (error) {
    const duration = (performance.now() - startTime).toFixed(2);
    
    console.log(
      `%c[${requestId}] ✗%c ${error.message} %c${duration}ms`,
      styles.info,
      styles.error,
      styles.duration
    );
    
    throw error;
  }
}
```

### Conditional Logging with Environment

```javascript
const isDevelopment = () => {
  try {
    return process.env.NODE_ENV === 'development';
  } catch {
    return location.hostname === 'localhost' || 
           location.hostname === '127.0.0.1';
  }
};

class ConditionalLogger {
  constructor() {
    this.enabled = isDevelopment();
  }
  
  enable() {
    this.enabled = true;
  }
  
  disable() {
    this.enabled = false;
  }
  
  log(...args) {
    if (this.enabled) {
      console.log(...args);
    }
  }
  
  error(...args) {
    if (this.enabled) {
      console.error(...args);
    }
  }
  
  warn(...args) {
    if (this.enabled) {
      console.warn(...args);
    }
  }
  
  group(...args) {
    if (this.enabled) {
      console.group(...args);
    }
  }
  
  groupEnd() {
    if (this.enabled) {
      console.groupEnd();
    }
  }
  
  table(data) {
    if (this.enabled) {
      console.table(data);
    }
  }
}

const devLogger = new ConditionalLogger();
```

### Request/Response Body Logging

```javascript
async function logBodies(url, options = {}) {
  const requestId = Date.now().toString(36);
  
  console.group(`[${requestId}] ${options.method || 'GET'} ${url}`);
  
  // Log request body
  if (options.body) {
    try {
      let bodyContent = options.body;
      
      if (options.body instanceof FormData) {
        console.log('Request Body (FormData):');
        for (const [key, value] of options.body.entries()) {
          console.log(`  ${key}:`, value);
        }
      } else if (typeof options.body === 'string') {
        try {
          bodyContent = JSON.parse(options.body);
          console.log('Request Body (JSON):', bodyContent);
        } catch {
          console.log('Request Body (Text):', options.body);
        }
      } else {
        console.log('Request Body:', options.body);
      }
    } catch (error) {
      console.warn('Could not log request body:', error);
    }
  }
  
  try {
    const response = await fetch(url, options);
    
    console.log(`Status: ${response.status} ${response.statusText}`);
    
    // Clone response to log body without consuming it
    const cloned = response.clone();
    
    const contentType = response.headers.get('content-type');
    
    if (contentType?.includes('application/json')) {
      try {
        const data = await cloned.json();
        console.log('Response Body (JSON):', data);
      } catch (error) {
        console.warn('Failed to parse JSON response:', error);
      }
    } else if (contentType?.includes('text/')) {
      try {
        const text = await cloned.text();
        console.log('Response Body (Text):', text);
      } catch (error) {
        console.warn('Failed to read text response:', error);
      }
    } else {
      console.log('Response Body: (binary data, not logged)');
    }
    
    console.groupEnd();
    return response;
  } catch (error) {
    console.error('Request failed:', error);
    console.groupEnd();
    throw error;
  }
}
```

### Performance Metrics Logging

```javascript
class PerformanceLogger {
  constructor() {
    this.metrics = [];
  }
  
  async fetch(url, options = {}) {
    const startMark = `fetch-start-${Date.now()}`;
    const endMark = `fetch-end-${Date.now()}`;
    const measureName = `fetch-${url}`;
    
    performance.mark(startMark);
    
    const startTime = performance.now();
    const method = options.method || 'GET';
    
    try {
      const response = await fetch(url, options);
      
      performance.mark(endMark);
      performance.measure(measureName, startMark, endMark);
      
      const duration = performance.now() - startTime;
      
      const metric = {
        url,
        method,
        status: response.status,
        duration: duration.toFixed(2),
        timestamp: new Date().toISOString(),
        success: response.ok
      };
      
      this.metrics.push(metric);
      
      console.log(
        `[PERF] ${method} ${url} - ${response.status} (${duration.toFixed(2)}ms)`
      );
      
      // Log slow requests
      if (duration > 1000) {
        console.warn(
          `[SLOW] ${method} ${url} took ${duration.toFixed(2)}ms`
        );
      }
      
      return response;
    } catch (error) {
      performance.mark(endMark);
      performance.measure(measureName, startMark, endMark);
      
      const duration = performance.now() - startTime;
      
      const metric = {
        url,
        method,
        error: error.message,
        duration: duration.toFixed(2),
        timestamp: new Date().toISOString(),
        success: false
      };
      
      this.metrics.push(metric);
      
      console.error(
        `[PERF] ${method} ${url} - ERROR (${duration.toFixed(2)}ms)`
      );
      
      throw error;
    }
  }
  
  getMetrics() {
    return this.metrics;
  }
  
  printSummary() {
    console.group('Performance Summary');
    console.table(this.metrics);
    
    const successful = this.metrics.filter(m => m.success).length;
    const failed = this.metrics.filter(m => !m.success).length;
    const avgDuration = (
      this.metrics.reduce((sum, m) => sum + parseFloat(m.duration), 0) / 
      this.metrics.length
    ).toFixed(2);
    
    console.log(`Total Requests: ${this.metrics.length}`);
    console.log(`Successful: ${successful}`);
    console.log(`Failed: ${failed}`);
    console.log(`Average Duration: ${avgDuration}ms`);
    
    console.groupEnd();
  }
  
  clear() {
    this.metrics = [];
  }
}

const perfLogger = new PerformanceLogger();
```

### Network Timeline Visualization

```javascript
class TimelineLogger {
  constructor() {
    this.requests = new Map();
  }
  
  async fetch(url, options = {}) {
    const requestId = crypto.randomUUID?.() || Date.now().toString(36);
    
    const timeline = {
      url,
      method: options.method || 'GET',
      phases: {
        start: performance.now(),
        dnsStart: null,
        connectStart: null,
        requestStart: null,
        responseStart: null,
        responseEnd: null
      }
    };
    
    this.requests.set(requestId, timeline);
    
    try {
      const response = await fetch(url, options);
      
      timeline.phases.responseEnd = performance.now();
      timeline.status = response.status;
      timeline.size = response.headers.get('content-length');
      
      this.logTimeline(requestId, timeline);
      
      return response;
    } catch (error) {
      timeline.phases.responseEnd = performance.now();
      timeline.error = error.message;
      
      this.logTimeline(requestId, timeline);
      throw error;
    }
  }
  
  logTimeline(requestId, timeline) {
    const total = timeline.phases.responseEnd - timeline.phases.start;
    
    console.group(`Timeline: ${timeline.method} ${timeline.url}`);
    console.log(`Total: ${total.toFixed(2)}ms`);
    
    if (timeline.status) {
      console.log(`Status: ${timeline.status}`);
    }
    
    if (timeline.size) {
      console.log(`Size: ${this.formatBytes(timeline.size)}`);
    }
    
    if (timeline.error) {
      console.error(`Error: ${timeline.error}`);
    }
    
    // Visual timeline
    this.drawTimeline(total);
    
    console.groupEnd();
  }
  
  drawTimeline(duration) {
    const maxWidth = 50;
    const barWidth = Math.min(Math.floor(duration / 20), maxWidth);
    const bar = '█'.repeat(barWidth);
    
    console.log(`Timeline: ${bar} ${duration.toFixed(2)}ms`);
  }
  
  formatBytes(bytes) {
    const sizes = ['B', 'KB', 'MB', 'GB'];
    if (bytes === 0) return '0 B';
    const i = Math.floor(Math.log(bytes) / Math.log(1024));
    return `${(bytes / Math.pow(1024, i)).toFixed(2)} ${sizes[i]}`;
  }
}

const timelineLogger = new TimelineLogger();
```

### Error Context Logging

```javascript
async function fetchWithErrorContext(url, options = {}) {
  const context = {
    url,
    method: options.method || 'GET',
    timestamp: new Date().toISOString(),
    userAgent: navigator.userAgent,
    online: navigator.onLine,
    connection: navigator.connection ? {
      effectiveType: navigator.connection.effectiveType,
      downlink: navigator.connection.downlink,
      rtt: navigator.connection.rtt
    } : null
  };
  
  try {
    const response = await fetch(url, options);
    
    if (!response.ok) {
      console.group(`%cHTTP Error ${response.status}`, 'color: red; font-weight: bold');
      console.log('URL:', context.url);
      console.log('Method:', context.method);
      console.log('Status:', `${response.status} ${response.statusText}`);
      console.log('Timestamp:', context.timestamp);
      console.log('Online:', context.online);
      
      if (context.connection) {
        console.log('Connection:', context.connection);
      }
      
      console.log('Request Headers:', options.headers || 'None');
      
      try {
        const cloned = response.clone();
        const text = await cloned.text();
        console.log('Response Body:', text);
      } catch {
        console.log('Response Body: (unable to read)');
      }
      
      console.groupEnd();
    }
    
    return response;
  } catch (error) {
    console.group(`%cNetwork Error`, 'color: red; font-weight: bold');
    console.log('Error:', error.name, error.message);
    console.log('URL:', context.url);
    console.log('Method:', context.method);
    console.log('Timestamp:', context.timestamp);
    console.log('Online:', context.online);
    
    if (context.connection) {
      console.log('Connection:', context.connection);
    }
    
    console.log('Error Stack:', error.stack);
    console.groupEnd();
    
    throw error;
  }
}
```

### Aggregated Logging

```javascript
class AggregatedLogger {
  constructor() {
    this.stats = {
      requests: 0,
      successes: 0,
      errors: 0,
      totalDuration: 0,
      byEndpoint: new Map(),
      byStatus: new Map()
    };
  }
  
  async fetch(url, options = {}) {
    const startTime = performance.now();
    const method = options.method || 'GET';
    
    this.stats.requests++;
    
    try {
      const response = await fetch(url, options);
      const duration = performance.now() - startTime;
      
      this.stats.totalDuration += duration;
      
      if (response.ok) {
        this.stats.successes++;
      } else {
        this.stats.errors++;
      }
      
      // Track by endpoint
      const endpoint = `${method} ${new URL(url, location.href).pathname}`;
      const endpointStats = this.stats.byEndpoint.get(endpoint) || {
        count: 0,
        totalDuration: 0,
        successes: 0,
        errors: 0
      };
      endpointStats.count++;
      endpointStats.totalDuration += duration;
      if (response.ok) {
        endpointStats.successes++;
      } else {
        endpointStats.errors++;
      }
      this.stats.byEndpoint.set(endpoint, endpointStats);
      
      // Track by status
      const statusCount = this.stats.byStatus.get(response.status) || 0;
      this.stats.byStatus.set(response.status, statusCount + 1);
      
      return response;
    } catch (error) {
      const duration = performance.now() - startTime;
      this.stats.totalDuration += duration;
      this.stats.errors++;
      
      const endpoint = `${method} ${new URL(url, location.href).pathname}`;
      const endpointStats = this.stats.byEndpoint.get(endpoint) || {
        count: 0,
        totalDuration: 0,
        successes: 0,
        errors: 0
      };
      endpointStats.count++;
      endpointStats.totalDuration += duration;
      endpointStats.errors++;
      this.stats.byEndpoint.set(endpoint, endpointStats);
      
      throw error;
    }
  }
  
  printStats() {
    console.group('Request Statistics');
    
    console.log(`Total Requests: ${this.stats.requests}`);
    console.log(`Successful: ${this.stats.successes}`);
    console.log(`Failed: ${this.stats.errors}`);
    
    const avgDuration = this.stats.requests > 0 
      ? (this.stats.totalDuration / this.stats.requests).toFixed(2)
      : 0;
    console.log(`Average Duration: ${avgDuration}ms`);
    
    console.group('By Endpoint');
    const endpointData = [];
    this.stats.byEndpoint.forEach((stats, endpoint) => {
      const avgDuration = (stats.totalDuration / stats.count).toFixed(2);
      endpointData.push({
        endpoint,
        requests: stats.count,
        successes: stats.successes,
        errors: stats.errors,
        avgDuration: `${avgDuration}ms`
      });
    });
    console.table(endpointData);
    console.groupEnd();
    
    console.group('By Status Code');
    const statusData = [];
    this.stats.byStatus.forEach((count, status) => {
      statusData.push({ status, count });
    });
    console.table(statusData);
    console.groupEnd();
    
    console.groupEnd();
  }
  
  reset() {
    this.stats = {
      requests: 0,
      successes: 0,
      errors: 0,
      totalDuration: 0,
      byEndpoint: new Map(),
      byStatus: new Map()
    };
  }
}

const aggLogger = new AggregatedLogger();
```

### Debug Mode Toggle

```javascript
class DebugFetch {
  constructor() {
    this.debugMode = false;
    this.verbose = false;
  }
  
  enableDebug() {
    this.debugMode = true;
    console.log('%c[DEBUG MODE ENABLED]', 'background: yellow; color: black; font-weight: bold');
  }
  
  disableDebug() {
    this.debugMode = false;
    console.log('%c[DEBUG MODE DISABLED]', 'background: gray; color: white');
  }
  
  enableVerbose() {
    this.verbose = true;
    this.debugMode = true;
    console.log('%c[VERBOSE MODE ENABLED]', 'background: orange; color: white; font-weight: bold');
  }
  
  async fetch(url, options = {}) {
    if (!this.debugMode) {
      return fetch(url, options);
    }
    
    const requestId = Date.now().toString(36);
    const startTime = performance.now();
    
    console.group(`[DEBUG ${requestId}] ${options.method || 'GET'} ${url}`);
    
    if (this.verbose) {
      console.log('Full URL:', url);
      console.log('Options:', JSON.stringify(options, null, 2));
      console.log('Timestamp:', new Date().toISOString());
      console.log('Navigator Online:', navigator.onLine);
      
      if (navigator.connection) {
        console.log('Connection:', {
          effectiveType: navigator.connection.effectiveType,
          downlink: navigator.connection.downlink,
          rtt: navigator.connection.rtt
        });
      }
    }
    
    try {
      const response = await fetch(url, options);
      const duration = (performance.now() - startTime).toFixed(2);
      
      console.log(`Status: ${response.status} ${response.statusText}`);
      console.log(`Duration: ${duration}ms`);
      
      if (this.verbose) {
        console.log('Response Type:', response.type);
        console.log('Redirected:', response.redirected);
        console.log('Headers:');
        response.headers.forEach((value, key) => {
          console.log(`  ${key}: ${value}`);
        });
      }
      
      console.groupEnd();
      return response;
    } catch (error) {
      const duration = (performance.now() - startTime).toFixed(2);
      
      console.error('Error:', error);
      console.log(`Duration: ${duration}ms`);
      
      if (this.verbose) {
        console.error('Error Stack:', error.stack);
      }
      
      console.groupEnd();
      throw error;
    }
  }
}

const debugFetch = new DebugFetch();

// Enable via console
window.enableDebug = () => debugFetch.enableDebug();
window.disableDebug = () => debugFetch.disableDebug();
window.enableVerbose = () => debugFetch.enableVerbose();
```

### Request Tracing

```javascript
class RequestTracer {
  constructor() {
    this.traces = new Map();
    this.traceId = 0;
  }
  
  async fetch(url, options = {}) {
    const traceId = ++this.traceId;
    const trace = {
      id: traceId,
      url,
      method: options.method || 'GET',
      events: []
    };
    
    this.addEvent(trace, 'initiated', { options });
    this.traces.set(traceId, trace);
    
    console.log(`[TRACE ${traceId}] Request initiated: ${trace.method} ${url}`);
    
    try {
      this.addEvent(trace, 'sending');
      const response = await fetch(url, options);
      
      this.addEvent(trace, 'received', { 
        status: response.status,
        statusText: response.statusText,
        headers: Object.fromEntries(response.headers.entries())
      });
      
      console.log(`[TRACE ${traceId}] Response received: ${response.status}`);
      
      return this.wrapResponse(response, trace);
    } catch (error) {
      this.addEvent(trace, 'error', { error: error.message });
      console.error(`[TRACE ${traceId}] Error: ${error.message}`);
      throw error;
    }
  }
  
  wrapResponse(response, trace) {
    const originalJson = response.json.bind(response);
    const originalText = response.text.bind(response);
    const originalBlob = response.blob.bind(response);
    
    response.json = async () => {
      this.addEvent(trace, 'parsing', { type: 'json' });
      const result = await originalJson();
      this.addEvent(trace, 'parsed', { type: 'json' });
      console.log(`[TRACE ${trace.id}] JSON parsed`);
      return result;
    };
    
    response.text = async () => {
      this.addEvent(trace, 'parsing', { type: 'text' });
      const result = await originalText();
      this.addEvent(trace, 'parsed', { type: 'text' });
      console.log(`[TRACE ${trace.id}] Text parsed`);
      return result;
    };
    
    response.blob = async () => {
      this.addEvent(trace, 'parsing', { type: 'blob' });
      const result = await originalBlob();
      this.addEvent(trace, 'parsed', { type: 'blob' });
      console.log(`[TRACE ${trace.id}] Blob parsed`);
      return result;
    };
    
    return response;
  }
  
  addEvent(trace, type, data = {}) {
    trace.events.push({
      type,
      timestamp: performance.now(),
      data
    });
  }
  
  getTrace(traceId) {
    return this.traces.get(traceId);
  }
  
  printTrace(traceId) {
    const trace = this.traces.get(traceId);
    if (!trace) {
      console.warn(`No trace found for ID: ${traceId}`);
      return;
    }
    
    console.group(`Trace #${traceId}: ${trace.method} ${trace.url}`);
    
    const startTime = trace.events[0].timestamp;
    trace.events.forEach((event, index) => {
      const elapsed = (event.timestamp - startTime).toFixed(2);
      console.log(`[+${elapsed}ms] ${event.type}`, event.data);
    });
    
    console.groupEnd();
  }
  
  printAllTraces() {
    console.group('All Request Traces');
    this.traces.forEach((trace, id) => {
      this.printTrace(id);
    });
    console.groupEnd();
  }
}

const tracer = new RequestTracer();
```

### Complete Logging Wrapper

```javascript
class CompleteFetchLogger {
  constructor(config = {}) {
    this.config = {
      enabled: true,
      level: LogLevel.INFO,
      logBodies: false,
      logHeaders: true,
      logPerformance: true,
      logErrors: true,
      groupLogs: true,
      styled: true,
      ...config
    };
    
    this.stats = new AggregatedLogger();
    this.tracer = new RequestTracer();
  }
  
  async fetch(url, options = {}) {
    if (!this.config.enabled) {
      return fetch(url, options);
    }
    
    const requestId = Date.now().toString(36);
    const method = options.method || 'GET';
    const startTime = performance.now();
    
    if (this.config.groupLogs) {
      console.group(this.formatGroupLabel(method, url));
    }
    
    this.logRequest(requestId, url, options);
    
    try {
      const response = await fetch(url, options);
      const duration = performance.now() - startTime;
      
      this.logResponse(requestId, response, duration);
      
      if (this.config.logBodies) {
        await this.logResponseBody(response.clone());
      }
      
      if (this.config.logPerformance) {
        this.stats.fetch(url, options);
      }
      
      if (this.config.groupLogs) {
        console.groupEnd();
      }
      
      return response;
    } catch (error) {
      const duration = performance.now() - startTime;
      
      if (this.config.logErrors) {
        this.logError(requestId, error, duration);
      }
      
      if (this.config.groupLogs) {
        console.groupEnd();
      }
      
      throw error;
    }
  }
  
  formatGroupLabel(method, url) {
    if (this.config.styled) {
      return `%c${method}%c ${url}`;
    }
    return `${method} ${url}`;
  }
  
  logRequest(requestId, url, options) {
    const method = options.method || 'GET';
    
    if (this.config.styled) {
      console.log(
        `%c[${requestId}] →%c ${method} %c${url}`,
        styles.info,
        styles.request,
        styles.info
      );
    } else {
      console.log(`[${requestId}] → ${method} ${url}`);
    }
    
    if (this.config.logHeaders && options.headers) {
      console.log('Request Headers:', options.headers);
    }
    
    if (this.config.logBodies && options.body) {
      console.log('Request Body:', options.body);
    }
  }
  
  logResponse(requestId, response, duration) {
    const statusStyle = response.ok ? styles.success : 
                       response.status >= 400 ? styles.error : 
                       styles.warning;
    
    if (this.config.styled) {
      console.log(
        `%c[${requestId}] ←%c ${response.status} ${response.statusText} %c${duration.toFixed(2)}ms`,
        styles.info,
        statusStyle,
        styles.duration
      );
    } else {
      console.log(
        `[${requestId}] ← ${response.status} ${response.statusText} (${duration.toFixed(2)}ms)`
      );
    }
    
    if (this.config.logHeaders) {
      console.log('Response Headers:', 
        Object.fromEntries(response.headers.entries())
      );
    }
  }
  
  async logResponseBody(response) {
    const contentType = response.headers.get('content-type');
    
    try {
      if (contentType?.includes('application/json')) {
        const data = await response.json();
        console.log('Response Body (JSON):', data);
      } else if (contentType?.includes('text/')) {
        const text = await response.text();
        console.log('Response Body (Text):', text);
      }
    } catch (error) {
      console.warn('Could not log response body:', error);
    }
  }
  
  logError(requestId, error, duration) {
    if (this.config.styled) {
      console.log(
        `%c[${requestId}] ✗%c ${error.message} %c${duration.toFixed(2)}ms`,
        styles.info,
        styles.error,
        styles.duration
      );
    } else {
      console.error(
        `[${requestId}] ✗ ${error.message} (${duration.toFixed(2)}ms)`
      );
    }
    
    console.error('Error Details:', {
      name: error.name,
      message: error.message,
      stack: error.stack
    });
  }
  
  configure(newConfig) {
    this.config = { ...this.config, ...newConfig };
  }
  
  enable() {
    this.config.enabled = true;
  }
  
  disable() {
    this.config.enabled = false;
  }
  
  getStats() {
    return this.stats.stats;
  }
  
  printStats() {
    this.stats.printStats();
  }
  
  reset() {
    this.stats.reset();
  }
}

// Usage
const logger = new CompleteFetchLogger({
  enabled: true,
  level: LogLevel.INFO,
  logBodies: true,
  logHeaders: true,
  logPerformance: true,
  styled: true
});

// Use it
await logger.fetch('/api/data');

// Configure on the fly
logger.configure({ logBodies: false });

// Disable in production
if (location.hostname !== 'localhost') {
  logger.disable();
}

// Print statistics
logger.printStats();
```

---

# State Management Integration

## Fetch API Redux Integration

### Redux Thunk Middleware

Redux Thunk enables action creators to return functions instead of plain objects, allowing asynchronous fetch operations:

```javascript
// Action types
const FETCH_USER_REQUEST = 'FETCH_USER_REQUEST';
const FETCH_USER_SUCCESS = 'FETCH_USER_SUCCESS';
const FETCH_USER_FAILURE = 'FETCH_USER_FAILURE';

// Action creators
const fetchUserRequest = () => ({ type: FETCH_USER_REQUEST });
const fetchUserSuccess = (user) => ({ type: FETCH_USER_SUCCESS, payload: user });
const fetchUserFailure = (error) => ({ type: FETCH_USER_FAILURE, payload: error });

// Thunk action creator
const fetchUser = (userId) => {
  return async (dispatch) => {
    dispatch(fetchUserRequest());
    
    try {
      const response = await fetch(`/api/users/${userId}`);
      
      if (!response.ok) {
        throw new Error(`HTTP error ${response.status}`);
      }
      
      const user = await response.json();
      dispatch(fetchUserSuccess(user));
    } catch (error) {
      dispatch(fetchUserFailure(error.message));
    }
  };
};
```

### Reducer Patterns for Fetch States

Typical reducer structure for handling fetch lifecycle:

```javascript
const initialState = {
  data: null,
  loading: false,
  error: null
};

function userReducer(state = initialState, action) {
  switch (action.type) {
    case FETCH_USER_REQUEST:
      return {
        ...state,
        loading: true,
        error: null
      };
      
    case FETCH_USER_SUCCESS:
      return {
        ...state,
        loading: false,
        data: action.payload,
        error: null
      };
      
    case FETCH_USER_FAILURE:
      return {
        ...state,
        loading: false,
        error: action.payload
      };
      
    default:
      return state;
  }
}
```

### Normalized State Management

Handling relational data from fetch responses:

```javascript
import { normalize, schema } from 'normalizr';

// Define schemas
const userSchema = new schema.Entity('users');
const commentSchema = new schema.Entity('comments', {
  author: userSchema
});
const postSchema = new schema.Entity('posts', {
  author: userSchema,
  comments: [commentSchema]
});

// Thunk with normalization
const fetchPost = (postId) => {
  return async (dispatch) => {
    dispatch({ type: 'FETCH_POST_REQUEST' });
    
    try {
      const response = await fetch(`/api/posts/${postId}`);
      const post = await response.json();
      
      // Normalize nested data
      const normalized = normalize(post, postSchema);
      
      dispatch({
        type: 'FETCH_POST_SUCCESS',
        payload: normalized
      });
    } catch (error) {
      dispatch({ type: 'FETCH_POST_FAILURE', payload: error.message });
    }
  };
};

// Reducer for normalized data
function entitiesReducer(state = { users: {}, posts: {}, comments: {} }, action) {
  switch (action.type) {
    case 'FETCH_POST_SUCCESS':
      return {
        users: { ...state.users, ...action.payload.entities.users },
        posts: { ...state.posts, ...action.payload.entities.posts },
        comments: { ...state.comments, ...action.payload.entities.comments }
      };
    default:
      return state;
  }
}
```

### Request Cancellation with AbortController

Integrating AbortController for cancellable requests:

```javascript
// Store abort controllers
const abortControllers = {};

const fetchUserCancellable = (userId) => {
  return async (dispatch) => {
    // Cancel previous request for this user
    if (abortControllers[userId]) {
      abortControllers[userId].abort();
    }
    
    const controller = new AbortController();
    abortControllers[userId] = controller;
    
    dispatch(fetchUserRequest());
    
    try {
      const response = await fetch(`/api/users/${userId}`, {
        signal: controller.signal
      });
      
      const user = await response.json();
      dispatch(fetchUserSuccess(user));
      
      delete abortControllers[userId];
    } catch (error) {
      if (error.name === 'AbortError') {
        // Request was cancelled, don't dispatch failure
        return;
      }
      dispatch(fetchUserFailure(error.message));
      delete abortControllers[userId];
    }
  };
};

// Cleanup action
const cancelFetchUser = (userId) => {
  return (dispatch) => {
    if (abortControllers[userId]) {
      abortControllers[userId].abort();
      delete abortControllers[userId];
    }
  };
};
```

### Redux Saga Integration

Using sagas for complex fetch orchestration:

```javascript
import { call, put, takeLatest, race, delay } from 'redux-saga/effects';

function* fetchUserSaga(action) {
  try {
    yield put({ type: 'FETCH_USER_REQUEST' });
    
    // Race between fetch and timeout
    const { response, timeout } = yield race({
      response: call(fetch, `/api/users/${action.payload.userId}`),
      timeout: delay(5000)
    });
    
    if (timeout) {
      throw new Error('Request timeout');
    }
    
    if (!response.ok) {
      throw new Error(`HTTP error ${response.status}`);
    }
    
    const user = yield response.json();
    yield put({ type: 'FETCH_USER_SUCCESS', payload: user });
  } catch (error) {
    yield put({ type: 'FETCH_USER_FAILURE', payload: error.message });
  }
}

function* watchFetchUser() {
  yield takeLatest('FETCH_USER', fetchUserSaga);
}
```

### Polling and Auto-Refresh

Implementing periodic data fetching:

```javascript
import { takeLatest, put, call, delay, cancelled } from 'redux-saga/effects';

function* pollDataSaga() {
  try {
    while (true) {
      const response = yield call(fetch, '/api/data');
      const data = yield response.json();
      
      yield put({ type: 'POLL_DATA_SUCCESS', payload: data });
      yield delay(5000); // Poll every 5 seconds
    }
  } catch (error) {
    yield put({ type: 'POLL_DATA_FAILURE', payload: error.message });
  } finally {
    if (yield cancelled()) {
      // Cleanup on cancellation
      console.log('Polling cancelled');
    }
  }
}

function* watchStartPolling() {
  yield takeLatest('START_POLLING', pollDataSaga);
}
```

### Optimistic Updates

Implementing optimistic UI updates before fetch completes:

```javascript
const updateUser = (userId, updates) => {
  return async (dispatch, getState) => {
    const previousUser = getState().users.data[userId];
    
    // Optimistic update
    dispatch({
      type: 'UPDATE_USER_OPTIMISTIC',
      payload: { userId, updates }
    });
    
    try {
      const response = await fetch(`/api/users/${userId}`, {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(updates)
      });
      
      const updatedUser = await response.json();
      
      dispatch({
        type: 'UPDATE_USER_SUCCESS',
        payload: updatedUser
      });
    } catch (error) {
      // Revert to previous state
      dispatch({
        type: 'UPDATE_USER_FAILURE',
        payload: { userId, previousUser, error: error.message }
      });
    }
  };
};

// Reducer
function usersReducer(state = { data: {} }, action) {
  switch (action.type) {
    case 'UPDATE_USER_OPTIMISTIC':
      return {
        ...state,
        data: {
          ...state.data,
          [action.payload.userId]: {
            ...state.data[action.payload.userId],
            ...action.payload.updates
          }
        }
      };
      
    case 'UPDATE_USER_FAILURE':
      return {
        ...state,
        data: {
          ...state.data,
          [action.payload.userId]: action.payload.previousUser
        },
        error: action.payload.error
      };
      
    default:
      return state;
  }
}
```

### Middleware for Request/Response Interception

Custom middleware for centralized fetch handling:

```javascript
const apiMiddleware = (store) => (next) => (action) => {
  if (action.type !== 'API_REQUEST') {
    return next(action);
  }
  
  const { endpoint, method = 'GET', body, types } = action.payload;
  const [requestType, successType, failureType] = types;
  
  store.dispatch({ type: requestType });
  
  const options = {
    method,
    headers: { 'Content-Type': 'application/json' }
  };
  
  if (body) {
    options.body = JSON.stringify(body);
  }
  
  return fetch(endpoint, options)
    .then(response => {
      if (!response.ok) {
        throw new Error(`HTTP error ${response.status}`);
      }
      return response.json();
    })
    .then(data => {
      store.dispatch({ type: successType, payload: data });
      return data;
    })
    .catch(error => {
      store.dispatch({ type: failureType, payload: error.message });
      throw error;
    });
};

// Usage
dispatch({
  type: 'API_REQUEST',
  payload: {
    endpoint: '/api/users',
    method: 'POST',
    body: { name: 'John' },
    types: ['CREATE_USER_REQUEST', 'CREATE_USER_SUCCESS', 'CREATE_USER_FAILURE']
  }
});
```

### Authentication Token Management

Handling authentication in Redux with fetch:

```javascript
const authenticatedFetch = (url, options = {}) => {
  return (dispatch, getState) => {
    const token = getState().auth.token;
    
    const headers = {
      ...options.headers,
      'Authorization': `Bearer ${token}`
    };
    
    return fetch(url, { ...options, headers })
      .then(response => {
        if (response.status === 401) {
          dispatch({ type: 'AUTH_TOKEN_EXPIRED' });
          throw new Error('Authentication required');
        }
        return response;
      });
  };
};

// Thunk with authenticated fetch
const fetchProtectedData = () => {
  return async (dispatch, getState) => {
    try {
      const response = await dispatch(authenticatedFetch('/api/protected'));
      const data = await response.json();
      dispatch({ type: 'FETCH_PROTECTED_SUCCESS', payload: data });
    } catch (error) {
      dispatch({ type: 'FETCH_PROTECTED_FAILURE', payload: error.message });
    }
  };
};
```

### Token Refresh Flow

Automatic token refresh on expiration:

```javascript
let refreshTokenPromise = null;

const fetchWithTokenRefresh = (url, options = {}) => {
  return async (dispatch, getState) => {
    const makeRequest = async (token) => {
      const headers = {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      };
      
      return fetch(url, { ...options, headers });
    };
    
    let token = getState().auth.token;
    let response = await makeRequest(token);
    
    if (response.status === 401) {
      // Token expired, refresh it
      if (!refreshTokenPromise) {
        refreshTokenPromise = dispatch(refreshToken())
          .finally(() => {
            refreshTokenPromise = null;
          });
      }
      
      await refreshTokenPromise;
      token = getState().auth.token;
      response = await makeRequest(token);
    }
    
    return response;
  };
};

const refreshToken = () => {
  return async (dispatch, getState) => {
    const refreshToken = getState().auth.refreshToken;
    
    const response = await fetch('/api/auth/refresh', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ refreshToken })
    });
    
    const { token } = await response.json();
    
    dispatch({ type: 'TOKEN_REFRESHED', payload: token });
    return token;
  };
};
```

### Caching Strategies

Implementing caching in Redux store:

```javascript
const fetchWithCache = (url, cacheTime = 60000) => {
  return async (dispatch, getState) => {
    const cache = getState().cache[url];
    const now = Date.now();
    
    // Return cached data if valid
    if (cache && (now - cache.timestamp) < cacheTime) {
      dispatch({
        type: 'FETCH_FROM_CACHE',
        payload: { url, data: cache.data }
      });
      return cache.data;
    }
    
    // Fetch fresh data
    dispatch({ type: 'FETCH_REQUEST', payload: { url } });
    
    try {
      const response = await fetch(url);
      const data = await response.json();
      
      dispatch({
        type: 'FETCH_SUCCESS',
        payload: { url, data, timestamp: now }
      });
      
      return data;
    } catch (error) {
      dispatch({
        type: 'FETCH_FAILURE',
        payload: { url, error: error.message }
      });
      throw error;
    }
  };
};

// Cache reducer
function cacheReducer(state = {}, action) {
  switch (action.type) {
    case 'FETCH_SUCCESS':
      return {
        ...state,
        [action.payload.url]: {
          data: action.payload.data,
          timestamp: action.payload.timestamp
        }
      };
      
    case 'INVALIDATE_CACHE':
      const { [action.payload.url]: removed, ...rest } = state;
      return rest;
      
    default:
      return state;
  }
}
```

### Batching Multiple Requests

Coordinating multiple fetch operations:

```javascript
const fetchMultiple = (endpoints) => {
  return async (dispatch) => {
    dispatch({ type: 'FETCH_MULTIPLE_REQUEST' });
    
    try {
      const promises = endpoints.map(endpoint => 
        fetch(endpoint).then(res => res.json())
      );
      
      const results = await Promise.all(promises);
      
      dispatch({
        type: 'FETCH_MULTIPLE_SUCCESS',
        payload: results.reduce((acc, data, index) => {
          acc[endpoints[index]] = data;
          return acc;
        }, {})
      });
    } catch (error) {
      dispatch({
        type: 'FETCH_MULTIPLE_FAILURE',
        payload: error.message
      });
    }
  };
};

// Sequential fetching with dependencies
const fetchSequential = () => {
  return async (dispatch) => {
    try {
      const userResponse = await fetch('/api/user');
      const user = await userResponse.json();
      
      dispatch({ type: 'FETCH_USER_SUCCESS', payload: user });
      
      // Fetch depends on user data
      const postsResponse = await fetch(`/api/users/${user.id}/posts`);
      const posts = await postsResponse.json();
      
      dispatch({ type: 'FETCH_POSTS_SUCCESS', payload: posts });
    } catch (error) {
      dispatch({ type: 'FETCH_SEQUENTIAL_FAILURE', payload: error.message });
    }
  };
};
```

### Error Handling Patterns

Centralized error handling:

```javascript
const handleApiError = (error, dispatch) => {
  if (error.name === 'AbortError') {
    // Request cancelled, no action needed
    return;
  }
  
  if (error.message.includes('NetworkError')) {
    dispatch({
      type: 'NETWORK_ERROR',
      payload: 'Network connection lost'
    });
  } else if (error.message.includes('401')) {
    dispatch({ type: 'AUTH_ERROR' });
  } else if (error.message.includes('403')) {
    dispatch({
      type: 'PERMISSION_ERROR',
      payload: 'Access denied'
    });
  } else {
    dispatch({
      type: 'GENERAL_ERROR',
      payload: error.message
    });
  }
};

// Enhanced thunk with error handling
const fetchWithErrorHandling = (url) => {
  return async (dispatch) => {
    dispatch({ type: 'FETCH_REQUEST' });
    
    try {
      const response = await fetch(url);
      
      if (!response.ok) {
        const error = new Error(`HTTP error ${response.status}`);
        error.status = response.status;
        throw error;
      }
      
      const data = await response.json();
      dispatch({ type: 'FETCH_SUCCESS', payload: data });
    } catch (error) {
      handleApiError(error, dispatch);
      dispatch({ type: 'FETCH_FAILURE', payload: error.message });
    }
  };
};
```

### Redux Toolkit Integration

Modern Redux Toolkit patterns with createAsyncThunk:

```javascript
import { createAsyncThunk, createSlice } from '@reduxjs/toolkit';

// Async thunk with fetch
export const fetchUser = createAsyncThunk(
  'users/fetchUser',
  async (userId, { rejectWithValue }) => {
    try {
      const response = await fetch(`/api/users/${userId}`);
      
      if (!response.ok) {
        throw new Error(`HTTP error ${response.status}`);
      }
      
      return await response.json();
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// Slice with automatic action creators
const usersSlice = createSlice({
  name: 'users',
  initialState: {
    entities: {},
    loading: false,
    error: null
  },
  reducers: {},
  extraReducers: (builder) => {
    builder
      .addCase(fetchUser.pending, (state) => {
        state.loading = true;
        state.error = null;
      })
      .addCase(fetchUser.fulfilled, (state, action) => {
        state.loading = false;
        state.entities[action.payload.id] = action.payload;
      })
      .addCase(fetchUser.rejected, (state, action) => {
        state.loading = false;
        state.error = action.payload;
      });
  }
});

export default usersSlice.reducer;
```

### RTK Query Setup

Full-featured data fetching with RTK Query:

```javascript
import { createApi, fetchBaseQuery } from '@reduxjs/toolkit/query/react';

// Define API slice
export const apiSlice = createApi({
  reducerPath: 'api',
  baseQuery: fetchBaseQuery({
    baseUrl: '/api',
    prepareHeaders: (headers, { getState }) => {
      const token = getState().auth.token;
      if (token) {
        headers.set('Authorization', `Bearer ${token}`);
      }
      return headers;
    }
  }),
  tagTypes: ['User', 'Post'],
  endpoints: (builder) => ({
    getUser: builder.query({
      query: (userId) => `/users/${userId}`,
      providesTags: (result, error, userId) => [{ type: 'User', id: userId }]
    }),
    updateUser: builder.mutation({
      query: ({ userId, ...patch }) => ({
        url: `/users/${userId}`,
        method: 'PATCH',
        body: patch
      }),
      invalidatesTags: (result, error, { userId }) => [{ type: 'User', id: userId }]
    }),
    getPosts: builder.query({
      query: () => '/posts',
      providesTags: ['Post']
    })
  })
});

export const { useGetUserQuery, useUpdateUserMutation, useGetPostsQuery } = apiSlice;
```

### Pagination Handling

Managing paginated fetch requests:

```javascript
const fetchPage = (page, limit = 20) => {
  return async (dispatch, getState) => {
    const existingData = getState().pagination.data;
    
    dispatch({
      type: 'FETCH_PAGE_REQUEST',
      payload: { page }
    });
    
    try {
      const response = await fetch(`/api/items?page=${page}&limit=${limit}`);
      const data = await response.json();
      
      dispatch({
        type: 'FETCH_PAGE_SUCCESS',
        payload: {
          page,
          data: data.items,
          hasMore: data.hasMore,
          total: data.total
        }
      });
    } catch (error) {
      dispatch({
        type: 'FETCH_PAGE_FAILURE',
        payload: error.message
      });
    }
  };
};

// Pagination reducer
function paginationReducer(state = { data: [], page: 1, hasMore: true }, action) {
  switch (action.type) {
    case 'FETCH_PAGE_SUCCESS':
      return {
        ...state,
        data: action.payload.page === 1 
          ? action.payload.data 
          : [...state.data, ...action.payload.data],
        page: action.payload.page,
        hasMore: action.payload.hasMore,
        total: action.payload.total
      };
      
    default:
      return state;
  }
}
```

### WebSocket to Redux Bridge

Combining fetch initialization with WebSocket updates:

```javascript
const initializeRealtimeData = (resourceId) => {
  return async (dispatch) => {
    // Initial fetch
    dispatch({ type: 'FETCH_RESOURCE_REQUEST' });
    
    try {
      const response = await fetch(`/api/resources/${resourceId}`);
      const data = await response.json();
      
      dispatch({
        type: 'FETCH_RESOURCE_SUCCESS',
        payload: data
      });
      
      // Establish WebSocket for updates
      const ws = new WebSocket(`wss://api.example.com/resources/${resourceId}`);
      
      ws.onmessage = (event) => {
        const update = JSON.parse(event.data);
        dispatch({
          type: 'RESOURCE_UPDATE',
          payload: update
        });
      };
      
      ws.onerror = () => {
        dispatch({ type: 'WEBSOCKET_ERROR' });
      };
      
      // Store WebSocket reference for cleanup
      dispatch({
        type: 'WEBSOCKET_CONNECTED',
        payload: { resourceId, ws }
      });
    } catch (error) {
      dispatch({
        type: 'FETCH_RESOURCE_FAILURE',
        payload: error.message
      });
    }
  };
};
```

---

## React Query Patterns

### Query Functions

#### Basic Query Function Structure

Query functions must return a Promise that resolves to data or throws an error:

```javascript
const fetchUser = async ({ queryKey }) => {
  const [_key, userId] = queryKey;
  const response = await fetch(`/api/users/${userId}`);
  
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  
  return response.json();
};

function UserProfile({ userId }) {
  const { data, error, isLoading } = useQuery({
    queryKey: ['user', userId],
    queryFn: fetchUser
  });
}
```

#### Extracting Query Key Parameters

Access query key parameters through the `queryKey` array:

```javascript
const fetchPaginatedData = async ({ queryKey, pageParam = 1 }) => {
  const [_key, filters, sortBy] = queryKey;
  
  const params = new URLSearchParams({
    page: pageParam,
    sort: sortBy,
    ...filters
  });
  
  const response = await fetch(`/api/items?${params}`);
  if (!response.ok) throw new Error('Fetch failed');
  
  return response.json();
};

useQuery({
  queryKey: ['items', { status: 'active', category: 'books' }, 'createdAt'],
  queryFn: fetchPaginatedData
});
```

#### Signal Integration for Cancellation

React Query passes an `AbortSignal` to query functions:

```javascript
const fetchWithCancellation = async ({ queryKey, signal }) => {
  const [_key, id] = queryKey;
  
  const response = await fetch(`/api/resource/${id}`, { signal });
  
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}`);
  }
  
  return response.json();
};

useQuery({
  queryKey: ['resource', id],
  queryFn: fetchWithCancellation
});
```

When a query is cancelled (component unmounts or query key changes), the fetch request aborts automatically.

#### Meta Information Access

Query functions receive metadata for advanced use cases:

```javascript
const fetchWithMeta = async ({ queryKey, signal, meta }) => {
  const [_key, id] = queryKey;
  
  const headers = {
    'Content-Type': 'application/json',
    ...(meta?.customHeaders || {})
  };
  
  const response = await fetch(`/api/data/${id}`, {
    signal,
    headers
  });
  
  if (!response.ok) throw new Error('Fetch failed');
  return response.json();
};

useQuery({
  queryKey: ['data', id],
  queryFn: fetchWithMeta,
  meta: {
    customHeaders: { 'X-Custom-Token': token }
  }
});
```

### Error Handling Patterns

#### Response Status Handling

Differentiate between network errors and HTTP errors:

```javascript
class HTTPError extends Error {
  constructor(response) {
    super(`HTTP Error: ${response.status}`);
    this.response = response;
    this.status = response.status;
  }
}

const fetchWithErrorHandling = async ({ queryKey }) => {
  const [_key, id] = queryKey;
  
  try {
    const response = await fetch(`/api/resource/${id}`);
    
    if (!response.ok) {
      throw new HTTPError(response);
    }
    
    return response.json();
  } catch (error) {
    if (error instanceof HTTPError) {
      // HTTP error (4xx, 5xx)
      throw error;
    }
    // Network error
    throw new Error(`Network error: ${error.message}`);
  }
};
```

#### Retry Logic Configuration

Configure retry behavior based on error types:

```javascript
useQuery({
  queryKey: ['resource', id],
  queryFn: fetchResource,
  retry: (failureCount, error) => {
    // Don't retry on 4xx errors
    if (error.status >= 400 && error.status < 500) {
      return false;
    }
    
    // Retry up to 3 times for 5xx or network errors
    return failureCount < 3;
  },
  retryDelay: (attemptIndex) => Math.min(1000 * 2 ** attemptIndex, 30000)
});
```

#### Error Boundary Integration

Handle errors at component boundaries:

```javascript
const fetchUser = async ({ queryKey, signal }) => {
  const [_key, userId] = queryKey;
  const response = await fetch(`/api/users/${userId}`, { signal });
  
  if (!response.ok) {
    const error = new Error('Failed to fetch user');
    error.status = response.status;
    error.info = await response.json().catch(() => ({}));
    throw error;
  }
  
  return response.json();
};

function UserComponent({ userId }) {
  const { data, error } = useQuery({
    queryKey: ['user', userId],
    queryFn: fetchUser,
    useErrorBoundary: (error) => error.status >= 500
  });
  
  if (error && error.status < 500) {
    return <div>User not found</div>;
  }
  
  return <div>{data.name}</div>;
}
```

#### Global Error Handler

Configure default error handling:

```javascript
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      queryFn: async ({ queryKey, signal }) => {
        const url = Array.isArray(queryKey) ? queryKey[0] : queryKey;
        const response = await fetch(url, { signal });
        
        if (!response.ok) {
          const error = new Error('Request failed');
          error.status = response.status;
          throw error;
        }
        
        return response.json();
      },
      onError: (error) => {
        console.error('Query error:', error);
        // Send to error tracking service
      }
    }
  }
});
```

### Mutations

#### Basic Mutation Pattern

Execute POST, PUT, DELETE requests:

```javascript
const createUser = async (userData) => {
  const response = await fetch('/api/users', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(userData)
  });
  
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}`);
  }
  
  return response.json();
};

function CreateUserForm() {
  const mutation = useMutation({
    mutationFn: createUser,
    onSuccess: (data) => {
      console.log('User created:', data);
    },
    onError: (error) => {
      console.error('Creation failed:', error);
    }
  });
  
  const handleSubmit = (formData) => {
    mutation.mutate(formData);
  };
  
  return (
    <form onSubmit={(e) => {
      e.preventDefault();
      handleSubmit(new FormData(e.target));
    }}>
      {mutation.isPending && <div>Creating...</div>}
      {mutation.isError && <div>Error: {mutation.error.message}</div>}
      {/* form fields */}
    </form>
  );
}
```

#### Optimistic Updates

Update UI immediately before server confirmation:

```javascript
const updateTodo = async ({ id, ...updates }) => {
  const response = await fetch(`/api/todos/${id}`, {
    method: 'PATCH',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(updates)
  });
  
  if (!response.ok) throw new Error('Update failed');
  return response.json();
};

function TodoItem({ todo }) {
  const queryClient = useQueryClient();
  
  const mutation = useMutation({
    mutationFn: updateTodo,
    onMutate: async (updatedTodo) => {
      // Cancel outgoing refetches
      await queryClient.cancelQueries({ queryKey: ['todos'] });
      
      // Snapshot previous value
      const previousTodos = queryClient.getQueryData(['todos']);
      
      // Optimistically update
      queryClient.setQueryData(['todos'], (old) =>
        old.map((t) => t.id === updatedTodo.id ? { ...t, ...updatedTodo } : t)
      );
      
      return { previousTodos };
    },
    onError: (err, updatedTodo, context) => {
      // Rollback on error
      queryClient.setQueryData(['todos'], context.previousTodos);
    },
    onSettled: () => {
      // Refetch after error or success
      queryClient.invalidateQueries({ queryKey: ['todos'] });
    }
  });
  
  return (
    <div>
      <input
        type="checkbox"
        checked={todo.completed}
        onChange={(e) => mutation.mutate({ id: todo.id, completed: e.target.checked })}
      />
    </div>
  );
}
```

#### Sequential Mutations

Chain dependent mutations:

```javascript
function MultiStepForm() {
  const queryClient = useQueryClient();
  
  const createUserMutation = useMutation({
    mutationFn: async (userData) => {
      const response = await fetch('/api/users', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(userData)
      });
      if (!response.ok) throw new Error('User creation failed');
      return response.json();
    }
  });
  
  const uploadAvatarMutation = useMutation({
    mutationFn: async ({ userId, file }) => {
      const formData = new FormData();
      formData.append('avatar', file);
      
      const response = await fetch(`/api/users/${userId}/avatar`, {
        method: 'POST',
        body: formData
      });
      if (!response.ok) throw new Error('Avatar upload failed');
      return response.json();
    },
    onSuccess: () => {
      queryClient.invalidateQueries({ queryKey: ['users'] });
    }
  });
  
  const handleSubmit = async (userData, avatarFile) => {
    try {
      const user = await createUserMutation.mutateAsync(userData);
      await uploadAvatarMutation.mutateAsync({ userId: user.id, file: avatarFile });
    } catch (error) {
      console.error('Form submission failed:', error);
    }
  };
}
```

#### Parallel Mutations

Execute multiple independent mutations:

```javascript
function BulkActions({ selectedIds }) {
  const queryClient = useQueryClient();
  
  const deleteMutation = useMutation({
    mutationFn: async (id) => {
      const response = await fetch(`/api/items/${id}`, { method: 'DELETE' });
      if (!response.ok) throw new Error(`Failed to delete ${id}`);
      return id;
    }
  });
  
  const handleBulkDelete = async () => {
    try {
      await Promise.all(
        selectedIds.map((id) => deleteMutation.mutateAsync(id))
      );
      queryClient.invalidateQueries({ queryKey: ['items'] });
    } catch (error) {
      console.error('Bulk delete failed:', error);
    }
  };
  
  return (
    <button 
      onClick={handleBulkDelete}
      disabled={deleteMutation.isPending}
    >
      Delete Selected ({selectedIds.length})
    </button>
  );
}
```

### Cache Invalidation Strategies

#### Selective Invalidation

Invalidate specific queries after mutations:

```javascript
const updateUserMutation = useMutation({
  mutationFn: async ({ userId, updates }) => {
    const response = await fetch(`/api/users/${userId}`, {
      method: 'PATCH',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(updates)
    });
    if (!response.ok) throw new Error('Update failed');
    return response.json();
  },
  onSuccess: (data, variables) => {
    // Invalidate specific user query
    queryClient.invalidateQueries({ queryKey: ['user', variables.userId] });
    
    // Invalidate user list
    queryClient.invalidateQueries({ queryKey: ['users'] });
  }
});
```

#### Exact vs Partial Matching

Control invalidation scope:

```javascript
// Invalidate exact match only
queryClient.invalidateQueries({
  queryKey: ['users', { status: 'active' }],
  exact: true
});

// Invalidate all queries starting with ['users']
queryClient.invalidateQueries({
  queryKey: ['users'],
  exact: false
});

// Predicate-based invalidation
queryClient.invalidateQueries({
  predicate: (query) => {
    return query.queryKey[0] === 'users' && 
           query.state.data?.length > 100;
  }
});
```

#### Manual Cache Updates

Directly update cache without invalidation:

```javascript
const createTodoMutation = useMutation({
  mutationFn: async (newTodo) => {
    const response = await fetch('/api/todos', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(newTodo)
    });
    if (!response.ok) throw new Error('Creation failed');
    return response.json();
  },
  onSuccess: (createdTodo) => {
    // Add to existing cache
    queryClient.setQueryData(['todos'], (old) => [...old, createdTodo]);
    
    // Or update specific item
    queryClient.setQueryData(['todo', createdTodo.id], createdTodo);
  }
});
```

#### Time-Based Invalidation

Combine with stale time for automatic refetching:

```javascript
useQuery({
  queryKey: ['dashboard'],
  queryFn: fetchDashboard,
  staleTime: 5 * 60 * 1000, // 5 minutes
  refetchInterval: 5 * 60 * 1000, // Refetch every 5 minutes
  refetchIntervalInBackground: true
});

// Manual invalidation still works
const handleRefresh = () => {
  queryClient.invalidateQueries({ queryKey: ['dashboard'] });
};
```

### Prefetching Patterns

#### Route-Based Prefetching

Prefetch data for anticipated navigation:

```javascript
function UserList() {
  const queryClient = useQueryClient();
  const { data: users } = useQuery({
    queryKey: ['users'],
    queryFn: fetchUsers
  });
  
  const handleHover = (userId) => {
    queryClient.prefetchQuery({
      queryKey: ['user', userId],
      queryFn: () => fetchUser({ queryKey: ['user', userId] }),
      staleTime: 10 * 1000 // Cache for 10 seconds
    });
  };
  
  return (
    <ul>
      {users.map((user) => (
        <li key={user.id}>
          <Link
            to={`/users/${user.id}`}
            onMouseEnter={() => handleHover(user.id)}
          >
            {user.name}
          </Link>
        </li>
      ))}
    </ul>
  );
}
```

#### Parallel Prefetching

Prefetch multiple related queries:

```javascript
function DashboardLoader() {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const prefetchDashboardData = async () => {
      await Promise.all([
        queryClient.prefetchQuery({
          queryKey: ['stats'],
          queryFn: fetchStats
        }),
        queryClient.prefetchQuery({
          queryKey: ['recentActivity'],
          queryFn: fetchRecentActivity
        }),
        queryClient.prefetchQuery({
          queryKey: ['notifications'],
          queryFn: fetchNotifications
        })
      ]);
    };
    
    prefetchDashboardData();
  }, [queryClient]);
  
  return <Outlet />;
}
```

#### Conditional Prefetching

Prefetch based on user behavior or permissions:

```javascript
function AdminPanel() {
  const queryClient = useQueryClient();
  const { data: user } = useQuery({ queryKey: ['currentUser'], queryFn: fetchCurrentUser });
  
  useEffect(() => {
    if (user?.role === 'admin') {
      queryClient.prefetchQuery({
        queryKey: ['adminStats'],
        queryFn: fetchAdminStats
      });
    }
  }, [user, queryClient]);
  
  return <div>{/* admin content */}</div>;
}
```

#### Infinite Query Prefetching

Prefetch next page of infinite queries:

```javascript
function InfiniteList() {
  const { data, fetchNextPage, hasNextPage } = useInfiniteQuery({
    queryKey: ['items'],
    queryFn: fetchItems,
    getNextPageParam: (lastPage) => lastPage.nextCursor,
    initialPageParam: undefined
  });
  
  const lastItemRef = useCallback((node) => {
    if (node && hasNextPage) {
      // Prefetch next page when near bottom
      const observer = new IntersectionObserver((entries) => {
        if (entries[0].isIntersecting) {
          fetchNextPage();
        }
      }, { rootMargin: '100px' });
      
      observer.observe(node);
      return () => observer.disconnect();
    }
  }, [hasNextPage, fetchNextPage]);
  
  return (
    <div>
      {data?.pages.map((page) =>
        page.items.map((item, i) => {
          const isLast = i === page.items.length - 1;
          return (
            <div key={item.id} ref={isLast ? lastItemRef : null}>
              {item.name}
            </div>
          );
        })
      )}
    </div>
  );
}
```

### Infinite Queries

#### Basic Infinite Query Structure

Fetch paginated data with cursor-based pagination:

```javascript
const fetchProjects = async ({ pageParam = 1 }) => {
  const response = await fetch(`/api/projects?cursor=${pageParam}&limit=20`);
  if (!response.ok) throw new Error('Fetch failed');
  
  const data = await response.json();
  return {
    items: data.projects,
    nextCursor: data.nextCursor,
    hasMore: data.hasMore
  };
};

function ProjectList() {
  const {
    data,
    fetchNextPage,
    hasNextPage,
    isFetchingNextPage,
    status
  } = useInfiniteQuery({
    queryKey: ['projects'],
    queryFn: fetchProjects,
    getNextPageParam: (lastPage) => lastPage.hasMore ? lastPage.nextCursor : undefined,
    initialPageParam: 1
  });
  
  return (
    <div>
      {data?.pages.map((page) =>
        page.items.map((project) => (
          <div key={project.id}>{project.name}</div>
        ))
      )}
      
      {hasNextPage && (
        <button onClick={() => fetchNextPage()} disabled={isFetchingNextPage}>
          {isFetchingNextPage ? 'Loading...' : 'Load More'}
        </button>
      )}
    </div>
  );
}
```

#### Bidirectional Infinite Queries

Support both forward and backward pagination:

```javascript
const fetchMessages = async ({ pageParam = { cursor: null, direction: 'forward' } }) => {
  const { cursor, direction } = pageParam;
  const endpoint = cursor
    ? `/api/messages?cursor=${cursor}&direction=${direction}`
    : '/api/messages';
  
  const response = await fetch(endpoint);
  if (!response.ok) throw new Error('Fetch failed');
  
  const data = await response.json();
  return {
    messages: data.messages,
    nextCursor: data.nextCursor,
    previousCursor: data.previousCursor
  };
};

function MessageThread() {
  const {
    data,
    fetchNextPage,
    fetchPreviousPage,
    hasNextPage,
    hasPreviousPage
  } = useInfiniteQuery({
    queryKey: ['messages', threadId],
    queryFn: fetchMessages,
    getNextPageParam: (lastPage) => 
      lastPage.nextCursor ? { cursor: lastPage.nextCursor, direction: 'forward' } : undefined,
    getPreviousPageParam: (firstPage) =>
      firstPage.previousCursor ? { cursor: firstPage.previousCursor, direction: 'backward' } : undefined,
    initialPageParam: { cursor: null, direction: 'forward' }
  });
  
  return (
    <div>
      {hasPreviousPage && (
        <button onClick={() => fetchPreviousPage()}>Load Earlier</button>
      )}
      
      {data?.pages.map((page) =>
        page.messages.map((msg) => <Message key={msg.id} message={msg} />)
      )}
      
      {hasNextPage && (
        <button onClick={() => fetchNextPage()}>Load More</button>
      )}
    </div>
  );
}
```

#### Infinite Query with Search/Filters

Reset and refetch when filters change:

```javascript
function FilteredProductList() {
  const [filters, setFilters] = useState({ category: 'all', minPrice: 0 });
  
  const {
    data,
    fetchNextPage,
    hasNextPage,
    refetch
  } = useInfiniteQuery({
    queryKey: ['products', filters],
    queryFn: async ({ pageParam = 1 }) => {
      const params = new URLSearchParams({
        page: pageParam,
        category: filters.category,
        minPrice: filters.minPrice
      });
      
      const response = await fetch(`/api/products?${params}`);
      if (!response.ok) throw new Error('Fetch failed');
      
      const data = await response.json();
      return {
        products: data.products,
        nextPage: data.nextPage
      };
    },
    getNextPageParam: (lastPage) => lastPage.nextPage,
    initialPageParam: 1
  });
  
  // Filters change triggers automatic refetch due to queryKey change
  const handleFilterChange = (newFilters) => {
    setFilters(newFilters);
  };
  
  return (
    <div>
      <FilterControls filters={filters} onChange={handleFilterChange} />
      {data?.pages.map((page) =>
        page.products.map((product) => (
          <ProductCard key={product.id} product={product} />
        ))
      )}
    </div>
  );
}
```

#### Infinite Query Mutations

Update infinite query cache after mutations:

```javascript
function InfiniteTaskList() {
  const queryClient = useQueryClient();
  
  const { data } = useInfiniteQuery({
    queryKey: ['tasks'],
    queryFn: fetchTasks,
    getNextPageParam: (lastPage) => lastPage.nextCursor,
    initialPageParam: undefined
  });
  
  const createTaskMutation = useMutation({
    mutationFn: async (newTask) => {
      const response = await fetch('/api/tasks', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(newTask)
      });
      if (!response.ok) throw new Error('Creation failed');
      return response.json();
    },
    onSuccess: (createdTask) => {
      queryClient.setQueryData(['tasks'], (old) => {
        if (!old) return old;
        
        return {
          ...old,
          pages: old.pages.map((page, i) => 
            i === 0
              ? { ...page, items: [createdTask, ...page.items] }
              : page
          )
        };
      });
    }
  });
  
  const deleteTaskMutation = useMutation({
    mutationFn: async (taskId) => {
      const response = await fetch(`/api/tasks/${taskId}`, { method: 'DELETE' });
      if (!response.ok) throw new Error('Deletion failed');
      return taskId;
    },
    onSuccess: (deletedId) => {
      queryClient.setQueryData(['tasks'], (old) => {
        if (!old) return old;
        
        return {
          ...old,
          pages: old.pages.map((page) => ({
            ...page,
            items: page.items.filter((task) => task.id !== deletedId)
          }))
        };
      });
    }
  });
}
```

### Dependent Queries

#### Serial Query Execution

Execute queries in sequence when data dependencies exist:

```javascript
function UserPosts({ userId }) {
  const { data: user } = useQuery({
    queryKey: ['user', userId],
    queryFn: async ({ queryKey }) => {
      const [_key, id] = queryKey;
      const response = await fetch(`/api/users/${id}`);
      if (!response.ok) throw new Error('User fetch failed');
      return response.json();
    }
  });
  
  const { data: posts } = useQuery({
    queryKey: ['posts', user?.id],
    queryFn: async ({ queryKey }) => {
      const [_key, authorId] = queryKey;
      const response = await fetch(`/api/posts?authorId=${authorId}`);
      if (!response.ok) throw new Error('Posts fetch failed');
      return response.json();
    },
    enabled: !!user
  });
  
  if (!user) return <div>Loading user...</div>;
  if (!posts) return <div>Loading posts...</div>;
  
  return (
    <div>
      <h1>{user.name}'s Posts</h1>
      {posts.map((post) => <Post key={post.id} post={post} />)}
    </div>
  );
}
```

#### Conditional Query Execution

Enable queries based on complex conditions:

```javascript
function ConditionalData({ mode, filters }) {
  const shouldFetchAnalytics = mode === 'analytics' && filters.dateRange;
  
  const { data: analyticsData } = useQuery({
    queryKey: ['analytics', filters.dateRange],
    queryFn: async ({ queryKey }) => {
      const [_key, dateRange] = queryKey;
      const response = await fetch(`/api/analytics?start=${dateRange.start}&end=${dateRange.end}`);
      if (!response.ok) throw new Error('Analytics fetch failed');
      return response.json();
    },
    enabled: shouldFetchAnalytics,
    staleTime: 10 * 60 * 1000
  });
  
  return shouldFetchAnalytics ? (
    <AnalyticsView data={analyticsData} />
  ) : (
    <StandardView />
  );
}
```

#### Multiple Dependent Queries

Chain multiple dependent fetches:

```javascript
function TeamProjectDashboard({ teamId }) {
  const { data: team } = useQuery({
    queryKey: ['team', teamId],
    queryFn: fetchTeam
  });
  
  const { data: projects } = useQuery({
    queryKey: ['projects', team?.id],
    queryFn: async ({ queryKey }) => {
      const [_key, id] = queryKey;
      const response = await fetch(`/api/teams/${id}/projects`);
      if (!response.ok) throw new Error('Projects fetch failed');
      return response.json();
    },
    enabled: !!team
  });
  
  const { data: metrics } = useQuery({
    queryKey: ['metrics', projects?.map(p => p.id)],
    queryFn: async ({ queryKey }) => {
      const [_key, projectIds] = queryKey;
      const response = await fetch('/api/metrics', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ projectIds })
      });
      if (!response.ok) throw new Error('Metrics fetch failed');
      return response.json();
    },
    enabled: !!projects && projects.length > 0
  });
  
  if (!team) return <Loading />;
  if (!projects) return <Loading />;
  
  return <Dashboard team={team} projects={projects} metrics={metrics} />;
}
```

### Parallel Queries

#### Multiple Independent Queries

Fetch unrelated data simultaneously:

```javascript
function Dashboard() {
  const userQuery = useQuery({
    queryKey: ['currentUser'],
    queryFn: async () => {
      const response = await fetch('/api/user/current');
      if (!response.ok) throw new Error('User fetch failed');
      return response.json();
    }
  });
  
  const statsQuery = useQuery({
    queryKey: ['stats'],
    queryFn: async () => {
      const response = await fetch('/api/stats');
      if (!response.ok) throw new Error('Stats fetch failed');
      return response.json();
    }
  });
  
  const notificationsQuery = useQuery({
    queryKey: ['notifications'],
    queryFn: async () => {
      const response = await fetch('/api/notifications');
      if (!response.ok) throw new Error('Notifications fetch failed');
      return response.json();
    }
  });
  
  const isLoading = userQuery.isLoading || statsQuery.isLoading || notificationsQuery.isLoading;
  
  if (isLoading) return <Loading />;
  
  return (
    <div>
      <UserInfo user={userQuery.data} />
      <Stats data={statsQuery.data} />
      <Notifications items={notificationsQuery.data} />
    </div>
  );
}
```

#### useQueries for Dynamic Parallel Queries

Fetch variable number of queries:

```javascript
function MultiUserProfiles({ userIds }) {
  const userQueries = useQueries({
    queries: userIds.map((id) => ({
      queryKey: ['user', id],
      queryFn: async () => {
        const response = await fetch(`/api/users/${id}`);
        if (!response.ok) throw new Error(`User ${id} fetch failed`);
        return response.json();
      },
      staleTime: 5 * 60 * 1000
    }))
  });
  
  const allLoading = userQueries.some((q) => q.isLoading);
  const anyError = userQueries.some((q) => q.isError);
  
  if (allLoading) return <Loading />;
  if (anyError) return <Error />;
  
  return (
    <div>
      {userQueries.map((query, i) => (
        <UserCard key={userIds[i]} user={query.data} />
      ))}
    </div>
  );
}
```

#### Combining Parallel and Dependent Queries

Mix independent and dependent query patterns:

```javascript
function ComplexDashboard({ organizationId }) {
  // Independent queries that can run immediately
  const settingsQuery = useQuery({
    queryKey: ['settings'],
    queryFn: fetchSettings
  });
  
  const userQuery = useQuery({
    queryKey: ['currentUser'],
    queryFn: fetchCurrentUser
  });
  
  // Dependent on organizationId
  const orgQuery = useQuery({
    queryKey: ['organization', organizationId],
    queryFn: async ({ queryKey }) => {
      const [_key, id] = queryKey;
      const response = await fetch(`/api/organizations/${id}`);
      if (!response.ok) throw new Error('Org fetch failed');
      return response.json();
    }
  });
  
  // Dependent on organization data
  const teamsQuery = useQuery({
    queryKey: ['teams', orgQuery.data?.id],
    queryFn: async ({ queryKey }) => {
      const [_key, orgId] = queryKey;
      const response = await fetch(`/api/organizations/${orgId}/teams`);
      if (!response.ok) throw new Error('Teams fetch failed');
      return response.json();
    },
    enabled: !!orgQuery.data
  });
  
  return (
    <div>
      <Settings data={settingsQuery.data} />
      <UserProfile user={userQuery.data} />
      <Organization org={orgQuery.data} teams={teamsQuery.data} />
    </div>
  );
}
```

### Background Refetching

#### Automatic Background Updates

Refetch stale data when window regains focus:

```javascript
useQuery({
  queryKey: ['liveData'],
  queryFn: async () => {
    const response = await fetch('/api/live-data');
    if (!response.ok) throw new Error('Fetch failed');
    return response.json();
  },
  staleTime: 30 * 1000, // Consider stale after 30s
  refetchOnWindowFocus: true,
  refetchOnReconnect: true
});
```

#### Polling Pattern

Continuously refetch at intervals:

```javascript
function LiveScoreboard() {
  const { data } = useQuery({
    queryKey: ['scores'],
    queryFn: async () => {
      const response = await fetch('/api/scores/live');
      if (!response.ok) throw new Error('Fetch failed');
      return response.json();
    },
    refetchInterval: 5000, // Poll every 5 seconds
    refetchIntervalInBackground: true
  });
  
  return <Scoreboard scores={data} />;
}
```

#### Adaptive Polling

Adjust polling frequency based on conditions:

```javascript
function AdaptivePolling({ matchId, isLive }) {
  const { data } = useQuery({
    queryKey: ['match', matchId],
    queryFn: async ({ queryKey }) => {
      const [_key, id] = queryKey;
      const response = await fetch(`/api/matches/${id}`);
      if (!response.ok) throw new Error('Fetch failed');
      return response.json();
    },
    refetchInterval: (data) => {
      if (!isLive) return false; // Stop polling
      if (data?.status === 'critical') return 2000; // 2s for critical
      return 10000; // 10s normally
    }
  });
  
  return <MatchDetails match={data} />;
}
```

#### Manual Refetch Control

Trigger refetches programmatically:

```javascript
function DataView() {
  const { data, refetch, isFetching } = useQuery({
    queryKey: ['data'],
    queryFn: fetchData,
    staleTime: Infinity, // Never auto-refetch
    refetchOnWindowFocus: false
  });
  
  return (
    <div>
      <button onClick={() => refetch()} disabled={isFetching}>
        {isFetching ? 'Refreshing...' : 'Refresh'}
      </button>
      <DataDisplay data={data} />
    </div>
  );
}
```

### Authentication Integration

#### Token Injection

Add authentication headers to all requests:

```javascript
const createAuthenticatedFetcher = (getToken) => {
  return async ({ queryKey, signal }) => {
    const token = await getToken();
    const [url] = queryKey;
    
    const response = await fetch(url, {
      signal,
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      }
    });
    
    if (!response.ok) {
      if (response.status === 401) {
        throw new Error('Unauthorized');
      }
      throw new Error(`HTTP ${response.status}`);
    }
    
    return response.json();
  };
};

function App() {
  const { getAccessToken } = useAuth();
  
  const queryClient = new QueryClient({
    defaultOptions: {
      queries: {
        queryFn: createAuthenticatedFetcher(getAccessToken)
      }
    }
  });
  
  return (
    <QueryClientProvider client={queryClient}>
      <AppContent />
    </QueryClientProvider>
  );
}
```

#### Token Refresh on 401

Automatically refresh expired tokens:

```javascript
const fetchWithTokenRefresh = async ({ queryKey, signal }, getToken, refreshToken) => {
  const [url] = queryKey;
  
  const makeRequest = async (token) => {
    const response = await fetch(url, {
      signal,
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      }
    });
    return response;
  };
  
  let token = await getToken();
  let response = await makeRequest(token);
  
  if (response.status === 401) {
    // Token expired, refresh and retry
    token = await refreshToken();
    response = await makeRequest(token);
  }
  
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}`);
  }
  
  return response.json();
};
```

#### Clearing Queries on Logout

Invalidate all cached data when user logs out:

```javascript
function useLogout() {
  const queryClient = useQueryClient();
  const { logout } = useAuth();
  
  return async () => {
    await logout();
    queryClient.clear(); // Remove all cached queries
  };
}
```

#### Protected Query Access

Prevent queries from executing without authentication:

```javascript
function ProtectedData() {
  const { isAuthenticated, token } = useAuth();
  
  const { data } = useQuery({
    queryKey: ['protectedData'],
    queryFn: async ({ signal }) => {
      const response = await fetch('/api/protected', {
        signal,
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });
      if (!response.ok) throw new Error('Fetch failed');
      return response.json();
    },
    enabled: isAuthenticated && !!token
  });
  
  if (!isAuthenticated) return <Login />;
  
  return <DataDisplay data={data} />;
}
```

### Request Deduplication

#### Automatic Deduplication

React Query deduplicates identical concurrent requests:

```javascript
// Both components mount simultaneously
function ComponentA() {
  useQuery({ queryKey: ['user', 1], queryFn: fetchUser });
}

function ComponentB() {
  useQuery({ queryKey: ['user', 1], queryFn: fetchUser });
}

// Only one network request is made
```

**[Inference]** React Query identifies identical queries by comparing queryKey arrays; matching keys result in request sharing.

#### Manual Request Batching

Batch multiple requests into single fetch:

```javascript
// Collect requests over time window
const requestBatcher = (() => {
  let batch = [];
  let timeoutId = null;
  
  return (id) => {
    return new Promise((resolve, reject) => {
      batch.push({ id, resolve, reject });
      
      if (timeoutId) clearTimeout(timeoutId);
      
      timeoutId = setTimeout(async () => {
        const currentBatch = batch;
        batch = [];
        
        try {
          const ids = currentBatch.map(item => item.id);
          const response = await fetch('/api/users/batch', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ ids })
          });
          
          if (!response.ok) throw new Error('Batch fetch failed');
          
          const results = await response.json();
          currentBatch.forEach(({ id, resolve }) => {
            resolve(results[id]);
          });
        } catch (error) {
          currentBatch.forEach(({ reject }) => reject(error));
        }
      }, 10); // 10ms batching window
    });
  };
})();

function UserProfile({ userId }) {
  const { data } = useQuery({
    queryKey: ['user', userId],
    queryFn: () => requestBatcher(userId)
  });
}
```

### Suspense Integration

#### Query Suspense Mode

Use React Suspense for loading states:

```javascript
function UserProfile({ userId }) {
  const { data } = useSuspenseQuery({
    queryKey: ['user', userId],
    queryFn: async ({ queryKey }) => {
      const [_key, id] = queryKey;
      const response = await fetch(`/api/users/${id}`);
      if (!response.ok) throw new Error('Fetch failed');
      return response.json();
    }
  });
  
  // No loading state needed - Suspense boundary handles it
  return <div>{data.name}</div>;
}

function App() {
  return (
    <Suspense fallback={<Loading />}>
      <UserProfile userId={1} />
    </Suspense>
  );
}
```

#### Multiple Suspense Queries

Coordinate multiple suspending queries:

```javascript
function Dashboard() {
  const { data: user } = useSuspenseQuery({
    queryKey: ['user'],
    queryFn: fetchUser
  });
  
  const { data: stats } = useSuspenseQuery({
    queryKey: ['stats'],
    queryFn: fetchStats
  });
  
  // Both queries must resolve before rendering
  return (
    <div>
      <UserInfo user={user} />
      <Stats data={stats} />
    </div>
  );
}

function App() {
  return (
    <Suspense fallback={<Loading />}>
      <Dashboard />
    </Suspense>
  );
}
```

#### Nested Suspense Boundaries

Progressive loading with multiple boundaries:

```javascript
function App() {
  return (
    <Suspense fallback={<PageLoading />}>
      <Header />
      
      <Suspense fallback={<ContentLoading />}>
        <MainContent />
        
        <Suspense fallback={<SidebarLoading />}>
          <Sidebar />
        </Suspense>
      </Suspense>
    </Suspense>
  );
}
```

### Server State Synchronization

#### Real-Time Updates via WebSocket

Synchronize query cache with server-sent events:

```javascript
function useWebSocketSync() {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const ws = new WebSocket('wss://api.example.com/updates');
    
    ws.onmessage = (event) => {
      const update = JSON.parse(event.data);
      
      switch (update.type) {
        case 'USER_UPDATED':
          queryClient.invalidateQueries({ queryKey: ['user', update.userId] });
          break;
        
        case 'ITEM_CREATED':
          queryClient.setQueryData(['items'], (old) => [update.item, ...old]);
          break;
        
        case 'ITEM_DELETED':
          queryClient.setQueryData(['items'], (old) =>
            old.filter(item => item.id !== update.itemId)
          );
          break;
      }
    };
    
    return () => ws.close();
  }, [queryClient]);
}
```

#### Server-Sent Events Integration

Stream updates from server:

```javascript
function useServerEvents(endpoint) {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const eventSource = new EventSource(endpoint);
    
    eventSource.addEventListener('update', (event) => {
      const data = JSON.parse(event.data);
      queryClient.setQueryData(['liveData'], data);
    });
    
    eventSource.addEventListener('invalidate', (event) => {
      const { queryKey } = JSON.parse(event.data);
      queryClient.invalidateQueries({ queryKey });
    });
    
    return () => eventSource.close();
  }, [endpoint, queryClient]);
}
```

#### Optimistic Concurrency Control

Handle conflicts with ETags or version numbers:

```javascript
const updateWithOCC = async ({ id, version, updates }) => {
  const response = await fetch(`/api/items/${id}`, {
    method: 'PATCH',
    headers: {
      'Content-Type': 'application/json',
      'If-Match': version
    },
    body: JSON.stringify(updates)
  });
  
  if (response.status === 412) {
    // Precondition failed - version conflict
    throw new Error('Version conflict');
  }
  
  if (!response.ok) {
    throw new Error('Update failed');
  }
  
  return response.json();
};

function EditableItem({ item }) {
  const queryClient = useQueryClient();
  
  const mutation = useMutation({
    mutationFn: updateWithOCC,
    onError: (error) => {
      if (error.message === 'Version conflict') {
        // Refetch latest version
        queryClient.invalidateQueries({ queryKey: ['item', item.id] });
      }
    },
    onSuccess: (updated) => {
      queryClient.setQueryData(['item', item.id], updated);
    }
  });
  
  return (
    <form onSubmit={(e) => {
      e.preventDefault();
      mutation.mutate({
        id: item.id,
        version: item.version,
        updates: formData
      });
    }}>
      {/* form fields */}
    </form>
  );
}
```

### Performance Optimization

#### Structural Sharing

React Query automatically shares unchanged data structures:

```javascript
// Large data structure
const { data: largeList } = useQuery({
  queryKey: ['items'],
  queryFn: fetchItems,
  structuralSharing: true // Default behavior
});

// When refetching, unchanged objects maintain referential equality
// This prevents unnecessary re-renders in child components
```

**[Inference]** Structural sharing compares nested objects to preserve references for unchanged data, reducing re-render frequency.

#### Select Transform

Transform query data without affecting cache:

```javascript
function UserNames() {
  const { data: names } = useQuery({
    queryKey: ['users'],
    queryFn: async () => {
      const response = await fetch('/api/users');
      if (!response.ok) throw new Error('Fetch failed');
      return response.json();
    },
    select: (users) => users.map((user) => user.name)
  });
  
  // Only re-renders when names change, not when other user properties change
  return <div>{names.join(', ')}</div>;
}
```

#### Placeholder Data

Show stale data while refetching:

```javascript
function UserProfile({ userId }) {
  const queryClient = useQueryClient();
  
  const { data } = useQuery({
    queryKey: ['user', userId],
    queryFn: fetchUser,
    placeholderData: () => {
      // Use data from user list if available
      const usersData = queryClient.getQueryData(['users']);
      return usersData?.find((user) => user.id === userId);
    }
  });
  
  return <div>{data?.name}</div>;
}
```

#### Initial Data from Cache

Seed new queries with existing cache data:

```javascript
function UserDetails({ userId }) {
  const queryClient = useQueryClient();
  
  const { data } = useQuery({
    queryKey: ['user', userId],
    queryFn: fetchUser,
    initialData: () => {
      const usersData = queryClient.getQueryData(['users']);
      return usersData?.find((user) => user.id === userId);
    },
    initialDataUpdatedAt: () => {
      const queryState = queryClient.getQueryState(['users']);
      return queryState?.dataUpdatedAt;
    }
  });
}
```

#### Query Key Factories

Centralize and type-safe query keys:

```javascript
const userKeys = {
  all: ['users'] as const,
  lists: () => [...userKeys.all, 'list'] as const,
  list: (filters) => [...userKeys.lists(), filters] as const,
  details: () => [...userKeys.all, 'detail'] as const,
  detail: (id) => [...userKeys.details(), id] as const
};

// Usage
useQuery({
  queryKey: userKeys.detail(userId),
  queryFn: fetchUser
});

// Invalidate all user queries
queryClient.invalidateQueries({ queryKey: userKeys.all });

// Invalidate user lists only
queryClient.invalidateQueries({ queryKey: userKeys.lists() });
```

#### Garbage Collection Configuration

Control when inactive queries are removed from cache:

```javascript
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      cacheTime: 5 * 60 * 1000, // 5 minutes
      staleTime: 30 * 1000, // 30 seconds
      gcTime: 10 * 60 * 1000 // Garbage collect after 10 minutes (v5+)
    }
  }
});

// Per-query override
useQuery({
  queryKey: ['temporary-data'],
  queryFn: fetchData,
  cacheTime: 0 // Remove immediately when unused
});
```

---

## Stale-While-Revalidate

### Core Concept

Stale-while-revalidate is a caching strategy where cached content is served immediately (even if stale) while simultaneously fetching fresh content in the background. This provides instant responses while ensuring eventual consistency.

The strategy originates from the HTTP `Cache-Control` header directive:

```http
Cache-Control: max-age=3600, stale-while-revalidate=86400
```

This tells the browser: serve from cache for 1 hour, and for the next 24 hours serve stale content while fetching fresh data.

### HTTP Cache-Control Implementation

The `stale-while-revalidate` directive works at the HTTP caching layer:

```javascript
// Server response
fetch('/api/data')
  .then(response => {
    // Response includes:
    // Cache-Control: max-age=60, stale-while-revalidate=3600
    return response.json();
  });
```

**Freshness Window (`max-age`):** Content is considered fresh and served directly from cache.

**Revalidation Window (`stale-while-revalidate`):** Content is stale but served from cache while the browser asynchronously revalidates.

**Beyond Revalidation Window:** Content is not served from cache; the browser waits for fresh data.

### Browser Support

Native `Cache-Control: stale-while-revalidate` support:

- Chrome 75+ (June 2019)
- Edge 79+ (January 2020)
- Firefox 68+ (July 2019) - behind flag until Firefox 79

**No Native Support:**

- Safari (all versions as of January 2025)
- Internet Explorer (all versions)

[Unverified] Safari may have added support after January 2025.

### Manual Implementation Pattern

Implementing SWR without native browser support:

```javascript
async function fetchWithSWR(url, options = {}) {
  const cacheKey = url;
  const cached = await getCachedData(cacheKey);
  
  // Return stale data immediately
  if (cached && cached.stale) {
    // Trigger background revalidation
    revalidateInBackground(url, cacheKey, options);
    return cached.data;
  }
  
  // Return fresh cached data
  if (cached && !cached.stale) {
    return cached.data;
  }
  
  // No cache, fetch fresh
  const response = await fetch(url, options);
  const data = await response.json();
  
  await setCachedData(cacheKey, data);
  return data;
}

function revalidateInBackground(url, cacheKey, options) {
  fetch(url, options)
    .then(response => response.json())
    .then(data => setCachedData(cacheKey, data))
    .catch(err => console.error('Revalidation failed:', err));
}
```

### Cache Storage API Integration

Using the Cache API for persistent storage:

```javascript
async function getCachedData(cacheKey) {
  const cache = await caches.open('swr-cache-v1');
  const cached = await cache.match(cacheKey);
  
  if (!cached) return null;
  
  const data = await cached.json();
  const cachedTime = new Date(cached.headers.get('X-Cached-Time'));
  const age = Date.now() - cachedTime.getTime();
  
  const maxAge = 60000; // 60 seconds fresh
  const staleTime = 3600000; // 1 hour stale-while-revalidate
  
  return {
    data,
    stale: age > maxAge,
    expired: age > maxAge + staleTime
  };
}

async function setCachedData(cacheKey, data) {
  const cache = await caches.open('swr-cache-v1');
  const response = new Response(JSON.stringify(data), {
    headers: {
      'Content-Type': 'application/json',
      'X-Cached-Time': new Date().toISOString()
    }
  });
  
  await cache.put(cacheKey, response);
}
```

### Service Worker Implementation

Service workers provide powerful SWR control:

```javascript
// service-worker.js
self.addEventListener('fetch', event => {
  if (event.request.url.includes('/api/')) {
    event.respondWith(staleWhileRevalidate(event.request));
  }
});

async function staleWhileRevalidate(request) {
  const cache = await caches.open('api-cache-v1');
  const cached = await cache.match(request);
  
  // Fetch fresh data in background
  const fetchPromise = fetch(request).then(response => {
    cache.put(request, response.clone());
    return response;
  });
  
  // Return cached immediately if available
  return cached || fetchPromise;
}
```

### Libraries and Frameworks

**SWR (Vercel):**

```javascript
import useSWR from 'swr';

function Profile() {
  const { data, error, isLoading } = useSWR('/api/user', fetcher);
  
  if (error) return <div>Failed to load</div>;
  if (isLoading) return <div>Loading...</div>;
  return <div>Hello {data.name}!</div>;
}

const fetcher = url => fetch(url).then(res => res.json());
```

The library handles:

- Automatic revalidation on focus
- Interval polling
- Deduplication of requests
- Cache invalidation

**React Query (TanStack Query):**

```javascript
import { useQuery } from '@tanstack/react-query';

function Profile() {
  const { data, isLoading } = useQuery({
    queryKey: ['user'],
    queryFn: () => fetch('/api/user').then(res => res.json()),
    staleTime: 60000, // Consider fresh for 60s
    cacheTime: 300000, // Keep in cache for 5min
  });
  
  return <div>{data?.name}</div>;
}
```

**Workbox:**

```javascript
import { StaleWhileRevalidate } from 'workbox-strategies';
import { registerRoute } from 'workbox-routing';

registerRoute(
  ({url}) => url.pathname.startsWith('/api/'),
  new StaleWhileRevalidate({
    cacheName: 'api-cache',
    plugins: [
      {
        cacheKeyWillBeUsed: async ({request}) => request.url,
      }
    ]
  })
);
```

### Configuration Parameters

**Max Age (Freshness Period):** Duration content is considered fresh. No revalidation occurs during this period.

```javascript
const maxAge = 60; // 60 seconds
```

**Stale Window (Revalidation Period):** Duration stale content can be served while revalidating.

```javascript
const staleWhileRevalidate = 3600; // 1 hour
```

**Cache Time (Retention):** How long data stays in cache before being purged.

```javascript
const cacheTime = 86400; // 24 hours
```

### Revalidation Triggers

**On Mount:**

```javascript
useSWR('/api/data', fetcher, {
  revalidateOnMount: true
});
```

**On Focus:**

```javascript
useSWR('/api/data', fetcher, {
  revalidateOnFocus: true
});
```

**On Reconnect:**

```javascript
useSWR('/api/data', fetcher, {
  revalidateOnReconnect: true
});
```

**Interval Polling:**

```javascript
useSWR('/api/data', fetcher, {
  refreshInterval: 3000 // Revalidate every 3s
});
```

**Manual Revalidation:**

```javascript
const { data, mutate } = useSWR('/api/data', fetcher);

// Trigger revalidation
mutate();
```

### Cache Invalidation

**Mutation with Optimistic Updates:**

```javascript
import { useSWRConfig } from 'swr';

function UpdateButton() {
  const { mutate } = useSWRConfig();
  
  const updateUser = async () => {
    // Optimistically update cache
    mutate('/api/user', { name: 'New Name' }, false);
    
    // Send update to server
    await fetch('/api/user', {
      method: 'PUT',
      body: JSON.stringify({ name: 'New Name' })
    });
    
    // Revalidate to confirm
    mutate('/api/user');
  };
  
  return <button onClick={updateUser}>Update</button>;
}
```

**Cache Invalidation Patterns:**

```javascript
// Invalidate single key
mutate('/api/user');

// Invalidate by pattern
mutate(key => key.startsWith('/api/users/'));

// Clear specific cache
cache.delete(new Request('/api/data'));

// Clear all caches
caches.keys().then(names => {
  names.forEach(name => caches.delete(name));
});
```

### Error Handling

**Stale-If-Error:**

Serve stale content if revalidation fails:

```javascript
async function fetchWithStaleIfError(url) {
  const cached = await getCachedData(url);
  
  try {
    const response = await fetch(url);
    if (!response.ok) throw new Error('Fetch failed');
    
    const data = await response.json();
    await setCachedData(url, data);
    return data;
  } catch (error) {
    // Return stale data on error
    if (cached) {
      console.warn('Using stale data due to error:', error);
      return cached.data;
    }
    throw error;
  }
}
```

**HTTP Header:**

```http
Cache-Control: max-age=60, stale-while-revalidate=3600, stale-if-error=86400
```

### Deduplication

Prevent multiple simultaneous requests for the same resource:

```javascript
const pendingRequests = new Map();

async function fetchWithDedup(url) {
  // Return existing pending request
  if (pendingRequests.has(url)) {
    return pendingRequests.get(url);
  }
  
  // Create new request
  const promise = fetch(url)
    .then(response => response.json())
    .finally(() => pendingRequests.delete(url));
  
  pendingRequests.set(url, promise);
  return promise;
}
```

### Memory Considerations

**Cache Size Limits:**

```javascript
async function pruneCacheIfNeeded() {
  const cache = await caches.open('swr-cache-v1');
  const requests = await cache.keys();
  
  const maxEntries = 100;
  if (requests.length > maxEntries) {
    // Remove oldest entries
    const toDelete = requests.slice(0, requests.length - maxEntries);
    await Promise.all(toDelete.map(req => cache.delete(req)));
  }
}
```

**Storage Quota:**

```javascript
if (navigator.storage && navigator.storage.estimate) {
  const estimate = await navigator.storage.estimate();
  const percentUsed = (estimate.usage / estimate.quota) * 100;
  console.log(`Storage: ${percentUsed.toFixed(2)}% used`);
}
```

### Race Condition Handling

**Last-Write-Wins:**

```javascript
let latestRequestId = 0;

async function fetchWithRaceProtection(url) {
  const requestId = ++latestRequestId;
  
  const cached = await getCachedData(url);
  if (cached) {
    // Return cached data immediately
    setTimeout(() => revalidate(url, requestId), 0);
    return cached.data;
  }
  
  return revalidate(url, requestId);
}

async function revalidate(url, requestId) {
  const data = await fetch(url).then(r => r.json());
  
  // Only update if this is still the latest request
  if (requestId === latestRequestId) {
    await setCachedData(url, data);
    return data;
  }
}
```

### Conditional Requests

Optimize revalidation with `ETag` and `Last-Modified`:

```javascript
async function fetchWithConditional(url) {
  const cache = await caches.open('swr-cache-v1');
  const cached = await cache.match(url);
  
  const headers = {};
  if (cached) {
    const etag = cached.headers.get('ETag');
    const lastModified = cached.headers.get('Last-Modified');
    
    if (etag) headers['If-None-Match'] = etag;
    if (lastModified) headers['If-Modified-Since'] = lastModified;
  }
  
  const response = await fetch(url, { headers });
  
  // 304 Not Modified - cached content is still fresh
  if (response.status === 304) {
    return cached;
  }
  
  // Update cache with fresh content
  await cache.put(url, response.clone());
  return response;
}
```

### Performance Benefits

**Perceived Performance:** Users see content instantly from cache rather than waiting for network requests.

**Reduced Server Load:** Fewer blocking requests to the server during the freshness period.

**Bandwidth Efficiency:** Content is fetched in background, not blocking user interaction.

**Offline Resilience:** Stale content can be served when network is unavailable.

### Drawbacks and Tradeoffs

**Stale Data Display:** Users may see outdated information briefly.

**Increased Bandwidth:** Background revalidation consumes bandwidth even when users don't notice updates.

**Cache Storage Overhead:** Requires managing cache storage and eviction policies.

**Complexity:** Requires careful handling of cache keys, invalidation, and race conditions.

### CDN Integration

CDNs like Cloudflare and Fastly support `stale-while-revalidate`:

```javascript
// Cloudflare Cache-Control
Response.headers.set(
  'Cache-Control',
  'public, max-age=60, stale-while-revalidate=3600'
);
```

**Cloudflare:** Respects `stale-while-revalidate` directive at edge locations.

**Fastly:** Supports via `stale-while-revalidate` and `stale-if-error` directives.

**AWS CloudFront:** [Unverified] May support `stale-while-revalidate` as of 2024 or later.

### Testing Strategies

**Simulating Stale Data:**

```javascript
// Mock cache with stale data
beforeEach(() => {
  const staleData = { name: 'Stale User' };
  const timestamp = Date.now() - 120000; // 2 minutes ago
  
  cache.put('/api/user', new Response(JSON.stringify(staleData), {
    headers: { 'X-Cached-Time': new Date(timestamp).toISOString() }
  }));
});

test('serves stale data while revalidating', async () => {
  const result = await fetchWithSWR('/api/user');
  expect(result.name).toBe('Stale User');
  
  // Wait for revalidation
  await new Promise(resolve => setTimeout(resolve, 100));
  
  const fresh = await getCachedData('/api/user');
  expect(fresh.data.name).toBe('Fresh User');
});
```

**Network Throttling:**

Test behavior under slow network conditions using browser DevTools or programmatically.

### GraphQL Integration

SWR with GraphQL queries:

```javascript
import useSWR from 'swr';

const query = `
  query User($id: ID!) {
    user(id: $id) {
      id
      name
      email
    }
  }
`;

function useUser(id) {
  return useSWR([query, id], ([query, id]) =>
    fetch('/graphql', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, variables: { id } })
    }).then(res => res.json())
  );
}
```

### WebSocket and Real-Time Updates

Combining SWR with WebSocket for real-time data:

```javascript
const { data, mutate } = useSWR('/api/data', fetcher);

useEffect(() => {
  const ws = new WebSocket('wss://api.example.com');
  
  ws.onmessage = (event) => {
    const update = JSON.parse(event.data);
    // Update cache with real-time data
    mutate(update, false);
  };
  
  return () => ws.close();
}, []);
```

---

## Apollo Client Comparison

### Request Patterns

#### Fetch API Direct Requests

The fetch API generates individual network requests for each operation. Each `fetch()` call creates a separate HTTP request visible in the network tab with distinct timing, headers, and response data. Multiple related requests execute independently without coordination.

Request deduplication requires manual implementation. Simultaneous identical requests generate duplicate network traffic unless explicitly handled through promise caching or request queuing mechanisms.

Polling implementations require manual `setInterval` or `setTimeout` management. Each poll creates a new network request regardless of whether previous responses contained relevant changes.

#### Apollo Client Request Management

Apollo Client consolidates GraphQL operations into structured requests sent to a single endpoint. The network tab shows POST requests to the GraphQL endpoint, with operations embedded in the request payload rather than URL paths.

**Automatic deduplication** prevents redundant requests. When multiple components request identical data simultaneously, Apollo Client batches them into a single network request or serves them from cache, reducing visible network activity.

**Query batching** combines multiple GraphQL queries into a single HTTP request when configured. The network tab shows one request containing multiple operations instead of separate requests for each query.

**Polling operations** appear as periodic requests in the waterfall view. Apollo Client manages intervals internally, with configurable poll intervals and automatic cleanup on component unmount.

### Request Headers

#### Fetch API Header Control

Request headers require explicit configuration for each fetch call. The `headers` parameter in `fetch(url, { headers: {...} })` defines custom headers. Authentication tokens, content types, and custom headers need manual inclusion in every request.

Default headers come from the browser, including `Accept`, `Accept-Encoding`, `Accept-Language`, and `User-Agent`. The `Content-Type` header requires explicit setting for POST requests, typically `application/json` for JSON payloads.

CORS preflight requests (OPTIONS) appear automatically when custom headers or non-simple request methods are used. Each distinct header combination may trigger separate preflight requests.

#### Apollo Client Header Management

Apollo Client centralizes header configuration through the link chain. Headers defined in `HttpLink` or authentication links apply to all requests automatically.

```javascript
// Example configuration pattern (not actual code)
const httpLink = new HttpLink({
  uri: '/graphql',
  headers: {
    authorization: localStorage.getItem('token'),
  }
});
```

**Context-based headers** allow per-request customization. Individual queries can override default headers through the context option, visible in the network tab as modified request headers.

**Dynamic headers** update through link middleware. Authentication links can refresh tokens and update headers without modifying every query call site. The network tab reflects these dynamic header changes across requests.

### Response Analysis

#### Fetch API Responses

Each fetch request produces a distinct response entry in the network tab. Response bodies contain complete endpoint data, whether a single resource, collection, or error response.

**Over-fetching** appears as large response payloads containing unused data. REST endpoints return entire resource representations, visible in the response preview as fields that may never be accessed by the application.

**Under-fetching** manifests as multiple sequential requests. Related data requires separate endpoint calls, creating waterfall patterns in the network tab as each response triggers subsequent requests.

Status codes follow HTTP conventions: 200 for success, 404 for not found, 500 for server errors. Each endpoint uses distinct status codes based on its specific error handling.

#### Apollo Client Responses

GraphQL responses follow a consistent structure with `data` and `errors` properties. The network tab shows POST requests to the GraphQL endpoint with status 200, even when queries partially fail. Actual operation success appears in the response body structure.

**Precise data fetching** results in smaller response payloads containing only requested fields. The response preview shows exactly the fields specified in the query, eliminating over-fetching visible in payload size comparisons.

**Nested data resolution** consolidates related data into single responses. Instead of multiple sequential requests, one GraphQL query retrieves interconnected resources, appearing as a single network entry with a comprehensive response body.

**Partial errors** appear with status 200 but include an `errors` array in the response. Some fields may contain data while others show errors, visible in the response JSON structure.

### Cache Behavior

#### Fetch API Caching

Browser HTTP caching depends on response headers. `Cache-Control`, `Expires`, and `ETag` headers determine caching behavior, visible in the network tab's "Size" column as "(disk cache)" or "(memory cache)".

**Cache misses** appear as full requests with transferred bytes equal to response size. Each request lacking valid cache entries fetches fresh data from the server.

**Cache hits** show no network transfer, with the "Size" column indicating the cache source. However, this caching operates at the HTTP level, unaware of application-level data dependencies or relationships.

Manual caching requires storing responses in variables, localStorage, or IndexedDB. The network tab shows no evidence of this application-level caching, as it occurs outside HTTP mechanisms.

#### Apollo Client Caching

Apollo Client implements normalized in-memory caching independent of HTTP caching. Network tab entries show whether data came from cache through query timing—cached queries resolve nearly instantaneously without network requests.

**Cache hits** may produce no network tab entry at all when data fully satisfies the query from cache. Partial cache hits generate requests for missing data only, visible as smaller response payloads fetching gaps in cached data.

**Cache updates** from mutations trigger automatic cache invalidation and refetching. The network tab shows subsequent refetch requests after mutations, though these may be optimized through cache updates that prevent unnecessary fetches.

**Cache normalization** reduces redundant data storage. Multiple queries referencing the same entity type and ID share cached data, preventing duplicate network requests visible in the absence of redundant fetch operations.

### Request Timing

#### Fetch API Timing Characteristics

Each fetch call shows standard HTTP timing phases: queueing, stalled, DNS lookup, initial connection, SSL, request sent, waiting (TTFB), and content download.

**Sequential requests** create waterfall patterns where each request waits for the previous to complete before starting. The timing view shows gaps between requests as processing time between fetch calls.

**Promise chaining** extends total time as each `.then()` block executes before initiating subsequent requests. The network tab reveals these delays as empty gaps in the waterfall between related requests.

**Parallel requests** using `Promise.all()` show concurrent execution in the waterfall view, with overlapping timing bars indicating simultaneous network activity.

#### Apollo Client Timing Characteristics

GraphQL requests to a single endpoint show consistent connection reuse. After initial connection establishment, subsequent queries skip DNS lookup, connection, and SSL phases, showing only request sent, TTFB, and download.

**Batched requests** appear as single network entries with slightly longer TTFB as the server processes multiple operations. The response payload size increases to include all batched operation results.

**Optimistic updates** create timing discrepancies between UI updates and network completion. The network tab shows the mutation request completing after UI changes, with optimistic data displayed before actual server confirmation.

**Deferred queries** with `@defer` directive generate multiple responses for a single request. The network tab may show streaming responses or multiple response chunks for one request entry.

### Error Identification

#### Fetch API Error Patterns

Failed requests appear with status codes 4xx or 5xx, clearly visible in the network tab's status column. The response preview shows error bodies returned by the server.

**Network failures** display as "failed" status with error messages like "net::ERR_CONNECTION_REFUSED" or "net::ERR_NETWORK_CHANGED". These indicate connectivity issues rather than server errors.

**CORS errors** appear as failed requests with no response data visible, accompanied by console error messages detailing the CORS violation. The preflight OPTIONS request may show success while the actual request fails.

**Timeout errors** occur when requests exceed browser or application timeout limits. The network tab shows very long waiting times followed by request cancellation.

#### Apollo Client Error Patterns

GraphQL errors appear in responses with status 200, requiring inspection of the response body's `errors` array. The network tab status column shows success despite operation failures.

**Partial errors** include both `data` and `errors` properties. Some fields resolve successfully while others fail, visible only through response body examination.

**Network errors** in Apollo Client appear as failed requests similar to fetch API, but Apollo Client's error handling policies determine retry behavior. The network tab may show multiple retry attempts for failed requests.

**GraphQL validation errors** return before server execution, appearing in the `errors` array with validation-specific error messages. The TTFB remains low since the server rejects invalid queries immediately.

### Request Payload Structure

#### Fetch API Payloads

Request payloads contain complete data structures for the endpoint. POST and PUT requests show full resource representations in the request body, visible in the network tab's payload viewer.

The payload size directly correlates with data complexity. Sending nested relationships or large arrays increases payload size proportionally, visible in the "Size" column.

Multiple related operations require separate requests, each with distinct payloads. Creating related entities generates multiple network entries, each carrying the data for one entity.

#### Apollo Client Payloads

GraphQL requests contain three primary components: `query` (the GraphQL operation string), `variables` (input parameters), and `operationName` (optional identifier). The network tab's payload viewer shows this structured format.

**Mutation payloads** separate the operation definition from input data. The `variables` object contains mutation inputs, keeping the operation string reusable across different input values. Payload sizes remain relatively small as only necessary data transmits.

**Batched operation payloads** contain arrays of operations, each with its query and variables. The network tab shows these as single requests with larger payloads containing multiple operation definitions.

**Automatic persisted queries** (APQ) show dramatically smaller payloads after initial query registration. Subsequent requests send only a query hash instead of the full query string, visible as reduced request sizes in the network tab.

### Response Payload Structure

#### Fetch API Response Bodies

Response structure varies by endpoint design. REST APIs return complete resource representations, collections with metadata, or error objects depending on the endpoint.

**Nested resources** may be embedded or referenced by ID. Embedded resources increase response size, visible in the network tab. Referenced resources require additional requests to resolve, creating sequential request patterns.

**Pagination metadata** appears in response bodies or headers (Link headers for REST). Large collections split across multiple requests show in the network tab as sequential fetches with page parameters.

#### Apollo Client Response Bodies

All GraphQL responses follow a consistent structure: a root object containing `data`, `errors`, and potentially `extensions`. This consistency appears across all network tab entries to the GraphQL endpoint.

The `data` property matches the exact shape of the query, containing only requested fields in the specified structure. Comparing query structure to response body demonstrates GraphQL's precise field selection.

The `errors` array contains error objects with `message`, `locations`, `path`, and `extensions` properties. Multiple errors may appear in a single response, all visible in the response body viewer.

The `extensions` property carries metadata like tracing information, cache hints, or custom server data. Performance tracing data in extensions provides additional timing insights beyond network tab metrics.

### Request Frequency and Patterns

#### Fetch API Request Characteristics

Application logic directly controls request timing. Each component or function call to fetch generates a network request, visible as discrete entries in the network tab.

**Redundant requests** occur when multiple components fetch identical data simultaneously. The network tab shows duplicate URLs with overlapping timing, indicating wasted bandwidth.

**Imperative refetching** appears as repeated requests to the same endpoint triggered by application events. The waterfall view shows these as sequential entries to identical URLs.

**Infinite scroll implementations** generate sequential requests as users scroll. The network tab displays these as a series of requests with incremental pagination parameters, forming a staircase pattern in the waterfall.

#### Apollo Client Request Characteristics

Query execution follows React component lifecycle or explicit refetch calls. However, the cache significantly reduces actual network requests visible in the network tab.

**Automatic deduplication** eliminates redundant simultaneous requests. When multiple components mount requesting identical data, the network tab shows a single request rather than duplicates.

**Reactive updates** prevent unnecessary refetching. When mutations update cached data, dependent queries receive updated data without new network requests, visible as the absence of expected fetch operations.

**Background refetching** with `fetchPolicy: 'cache-and-network'` shows immediate cache resolution followed by a background network request for fresh data. The network tab displays this as a delayed request after component rendering.

### Size Comparison

#### Fetch API Size Metrics

The "Size" column shows transferred bytes including headers and compressed body, plus the uncompressed resource size. REST endpoints often transfer more data than needed due to over-fetching.

**Request overhead** includes HTTP headers, cookies, and authentication tokens for each request. Multiple requests to different endpoints accumulate this overhead, visible in total transferred bytes.

**Response redundancy** appears when similar resources are fetched separately. The network tab shows multiple requests returning overlapping data structures, duplicating common fields across responses.

#### Apollo Client Size Metrics

GraphQL requests maintain consistent header overhead to a single endpoint. The "Size" column shows this stable baseline across all GraphQL operations.

**Query size** correlates directly with requested fields. Larger queries selecting more fields show proportionally larger response bodies. Comparing similar queries with different field selections demonstrates precise size control.

**Batched request sizing** shows cumulative effects. A single batched request carrying multiple operations shows larger payload sizes than individual queries, but smaller than the sum of separate requests due to reduced header overhead.

**APQ size reduction** becomes evident comparing initial queries (full query string in payload) against subsequent requests (hash-only payloads). The network tab clearly shows this dramatic request size decrease.

### Performance Optimization Opportunities

#### Fetch API Optimization Indicators

**Large response payloads** signal over-fetching opportunities. Examining response bodies in the network tab reveals unused fields consuming bandwidth unnecessarily.

**High request counts** to similar endpoints suggest opportunities for endpoint consolidation or batching. Numerous sequential requests to related resources indicate potential for combined endpoints.

**Long waterfall chains** demonstrate sequential dependency issues. Each level of the waterfall represents a round-trip delay, revealing opportunities for parallel fetching or data embedding.

**Cache misses** on repeated requests indicate missing or ineffective cache headers. Responses lacking appropriate `Cache-Control` directives show as full transfers in the network tab rather than cache hits.

#### Apollo Client Optimization Indicators

**Large GraphQL responses** suggest over-selection in queries. Reviewing response bodies identifies fields selected but unused by components, representing optimization opportunities through query refinement.

**Frequent refetches** of unchanged data indicate suboptimal `fetchPolicy` configuration. The network tab showing repeated requests to stable data suggests switching to cache-first policies.

**Unbatched query patterns** appear as multiple simultaneous requests to the GraphQL endpoint. Enabling batch links consolidates these into single requests, visible as reduced network tab entries.

**Missing query deduplication** shows identical simultaneous queries as separate network requests. This indicates disabled deduplication features or queries with different variables mistaken as distinct.

### Developer Tools Integration

#### Fetch API Monitoring

Browser DevTools provide the primary interface for monitoring fetch requests. The Network tab displays all HTTP traffic with filtering, sorting, and detailed inspection capabilities.

**Console logging** of fetch operations requires manual instrumentation. Network-level monitoring captures requests automatically, but application-level context requires explicit logging.

**Performance timing** through the Performance tab shows fetch requests in context of page load and interaction timelines. Resource timing API provides programmatic access to detailed timing data.

**Third-party tools** like Fiddler, Charles Proxy, or browser extensions offer additional monitoring capabilities beyond native DevTools, particularly for mobile debugging or detailed traffic analysis.

#### Apollo Client Monitoring

Apollo Client DevTools extension provides specialized GraphQL monitoring beyond standard network tab capabilities. It displays queries, mutations, cache contents, and operation details in a GraphQL-aware interface.

**Cache inspection** through Apollo DevTools shows normalized cache structure, entity relationships, and cached field values. This complements network tab analysis by revealing why certain requests do or don't occur.

**Query tracking** displays all GraphQL operations with their variables, results, and cache interactions. This provides application-level context missing from raw network tab entries.

**Integration with Apollo Studio** enables production monitoring, performance tracking, and error reporting beyond local development tools. Network-level metrics combine with GraphQL-specific insights for comprehensive observability.

### Debugging Strategies

#### Fetch API Debugging Approaches

Network tab filtering by domain, type, or status isolates relevant requests. Searching by URL fragments quickly locates specific endpoints in high-traffic applications.

**Response inspection** through the Preview and Response tabs reveals data structure and content issues. Comparing expected versus actual response data identifies backend problems or integration misunderstandings.

**Timing analysis** identifies performance bottlenecks. Sorting by duration or examining waterfall patterns reveals slow endpoints, sequential dependencies, or connection issues.

**Header examination** diagnoses authentication failures, CORS issues, or caching problems. Comparing request and response headers against requirements identifies configuration mismatches.

#### Apollo Client Debugging Approaches

Network tab analysis combined with Apollo DevTools provides comprehensive debugging. Network tab shows HTTP-level details while Apollo DevTools reveals GraphQL-specific context.

**Cache debugging** through Apollo DevTools identifies stale data, missing cache updates, or incorrect normalization. Cross-referencing with network activity reveals whether problems stem from caching or server responses.

**Query analysis** examines whether queries request appropriate data. Comparing query definitions against response structures and component needs identifies over- or under-fetching.

**Error tracing** through response body `errors` arrays provides detailed error information. The `path` property indicates which specific field failed, while `extensions` may contain stack traces or additional debugging context.

---

## Context API Usage

### Request Destination Property

The `destination` property is a read-only attribute of the Request interface that describes the type of content being requested. It returns a string indicating what the fetch request is intended to retrieve, allowing user agents to make context-specific decisions about how to handle the request.

#### Available Destination Values

The destination property can return one of the following values:

- `""` (empty string) - Default value for destinations without specific values, including `fetch()`, `navigator.sendBeacon()`, `EventSource`, `XMLHttpRequest`, and `WebSocket`
- `"audio"` - Audio data, typically from `<audio>` elements
- `"audioworklet"` - Data for audio worklet, from `audioWorklet.addModule()`
- `"document"` - HTML or XML document from user-initiated top-level navigation
- `"embed"` - Embedded content from `<embed>` tags
- `"fencedframe"` - Content for fenced frames
- `"font"` - Font resources from CSS `@font-face`
- `"frame"` - Content from `<frame>` tags
- `"iframe"` - Content from `<iframe>` tags
- `"image"` - Images from `<img>`, SVG `<image>`, CSS `background-image`, `cursor`, `list-style-image`
- `"json"` - JSON resources
- `"manifest"` - Web app manifests
- `"object"` - Content from `<object>` tags
- `"paintworklet"` - Data for paint worklet
- `"report"` - Reporting endpoints
- `"script"` - JavaScript from `<script>` tags or `WorkerGlobalScope.importScripts()`
- `"serviceworker"` - Service worker scripts from `navigator.serviceWorker.register()`
- `"sharedworker"` - Shared worker scripts
- `"style"` - Stylesheets from `<link rel=stylesheet>` or CSS `@import`
- `"track"` - Text tracks from `<track>` tags
- `"video"` - Video data from `<video>` tags
- `"webidentity"` - Endpoints for verifying user identity (FedCM API)
- `"worker"` - Web worker scripts
- `"xslt"` - XSLT transforms

#### Browser Exposure and Service Worker Handling

The destination values are exposed through the `RequestDestination` enumeration in browsers, with two exceptions: `"serviceworker"` and `"webidentity"` are not reflected in the enumeration because fetches with these destinations bypass service workers entirely.

#### Usage in Code

```javascript
// Accessing destination from a Request object
const request = new Request('https://example.com/data');
console.log(request.destination); // "" (empty string for fetch())

// In a service worker, examining fetch event requests
self.addEventListener('fetch', (event) => {
  const destination = event.request.destination;
  
  if (destination === 'image') {
    // Handle image requests differently
    event.respondWith(
      caches.match(event.request)
        .then(response => response || fetch(event.request))
    );
  }
});
```

### Content Security Policy Integration

Request destinations play a crucial role in Content Security Policy (CSP) enforcement. The destination determines which CSP directive applies to a given request.

#### Destination-to-CSP Directive Mapping

Different destinations map to specific CSP directives:

- `"script"`, `"audioworklet"`, `"paintworklet"`, `"serviceworker"`, `"sharedworker"`, `"worker"` → `script-src`
- `"style"` → `style-src`
- `"image"` → `img-src`
- `"font"` → `font-src`
- `"audio"`, `"video"`, `"track"` → `media-src`
- `"manifest"` → `manifest-src`
- `"document"`, `"frame"`, `"iframe"` → `frame-src` or `child-src`
- `"object"`, `"embed"` → `object-src`
- Empty string (from `fetch()`) → `connect-src`

When a CSP policy doesn't define a specific directive, the check falls back to `default-src`.

#### CSP Challenges in Service Workers

Service workers introduce complexity to CSP enforcement. When a service worker intercepts a request using `fetch(event.request)`, the re-fetched request loses its original destination information, defaulting to an empty string. This causes CSP checks to use `connect-src` instead of the original directive.

**Example scenario:**

```javascript
// Page CSP: default-src 'self'; img-src *
// This allows images from any origin

self.addEventListener('fetch', (event) => {
  // event.request.destination is "image"
  
  // Creating new request loses destination context
  const newRequest = new Request(event.request);
  // newRequest.destination is "" (empty string)
  
  event.respondWith(fetch(newRequest));
  // This now uses connect-src instead of img-src for CSP
});
```

[Inference] Browsers perform multiple CSP checks in service worker scenarios:

1. Initial request checked against appropriate directive (e.g., `img-src` for images)
2. Service worker's fetch checked against `connect-src`
3. Response from service worker validated before returning to page

This multi-layered approach prevents CSP bypass, but requires service workers to have permissive `connect-src` policies for pass-through fetch operations.

### Script-Like Destinations

The specification defines certain destinations as "script-like" because they can execute code:

- `"audioworklet"`
- `"paintworklet"`
- `"script"`
- `"serviceworker"`
- `"sharedworker"`
- `"worker"`

**Note:** `"xslt"` can also cause script execution but isn't included in the script-like category as it may require different handling in some contexts.

#### MIME Type Validation for Script-Like Destinations

Requests with script-like destinations undergo additional validation. If the response's MIME type essence starts with `"audio/"`, `"image/"`, or `"video/"`, the request is blocked to prevent security issues.

### Subresource vs Non-Subresource Requests

Destinations are categorized into two types:

**Subresource requests** - Resources loaded as part of a page:

- `"audio"`, `"audioworklet"`, `"font"`, `"image"`, `"json"`, `"manifest"`, `"paintworklet"`, `"script"`, `"style"`, `"track"`, `"video"`, `"xslt"`, or empty string

**Non-subresource requests** - Navigation and worker contexts:

- `"document"`, `"embed"`, `"frame"`, `"iframe"`, `"object"`, `"report"`, `"serviceworker"`, `"sharedworker"`, `"worker"`

**Navigation requests** (subset of non-subresource):

- `"document"`, `"embed"`, `"frame"`, `"iframe"`, `"object"`

This categorization helps browsers apply different handling logic based on the nature of the request.

### Sec-Fetch-Dest Header

The browser automatically sends the `Sec-Fetch-Dest` HTTP header with requests, containing the destination value. This forbidden request header (cannot be modified by JavaScript) provides servers with context about how the resource will be used.

#### Server-Side Benefits

Servers can use `Sec-Fetch-Dest` to:

- Validate that requests match expected resource types
- Prevent resource type confusion attacks
- Apply appropriate security policies
- Optimize responses based on destination

**Example header values:**

```
Sec-Fetch-Dest: image
Sec-Fetch-Dest: script
Sec-Fetch-Dest: empty
Sec-Fetch-Dest: document
```

A cross-origin image request would include:

```
GET /photo.jpg HTTP/1.1
Host: cdn.example.com
Sec-Fetch-Dest: image
Sec-Fetch-Mode: no-cors
Sec-Fetch-Site: cross-site
```

Servers can verify the request is genuinely for an image and reject requests with mismatched destinations.

### Request Priority and Destination

Destinations influence request priority determination. According to the fetch specification, when a request's internal priority is null, the browser uses the request's priority, initiator, destination, and render-blocking properties to set an implementation-defined internal priority.

[Inference] Different destinations receive different default priorities:

- `"document"`, `"frame"`, `"iframe"` - Typically highest priority (navigation critical)
- `"script"`, `"style"`, `"font"` - High priority (render-blocking resources)
- `"image"` - Medium priority (visible content)
- `"audio"`, `"video"` - Variable priority (depends on visibility and playback state)
- Empty string from `fetch()` - Lower priority (developer-initiated)

The actual priority assignment is implementation-defined and may vary between browsers.

### Request Initiator

While not directly exposed to JavaScript, requests have an associated initiator property used internally for CSP and Mixed Content decisions. The initiator differs from destination in that it describes what triggered the request rather than what type of content is expected.

**Initiator values:**

- `""` (empty string) - Default
- `"download"` - Download operations
- `"imageset"` - Responsive image sets
- `"manifest"` - Web app manifest processing
- `"prefetch"` - Prefetch operations
- `"prerender"` - Prerender operations
- `"xslt"` - XSLT processing

[Inference] The initiator remains intentionally non-granular, serving primarily as a specification device rather than a detailed tracking mechanism. It helps distinguish between user-initiated actions and automatic browser behaviors when applying security policies.

### Deprecated Context Property

**Historical note:** The Request interface originally included a `context` property that has been completely replaced by `destination`. The `context` property was deprecated and removed from implementations.

```javascript
// Deprecated - no longer functional
const request = new Request('flowers.jpg');
const context = request.context; // Would return empty string

// Modern approach - use destination instead
const destination = request.destination;
```

The context property was relevant primarily in Service Worker API scenarios where workers needed to make decisions based on resource type. All functionality migrated to the more comprehensive `destination` property.

### Practical Service Worker Patterns

#### Destination-Based Caching Strategy

```javascript
self.addEventListener('fetch', (event) => {
  const { destination } = event.request;
  
  // Cache-first for images and fonts
  if (destination === 'image' || destination === 'font') {
    event.respondWith(
      caches.match(event.request)
        .then(cached => cached || fetch(event.request)
          .then(response => {
            const cache = caches.open('assets-v1');
            cache.then(c => c.put(event.request, response.clone()));
            return response;
          })
        )
    );
    return;
  }
  
  // Network-first for scripts and styles
  if (destination === 'script' || destination === 'style') {
    event.respondWith(
      fetch(event.request)
        .catch(() => caches.match(event.request))
    );
    return;
  }
  
  // Default: network only
  event.respondWith(fetch(event.request));
});
```

#### Cache-Only Policy for Specific Destinations

```javascript
self.addEventListener('fetch', (event) => {
  // Only serve scripts and styles from cache
  if (event.request.destination === 'script' || 
      event.request.destination === 'style') {
    event.respondWith(
      caches.match(event.request)
        .then(response => {
          if (response) return response;
          
          // Return error response instead of fetching
          return new Response('Resource not in cache', {
            status: 503,
            statusText: 'Service Unavailable'
          });
        })
    );
  }
});
```

#### Selective Request Blocking

```javascript
self.addEventListener('fetch', (event) => {
  const url = new URL(event.request.url);
  
  // Block third-party tracking scripts
  if (event.request.destination === 'script' && 
      url.origin !== location.origin &&
      url.hostname.includes('analytics')) {
    event.respondWith(
      new Response('', { status: 204 })
    );
    return;
  }
});
```

### Header Initialization Based on Destination

[Unverified] When browsers create requests for different HTML elements, they automatically initialize appropriate headers based on the destination:

**Image requests** (`destination: "image"`):

- `Accept: image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8`
- May include `Sec-CH-DPR`, `Sec-CH-Viewport-Width`, `Sec-CH-Width` client hints

**Script requests** (`destination: "script"`):

- `Accept: */*`
- May include CSP nonce headers

**Style requests** (`destination: "style"`):

- `Accept: text/css,*/*;q=0.1`

**Font requests** (`destination: "font"`):

- `Accept: */*`
- Often includes `Origin` header for CORS

**Fetch requests** (`destination: ""`):

- Headers depend entirely on developer specification
- No automatic Accept header initialization

This automatic header initialization explains why `<img>` tags successfully negotiate image formats while `fetch()` calls to the same URL might receive different responses without explicit Accept headers.

### Destination and Resource Hints

Resource hints like `<link rel="preload">` use the `as` attribute to specify destination:

```html
<link rel="preload" href="style.css" as="style">
<link rel="preload" href="font.woff2" as="font" crossorigin>
<link rel="preload" href="image.webp" as="image">
<link rel="prefetch" href="next-page.html" as="document">
```

The `as` attribute value maps directly to request destinations:

- `as="style"` → `destination: "style"`
- `as="script"` → `destination: "script"`
- `as="image"` → `destination: "image"`
- `as="font"` → `destination: "font"`
- `as="fetch"` → `destination: ""` (empty string)
- `as="document"` → `destination: "document"`

[Inference] This mapping ensures preloaded resources receive the same CSP treatment, priority, and header initialization as if they were loaded by their corresponding HTML elements. Without the correct `as` value, preloaded resources might violate CSP policies or receive incorrect response content.

### Cross-Origin Request Considerations

Destination affects CORS behavior and request mode:

**No-CORS requests** are restricted to specific destinations:

- Only `"audio"`, `"font"`, `"image"`, `"script"`, `"style"`, `"track"`, `"video"`, and empty string can use `mode: "no-cors"`
- Other destinations require CORS or same-origin mode

**CORS-safelisted methods and headers** apply differently based on destination:

- Simple requests (GET, HEAD, POST with specific content types) work across destinations
- Some destinations automatically trigger preflight requests due to headers

### Destination in Request Construction

When creating Request objects programmatically, the destination cannot be set directly through the constructor. It remains read-only and is determined by the context:

```javascript
// Destination is always "" for programmatic fetch
const req1 = new Request('https://example.com/api');
console.log(req1.destination); // ""

// Even when copying requests, destination becomes ""
const originalReq = new Request('https://example.com/image.jpg');
const copiedReq = new Request(originalReq);
console.log(copiedReq.destination); // ""

// Destination is set by browser for element-initiated requests
// (not accessible from JavaScript creation)
```

[Unverified] Some proposals have suggested adding a way to specify destination context for programmatic fetch calls to enable proper CSP handling and header initialization, but these remain unimplemented. The GitHub issue whatwg/fetch#43 discusses "initializing context/content specific fetch defaults" to address this limitation.

### Implementation Differences

#### Firefox Implementation

Firefox maps fetch destinations to internal `nsContentPolicyType` values:

- `TYPE_FETCH` - Default for programmatic fetch
- `TYPE_IMAGE`, `TYPE_INTERNAL_IMAGE`, `TYPE_INTERNAL_IMAGE_PRELOAD` - Images
- `TYPE_SCRIPT`, `TYPE_INTERNAL_SCRIPT`, `TYPE_INTERNAL_SCRIPT_PRELOAD` - Scripts
- `TYPE_STYLESHEET`, `TYPE_INTERNAL_STYLESHEET` - Styles
- `TYPE_FONT`, `TYPE_INTERNAL_FONT_PRELOAD` - Fonts
- `TYPE_MEDIA`, `TYPE_INTERNAL_AUDIO`, `TYPE_INTERNAL_VIDEO`, `TYPE_INTERNAL_TRACK` - Media

The internal types provide more granularity than the spec requires, distinguishing between external requests and internal browser operations. This granularity helps with features like preload hints and worker contexts.

#### Chrome Implementation

[Unverified] Chrome uses internal resource type enums rather than directly mapping destinations to priorities or CSP directives. The internal representation may differ from the exposed `destination` values while maintaining spec compliance.

### Debugging Destination Values

**In browser DevTools:**

1. Network panel → Select request → Headers tab → View `Sec-Fetch-Dest` header
2. Console: Examine Request objects directly

```javascript
// Log all fetch destinations
const originalFetch = window.fetch;
window.fetch = function(...args) {
  const request = new Request(...args);
  console.log('Fetch destination:', request.destination);
  return originalFetch.apply(this, args);
};
```

**In service workers:**

```javascript
self.addEventListener('fetch', (event) => {
  console.log({
    url: event.request.url,
    destination: event.request.destination,
    mode: event.request.mode,
    credentials: event.request.credentials
  });
});
```

### Security Implications

#### Resource Type Confusion Prevention

Destination values help prevent attacks where an attacker tricks a victim into loading a resource with incorrect expectations:

- A malicious script served with `Content-Type: image/png` would be blocked if requested with `destination: "image"`
- An HTML document served to an `<img>` tag cannot execute embedded scripts
- XSLT stylesheets must be requested with appropriate destination to execute

#### CSP Bypass Prevention

[Inference] Without destination information, CSP policies could be circumvented:

1. Attacker uploads malicious script as image to CDN
2. Page loads "image" via `fetch()` (empty destination → `connect-src`)
3. If `connect-src` allows CDN but `script-src` doesn't, attacker could potentially execute the script through `eval()` or similar

The destination property ensures proper CSP directive application at fetch time, combined with MIME type validation at execution time, creates defense in depth.

#### Service Worker Interception Transparency

The destination property allows service workers to maintain security properties of intercepted requests. A properly implemented service worker can preserve the original destination when re-fetching, though current APIs make this challenging due to Request constructor behavior.

### Future Considerations

**Potential enhancements discussed in specifications:**

1. **Destination context parameter** - Allow developers to explicitly specify destination for programmatic fetch calls to receive appropriate header initialization and CSP treatment
2. **Prefetch destination** - Dedicated destination for prefetched resources to enable proper CSP directive (prefetch-src)
3. **Request.destination preservation** - Maintaining destination when creating new Request from existing Request in service workers

These enhancements would address current limitations while maintaining backward compatibility. As of the knowledge cutoff date, these remain proposals rather than implemented features.

---

## Local State Synchronization

### Optimistic Updates

#### Immediate UI Updates

Apply state changes immediately before the fetch request completes to provide instant user feedback. Store the previous state to enable rollback if the request fails.

```javascript
const optimisticUpdate = async (item) => {
  const previousState = [...items];
  setItems(prev => [...prev, item]);
  
  try {
    const response = await fetch('/api/items', {
      method: 'POST',
      body: JSON.stringify(item)
    });
    const serverItem = await response.json();
    setItems(prev => prev.map(i => i.id === item.id ? serverItem : i));
  } catch (error) {
    setItems(previousState);
    showError('Update failed');
  }
};
```

The temporary client-side ID gets replaced with the server-assigned ID once the response returns. This pattern prevents flickering while maintaining data consistency.

#### Conflict Resolution

When multiple optimistic updates occur simultaneously, implement a queue system to process them sequentially. Track pending operations and their dependencies to avoid race conditions.

```javascript
const updateQueue = [];
let isProcessing = false;

const queueUpdate = async (operation) => {
  updateQueue.push(operation);
  if (!isProcessing) processQueue();
};

const processQueue = async () => {
  isProcessing = true;
  while (updateQueue.length > 0) {
    const operation = updateQueue.shift();
    await operation();
  }
  isProcessing = false;
};
```

#### Rollback Strategies

Implement granular rollback that only reverts the failed operation without affecting successful concurrent updates. Use version numbers or timestamps to identify which state changes belong to which operation.

```javascript
const withRollback = async (updateFn, rollbackFn) => {
  const checkpoint = createCheckpoint();
  updateFn();
  
  try {
    await fetch(/* ... */);
  } catch (error) {
    rollbackFn(checkpoint);
    throw error;
  }
};
```

### Polling Strategies

#### Fixed Interval Polling

Execute fetch requests at regular intervals to keep local state synchronized with the server. Clear intervals on component unmount to prevent memory leaks.

```javascript
useEffect(() => {
  const syncInterval = setInterval(async () => {
    const response = await fetch('/api/state');
    const serverState = await response.json();
    reconcileState(localState, serverState);
  }, 5000);
  
  return () => clearInterval(syncInterval);
}, []);
```

Choose polling intervals based on data volatility and user expectations. High-frequency updates require shorter intervals (1-5 seconds), while less critical data can poll every 30-60 seconds.

#### Adaptive Polling

Adjust polling frequency based on user activity, data freshness, or system load. Reduce polling when the tab is inactive or increase frequency after user interactions.

```javascript
let pollInterval = 10000;

document.addEventListener('visibilitychange', () => {
  pollInterval = document.hidden ? 60000 : 10000;
  restartPolling();
});

const restartPolling = () => {
  clearInterval(currentInterval);
  currentInterval = setInterval(poll, pollInterval);
};
```

Implement exponential backoff when the server returns errors to avoid overwhelming struggling services. Reset to normal intervals once successful responses resume.

#### Long Polling

Keep a fetch request open until the server has new data, then immediately start a new request. This pseudo-real-time approach reduces unnecessary requests compared to fixed polling.

```javascript
const longPoll = async () => {
  try {
    const response = await fetch('/api/updates?timeout=30');
    const updates = await response.json();
    applyUpdates(updates);
  } catch (error) {
    await new Promise(r => setTimeout(r, 5000));
  }
  longPoll(); // Immediately start next poll
};
```

### Synchronization Patterns

#### Last-Write-Wins

The most recent update overwrites previous values regardless of origin. Simple to implement but risks data loss when multiple clients update simultaneously.

```javascript
const sync = async (localData) => {
  const response = await fetch('/api/data', {
    method: 'PUT',
    body: JSON.stringify({
      ...localData,
      timestamp: Date.now()
    })
  });
};
```

#### Timestamp-Based Merging

Compare timestamps between local and server state to determine which changes to apply. Merge non-conflicting changes while flagging conflicts for user resolution.

```javascript
const merge = (local, server) => {
  const merged = {};
  for (const key in { ...local, ...server }) {
    if (!server[key]) merged[key] = local[key];
    else if (!local[key]) merged[key] = server[key];
    else if (local[key].timestamp > server[key].timestamp) {
      merged[key] = local[key];
    } else {
      merged[key] = server[key];
    }
  }
  return merged;
};
```

#### Version Vectors

Track update history across multiple clients using version vectors. Each client maintains counters for all participating clients to detect concurrent modifications and causal relationships.

```javascript
const versionVector = { clientA: 5, clientB: 3, clientC: 2 };

const updateVector = (clientId) => {
  versionVector[clientId] = (versionVector[clientId] || 0) + 1;
  return { ...versionVector };
};

const detectConflict = (v1, v2) => {
  const v1Newer = Object.keys(v1).some(k => v1[k] > (v2[k] || 0));
  const v2Newer = Object.keys(v2).some(k => v2[k] > (v1[k] || 0));
  return v1Newer && v2Newer; // Concurrent updates
};
```

#### Operational Transformation

Transform operations based on concurrent changes to maintain consistency. Each operation includes context about the state it was created against.

```javascript
const transform = (op1, op2) => {
  if (op1.position <= op2.position) {
    return op1;
  } else {
    return { ...op1, position: op1.position + op2.length };
  }
};
```

### Differential Synchronization

#### Delta Updates

Send only changed data rather than the entire state to reduce bandwidth and processing overhead. Calculate diffs client-side before fetch requests.

```javascript
const calculateDiff = (previous, current) => {
  const diff = {};
  for (const key in current) {
    if (JSON.stringify(previous[key]) !== JSON.stringify(current[key])) {
      diff[key] = current[key];
    }
  }
  return diff;
};

const syncDelta = async (previousState, currentState) => {
  const delta = calculateDiff(previousState, currentState);
  if (Object.keys(delta).length === 0) return;
  
  await fetch('/api/sync', {
    method: 'PATCH',
    body: JSON.stringify(delta)
  });
};
```

#### Patch Application

Apply incremental updates to local state when receiving server changes. Use JSON Patch (RFC 6902) format for standardized delta operations.

```javascript
const applyPatch = (state, patch) => {
  const newState = { ...state };
  for (const op of patch) {
    switch (op.op) {
      case 'add':
      case 'replace':
        setPath(newState, op.path, op.value);
        break;
      case 'remove':
        deletePath(newState, op.path);
        break;
    }
  }
  return newState;
};
```

### State Reconciliation

#### Three-Way Merge

Compare local state, server state, and the last synchronized common ancestor to intelligently merge changes from both sides.

```javascript
const threeWayMerge = (base, local, server) => {
  const merged = {};
  
  for (const key of new Set([...Object.keys(local), ...Object.keys(server)])) {
    if (local[key] === server[key]) {
      merged[key] = local[key];
    } else if (local[key] === base[key]) {
      merged[key] = server[key]; // Server changed
    } else if (server[key] === base[key]) {
      merged[key] = local[key]; // Local changed
    } else {
      merged[key] = resolveConflict(base[key], local[key], server[key]);
    }
  }
  
  return merged;
};
```

#### Conflict Detection

Identify concurrent modifications that cannot be automatically merged. Flag conflicts for user review or apply predefined resolution policies.

```javascript
const detectConflicts = (localChanges, serverChanges) => {
  const conflicts = [];
  
  for (const key in localChanges) {
    if (key in serverChanges) {
      if (JSON.stringify(localChanges[key]) !== JSON.stringify(serverChanges[key])) {
        conflicts.push({
          field: key,
          local: localChanges[key],
          server: serverChanges[key]
        });
      }
    }
  }
  
  return conflicts;
};
```

#### Manual Conflict Resolution

Present conflicting changes to users through UI components that allow choosing between versions or manually merging values.

```javascript
const resolveManually = async (conflicts) => {
  const resolutions = await showConflictUI(conflicts);
  
  const resolved = conflicts.map((conflict, i) => ({
    field: conflict.field,
    value: resolutions[i]
  }));
  
  await fetch('/api/resolve', {
    method: 'POST',
    body: JSON.stringify(resolved)
  });
};
```

### Queue Management

#### Offline Queue

Store failed fetch requests in a queue for retry when connectivity returns. Persist the queue to survive page reloads or crashes.

```javascript
class SyncQueue {
  constructor() {
    this.queue = this.loadQueue();
  }
  
  async add(request) {
    this.queue.push({
      url: request.url,
      options: request.options,
      timestamp: Date.now(),
      retries: 0
    });
    this.saveQueue();
    this.processQueue();
  }
  
  async processQueue() {
    while (this.queue.length > 0 && navigator.onLine) {
      const item = this.queue[0];
      try {
        await fetch(item.url, item.options);
        this.queue.shift();
        this.saveQueue();
      } catch (error) {
        item.retries++;
        if (item.retries > 5) {
          this.queue.shift(); // Give up
        }
        break;
      }
    }
  }
}
```

#### Priority Queuing

Process high-priority operations before low-priority ones. Critical updates execute immediately while background synchronization can wait.

```javascript
const priorityQueue = {
  high: [],
  normal: [],
  low: []
};

const enqueue = (operation, priority = 'normal') => {
  priorityQueue[priority].push(operation);
  processNext();
};

const processNext = async () => {
  const operation = 
    priorityQueue.high.shift() ||
    priorityQueue.normal.shift() ||
    priorityQueue.low.shift();
  
  if (operation) {
    await operation();
    processNext();
  }
};
```

#### Deduplication

Merge or eliminate redundant operations in the queue before execution. Multiple updates to the same resource can often be consolidated into a single request.

```javascript
const deduplicate = (queue) => {
  const seen = new Map();
  return queue.filter(op => {
    const key = `${op.method}-${op.url}`;
    if (seen.has(key)) {
      seen.get(key).data = { ...seen.get(key).data, ...op.data };
      return false;
    }
    seen.set(key, op);
    return true;
  });
};
```

### Event-Driven Synchronization

#### State Change Listeners

Trigger synchronization automatically when local state changes. Debounce rapid changes to avoid excessive fetch requests.

```javascript
let syncTimeout;

const onChange = (newState) => {
  clearTimeout(syncTimeout);
  syncTimeout = setTimeout(() => {
    syncToServer(newState);
  }, 1000);
};

const syncToServer = async (state) => {
  await fetch('/api/state', {
    method: 'PUT',
    body: JSON.stringify(state)
  });
};
```

#### Server-Sent Events Integration

Combine fetch with SSE to receive server-initiated updates. Fetch handles client-to-server synchronization while SSE handles server-to-client.

```javascript
const eventSource = new EventSource('/api/events');

eventSource.onmessage = (event) => {
  const serverUpdate = JSON.parse(event.data);
  mergeServerState(serverUpdate);
};

const sendUpdate = async (data) => {
  await fetch('/api/update', {
    method: 'POST',
    body: JSON.stringify(data)
  });
};
```

#### WebSocket Fallback

Use WebSocket for bidirectional real-time sync, falling back to fetch polling when WebSocket connections fail or aren't supported.

```javascript
let ws;
let pollInterval;

const connectWebSocket = () => {
  ws = new WebSocket('wss://api.example.com/sync');
  
  ws.onmessage = (event) => {
    applyUpdate(JSON.parse(event.data));
  };
  
  ws.onerror = () => {
    fallbackToPolling();
  };
};

const fallbackToPolling = () => {
  pollInterval = setInterval(async () => {
    const response = await fetch('/api/state');
    const state = await response.json();
    applyUpdate(state);
  }, 5000);
};
```

### Synchronization State Management

#### Sync Status Tracking

Maintain metadata about synchronization state including last sync time, pending operations, and error conditions.

```javascript
const syncState = {
  lastSync: null,
  pending: [],
  syncing: false,
  errors: []
};

const updateSyncStatus = (status) => {
  Object.assign(syncState, status);
  notifyStatusListeners(syncState);
};
```

#### Progress Indication

Display synchronization progress to users, especially for large datasets or slow connections. Track bytes transferred and estimated completion time.

```javascript
const syncWithProgress = async (data) => {
  const chunks = chunkData(data, 1000);
  
  for (let i = 0; i < chunks.length; i++) {
    await fetch('/api/sync', {
      method: 'POST',
      body: JSON.stringify(chunks[i])
    });
    
    updateProgress({
      current: i + 1,
      total: chunks.length,
      percentage: ((i + 1) / chunks.length) * 100
    });
  }
};
```

#### Error Recovery

Implement automatic retry with exponential backoff for transient failures. Distinguish between retryable errors (network issues) and permanent failures (validation errors).

```javascript
const fetchWithRetry = async (url, options, maxRetries = 3) => {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      if (!response.ok && response.status >= 500) {
        throw new Error('Server error');
      }
      return response;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(r => setTimeout(r, Math.pow(2, i) * 1000));
    }
  }
};
```

### Batch Synchronization

#### Request Batching

Accumulate multiple state changes and send them in a single fetch request to reduce network overhead.

```javascript
let batchQueue = [];
let batchTimeout;

const addToBatch = (change) => {
  batchQueue.push(change);
  
  clearTimeout(batchTimeout);
  batchTimeout = setTimeout(flushBatch, 100);
  
  if (batchQueue.length >= 50) {
    flushBatch();
  }
};

const flushBatch = async () => {
  if (batchQueue.length === 0) return;
  
  const batch = [...batchQueue];
  batchQueue = [];
  
  await fetch('/api/batch', {
    method: 'POST',
    body: JSON.stringify(batch)
  });
};
```

#### Response Aggregation

Process batched server responses and apply multiple state updates atomically to maintain consistency.

```javascript
const processBatchResponse = (responses) => {
  setState(prevState => {
    let newState = { ...prevState };
    
    for (const response of responses) {
      newState = applyUpdate(newState, response);
    }
    
    return newState;
  });
};
```

### Consistency Guarantees

#### Read-Your-Writes

Ensure users see their own changes immediately by updating local state optimistically, even if server confirmation is pending.

```javascript
const writeWithLocalRead = async (data) => {
  const tempId = generateTempId();
  updateLocalState({ ...data, id: tempId });
  
  const response = await fetch('/api/items', {
    method: 'POST',
    body: JSON.stringify(data)
  });
  
  const serverData = await response.json();
  updateLocalState(serverData, tempId);
};
```

#### Monotonic Reads

Prevent users from seeing older versions of data after viewing newer versions by tracking sequence numbers or timestamps.

```javascript
let lastSeenVersion = 0;

const applyUpdate = (update) => {
  if (update.version > lastSeenVersion) {
    setState(update.data);
    lastSeenVersion = update.version;
  }
};
```

#### Causal Consistency

Maintain cause-and-effect relationships between operations. Dependent updates wait for their prerequisites to complete.

```javascript
const dependencies = new Map();

const executeWithDependencies = async (operation) => {
  const deps = dependencies.get(operation.id) || [];
  await Promise.all(deps.map(id => operations.get(id)));
  
  await fetch(operation.url, operation.options);
  operations.set(operation.id, Promise.resolve());
};
```

---

## Optimistic Updates

### Basic Optimistic Update Pattern

#### Simple Implementation

```javascript
async function updateItemOptimistically(itemId, newData) {
  // Store original state
  const originalItem = getItem(itemId);
  
  // Update UI immediately
  updateUI(itemId, newData);
  
  try {
    // Send request to server
    const response = await fetch(`/api/items/${itemId}`, {
      method: 'PUT',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(newData)
    });
    
    if (!response.ok) {
      throw new Error('Update failed');
    }
    
    // Optionally sync with server response
    const serverData = await response.json();
    updateUI(itemId, serverData);
    
  } catch (error) {
    // Rollback on failure
    updateUI(itemId, originalItem);
    showError('Update failed. Changes reverted.');
  }
}
```

#### With State Management

```javascript
class OptimisticStateManager {
  constructor() {
    this.state = {};
    this.pendingUpdates = new Map();
  }
  
  getItem(id) {
    return this.state[id];
  }
  
  async updateItem(id, updates) {
    const original = { ...this.state[id] };
    const optimistic = { ...original, ...updates };
    
    // Apply optimistic update
    this.state[id] = optimistic;
    this.notifyListeners(id);
    
    // Track pending update
    const updateId = Date.now();
    this.pendingUpdates.set(updateId, { id, original });
    
    try {
      const response = await fetch(`/api/items/${id}`, {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(updates)
      });
      
      if (!response.ok) throw new Error('Update failed');
      
      const serverData = await response.json();
      this.state[id] = serverData;
      this.notifyListeners(id);
      
    } catch (error) {
      // Rollback
      this.state[id] = original;
      this.notifyListeners(id);
      throw error;
      
    } finally {
      this.pendingUpdates.delete(updateId);
    }
  }
  
  notifyListeners(id) {
    // Trigger UI updates
  }
}
```

### Handling Multiple Concurrent Updates

#### Queue-Based Approach

```javascript
class UpdateQueue {
  constructor() {
    this.queues = new Map(); // resourceId -> array of updates
  }
  
  async enqueue(resourceId, updateFn) {
    if (!this.queues.has(resourceId)) {
      this.queues.set(resourceId, []);
    }
    
    const queue = this.queues.get(resourceId);
    
    return new Promise((resolve, reject) => {
      queue.push({ updateFn, resolve, reject });
      
      if (queue.length === 1) {
        this.processQueue(resourceId);
      }
    });
  }
  
  async processQueue(resourceId) {
    const queue = this.queues.get(resourceId);
    
    while (queue.length > 0) {
      const { updateFn, resolve, reject } = queue[0];
      
      try {
        const result = await updateFn();
        resolve(result);
      } catch (error) {
        reject(error);
      }
      
      queue.shift();
    }
    
    this.queues.delete(resourceId);
  }
}

// Usage
const updateQueue = new UpdateQueue();

async function optimisticUpdate(itemId, data) {
  return updateQueue.enqueue(itemId, async () => {
    const original = getItem(itemId);
    updateUI(itemId, data);
    
    try {
      const response = await fetch(`/api/items/${itemId}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(data)
      });
      
      if (!response.ok) throw new Error('Failed');
      return await response.json();
      
    } catch (error) {
      updateUI(itemId, original);
      throw error;
    }
  });
}
```

#### Conflict Resolution

```javascript
class ConflictResolver {
  async updateWithConflictResolution(itemId, localChanges) {
    const originalVersion = getItemVersion(itemId);
    const original = getItem(itemId);
    
    // Apply optimistic update
    const optimistic = { ...original, ...localChanges };
    updateUI(itemId, optimistic);
    
    try {
      const response = await fetch(`/api/items/${itemId}`, {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
          'If-Match': originalVersion // ETag-based versioning
        },
        body: JSON.stringify(localChanges)
      });
      
      if (response.status === 409) {
        // Conflict detected
        const serverData = await response.json();
        const resolved = await this.resolveConflict(original, localChanges, serverData);
        
        updateUI(itemId, resolved);
        
        // Retry with resolved data
        return this.updateWithConflictResolution(itemId, resolved);
      }
      
      if (!response.ok) throw new Error('Update failed');
      
      const serverData = await response.json();
      updateUI(itemId, serverData);
      return serverData;
      
    } catch (error) {
      // Rollback
      updateUI(itemId, original);
      throw error;
    }
  }
  
  async resolveConflict(original, local, server) {
    // Strategy 1: Server wins
    return server;
    
    // Strategy 2: Local wins (force update)
    // return local;
    
    // Strategy 3: Field-level merge
    // const merged = { ...server };
    // for (const [key, value] of Object.entries(local)) {
    //   if (original[key] === server[key]) {
    //     merged[key] = value;
    //   }
    // }
    // return merged;
    
    // Strategy 4: Prompt user
    // return await promptUserForResolution(original, local, server);
  }
}
```

### Optimistic Creation

#### Creating New Items

```javascript
async function optimisticCreate(newItem) {
  // Generate temporary ID
  const tempId = `temp-${Date.now()}`;
  const optimisticItem = {
    id: tempId,
    ...newItem,
    _pending: true
  };
  
  // Add to UI immediately
  addToUI(optimisticItem);
  
  try {
    const response = await fetch('/api/items', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(newItem)
    });
    
    if (!response.ok) throw new Error('Creation failed');
    
    const serverItem = await response.json();
    
    // Replace temporary item with server version
    replaceInUI(tempId, serverItem);
    
    return serverItem;
    
  } catch (error) {
    // Remove optimistic item
    removeFromUI(tempId);
    showError('Failed to create item');
    throw error;
  }
}
```

#### Handling Dependent Creates

```javascript
class DependentCreateManager {
  constructor() {
    this.tempIdMap = new Map(); // temp ID -> server ID
  }
  
  async createWithDependencies(item, dependencies = []) {
    // Wait for dependencies to resolve
    const resolvedDeps = await Promise.all(
      dependencies.map(dep => this.resolveTempId(dep))
    );
    
    // Replace temp IDs in item
    const itemWithResolvedDeps = this.replaceTempIds(item, resolvedDeps);
    
    const tempId = `temp-${Date.now()}`;
    const optimisticItem = { id: tempId, ...itemWithResolvedDeps };
    
    addToUI(optimisticItem);
    
    const promise = (async () => {
      try {
        const response = await fetch('/api/items', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(itemWithResolvedDeps)
        });
        
        if (!response.ok) throw new Error('Creation failed');
        
        const serverItem = await response.json();
        this.tempIdMap.set(tempId, serverItem.id);
        
        replaceInUI(tempId, serverItem);
        return serverItem;
        
      } catch (error) {
        removeFromUI(tempId);
        throw error;
      }
    })();
    
    // Store promise for dependency resolution
    this.tempIdMap.set(tempId, promise);
    
    return promise;
  }
  
  async resolveTempId(id) {
    if (!id.startsWith('temp-')) return id;
    
    const value = this.tempIdMap.get(id);
    
    if (value instanceof Promise) {
      const resolved = await value;
      return resolved.id;
    }
    
    return value || id;
  }
  
  replaceTempIds(item, resolvedDeps) {
    // Replace temp IDs in item properties
    const result = { ...item };
    
    for (const [key, value] of Object.entries(result)) {
      if (typeof value === 'string' && value.startsWith('temp-')) {
        result[key] = this.tempIdMap.get(value) || value;
      }
    }
    
    return result;
  }
}
```

### Optimistic Deletion

#### Safe Delete with Undo

```javascript
class OptimisticDelete {
  constructor() {
    this.deletedItems = new Map();
    this.undoTimeouts = new Map();
  }
  
  async deleteItem(itemId, { undoTimeout = 5000 } = {}) {
    const item = getItem(itemId);
    
    // Mark as deleted in UI (fade out, strikethrough, etc.)
    markAsDeleted(itemId);
    
    // Store for potential undo
    this.deletedItems.set(itemId, item);
    
    // Set up undo timeout
    const timeoutId = setTimeout(() => {
      this.commitDelete(itemId);
    }, undoTimeout);
    
    this.undoTimeouts.set(itemId, timeoutId);
    
    // Show undo notification
    showUndoNotification(itemId, undoTimeout);
  }
  
  async commitDelete(itemId) {
    const item = this.deletedItems.get(itemId);
    if (!item) return;
    
    try {
      const response = await fetch(`/api/items/${itemId}`, {
        method: 'DELETE'
      });
      
      if (!response.ok) throw new Error('Delete failed');
      
      // Remove from UI permanently
      removeFromUI(itemId);
      
    } catch (error) {
      // Restore item on failure
      this.undoDelete(itemId);
      showError('Delete failed. Item restored.');
    } finally {
      this.deletedItems.delete(itemId);
      this.undoTimeouts.delete(itemId);
    }
  }
  
  undoDelete(itemId) {
    // Clear timeout
    const timeoutId = this.undoTimeouts.get(itemId);
    if (timeoutId) {
      clearTimeout(timeoutId);
      this.undoTimeouts.delete(itemId);
    }
    
    // Restore item
    const item = this.deletedItems.get(itemId);
    if (item) {
      restoreInUI(itemId, item);
      this.deletedItems.delete(itemId);
    }
  }
}
```

### Batch Optimistic Updates

#### Batching Multiple Changes

```javascript
class BatchOptimisticUpdater {
  constructor() {
    this.batch = [];
    this.batchTimer = null;
    this.flushDelay = 300;
  }
  
  scheduleUpdate(itemId, updates) {
    // Apply optimistic update immediately
    const original = getItem(itemId);
    const optimistic = { ...original, ...updates };
    updateUI(itemId, optimistic);
    
    // Add to batch
    this.batch.push({
      itemId,
      updates,
      original,
      optimistic
    });
    
    // Schedule flush
    clearTimeout(this.batchTimer);
    this.batchTimer = setTimeout(() => this.flush(), this.flushDelay);
  }
  
  async flush() {
    if (this.batch.length === 0) return;
    
    const currentBatch = [...this.batch];
    this.batch = [];
    
    try {
      const response = await fetch('/api/items/batch', {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          updates: currentBatch.map(({ itemId, updates }) => ({
            id: itemId,
            data: updates
          }))
        })
      });
      
      if (!response.ok) throw new Error('Batch update failed');
      
      const results = await response.json();
      
      // Update with server data
      results.forEach(serverItem => {
        updateUI(serverItem.id, serverItem);
      });
      
    } catch (error) {
      // Rollback all changes in batch
      currentBatch.forEach(({ itemId, original }) => {
        updateUI(itemId, original);
      });
      
      showError('Batch update failed. Changes reverted.');
    }
  }
  
  async forceFlush() {
    clearTimeout(this.batchTimer);
    await this.flush();
  }
}
```

### Optimistic UI Indicators

#### Visual Feedback Patterns

```javascript
class OptimisticUIManager {
  constructor() {
    this.pendingOperations = new Map();
  }
  
  async performOptimisticUpdate(itemId, updates, operation) {
    // Track operation
    this.pendingOperations.set(itemId, {
      type: operation,
      startTime: Date.now()
    });
    
    // Update UI with pending indicator
    this.updatePendingState(itemId, true);
    
    const original = getItem(itemId);
    updateUI(itemId, { ...original, ...updates });
    
    try {
      const response = await fetch(`/api/items/${itemId}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(updates)
      });
      
      if (!response.ok) throw new Error('Update failed');
      
      const serverData = await response.json();
      updateUI(itemId, serverData);
      
      // Success feedback
      this.showSuccessFeedback(itemId);
      
    } catch (error) {
      updateUI(itemId, original);
      this.showErrorFeedback(itemId);
      throw error;
      
    } finally {
      this.pendingOperations.delete(itemId);
      this.updatePendingState(itemId, false);
    }
  }
  
  updatePendingState(itemId, isPending) {
    const element = document.querySelector(`[data-item-id="${itemId}"]`);
    if (!element) return;
    
    if (isPending) {
      element.classList.add('optimistic-pending');
      element.setAttribute('aria-busy', 'true');
    } else {
      element.classList.remove('optimistic-pending');
      element.removeAttribute('aria-busy');
    }
  }
  
  showSuccessFeedback(itemId) {
    const element = document.querySelector(`[data-item-id="${itemId}"]`);
    if (!element) return;
    
    element.classList.add('optimistic-success');
    setTimeout(() => {
      element.classList.remove('optimistic-success');
    }, 1000);
  }
  
  showErrorFeedback(itemId) {
    const element = document.querySelector(`[data-item-id="${itemId}"]`);
    if (!element) return;
    
    element.classList.add('optimistic-error');
    setTimeout(() => {
      element.classList.remove('optimistic-error');
    }, 2000);
  }
}
```

### Offline Queue with Optimistic Updates

#### Persisting Pending Operations

```javascript
class OfflineOptimisticQueue {
  constructor() {
    this.queue = this.loadQueue();
    this.processing = false;
    
    window.addEventListener('online', () => this.processQueue());
  }
  
  loadQueue() {
    const stored = localStorage.getItem('optimistic-queue');
    return stored ? JSON.parse(stored) : [];
  }
  
  saveQueue() {
    localStorage.setItem('optimistic-queue', JSON.stringify(this.queue));
  }
  
  async enqueue(operation) {
    const queueItem = {
      id: `op-${Date.now()}`,
      operation,
      timestamp: Date.now(),
      retries: 0
    };
    
    this.queue.push(queueItem);
    this.saveQueue();
    
    // Apply optimistic update immediately
    this.applyOptimisticChange(operation);
    
    if (navigator.onLine) {
      this.processQueue();
    }
    
    return queueItem.id;
  }
  
  async processQueue() {
    if (this.processing || this.queue.length === 0) return;
    
    this.processing = true;
    
    while (this.queue.length > 0 && navigator.onLine) {
      const item = this.queue[0];
      
      try {
        await this.executeOperation(item.operation);
        this.queue.shift();
        this.saveQueue();
        
      } catch (error) {
        item.retries++;
        
        if (item.retries >= 3) {
          // Max retries reached
          this.queue.shift();
          this.rollbackOperation(item.operation);
          showError('Operation failed after retries');
        } else {
          // Retry later
          await new Promise(resolve => setTimeout(resolve, 1000 * item.retries));
        }
        
        this.saveQueue();
      }
    }
    
    this.processing = false;
  }
  
  async executeOperation(operation) {
    const { type, itemId, data } = operation;
    
    const response = await fetch(`/api/items/${itemId}`, {
      method: type === 'update' ? 'PUT' : type === 'create' ? 'POST' : 'DELETE',
      headers: { 'Content-Type': 'application/json' },
      body: type !== 'delete' ? JSON.stringify(data) : undefined
    });
    
    if (!response.ok) throw new Error('Operation failed');
    
    return await response.json();
  }
  
  applyOptimisticChange(operation) {
    // Apply change to UI
    switch (operation.type) {
      case 'update':
        updateUI(operation.itemId, operation.data);
        break;
      case 'create':
        addToUI(operation.data);
        break;
      case 'delete':
        markAsDeleted(operation.itemId);
        break;
    }
  }
  
  rollbackOperation(operation) {
    // Revert optimistic change
    switch (operation.type) {
      case 'update':
        updateUI(operation.itemId, operation.original);
        break;
      case 'create':
        removeFromUI(operation.tempId);
        break;
      case 'delete':
        restoreInUI(operation.itemId, operation.original);
        break;
    }
  }
}
```

### Optimistic Reordering

#### Drag and Drop with Optimistic Updates

```javascript
class OptimisticReorder {
  async reorderItems(itemId, newPosition, list) {
    const oldPosition = list.findIndex(item => item.id === itemId);
    const oldList = [...list];
    
    // Optimistic reorder
    const newList = [...list];
    const [item] = newList.splice(oldPosition, 1);
    newList.splice(newPosition, 0, item);
    
    // Update UI immediately
    updateListUI(newList);
    
    try {
      const response = await fetch(`/api/items/${itemId}/reorder`, {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          position: newPosition,
          adjacentIds: {
            before: newList[newPosition - 1]?.id,
            after: newList[newPosition + 1]?.id
          }
        })
      });
      
      if (!response.ok) throw new Error('Reorder failed');
      
      // Optionally sync with server order
      const serverList = await response.json();
      updateListUI(serverList);
      
    } catch (error) {
      // Revert to old order
      updateListUI(oldList);
      showError('Reorder failed. Changes reverted.');
    }
  }
}
```

### Transaction-like Updates

#### Atomic Multi-Resource Updates

```javascript
class OptimisticTransaction {
  constructor() {
    this.activeTransactions = new Map();
  }
  
  async executeTransaction(transactionId, operations) {
    const rollbackData = [];
    
    // Apply all optimistic changes
    for (const op of operations) {
      const original = this.applyOptimisticOp(op);
      rollbackData.push({ op, original });
    }
    
    this.activeTransactions.set(transactionId, rollbackData);
    
    try {
      const response = await fetch('/api/transactions', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ operations })
      });
      
      if (!response.ok) throw new Error('Transaction failed');
      
      const results = await response.json();
      
      // Update with server data
      results.forEach(result => {
        updateUI(result.id, result.data);
      });
      
    } catch (error) {
      // Rollback entire transaction
      this.rollbackTransaction(transactionId);
      showError('Transaction failed. All changes reverted.');
      throw error;
      
    } finally {
      this.activeTransactions.delete(transactionId);
    }
  }
  
  applyOptimisticOp(op) {
    const { type, resourceId, data } = op;
    const original = getItem(resourceId);
    
    switch (type) {
      case 'update':
        updateUI(resourceId, { ...original, ...data });
        break;
      case 'create':
        addToUI(data);
        break;
      case 'delete':
        markAsDeleted(resourceId);
        break;
    }
    
    return original;
  }
  
  rollbackTransaction(transactionId) {
    const rollbackData = this.activeTransactions.get(transactionId);
    if (!rollbackData) return;
    
    // Rollback in reverse order
    for (let i = rollbackData.length - 1; i >= 0; i--) {
      const { op, original } = rollbackData[i];
      
      switch (op.type) {
        case 'update':
          updateUI(op.resourceId, original);
          break;
        case 'create':
          removeFromUI(op.data.id);
          break;
        case 'delete':
          restoreInUI(op.resourceId, original);
          break;
      }
    }
  }
}
```

---

# Framework Integration

## React Hooks Patterns for Fetch API Integration

### Basic Data Fetching

#### useEffect for Single Request

```javascript
function UserProfile({ userId }) {
  const [user, setUser] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    setLoading(true);
    fetch(`/api/users/${userId}`)
      .then(res => {
        if (!res.ok) throw new Error('Failed to fetch');
        return res.json();
      })
      .then(data => {
        setUser(data);
        setError(null);
      })
      .catch(err => setError(err.message))
      .finally(() => setLoading(false));
  }, [userId]);

  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error}</div>;
  return <div>{user?.name}</div>;
}
```

#### AbortController for Cleanup

```javascript
useEffect(() => {
  const controller = new AbortController();
  
  fetch('/api/data', { signal: controller.signal })
    .then(res => res.json())
    .then(setData)
    .catch(err => {
      if (err.name !== 'AbortError') {
        setError(err.message);
      }
    });

  return () => controller.abort();
}, []);
```

#### Async/Await Pattern

```javascript
useEffect(() => {
  const controller = new AbortController();
  
  async function fetchData() {
    try {
      setLoading(true);
      const res = await fetch('/api/data', { signal: controller.signal });
      if (!res.ok) throw new Error(`HTTP error: ${res.status}`);
      const json = await res.json();
      setData(json);
    } catch (err) {
      if (err.name !== 'AbortError') {
        setError(err.message);
      }
    } finally {
      setLoading(false);
    }
  }
  
  fetchData();
  return () => controller.abort();
}, []);
```

### Custom Hooks

#### useFetch Hook

```javascript
function useFetch(url, options = {}) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setLoading(true);
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) {
          throw new Error(`HTTP ${res.status}: ${res.statusText}`);
        }
        
        const json = await res.json();
        setData(json);
        setError(null);
      } catch (err) {
        if (err.name !== 'AbortError') {
          setError(err);
        }
      } finally {
        if (!controller.signal.aborted) {
          setLoading(false);
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, JSON.stringify(options)]);

  return { data, loading, error };
}
```

#### useFetch with Refetch

```javascript
function useFetch(url, options = {}) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  const [trigger, setTrigger] = useState(0);

  const refetch = useCallback(() => {
    setTrigger(prev => prev + 1);
  }, []);

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setLoading(true);
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const json = await res.json();
        setData(json);
        setError(null);
      } catch (err) {
        if (err.name !== 'AbortError') {
          setError(err);
        }
      } finally {
        if (!controller.signal.aborted) {
          setLoading(false);
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, trigger, JSON.stringify(options)]);

  return { data, loading, error, refetch };
}
```

#### useAsync for Manual Triggering

```javascript
function useAsync(asyncFunction) {
  const [state, setState] = useState({
    data: null,
    loading: false,
    error: null
  });

  const execute = useCallback(async (...params) => {
    setState({ data: null, loading: true, error: null });
    
    try {
      const data = await asyncFunction(...params);
      setState({ data, loading: false, error: null });
      return data;
    } catch (error) {
      setState({ data: null, loading: false, error });
      throw error;
    }
  }, [asyncFunction]);

  return { ...state, execute };
}

// Usage
function CreateUser() {
  const createUserFn = async (userData) => {
    const res = await fetch('/api/users', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(userData)
    });
    if (!res.ok) throw new Error('Failed to create user');
    return res.json();
  };

  const { data, loading, error, execute } = useAsync(createUserFn);

  const handleSubmit = (formData) => {
    execute(formData);
  };

  return (/* form UI */);
}
```

### State Management Patterns

#### useReducer for Complex State

```javascript
const fetchReducer = (state, action) => {
  switch (action.type) {
    case 'FETCH_INIT':
      return { ...state, loading: true, error: null };
    case 'FETCH_SUCCESS':
      return { 
        ...state, 
        loading: false, 
        error: null, 
        data: action.payload 
      };
    case 'FETCH_FAILURE':
      return { 
        ...state, 
        loading: false, 
        error: action.payload 
      };
    default:
      throw new Error(`Unhandled action: ${action.type}`);
  }
};

function useFetchReducer(url, options = {}) {
  const [state, dispatch] = useReducer(fetchReducer, {
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchData() {
      dispatch({ type: 'FETCH_INIT' });
      
      try {
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        dispatch({ type: 'FETCH_SUCCESS', payload: data });
      } catch (err) {
        if (err.name !== 'AbortError') {
          dispatch({ type: 'FETCH_FAILURE', payload: err.message });
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, JSON.stringify(options)]);

  return state;
}
```

#### Pagination State

```javascript
function usePaginatedFetch(baseUrl, pageSize = 10) {
  const [state, setState] = useState({
    data: [],
    page: 1,
    hasMore: true,
    loading: false,
    error: null
  });

  const fetchPage = useCallback(async (page) => {
    setState(prev => ({ ...prev, loading: true, error: null }));
    
    try {
      const res = await fetch(`${baseUrl}?page=${page}&limit=${pageSize}`);
      if (!res.ok) throw new Error(`HTTP ${res.status}`);
      
      const newData = await res.json();
      
      setState(prev => ({
        ...prev,
        data: page === 1 ? newData : [...prev.data, ...newData],
        page,
        hasMore: newData.length === pageSize,
        loading: false
      }));
    } catch (err) {
      setState(prev => ({ ...prev, error: err.message, loading: false }));
    }
  }, [baseUrl, pageSize]);

  const loadMore = useCallback(() => {
    if (!state.loading && state.hasMore) {
      fetchPage(state.page + 1);
    }
  }, [state.loading, state.hasMore, state.page, fetchPage]);

  const reset = useCallback(() => {
    fetchPage(1);
  }, [fetchPage]);

  useEffect(() => {
    fetchPage(1);
  }, [fetchPage]);

  return { ...state, loadMore, reset };
}
```

### Caching Patterns

#### Simple Cache with useRef

```javascript
function useFetchWithCache(url, options = {}) {
  const cache = useRef({});
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const cacheKey = `${url}-${JSON.stringify(options)}`;
    
    if (cache.current[cacheKey]) {
      setState({
        data: cache.current[cacheKey],
        loading: false,
        error: null
      });
      return;
    }

    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        cache.current[cacheKey] = data;
        
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState({ data: null, loading: false, error: err.message });
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, JSON.stringify(options)]);

  return state;
}
```

#### Time-based Cache Invalidation

```javascript
function useFetchWithTTL(url, ttl = 60000, options = {}) {
  const cache = useRef(new Map());
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const cacheKey = `${url}-${JSON.stringify(options)}`;
    const cached = cache.current.get(cacheKey);
    
    if (cached && Date.now() - cached.timestamp < ttl) {
      setState({
        data: cached.data,
        loading: false,
        error: null
      });
      return;
    }

    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        
        cache.current.set(cacheKey, {
          data,
          timestamp: Date.now()
        });
        
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState({ data: null, loading: false, error: err.message });
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, ttl, JSON.stringify(options)]);

  return state;
}
```

### Optimistic Updates

#### Mutation with Rollback

```javascript
function useOptimisticMutation(url, options = {}) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const previousData = useRef(null);

  const mutate = useCallback(async (newData, optimisticData) => {
    previousData.current = data;
    setData(optimisticData);
    setLoading(true);
    setError(null);

    try {
      const res = await fetch(url, {
        ...options,
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(newData)
      });

      if (!res.ok) throw new Error(`HTTP ${res.status}`);

      const result = await res.json();
      setData(result);
      return result;
    } catch (err) {
      setData(previousData.current);
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, [url, data, JSON.stringify(options)]);

  return { data, loading, error, mutate };
}

// Usage
function TodoList() {
  const { data: todos, mutate } = useOptimisticMutation('/api/todos');

  const addTodo = async (text) => {
    const newTodo = { id: Date.now(), text, completed: false };
    const optimisticTodos = [...(todos || []), newTodo];
    
    await mutate({ text }, optimisticTodos);
  };

  return (/* UI */);
}
```

### Parallel and Sequential Requests

#### Parallel Fetching

```javascript
function useParallelFetch(urls) {
  const [state, setState] = useState({
    data: [],
    loading: true,
    error: null
  });

  useEffect(() => {
    const controllers = urls.map(() => new AbortController());
    
    async function fetchAll() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const promises = urls.map((url, index) =>
          fetch(url, { signal: controllers[index].signal })
            .then(res => {
              if (!res.ok) throw new Error(`HTTP ${res.status} for ${url}`);
              return res.json();
            })
        );
        
        const results = await Promise.all(promises);
        setState({ data: results, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState({ data: [], loading: false, error: err.message });
        }
      }
    }
    
    fetchAll();
    return () => controllers.forEach(c => c.abort());
  }, [JSON.stringify(urls)]);

  return state;
}
```

#### Sequential Dependencies

```javascript
function useSequentialFetch(getUserUrl, getPostsUrl) {
  const [state, setState] = useState({
    user: null,
    posts: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchSequential() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const userRes = await fetch(getUserUrl, { signal: controller.signal });
        if (!userRes.ok) throw new Error('Failed to fetch user');
        const user = await userRes.json();
        
        const postsRes = await fetch(getPostsUrl(user.id), { 
          signal: controller.signal 
        });
        if (!postsRes.ok) throw new Error('Failed to fetch posts');
        const posts = await postsRes.json();
        
        setState({ user, posts, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState(prev => ({ 
            ...prev, 
            loading: false, 
            error: err.message 
          }));
        }
      }
    }
    
    fetchSequential();
    return () => controller.abort();
  }, [getUserUrl, getPostsUrl]);

  return state;
}
```

### Debouncing and Throttling

#### Debounced Search

```javascript
function useDebouncedFetch(url, delay = 500) {
  const [query, setQuery] = useState('');
  const [debouncedQuery, setDebouncedQuery] = useState('');
  const [state, setState] = useState({
    data: null,
    loading: false,
    error: null
  });

  useEffect(() => {
    const timer = setTimeout(() => {
      setDebouncedQuery(query);
    }, delay);

    return () => clearTimeout(timer);
  }, [query, delay]);

  useEffect(() => {
    if (!debouncedQuery) {
      setState({ data: null, loading: false, error: null });
      return;
    }

    const controller = new AbortController();
    
    async function search() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const res = await fetch(`${url}?q=${debouncedQuery}`, {
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState({ data: null, loading: false, error: err.message });
        }
      }
    }
    
    search();
    return () => controller.abort();
  }, [debouncedQuery, url]);

  return { ...state, query, setQuery };
}
```

### Polling

#### Interval-based Polling

```javascript
function usePolling(url, interval = 5000, options = {}) {
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });
  const [isPolling, setIsPolling] = useState(true);

  useEffect(() => {
    if (!isPolling) return;

    const controller = new AbortController();
    
    async function fetchData() {
      try {
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState(prev => ({ ...prev, error: err.message, loading: false }));
        }
      }
    }
    
    fetchData();
    const timer = setInterval(fetchData, interval);

    return () => {
      controller.abort();
      clearInterval(timer);
    };
  }, [url, interval, isPolling, JSON.stringify(options)]);

  return { ...state, isPolling, setIsPolling };
}
```

#### Conditional Polling

```javascript
function useConditionalPolling(url, shouldPoll, interval = 3000) {
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    if (!shouldPoll(state.data)) return;

    const controller = new AbortController();
    
    async function fetchData() {
      try {
        const res = await fetch(url, { signal: controller.signal });
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState(prev => ({ ...prev, error: err.message, loading: false }));
        }
      }
    }
    
    fetchData();
    const timer = setInterval(fetchData, interval);

    return () => {
      controller.abort();
      clearInterval(timer);
    };
  }, [url, interval, shouldPoll, state.data]);

  return state;
}

// Usage: poll until job is complete
function JobStatus({ jobId }) {
  const shouldPoll = (data) => data?.status !== 'completed';
  const { data } = useConditionalPolling(
    `/api/jobs/${jobId}`,
    shouldPoll,
    2000
  );

  return <div>Status: {data?.status}</div>;
}
```

### Error Handling Patterns

#### Retry Logic

```javascript
function useFetchWithRetry(url, maxRetries = 3, retryDelay = 1000, options = {}) {
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null,
    retryCount: 0
  });

  useEffect(() => {
    const controller = new AbortController();
    let retryTimeout;
    
    async function fetchWithRetry(attempt = 0) {
      try {
        setState(prev => ({ 
          ...prev, 
          loading: true, 
          retryCount: attempt 
        }));
        
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        setState({ 
          data, 
          loading: false, 
          error: null, 
          retryCount: attempt 
        });
      } catch (err) {
        if (err.name === 'AbortError') return;
        
        if (attempt < maxRetries) {
          retryTimeout = setTimeout(() => {
            fetchWithRetry(attempt + 1);
          }, retryDelay * Math.pow(2, attempt)); // Exponential backoff
        } else {
          setState({ 
            data: null, 
            loading: false, 
            error: err.message, 
            retryCount: attempt 
          });
        }
      }
    }
    
    fetchWithRetry();
    
    return () => {
      controller.abort();
      clearTimeout(retryTimeout);
    };
  }, [url, maxRetries, retryDelay, JSON.stringify(options)]);

  return state;
}
```

#### Error Boundary Integration

```javascript
function useFetchWithErrorBoundary(url, options = {}) {
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const res = await fetch(url, {
          ...options,
          signal: controller.signal
        });
        
        if (!res.ok) {
          const error = new Error(`HTTP ${res.status}`);
          error.status = res.status;
          throw error;
        }
        
        const data = await res.json();
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          // Throw critical errors to Error Boundary
          if (err.status >= 500) {
            throw err;
          }
          // Handle client errors in component
          setState({ data: null, loading: false, error: err });
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [url, JSON.stringify(options)]);

  return state;
}
```

### Authentication Patterns

#### Token Refresh

```javascript
function useFetchWithAuth(url, options = {}) {
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });
  const tokenRef = useRef(null);

  const refreshToken = useCallback(async () => {
    const res = await fetch('/api/refresh-token', {
      method: 'POST',
      credentials: 'include'
    });
    
    if (!res.ok) throw new Error('Token refresh failed');
    
    const { token } = await res.json();
    tokenRef.current = token;
    return token;
  }, []);

  const fetchWithAuth = useCallback(async (token) => {
    const res = await fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });

    if (res.status === 401) {
      const newToken = await refreshToken();
      return fetch(url, {
        ...options,
        headers: {
          ...options.headers,
          'Authorization': `Bearer ${newToken}`
        }
      });
    }

    return res;
  }, [url, options, refreshToken]);

  useEffect(() => {
    const controller = new AbortController();
    
    async function fetchData() {
      try {
        setState(prev => ({ ...prev, loading: true }));
        
        const res = await fetchWithAuth(tokenRef.current);
        
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        
        const data = await res.json();
        setState({ data, loading: false, error: null });
      } catch (err) {
        if (err.name !== 'AbortError') {
          setState({ data: null, loading: false, error: err.message });
        }
      }
    }
    
    fetchData();
    return () => controller.abort();
  }, [fetchWithAuth]);

  return state;
}
```

### Suspense Integration

#### Resource Pattern for Suspense

```javascript
function wrapPromise(promise) {
  let status = 'pending';
  let result;
  
  const suspender = promise.then(
    (res) => {
      status = 'success';
      result = res;
    },
    (err) => {
      status = 'error';
      result = err;
    }
  );

  return {
    read() {
      if (status === 'pending') throw suspender;
      if (status === 'error') throw result;
      return result;
    }
  };
}

function fetchData(url) {
  const promise = fetch(url)
    .then(res => {
      if (!res.ok) throw new Error(`HTTP ${res.status}`);
      return res.json();
    });
  
  return wrapPromise(promise);
}

// Usage with Suspense
function DataComponent({ resource }) {
  const data = resource.read();
  return <div>{JSON.stringify(data)}</div>;
}

function App() {
  const resource = useMemo(() => fetchData('/api/data'), []);
  
  return (
    <Suspense fallback={<div>Loading...</div>}>
      <DataComponent resource={resource} />
    </Suspense>
  );
}
```

### Request Deduplication

#### Preventing Duplicate Requests

```javascript
function useDeduplicatedFetch(url, options = {}) {
  const pendingRequests = useRef(new Map());
  const [state, setState] = useState({
    data: null,
    loading: true,
    error: null
  });

  useEffect(() => {
    const cacheKey = `${url}-${JSON.stringify(options)}`;
    
    if (pendingRequests.current.has(cacheKey)) {
      pendingRequests.current.get(cacheKey).then(
        data => setState({ data, loading: false, error: null }),
        err => setState({ data: null, loading: false, error: err.message })
      );
      return;
    }

    const controller = new AbortController();
    
    const promise = fetch(url, {
      ...options,
      signal: controller.signal
    })
      .then(res => {
        if (!res.ok) throw new Error(`HTTP ${res.status}`);
        return res.json();
      })
      .finally(() => {
        pendingRequests.current.delete(cacheKey);
      });

    pendingRequests.current.set(cacheKey, promise);

    promise.then(
      data => setState({ data, loading: false, error: null }),
      err => {
        if (err.name !== 'AbortError') {
          setState({ data: null, loading: false, error: err.message });
        }
      }
    );

    return () => controller.abort();
  }, [url, JSON.stringify(options)]);

  return state;
}
```

### Context-based Request Management

#### Global Fetch Context

```javascript
const FetchContext = createContext(null);

function FetchProvider({ children, baseURL, defaultHeaders = {} }) {
  const pendingRequests = useRef(new Map());
  
  const fetcher = useCallback(async (endpoint, options = {}) => {
    const url = `${baseURL}${endpoint}`;
    const config = {
      ...options,
      headers: {
        ...defaultHeaders,
        ...options.headers
      }
    };
    
    const cacheKey = `${url}-${JSON.stringify(config)}`;
    
    if (pendingRequests.current.has(cacheKey)) {
      return pendingRequests.current.get(cacheKey);
    }
    
    const promise = fetch(url, config)
      .then(async res => {
        if (!res.ok) {
          const error = new Error(`HTTP ${res.status}`);
          error.response = res;
          throw error;
        }
        return res.json();
      })
      .finally(() => {
        pendingRequests.current.delete(cacheKey);
      });
    
    pendingRequests.current.set(cacheKey, promise);
    return promise;
  }, [baseURL, defaultHeaders]);

  return (
    <FetchContext.Provider value={fetcher}>
      {children}
    </FetchContext.Provider>
  );
}

function useFetchContext() {
  const fetcher = useContext(FetchContext);
  if (!fetcher) {
    throw new Error('useFetchContext must be used within FetchProvider');
  }
  return fetcher;
}

// Usage in component
function UserList() {
  const fetcher = useFetchContext();
  const [users, setUsers] = useState([]);
  
  useEffect(() => {
    fetcher('/users')
      .then(setUsers)
      .catch(console.error);
  }, [fetcher]);
  
  return <ul>{users.map(u => <li key={u.id}>{u.name}</li>)}</ul>;
}
```

---

## Next.js Data Fetching Integration

### App Router Architecture

#### Server Components as Default

Server Components fetch data directly without client-side JavaScript overhead. Use async/await syntax at the component level:

```tsx
async function ProductPage({ params }: { params: { id: string } }) {
  const product = await fetch(`https://api.example.com/products/${params.id}`)
    .then(res => res.json());
  
  return <ProductDetails data={product} />;
}
```

#### Request Memoization

Next.js automatically deduplicates identical fetch requests within a single render pass. Multiple components requesting the same URL receive cached results:

```tsx
// Both calls use the same data - only one network request
async function Header() {
  const user = await fetch('https://api.example.com/user').then(r => r.json());
  return <UserMenu user={user} />;
}

async function Sidebar() {
  const user = await fetch('https://api.example.com/user').then(r => r.json());
  return <UserProfile user={user} />;
}
```

### Caching Strategies

#### Force-Cache (Default)

Aggressive caching stores responses indefinitely until revalidated:

```tsx
fetch('https://api.example.com/data', {
  cache: 'force-cache' // Default behavior
});
```

#### No-Store

Bypass all caching for dynamic, real-time data:

```tsx
async function LiveDashboard() {
  const metrics = await fetch('https://api.example.com/metrics', {
    cache: 'no-store'
  }).then(r => r.json());
  
  return <MetricsDisplay data={metrics} />;
}
```

This marks the entire route as dynamic.

#### Time-Based Revalidation

Set stale-while-revalidate behavior with `next.revalidate`:

```tsx
fetch('https://api.example.com/posts', {
  next: { revalidate: 3600 } // Revalidate after 1 hour
});
```

#### On-Demand Revalidation

Programmatically purge cache using tags:

```tsx
// Tagging requests
fetch('https://api.example.com/posts', {
  next: { tags: ['posts'] }
});

// Revalidation in API route or Server Action
import { revalidateTag } from 'next/cache';

revalidateTag('posts');
```

Path-based revalidation:

```tsx
import { revalidatePath } from 'next/cache';

revalidatePath('/blog');
revalidatePath('/blog/[slug]', 'page'); // Specific dynamic route
revalidatePath('/blog', 'layout'); // All routes under layout
```

### Route Segment Configuration

#### Dynamic Rendering Control

Configure entire route segments via exported constants:

```tsx
// app/dashboard/page.tsx
export const dynamic = 'force-dynamic'; // Always dynamic
export const revalidate = 3600; // ISR with 1-hour revalidation
export const fetchCache = 'force-no-store'; // Override default caching

async function Dashboard() {
  const data = await fetch('https://api.example.com/dashboard');
  return <DashboardView data={data} />;
}
```

Options for `dynamic`:
- `'auto'` - Default, cache when possible
- `'force-dynamic'` - Always dynamic rendering
- `'error'` - Force static, error if dynamic needed
- `'force-static'` - Force static, empty dynamic functions

#### Runtime Selection

Choose execution environment per route:

```tsx
export const runtime = 'edge'; // or 'nodejs' (default)
```

Edge runtime provides lower latency with limitations (no Node.js APIs, smaller bundle size).

### Parallel and Sequential Patterns

#### Parallel Data Fetching

Use `Promise.all()` for independent requests:

```tsx
async function DashboardPage() {
  const [users, posts, analytics] = await Promise.all([
    fetch('https://api.example.com/users').then(r => r.json()),
    fetch('https://api.example.com/posts').then(r => r.json()),
    fetch('https://api.example.com/analytics').then(r => r.json())
  ]);
  
  return <Dashboard users={users} posts={posts} analytics={analytics} />;
}
```

#### Sequential with Dependency

Fetch serially when one request depends on another:

```tsx
async function UserPostsPage({ params }: { params: { id: string } }) {
  const user = await fetch(`https://api.example.com/users/${params.id}`)
    .then(r => r.json());
  
  // Depends on user.organizationId
  const orgData = await fetch(`https://api.example.com/orgs/${user.organizationId}`)
    .then(r => r.json());
  
  return <UserProfile user={user} organization={orgData} />;
}
```

#### Preloading Pattern

Start fetches early, await later:

```tsx
async function BlogPost({ params }: { params: { slug: string } }) {
  // Start both fetches immediately
  const postPromise = fetch(`https://api.example.com/posts/${params.slug}`);
  const commentsPromise = fetch(`https://api.example.com/posts/${params.slug}/comments`);
  
  // Await when needed
  const post = await postPromise.then(r => r.json());
  
  return (
    <article>
      <PostContent data={post} />
      <Comments commentsPromise={commentsPromise} />
    </article>
  );
}
```

### Streaming and Suspense Integration

#### Boundary-Based Loading

Wrap slow-fetching components in Suspense:

```tsx
import { Suspense } from 'react';

function ProductPage() {
  return (
    <div>
      <ProductHeader />
      <Suspense fallback={<ReviewsSkeleton />}>
        <Reviews /> {/* Slow fetch */}
      </Suspense>
      <Suspense fallback={<RecommendationsSkeleton />}>
        <Recommendations /> {/* Slow fetch */}
      </Suspense>
    </div>
  );
}

async function Reviews() {
  const reviews = await fetch('https://api.example.com/reviews?slow=true', {
    cache: 'no-store'
  }).then(r => r.json());
  
  return <ReviewsList data={reviews} />;
}
```

#### Loading.tsx Convention

Create automatic Suspense boundaries:

```tsx
// app/dashboard/loading.tsx
export default function Loading() {
  return <DashboardSkeleton />;
}

// app/dashboard/page.tsx - automatically wrapped in Suspense
async function Dashboard() {
  const data = await fetch('https://api.example.com/dashboard');
  return <DashboardView data={data} />;
}
```

### Client-Side Fetching

#### Client Component Fetching

Use `'use client'` directive for interactive data needs:

```tsx
'use client';

import { useState, useEffect } from 'react';

export function SearchResults({ query }: { query: string }) {
  const [results, setResults] = useState([]);
  
  useEffect(() => {
    fetch(`https://api.example.com/search?q=${query}`)
      .then(r => r.json())
      .then(setResults);
  }, [query]);
  
  return <ResultsList items={results} />;
}
```

#### SWR Integration

Specialized React hook library for client-side fetching:

```tsx
'use client';

import useSWR from 'swr';

const fetcher = (url: string) => fetch(url).then(r => r.json());

export function Profile() {
  const { data, error, isLoading, mutate } = useSWR(
    'https://api.example.com/user',
    fetcher,
    {
      revalidateOnFocus: true,
      dedupingInterval: 2000
    }
  );
  
  if (error) return <Error />;
  if (isLoading) return <Skeleton />;
  
  return <ProfileView data={data} onUpdate={mutate} />;
}
```

#### React Query Integration

More comprehensive caching and state management:

```tsx
'use client';

import { useQuery, QueryClient, QueryClientProvider } from '@tanstack/react-query';

export function Providers({ children }: { children: React.ReactNode }) {
  const queryClient = new QueryClient({
    defaultOptions: {
      queries: {
        staleTime: 60 * 1000,
      },
    },
  });
  
  return (
    <QueryClientProvider client={queryClient}>
      {children}
    </QueryClientProvider>
  );
}

function Posts() {
  const { data, error, isLoading } = useQuery({
    queryKey: ['posts'],
    queryFn: () => fetch('https://api.example.com/posts').then(r => r.json()),
  });
  
  if (isLoading) return <Skeleton />;
  if (error) return <Error error={error} />;
  
  return <PostsList posts={data} />;
}
```

### Server Actions for Mutations

#### Form Submissions

Server Actions handle mutations with automatic revalidation:

```tsx
// app/actions.ts
'use server';

import { revalidatePath } from 'next/cache';

export async function createPost(formData: FormData) {
  const title = formData.get('title');
  const content = formData.get('content');
  
  const response = await fetch('https://api.example.com/posts', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ title, content })
  });
  
  if (!response.ok) {
    throw new Error('Failed to create post');
  }
  
  revalidatePath('/blog');
  return response.json();
}
```

```tsx
// app/blog/new/page.tsx
import { createPost } from '@/app/actions';

export default function NewPost() {
  return (
    <form action={createPost}>
      <input name="title" required />
      <textarea name="content" required />
      <button type="submit">Create Post</button>
    </form>
  );
}
```

#### Programmatic Invocation

Call Server Actions from Client Components:

```tsx
'use client';

import { createPost } from '@/app/actions';
import { useTransition } from 'react';

export function CreatePostButton() {
  const [isPending, startTransition] = useTransition();
  
  const handleClick = () => {
    startTransition(async () => {
      const formData = new FormData();
      formData.append('title', 'New Post');
      formData.append('content', 'Content here');
      
      await createPost(formData);
    });
  };
  
  return (
    <button onClick={handleClick} disabled={isPending}>
      {isPending ? 'Creating...' : 'Create Post'}
    </button>
  );
}
```

### Route Handlers for Custom APIs

#### GET Handlers

Create API routes that integrate with Next.js caching:

```tsx
// app/api/posts/route.ts
import { NextResponse } from 'next/server';

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const category = searchParams.get('category');
  
  const response = await fetch(
    `https://api.example.com/posts?category=${category}`,
    {
      next: { revalidate: 3600, tags: ['posts'] }
    }
  );
  
  const data = await response.json();
  
  return NextResponse.json(data);
}

export const dynamic = 'force-dynamic'; // or revalidate = 3600
```

#### POST/PUT/DELETE Handlers

Mutations with automatic cache invalidation:

```tsx
// app/api/posts/[id]/route.ts
import { NextResponse } from 'next/server';
import { revalidateTag } from 'next/cache';

export async function PUT(
  request: Request,
  { params }: { params: { id: string } }
) {
  const body = await request.json();
  
  const response = await fetch(
    `https://api.example.com/posts/${params.id}`,
    {
      method: 'PUT',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(body)
    }
  );
  
  if (!response.ok) {
    return NextResponse.json(
      { error: 'Failed to update' },
      { status: response.status }
    );
  }
  
  revalidateTag('posts');
  
  return NextResponse.json(await response.json());
}
```

#### Dynamic Route Handlers

Handle parameterized endpoints:

```tsx
// app/api/users/[userId]/posts/[postId]/route.ts
export async function GET(
  request: Request,
  { params }: { params: { userId: string; postId: string } }
) {
  const post = await fetch(
    `https://api.example.com/users/${params.userId}/posts/${params.postId}`
  ).then(r => r.json());
  
  return NextResponse.json(post);
}
```

### Error Handling Patterns

#### Try-Catch Boundaries

Handle fetch failures gracefully:

```tsx
async function ProductPage({ params }: { params: { id: string } }) {
  try {
    const product = await fetch(`https://api.example.com/products/${params.id}`)
      .then(async (res) => {
        if (!res.ok) {
          throw new Error(`HTTP ${res.status}: ${res.statusText}`);
        }
        return res.json();
      });
    
    return <ProductDetails data={product} />;
  } catch (error) {
    console.error('Failed to fetch product:', error);
    return <ProductError message="Unable to load product" />;
  }
}
```

#### Error.tsx Convention

Automatic error boundaries for route segments:

```tsx
// app/products/error.tsx
'use client';

export default function Error({
  error,
  reset,
}: {
  error: Error & { digest?: string };
  reset: () => void;
}) {
  return (
    <div>
      <h2>Something went wrong!</h2>
      <p>{error.message}</p>
      <button onClick={reset}>Try again</button>
    </div>
  );
}
```

#### Not-Found Handling

Custom 404 pages for missing resources:

```tsx
// app/products/[id]/page.tsx
import { notFound } from 'next/navigation';

async function ProductPage({ params }: { params: { id: string } }) {
  const response = await fetch(`https://api.example.com/products/${params.id}`);
  
  if (response.status === 404) {
    notFound(); // Renders not-found.tsx
  }
  
  if (!response.ok) {
    throw new Error('Failed to fetch product');
  }
  
  const product = await response.json();
  return <ProductDetails data={product} />;
}
```

```tsx
// app/products/[id]/not-found.tsx
export default function NotFound() {
  return <div>Product not found</div>;
}
```

### Authentication Integration

#### Middleware-Based Auth

Intercept requests before route execution:

```tsx
// middleware.ts
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';

export function middleware(request: NextRequest) {
  const token = request.cookies.get('auth-token');
  
  if (!token && request.nextUrl.pathname.startsWith('/dashboard')) {
    return NextResponse.redirect(new URL('/login', request.url));
  }
  
  // Add auth header to all API requests
  const requestHeaders = new Headers(request.headers);
  if (token) {
    requestHeaders.set('Authorization', `Bearer ${token.value}`);
  }
  
  return NextResponse.next({
    request: {
      headers: requestHeaders,
    },
  });
}

export const config = {
  matcher: ['/dashboard/:path*', '/api/:path*'],
};
```

#### Server Component Auth

Access headers and cookies directly:

```tsx
import { cookies, headers } from 'next/headers';

async function UserDashboard() {
  const cookieStore = cookies();
  const token = cookieStore.get('auth-token');
  
  const userData = await fetch('https://api.example.com/user', {
    headers: {
      'Authorization': `Bearer ${token?.value}`,
    },
    cache: 'no-store' // User-specific data shouldn't be cached
  }).then(r => r.json());
  
  return <Dashboard user={userData} />;
}
```

#### Session-Based Fetching

Integrate with authentication libraries:

```tsx
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';

async function ProtectedPage() {
  const session = await getServerSession(authOptions);
  
  if (!session) {
    redirect('/login');
  }
  
  const privateData = await fetch('https://api.example.com/private', {
    headers: {
      'Authorization': `Bearer ${session.accessToken}`,
    },
  }).then(r => r.json());
  
  return <PrivateContent data={privateData} />;
}
```

### Incremental Static Regeneration (ISR)

#### Background Revalidation

Serve stale content while regenerating in background:

```tsx
// Revalidate every 10 minutes
export const revalidate = 600;

async function BlogPost({ params }: { params: { slug: string } }) {
  const post = await fetch(`https://api.example.com/posts/${params.slug}`)
    .then(r => r.json());
  
  return <Article data={post} />;
}
```

#### On-Demand ISR

Trigger regeneration via webhook or API:

```tsx
// app/api/revalidate/route.ts
import { revalidatePath } from 'next/cache';
import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
  const body = await request.json();
  const secret = request.headers.get('x-revalidate-secret');
  
  if (secret !== process.env.REVALIDATE_SECRET) {
    return NextResponse.json({ message: 'Invalid secret' }, { status: 401 });
  }
  
  revalidatePath(`/blog/${body.slug}`);
  
  return NextResponse.json({ revalidated: true });
}
```

Webhook from CMS triggers regeneration after content updates.

#### Stale-While-Revalidate Behavior

[Inference] Next.js likely serves cached content immediately while fetching fresh data in background:

```tsx
fetch('https://api.example.com/data', {
  next: { revalidate: 60 }
});
```

First request after 60 seconds receives cached data; subsequent requests get updated content.

### Request Deduplication Patterns

#### Automatic Deduplication Scope

Next.js deduplicates within a single render pass only. Separate page navigations create new requests:

```tsx
// Same render - deduplicated
async function Layout() {
  const config = await fetch('https://api.example.com/config').then(r => r.json());
  return (
    <>
      <Header config={config} />
      <Sidebar config={config} /> {/* Uses memoized result */}
    </>
  );
}
```

#### React Cache for Extended Memoization

Use `cache()` for custom deduplication logic:

```tsx
import { cache } from 'react';

const getUser = cache(async (id: string) => {
  const response = await fetch(`https://api.example.com/users/${id}`);
  return response.json();
});

async function UserProfile({ id }: { id: string }) {
  const user = await getUser(id);
  return <Profile data={user} />;
}

async function UserPosts({ id }: { id: string }) {
  const user = await getUser(id); // Same memoized result
  return <Posts userId={user.id} />;
}
```

`cache()` persists across component boundaries within the same request.

### Data Mutation Strategies

#### Optimistic Updates Pattern

Update UI before server confirmation:

```tsx
'use client';

import { useState, useTransition } from 'react';
import { updatePost } from '@/app/actions';

export function PostEditor({ initialData }: { initialData: Post }) {
  const [post, setPost] = useState(initialData);
  const [isPending, startTransition] = useTransition();
  
  const handleUpdate = (newContent: string) => {
    // Optimistic update
    setPost(prev => ({ ...prev, content: newContent }));
    
    startTransition(async () => {
      try {
        await updatePost(post.id, newContent);
      } catch (error) {
        // Rollback on failure
        setPost(initialData);
      }
    });
  };
  
  return <Editor content={post.content} onUpdate={handleUpdate} />;
}
```

#### Mutation with Revalidation

Server Actions automatically revalidate affected paths:

```tsx
'use server';

import { revalidatePath, revalidateTag } from 'next/cache';

export async function deletePost(postId: string) {
  await fetch(`https://api.example.com/posts/${postId}`, {
    method: 'DELETE',
  });
  
  revalidatePath('/blog');
  revalidateTag('posts');
}
```

### Performance Optimization

#### Partial Prerendering

[Inference] Static and dynamic content rendered separately:

```tsx
export const experimental_ppr = true;

async function ProductPage({ params }: { params: { id: string } }) {
  return (
    <>
      {/* Static shell renders immediately */}
      <ProductLayout>
        {/* Dynamic content streams in */}
        <Suspense fallback={<PriceSkeleton />}>
          <ProductPrice id={params.id} />
        </Suspense>
        
        <Suspense fallback={<StockSkeleton />}>
          <StockStatus id={params.id} />
        </Suspense>
      </ProductLayout>
    </>
  );
}
```

#### Route Prefetching

Next.js automatically prefetches visible links:

```tsx
import Link from 'next/link';

// Prefetched when link enters viewport
<Link href="/products/123" prefetch={true}>
  View Product
</Link>

// Disable prefetching
<Link href="/products/123" prefetch={false}>
  View Product
</Link>
```

#### Selective Hydration

[Inference] Suspense boundaries may enable progressive hydration:

```tsx
function Page() {
  return (
    <>
      <CriticalContent /> {/* Hydrates first */}
      
      <Suspense fallback={<Skeleton />}>
        <HeavyComponent /> {/* Hydrates after */}
      </Suspense>
    </>
  );
}
```

### Headers and Cookies Access

#### Reading Headers

Access request headers in Server Components:

```tsx
import { headers } from 'next/headers';

async function Page() {
  const headersList = headers();
  const userAgent = headersList.get('user-agent');
  const referer = headersList.get('referer');
  
  const data = await fetch('https://api.example.com/data', {
    headers: {
      'User-Agent': userAgent || '',
    },
  }).then(r => r.json());
  
  return <Content data={data} />;
}
```

#### Cookie Management

Read and set cookies:

```tsx
import { cookies } from 'next/headers';

async function Page() {
  const cookieStore = cookies();
  
  // Read cookie
  const theme = cookieStore.get('theme');
  
  // Set cookie
  cookieStore.set('last-visit', new Date().toISOString(), {
    httpOnly: true,
    secure: process.env.NODE_ENV === 'production',
    maxAge: 60 * 60 * 24 * 7, // 1 week
  });
  
  const preferences = await fetch('https://api.example.com/preferences', {
    headers: {
      'Cookie': cookieStore.toString(),
    },
  }).then(r => r.json());
  
  return <PreferencesView data={preferences} theme={theme?.value} />;
}
```

### Edge Runtime Considerations

#### Edge-Compatible Fetching

Edge runtime has restrictions:

```tsx
export const runtime = 'edge';

// ✅ Works in edge
async function EdgePage() {
  const data = await fetch('https://api.example.com/data')
    .then(r => r.json());
  
  return <Content data={data} />;
}

// ❌ Node.js APIs unavailable
// - fs, path modules
// - Native crypto
// - Some npm packages
```

#### Edge-Optimized Patterns

Minimize bundle size and latency:

```tsx
export const runtime = 'edge';

export async function GET(request: Request) {
  const { searchParams } = new URL(request.url);
  const id = searchParams.get('id');
  
  // Use edge-friendly libraries
  const response = await fetch(`https://api.example.com/data/${id}`, {
    // Leverage edge caching
    cf: {
      cacheTtl: 300,
      cacheEverything: true,
    },
  });
  
  return new Response(response.body, {
    headers: {
      'Cache-Control': 'public, s-maxage=300',
    },
  });
}
```

### Debugging and Monitoring

#### Logging Fetch Requests

Debug fetch behavior in development:

```tsx
async function Page() {
  const startTime = Date.now();
  
  const data = await fetch('https://api.example.com/data', {
    next: { revalidate: 3600 }
  }).then(async (res) => {
    console.log(`Fetch completed in ${Date.now() - startTime}ms`);
    console.log('Cache status:', res.headers.get('x-vercel-cache'));
    return res.json();
  });
  
  return <Content data={data} />;
}
```

#### Cache Hit Indicators

Check response headers for cache status:

- `x-nextjs-cache: HIT` - Served from Next.js cache
- `x-nextjs-cache: MISS` - Fresh fetch executed
- `x-nextjs-cache: STALE` - Revalidating in background

#### Performance Monitoring

Track fetch performance in production:

```tsx
async function Page() {
  const start = performance.now();
  
  try {
    const data = await fetch('https://api.example.com/data');
    const duration = performance.now() - start;
    
    // Send to analytics
    if (typeof window !== 'undefined') {
      window.gtag?.('event', 'fetch_timing', {
        url: 'https://api.example.com/data',
        duration,
      });
    }
    
    return <Content data={data} />;
  } catch (error) {
    // Log errors to monitoring service
    console.error('Fetch failed:', error);
    throw error;
  }
}
```

---

## Server-Side Rendering Considerations

### Execution Environment Differences

The fetch API behaves differently between server and client environments. On the server, fetch executes in Node.js (or edge runtime environments), while client-side fetch runs in the browser. Server environments lack browser-specific features like cookies stored in `document.cookie`, `localStorage`, and automatic credential inclusion from the browser's cookie jar.

Server-side fetch requires explicit header management for authentication. Cookies must be forwarded manually from incoming requests to outgoing fetch calls, typically by reading them from request headers and passing them through.

### Next.js Integration

#### App Router Fetch Extensions

Next.js extends the native fetch API with additional caching and revalidation capabilities in the App Router. The framework wraps fetch to provide automatic request deduplication within a single render pass.

```javascript
// Static data fetching with indefinite cache
const response = await fetch('https://api.example.com/data', {
  cache: 'force-cache' // Default behavior
});

// Dynamic data fetching with no caching
const response = await fetch('https://api.example.com/data', {
  cache: 'no-store'
});

// Time-based revalidation
const response = await fetch('https://api.example.com/data', {
  next: { revalidate: 3600 } // Revalidate every hour
});

// Tag-based revalidation
const response = await fetch('https://api.example.com/data', {
  next: { tags: ['products'] }
});
```

The `next.revalidate` option controls cache lifetime at the request level. The `next.tags` option allows on-demand revalidation using `revalidateTag()` or `revalidatePath()` from server actions or route handlers.

#### Request Deduplication

Next.js automatically deduplicates identical fetch requests during server rendering. Multiple components requesting the same URL with identical options result in a single network request, with the response shared across all consumers.

```javascript
// These three fetches result in one network request
async function ComponentA() {
  const data = await fetch('https://api.example.com/user/1');
}

async function ComponentB() {
  const data = await fetch('https://api.example.com/user/1');
}

async function ComponentC() {
  const data = await fetch('https://api.example.com/user/1');
}
```

Deduplication applies only within the same render pass and only to GET requests. POST requests and requests with different headers are not deduplicated.

#### Pages Router Considerations

In the Pages Router, fetch is available but without the automatic caching extensions. Data fetching occurs in `getServerSideProps`, `getStaticProps`, or `getInitialProps`, where you control caching behavior through response headers or the framework's revalidation mechanisms.

```javascript
export async function getServerSideProps(context) {
  const response = await fetch('https://api.example.com/data', {
    headers: {
      cookie: context.req.headers.cookie || ''
    }
  });
  
  return {
    props: {
      data: await response.json()
    }
  };
}
```

### SvelteKit Integration

#### Load Functions

SvelteKit provides `load` functions that run on both server and client during navigation. The framework provides a custom `fetch` function as a parameter to these load functions.

```javascript
// +page.server.js - Server-only load
export async function load({ fetch, cookies, request }) {
  const response = await fetch('https://api.example.com/data', {
    headers: {
      cookie: cookies.serialize()
    }
  });
  
  return {
    data: await response.json()
  };
}

// +page.js - Universal load (runs on both server and client)
export async function load({ fetch, parent }) {
  const response = await fetch('https://api.example.com/data');
  
  return {
    data: await response.json()
  };
}
```

The SvelteKit-provided `fetch` function inherits credentials and headers from the original request during SSR, avoiding the need to manually forward cookies for same-origin requests. It also enables relative URLs that resolve correctly in both environments.

#### Cookie and Header Propagation

SvelteKit automatically forwards cookies from the incoming request to same-origin fetch calls during SSR. For cross-origin requests, you must explicitly include credentials or set appropriate headers.

```javascript
export async function load({ fetch, cookies }) {
  // Same-origin: cookies forwarded automatically
  const response1 = await fetch('/api/data');
  
  // Cross-origin: manual credential handling
  const response2 = await fetch('https://external-api.com/data', {
    credentials: 'include',
    headers: {
      'Authorization': `Bearer ${cookies.get('token')}`
    }
  });
  
  return {
    data1: await response1.json(),
    data2: await response2.json()
  };
}
```

### Remix Integration

#### Loaders and Actions

Remix handles data fetching through `loader` functions that execute on the server during SSR and on subsequent navigations. The framework doesn't extend fetch directly but provides request context.

```javascript
// app/routes/products.$id.jsx
export async function loader({ params, request }) {
  const cookie = request.headers.get('Cookie');
  
  const response = await fetch(`https://api.example.com/products/${params.id}`, {
    headers: {
      'Cookie': cookie || ''
    }
  });
  
  if (!response.ok) {
    throw new Response('Not Found', { status: 404 });
  }
  
  return response.json();
}
```

Remix loaders receive the raw Request object, allowing direct access to headers for forwarding. The loader's return value automatically serializes to JSON and becomes available to the route component through `useLoaderData()`.

#### Mutation Handling

Form submissions and mutations go through `action` functions, which also execute on the server. Actions handle POST, PUT, DELETE, and PATCH requests.

```javascript
export async function action({ request }) {
  const formData = await request.formData();
  const cookie = request.headers.get('Cookie');
  
  const response = await fetch('https://api.example.com/products', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Cookie': cookie || ''
    },
    body: JSON.stringify({
      name: formData.get('name'),
      price: formData.get('price')
    })
  });
  
  if (!response.ok) {
    return { error: 'Failed to create product' };
  }
  
  return redirect('/products');
}
```

### Astro Integration

#### Server-Only Execution

Astro components run only on the server during build or at request time (SSR mode). Fetch calls in Astro component frontmatter execute server-side, with no client-side re-execution.

```astro
---
// This runs on the server only
const response = await fetch('https://api.example.com/data');
const data = await response.json();
---

<div>
  {data.items.map(item => (
    <article>{item.title}</article>
  ))}
</div>
```

For client-side interactivity requiring data fetching, Astro requires explicit client-side scripts or framework components (React, Vue, Svelte) with client directives.

#### API Routes

Astro's API routes provide server endpoints for client-side fetch calls. These routes have access to the incoming request context.

```javascript
// src/pages/api/data.js
export async function GET({ request, cookies }) {
  const token = cookies.get('auth-token');
  
  const response = await fetch('https://api.example.com/data', {
    headers: {
      'Authorization': `Bearer ${token?.value}`
    }
  });
  
  return new Response(JSON.stringify(await response.json()), {
    headers: {
      'Content-Type': 'application/json'
    }
  });
}
```

### Nuxt Integration

#### useAsyncData and useFetch

Nuxt provides composables that wrap fetch with SSR-aware caching and hydration. These composables execute on the server during initial render and handle client-side hydration automatically.

```javascript
// Automatic key generation and caching
const { data, pending, error, refresh } = await useFetch('/api/products');

// Manual key for better control
const { data } = await useAsyncData('products', () => 
  fetch('https://api.example.com/products').then(r => r.json())
);

// With options
const { data } = await useFetch('/api/products', {
  key: 'products-list',
  method: 'POST',
  body: { category: 'electronics' },
  transform: (data) => data.items,
  pick: ['id', 'name', 'price']
});
```

The `useFetch` composable automatically handles cookie forwarding for same-origin requests during SSR. The data fetched on the server gets serialized and sent to the client for hydration, avoiding duplicate requests.

#### Server Routes

Nuxt server routes (in the `server/` directory) handle API requests and have access to event context for cookie and header management.

```javascript
// server/api/products.js
export default defineEventHandler(async (event) => {
  const cookies = parseCookies(event);
  
  const response = await fetch('https://api.example.com/products', {
    headers: {
      'Authorization': `Bearer ${cookies.token}`
    }
  });
  
  return response.json();
});
```

### Authentication and Authorization

#### Token Management

Server-side rendering requires careful handling of authentication tokens. Tokens stored in cookies should be forwarded with fetch requests, while tokens in localStorage (client-only) require alternative strategies.

```javascript
// Next.js App Router
async function ServerComponent() {
  const { cookies } = await import('next/headers');
  const token = cookies().get('auth-token');
  
  const response = await fetch('https://api.example.com/protected', {
    headers: {
      'Authorization': `Bearer ${token?.value}`
    }
  });
  
  return response.json();
}

// SvelteKit
export async function load({ fetch, cookies }) {
  const token = cookies.get('auth-token');
  
  const response = await fetch('https://api.example.com/protected', {
    headers: {
      'Authorization': `Bearer ${token}`
    }
  });
  
  return { data: await response.json() };
}
```

#### Session Handling

Framework-specific session management libraries often provide helpers for authenticated fetch requests. These libraries handle token refresh, session validation, and credential forwarding.

```javascript
// Next.js with next-auth
import { getServerSession } from 'next-auth';

export async function GET(request) {
  const session = await getServerSession();
  
  if (!session) {
    return new Response('Unauthorized', { status: 401 });
  }
  
  const response = await fetch('https://api.example.com/data', {
    headers: {
      'Authorization': `Bearer ${session.accessToken}`
    }
  });
  
  return response;
}
```

### Error Handling Patterns

#### Framework-Specific Error Boundaries

Different frameworks provide different mechanisms for handling fetch errors during SSR. Understanding these patterns prevents hydration mismatches and improves error reporting.

```javascript
// Next.js App Router - Error boundaries
// error.jsx
export default function Error({ error, reset }) {
  return (
    <div>
      <h2>Something went wrong!</h2>
      <button onClick={() => reset()}>Try again</button>
    </div>
  );
}

// Remix - Error boundaries with caught responses
export function ErrorBoundary({ error }) {
  return (
    <div>
      <h1>Error</h1>
      <p>{error.message}</p>
    </div>
  );
}

// SvelteKit - Error page
// +error.svelte
<script>
  import { page } from '$app/stores';
</script>

<h1>{$page.status}: {$page.error.message}</h1>
```

#### Retry and Fallback Strategies

Server-side fetch failures require different handling than client-side failures. Network timeouts, DNS failures, and connection errors should trigger appropriate fallbacks or cached responses.

```javascript
async function fetchWithRetry(url, options = {}, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      const response = await fetch(url, {
        ...options,
        signal: AbortSignal.timeout(5000)
      });
      
      if (!response.ok && i < retries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
        continue;
      }
      
      return response;
    } catch (error) {
      if (i === retries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
}
```

### Performance Optimization

#### Request Parallelization

Server-side rendering allows parallelizing independent data fetches to reduce total rendering time. Use `Promise.all()` or `Promise.allSettled()` to fetch data concurrently.

```javascript
// Next.js
async function Page() {
  const [user, products, categories] = await Promise.all([
    fetch('https://api.example.com/user').then(r => r.json()),
    fetch('https://api.example.com/products').then(r => r.json()),
    fetch('https://api.example.com/categories').then(r => r.json())
  ]);
  
  return <Layout user={user} products={products} categories={categories} />;
}

// SvelteKit
export async function load({ fetch }) {
  const [userRes, productsRes, categoriesRes] = await Promise.all([
    fetch('/api/user'),
    fetch('/api/products'),
    fetch('/api/categories')
  ]);
  
  return {
    user: await userRes.json(),
    products: await productsRes.json(),
    categories: await categoriesRes.json()
  };
}
```

#### Streaming and Suspense

Modern frameworks support streaming responses, allowing partial page rendering while data loads. This reduces time-to-first-byte and improves perceived performance.

```javascript
// Next.js with Suspense
import { Suspense } from 'react';

async function UserProfile() {
  const user = await fetch('https://api.example.com/user').then(r => r.json());
  return <div>{user.name}</div>;
}

export default function Page() {
  return (
    <div>
      <h1>Dashboard</h1>
      <Suspense fallback={<div>Loading user...</div>}>
        <UserProfile />
      </Suspense>
    </div>
  );
}
```

Remix and SvelteKit support similar patterns through deferred data loading and streaming responses, allowing progressive enhancement of server-rendered pages.

### Cache Strategies

#### Framework Cache Integration

Frameworks provide different approaches to caching fetch responses during SSR. Understanding these mechanisms prevents stale data issues and optimizes build times.

```javascript
// Next.js - Segment-level caching
export const revalidate = 3600; // Revalidate every hour

export default async function Page() {
  const data = await fetch('https://api.example.com/data', {
    next: { revalidate: 60 } // Override segment-level cache
  });
  
  return <div>{/* render data */}</div>;
}

// Nuxt - Cache control
const { data } = await useFetch('/api/data', {
  key: 'my-data',
  getCachedData(key) {
    return useNuxtApp().payload.data[key] || useNuxtApp().static.data[key];
  }
});
```

#### Build-Time vs Runtime Caching

Static site generation frameworks cache fetch results at build time, while SSR frameworks cache at runtime. Choose the appropriate strategy based on data freshness requirements.

```javascript
// Astro - Build-time fetch (SSG)
---
const response = await fetch('https://api.example.com/data');
const data = await response.json();
---

// Next.js - Runtime fetch with ISR
export default async function Page() {
  const data = await fetch('https://api.example.com/data', {
    next: { revalidate: 60 }
  }).then(r => r.json());
  
  return <div>{/* render data */}</div>;
}
```

### Hydration Considerations

#### Data Serialization

Data fetched on the server must serialize to the client for hydration. Avoid non-serializable values like functions, dates (without conversion), and circular references.

```javascript
// Next.js - Serialization handling
export default async function Page() {
  const data = await fetch('https://api.example.com/data').then(r => r.json());
  
  // Convert dates to strings for serialization
  const serializedData = {
    ...data,
    createdAt: new Date(data.createdAt).toISOString()
  };
  
  return <Component data={serializedData} />;
}

// Nuxt - Automatic serialization
const { data } = await useAsyncData('products', async () => {
  const response = await fetch('https://api.example.com/products');
  const products = await response.json();
  
  // Transform dates for serialization
  return products.map(p => ({
    ...p,
    createdAt: p.createdAt.toISOString()
  }));
});
```

#### Avoiding Double Fetching

Frameworks must prevent duplicate fetches during hydration. Server-fetched data should populate the client-side state without triggering additional requests.

```javascript
// SvelteKit - Automatic hydration
export async function load({ fetch }) {
  // Fetched on server, hydrated on client
  const response = await fetch('/api/data');
  return {
    data: await response.json()
  };
}

// Remix - Automatic data hydration
export function loader() {
  // Runs on server, result hydrates to client
  return fetch('https://api.example.com/data').then(r => r.json());
}

export default function Route() {
  const data = useLoaderData(); // No additional fetch
  return <div>{/* render data */}</div>;
}
```

### Edge Runtime Considerations

#### Cloudflare Workers and Vercel Edge

Edge runtimes provide a global fetch API but with limitations compared to Node.js. These environments restrict certain Node.js APIs and impose stricter execution time limits.

```javascript
// Vercel Edge Runtime
export const config = {
  runtime: 'edge'
};

export default async function handler(request) {
  const response = await fetch('https://api.example.com/data', {
    headers: {
      'User-Agent': 'Edge Function'
    }
  });
  
  return new Response(response.body, {
    headers: {
      'Content-Type': 'application/json',
      'Cache-Control': 's-maxage=60'
    }
  });
}
```

Edge runtimes optimize for low-latency responses but may have limited support for large request/response bodies and long-running operations.

#### Request/Response Streaming

Edge environments support streaming responses, enabling progressive data delivery for large datasets or real-time updates.

```javascript
export default async function handler() {
  const encoder = new TextEncoder();
  
  const stream = new ReadableStream({
    async start(controller) {
      const response = await fetch('https://api.example.com/stream');
      const reader = response.body.getReader();
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        controller.enqueue(value);
      }
      
      controller.close();
    }
  });
  
  return new Response(stream, {
    headers: { 'Content-Type': 'application/json' }
  });
}
```

### Testing SSR Fetch Behavior

#### Mocking Server Environment

Testing server-side fetch requires mocking the server environment and simulating framework-specific contexts. Libraries like MSW (Mock Service Worker) work in both Node.js and browser environments.

```javascript
// Vitest with MSW
import { http, HttpResponse } from 'msw';
import { setupServer } from 'msw/node';

const server = setupServer(
  http.get('https://api.example.com/data', () => {
    return HttpResponse.json({ items: [] });
  })
);

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());

test('fetches data during SSR', async () => {
  const response = await fetch('https://api.example.com/data');
  const data = await response.json();
  expect(data.items).toEqual([]);
});
```

#### Framework Test Utilities

Frameworks provide testing utilities that simulate their SSR environment, including request context and data loading mechanisms.

```javascript
// Next.js testing
import { render } from '@testing-library/react';

test('renders with SSR data', async () => {
  // Mock fetch for component
  global.fetch = vi.fn(() =>
    Promise.resolve({
      ok: true,
      json: () => Promise.resolve({ name: 'Test' })
    })
  );
  
  const { findByText } = render(<ServerComponent />);
  expect(await findByText('Test')).toBeInTheDocument();
});

// SvelteKit testing
import { load } from './+page.server.js';

test('load function fetches data', async () => {
  const mockFetch = vi.fn(() =>
    Promise.resolve({
      json: () => Promise.resolve({ items: [] })
    })
  );
  
  const result = await load({ fetch: mockFetch });
  expect(result.data.items).toEqual([]);
});
```

---

## Static Generation Patterns

### Build-Time Data Fetching

#### Next.js Static Generation

##### getStaticProps

```javascript
export async function getStaticProps(context) {
  const res = await fetch('https://api.example.com/data');
  const data = await res.json();
  
  return {
    props: { data },
    revalidate: 3600 // ISR: regenerate every hour
  };
}
```

##### Parallel Data Fetching

```javascript
export async function getStaticProps() {
  const [users, posts, comments] = await Promise.all([
    fetch('https://api.example.com/users').then(r => r.json()),
    fetch('https://api.example.com/posts').then(r => r.json()),
    fetch('https://api.example.com/comments').then(r => r.json())
  ]);
  
  return {
    props: { users, posts, comments }
  };
}
```

##### Dynamic Path Generation

```javascript
export async function getStaticPaths() {
  const res = await fetch('https://api.example.com/posts');
  const posts = await res.json();
  
  const paths = posts.map(post => ({
    params: { id: post.id.toString() }
  }));
  
  return {
    paths,
    fallback: 'blocking' // or false, true
  };
}

export async function getStaticProps({ params }) {
  const res = await fetch(`https://api.example.com/posts/${params.id}`);
  const post = await res.json();
  
  return { props: { post } };
}
```

##### App Router (Next.js 13+)

```javascript
// app/posts/[id]/page.js
async function getPost(id) {
  const res = await fetch(`https://api.example.com/posts/${id}`, {
    next: { revalidate: 3600 }
  });
  return res.json();
}

export async function generateStaticParams() {
  const posts = await fetch('https://api.example.com/posts').then(r => r.json());
  return posts.map(post => ({ id: post.id.toString() }));
}

export default async function Page({ params }) {
  const post = await getPost(params.id);
  return <article>{post.content}</article>;
}
```

#### Incremental Static Regeneration (ISR)

##### Time-Based Revalidation

```javascript
export async function getStaticProps() {
  const res = await fetch('https://api.example.com/products');
  const products = await res.json();
  
  return {
    props: { products },
    revalidate: 60 // Regenerate at most once per minute
  };
}
```

##### On-Demand Revalidation

```javascript
// API route: pages/api/revalidate.js
export default async function handler(req, res) {
  if (req.query.secret !== process.env.REVALIDATE_TOKEN) {
    return res.status(401).json({ message: 'Invalid token' });
  }
  
  try {
    await res.revalidate('/products');
    await res.revalidate(`/products/${req.query.id}`);
    return res.json({ revalidated: true });
  } catch (err) {
    return res.status(500).send('Error revalidating');
  }
}
```

##### Tag-Based Revalidation (App Router)

```javascript
// Fetch with tags
async function getData() {
  const res = await fetch('https://api.example.com/posts', {
    next: { tags: ['posts'] }
  });
  return res.json();
}

// Revalidate by tag
import { revalidateTag } from 'next/cache';

export async function POST(request) {
  const tag = request.nextUrl.searchParams.get('tag');
  revalidateTag(tag);
  return Response.json({ revalidated: true, now: Date.now() });
}
```

### SvelteKit Static Adapter

#### Load Functions

```javascript
// +page.js
export async function load({ fetch, params }) {
  const res = await fetch('https://api.example.com/data');
  const data = await res.json();
  
  return { data };
}

// svelte.config.js
import adapter from '@sveltejs/adapter-static';

export default {
  kit: {
    adapter: adapter({
      pages: 'build',
      assets: 'build',
      fallback: null,
      precompress: false
    })
  }
};
```

#### Prerendering Specific Routes

```javascript
// +page.js
export const prerender = true;

export async function load({ fetch }) {
  const res = await fetch('https://api.example.com/static-content');
  return { content: await res.json() };
}
```

#### Dynamic Route Prerendering

```javascript
// +page.server.js
export const prerender = true;

export async function entries() {
  const res = await fetch('https://api.example.com/posts');
  const posts = await res.json();
  
  return posts.map(post => ({ id: post.id }));
}

export async function load({ params, fetch }) {
  const res = await fetch(`https://api.example.com/posts/${params.id}`);
  return { post: await res.json() };
}
```

### Astro Static Site Generation

#### Data Fetching in Components

```astro
---
// src/pages/posts/[id].astro
export async function getStaticPaths() {
  const response = await fetch('https://api.example.com/posts');
  const posts = await response.json();
  
  return posts.map(post => ({
    params: { id: post.id },
    props: { post }
  }));
}

const { post } = Astro.props;
---

<article>
  <h1>{post.title}</h1>
  <p>{post.content}</p>
</article>
```

#### Parallel Route Generation

```astro
---
export async function getStaticPaths() {
  const [posts, authors] = await Promise.all([
    fetch('https://api.example.com/posts').then(r => r.json()),
    fetch('https://api.example.com/authors').then(r => r.json())
  ]);
  
  return posts.map(post => {
    const author = authors.find(a => a.id === post.authorId);
    return {
      params: { id: post.id },
      props: { post, author }
    };
  });
}
---
```

#### Content Collections with Remote Data

```javascript
// src/content/config.ts
import { defineCollection, z } from 'astro:content';

const posts = defineCollection({
  loader: async () => {
    const response = await fetch('https://api.example.com/posts');
    const data = await response.json();
    return data.map(post => ({
      id: post.id,
      ...post
    }));
  },
  schema: z.object({
    title: z.string(),
    content: z.string(),
    publishedAt: z.string()
  })
});

export const collections = { posts };
```

### Gatsby Source Plugin Pattern

#### Custom Source Plugin

```javascript
// gatsby-node.js
exports.sourceNodes = async ({
  actions,
  createNodeId,
  createContentDigest
}) => {
  const { createNode } = actions;
  
  const response = await fetch('https://api.example.com/posts');
  const posts = await response.json();
  
  posts.forEach(post => {
    createNode({
      ...post,
      id: createNodeId(`Post-${post.id}`),
      parent: null,
      children: [],
      internal: {
        type: 'Post',
        contentDigest: createContentDigest(post)
      }
    });
  });
};
```

#### GraphQL Query in Pages

```javascript
// src/pages/index.js
import { graphql } from 'gatsby';

export const query = graphql`
  query {
    allPost {
      nodes {
        id
        title
        content
      }
    }
  }
`;

export default function Index({ data }) {
  return (
    <ul>
      {data.allPost.nodes.map(post => (
        <li key={post.id}>{post.title}</li>
      ))}
    </ul>
  );
}
```

#### Dynamic Page Creation

```javascript
// gatsby-node.js
exports.createPages = async ({ graphql, actions }) => {
  const { createPage } = actions;
  
  const result = await graphql(`
    query {
      allPost {
        nodes {
          id
          slug
        }
      }
    }
  `);
  
  result.data.allPost.nodes.forEach(post => {
    createPage({
      path: `/posts/${post.slug}`,
      component: require.resolve('./src/templates/post.js'),
      context: { id: post.id }
    });
  });
};
```

### Nuxt Static Generation

#### asyncData Pattern

```javascript
// pages/posts/_id.vue
export default {
  async asyncData({ params, $axios }) {
    const post = await $axios.$get(`https://api.example.com/posts/${params.id}`);
    return { post };
  }
};
```

#### generate Property

```javascript
// nuxt.config.js
export default {
  target: 'static',
  generate: {
    async routes() {
      const { data } = await axios.get('https://api.example.com/posts');
      return data.map(post => ({
        route: `/posts/${post.id}`,
        payload: post
      }));
    }
  }
};
```

#### Nuxt 3 useFetch

```javascript
// pages/posts/[id].vue
<script setup>
const route = useRoute();

const { data: post } = await useFetch(
  `https://api.example.com/posts/${route.params.id}`,
  {
    key: `post-${route.params.id}`
  }
);
</script>
```

#### Nuxt 3 Prerendering

```javascript
// nuxt.config.ts
export default defineNuxtConfig({
  nitro: {
    prerender: {
      crawlLinks: true,
      routes: ['/'],
      ignore: ['/api']
    }
  }
});

// server/routes/sitemap.xml.ts
export default defineEventHandler(async (event) => {
  const posts = await $fetch('https://api.example.com/posts');
  return posts.map(post => `/posts/${post.id}`);
});
```

### Remix Loaders

#### Route Loaders

```javascript
// app/routes/posts.$id.tsx
export async function loader({ params }) {
  const response = await fetch(`https://api.example.com/posts/${params.id}`);
  
  if (!response.ok) {
    throw new Response('Not Found', { status: 404 });
  }
  
  return response.json();
}

export default function Post() {
  const post = useLoaderData();
  return <article>{post.content}</article>;
}
```

#### Parallel Route Loading

```javascript
export async function loader({ params }) {
  const [post, author, comments] = await Promise.all([
    fetch(`https://api.example.com/posts/${params.id}`).then(r => r.json()),
    fetch(`https://api.example.com/authors/${params.authorId}`).then(r => r.json()),
    fetch(`https://api.example.com/posts/${params.id}/comments`).then(r => r.json())
  ]);
  
  return { post, author, comments };
}
```

#### Caching Strategy

```javascript
export async function loader({ request }) {
  const url = new URL(request.url);
  const cacheKey = `post-${url.pathname}`;
  
  // Check cache first
  const cached = await cache.get(cacheKey);
  if (cached) return cached;
  
  const response = await fetch('https://api.example.com/data');
  const data = await response.json();
  
  await cache.set(cacheKey, data, { ttl: 3600 });
  return data;
}
```

### Error Handling Patterns

#### Fallback Content

```javascript
export async function getStaticProps() {
  try {
    const res = await fetch('https://api.example.com/data', {
      signal: AbortSignal.timeout(5000)
    });
    
    if (!res.ok) throw new Error('Fetch failed');
    
    const data = await res.json();
    return { props: { data } };
  } catch (error) {
    console.error('Build-time fetch failed:', error);
    return {
      props: { data: null, error: error.message }
    };
  }
}
```

#### notFound Handling

```javascript
export async function getStaticProps({ params }) {
  const res = await fetch(`https://api.example.com/posts/${params.id}`);
  
  if (res.status === 404) {
    return { notFound: true };
  }
  
  if (!res.ok) {
    throw new Error('Failed to fetch data');
  }
  
  const post = await res.json();
  return { props: { post } };
}
```

#### Retry Logic

```javascript
async function fetchWithRetry(url, options = {}, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      const res = await fetch(url, options);
      if (res.ok) return res;
      
      if (res.status >= 500 && i < retries - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
        continue;
      }
      
      throw new Error(`HTTP ${res.status}`);
    } catch (error) {
      if (i === retries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
}

export async function getStaticProps() {
  const res = await fetchWithRetry('https://api.example.com/data');
  const data = await res.json();
  return { props: { data } };
}
```

### Optimization Patterns

#### Deduplication

```javascript
const fetchCache = new Map();

async function fetchDedupe(url, options) {
  const key = `${url}-${JSON.stringify(options)}`;
  
  if (fetchCache.has(key)) {
    return fetchCache.get(key);
  }
  
  const promise = fetch(url, options).then(r => r.json());
  fetchCache.set(key, promise);
  
  try {
    return await promise;
  } finally {
    // Clear cache after response
    setTimeout(() => fetchCache.delete(key), 0);
  }
}

export async function getStaticProps() {
  // Multiple calls to same endpoint return same promise
  const [data1, data2] = await Promise.all([
    fetchDedupe('https://api.example.com/data'),
    fetchDedupe('https://api.example.com/data')
  ]);
  
  return { props: { data: data1 } };
}
```

#### Request Batching

```javascript
class BatchFetcher {
  constructor(baseUrl, delay = 10) {
    this.baseUrl = baseUrl;
    this.delay = delay;
    this.queue = [];
    this.timer = null;
  }
  
  fetch(endpoint) {
    return new Promise((resolve, reject) => {
      this.queue.push({ endpoint, resolve, reject });
      
      if (!this.timer) {
        this.timer = setTimeout(() => this.flush(), this.delay);
      }
    });
  }
  
  async flush() {
    const batch = this.queue.splice(0);
    this.timer = null;
    
    const ids = batch.map(item => item.endpoint.split('/').pop());
    const response = await fetch(`${this.baseUrl}/batch`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ ids })
    });
    
    const results = await response.json();
    
    batch.forEach((item, index) => {
      item.resolve(results[index]);
    });
  }
}

const batcher = new BatchFetcher('https://api.example.com');

export async function getStaticPaths() {
  const ids = Array.from({ length: 100 }, (_, i) => i + 1);
  
  const posts = await Promise.all(
    ids.map(id => batcher.fetch(`/posts/${id}`))
  );
  
  return {
    paths: posts.map(post => ({ params: { id: post.id.toString() } })),
    fallback: false
  };
}
```

#### Streaming Responses

```javascript
// Next.js App Router
export async function generateStaticParams() {
  const response = await fetch('https://api.example.com/posts/stream');
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  
  const ids = [];
  let buffer = '';
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');
    buffer = lines.pop();
    
    for (const line of lines) {
      if (line.trim()) {
        const post = JSON.parse(line);
        ids.push({ id: post.id.toString() });
      }
    }
  }
  
  return ids;
}
```

### Data Revalidation Strategies

#### Stale-While-Revalidate

```javascript
export async function getStaticProps() {
  const res = await fetch('https://api.example.com/data');
  const data = await res.json();
  
  return {
    props: { data, generatedAt: Date.now() },
    revalidate: 60 // Background regeneration every 60 seconds
  };
}

// Client-side component
export default function Page({ data, generatedAt }) {
  const [currentData, setCurrentData] = useState(data);
  
  useEffect(() => {
    const age = Date.now() - generatedAt;
    
    if (age > 60000) {
      // Stale data, revalidate in background
      fetch('/api/revalidate?path=' + window.location.pathname)
        .catch(console.error);
    }
  }, [generatedAt]);
  
  return <div>{JSON.stringify(currentData)}</div>;
}
```

#### Conditional Revalidation

```javascript
export async function getStaticProps() {
  const res = await fetch('https://api.example.com/data');
  const data = await res.json();
  const etag = res.headers.get('etag');
  
  // Store etag in props
  return {
    props: { data, etag },
    revalidate: 300
  };
}

// Revalidation API route
export default async function handler(req, res) {
  const { etag, path } = req.query;
  
  const response = await fetch('https://api.example.com/data', {
    headers: { 'If-None-Match': etag }
  });
  
  if (response.status === 304) {
    // Not modified, no revalidation needed
    return res.json({ revalidated: false });
  }
  
  await res.revalidate(path);
  return res.json({ revalidated: true });
}
```

#### Time-Based Segments

```javascript
export async function getStaticProps() {
  const res = await fetch('https://api.example.com/data');
  const data = await res.json();
  
  // Different revalidation for different times of day
  const hour = new Date().getHours();
  let revalidate;
  
  if (hour >= 9 && hour <= 17) {
    revalidate = 60; // 1 minute during business hours
  } else if (hour >= 18 && hour <= 23) {
    revalidate = 300; // 5 minutes during evening
  } else {
    revalidate = 3600; // 1 hour during night
  }
  
  return {
    props: { data },
    revalidate
  };
}
```

### Build-Time Configuration

#### Environment-Based Fetching

```javascript
export async function getStaticProps() {
  const apiUrl = process.env.NODE_ENV === 'production'
    ? 'https://api.example.com'
    : 'http://localhost:3001';
  
  const res = await fetch(`${apiUrl}/data`);
  const data = await res.json();
  
  return { props: { data } };
}
```

#### Build-Time Secrets

```javascript
export async function getStaticProps() {
  const res = await fetch('https://api.example.com/data', {
    headers: {
      'Authorization': `Bearer ${process.env.BUILD_API_KEY}`,
      'X-Build-ID': process.env.BUILD_ID
    }
  });
  
  const data = await res.json();
  
  // Remove sensitive data before sending to client
  const sanitized = {
    ...data,
    apiKey: undefined,
    secret: undefined
  };
  
  return { props: { data: sanitized } };
}
```

#### Conditional Route Generation

```javascript
export async function getStaticPaths() {
  const generateAll = process.env.GENERATE_ALL_PAGES === 'true';
  
  if (!generateAll) {
    // Generate only popular pages during development
    return {
      paths: [
        { params: { id: '1' } },
        { params: { id: '2' } }
      ],
      fallback: 'blocking'
    };
  }
  
  // Full generation for production
  const res = await fetch('https://api.example.com/posts');
  const posts = await res.json();
  
  return {
    paths: posts.map(post => ({ params: { id: post.id.toString() } })),
    fallback: false
  };
}
```

---

# Real-World Patterns

## Fetch API Pagination

### Pagination Strategies

#### Offset-Based Pagination

Offset-based pagination uses `limit` and `offset` (or `skip`) parameters to navigate through pages. The offset specifies how many records to skip, while the limit defines the page size.

```javascript
async function fetchPageOffset(page, pageSize) {
  const offset = (page - 1) * pageSize;
  const response = await fetch(
    `https://api.example.com/items?limit=${pageSize}&offset=${offset}`
  );
  return response.json();
}

// Fetch multiple pages
async function fetchAllPagesOffset(pageSize) {
  const allItems = [];
  let page = 1;
  let hasMore = true;

  while (hasMore) {
    const data = await fetchPageOffset(page, pageSize);
    allItems.push(...data.items);
    hasMore = data.items.length === pageSize;
    page++;
  }

  return allItems;
}
```

**Advantages:** Simple implementation, direct page access, easy to calculate total pages.

**Disadvantages:** Performance degrades with large offsets as databases must scan and skip records. Data inconsistency occurs if items are added or deleted between requests (page drift).

#### Cursor-Based Pagination

Cursor-based pagination uses a pointer (cursor) to track position in the dataset. The cursor typically encodes the last item's identifier or timestamp.

```javascript
async function fetchPageCursor(cursor, pageSize) {
  const url = new URL('https://api.example.com/items');
  url.searchParams.set('limit', pageSize);
  if (cursor) {
    url.searchParams.set('cursor', cursor);
  }

  const response = await fetch(url);
  return response.json();
}

// Fetch all pages using cursors
async function fetchAllPagesCursor(pageSize) {
  const allItems = [];
  let cursor = null;

  while (true) {
    const data = await fetchPageCursor(cursor, pageSize);
    allItems.push(...data.items);
    
    if (!data.next_cursor) break;
    cursor = data.next_cursor;
  }

  return allItems;
}
```

**Advantages:** Consistent performance regardless of dataset size, no page drift issues, efficient for infinite scroll.

**Disadvantages:** Cannot jump to arbitrary pages, more complex implementation, cursor format varies by API.

#### Page-Based Pagination

Page-based pagination uses explicit page numbers, similar to offset-based but with a clearer semantic.

```javascript
async function fetchPage(pageNumber, pageSize) {
  const response = await fetch(
    `https://api.example.com/items?page=${pageNumber}&per_page=${pageSize}`
  );
  const data = await response.json();
  
  return {
    items: data.items,
    currentPage: data.page,
    totalPages: data.total_pages,
    totalItems: data.total
  };
}

// Navigate through pages
async function fetchPageRange(startPage, endPage, pageSize) {
  const promises = [];
  
  for (let page = startPage; page <= endPage; page++) {
    promises.push(fetchPage(page, pageSize));
  }
  
  return Promise.all(promises);
}
```

#### Keyset Pagination

Keyset pagination (also called seek method) uses the values from the last retrieved record to fetch the next set. This typically involves filtering by a unique, ordered column.

```javascript
async function fetchPageKeyset(lastId, pageSize) {
  const url = new URL('https://api.example.com/items');
  url.searchParams.set('limit', pageSize);
  if (lastId) {
    url.searchParams.set('after_id', lastId);
  }

  const response = await fetch(url);
  return response.json();
}

// Fetch with composite keys (id + timestamp)
async function fetchPageKeysetComposite(lastId, lastTimestamp, pageSize) {
  const url = new URL('https://api.example.com/items');
  url.searchParams.set('limit', pageSize);
  
  if (lastId && lastTimestamp) {
    url.searchParams.set('after_id', lastId);
    url.searchParams.set('after_timestamp', lastTimestamp);
  }

  const response = await fetch(url);
  return response.json();
}
```

**Advantages:** Excellent performance, consistent results, works well with indexes.

**Disadvantages:** Requires ordered, indexed columns, bidirectional navigation is complex.

### Advanced Pagination Patterns

#### Concurrent Page Fetching

```javascript
async function fetchMultiplePagesParallel(startPage, endPage, pageSize) {
  const pagePromises = [];
  
  for (let page = startPage; page <= endPage; page++) {
    pagePromises.push(
      fetch(`https://api.example.com/items?page=${page}&per_page=${pageSize}`)
        .then(res => res.json())
    );
  }
  
  const results = await Promise.all(pagePromises);
  return results.flatMap(result => result.items);
}

// With concurrency limit
async function fetchPagesWithLimit(totalPages, pageSize, concurrency = 5) {
  const allItems = [];
  
  for (let i = 1; i <= totalPages; i += concurrency) {
    const batch = [];
    const end = Math.min(i + concurrency - 1, totalPages);
    
    for (let page = i; page <= end; page++) {
      batch.push(
        fetch(`https://api.example.com/items?page=${page}&per_page=${pageSize}`)
          .then(res => res.json())
      );
    }
    
    const results = await Promise.all(batch);
    allItems.push(...results.flatMap(r => r.items));
  }
  
  return allItems;
}
```

#### Prefetching Next Page

```javascript
class PaginationPrefetcher {
  constructor(baseUrl, pageSize) {
    this.baseUrl = baseUrl;
    this.pageSize = pageSize;
    this.cache = new Map();
    this.prefetchPromises = new Map();
  }

  async fetchPage(page) {
    // Return from cache if available
    if (this.cache.has(page)) {
      return this.cache.get(page);
    }

    // Wait for prefetch if in progress
    if (this.prefetchPromises.has(page)) {
      return this.prefetchPromises.get(page);
    }

    // Fetch current page
    const promise = this._doFetch(page);
    this.prefetchPromises.set(page, promise);
    
    const data = await promise;
    this.cache.set(page, data);
    this.prefetchPromises.delete(page);

    // Prefetch next page
    this._prefetchPage(page + 1);

    return data;
  }

  _prefetchPage(page) {
    if (!this.cache.has(page) && !this.prefetchPromises.has(page)) {
      const promise = this._doFetch(page);
      this.prefetchPromises.set(page, promise);
      
      promise.then(data => {
        this.cache.set(page, data);
        this.prefetchPromises.delete(page);
      }).catch(() => {
        this.prefetchPromises.delete(page);
      });
    }
  }

  async _doFetch(page) {
    const response = await fetch(
      `${this.baseUrl}?page=${page}&per_page=${this.pageSize}`
    );
    return response.json();
  }
}
```

#### Infinite Scroll Implementation

```javascript
class InfiniteScrollPaginator {
  constructor(apiUrl, pageSize, container) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.container = container;
    this.currentPage = 1;
    this.loading = false;
    this.hasMore = true;
    
    this.setupIntersectionObserver();
  }

  setupIntersectionObserver() {
    const sentinel = document.createElement('div');
    sentinel.className = 'scroll-sentinel';
    this.container.appendChild(sentinel);

    this.observer = new IntersectionObserver(
      entries => {
        if (entries[0].isIntersecting && !this.loading && this.hasMore) {
          this.loadMore();
        }
      },
      { threshold: 0.1 }
    );

    this.observer.observe(sentinel);
  }

  async loadMore() {
    if (this.loading || !this.hasMore) return;

    this.loading = true;

    try {
      const response = await fetch(
        `${this.apiUrl}?page=${this.currentPage}&per_page=${this.pageSize}`
      );
      const data = await response.json();

      this.renderItems(data.items);
      this.currentPage++;
      this.hasMore = data.items.length === this.pageSize;
    } catch (error) {
      console.error('Failed to load more:', error);
    } finally {
      this.loading = false;
    }
  }

  renderItems(items) {
    // Implementation depends on UI framework
    items.forEach(item => {
      const element = this.createItemElement(item);
      this.container.insertBefore(
        element,
        this.container.querySelector('.scroll-sentinel')
      );
    });
  }
}
```

#### Bidirectional Pagination

```javascript
class BidirectionalPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
  }

  async fetchNext(cursor) {
    const url = new URL(this.apiUrl);
    url.searchParams.set('limit', this.pageSize);
    if (cursor) {
      url.searchParams.set('after', cursor);
    }

    const response = await fetch(url);
    const data = await response.json();

    return {
      items: data.items,
      nextCursor: data.next_cursor,
      prevCursor: data.items.length > 0 ? data.items[0].id : null
    };
  }

  async fetchPrevious(cursor) {
    const url = new URL(this.apiUrl);
    url.searchParams.set('limit', this.pageSize);
    url.searchParams.set('before', cursor);

    const response = await fetch(url);
    const data = await response.json();

    return {
      items: data.items.reverse(), // Often returned in reverse order
      nextCursor: data.items.length > 0 ? data.items[data.items.length - 1].id : null,
      prevCursor: data.prev_cursor
    };
  }
}
```

### Error Handling and Retry Logic

#### Retry with Exponential Backoff

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  let lastError;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return await response.json();
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries) {
        const delay = Math.min(1000 * Math.pow(2, attempt), 10000);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError;
}

// Usage in pagination
async function fetchPageWithRetry(page, pageSize) {
  const url = `https://api.example.com/items?page=${page}&per_page=${pageSize}`;
  return fetchWithRetry(url);
}
```

#### Handling Rate Limits

```javascript
class RateLimitedPaginator {
  constructor(apiUrl, pageSize, requestsPerSecond = 10) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.minInterval = 1000 / requestsPerSecond;
    this.lastRequestTime = 0;
  }

  async fetchPage(page) {
    // Throttle requests
    const now = Date.now();
    const timeSinceLastRequest = now - this.lastRequestTime;
    
    if (timeSinceLastRequest < this.minInterval) {
      await new Promise(resolve => 
        setTimeout(resolve, this.minInterval - timeSinceLastRequest)
      );
    }

    this.lastRequestTime = Date.now();

    const response = await fetch(
      `${this.apiUrl}?page=${page}&per_page=${this.pageSize}`
    );

    // Handle 429 Too Many Requests
    if (response.status === 429) {
      const retryAfter = response.headers.get('Retry-After');
      const delay = retryAfter ? parseInt(retryAfter) * 1000 : 5000;
      
      await new Promise(resolve => setTimeout(resolve, delay));
      return this.fetchPage(page); // Retry
    }

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }

    return response.json();
  }
}
```

#### Partial Failure Recovery

```javascript
async function fetchAllPagesWithRecovery(totalPages, pageSize) {
  const results = new Array(totalPages).fill(null);
  const failed = [];

  // First attempt: fetch all pages
  const promises = Array.from({ length: totalPages }, (_, i) => {
    const page = i + 1;
    return fetch(`https://api.example.com/items?page=${page}&per_page=${pageSize}`)
      .then(res => res.json())
      .then(data => {
        results[i] = data.items;
      })
      .catch(() => {
        failed.push(page);
      });
  });

  await Promise.allSettled(promises);

  // Retry failed pages
  if (failed.length > 0) {
    for (const page of failed) {
      try {
        const response = await fetch(
          `https://api.example.com/items?page=${page}&per_page=${pageSize}`
        );
        const data = await response.json();
        results[page - 1] = data.items;
      } catch (error) {
        console.error(`Failed to fetch page ${page}:`, error);
      }
    }
  }

  return results.filter(Boolean).flat();
}
```

### Response Parsing and Metadata

#### Extracting Pagination Metadata

```javascript
function parsePaginationHeaders(response) {
  const linkHeader = response.headers.get('Link');
  const totalCount = response.headers.get('X-Total-Count');
  const perPage = response.headers.get('X-Per-Page');
  const currentPage = response.headers.get('X-Page');

  const links = {};
  if (linkHeader) {
    linkHeader.split(',').forEach(link => {
      const [url, rel] = link.split(';').map(s => s.trim());
      const relMatch = rel.match(/rel="(.+)"/);
      if (relMatch) {
        links[relMatch[1]] = url.slice(1, -1); // Remove < >
      }
    });
  }

  return {
    total: totalCount ? parseInt(totalCount) : null,
    perPage: perPage ? parseInt(perPage) : null,
    currentPage: currentPage ? parseInt(currentPage) : null,
    totalPages: totalCount && perPage 
      ? Math.ceil(parseInt(totalCount) / parseInt(perPage))
      : null,
    links
  };
}

async function fetchWithMetadata(url) {
  const response = await fetch(url);
  const data = await response.json();
  const metadata = parsePaginationHeaders(response);

  return { data, metadata };
}
```

#### Link Header Parsing

```javascript
function parseNextPageUrl(response) {
  const linkHeader = response.headers.get('Link');
  if (!linkHeader) return null;

  const nextLinkMatch = linkHeader.match(/<([^>]+)>;\s*rel="next"/);
  return nextLinkMatch ? nextLinkMatch[1] : null;
}

async function fetchAllPagesFromLinks(initialUrl) {
  const allItems = [];
  let nextUrl = initialUrl;

  while (nextUrl) {
    const response = await fetch(nextUrl);
    const data = await response.json();
    
    allItems.push(...data.items);
    nextUrl = parseNextPageUrl(response);
  }

  return allItems;
}
```

#### Handling Different Response Formats

```javascript
class UniversalPaginator {
  constructor(apiUrl) {
    this.apiUrl = apiUrl;
  }

  async fetchPage(page, pageSize) {
    const response = await fetch(
      `${this.apiUrl}?page=${page}&per_page=${pageSize}`
    );
    const data = await response.json();

    // Detect format and normalize
    return this.normalizeResponse(data, response);
  }

  normalizeResponse(data, response) {
    // Format 1: { items: [], page: 1, total: 100 }
    if (data.items && Array.isArray(data.items)) {
      return {
        items: data.items,
        currentPage: data.page || data.current_page,
        totalPages: data.total_pages || data.pages,
        totalItems: data.total || data.total_count,
        hasNext: data.has_next || !!data.next_page
      };
    }

    // Format 2: { data: [], meta: { page: 1, total: 100 } }
    if (data.data && data.meta) {
      return {
        items: data.data,
        currentPage: data.meta.page || data.meta.current_page,
        totalPages: data.meta.total_pages || data.meta.pages,
        totalItems: data.meta.total || data.meta.total_count,
        hasNext: data.meta.has_next
      };
    }

    // Format 3: Array with headers
    if (Array.isArray(data)) {
      const metadata = parsePaginationHeaders(response);
      return {
        items: data,
        ...metadata,
        hasNext: !!metadata.links?.next
      };
    }

    // Format 4: { results: [], next: "url", previous: "url" }
    if (data.results) {
      return {
        items: data.results,
        nextUrl: data.next,
        previousUrl: data.previous,
        hasNext: !!data.next
      };
    }

    throw new Error('Unknown pagination format');
  }
}
```

### State Management

#### Pagination State Object

```javascript
class PaginationState {
  constructor(initialPage = 1, pageSize = 20) {
    this.currentPage = initialPage;
    this.pageSize = pageSize;
    this.totalPages = null;
    this.totalItems = null;
    this.items = [];
    this.loading = false;
    this.error = null;
    this.cursors = { next: null, prev: null };
  }

  setLoading(loading) {
    this.loading = loading;
    this.error = null;
  }

  setError(error) {
    this.loading = false;
    this.error = error;
  }

  setData(items, metadata) {
    this.items = items;
    this.totalPages = metadata.totalPages;
    this.totalItems = metadata.totalItems;
    this.cursors = metadata.cursors || this.cursors;
    this.loading = false;
    this.error = null;
  }

  nextPage() {
    if (this.hasNextPage()) {
      this.currentPage++;
      return true;
    }
    return false;
  }

  previousPage() {
    if (this.hasPreviousPage()) {
      this.currentPage--;
      return true;
    }
    return false;
  }

  goToPage(page) {
    if (page >= 1 && (!this.totalPages || page <= this.totalPages)) {
      this.currentPage = page;
      return true;
    }
    return false;
  }

  hasNextPage() {
    return !this.totalPages || this.currentPage < this.totalPages;
  }

  hasPreviousPage() {
    return this.currentPage > 1;
  }

  reset() {
    this.currentPage = 1;
    this.items = [];
    this.error = null;
  }
}
```

#### Cache Management

```javascript
class PaginationCache {
  constructor(maxSize = 50) {
    this.cache = new Map();
    this.maxSize = maxSize;
    this.accessOrder = [];
  }

  get(key) {
    if (this.cache.has(key)) {
      // Update access order
      this.accessOrder = this.accessOrder.filter(k => k !== key);
      this.accessOrder.push(key);
      return this.cache.get(key);
    }
    return null;
  }

  set(key, value) {
    // Remove oldest if at capacity
    if (this.cache.size >= this.maxSize && !this.cache.has(key)) {
      const oldest = this.accessOrder.shift();
      this.cache.delete(oldest);
    }

    this.cache.set(key, value);
    
    // Update access order
    this.accessOrder = this.accessOrder.filter(k => k !== key);
    this.accessOrder.push(key);
  }

  has(key) {
    return this.cache.has(key);
  }

  clear() {
    this.cache.clear();
    this.accessOrder = [];
  }

  getCacheKey(page, filters = {}) {
    const filterString = Object.keys(filters)
      .sort()
      .map(key => `${key}:${filters[key]}`)
      .join('|');
    return `page:${page}|${filterString}`;
  }
}

// Usage
class CachedPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.cache = new PaginationCache();
  }

  async fetchPage(page, filters = {}) {
    const cacheKey = this.cache.getCacheKey(page, filters);
    
    const cached = this.cache.get(cacheKey);
    if (cached) {
      return cached;
    }

    const url = new URL(this.apiUrl);
    url.searchParams.set('page', page);
    url.searchParams.set('per_page', this.pageSize);
    
    Object.entries(filters).forEach(([key, value]) => {
      url.searchParams.set(key, value);
    });

    const response = await fetch(url);
    const data = await response.json();

    this.cache.set(cacheKey, data);
    return data;
  }
}
```

### Performance Optimization

#### Request Deduplication

```javascript
class DeduplicatedPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.pendingRequests = new Map();
  }

  async fetchPage(page) {
    const key = `${page}`;

    // Return existing promise if request is in flight
    if (this.pendingRequests.has(key)) {
      return this.pendingRequests.get(key);
    }

    const promise = this._doFetch(page)
      .finally(() => {
        this.pendingRequests.delete(key);
      });

    this.pendingRequests.set(key, promise);
    return promise;
  }

  async _doFetch(page) {
    const response = await fetch(
      `${this.apiUrl}?page=${page}&per_page=${this.pageSize}`
    );
    return response.json();
  }
}
```

#### Batch Request Optimization

```javascript
async function fetchPagesInBatches(pageRange, pageSize, batchSize = 3) {
  const results = [];
  
  for (let i = 0; i < pageRange.length; i += batchSize) {
    const batch = pageRange.slice(i, i + batchSize);
    const batchPromises = batch.map(page =>
      fetch(`https://api.example.com/items?page=${page}&per_page=${pageSize}`)
        .then(res => res.json())
    );
    
    const batchResults = await Promise.all(batchPromises);
    results.push(...batchResults);
    
    // Optional: delay between batches
    if (i + batchSize < pageRange.length) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }
  
  return results.flatMap(r => r.items);
}
```

#### Streaming Large Datasets

```javascript
async function* streamPages(apiUrl, pageSize) {
  let page = 1;
  let hasMore = true;

  while (hasMore) {
    const response = await fetch(
      `${apiUrl}?page=${page}&per_page=${pageSize}`
    );
    const data = await response.json();

    yield data.items;

    hasMore = data.items.length === pageSize;
    page++;
  }
}

// Usage
async function processAllItems(apiUrl, pageSize) {
  for await (const items of streamPages(apiUrl, pageSize)) {
    // Process each page as it arrives
    items.forEach(item => {
      console.log(item);
    });
  }
}
```

#### Progressive Loading

```javascript
class ProgressivePaginator {
  constructor(apiUrl, pageSize, onProgress) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.onProgress = onProgress;
  }

  async fetchAll(estimatedTotal) {
    const allItems = [];
    let page = 1;
    let hasMore = true;

    while (hasMore) {
      const response = await fetch(
        `${this.apiUrl}?page=${page}&per_page=${this.pageSize}`
      );
      const data = await response.json();

      allItems.push(...data.items);
      hasMore = data.items.length === this.pageSize;

      if (this.onProgress) {
        const progress = estimatedTotal 
          ? Math.min((allItems.length / estimatedTotal) * 100, 100)
          : null;
        
        this.onProgress({
          loaded: allItems.length,
          total: estimatedTotal,
          progress,
          page
        });
      }

      page++;
    }

    return allItems;
  }
}

// Usage
const paginator = new ProgressivePaginator(
  'https://api.example.com/items',
  50,
  ({ loaded, total, progress }) => {
    console.log(`Loaded ${loaded}/${total} (${progress.toFixed(1)}%)`);
  }
);

const items = await paginator.fetchAll(1000);
```

### Filter and Sort Integration

#### Combined Pagination and Filtering

```javascript
class FilteredPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
    this.filters = {};
    this.sortBy = null;
    this.sortOrder = 'asc';
  }

  setFilters(filters) {
    this.filters = { ...filters };
    return this;
  }

  setSort(field, order = 'asc') {
    this.sortBy = field;
    this.sortOrder = order;
    return this;
  }

  async fetchPage(page) {
    const url = new URL(this.apiUrl);
    url.searchParams.set('page', page);
    url.searchParams.set('per_page', this.pageSize);

    // Add filters
    Object.entries(this.filters).forEach(([key, value]) => {
      if (value !== null && value !== undefined && value !== '') {
        url.searchParams.set(key, value);
      }
    });

    // Add sorting
    if (this.sortBy) {
      url.searchParams.set('sort', this.sortBy);
      url.searchParams.set('order', this.sortOrder);
    }

    const response = await fetch(url);
    return response.json();
  }

  clearFilters() {
    this.filters = {};
    return this;
  }
}

// Usage
const paginator = new FilteredPaginator('https://api.example.com/items', 20);
const data = await paginator
  .setFilters({ status: 'active', category: 'electronics' })
  .setSort('price', 'desc')
  .fetchPage(1);
```

#### Dynamic Query Building

```javascript
class QueryBuilder {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.params = new URLSearchParams();
  }

  page(number) {
    this.params.set('page', number);
    return this;
  }

  limit(size) {
    this.params.set('limit', size);
    return this;
  }

  filter(field, operator, value) {
    // Support different filter formats
    if (operator === 'eq') {
      this.params.set(field, value);
    } else if (operator === 'gt') {
      this.params.set(`${field}_gt`, value);
    } else if (operator === 'lt') {
      this.params.set(`${field}_lt`, value);
    } else if (operator === 'contains') {
      this.params.set(`${field}_like`, value);
    }
    return this;
  }

  sort(field, direction = 'asc') {
    const sortValue = direction === 'desc' ? `-${field}` : field;
    this.params.set('sort', sortValue);
    return this;
  }

  search(query) {
    this.params.set('q', query);
    return this;
  }

  build() {
    return `${this.baseUrl}?${this.params.toString()}`;
  }

  async fetch() {
    const url = this.build();
    const response = await fetch(url);
    return response.json();
  }
}

// Usage
const query = new QueryBuilder('https://api.example.com/items')
  .page(1)
  .limit(20)
  .filter('price', 'gt', 100)
  .filter('status', 'eq', 'available')
  .sort('created_at', 'desc')
  .search('laptop');

const data = await query.fetch();
```

### Testing Pagination

#### Mock Paginated Responses

```javascript
function createMockPaginatedApi(totalItems, pageSize) {
  const items = Array.from({ length: totalItems }, (_, i) => ({
    id: i + 1,
    name: `Item ${i + 1}`,
    value: Math.random() * 100
  }));

  return async function mockFetch(page) {
    // Simulate network delay
    await new Promise(resolve => setTimeout(resolve, 100));

    const start = (page - 1) * pageSize;
    const end = start + pageSize;
    const pageItems = items.slice(start, end);

    return {
      items: pageItems,
      page,
      per_page: pageSize,
      total: totalItems,
      total_pages: Math.ceil(totalItems / pageSize),
      has_next: end < totalItems,
      has_prev: page > 1
    };
  };
}

// Testing
const mockApi = createMockPaginatedApi(100, 10);
const page1 = await mockApi(1);
const page2 = await mockApi(2);
```

#### Testing Pagination Logic

```javascript
// Test helper for assertions
function createPaginationTester() {
  return {
    async testPageNavigation(paginator, expectedPages) {
      const results = [];
      
      for (let i = 1; i <= expectedPages; i++) {
        const data = await paginator.fetchPage(i);
        results.push(data);
        
        // Verify page numbers
        if (data.page !== i) {
          throw new Error(`Expected page ${i}, got ${data.page}`);
        }
      }
      
      return results;
    },

    async testCursorConsistency(paginator) {
      const firstPass = [];
      const secondPass = [];
      
      // First pass
      let cursor = null;
      for (let i = 0; i < 3; i++) {
        const data = await paginator.fetchPage(cursor);
        firstPass.push(...data.items);
        cursor = data.next_cursor;
        if (!cursor) break;
      }
      
      // Second pass with same cursors
      cursor = null;
      for (let i = 0; i < 3; i++) {
        const data = await paginator.fetchPage(cursor);
        secondPass.push(...data.items);
        cursor = data.next_cursor;
        if (!cursor) break;
      }
      
      // Verify consistency
      if (JSON.stringify(firstPass) !== JSON.stringify(secondPass)) {
        throw new Error('Cursor pagination returned inconsistent results');
      }
      
      return true;
    },

    async testNoDuplicates(paginator, totalPages) {
      const allIds = new Set();
      const duplicates = [];
      
      for (let page = 1; page <= totalPages; page++) {
        const data = await paginator.fetchPage(page);
        
        data.items.forEach(item => {
          if (allIds.has(item.id)) {
            duplicates.push(item.id);
          }
          allIds.add(item.id);
        });
      }
      
      if (duplicates.length > 0) {
        throw new Error(`Found duplicate IDs: ${duplicates.join(', ')}`);
      }
      
      return true;
    },

    async testNoMissingItems(paginator, expectedTotal) {
      const allItems = [];
      let page = 1;
      let hasMore = true;
      
      while (hasMore) {
        const data = await paginator.fetchPage(page);
        allItems.push(...data.items);
        hasMore = data.items.length > 0;
        page++;
        
        if (page > 1000) { // Safety limit
          throw new Error('Too many pages, possible infinite loop');
        }
      }
      
      if (allItems.length !== expectedTotal) {
        throw new Error(
          `Expected ${expectedTotal} items, got ${allItems.length}`
        );
      }
      
      return true;
    }
  };
}
```

#### Mock with Network Failures

```javascript
function createUnreliableMockApi(totalItems, pageSize, failureRate = 0.2) {
  const items = Array.from({ length: totalItems }, (_, i) => ({
    id: i + 1,
    name: `Item ${i + 1}`
  }));
  
  let requestCount = 0;

  return async function mockFetch(page) {
    requestCount++;
    
    // Simulate network delay
    await new Promise(resolve => setTimeout(resolve, 50 + Math.random() * 150));

    // Randomly fail based on failure rate
    if (Math.random() < failureRate) {
      throw new Error('Network error');
    }

    const start = (page - 1) * pageSize;
    const end = start + pageSize;
    const pageItems = items.slice(start, end);

    return {
      items: pageItems,
      page,
      per_page: pageSize,
      total: totalItems,
      total_pages: Math.ceil(totalItems / pageSize),
      request_number: requestCount
    };
  };
}

// Test retry logic
async function testRetryLogic() {
  const mockApi = createUnreliableMockApi(100, 10, 0.3);
  let successCount = 0;
  let retryCount = 0;

  async function fetchWithRetry(page, maxRetries = 3) {
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const data = await mockApi(page);
        successCount++;
        return data;
      } catch (error) {
        retryCount++;
        if (attempt === maxRetries) throw error;
        await new Promise(r => setTimeout(r, 100 * Math.pow(2, attempt)));
      }
    }
  }

  await fetchWithRetry(1);
  console.log(`Success: ${successCount}, Retries: ${retryCount}`);
}
```

#### Integration Test Example

```javascript
async function testPaginationIntegration() {
  const results = {
    passed: [],
    failed: []
  };

  const tests = [
    {
      name: 'Fetch all pages sequentially',
      fn: async () => {
        const mockApi = createMockPaginatedApi(50, 10);
        const allItems = [];
        
        for (let page = 1; page <= 5; page++) {
          const data = await mockApi(page);
          allItems.push(...data.items);
        }
        
        if (allItems.length !== 50) {
          throw new Error(`Expected 50 items, got ${allItems.length}`);
        }
      }
    },
    {
      name: 'Handle empty results',
      fn: async () => {
        const mockApi = createMockPaginatedApi(15, 10);
        const page2 = await mockApi(2);
        
        if (page2.items.length !== 5) {
          throw new Error('Second page should have 5 items');
        }
        
        if (page2.has_next) {
          throw new Error('Should not have next page');
        }
      }
    },
    {
      name: 'Concurrent page fetching',
      fn: async () => {
        const mockApi = createMockPaginatedApi(100, 10);
        
        const promises = [
          mockApi(1),
          mockApi(2),
          mockApi(3)
        ];
        
        const results = await Promise.all(promises);
        const totalItems = results.reduce((sum, r) => sum + r.items.length, 0);
        
        if (totalItems !== 30) {
          throw new Error(`Expected 30 items, got ${totalItems}`);
        }
      }
    },
    {
      name: 'Cache effectiveness',
      fn: async () => {
        const cache = new PaginationCache(10);
        let fetchCount = 0;
        
        async function cachedFetch(page) {
          const key = `page-${page}`;
          const cached = cache.get(key);
          
          if (cached) return cached;
          
          fetchCount++;
          const mockApi = createMockPaginatedApi(100, 10);
          const data = await mockApi(page);
          cache.set(key, data);
          return data;
        }
        
        await cachedFetch(1);
        await cachedFetch(1); // Should use cache
        await cachedFetch(2);
        await cachedFetch(1); // Should use cache
        
        if (fetchCount !== 2) {
          throw new Error(`Expected 2 fetches, got ${fetchCount}`);
        }
      }
    }
  ];

  for (const test of tests) {
    try {
      await test.fn();
      results.passed.push(test.name);
    } catch (error) {
      results.failed.push({ name: test.name, error: error.message });
    }
  }

  return results;
}
```

### Real-World Examples

#### GitHub API Pagination

```javascript
class GitHubPaginator {
  constructor(token) {
    this.token = token;
    this.baseUrl = 'https://api.github.com';
  }

  async fetchRepositories(username, perPage = 30) {
    const repos = [];
    let page = 1;
    let hasMore = true;

    while (hasMore) {
      const url = `${this.baseUrl}/users/${username}/repos?per_page=${perPage}&page=${page}`;
      
      const response = await fetch(url, {
        headers: {
          'Authorization': `token ${this.token}`,
          'Accept': 'application/vnd.github.v3+json'
        }
      });

      const data = await response.json();
      repos.push(...data);

      // GitHub uses Link header for pagination
      const linkHeader = response.headers.get('Link');
      hasMore = linkHeader && linkHeader.includes('rel="next"');
      page++;
    }

    return repos;
  }

  async fetchIssues(owner, repo, state = 'open') {
    const issues = [];
    const url = new URL(`${this.baseUrl}/repos/${owner}/${repo}/issues`);
    url.searchParams.set('state', state);
    url.searchParams.set('per_page', 100);

    let nextUrl = url.toString();

    while (nextUrl) {
      const response = await fetch(nextUrl, {
        headers: {
          'Authorization': `token ${this.token}`,
          'Accept': 'application/vnd.github.v3+json'
        }
      });

      const data = await response.json();
      issues.push(...data);

      // Extract next URL from Link header
      const linkHeader = response.headers.get('Link');
      nextUrl = this.parseNextUrl(linkHeader);
    }

    return issues;
  }

  parseNextUrl(linkHeader) {
    if (!linkHeader) return null;
    
    const links = linkHeader.split(',');
    const nextLink = links.find(link => link.includes('rel="next"'));
    
    if (!nextLink) return null;
    
    const match = nextLink.match(/<([^>]+)>/);
    return match ? match[1] : null;
  }
}
```

#### REST API with Cursor Pagination

```javascript
class TwitterStylePaginator {
  constructor(apiUrl, bearerToken) {
    this.apiUrl = apiUrl;
    this.bearerToken = bearerToken;
  }

  async fetchTweets(userId, maxResults = 100) {
    const allTweets = [];
    let nextToken = null;

    do {
      const url = new URL(`${this.apiUrl}/users/${userId}/tweets`);
      url.searchParams.set('max_results', Math.min(maxResults, 100));
      
      if (nextToken) {
        url.searchParams.set('pagination_token', nextToken);
      }

      const response = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${this.bearerToken}`
        }
      });

      const data = await response.json();
      
      if (data.data) {
        allTweets.push(...data.data);
      }

      nextToken = data.meta?.next_token;
      
      // Stop if we've reached desired amount
      if (allTweets.length >= maxResults) {
        break;
      }
    } while (nextToken);

    return allTweets.slice(0, maxResults);
  }

  async *streamTweets(userId) {
    let nextToken = null;

    do {
      const url = new URL(`${this.apiUrl}/users/${userId}/tweets`);
      url.searchParams.set('max_results', 100);
      
      if (nextToken) {
        url.searchParams.set('pagination_token', nextToken);
      }

      const response = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${this.bearerToken}`
        }
      });

      const data = await response.json();
      
      if (data.data) {
        yield data.data;
      }

      nextToken = data.meta?.next_token;
    } while (nextToken);
  }
}
```

#### GraphQL Pagination

```javascript
class GraphQLPaginator {
  constructor(endpoint, token) {
    this.endpoint = endpoint;
    this.token = token;
  }

  async fetchWithPagination(query, variables = {}, pageSize = 50) {
    const allResults = [];
    let hasNextPage = true;
    let endCursor = null;

    while (hasNextPage) {
      const response = await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.token}`
        },
        body: JSON.stringify({
          query,
          variables: {
            ...variables,
            first: pageSize,
            after: endCursor
          }
        })
      });

      const result = await response.json();
      
      if (result.errors) {
        throw new Error(result.errors[0].message);
      }

      const { edges, pageInfo } = result.data.repository.issues;
      
      allResults.push(...edges.map(edge => edge.node));
      
      hasNextPage = pageInfo.hasNextPage;
      endCursor = pageInfo.endCursor;
    }

    return allResults;
  }

  // Example query structure
  static ISSUES_QUERY = `
    query GetIssues($owner: String!, $name: String!, $first: Int!, $after: String) {
      repository(owner: $owner, name: $name) {
        issues(first: $first, after: $after) {
          edges {
            node {
              id
              title
              state
              createdAt
            }
            cursor
          }
          pageInfo {
            hasNextPage
            endCursor
          }
        }
      }
    }
  `;
}

// Usage
const paginator = new GraphQLPaginator('https://api.github.com/graphql', 'token');
const issues = await paginator.fetchWithPagination(
  GraphQLPaginator.ISSUES_QUERY,
  { owner: 'facebook', name: 'react' },
  100
);
```

#### Elasticsearch-Style Pagination

```javascript
class SearchPaginator {
  constructor(apiUrl) {
    this.apiUrl = apiUrl;
  }

  // Search After pagination (recommended for deep pagination)
  async searchAfter(query, searchAfter = null, size = 10) {
    const body = {
      query: {
        match: { content: query }
      },
      size,
      sort: [
        { timestamp: 'desc' },
        { _id: 'desc' }
      ]
    };

    if (searchAfter) {
      body.search_after = searchAfter;
    }

    const response = await fetch(`${this.apiUrl}/_search`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(body)
    });

    const data = await response.json();
    const hits = data.hits.hits;
    
    return {
      results: hits.map(hit => hit._source),
      nextSearchAfter: hits.length > 0 
        ? hits[hits.length - 1].sort 
        : null,
      total: data.hits.total.value
    };
  }

  async fetchAllResults(query, size = 100) {
    const allResults = [];
    let searchAfter = null;

    while (true) {
      const page = await this.searchAfter(query, searchAfter, size);
      allResults.push(...page.results);
      
      if (!page.nextSearchAfter || page.results.length < size) {
        break;
      }
      
      searchAfter = page.nextSearchAfter;
    }

    return allResults;
  }

  // From/Size pagination (for shallow pagination only)
  async fromSize(query, from = 0, size = 10) {
    const response = await fetch(`${this.apiUrl}/_search`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query: {
          match: { content: query }
        },
        from,
        size
      })
    });

    const data = await response.json();
    
    return {
      results: data.hits.hits.map(hit => hit._source),
      total: data.hits.total.value
    };
  }

  // Scroll API (for exporting large datasets)
  async initializeScroll(query, size = 1000, scrollTime = '2m') {
    const response = await fetch(
      `${this.apiUrl}/_search?scroll=${scrollTime}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: {
            match: { content: query }
          },
          size
        })
      }
    );

    const data = await response.json();
    
    return {
      scrollId: data._scroll_id,
      results: data.hits.hits.map(hit => hit._source),
      total: data.hits.total.value
    };
  }

  async continueScroll(scrollId, scrollTime = '2m') {
    const response = await fetch(`${this.apiUrl}/_search/scroll`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        scroll: scrollTime,
        scroll_id: scrollId
      })
    });

    const data = await response.json();
    
    return {
      scrollId: data._scroll_id,
      results: data.hits.hits.map(hit => hit._source)
    };
  }

  async clearScroll(scrollId) {
    await fetch(`${this.apiUrl}/_search/scroll`, {
      method: 'DELETE',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        scroll_id: scrollId
      })
    });
  }

  async exportAllData(query) {
    const allResults = [];
    const initial = await this.initializeScroll(query);
    
    allResults.push(...initial.results);
    let scrollId = initial.scrollId;

    try {
      while (true) {
        const page = await this.continueScroll(scrollId);
        
        if (page.results.length === 0) break;
        
        allResults.push(...page.results);
        scrollId = page.scrollId;
      }
    } finally {
      await this.clearScroll(scrollId);
    }

    return allResults;
  }
}
```

### Edge Cases and Gotchas

#### Handling Time-Based Pagination

```javascript
class TimeBasedPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
  }

  async fetchByTimeRange(startTime, endTime) {
    const allItems = [];
    let currentEndTime = endTime;

    while (true) {
      const url = new URL(this.apiUrl);
      url.searchParams.set('start_time', startTime);
      url.searchParams.set('end_time', currentEndTime);
      url.searchParams.set('limit', this.pageSize);
      url.searchParams.set('sort', 'desc'); // Newest first

      const response = await fetch(url);
      const data = await response.json();

      if (data.items.length === 0) break;

      allItems.push(...data.items);

      // Use oldest item's timestamp for next page
      const oldestItem = data.items[data.items.length - 1];
      currentEndTime = oldestItem.timestamp;

      // Avoid infinite loop if timestamp doesn't change
      if (data.items.length < this.pageSize) break;

      // Small delay to avoid overwhelming server
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    return allItems;
  }

  // Handle items with identical timestamps
  async fetchByTimeWithTieBreaker(startTime, endTime) {
    const allItems = [];
    const seenIds = new Set();
    let currentEndTime = endTime;
    let lastId = null;

    while (true) {
      const url = new URL(this.apiUrl);
      url.searchParams.set('start_time', startTime);
      url.searchParams.set('end_time', currentEndTime);
      url.searchParams.set('limit', this.pageSize);
      
      if (lastId) {
        url.searchParams.set('last_id', lastId);
      }

      const response = await fetch(url);
      const data = await response.json();

      if (data.items.length === 0) break;

      // Filter out duplicates
      const newItems = data.items.filter(item => !seenIds.has(item.id));
      newItems.forEach(item => seenIds.add(item.id));
      allItems.push(...newItems);

      const oldestItem = data.items[data.items.length - 1];
      currentEndTime = oldestItem.timestamp;
      lastId = oldestItem.id;

      if (data.items.length < this.pageSize) break;
    }

    return allItems;
  }
}
```

#### Handling Concurrent Modifications

```javascript
class VersionedPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
  }

  async fetchConsistentSnapshot() {
    // Get a snapshot version first
    const snapshotResponse = await fetch(`${this.apiUrl}/snapshot`);
    const { snapshot_id, total } = await snapshotResponse.json();

    const allItems = [];
    let page = 1;
    const totalPages = Math.ceil(total / this.pageSize);

    while (page <= totalPages) {
      const url = new URL(`${this.apiUrl}/items`);
      url.searchParams.set('snapshot_id', snapshot_id);
      url.searchParams.set('page', page);
      url.searchParams.set('per_page', this.pageSize);

      const response = await fetch(url);
      const data = await response.json();

      allItems.push(...data.items);
      page++;
    }

    return allItems;
  }

  // Use ETags for optimistic locking
  async fetchWithETag(page) {
    const url = `${this.apiUrl}?page=${page}&per_page=${this.pageSize}`;
    
    const response = await fetch(url);
    const etag = response.headers.get('ETag');
    const data = await response.json();

    return {
      data,
      etag,
      async refetch() {
        const refetchResponse = await fetch(url, {
          headers: { 'If-None-Match': etag }
        });

        if (refetchResponse.status === 304) {
          return { data, unchanged: true };
        }

        const newData = await refetchResponse.json();
        return { data: newData, unchanged: false };
      }
    };
  }
}
```

#### Handling Missing Pages

```javascript
async function fetchWithGapDetection(apiUrl, expectedPages, pageSize) {
  const results = new Map();
  const missing = [];

  // Fetch all pages
  const promises = Array.from({ length: expectedPages }, (_, i) => {
    const page = i + 1;
    return fetch(`${apiUrl}?page=${page}&per_page=${pageSize}`)
      .then(res => res.json())
      .then(data => results.set(page, data))
      .catch(() => missing.push(page));
  });

  await Promise.allSettled(promises);

  // Retry missing pages
  for (const page of missing) {
    try {
      const response = await fetch(
        `${apiUrl}?page=${page}&per_page=${pageSize}`
      );
      const data = await response.json();
      results.set(page, data);
    } catch (error) {
      console.error(`Failed to fetch page ${page}:`, error);
    }
  }

  // Convert to array and check for gaps
  const sortedResults = Array.from(results.entries())
    .sort(([a], [b]) => a - b)
    .map(([_, data]) => data.items)
    .flat();

  return sortedResults;
}
```

#### Handling Large Offset Performance Issues

```javascript
class HybridPaginator {
  constructor(apiUrl, pageSize) {
    this.apiUrl = apiUrl;
    this.pageSize = pageSize;
  }

  // Use offset for first few pages, switch to cursor for deep pagination
  async fetchPage(page) {
    const threshold = 10; // Switch to cursor after 10 pages

    if (page <= threshold) {
      return this.fetchWithOffset(page);
    } else {
      // Calculate cursor based on threshold
      const skipPages = threshold;
      const cursor = await this.getCursorAtPage(skipPages);
      const remainingPages = page - skipPages;
      return this.fetchWithCursor(cursor, remainingPages);
    }
  }

  async fetchWithOffset(page) {
    const offset = (page - 1) * this.pageSize;
    const url = `${this.apiUrl}?limit=${this.pageSize}&offset=${offset}`;
    
    const response = await fetch(url);
    return response.json();
  }

  async getCursorAtPage(page) {
    const offset = (page - 1) * this.pageSize;
    const url = `${this.apiUrl}?limit=1&offset=${offset}`;
    
    const response = await fetch(url);
    const data = await response.json();
    return data.items[0]?.id;
  }

  async fetchWithCursor(cursor, pagesToSkip) {
    let currentCursor = cursor;
    
    // Skip pages using cursor
    for (let i = 0; i < pagesToSkip; i++) {
      const response = await fetch(
        `${this.apiUrl}?limit=${this.pageSize}&cursor=${currentCursor}`
      );
      const data = await response.json();
      currentCursor = data.next_cursor;
    }

    // Fetch target page
    const response = await fetch(
      `${this.apiUrl}?limit=${this.pageSize}&cursor=${currentCursor}`
    );
    return response.json();
  }
}
```

---

## Infinite Scroll with Fetch API

### Core Implementation Pattern

Infinite scroll monitors the viewport and scroll position to trigger data fetching when users approach the content boundary. The fundamental pattern involves three components: scroll detection, fetch execution, and DOM manipulation.

```javascript
let page = 1;
let loading = false;
let hasMore = true;

async function loadMore() {
  if (loading || !hasMore) return;
  
  loading = true;
  try {
    const response = await fetch(`/api/items?page=${page}&limit=20`);
    const data = await response.json();
    
    if (data.items.length === 0) {
      hasMore = false;
      return;
    }
    
    appendItems(data.items);
    page++;
  } catch (error) {
    handleError(error);
  } finally {
    loading = false;
  }
}
```

### Scroll Detection Strategies

#### Threshold-Based Detection

Calculate remaining scroll distance and trigger when crossing a threshold:

```javascript
function checkScroll() {
  const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
  const windowHeight = window.innerHeight;
  const documentHeight = document.documentElement.scrollHeight;
  
  const distanceFromBottom = documentHeight - (scrollTop + windowHeight);
  const threshold = 300; // pixels from bottom
  
  if (distanceFromBottom < threshold) {
    loadMore();
  }
}

window.addEventListener('scroll', checkScroll);
```

#### Intersection Observer Approach

Modern, performant method using a sentinel element:

```javascript
const sentinel = document.querySelector('#sentinel');
let observer;

function initIntersectionObserver() {
  observer = new IntersectionObserver(
    (entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          loadMore();
        }
      });
    },
    {
      root: null, // viewport
      rootMargin: '200px', // trigger 200px before sentinel visible
      threshold: 0
    }
  );
  
  observer.observe(sentinel);
}
```

### Debouncing and Throttling

Prevent excessive fetch calls during rapid scrolling:

```javascript
// Throttle approach
function throttle(func, delay) {
  let lastCall = 0;
  return function(...args) {
    const now = Date.now();
    if (now - lastCall >= delay) {
      lastCall = now;
      func(...args);
    }
  };
}

const throttledCheck = throttle(checkScroll, 200);
window.addEventListener('scroll', throttledCheck);

// Debounce approach
function debounce(func, delay) {
  let timeoutId;
  return function(...args) {
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => func(...args), delay);
  };
}
```

### State Management

Maintain application state to prevent race conditions and duplicate requests:

```javascript
class InfiniteScrollManager {
  constructor(apiEndpoint, container) {
    this.apiEndpoint = apiEndpoint;
    this.container = container;
    this.page = 1;
    this.loading = false;
    this.hasMore = true;
    this.abortController = null;
  }
  
  async fetchPage() {
    if (this.loading || !this.hasMore) return;
    
    // Cancel previous request if still pending
    if (this.abortController) {
      this.abortController.abort();
    }
    
    this.abortController = new AbortController();
    this.loading = true;
    this.showLoader();
    
    try {
      const response = await fetch(
        `${this.apiEndpoint}?page=${this.page}&limit=20`,
        { signal: this.abortController.signal }
      );
      
      if (!response.ok) throw new Error(`HTTP ${response.status}`);
      
      const data = await response.json();
      
      if (data.items.length === 0 || data.items.length < 20) {
        this.hasMore = false;
      }
      
      this.renderItems(data.items);
      this.page++;
    } catch (error) {
      if (error.name !== 'AbortError') {
        this.handleError(error);
      }
    } finally {
      this.loading = false;
      this.hideLoader();
      this.abortController = null;
    }
  }
  
  reset() {
    this.page = 1;
    this.hasMore = true;
    this.loading = false;
    this.container.innerHTML = '';
  }
}
```

### Pagination Strategies

#### Offset-Based Pagination

```javascript
// Client side
const limit = 20;
const offset = (page - 1) * limit;
const url = `/api/items?limit=${limit}&offset=${offset}`;

// Common API response structure
{
  items: [...],
  total: 1000,
  limit: 20,
  offset: 40,
  hasMore: true
}
```

#### Cursor-Based Pagination

More reliable for real-time data where items may be added/removed:

```javascript
let cursor = null;

async function fetchWithCursor() {
  const url = cursor 
    ? `/api/items?cursor=${cursor}&limit=20`
    : `/api/items?limit=20`;
  
  const response = await fetch(url);
  const data = await response.json();
  
  cursor = data.nextCursor; // null when no more data
  hasMore = data.nextCursor !== null;
  
  return data.items;
}

// Typical cursor response
{
  items: [...],
  nextCursor: "eyJpZCI6MTAwLCJ0aW1lc3RhbXAiOjE2MzI0....",
  hasMore: true
}
```

### Error Handling and Retry Logic

```javascript
class RetryableFetch {
  constructor(maxRetries = 3, baseDelay = 1000) {
    this.maxRetries = maxRetries;
    this.baseDelay = baseDelay;
  }
  
  async fetchWithRetry(url, options = {}, attempt = 1) {
    try {
      const response = await fetch(url, options);
      
      if (!response.ok) {
        if (response.status >= 500 && attempt < this.maxRetries) {
          // Server error, retry with exponential backoff
          const delay = this.baseDelay * Math.pow(2, attempt - 1);
          await this.sleep(delay);
          return this.fetchWithRetry(url, options, attempt + 1);
        }
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return response;
    } catch (error) {
      if (attempt < this.maxRetries && this.isNetworkError(error)) {
        const delay = this.baseDelay * Math.pow(2, attempt - 1);
        await this.sleep(delay);
        return this.fetchWithRetry(url, options, attempt + 1);
      }
      throw error;
    }
  }
  
  isNetworkError(error) {
    return error.name === 'TypeError' || error.message.includes('fetch');
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Usage
const retryFetch = new RetryableFetch(3, 1000);
const response = await retryFetch.fetchWithRetry('/api/items?page=5');
```

### Performance Optimization

#### Request Deduplication

Prevent multiple simultaneous requests for the same data:

```javascript
class RequestCache {
  constructor() {
    this.pending = new Map();
  }
  
  async fetch(url, options) {
    const key = `${url}-${JSON.stringify(options)}`;
    
    if (this.pending.has(key)) {
      return this.pending.get(key);
    }
    
    const promise = fetch(url, options)
      .then(response => response.json())
      .finally(() => {
        this.pending.delete(key);
      });
    
    this.pending.set(key, promise);
    return promise;
  }
}
```

#### Virtual Scrolling Integration

For massive datasets, combine infinite scroll with virtual scrolling:

```javascript
class VirtualInfiniteScroll {
  constructor(container, itemHeight, bufferSize = 10) {
    this.container = container;
    this.itemHeight = itemHeight;
    this.bufferSize = bufferSize;
    this.items = [];
    this.visibleStart = 0;
    this.visibleEnd = 0;
  }
  
  calculateVisibleRange() {
    const scrollTop = this.container.scrollTop;
    const viewportHeight = this.container.clientHeight;
    
    this.visibleStart = Math.max(0, 
      Math.floor(scrollTop / this.itemHeight) - this.bufferSize
    );
    this.visibleEnd = Math.min(
      this.items.length,
      Math.ceil((scrollTop + viewportHeight) / this.itemHeight) + this.bufferSize
    );
  }
  
  render() {
    this.calculateVisibleRange();
    const visibleItems = this.items.slice(this.visibleStart, this.visibleEnd);
    
    // Set container height for scrollbar
    this.container.style.height = `${this.items.length * this.itemHeight}px`;
    
    // Offset visible items
    const offset = this.visibleStart * this.itemHeight;
    // Render visibleItems with offset...
  }
  
  shouldLoadMore() {
    const scrollBottom = this.container.scrollTop + this.container.clientHeight;
    const totalHeight = this.items.length * this.itemHeight;
    return totalHeight - scrollBottom < this.itemHeight * 5;
  }
}
```

### Loading States and UI Feedback

```javascript
class LoadingStateManager {
  constructor() {
    this.loader = document.querySelector('.loader');
    this.endMessage = document.querySelector('.end-message');
    this.errorMessage = document.querySelector('.error-message');
  }
  
  showLoader() {
    this.loader.classList.add('active');
    this.hideError();
    this.hideEndMessage();
  }
  
  hideLoader() {
    this.loader.classList.remove('active');
  }
  
  showEndMessage() {
    this.hideLoader();
    this.endMessage.classList.add('visible');
  }
  
  showError(message) {
    this.hideLoader();
    this.errorMessage.textContent = message;
    this.errorMessage.classList.add('visible');
  }
  
  hideError() {
    this.errorMessage.classList.remove('visible');
  }
  
  hideEndMessage() {
    this.endMessage.classList.remove('visible');
  }
}
```

### Skeleton Loading Pattern

Display placeholder content while fetching:

```javascript
function renderSkeletons(count = 5) {
  const container = document.querySelector('.items-container');
  const fragment = document.createDocumentFragment();
  
  for (let i = 0; i < count; i++) {
    const skeleton = document.createElement('div');
    skeleton.className = 'skeleton-item';
    skeleton.innerHTML = `
      <div class="skeleton-avatar"></div>
      <div class="skeleton-text"></div>
      <div class="skeleton-text short"></div>
    `;
    fragment.appendChild(skeleton);
  }
  
  container.appendChild(fragment);
}

function removeSkeletons() {
  document.querySelectorAll('.skeleton-item').forEach(el => el.remove());
}

// In loadMore function
async function loadMore() {
  renderSkeletons();
  try {
    const data = await fetchData();
    removeSkeletons();
    renderItems(data);
  } catch (error) {
    removeSkeletons();
    handleError(error);
  }
}
```

### Prefetching Strategy

Anticipate user behavior and preload next page:

```javascript
class PrefetchManager {
  constructor(prefetchThreshold = 2) {
    this.prefetchThreshold = prefetchThreshold; // pages ahead
    this.prefetchedData = new Map();
  }
  
  async prefetch(page) {
    if (this.prefetchedData.has(page)) return;
    
    try {
      const response = await fetch(`/api/items?page=${page}&limit=20`);
      const data = await response.json();
      this.prefetchedData.set(page, data);
      
      // Clean old cached data
      if (this.prefetchedData.size > 5) {
        const oldestKey = this.prefetchedData.keys().next().value;
        this.prefetchedData.delete(oldestKey);
      }
    } catch (error) {
      console.warn(`Prefetch failed for page ${page}`, error);
    }
  }
  
  async getPage(page) {
    // Trigger prefetch of next page
    this.prefetch(page + this.prefetchThreshold);
    
    if (this.prefetchedData.has(page)) {
      const data = this.prefetchedData.get(page);
      this.prefetchedData.delete(page);
      return data;
    }
    
    // Fallback to normal fetch
    const response = await fetch(`/api/items?page=${page}&limit=20`);
    return response.json();
  }
}
```

### Abort and Cleanup

Properly cancel requests when component unmounts or user navigates:

```javascript
class InfiniteScrollController {
  constructor() {
    this.abortController = null;
    this.observer = null;
  }
  
  async load() {
    // Abort previous request
    this.abort();
    
    this.abortController = new AbortController();
    
    try {
      const response = await fetch('/api/items', {
        signal: this.abortController.signal
      });
      // Process response...
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Request cancelled');
        return;
      }
      throw error;
    }
  }
  
  abort() {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
  }
  
  destroy() {
    this.abort();
    
    if (this.observer) {
      this.observer.disconnect();
      this.observer = null;
    }
    
    window.removeEventListener('scroll', this.scrollHandler);
  }
}

// Usage
const controller = new InfiniteScrollController();

// When navigating away or unmounting
controller.destroy();
```

### Handling Network Conditions

Adapt behavior based on connection quality:

```javascript
class AdaptiveInfiniteScroll {
  constructor() {
    this.connection = navigator.connection || navigator.mozConnection || navigator.webkitConnection;
    this.itemsPerPage = this.getOptimalPageSize();
  }
  
  getOptimalPageSize() {
    if (!this.connection) return 20;
    
    const effectiveType = this.connection.effectiveType;
    
    switch (effectiveType) {
      case 'slow-2g':
      case '2g':
        return 5;
      case '3g':
        return 10;
      case '4g':
        return 20;
      default:
        return 20;
    }
  }
  
  updatePageSize() {
    this.itemsPerPage = this.getOptimalPageSize();
  }
  
  init() {
    if (this.connection) {
      this.connection.addEventListener('change', () => {
        this.updatePageSize();
      });
    }
  }
  
  async fetchItems(page) {
    const url = `/api/items?page=${page}&limit=${this.itemsPerPage}`;
    const response = await fetch(url);
    return response.json();
  }
}
```

### Data Synchronization

Handle real-time updates while maintaining scroll position:

```javascript
class SyncedInfiniteScroll {
  constructor() {
    this.items = [];
    this.newItemsQueue = [];
    this.syncInterval = null;
  }
  
  startSync(intervalMs = 30000) {
    this.syncInterval = setInterval(() => {
      this.checkForNewItems();
    }, intervalMs);
  }
  
  async checkForNewItems() {
    const latestId = this.items[0]?.id;
    if (!latestId) return;
    
    const response = await fetch(`/api/items/since/${latestId}`);
    const newItems = await response.json();
    
    if (newItems.length > 0) {
      this.newItemsQueue.push(...newItems);
      this.showNewItemsNotification(newItems.length);
    }
  }
  
  showNewItemsNotification(count) {
    const notification = document.createElement('div');
    notification.className = 'new-items-notification';
    notification.textContent = `${count} new items available`;
    notification.onclick = () => this.prependNewItems();
    document.body.appendChild(notification);
  }
  
  prependNewItems() {
    if (this.newItemsQueue.length === 0) return;
    
    // Save scroll position
    const scrollTop = window.pageYOffset;
    const firstItem = document.querySelector('.item');
    const firstItemOffset = firstItem?.offsetTop || 0;
    
    // Prepend items
    this.items.unshift(...this.newItemsQueue);
    this.renderItems(this.newItemsQueue, 'prepend');
    
    // Restore scroll position
    const newOffset = firstItem?.offsetTop || 0;
    window.scrollTo(0, scrollTop + (newOffset - firstItemOffset));
    
    this.newItemsQueue = [];
  }
  
  stopSync() {
    if (this.syncInterval) {
      clearInterval(this.syncInterval);
      this.syncInterval = null;
    }
  }
}
```

### Memory Management

Prevent memory leaks with large datasets:

```javascript
class MemoryEfficientScroll {
  constructor(maxItems = 200) {
    this.maxItems = maxItems;
    this.items = [];
    this.removedCount = 0;
  }
  
  addItems(newItems) {
    this.items.push(...newItems);
    
    // Remove old items if exceeding limit
    if (this.items.length > this.maxItems) {
      const removeCount = this.items.length - this.maxItems;
      this.items.splice(0, removeCount);
      this.removedCount += removeCount;
      
      // Remove corresponding DOM elements
      this.removeOldDOMElements(removeCount);
    }
  }
  
  removeOldDOMElements(count) {
    const container = document.querySelector('.items-container');
    const elements = container.querySelectorAll('.item');
    
    for (let i = 0; i < count && i < elements.length; i++) {
      elements[i].remove();
    }
  }
  
  getTotalItemCount() {
    return this.removedCount + this.items.length;
  }
}
```

### Accessibility Considerations

Announce loading states to screen readers:

```javascript
class AccessibleInfiniteScroll {
  constructor() {
    this.liveRegion = this.createLiveRegion();
  }
  
  createLiveRegion() {
    const region = document.createElement('div');
    region.setAttribute('role', 'status');
    region.setAttribute('aria-live', 'polite');
    region.setAttribute('aria-atomic', 'true');
    region.className = 'sr-only';
    document.body.appendChild(region);
    return region;
  }
  
  announce(message) {
    this.liveRegion.textContent = message;
  }
  
  async loadMore() {
    this.announce('Loading more items');
    
    try {
      const data = await fetchData();
      this.renderItems(data);
      this.announce(`Loaded ${data.length} more items. ${this.getTotalCount()} items total.`);
    } catch (error) {
      this.announce('Failed to load more items. Please try again.');
    }
  }
  
  setupKeyboardNavigation() {
    // Allow keyboard users to trigger load more
    const loadButton = document.createElement('button');
    loadButton.textContent = 'Load more items';
    loadButton.onclick = () => this.loadMore();
    loadButton.className = 'load-more-button';
    document.querySelector('.container').appendChild(loadButton);
  }
}
```

### Complete Implementation Example

```javascript
class InfiniteScrollImplementation {
  constructor(config) {
    this.apiEndpoint = config.apiEndpoint;
    this.container = document.querySelector(config.container);
    this.itemRenderer = config.itemRenderer;
    
    // State
    this.page = 1;
    this.loading = false;
    this.hasMore = true;
    this.items = [];
    
    // Controllers
    this.abortController = null;
    this.observer = null;
    
    // Configuration
    this.pageSize = config.pageSize || 20;
    this.prefetchThreshold = config.prefetchThreshold || 200;
    
    this.init();
  }
  
  init() {
    this.setupIntersectionObserver();
    this.loadInitialData();
  }
  
  setupIntersectionObserver() {
    const sentinel = document.createElement('div');
    sentinel.className = 'scroll-sentinel';
    this.container.appendChild(sentinel);
    
    this.observer = new IntersectionObserver(
      (entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting && !this.loading && this.hasMore) {
            this.loadMore();
          }
        });
      },
      {
        root: null,
        rootMargin: `${this.prefetchThreshold}px`,
        threshold: 0
      }
    );
    
    this.observer.observe(sentinel);
  }
  
  async loadInitialData() {
    await this.loadMore();
  }
  
  async loadMore() {
    if (this.loading || !this.hasMore) return;
    
    this.loading = true;
    this.showLoader();
    
    if (this.abortController) {
      this.abortController.abort();
    }
    this.abortController = new AbortController();
    
    try {
      const response = await fetch(
        `${this.apiEndpoint}?page=${this.page}&limit=${this.pageSize}`,
        { signal: this.abortController.signal }
      );
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.items.length === 0) {
        this.hasMore = false;
        this.showEndMessage();
        return;
      }
      
      if (data.items.length < this.pageSize) {
        this.hasMore = false;
      }
      
      this.items.push(...data.items);
      this.renderItems(data.items);
      this.page++;
      
    } catch (error) {
      if (error.name !== 'AbortError') {
        this.handleError(error);
      }
    } finally {
      this.loading = false;
      this.hideLoader();
      this.abortController = null;
    }
  }
  
  renderItems(items) {
    const fragment = document.createDocumentFragment();
    
    items.forEach(item => {
      const element = this.itemRenderer(item);
      fragment.appendChild(element);
    });
    
    const sentinel = this.container.querySelector('.scroll-sentinel');
    this.container.insertBefore(fragment, sentinel);
  }
  
  showLoader() {
    const loader = this.container.querySelector('.loader');
    if (loader) loader.classList.add('active');
  }
  
  hideLoader() {
    const loader = this.container.querySelector('.loader');
    if (loader) loader.classList.remove('active');
  }
  
  showEndMessage() {
    const message = document.createElement('div');
    message.className = 'end-message';
    message.textContent = 'No more items to load';
    const sentinel = this.container.querySelector('.scroll-sentinel');
    this.container.insertBefore(message, sentinel);
  }
  
  handleError(error) {
    console.error('Failed to load items:', error);
    const errorEl = document.createElement('div');
    errorEl.className = 'error-message';
    errorEl.textContent = 'Failed to load items. Click to retry.';
    errorEl.onclick = () => {
      errorEl.remove();
      this.loadMore();
    };
    const sentinel = this.container.querySelector('.scroll-sentinel');
    this.container.insertBefore(errorEl, sentinel);
  }
  
  reset() {
    this.page = 1;
    this.loading = false;
    this.hasMore = true;
    this.items = [];
    
    // Clear container except sentinel
    const sentinel = this.container.querySelector('.scroll-sentinel');
    this.container.innerHTML = '';
    this.container.appendChild(sentinel);
    
    this.loadMore();
  }
  
  destroy() {
    if (this.abortController) {
      this.abortController.abort();
    }
    
    if (this.observer) {
      this.observer.disconnect();
    }
  }
}

// Usage
const infiniteScroll = new InfiniteScrollImplementation({
  apiEndpoint: '/api/items',
  container: '.items-container',
  pageSize: 20,
  prefetchThreshold: 200,
  itemRenderer: (item) => {
    const div = document.createElement('div');
    div.className = 'item';
    div.innerHTML = `
      <h3>${item.title}</h3>
      <p>${item.description}</p>
    `;
    return div;
  }
});
```

---

## Search and Filtering with Fetch API

### Query Parameters

Query parameters encode search and filter criteria in the URL. Multiple approaches exist for building query strings:

```javascript
// Manual string concatenation
const searchTerm = 'javascript';
const category = 'tutorials';
fetch(`/api/posts?search=${searchTerm}&category=${category}`);

// URLSearchParams for complex queries
const params = new URLSearchParams({
  search: 'javascript',
  category: 'tutorials',
  sort: 'date',
  order: 'desc'
});
fetch(`/api/posts?${params.toString()}`);

// Building from existing URL
const url = new URL('https://api.example.com/posts');
url.searchParams.append('search', 'javascript');
url.searchParams.append('tags', 'web');
url.searchParams.append('tags', 'frontend'); // Multiple values
fetch(url);
```

### Encoding Special Characters

URLSearchParams automatically handles encoding, but manual encoding may be needed:

```javascript
const query = 'search term with spaces & special!';
const encoded = encodeURIComponent(query);
fetch(`/api/search?q=${encoded}`);

// URLSearchParams handles this automatically
const params = new URLSearchParams({ q: query });
fetch(`/api/search?${params}`); // Properly encoded
```

### Array and Object Parameters

Different APIs expect different formats for complex parameters:

```javascript
// Array as repeated parameters (most common)
const tags = ['javascript', 'react', 'typescript'];
const params = new URLSearchParams();
tags.forEach(tag => params.append('tags', tag));
// Result: ?tags=javascript&tags=react&tags=typescript

// Array as comma-separated
const tagsParam = tags.join(',');
fetch(`/api/posts?tags=${tagsParam}`);
// Result: ?tags=javascript,react,typescript

// Array with bracket notation
tags.forEach((tag, i) => params.append(`tags[${i}]`, tag));
// Result: ?tags[0]=javascript&tags[1]=react&tags[2]=typescript

// Nested objects (JSON in query string)
const filters = {
  author: { name: 'John', verified: true },
  date: { from: '2024-01-01', to: '2024-12-31' }
};
const params = new URLSearchParams({
  filters: JSON.stringify(filters)
});
```

### Range Filters

Numerical and date ranges are common filtering patterns:

```javascript
// Date ranges
const params = new URLSearchParams({
  startDate: '2024-01-01',
  endDate: '2024-12-31',
  minPrice: '10',
  maxPrice: '100'
});

// Using comparison operators (API-dependent)
const params = new URLSearchParams({
  'price[gte]': '10',  // greater than or equal
  'price[lte]': '100', // less than or equal
  'date[gt]': '2024-01-01'
});

// ISO date strings for timestamps
const startDate = new Date('2024-01-01').toISOString();
const params = new URLSearchParams({ created_after: startDate });
```

### Pagination with Search

Combining pagination with search and filters:

```javascript
async function fetchPagedResults(page = 1, filters = {}) {
  const params = new URLSearchParams({
    page: page,
    limit: 20,
    ...filters
  });
  
  const response = await fetch(`/api/posts?${params}`);
  const data = await response.json();
  
  return {
    results: data.results,
    totalPages: data.totalPages,
    currentPage: data.page,
    hasNext: data.hasNext
  };
}

// Usage
const results = await fetchPagedResults(1, {
  search: 'javascript',
  category: 'tutorials',
  sort: 'date'
});
```

### Debouncing Search Requests

Avoid excessive requests during user input:

```javascript
let searchTimeout;

function debounceSearch(query, delay = 300) {
  clearTimeout(searchTimeout);
  
  return new Promise((resolve) => {
    searchTimeout = setTimeout(async () => {
      const params = new URLSearchParams({ q: query });
      const response = await fetch(`/api/search?${params}`);
      const data = await response.json();
      resolve(data);
    }, delay);
  });
}

// Usage with input event
searchInput.addEventListener('input', async (e) => {
  const results = await debounceSearch(e.target.value);
  displayResults(results);
});
```

### AbortController for Search Cancellation

Cancel in-flight requests when new searches begin:

```javascript
let currentController = null;

async function search(query) {
  // Cancel previous request
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  
  try {
    const params = new URLSearchParams({ q: query });
    const response = await fetch(`/api/search?${params}`, {
      signal: currentController.signal
    });
    
    const data = await response.json();
    return data;
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Search cancelled');
      return null;
    }
    throw error;
  }
}

// Usage
searchInput.addEventListener('input', async (e) => {
  const results = await search(e.target.value);
  if (results) {
    displayResults(results);
  }
});
```

### Combining Debounce and Abort

Optimize search performance with both techniques:

```javascript
class SearchManager {
  constructor(delay = 300) {
    this.delay = delay;
    this.timeout = null;
    this.controller = null;
  }
  
  async search(query) {
    // Clear existing timeout
    clearTimeout(this.timeout);
    
    // Cancel existing request
    if (this.controller) {
      this.controller.abort();
    }
    
    return new Promise((resolve, reject) => {
      this.timeout = setTimeout(async () => {
        this.controller = new AbortController();
        
        try {
          const params = new URLSearchParams({ q: query });
          const response = await fetch(`/api/search?${params}`, {
            signal: this.controller.signal
          });
          
          const data = await response.json();
          resolve(data);
        } catch (error) {
          if (error.name === 'AbortError') {
            resolve(null);
          } else {
            reject(error);
          }
        }
      }, this.delay);
    });
  }
}

// Usage
const searchManager = new SearchManager();
searchInput.addEventListener('input', async (e) => {
  const results = await searchManager.search(e.target.value);
  if (results) {
    displayResults(results);
  }
});
```

### Filter State Management

Maintain filter state across multiple requests:

```javascript
class FilterManager {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.filters = new Map();
  }
  
  setFilter(key, value) {
    if (value === null || value === undefined || value === '') {
      this.filters.delete(key);
    } else {
      this.filters.set(key, value);
    }
  }
  
  setFilters(filters) {
    Object.entries(filters).forEach(([key, value]) => {
      this.setFilter(key, value);
    });
  }
  
  clearFilter(key) {
    this.filters.delete(key);
  }
  
  clearAll() {
    this.filters.clear();
  }
  
  getUrl() {
    const url = new URL(this.baseUrl);
    this.filters.forEach((value, key) => {
      if (Array.isArray(value)) {
        value.forEach(v => url.searchParams.append(key, v));
      } else {
        url.searchParams.append(key, value);
      }
    });
    return url;
  }
  
  async fetch(options = {}) {
    const response = await fetch(this.getUrl(), options);
    return response.json();
  }
}

// Usage
const filters = new FilterManager('https://api.example.com/posts');
filters.setFilter('category', 'tutorials');
filters.setFilter('tags', ['javascript', 'react']);
filters.setFilter('minPrice', 10);

const results = await filters.fetch();
```

### Server-Side Search Patterns

POST requests for complex search criteria:

```javascript
// GET with query params (simple searches)
async function simpleSearch(query) {
  const params = new URLSearchParams({ q: query });
  const response = await fetch(`/api/search?${params}`);
  return response.json();
}

// POST with request body (complex searches)
async function advancedSearch(criteria) {
  const response = await fetch('/api/search', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      query: criteria.query,
      filters: {
        categories: criteria.categories,
        dateRange: {
          start: criteria.startDate,
          end: criteria.endDate
        },
        price: {
          min: criteria.minPrice,
          max: criteria.maxPrice
        }
      },
      sort: criteria.sortBy,
      page: criteria.page,
      limit: criteria.limit
    })
  });
  
  return response.json();
}
```

### Full-Text Search Parameters

Common patterns for full-text search APIs:

```javascript
// Basic full-text search
const params = new URLSearchParams({
  q: 'javascript tutorials',
  fields: 'title,content,tags' // Fields to search
});

// Fuzzy matching and wildcards
const params = new URLSearchParams({
  q: 'javascrpt~2', // Allow 2 character edits
  wildcard: 'java*' // Wildcard search
});

// Boolean operators (API-dependent)
const params = new URLSearchParams({
  q: 'javascript AND (react OR vue) NOT angular'
});

// Phrase search
const params = new URLSearchParams({
  q: '"modern javascript"' // Exact phrase
});

// Highlighting results
const params = new URLSearchParams({
  q: 'javascript',
  highlight: 'true',
  highlight_fields: 'title,content'
});
```

### Faceted Search

Retrieve aggregated filter options alongside results:

```javascript
async function facetedSearch(query) {
  const params = new URLSearchParams({
    q: query,
    facets: 'category,author,tags,year'
  });
  
  const response = await fetch(`/api/search?${params}`);
  const data = await response.json();
  
  return {
    results: data.results,
    facets: {
      categories: data.facets.category, // [{value: 'tutorials', count: 45}, ...]
      authors: data.facets.author,
      tags: data.facets.tags,
      years: data.facets.year
    },
    total: data.total
  };
}

// Applying facet filters
async function searchWithFacets(query, selectedFacets) {
  const params = new URLSearchParams({ q: query });
  
  Object.entries(selectedFacets).forEach(([facet, values]) => {
    if (Array.isArray(values)) {
      values.forEach(v => params.append(facet, v));
    } else {
      params.append(facet, values);
    }
  });
  
  const response = await fetch(`/api/search?${params}`);
  return response.json();
}
```

### Sorting Results

Apply sorting to filtered results:

```javascript
// Single sort field
const params = new URLSearchParams({
  search: 'javascript',
  sort: 'date',
  order: 'desc'
});

// Multiple sort fields
const params = new URLSearchParams({
  search: 'javascript',
  sort: 'relevance,date',
  order: 'desc,desc'
});

// API-specific sort syntax
const params = new URLSearchParams({
  search: 'javascript',
  sort: '-date,+title' // - for desc, + for asc
});

// Dynamic sorting
function buildSortParams(sortFields) {
  const params = new URLSearchParams();
  sortFields.forEach(({ field, direction }) => {
    params.append('sort', `${field}:${direction}`);
  });
  return params;
}

const sortParams = buildSortParams([
  { field: 'relevance', direction: 'desc' },
  { field: 'date', direction: 'desc' }
]);
```

### Caching Search Results

Reduce redundant requests with client-side caching:

```javascript
class SearchCache {
  constructor(ttl = 5 * 60 * 1000) { // 5 minutes default
    this.cache = new Map();
    this.ttl = ttl;
  }
  
  getCacheKey(url, options) {
    return `${url}-${JSON.stringify(options)}`;
  }
  
  get(url, options) {
    const key = this.getCacheKey(url, options);
    const cached = this.cache.get(key);
    
    if (!cached) return null;
    
    if (Date.now() - cached.timestamp > this.ttl) {
      this.cache.delete(key);
      return null;
    }
    
    return cached.data;
  }
  
  set(url, options, data) {
    const key = this.getCacheKey(url, options);
    this.cache.set(key, {
      data,
      timestamp: Date.now()
    });
  }
  
  clear() {
    this.cache.clear();
  }
  
  async fetch(url, options = {}) {
    const cached = this.get(url, options);
    if (cached) {
      return cached;
    }
    
    const response = await fetch(url, options);
    const data = await response.json();
    
    this.set(url, options, data);
    return data;
  }
}

// Usage
const searchCache = new SearchCache();
const results = await searchCache.fetch('/api/search?q=javascript');
```

### URL State Synchronization

Keep search state in sync with browser URL:

```javascript
class SearchStateManager {
  constructor() {
    this.params = new URLSearchParams(window.location.search);
    
    // Listen to back/forward navigation
    window.addEventListener('popstate', () => {
      this.params = new URLSearchParams(window.location.search);
      this.onStateChange();
    });
  }
  
  updateParam(key, value) {
    if (value === null || value === undefined || value === '') {
      this.params.delete(key);
    } else {
      this.params.set(key, value);
    }
    this.updateUrl();
  }
  
  updateParams(updates) {
    Object.entries(updates).forEach(([key, value]) => {
      this.updateParam(key, value);
    });
  }
  
  getParam(key) {
    return this.params.get(key);
  }
  
  getAllParams() {
    return Object.fromEntries(this.params);
  }
  
  updateUrl() {
    const url = new URL(window.location);
    url.search = this.params.toString();
    window.history.pushState({}, '', url);
    this.onStateChange();
  }
  
  async onStateChange() {
    // Override this method to perform search when state changes
    const results = await this.performSearch();
    this.displayResults(results);
  }
  
  async performSearch() {
    const response = await fetch(`/api/search?${this.params}`);
    return response.json();
  }
  
  displayResults(results) {
    // Override to display results
  }
}

// Usage
const searchState = new SearchStateManager();
searchState.updateParam('q', 'javascript');
searchState.updateParam('category', 'tutorials');
```

### Error Handling for Search

Handle common search-related errors:

```javascript
async function robustSearch(query, filters = {}) {
  const params = new URLSearchParams({
    q: query,
    ...filters
  });
  
  try {
    const response = await fetch(`/api/search?${params}`);
    
    if (!response.ok) {
      if (response.status === 400) {
        const error = await response.json();
        throw new Error(`Invalid search parameters: ${error.message}`);
      }
      if (response.status === 429) {
        throw new Error('Too many requests. Please try again later.');
      }
      throw new Error(`Search failed: ${response.statusText}`);
    }
    
    const data = await response.json();
    
    // Validate response structure
    if (!data.results || !Array.isArray(data.results)) {
      throw new Error('Invalid response format');
    }
    
    return data;
    
  } catch (error) {
    if (error.name === 'AbortError') {
      return { results: [], cancelled: true };
    }
    
    if (error.name === 'TypeError') {
      throw new Error('Network error. Please check your connection.');
    }
    
    throw error;
  }
}

// Usage with error display
try {
  const results = await robustSearch(query, filters);
  if (results.cancelled) {
    return;
  }
  displayResults(results);
} catch (error) {
  displayError(error.message);
}
```

### Progressive Search Results

Load and display results incrementally:

```javascript
async function* streamSearchResults(query, batchSize = 10) {
  let page = 1;
  let hasMore = true;
  
  while (hasMore) {
    const params = new URLSearchParams({
      q: query,
      page: page,
      limit: batchSize
    });
    
    const response = await fetch(`/api/search?${params}`);
    const data = await response.json();
    
    yield data.results;
    
    hasMore = data.hasMore;
    page++;
  }
}

// Usage
async function displayProgressiveResults(query) {
  const container = document.getElementById('results');
  container.innerHTML = '';
  
  for await (const batch of streamSearchResults(query)) {
    batch.forEach(result => {
      const element = createResultElement(result);
      container.appendChild(element);
    });
  }
}
```

### Search Suggestions and Autocomplete

Implement typeahead search suggestions:

```javascript
class SearchAutocomplete {
  constructor(inputElement, options = {}) {
    this.input = inputElement;
    this.delay = options.delay || 200;
    this.minChars = options.minChars || 2;
    this.maxResults = options.maxResults || 10;
    this.controller = null;
    this.timeout = null;
    
    this.input.addEventListener('input', (e) => this.handleInput(e));
  }
  
  handleInput(event) {
    const query = event.target.value.trim();
    
    clearTimeout(this.timeout);
    
    if (query.length < this.minChars) {
      this.clearSuggestions();
      return;
    }
    
    this.timeout = setTimeout(() => {
      this.fetchSuggestions(query);
    }, this.delay);
  }
  
  async fetchSuggestions(query) {
    if (this.controller) {
      this.controller.abort();
    }
    
    this.controller = new AbortController();
    
    try {
      const params = new URLSearchParams({
        q: query,
        limit: this.maxResults
      });
      
      const response = await fetch(`/api/suggestions?${params}`, {
        signal: this.controller.signal
      });
      
      const suggestions = await response.json();
      this.displaySuggestions(suggestions);
      
    } catch (error) {
      if (error.name !== 'AbortError') {
        console.error('Suggestion fetch failed:', error);
      }
    }
  }
  
  displaySuggestions(suggestions) {
    // Implementation to display suggestions
  }
  
  clearSuggestions() {
    // Implementation to clear suggestions
  }
}

// Usage
const autocomplete = new SearchAutocomplete(
  document.getElementById('search-input'),
  { delay: 200, minChars: 2 }
);
```

---

## Fetch API Sorting

### Basic Sort Parameter

The fetch API accepts a `sort` parameter in the request options to order results. The sort parameter takes a string value specifying the field name to sort by:

```javascript
const response = await fetch('/api/items?sort=name');
```

### Sort Direction

Sort direction is controlled by prefixing the field name with a plus sign (`+`) for ascending order or a minus sign (`-`) for descending order:

```javascript
// Ascending order (explicit)
const response = await fetch('/api/items?sort=+price');

// Descending order
const response = await fetch('/api/items?sort=-price');

// Ascending order (implicit default)
const response = await fetch('/api/items?sort=price');
```

Most APIs default to ascending order when no prefix is specified.

### Multiple Sort Fields

Multiple sort criteria can be applied by separating field names with commas. The API processes sorts from left to right, with earlier fields taking precedence:

```javascript
// Sort by category ascending, then by price descending
const response = await fetch('/api/items?sort=category,-price');

// Sort by priority descending, status ascending, then date descending
const response = await fetch('/api/items?sort=-priority,+status,-createdAt');
```

### Nested Field Sorting

Nested object properties can be sorted using dot notation:

```javascript
// Sort by nested field
const response = await fetch('/api/users?sort=address.city');

// Sort by deeply nested field
const response = await fetch('/api/orders?sort=customer.billing.zipCode');
```

### URL Encoding

Sort parameters containing special characters, spaces, or non-ASCII characters must be URL-encoded:

```javascript
const sortParam = encodeURIComponent('user.name,-created_at');
const response = await fetch(`/api/items?sort=${sortParam}`);
```

For complex sort strings:

```javascript
const params = new URLSearchParams({
  sort: '-priority,status,customer.name'
});
const response = await fetch(`/api/items?${params}`);
```

### Array-Based Sort Syntax

Some APIs accept array syntax for multiple sort fields:

```javascript
// Using repeated parameters
const response = await fetch('/api/items?sort[]=-price&sort[]=name');

// Using bracket notation with indices
const response = await fetch('/api/items?sort[0]=-price&sort[1]=name');
```

### Case Sensitivity

Sort behavior for string fields varies by implementation:

```javascript
// Case-sensitive sort (default in many systems)
const response = await fetch('/api/items?sort=name');

// Case-insensitive sort (API-dependent)
const response = await fetch('/api/items?sort=name&case=insensitive');
```

[Inference] String comparison typically follows lexicographic ordering where uppercase letters sort before lowercase letters in case-sensitive modes.

### Null Handling

Different APIs handle null or undefined values differently during sorting:

```javascript
// Nulls first
const response = await fetch('/api/items?sort=optionalField&nulls=first');

// Nulls last (common default)
const response = await fetch('/api/items?sort=optionalField&nulls=last');
```

### Combining Sort with Other Parameters

Sort parameters work alongside filtering, pagination, and field selection:

```javascript
const params = new URLSearchParams({
  sort: '-createdAt,name',
  limit: '20',
  offset: '40',
  filter: 'status:active',
  fields: 'id,name,price'
});

const response = await fetch(`/api/items?${params}`);
```

### Sort Order Validation

Client-side validation helps catch errors before making requests:

```javascript
function validateSortParam(sort, allowedFields) {
  const sortFields = sort.split(',').map(s => s.replace(/^[+-]/, ''));
  const invalid = sortFields.filter(f => !allowedFields.includes(f));
  
  if (invalid.length > 0) {
    throw new Error(`Invalid sort fields: ${invalid.join(', ')}`);
  }
}

const allowedFields = ['name', 'price', 'createdAt', 'category'];
const sortParam = '-price,name';
validateSortParam(sortParam, allowedFields);

const response = await fetch(`/api/items?sort=${sortParam}`);
```

### Dynamic Sort Construction

Building sort parameters dynamically based on user input:

```javascript
function buildSortParam(sortConfig) {
  return sortConfig
    .map(({ field, direction }) => {
      const prefix = direction === 'desc' ? '-' : '';
      return `${prefix}${field}`;
    })
    .join(',');
}

const sortConfig = [
  { field: 'priority', direction: 'desc' },
  { field: 'name', direction: 'asc' },
  { field: 'createdAt', direction: 'desc' }
];

const sortParam = buildSortParam(sortConfig);
const response = await fetch(`/api/items?sort=${sortParam}`);
```

### Error Handling

Handling invalid sort parameters:

```javascript
try {
  const response = await fetch('/api/items?sort=-invalidField');
  
  if (!response.ok) {
    const error = await response.json();
    if (response.status === 400 && error.code === 'INVALID_SORT_FIELD') {
      console.error('Invalid sort field:', error.message);
    }
  }
  
  const data = await response.json();
} catch (error) {
  console.error('Request failed:', error);
}
```

### Custom Sort Functions

Some APIs support custom sort expressions or functions:

```javascript
// Custom sort expression (API-dependent syntax)
const response = await fetch('/api/items?sort=custom(price*quantity)');

// Function-based sorting (rare, API-specific)
const response = await fetch('/api/items?sort=fn:calculateScore');
```

[Unverified] Custom sort function support varies significantly between APIs and is not part of standard fetch conventions.

### Performance Considerations

Sorting impacts query performance, especially on large datasets:

```javascript
// Indexed field - faster
const response = await fetch('/api/items?sort=id');

// Non-indexed field - slower
const response = await fetch('/api/items?sort=description');

// Multiple fields - performance depends on indexes
const response = await fetch('/api/items?sort=category,-price,name');
```

[Inference] Database indexes on sort fields significantly improve query performance, but the specific performance characteristics depend on the backend implementation.

### Client-Side vs Server-Side Sorting

Deciding where to sort:

```javascript
// Server-side sort (recommended for large datasets)
const response = await fetch('/api/items?sort=-price&limit=100');
const data = await response.json();

// Client-side sort (suitable for small datasets)
const response = await fetch('/api/items');
const data = await response.json();
const sorted = data.sort((a, b) => b.price - a.price);
```

### RESTful Sort Conventions

Common patterns in REST APIs:

```javascript
// Query parameter style (most common)
fetch('/api/items?sort=name');

// Header-based sorting (rare)
fetch('/api/items', {
  headers: { 'X-Sort': '-createdAt,name' }
});

// Path-based sorting (uncommon)
fetch('/api/items/sorted-by/name');
```

### GraphQL Comparison

For reference, sorting in GraphQL differs from REST:

```javascript
// REST approach
fetch('/api/items?sort=-price,name');

// GraphQL approach
fetch('/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: `
      query {
        items(orderBy: [{ price: DESC }, { name: ASC }]) {
          id
          name
          price
        }
      }
    `
  })
});
```

### Locale-Aware Sorting

String sorting with locale considerations:

```javascript
// Request locale-specific sorting
const response = await fetch('/api/items?sort=name&locale=en-US');

// With collation options
const response = await fetch('/api/items?sort=name&locale=fr-FR&collation=accent');
```

[Unverified] Locale-aware sorting support depends entirely on the API implementation and is not a standard feature of the fetch API itself.

### Sort State Management

Maintaining sort state in applications:

```javascript
class DataFetcher {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.currentSort = null;
  }
  
  async fetchSorted(sortParam) {
    this.currentSort = sortParam;
    const response = await fetch(`${this.baseUrl}?sort=${sortParam}`);
    return response.json();
  }
  
  async refetch() {
    if (this.currentSort) {
      return this.fetchSorted(this.currentSort);
    }
    const response = await fetch(this.baseUrl);
    return response.json();
  }
}

const fetcher = new DataFetcher('/api/items');
const data = await fetcher.fetchSorted('-price,name');
```

### Debugging Sort Issues

Techniques for troubleshooting sort problems:

```javascript
async function fetchWithSortDebug(url, sortParam) {
  const fullUrl = `${url}?sort=${sortParam}`;
  console.log('Sort request:', fullUrl);
  
  const response = await fetch(fullUrl);
  
  console.log('Sort response status:', response.status);
  console.log('Sort response headers:', Object.fromEntries(response.headers));
  
  const data = await response.json();
  console.log('First item:', data[0]);
  console.log('Last item:', data[data.length - 1]);
  
  return data;
}

const data = await fetchWithSortDebug('/api/items', '-price,name');
```

---

## Real-time Updates using Fetch API

### Streaming Responses

The Fetch API supports streaming responses through the `ReadableStream` interface, allowing you to process data as it arrives rather than waiting for the complete response.

#### Accessing the Stream

```javascript
const response = await fetch('https://api.example.com/stream');
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, { stream: true });
  console.log('Received chunk:', chunk);
}
```

#### Processing Chunked Data

For line-delimited data (like Server-Sent Events format):

```javascript
async function processStream(response) {
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    
    if (done) {
      if (buffer.length > 0) {
        processLine(buffer);
      }
      break;
    }

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');
    buffer = lines.pop(); // Keep incomplete line in buffer

    lines.forEach(line => {
      if (line.trim()) {
        processLine(line);
      }
    });
  }
}

function processLine(line) {
  try {
    const data = JSON.parse(line);
    updateUI(data);
  } catch (e) {
    console.error('Parse error:', e);
  }
}
```

### Server-Sent Events (SSE) Alternative

While not directly part of Fetch API, SSE via `EventSource` is commonly used for server-to-client streaming:

```javascript
const eventSource = new EventSource('https://api.example.com/events');

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  updateUI(data);
};

eventSource.onerror = (error) => {
  console.error('SSE error:', error);
  eventSource.close();
};

// Custom event types
eventSource.addEventListener('update', (event) => {
  console.log('Update event:', event.data);
});
```

### Long Polling Pattern

Implementing long polling with Fetch API for environments that don't support streaming:

```javascript
async function longPoll(url, options = {}) {
  const { timeout = 30000, maxRetries = 3 } = options;
  let retries = 0;

  while (retries < maxRetries) {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);

      const response = await fetch(url, {
        signal: controller.signal,
        headers: {
          'Content-Type': 'application/json',
        }
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      
      if (data.updates) {
        processUpdates(data.updates);
      }

      // Continue polling
      await longPoll(url, options);
      break;

    } catch (error) {
      if (error.name === 'AbortError') {
        // Timeout - restart poll
        continue;
      }

      retries++;
      if (retries >= maxRetries) {
        console.error('Max retries reached:', error);
        break;
      }

      // Exponential backoff
      await new Promise(resolve => 
        setTimeout(resolve, Math.min(1000 * Math.pow(2, retries), 30000))
      );
    }
  }
}
```

### Polling with Exponential Backoff

For periodic polling when real-time streaming isn't available:

```javascript
class PollingManager {
  constructor(url, options = {}) {
    this.url = url;
    this.interval = options.interval || 5000;
    this.maxInterval = options.maxInterval || 60000;
    this.backoffMultiplier = options.backoffMultiplier || 1.5;
    this.currentInterval = this.interval;
    this.timeoutId = null;
    this.isPolling = false;
  }

  async poll() {
    if (!this.isPolling) return;

    try {
      const response = await fetch(this.url);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      this.handleSuccess(data);

      // Reset interval on success
      this.currentInterval = this.interval;

    } catch (error) {
      this.handleError(error);

      // Increase interval on error
      this.currentInterval = Math.min(
        this.currentInterval * this.backoffMultiplier,
        this.maxInterval
      );
    }

    if (this.isPolling) {
      this.timeoutId = setTimeout(() => this.poll(), this.currentInterval);
    }
  }

  start() {
    if (this.isPolling) return;
    this.isPolling = true;
    this.poll();
  }

  stop() {
    this.isPolling = false;
    if (this.timeoutId) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
  }

  handleSuccess(data) {
    console.log('Poll success:', data);
  }

  handleError(error) {
    console.error('Poll error:', error);
  }
}
```

### Streaming JSON Parsing

For handling large JSON responses incrementally:

```javascript
async function streamJSON(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';
  let depth = 0;
  let objectStart = -1;

  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;

    buffer += decoder.decode(value, { stream: true });

    for (let i = 0; i < buffer.length; i++) {
      const char = buffer[i];

      if (char === '{') {
        if (depth === 0) objectStart = i;
        depth++;
      } else if (char === '}') {
        depth--;
        if (depth === 0 && objectStart !== -1) {
          const jsonStr = buffer.substring(objectStart, i + 1);
          try {
            const obj = JSON.parse(jsonStr);
            handleObject(obj);
          } catch (e) {
            console.error('JSON parse error:', e);
          }
          buffer = buffer.substring(i + 1);
          i = -1;
          objectStart = -1;
        }
      }
    }
  }
}
```

### Handling Binary Streams

Processing binary data streams:

```javascript
async function processBinaryStream(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  let receivedLength = 0;
  const chunks = [];

  while (true) {
    const { done, value } = await reader.read();

    if (done) break;

    chunks.push(value);
    receivedLength += value.length;

    // Update progress
    const contentLength = response.headers.get('Content-Length');
    if (contentLength) {
      const progress = (receivedLength / parseInt(contentLength)) * 100;
      updateProgress(progress);
    }

    // Process chunk immediately if needed
    processChunk(value);
  }

  // Combine all chunks
  const allChunks = new Uint8Array(receivedLength);
  let position = 0;
  for (const chunk of chunks) {
    allChunks.set(chunk, position);
    position += chunk.length;
  }

  return allChunks;
}
```

### Abort and Cleanup

Managing stream lifecycle:

```javascript
class StreamManager {
  constructor() {
    this.controller = null;
    this.reader = null;
  }

  async startStream(url) {
    this.controller = new AbortController();

    try {
      const response = await fetch(url, {
        signal: this.controller.signal
      });

      this.reader = response.body.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await this.reader.read();
        
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        this.onData(chunk);
      }

    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('Stream aborted');
      } else {
        this.onError(error);
      }
    } finally {
      this.cleanup();
    }
  }

  stop() {
    if (this.controller) {
      this.controller.abort();
    }
  }

  cleanup() {
    if (this.reader) {
      this.reader.releaseLock();
      this.reader = null;
    }
    this.controller = null;
  }

  onData(chunk) {
    console.log('Received:', chunk);
  }

  onError(error) {
    console.error('Stream error:', error);
  }
}
```

### Backpressure Handling

[Inference] Managing flow control when consumer is slower than producer:

```javascript
async function streamWithBackpressure(url, processChunk) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      
      // Wait for processing to complete before reading next chunk
      await processChunk(chunk);
    }
  } finally {
    reader.releaseLock();
  }
}

// Usage
await streamWithBackpressure(url, async (chunk) => {
  // Simulate slow processing
  await heavyProcessing(chunk);
  await saveToDatabase(chunk);
});
```

### Multiplexing Multiple Streams

Handling multiple concurrent streams:

```javascript
class MultiStreamManager {
  constructor() {
    this.streams = new Map();
  }

  async addStream(id, url) {
    const controller = new AbortController();
    
    const streamPromise = this.processStream(url, controller.signal)
      .catch(error => {
        if (error.name !== 'AbortError') {
          console.error(`Stream ${id} error:`, error);
        }
      })
      .finally(() => {
        this.streams.delete(id);
      });

    this.streams.set(id, {
      promise: streamPromise,
      controller
    });
  }

  async processStream(url, signal) {
    const response = await fetch(url, { signal });
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const chunk = decoder.decode(value, { stream: true });
      this.onData(url, chunk);
    }
  }

  stopStream(id) {
    const stream = this.streams.get(id);
    if (stream) {
      stream.controller.abort();
    }
  }

  stopAll() {
    for (const [id, stream] of this.streams) {
      stream.controller.abort();
    }
    this.streams.clear();
  }

  onData(url, chunk) {
    console.log(`Data from ${url}:`, chunk);
  }
}
```

### Reconnection Strategy

Implementing automatic reconnection:

```javascript
class ReconnectingStream {
  constructor(url, options = {}) {
    this.url = url;
    this.maxRetries = options.maxRetries || Infinity;
    this.retryDelay = options.retryDelay || 1000;
    this.maxRetryDelay = options.maxRetryDelay || 30000;
    this.retryCount = 0;
    this.isConnected = false;
    this.shouldReconnect = true;
  }

  async connect() {
    while (this.shouldReconnect && this.retryCount < this.maxRetries) {
      try {
        await this.startStream();
        this.retryCount = 0;
        
      } catch (error) {
        console.error('Connection error:', error);
        this.isConnected = false;
        
        if (!this.shouldReconnect) break;

        this.retryCount++;
        const delay = Math.min(
          this.retryDelay * Math.pow(2, this.retryCount - 1),
          this.maxRetryDelay
        );

        console.log(`Reconnecting in ${delay}ms (attempt ${this.retryCount})`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  async startStream() {
    const response = await fetch(this.url);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }

    this.isConnected = true;
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    try {
      while (this.shouldReconnect) {
        const { done, value } = await reader.read();
        
        if (done) {
          throw new Error('Stream ended');
        }

        const chunk = decoder.decode(value, { stream: true });
        this.onData(chunk);
      }
    } finally {
      reader.releaseLock();
    }
  }

  disconnect() {
    this.shouldReconnect = false;
    this.isConnected = false;
  }

  onData(chunk) {
    console.log('Received:', chunk);
  }
}
```

### Rate Limiting Outgoing Updates

Throttling requests when sending real-time updates:

```javascript
class RateLimitedUpdater {
  constructor(url, options = {}) {
    this.url = url;
    this.rateLimit = options.rateLimit || 10; // requests per second
    this.queue = [];
    this.processing = false;
    this.interval = 1000 / this.rateLimit;
  }

  async sendUpdate(data) {
    return new Promise((resolve, reject) => {
      this.queue.push({ data, resolve, reject });
      this.processQueue();
    });
  }

  async processQueue() {
    if (this.processing || this.queue.length === 0) return;

    this.processing = true;

    while (this.queue.length > 0) {
      const { data, resolve, reject } = this.queue.shift();

      try {
        const response = await fetch(this.url, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(data)
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        const result = await response.json();
        resolve(result);

      } catch (error) {
        reject(error);
      }

      // Wait before processing next
      if (this.queue.length > 0) {
        await new Promise(resolve => setTimeout(resolve, this.interval));
      }
    }

    this.processing = false;
  }
}
```

### Progressive Enhancement Pattern

Falling back gracefully when streaming isn't supported:

```javascript
async function fetchWithFallback(url) {
  // Check if streaming is supported
  const supportsStreaming = typeof ReadableStream !== 'undefined' &&
                           typeof Response !== 'undefined' &&
                           Response.prototype.hasOwnProperty('body');

  if (supportsStreaming) {
    try {
      return await streamingFetch(url);
    } catch (error) {
      console.warn('Streaming failed, falling back:', error);
    }
  }

  // Fallback to regular fetch
  return await regularFetch(url);
}

async function streamingFetch(url) {
  const response = await fetch(url);
  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const chunk = decoder.decode(value, { stream: true });
    processChunk(chunk);
  }
}

async function regularFetch(url) {
  const response = await fetch(url);
  const data = await response.text();
  processChunk(data);
}
```

---

## WebSocket Fallback Strategies

### Detecting Connection Failures

#### Connection State Monitoring

The `WebSocket.readyState` property provides the current connection status. Monitor state transitions to detect when fallback mechanisms should activate:

```javascript
const ws = new WebSocket('wss://example.com');

ws.addEventListener('error', (event) => {
  // Connection failed - trigger fallback
});

ws.addEventListener('close', (event) => {
  if (event.code === 1006) {
    // Abnormal closure - connection was not cleanly closed
  }
});
```

#### Timeout-Based Detection

Implement connection timeouts to detect scenarios where the WebSocket hangs without triggering error events:

```javascript
const CONNECTION_TIMEOUT = 5000;

const connectWithTimeout = (url) => {
  return new Promise((resolve, reject) => {
    const ws = new WebSocket(url);
    const timeout = setTimeout(() => {
      ws.close();
      reject(new Error('Connection timeout'));
    }, CONNECTION_TIMEOUT);

    ws.addEventListener('open', () => {
      clearTimeout(timeout);
      resolve(ws);
    });

    ws.addEventListener('error', () => {
      clearTimeout(timeout);
      reject(new Error('Connection failed'));
    });
  });
};
```

#### Heartbeat Mechanism

Implement ping/pong patterns to detect silent connection failures:

```javascript
class WebSocketWithHeartbeat {
  constructor(url) {
    this.ws = new WebSocket(url);
    this.pingInterval = null;
    this.lastPong = Date.now();
    this.HEARTBEAT_INTERVAL = 30000;
    this.HEARTBEAT_TIMEOUT = 5000;
  }

  startHeartbeat() {
    this.pingInterval = setInterval(() => {
      if (Date.now() - this.lastPong > this.HEARTBEAT_TIMEOUT) {
        this.ws.close();
        this.triggerFallback();
        return;
      }
      this.ws.send(JSON.stringify({ type: 'ping' }));
    }, this.HEARTBEAT_INTERVAL);
  }

  handlePong() {
    this.lastPong = Date.now();
  }
}
```

### HTTP Long-Polling Fallback

#### Basic Long-Polling Implementation

Long-polling maintains a persistent HTTP request that the server holds open until data is available:

```javascript
class LongPollingTransport {
  constructor(url) {
    this.url = url;
    this.abortController = null;
    this.isActive = false;
  }

  async poll() {
    while (this.isActive) {
      this.abortController = new AbortController();
      
      try {
        const response = await fetch(this.url, {
          method: 'GET',
          signal: this.abortController.signal,
          headers: { 'Content-Type': 'application/json' }
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        const data = await response.json();
        this.onMessage(data);
        
      } catch (error) {
        if (error.name !== 'AbortError') {
          await this.handleError(error);
        }
      }
    }
  }

  send(data) {
    return fetch(this.url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
  }

  stop() {
    this.isActive = false;
    if (this.abortController) {
      this.abortController.abort();
    }
  }
}
```

#### Exponential Backoff for Failed Polls

Implement retry logic with exponential backoff to handle temporary network issues:

```javascript
class LongPollingWithBackoff extends LongPollingTransport {
  constructor(url) {
    super(url);
    this.retryCount = 0;
    this.maxRetries = 5;
    this.baseDelay = 1000;
  }

  async handleError(error) {
    if (this.retryCount >= this.maxRetries) {
      this.onFatalError(error);
      return;
    }

    const delay = Math.min(
      this.baseDelay * Math.pow(2, this.retryCount),
      30000
    );
    
    this.retryCount++;
    await new Promise(resolve => setTimeout(resolve, delay));
  }

  resetRetryCount() {
    this.retryCount = 0;
  }
}
```

### Server-Sent Events (SSE) Fallback

#### SSE Implementation

Server-Sent Events provide unidirectional communication from server to client:

```javascript
class SSETransport {
  constructor(url) {
    this.url = url;
    this.eventSource = null;
  }

  connect() {
    this.eventSource = new EventSource(this.url);

    this.eventSource.addEventListener('message', (event) => {
      const data = JSON.parse(event.data);
      this.onMessage(data);
    });

    this.eventSource.addEventListener('error', (error) => {
      if (this.eventSource.readyState === EventSource.CLOSED) {
        this.onConnectionClosed();
      } else {
        this.onError(error);
      }
    });

    this.eventSource.addEventListener('open', () => {
      this.onOpen();
    });
  }

  // SSE is unidirectional - use fetch for sending
  async send(data) {
    return fetch(`${this.url}/send`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
  }

  close() {
    if (this.eventSource) {
      this.eventSource.close();
    }
  }
}
```

#### Custom Event Types

Leverage SSE's built-in event type support for different message categories:

```javascript
class SSEWithCustomEvents extends SSETransport {
  connect() {
    this.eventSource = new EventSource(this.url);

    // Handle different event types
    this.eventSource.addEventListener('notification', (event) => {
      this.onNotification(JSON.parse(event.data));
    });

    this.eventSource.addEventListener('update', (event) => {
      this.onUpdate(JSON.parse(event.data));
    });

    this.eventSource.addEventListener('heartbeat', (event) => {
      this.lastHeartbeat = Date.now();
    });
  }
}
```

#### SSE Reconnection Logic

EventSource automatically reconnects, but implement custom logic for better control:

```javascript
class SSEWithReconnection {
  constructor(url, options = {}) {
    this.url = url;
    this.maxReconnectAttempts = options.maxReconnectAttempts || Infinity;
    this.reconnectInterval = options.reconnectInterval || 3000;
    this.reconnectAttempts = 0;
  }

  connect() {
    this.eventSource = new EventSource(this.url);

    this.eventSource.addEventListener('open', () => {
      this.reconnectAttempts = 0;
      this.onOpen();
    });

    this.eventSource.addEventListener('error', () => {
      this.eventSource.close();
      
      if (this.reconnectAttempts < this.maxReconnectAttempts) {
        this.reconnectAttempts++;
        setTimeout(() => this.connect(), this.reconnectInterval);
      } else {
        this.onMaxReconnectAttemptsReached();
      }
    });
  }
}
```

### Graceful Degradation Architecture

#### Transport Abstraction Layer

Create a unified interface that abstracts the underlying transport mechanism:

```javascript
class TransportInterface {
  async connect() { throw new Error('Not implemented'); }
  async send(data) { throw new Error('Not implemented'); }
  async close() { throw new Error('Not implemented'); }
  onMessage(callback) { this.messageCallback = callback; }
  onError(callback) { this.errorCallback = callback; }
  onClose(callback) { this.closeCallback = callback; }
}

class WebSocketTransport extends TransportInterface {
  constructor(url) {
    super();
    this.url = url;
    this.ws = null;
  }

  async connect() {
    return new Promise((resolve, reject) => {
      this.ws = new WebSocket(this.url);
      
      this.ws.addEventListener('open', () => resolve());
      this.ws.addEventListener('error', reject);
      
      this.ws.addEventListener('message', (event) => {
        this.messageCallback?.(JSON.parse(event.data));
      });
    });
  }

  async send(data) {
    if (this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(data));
    }
  }

  async close() {
    this.ws?.close();
  }
}
```

#### Priority-Based Transport Selection

Implement a system that attempts transports in order of preference:

```javascript
class TransportManager {
  constructor(url) {
    this.url = url;
    this.transports = [
      { name: 'websocket', factory: () => new WebSocketTransport(url) },
      { name: 'sse', factory: () => new SSETransport(url) },
      { name: 'long-polling', factory: () => new LongPollingTransport(url) }
    ];
    this.currentTransport = null;
    this.currentIndex = 0;
  }

  async connect() {
    for (let i = this.currentIndex; i < this.transports.length; i++) {
      const transport = this.transports[i];
      
      try {
        const instance = transport.factory();
        await this.attemptConnection(instance, 5000);
        
        this.currentTransport = instance;
        this.currentIndex = i;
        this.onConnected(transport.name);
        return instance;
        
      } catch (error) {
        console.warn(`${transport.name} failed, trying next transport`);
        continue;
      }
    }
    
    throw new Error('All transports failed');
  }

  async attemptConnection(transport, timeout) {
    return Promise.race([
      transport.connect(),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Timeout')), timeout)
      )
    ]);
  }

  async reconnect() {
    await this.currentTransport?.close();
    return this.connect();
  }
}
```

#### Feature Detection

Detect browser capabilities to determine available transports:

```javascript
class FeatureDetector {
  static detectAvailableTransports() {
    const transports = [];

    // WebSocket support
    if ('WebSocket' in window) {
      transports.push({
        name: 'websocket',
        bidirectional: true,
        overhead: 'low',
        latency: 'low'
      });
    }

    // Server-Sent Events support
    if ('EventSource' in window) {
      transports.push({
        name: 'sse',
        bidirectional: false,
        overhead: 'medium',
        latency: 'medium'
      });
    }

    // Long-polling (always available)
    if ('fetch' in window) {
      transports.push({
        name: 'long-polling',
        bidirectional: true,
        overhead: 'high',
        latency: 'high'
      });
    }

    return transports;
  }

  static checkWebSocketSupport() {
    if (!('WebSocket' in window)) return false;
    
    try {
      const ws = new WebSocket('ws://localhost:1');
      ws.close();
      return true;
    } catch {
      return false;
    }
  }
}
```

### Hybrid Approaches

#### WebSocket + Fetch Hybrid

Use WebSocket for real-time updates and fetch for critical operations:

```javascript
class HybridTransport {
  constructor(wsUrl, httpUrl) {
    this.wsUrl = wsUrl;
    this.httpUrl = httpUrl;
    this.ws = null;
    this.preferWebSocket = true;
  }

  async connect() {
    try {
      this.ws = new WebSocket(this.wsUrl);
      await new Promise((resolve, reject) => {
        this.ws.addEventListener('open', resolve);
        this.ws.addEventListener('error', reject);
        setTimeout(reject, 5000);
      });
      this.preferWebSocket = true;
    } catch {
      this.preferWebSocket = false;
    }
  }

  async send(data, options = {}) {
    const { critical = false, timeout = 10000 } = options;

    // Critical messages always use HTTP for reliability
    if (critical || !this.preferWebSocket || this.ws?.readyState !== WebSocket.OPEN) {
      return this.sendViaHttp(data, timeout);
    }

    // Try WebSocket first for non-critical messages
    try {
      this.ws.send(JSON.stringify(data));
      return { success: true, transport: 'websocket' };
    } catch {
      return this.sendViaHttp(data, timeout);
    }
  }

  async sendViaHttp(data, timeout) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);

    try {
      const response = await fetch(this.httpUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(data),
        signal: controller.signal
      });

      clearTimeout(timeoutId);
      return { 
        success: response.ok, 
        transport: 'http',
        data: await response.json()
      };
    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }
}
```

#### Automatic Transport Switching

Dynamically switch transports based on connection quality:

```javascript
class AdaptiveTransport {
  constructor(url) {
    this.url = url;
    this.transportManager = new TransportManager(url);
    this.metrics = {
      latency: [],
      failures: 0,
      successRate: 1.0
    };
  }

  async send(data) {
    const startTime = Date.now();

    try {
      const result = await this.transportManager.currentTransport.send(data);
      const latency = Date.now() - startTime;
      
      this.recordSuccess(latency);
      return result;
      
    } catch (error) {
      this.recordFailure();
      
      if (this.shouldSwitchTransport()) {
        await this.switchToNextTransport();
        return this.send(data); // Retry with new transport
      }
      
      throw error;
    }
  }

  recordSuccess(latency) {
    this.metrics.latency.push(latency);
    if (this.metrics.latency.length > 100) {
      this.metrics.latency.shift();
    }
    
    this.metrics.failures = Math.max(0, this.metrics.failures - 1);
    this.updateSuccessRate();
  }

  recordFailure() {
    this.metrics.failures++;
    this.updateSuccessRate();
  }

  updateSuccessRate() {
    const total = this.metrics.latency.length + this.metrics.failures;
    this.metrics.successRate = this.metrics.latency.length / Math.max(total, 1);
  }

  shouldSwitchTransport() {
    const avgLatency = this.metrics.latency.reduce((a, b) => a + b, 0) / 
                       this.metrics.latency.length;
    
    return this.metrics.successRate < 0.8 || 
           avgLatency > 3000 || 
           this.metrics.failures > 5;
  }

  async switchToNextTransport() {
    this.transportManager.currentIndex++;
    await this.transportManager.reconnect();
    this.resetMetrics();
  }

  resetMetrics() {
    this.metrics = {
      latency: [],
      failures: 0,
      successRate: 1.0
    };
  }
}
```

### Connection State Management

#### State Machine Implementation

Implement a finite state machine to manage connection lifecycle:

```javascript
const ConnectionState = {
  DISCONNECTED: 'disconnected',
  CONNECTING: 'connecting',
  CONNECTED: 'connected',
  RECONNECTING: 'reconnecting',
  FAILED: 'failed'
};

class ConnectionStateMachine {
  constructor() {
    this.state = ConnectionState.DISCONNECTED;
    this.listeners = new Map();
    this.reconnectAttempts = 0;
    this.maxReconnectAttempts = 5;
  }

  transition(newState, metadata = {}) {
    const oldState = this.state;
    this.state = newState;
    
    this.emit('stateChange', {
      from: oldState,
      to: newState,
      ...metadata
    });
  }

  async connect(transport) {
    if (this.state === ConnectionState.CONNECTED) return;
    
    this.transition(ConnectionState.CONNECTING);

    try {
      await transport.connect();
      this.reconnectAttempts = 0;
      this.transition(ConnectionState.CONNECTED, { transport: transport.name });
    } catch (error) {
      await this.handleConnectionFailure(transport, error);
    }
  }

  async handleConnectionFailure(transport, error) {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      this.transition(ConnectionState.RECONNECTING, {
        attempt: this.reconnectAttempts,
        error: error.message
      });
      
      await this.delay(this.getReconnectDelay());
      await this.connect(transport);
    } else {
      this.transition(ConnectionState.FAILED, { error: error.message });
    }
  }

  getReconnectDelay() {
    return Math.min(1000 * Math.pow(2, this.reconnectAttempts), 30000);
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  on(event, callback) {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, []);
    }
    this.listeners.get(event).push(callback);
  }

  emit(event, data) {
    const callbacks = this.listeners.get(event) || [];
    callbacks.forEach(callback => callback(data));
  }
}
```

#### Message Queue for Offline Support

Buffer messages when connection is unavailable and replay when reconnected:

```javascript
class MessageQueue {
  constructor(maxSize = 1000) {
    this.queue = [];
    this.maxSize = maxSize;
    this.processing = false;
  }

  enqueue(message) {
    if (this.queue.length >= this.maxSize) {
      this.queue.shift(); // Remove oldest message
    }
    
    this.queue.push({
      data: message,
      timestamp: Date.now(),
      attempts: 0
    });
  }

  async process(sendFunction) {
    if (this.processing) return;
    
    this.processing = true;

    while (this.queue.length > 0) {
      const message = this.queue[0];
      
      try {
        await sendFunction(message.data);
        this.queue.shift(); // Remove successfully sent message
      } catch (error) {
        message.attempts++;
        
        if (message.attempts >= 3) {
          this.queue.shift(); // Remove failed message after 3 attempts
          this.onMessageFailed?.(message);
        } else {
          break; // Stop processing on failure, will retry later
        }
      }
    }

    this.processing = false;
  }

  clear() {
    this.queue = [];
  }

  size() {
    return this.queue.length;
  }
}

class ResilientConnection {
  constructor(transport) {
    this.transport = transport;
    this.queue = new MessageQueue();
    this.isConnected = false;

    this.transport.onClose(() => {
      this.isConnected = false;
    });

    this.transport.onOpen(() => {
      this.isConnected = true;
      this.queue.process((data) => this.transport.send(data));
    });
  }

  async send(data) {
    if (this.isConnected) {
      try {
        await this.transport.send(data);
      } catch (error) {
        this.queue.enqueue(data);
        throw error;
      }
    } else {
      this.queue.enqueue(data);
    }
  }
}
```

### Protocol Negotiation

#### Client-Server Capability Exchange

Negotiate the best transport during the initial handshake:

```javascript
class ProtocolNegotiator {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
  }

  async negotiate() {
    const clientCapabilities = {
      transports: FeatureDetector.detectAvailableTransports(),
      protocols: ['json', 'msgpack'],
      compression: ['gzip', 'deflate'],
      features: ['binary', 'streaming']
    };

    const response = await fetch(`${this.baseUrl}/negotiate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(clientCapabilities)
    });

    const serverCapabilities = await response.json();
    
    return this.selectOptimalConfiguration(
      clientCapabilities,
      serverCapabilities
    );
  }

  selectOptimalConfiguration(client, server) {
    // Find best transport both support
    const transport = this.selectTransport(
      client.transports,
      server.supportedTransports
    );

    // Select protocol
    const protocol = this.selectProtocol(
      client.protocols,
      server.supportedProtocols
    );

    // Select compression
    const compression = this.selectCompression(
      client.compression,
      server.supportedCompression
    );

    return {
      transport,
      protocol,
      compression,
      connectionId: server.connectionId
    };
  }

  selectTransport(client, server) {
    const priority = ['websocket', 'sse', 'long-polling'];
    
    for (const transport of priority) {
      const clientSupport = client.find(t => t.name === transport);
      const serverSupport = server.includes(transport);
      
      if (clientSupport && serverSupport) {
        return transport;
      }
    }
    
    return 'long-polling'; // Default fallback
  }

  selectProtocol(client, server) {
    return client.find(p => server.includes(p)) || 'json';
  }

  selectCompression(client, server) {
    return client.find(c => server.includes(c)) || null;
  }
}
```

#### Version Compatibility Handling

Handle protocol version mismatches gracefully:

```javascript
class VersionedConnection {
  constructor(baseUrl, version = '1.0') {
    this.baseUrl = baseUrl;
    this.clientVersion = version;
    this.serverVersion = null;
  }

  async connect() {
    const handshake = await fetch(`${this.baseUrl}/handshake`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Protocol-Version': this.clientVersion
      },
      body: JSON.stringify({
        version: this.clientVersion,
        features: this.getSupportedFeatures()
      })
    });

    const response = await handshake.json();
    this.serverVersion = response.version;

    if (!this.isCompatible(this.clientVersion, this.serverVersion)) {
      throw new Error(
        `Version mismatch: client ${this.clientVersion}, server ${this.serverVersion}`
      );
    }

    return this.createConnection(response);
  }

  isCompatible(client, server) {
    const [clientMajor] = client.split('.');
    const [serverMajor] = server.split('.');
    
    return clientMajor === serverMajor;
  }

  getSupportedFeatures() {
    const features = {
      '1.0': ['basic', 'reconnect'],
      '1.1': ['basic', 'reconnect', 'compression'],
      '2.0': ['basic', 'reconnect', 'compression', 'multiplexing']
    };

    return features[this.clientVersion] || features['1.0'];
  }

  createConnection(config) {
    // Create transport based on negotiated configuration
    const transportFactory = this.getTransportFactory(config.transport);
    return transportFactory(config);
  }
}
```

### Proxy and Firewall Handling

#### Detecting Proxy Issues

Identify when connections fail due to proxy or firewall restrictions:

```javascript
class ProxyDetector {
  async detectProxyIssues(wsUrl, httpUrl) {
    const results = {
      websocketBlocked: false,
      httpBlocked: false,
      httpsBlocked: false,
      proxyDetected: false
    };

    // Test WebSocket
    try {
      await this.testWebSocket(wsUrl);
    } catch (error) {
      results.websocketBlocked = true;
    }

    // Test HTTP
    try {
      await this.testHttp(httpUrl);
    } catch (error) {
      results.httpBlocked = true;
    }

    // Test HTTPS
    try {
      await this.testHttps(httpUrl.replace('http:', 'https:'));
    } catch (error) {
      results.httpsBlocked = true;
    }

    // Check for proxy indicators
    results.proxyDetected = this.checkProxyHeaders();

    return results;
  }

  async testWebSocket(url, timeout = 3000) {
    return new Promise((resolve, reject) => {
      const ws = new WebSocket(url);
      const timer = setTimeout(() => {
        ws.close();
        reject(new Error('WebSocket timeout'));
      }, timeout);

      ws.addEventListener('open', () => {
        clearTimeout(timer);
        ws.close();
        resolve();
      });

      ws.addEventListener('error', () => {
        clearTimeout(timer);
        reject(new Error('WebSocket error'));
      });
    });
  }

  async testHttp(url, timeout = 3000) {
    const controller = new AbortController();
    const timer = setTimeout(() => controller.abort(), timeout);

    try {
      await fetch(url, { signal: controller.signal });
      clearTimeout(timer);
    } catch (error) {
      clearTimeout(timer);
      throw error;
    }
  }

  async testHttps(url, timeout = 3000) {
    return this.testHttp(url, timeout);
  }

  checkProxyHeaders() {
    // Some proxies inject headers that are accessible via timing attacks
    // or by checking for specific behavior patterns
    return navigator.connection?.effectiveType === 'slow-2g' ||
           navigator.connection?.saveData === true;
  }
}
```

#### Working Around Restrictions

Implement strategies to bypass common proxy/firewall limitations:

```javascript
class ProxyWorkaround {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.useHttps = true;
    this.useStandardPorts = false;
  }

  async findWorkingConfiguration() {
    const configurations = [
      // Try WebSocket over standard HTTPS port
      { protocol: 'wss', port: 443, path: '/ws' },
      
      // Try WebSocket over HTTP port  
      { protocol: 'ws', port: 80, path: '/ws' },
      
      // Try WebSocket on custom port
      { protocol: 'wss', port: 8080, path: '/ws' },
      
      // Fallback to HTTPS long-polling
      { protocol: 'https', port: 443, path: '/poll' },
      
      // Fallback to HTTP long-polling
      { protocol: 'http', port: 80, path: '/poll' }
    ];

    for (const config of configurations) {
      try {
        const url = this.buildUrl(config);
        await this.testConnection(url, config.protocol);
        return { url, config };
      } catch (error) {
        continue;
      }
    }

    throw new Error('No working configuration found');
  }

  buildUrl(config) {
    const base = new URL(this.baseUrl);
    return `${config.protocol}://${base.hostname}:${config.port}${config.path}`;
  }

  async testConnection(url, protocol) {
    if (protocol.startsWith('ws')) {
      return this.testWebSocket(url);
    } else {
      return this.testHttp(url);
    }
  }

  async testWebSocket(url) {
    return new Promise((resolve, reject) => {
      const ws = new WebSocket(url);
      const timeout = setTimeout(() => {
        ws.close();
        reject(new Error('Timeout'));
      }, 3000);

      ws.addEventListener('open', () => {
        clearTimeout(timeout);
        ws.close();
        resolve();
      });

      ws.addEventListener('error', reject);
    });
  }

  async testHttp(url) {
    const controller = new AbortController();
    setTimeout(() => controller.abort(), 3000);

    const response = await fetch(url, { signal: controller.signal });
    if (!response.ok) throw new Error('HTTP test failed');
  }
}
```

### Performance Optimization

#### Message Batching

Reduce overhead by batching multiple messages into single transmissions:

```javascript
class BatchingTransport {
  constructor(transport, options = {}) {
    this.transport = transport;
    this.batchSize = options.batchSize || 10;
    this.batchTimeout = options.batchTimeout || 100;
    this.pendingMessages = [];
    this.batchTimer = null;
  }

  send(data) {
    this.pendingMessages.push(data);

    if (this.pendingMessages.length >= this.batchSize) {
      this.flush();
    } else if (!this.batchTimer) {
      this.batchTimer = setTimeout(() => this.flush(), this.batchTimeout);
    }
  }

  flush() {
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
      this.batchTimer = null;
    }

    if (this.pendingMessages.length === 0) return;

    const batch = {
      type: 'batch',
      messages: this.pendingMessages.splice(0)
    };

    this.transport.send(batch);
  }

  async close() {
    this.flush();
    await this.transport.close();
  }
}
```

#### Message Compression

Compress large payloads before transmission:

```javascript
class CompressionTransport {
  constructor(transport, options = {}) {
    this.transport = transport;
    this.compressionThreshold = options.threshold || 1024; // 1KB
    this.compressionStream = null;
  }

  async send(data) {
    const serialized = JSON.stringify(data);
    
    if (serialized.length < this.compressionThreshold) {
      return this.transport.send({ compressed: false, data });
    }

    const compressed = await this.compress(serialized);
```

---

## Long Polling

### Core Mechanism

Long polling maintains a persistent connection by keeping HTTP requests open until the server has new data to send. When the server responds, the client immediately initiates a new request, creating a continuous communication channel. Unlike traditional polling which makes frequent requests at fixed intervals regardless of data availability, long polling reduces unnecessary network traffic by only responding when meaningful updates exist.

The server holds the request open, monitoring for events or changes. Once data becomes available or a timeout occurs, it responds to the pending request. The client processes the response and immediately establishes a new long-polling connection.

### Implementation Pattern

#### Basic Long Polling Loop

```javascript
async function longPoll(url, options = {}) {
  while (true) {
    try {
      const response = await fetch(url, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
        signal: options.signal,
      });

      if (!response.ok) {
        throw new Error(`HTTP error: ${response.status}`);
      }

      const data = await response.json();
      
      if (options.onMessage) {
        options.onMessage(data);
      }

      if (options.shouldContinue && !options.shouldContinue(data)) {
        break;
      }
    } catch (error) {
      if (error.name === 'AbortError') {
        break;
      }

      if (options.onError) {
        options.onError(error);
      }

      await new Promise(resolve => setTimeout(resolve, options.retryDelay || 5000));
    }
  }
}
```

#### Cancellation Support

```javascript
const controller = new AbortController();

longPoll('/api/updates', {
  signal: controller.signal,
  onMessage: (data) => {
    console.log('Received:', data);
  },
  onError: (error) => {
    console.error('Error:', error);
  }
});

// Stop polling
controller.abort();
```

### Timeout Handling

#### Server-Side Timeout

Servers typically implement timeouts to prevent indefinite connection holding:

```javascript
// Server timeout after 30 seconds
async function longPoll(url) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 30000);

  try {
    const response = await fetch(url, {
      signal: controller.signal
    });
    clearTimeout(timeoutId);
    return await response.json();
  } catch (error) {
    clearTimeout(timeoutId);
    if (error.name === 'AbortError') {
      // Timeout occurred, reconnect
      return longPoll(url);
    }
    throw error;
  }
}
```

#### Client-Side Timeout

```javascript
async function longPollWithTimeout(url, clientTimeout = 35000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), clientTimeout);

  try {
    const response = await fetch(url, { signal: controller.signal });
    clearTimeout(timeoutId);
    
    if (response.status === 204) {
      // No content, server timeout
      return longPollWithTimeout(url, clientTimeout);
    }
    
    return await response.json();
  } catch (error) {
    clearTimeout(timeoutId);
    throw error;
  }
}
```

### Reconnection Strategies

#### Exponential Backoff

```javascript
async function longPollWithBackoff(url, maxRetries = 5) {
  let retryCount = 0;
  let delay = 1000;

  while (retryCount < maxRetries) {
    try {
      const response = await fetch(url);
      retryCount = 0; // Reset on success
      delay = 1000;
      
      const data = await response.json();
      handleData(data);
      
      // Immediately reconnect
      continue;
    } catch (error) {
      retryCount++;
      console.error(`Attempt ${retryCount} failed:`, error);
      
      if (retryCount >= maxRetries) {
        throw new Error('Max retries exceeded');
      }
      
      await new Promise(resolve => setTimeout(resolve, delay));
      delay = Math.min(delay * 2, 30000); // Cap at 30 seconds
    }
  }
}
```

#### Jittered Backoff

```javascript
function calculateJitteredDelay(baseDelay, attempt, maxDelay = 30000) {
  const exponentialDelay = Math.min(baseDelay * Math.pow(2, attempt), maxDelay);
  const jitter = Math.random() * exponentialDelay * 0.3;
  return exponentialDelay + jitter;
}

async function longPollWithJitter(url) {
  let attempt = 0;

  while (true) {
    try {
      const response = await fetch(url);
      attempt = 0; // Reset on success
      
      const data = await response.json();
      processData(data);
    } catch (error) {
      const delay = calculateJitteredDelay(1000, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
      attempt++;
    }
  }
}
```

### State Management

#### Tracking Connection State

```javascript
class LongPollingClient {
  constructor(url) {
    this.url = url;
    this.state = 'disconnected'; // 'disconnected', 'connecting', 'connected'
    this.controller = null;
    this.listeners = new Set();
  }

  on(event, callback) {
    this.listeners.add({ event, callback });
  }

  emit(event, data) {
    this.listeners.forEach(({ event: e, callback }) => {
      if (e === event) callback(data);
    });
  }

  async start() {
    if (this.state !== 'disconnected') return;
    
    this.controller = new AbortController();
    this.state = 'connecting';
    this.emit('stateChange', 'connecting');
    
    await this.poll();
  }

  async poll() {
    while (this.state !== 'disconnected') {
      try {
        const response = await fetch(this.url, {
          signal: this.controller.signal
        });

        if (this.state === 'connecting') {
          this.state = 'connected';
          this.emit('stateChange', 'connected');
        }

        const data = await response.json();
        this.emit('message', data);
      } catch (error) {
        if (error.name === 'AbortError') break;
        
        this.state = 'connecting';
        this.emit('stateChange', 'connecting');
        this.emit('error', error);
        
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }
  }

  stop() {
    if (this.controller) {
      this.controller.abort();
    }
    this.state = 'disconnected';
    this.emit('stateChange', 'disconnected');
  }
}
```

#### Last Event ID Pattern

```javascript
async function longPollWithEventId(url) {
  let lastEventId = localStorage.getItem('lastEventId') || '0';

  while (true) {
    try {
      const response = await fetch(`${url}?lastEventId=${lastEventId}`);
      const data = await response.json();
      
      if (data.eventId) {
        lastEventId = data.eventId;
        localStorage.setItem('lastEventId', lastEventId);
      }
      
      processEvents(data.events);
    } catch (error) {
      console.error('Polling error:', error);
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }
}
```

### Request Configuration

#### Headers and Authentication

```javascript
async function authenticatedLongPoll(url, token) {
  while (true) {
    try {
      const response = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${token}`,
          'X-Client-Version': '1.0.0',
          'Accept': 'application/json',
        },
        credentials: 'include',
      });

      if (response.status === 401) {
        // Token expired, refresh
        token = await refreshToken();
        continue;
      }

      const data = await response.json();
      handleUpdate(data);
    } catch (error) {
      handleError(error);
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
```

#### Request Body for Filtering

```javascript
async function filteredLongPoll(url, filters) {
  while (true) {
    try {
      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          filters: filters,
          timestamp: Date.now(),
        }),
      });

      const data = await response.json();
      processFilteredData(data);
    } catch (error) {
      console.error(error);
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
```

### Error Recovery

#### Network Error Handling

```javascript
async function robustLongPoll(url) {
  const maxConsecutiveErrors = 3;
  let consecutiveErrors = 0;

  while (true) {
    try {
      const response = await fetch(url);
      
      if (!response.ok) {
        if (response.status >= 500) {
          throw new Error('Server error');
        } else if (response.status === 429) {
          const retryAfter = response.headers.get('Retry-After') || 60;
          await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
          continue;
        } else {
          throw new Error(`HTTP ${response.status}`);
        }
      }

      consecutiveErrors = 0;
      const data = await response.json();
      processData(data);
    } catch (error) {
      consecutiveErrors++;

      if (consecutiveErrors >= maxConsecutiveErrors) {
        notifyConnectionFailure();
        await new Promise(resolve => setTimeout(resolve, 30000));
        consecutiveErrors = 0;
      } else {
        await new Promise(resolve => setTimeout(resolve, 5000));
      }
    }
  }
}
```

#### Partial Response Handling

```javascript
async function handlePartialResponses(url) {
  while (true) {
    try {
      const response = await fetch(url);
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        
        // Process complete JSON objects
        let boundary;
        while ((boundary = buffer.indexOf('\n')) !== -1) {
          const line = buffer.slice(0, boundary);
          buffer = buffer.slice(boundary + 1);
          
          if (line.trim()) {
            try {
              const data = JSON.parse(line);
              handleMessage(data);
            } catch (e) {
              console.error('Parse error:', e);
            }
          }
        }
      }
      
      // Reconnect
      continue;
    } catch (error) {
      console.error(error);
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
```

### Performance Optimization

#### Connection Pooling

```javascript
class LongPollingPool {
  constructor(baseUrl, poolSize = 3) {
    this.baseUrl = baseUrl;
    this.poolSize = poolSize;
    this.connections = [];
    this.messageQueue = [];
  }

  async start() {
    for (let i = 0; i < this.poolSize; i++) {
      this.connections.push(this.createConnection(i));
    }
  }

  async createConnection(id) {
    while (true) {
      try {
        const response = await fetch(`${this.baseUrl}?conn=${id}`);
        const data = await response.json();
        
        data.messages.forEach(msg => this.messageQueue.push(msg));
        this.processQueue();
      } catch (error) {
        console.error(`Connection ${id} error:`, error);
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    }
  }

  processQueue() {
    while (this.messageQueue.length > 0) {
      const message = this.messageQueue.shift();
      this.handleMessage(message);
    }
  }

  handleMessage(message) {
    // Process message
  }

  stop() {
    // Stop all connections
  }
}
```

#### Request Deduplication

```javascript
class DedupedLongPolling {
  constructor(url) {
    this.url = url;
    this.pendingRequest = null;
    this.subscribers = new Set();
  }

  async subscribe(callback) {
    this.subscribers.add(callback);

    if (!this.pendingRequest) {
      this.pendingRequest = this.poll();
    }

    return () => this.subscribers.delete(callback);
  }

  async poll() {
    while (this.subscribers.size > 0) {
      try {
        const response = await fetch(this.url);
        const data = await response.json();

        this.subscribers.forEach(callback => {
          try {
            callback(data);
          } catch (error) {
            console.error('Subscriber error:', error);
          }
        });
      } catch (error) {
        console.error('Polling error:', error);
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }

    this.pendingRequest = null;
  }
}
```

### Browser Lifecycle Integration

#### Visibility API Integration

```javascript
class VisibilityAwareLongPolling {
  constructor(url) {
    this.url = url;
    this.controller = null;
    this.isPolling = false;

    document.addEventListener('visibilitychange', () => {
      if (document.hidden) {
        this.pause();
      } else {
        this.resume();
      }
    });
  }

  async start() {
    if (this.isPolling) return;
    
    this.isPolling = true;
    this.controller = new AbortController();
    
    await this.poll();
  }

  async poll() {
    while (this.isPolling && !document.hidden) {
      try {
        const response = await fetch(this.url, {
          signal: this.controller.signal
        });
        
        const data = await response.json();
        this.handleData(data);
      } catch (error) {
        if (error.name === 'AbortError') break;
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }
  }

  pause() {
    if (this.controller) {
      this.controller.abort();
      this.controller = null;
    }
  }

  resume() {
    if (this.isPolling && !this.controller) {
      this.start();
    }
  }

  stop() {
    this.isPolling = false;
    if (this.controller) {
      this.controller.abort();
    }
  }

  handleData(data) {
    // Process data
  }
}
```

#### Online/Offline Detection

```javascript
class NetworkAwareLongPolling {
  constructor(url) {
    this.url = url;
    this.online = navigator.onLine;
    this.controller = null;

    window.addEventListener('online', () => {
      this.online = true;
      this.reconnect();
    });

    window.addEventListener('offline', () => {
      this.online = false;
      if (this.controller) {
        this.controller.abort();
      }
    });
  }

  async start() {
    if (!this.online) {
      console.log('Offline, waiting for connection');
      return;
    }

    await this.poll();
  }

  async poll() {
    this.controller = new AbortController();

    while (this.online) {
      try {
        const response = await fetch(this.url, {
          signal: this.controller.signal
        });

        const data = await response.json();
        this.processData(data);
      } catch (error) {
        if (error.name === 'AbortError') break;
        
        // Check if still online
        if (!navigator.onLine) {
          this.online = false;
          break;
        }

        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }
  }

  reconnect() {
    this.start();
  }

  processData(data) {
    // Handle data
  }
}
```

### Comparison with Alternatives

#### Long Polling vs Short Polling

Short polling makes requests at fixed intervals regardless of data availability. Long polling keeps connections open until data exists, reducing unnecessary requests and latency.

**Latency**: Long polling delivers updates immediately when available. Short polling has latency up to the polling interval.

**Server Load**: Long polling maintains fewer connections but holds them longer. Short polling creates more frequent connections but releases them quickly.

**Network Efficiency**: Long polling reduces bandwidth when updates are infrequent. Short polling generates constant traffic regardless of activity.

#### Long Polling vs WebSockets

WebSockets provide full-duplex bidirectional communication over a persistent connection. Long polling is unidirectional (server to client) and uses HTTP requests.

**Connection Model**: WebSockets establish a single persistent connection. Long polling creates sequential HTTP connections.

**Protocol Overhead**: WebSockets have minimal framing overhead after handshake. Long polling repeats HTTP headers with each request.

**Browser Support**: Long polling works universally with HTTP. WebSockets require WebSocket protocol support.

**Proxy Compatibility**: Long polling works through HTTP proxies. WebSockets may be blocked by some proxies and firewalls.

**Implementation Complexity**: Long polling uses standard fetch API. WebSockets require WebSocket API and more complex state management.

#### Long Polling vs Server-Sent Events

Server-Sent Events (SSE) provide server-to-client streaming over HTTP with automatic reconnection. Long polling requires manual reconnection logic.

**Connection Persistence**: SSE maintains a persistent connection for multiple messages. Long polling creates new connections per message.

**Reconnection**: SSE includes automatic reconnection with last event ID. Long polling requires manual implementation.

**Message Format**: SSE uses text-based event stream format. Long polling can use any response format.

**Browser API**: SSE uses EventSource API with built-in features. Long polling uses fetch with custom implementation.

**Binary Data**: Long polling can handle binary responses. SSE is text-only.

### Use Cases

#### Chat Applications

Long polling works for chat applications where message frequency is moderate and WebSocket infrastructure is unavailable:

```javascript
class ChatLongPolling {
  constructor(chatId, userId) {
    this.chatId = chatId;
    this.userId = userId;
    this.lastMessageId = 0;
  }

  async start() {
    while (true) {
      try {
        const response = await fetch(`/api/chat/${this.chatId}/messages`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            lastMessageId: this.lastMessageId,
            userId: this.userId
          })
        });

        const { messages } = await response.json();
        
        if (messages.length > 0) {
          this.displayMessages(messages);
          this.lastMessageId = messages[messages.length - 1].id;
        }
      } catch (error) {
        console.error('Chat polling error:', error);
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    }
  }

  displayMessages(messages) {
    messages.forEach(msg => {
      // Render message in UI
    });
  }
}
```

#### Notification Systems

Long polling efficiently delivers notifications without constant polling overhead:

```javascript
async function pollNotifications(userId) {
  let sequence = 0;

  while (true) {
    try {
      const response = await fetch(`/api/notifications/${userId}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ sequence })
      });

      const { notifications, nextSequence } = await response.json();
      
      if (notifications.length > 0) {
        notifications.forEach(showNotification);
        sequence = nextSequence;
      }
    } catch (error) {
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }
}
```

#### Live Dashboard Updates

Long polling provides near-real-time dashboard updates without WebSocket complexity:

```javascript
class DashboardPoller {
  constructor(dashboardId) {
    this.dashboardId = dashboardId;
    this.widgets = new Map();
  }

  async pollWidget(widgetId) {
    while (true) {
      try {
        const response = await fetch(
          `/api/dashboard/${this.dashboardId}/widget/${widgetId}/data`
        );

        const data = await response.json();
        this.updateWidget(widgetId, data);
      } catch (error) {
        console.error(`Widget ${widgetId} error:`, error);
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }
  }

  startPolling(widgetIds) {
    widgetIds.forEach(id => {
      this.pollWidget(id);
    });
  }

  updateWidget(widgetId, data) {
    // Update widget display
  }
}
```

### Security Considerations

#### Request Authentication

```javascript
async function secureLongPoll(url) {
  let token = await getAuthToken();
  let tokenRefreshTime = Date.now() + 50 * 60 * 1000; // 50 minutes

  while (true) {
    // Refresh token before expiry
    if (Date.now() >= tokenRefreshTime) {
      token = await refreshAuthToken();
      tokenRefreshTime = Date.now() + 50 * 60 * 1000;
    }

    try {
      const response = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${token}`,
          'X-Request-ID': generateRequestId(),
        },
        credentials: 'include',
      });

      if (response.status === 401) {
        token = await refreshAuthToken();
        continue;
      }

      const data = await response.json();
      processSecureData(data);
    } catch (error) {
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
```

#### Rate Limiting Compliance

```javascript
class RateLimitedLongPolling {
  constructor(url) {
    this.url = url;
    this.requestCount = 0;
    this.resetTime = Date.now() + 60000;
    this.maxRequests = 100;
  }

  async poll() {
    while (true) {
      // Check rate limit
      if (Date.now() >= this.resetTime) {
        this.requestCount = 0;
        this.resetTime = Date.now() + 60000;
      }

      if (this.requestCount >= this.maxRequests) {
        const waitTime = this.resetTime - Date.now();
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }

      try {
        this.requestCount++;
        const response = await fetch(this.url);

        // Update limits from response headers
        const remaining = response.headers.get('X-RateLimit-Remaining');
        const reset = response.headers.get('X-RateLimit-Reset');
        
        if (remaining) this.maxRequests = parseInt(remaining);
        if (reset) this.resetTime = parseInt(reset) * 1000;

        const data = await response.json();
        this.handleData(data);
      } catch (error) {
        await new Promise(resolve => setTimeout(resolve, 5000));
      }
    }
  }

  handleData(data) {
    // Process data
  }
}
```

#### CSRF Protection

```javascript
async function csrfProtectedLongPoll(url) {
  let csrfToken = document.querySelector('meta[name="csrf-token"]')?.content;

  while (true) {
    try {
      const response = await fetch(url, {
        headers: {
          'X-CSRF-Token': csrfToken,
          'Content-Type': 'application/json',
        },
        credentials: 'same-origin',
      });

      if (response.status === 403) {
        // CSRF token expired, reload page
        window.location.reload();
        break;
      }

      const data = await response.json();
      processData(data);
    } catch (error) {
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}
```

## Data Synchronization

### Real-time Synchronization

#### WebSocket + Fetch Hybrid

```javascript
function useRealtimeSync(endpoint, wsUrl) {
  const [data, setData] = useState(null);
  const [status, setStatus] = useState('disconnected');
  const wsRef = useRef(null);

  const fetchInitialData = useCallback(async () => {
    const res = await fetch(endpoint);
    if (!res.ok) throw new Error('Failed to fetch');
    const json = await res.json();
    setData(json);
  }, [endpoint]);

  useEffect(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      setStatus('connected');
      fetchInitialData();
    };

    ws.onmessage = (event) => {
      const update = JSON.parse(event.data);
      setData(prev => {
        if (update.type === 'full') return update.data;
        if (update.type === 'patch') return applyPatch(prev, update.patch);
        return prev;
      });
    };

    ws.onerror = () => setStatus('error');
    ws.onclose = () => setStatus('disconnected');

    return () => ws.close();
  }, [wsUrl, fetchInitialData]);

  return { data, status };
}
```

#### Server-Sent Events

```javascript
function useSSESync(url) {
  const [data, setData] = useState(null);
  const [status, setStatus] = useState('connecting');

  useEffect(() => {
    const eventSource = new EventSource(url);

    eventSource.onopen = () => setStatus('connected');
    eventSource.onmessage = (e) => setData(JSON.parse(e.data));
    eventSource.addEventListener('patch', (e) => {
      const patch = JSON.parse(e.data);
      setData(prev => applyPatch(prev, patch));
    });
    eventSource.onerror = () => setStatus('error');

    return () => eventSource.close();
  }, [url]);

  return { data, status };
}
```

### Optimistic UI

#### Queue-based Updates

```javascript
function useOptimisticQueue(endpoint) {
  const [data, setData] = useState([]);
  const [queue, setQueue] = useState([]);
  const [syncing, setSyncing] = useState(false);

  const processQueue = useCallback(async () => {
    if (queue.length === 0 || syncing) return;

    setSyncing(true);
    const operation = queue[0];

    try {
      const res = await fetch(endpoint, {
        method: operation.method,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(operation.data)
      });

      if (!res.ok) throw new Error('Sync failed');
      const result = await res.json();

      setData(prev => prev.map(item =>
        item.id === operation.tempId ? { ...result, id: result.id } : item
      ));

      setQueue(prev => prev.slice(1));
    } catch (err) {
      setData(prev => prev.filter(item => item.id !== operation.tempId));
      setQueue(prev => prev.slice(1));
    } finally {
      setSyncing(false);
    }
  }, [endpoint, queue, syncing]);

  useEffect(() => {
    if (queue.length > 0) processQueue();
  }, [queue, processQueue]);

  const addItem = useCallback((item) => {
    const tempId = `temp-${Date.now()}`;
    setData(prev => [...prev, { ...item, id: tempId, _pending: true }]);
    setQueue(prev => [...prev, { method: 'POST', data: item, tempId }]);
  }, []);

  return { data, addItem, syncing, queueSize: queue.length };
}
```

#### Conflict Resolution

```javascript
function useConflictResolution(endpoint, strategy = 'server-wins') {
  const [data, setData] = useState({});
  const [conflicts, setConflicts] = useState([]);
  const versionRef = useRef({});

  const updateItem = useCallback(async (id, updates) => {
    const currentVersion = versionRef.current[id];
    const optimistic = { ...data[id], ...updates };

    setData(prev => ({ ...prev, [id]: optimistic }));

    try {
      const res = await fetch(`${endpoint}/${id}`, {
        method: 'PATCH',
        headers: { 
          'Content-Type': 'application/json',
          'If-Match': currentVersion
        },
        body: JSON.stringify(updates)
      });

      if (res.status === 412) {
        const serverData = await res.json();
        
        setConflicts(prev => [...prev, {
          id,
          local: optimistic,
          server: serverData.current,
          timestamp: Date.now()
        }]);

        if (strategy === 'server-wins') {
          setData(prev => ({ ...prev, [id]: serverData.current }));
          versionRef.current[id] = serverData.current.version;
        }

        return { conflict: true, data: serverData.current };
      }

      const result = await res.json();
      setData(prev => ({ ...prev, [id]: result }));
      versionRef.current[id] = result.version;

      return { conflict: false, data: result };
    } catch (err) {
      setData(prev => ({ ...prev, [id]: data[id] }));
      throw err;
    }
  }, [endpoint, data, strategy]);

  return { data: Object.values(data), conflicts, updateItem };
}
```

### Offline Synchronization

#### IndexedDB Queue

```javascript
function useOfflineSync(endpoint, dbName = 'offline-queue') {
  const [online, setOnline] = useState(navigator.onLine);
  const [pendingCount, setPendingCount] = useState(0);
  const dbRef = useRef(null);

  useEffect(() => {
    const request = indexedDB.open(dbName, 1);

    request.onupgradeneeded = (e) => {
      const db = e.target.result;
      if (!db.objectStoreNames.contains('queue')) {
        db.createObjectStore('queue', { keyPath: 'id', autoIncrement: true });
      }
    };

    request.onsuccess = (e) => {
      dbRef.current = e.target.result;
      updateCount();
    };

    const handleOnline = () => {
      setOnline(true);
      syncQueue();
    };

    window.addEventListener('online', handleOnline);
    window.addEventListener('offline', () => setOnline(false));

    return () => {
      window.removeEventListener('online', handleOnline);
      if (dbRef.current) dbRef.current.close();
    };
  }, []);

  const updateCount = useCallback(() => {
    if (!dbRef.current) return;
    const tx = dbRef.current.transaction(['queue'], 'readonly');
    const store = tx.objectStore('queue');
    const req = store.count();
    req.onsuccess = () => setPendingCount(req.result);
  }, []);

  const enqueue = useCallback(async (operation) => {
    if (!dbRef.current) return;
    const tx = dbRef.current.transaction(['queue'], 'readwrite');
    const store = tx.objectStore('queue');
    store.add({ ...operation, timestamp: Date.now() });
    tx.oncomplete = () => {
      updateCount();
      if (online) syncQueue();
    };
  }, [online]);

  const syncQueue = useCallback(async () => {
    if (!dbRef.current || !online) return;
    const tx = dbRef.current.transaction(['queue'], 'readwrite');
    const store = tx.objectStore('queue');
    const req = store.getAll();

    req.onsuccess = async () => {
      for (const item of req.result) {
        try {
          const res = await fetch(`${endpoint}${item.path}`, {
            method: item.method,
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(item.data)
          });

          if (res.ok) {
            const delTx = dbRef.current.transaction(['queue'], 'readwrite');
            delTx.objectStore('queue').delete(item.id);
          }
        } catch (err) {
          console.error('Sync error:', err);
        }
      }
      updateCount();
    };
  }, [endpoint, online]);

  return { online, pendingCount, enqueue, syncQueue };
}
```

#### Cache-First Strategy

```javascript
function useCacheFirstSync(endpoint) {
  const [data, setData] = useState(null);
  const [cacheAge, setCacheAge] = useState(null);

  const getCacheKey = () => `cache:${endpoint}`;

  const loadCache = useCallback(async () => {
    const cached = localStorage.getItem(getCacheKey());
    if (cached) {
      const { data, timestamp } = JSON.parse(cached);
      setData(data);
      setCacheAge(Date.now() - timestamp);
      return true;
    }
    return false;
  }, [endpoint]);

  const saveCache = useCallback((data) => {
    localStorage.setItem(getCacheKey(), JSON.stringify({
      data,
      timestamp: Date.now()
    }));
  }, [endpoint]);

  const fetchServer = useCallback(async () => {
    const res = await fetch(endpoint);
    if (!res.ok) throw new Error('Fetch failed');
    const json = await res.json();
    setData(json);
    saveCache(json);
    setCacheAge(0);
  }, [endpoint, saveCache]);

  useEffect(() => {
    loadCache().then(hasCache => {
      if (!hasCache) fetchServer();
      else fetchServer(); // Background sync
    });
  }, []);

  return { data, cacheAge };
}
```

### Differential Sync

#### Delta Updates

```javascript
function useDeltaSync(endpoint) {
  const [data, setData] = useState([]);
  const [lastSync, setLastSync] = useState(null);

  const fetchDelta = useCallback(async () => {
    const params = new URLSearchParams();
    if (lastSync) params.set('since', lastSync.toISOString());

    const res = await fetch(`${endpoint}?${params}`);
    if (!res.ok) throw new Error('Delta fetch failed');

    const delta = await res.json();

    setData(prev => {
      let updated = [...prev];

      if (delta.deleted) {
        updated = updated.filter(item => !delta.deleted.includes(item.id));
      }

      if (delta.updated) {
        delta.updated.forEach(newItem => {
          const idx = updated.findIndex(item => item.id === newItem.id);
          if (idx >= 0) updated[idx] = newItem;
          else updated.push(newItem);
        });
      }

      return updated;
    });

    setLastSync(new Date());
  }, [endpoint, lastSync]);

  return { data, fetchDelta, lastSync };
}
```

#### Three-way Merge

```javascript
function useThreeWayMerge(endpoint) {
  const [data, setData] = useState({});
  const baselineRef = useRef({});
  const dirtyRef = useRef(new Set());

  const merge = useCallback((base, local, server) => {
    const merged = { ...base };

    Object.keys({ ...local, ...server }).forEach(key => {
      const baseVal = base[key];
      const localVal = local[key];
      const serverVal = server[key];

      if (localVal === serverVal) {
        merged[key] = localVal;
      } else if (localVal === baseVal) {
        merged[key] = serverVal;
      } else if (serverVal === baseVal) {
        merged[key] = localVal;
      } else {
        merged[key] = { _conflict: true, local: localVal, server: serverVal };
      }
    });

    return merged;
  }, []);

  const updateLocal = useCallback((id, updates) => {
    setData(prev => {
      dirtyRef.current.add(id);
      return { ...prev, [id]: { ...prev[id], ...updates } };
    });
  }, []);

  const sync = useCallback(async () => {
    const dirtyIds = Array.from(dirtyRef.current);
    if (dirtyIds.length === 0) return;

    const res = await fetch(`${endpoint}/sync`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ ids: dirtyIds })
    });

    const serverData = await res.json();

    setData(prev => {
      const merged = { ...prev };
      dirtyIds.forEach(id => {
        const base = baselineRef.current[id] || {};
        merged[id] = merge(base, prev[id], serverData[id]);
        baselineRef.current[id] = serverData[id];
      });
      return merged;
    });

    dirtyRef.current.clear();
  }, [endpoint, merge]);

  return { data: Object.values(data), updateLocal, sync };
}
```

### Batch Synchronization

#### Batch Processor

```javascript
function useBatchSync(endpoint, batchSize = 10, delay = 1000) {
  const [pending, setPending] = useState([]);
  const [processing, setProcessing] = useState(false);

  const processBatch = useCallback(async () => {
    if (processing || pending.length === 0) return;

    setProcessing(true);
    const batch = pending.slice(0, batchSize);

    try {
      const res = await fetch(`${endpoint}/batch`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ operations: batch })
      });

      if (res.ok) {
        setPending(prev => prev.slice(batchSize));
      }
    } catch (err) {
      console.error('Batch failed:', err);
    } finally {
      setProcessing(false);
    }
  }, [endpoint, batchSize, pending, processing]);

  useEffect(() => {
    if (pending.length >= batchSize) {
      processBatch();
    } else if (pending.length > 0) {
      const timer = setTimeout(processBatch, delay);
      return () => clearTimeout(timer);
    }
  }, [pending, batchSize, delay, processBatch]);

  const addOperation = useCallback((op) => {
    setPending(prev => [...prev, { ...op, id: Date.now() }]);
  }, []);

  return { addOperation, pendingCount: pending.length, processing };
}
```

### Eventual Consistency

#### CRDT Operations

```javascript
function useCRDTSync(endpoint, userId) {
  const [state, setState] = useState({ items: new Map(), vector: {} });

  const addItem = useCallback(async (item) => {
    const vector = { ...state.vector, [userId]: (state.vector[userId] || 0) + 1 };
    const operation = {
      type: 'add',
      id: `${userId}-${Date.now()}`,
      data: item,
      vector
    };

    setState(prev => {
      const items = new Map(prev.items);
      items.set(operation.id, item);
      return { items, vector };
    });

    await fetch(`${endpoint}/operations`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(operation)
    });
  }, [endpoint, userId, state.vector]);

  return { items: Array.from(state.items.values()), addItem };
}
```

### Polling Strategies

#### Smart Polling

```javascript
function useSmartPolling(endpoint, baseInterval = 5000) {
  const [data, setData] = useState(null);
  const [interval, setInterval] = useState(baseInterval);
  const lastChangeRef = useRef(Date.now());

  useEffect(() => {
    const poll = async () => {
      const res = await fetch(endpoint);
      const json = await res.json();

      if (JSON.stringify(json) !== JSON.stringify(data)) {
        lastChangeRef.current = Date.now();
        setInterval(baseInterval);
      } else {
        const timeSinceChange = Date.now() - lastChangeRef.current;
        if (timeSinceChange > 30000) {
          setInterval(Math.min(interval * 1.5, 60000));
        }
      }

      setData(json);
    };

    poll();
    const timer = setInterval(poll, interval);
    return () => clearInterval(timer);
  }, [endpoint, interval, baseInterval, data]);

  return { data };
}
```

#### Long Polling

```javascript
function useLongPolling(endpoint) {
  const [data, setData] = useState(null);
  const [connected, setConnected] = useState(false);

  useEffect(() => {
    let active = true;

    const poll = async () => {
      try {
        setConnected(true);
        const res = await fetch(`${endpoint}?timeout=30`);
        if (!res.ok) throw new Error('Poll failed');

        const json = await res.json();
        if (active) {
          setData(json);
          poll();
        }
      } catch (err) {
        setConnected(false);
        if (active) {
          setTimeout(poll, 3000);
        }
      }
    };

    poll();

    return () => {
      active = false;
    };
  }, [endpoint]);

  return { data, connected };
}
```

### Sync Coordination

#### Leader Election

```javascript
function useLeaderElection(tabId = Math.random().toString(36)) {
  const [isLeader, setIsLeader] = useState(false);
  const channelRef = useRef(null);

  useEffect(() => {
    const channel = new BroadcastChannel('sync-coordination');
    channelRef.current = channel;

    const heartbeatKey = 'leader-heartbeat';
    
    const checkLeadership = () => {
      const lastHeartbeat = localStorage.getItem(heartbeatKey);
      const now = Date.now();

      if (!lastHeartbeat || now - parseInt(lastHeartbeat) > 5000) {
        localStorage.setItem(heartbeatKey, now.toString());
        setIsLeader(true);
        channel.postMessage({ type: 'leader', id: tabId });
      } else {
        setIsLeader(false);
      }
    };

    channel.onmessage = (e) => {
      if (e.data.type === 'leader' && e.data.id !== tabId) {
        setIsLeader(false);
      }
    };

    checkLeadership();
    const interval = setInterval(checkLeadership, 2000);

    return () => {
      clearInterval(interval);
      channel.close();
    };
  }, [tabId]);

  return isLeader;
}
```

#### Broadcast Updates

```javascript
function useBroadcastSync(channelName = 'data-sync') {
  const [data, setData] = useState(null);
  const channelRef = useRef(null);

  useEffect(() => {
    const channel = new BroadcastChannel(channelName);
    channelRef.current = channel;

    channel.onmessage = (event) => {
      if (event.data.type === 'update') {
        setData(event.data.payload);
      }
    };

    return () => channel.close();
  }, [channelName]);

  const broadcastUpdate = useCallback((newData) => {
    setData(newData);
    channelRef.current?.postMessage({
      type: 'update',
      payload: newData,
      timestamp: Date.now()
    });
  }, []);

  return { data, broadcastUpdate };
}
```

---

# API Design Considerations

## REST API Best Practices

### Resource Naming Conventions

#### Plural Nouns for Collections

Use plural nouns to represent resource collections:

```
✅ GET /users
✅ GET /products
✅ GET /orders

❌ GET /user
❌ GET /product
❌ GET /getUsers
```

#### Hierarchical Resource Relationships

Express resource relationships through URL structure:

```
GET    /users/123/orders           # User's orders
GET    /users/123/orders/456       # Specific order for user
POST   /users/123/addresses        # Create address for user
GET    /organizations/789/members  # Organization members
DELETE /posts/456/comments/789     # Delete comment from post
```

Limit nesting to 2-3 levels maximum for readability.

#### Lowercase with Hyphens

Use lowercase letters with hyphens for multi-word resources:

```
✅ /product-categories
✅ /user-profiles
✅ /shipping-addresses

❌ /productCategories
❌ /UserProfiles
❌ /shipping_addresses
```

#### Avoid File Extensions

Exclude file extensions; use `Accept` header for content negotiation:

```
✅ GET /users/123
   Accept: application/json

❌ GET /users/123.json
❌ GET /users/123.xml
```

### HTTP Method Usage

#### Standard CRUD Operations

Map operations to appropriate HTTP methods:

```
GET    /users           # List all users
GET    /users/123       # Retrieve specific user
POST   /users           # Create new user
PUT    /users/123       # Replace entire user
PATCH  /users/123       # Partial update user
DELETE /users/123       # Delete user
```

#### Idempotency Considerations

Idempotent methods produce same result on repeated calls:

- **GET, PUT, DELETE, HEAD, OPTIONS**: Idempotent
- **POST, PATCH**: Not guaranteed idempotent

```
# Idempotent - safe to retry
PUT /users/123
{
  "name": "John Doe",
  "email": "john@example.com"
}

# Not idempotent - multiple calls create multiple resources
POST /users
{
  "name": "John Doe"
}
```

#### Safe Methods

GET, HEAD, OPTIONS should never modify resources:

```
✅ GET /users/123        # Read-only operation

❌ GET /users/123/delete # Mutation via GET
❌ GET /orders/456/pay   # Side effects via GET
```

#### Method-Specific Semantics

**POST**: Create subordinate resources, non-idempotent operations

```
POST /users
POST /payments/process
POST /orders/123/refund
```

**PUT**: Complete replacement, must include all fields

```
PUT /users/123
{
  "name": "John Doe",
  "email": "john@example.com",
  "phone": "+1234567890",
  "address": "123 Main St"
}
```

**PATCH**: Partial updates, include only changed fields

```
PATCH /users/123
{
  "email": "newemail@example.com"
}
```

**DELETE**: Remove resources, return appropriate status

```
DELETE /users/123

# First call: 204 No Content
# Subsequent calls: 404 Not Found
```

### Status Code Standards

#### Success Codes (2xx)

Use specific success codes:

```
200 OK                  # Successful GET, PUT, PATCH with response body
201 Created             # Successful POST creating resource
204 No Content          # Successful DELETE or update with no response body
202 Accepted            # Request accepted for async processing
206 Partial Content     # Partial GET (range requests)
```

Example responses:

```
POST /users
201 Created
Location: /users/123
{
  "id": 123,
  "name": "John Doe",
  "createdAt": "2024-01-15T10:30:00Z"
}

DELETE /users/123
204 No Content
```

#### Client Error Codes (4xx)

Indicate client-side issues:

```
400 Bad Request         # Malformed request, validation errors
401 Unauthorized        # Missing or invalid authentication
403 Forbidden           # Authenticated but insufficient permissions
404 Not Found           # Resource doesn't exist
405 Method Not Allowed  # HTTP method not supported for endpoint
409 Conflict            # Resource state conflict (e.g., duplicate email)
410 Gone                # Resource permanently deleted
422 Unprocessable Entity # Semantic validation errors
429 Too Many Requests   # Rate limit exceeded
```

Detailed error responses:

```json
400 Bad Request
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "details": [
      {
        "field": "email",
        "message": "Invalid email format"
      },
      {
        "field": "age",
        "message": "Must be at least 18"
      }
    ]
  }
}
```

#### Server Error Codes (5xx)

Indicate server-side failures:

```
500 Internal Server Error  # Unexpected server error
501 Not Implemented        # Feature not implemented
502 Bad Gateway            # Invalid upstream response
503 Service Unavailable    # Temporary unavailability
504 Gateway Timeout        # Upstream timeout
```

Never expose internal error details in production:

```
✅ 500 Internal Server Error
{
  "error": {
    "code": "INTERNAL_ERROR",
    "message": "An unexpected error occurred",
    "requestId": "req_abc123"
  }
}

❌ 500 Internal Server Error
{
  "error": "Database connection failed: ECONNREFUSED 192.168.1.100:5432",
  "stack": "Error: connection refused\n  at Connection.connect..."
}
```

### Versioning Strategies

#### URI Path Versioning

Most explicit and commonly used:

```
https://api.example.com/v1/users
https://api.example.com/v2/users
https://api.example.com/v1/products
```

Pros: Clear, easy to route, browser-testable
Cons: URL changes, cache invalidation

#### Header Versioning

Version specified in custom header:

```
GET /users
API-Version: 2
Accept: application/json
```

Or via Accept header:

```
GET /users
Accept: application/vnd.company.v2+json
```

Pros: Clean URLs, same resource identifier
Cons: Less visible, harder to test manually

#### Query Parameter Versioning

Version as query string:

```
GET /users?version=2
GET /products?v=1
```

Pros: Simple, URL-based
Cons: Pollutes query parameters, caching complications

#### Version Deprecation Policy

Communicate lifecycle clearly:

```
# Response headers for deprecated versions
GET /v1/users

Deprecation: true
Sunset: Sat, 31 Dec 2024 23:59:59 GMT
Link: </v2/users>; rel="successor-version"
Warning: 299 - "API v1 is deprecated and will be removed on 2024-12-31"
```

Maintain multiple versions simultaneously with clear timelines:

- v1: Active (6 months deprecation notice)
- v2: Current
- v3: Beta/Preview

### Pagination Patterns

#### Offset-Based Pagination

Traditional page-based approach:

```
GET /users?page=2&limit=20
GET /users?offset=40&limit=20

Response:
{
  "data": [...],
  "pagination": {
    "page": 2,
    "limit": 20,
    "total": 1250,
    "totalPages": 63,
    "hasNext": true,
    "hasPrevious": true
  }
}
```

Pros: Simple, supports random access
Cons: Performance degrades with high offsets, inconsistent with real-time data

#### Cursor-Based Pagination

Position-based using unique identifiers:

```
GET /users?cursor=eyJpZCI6MTIzfQ&limit=20

Response:
{
  "data": [...],
  "pagination": {
    "nextCursor": "eyJpZCI6MTQzfQ",
    "prevCursor": "eyJpZCI6MTAzfQ",
    "hasNext": true,
    "hasPrevious": true
  }
}
```

Cursor typically encodes last ID or timestamp:

```
# Encoded cursor example
{
  "id": 143,
  "createdAt": "2024-01-15T10:30:00Z"
}
```

Pros: Consistent with real-time data, better performance
Cons: No random access, more complex implementation

#### Link Header Pagination (RFC 5988)

Provide navigation links in headers:

```
GET /users?page=2

Link: </users?page=1>; rel="first",
      </users?page=1>; rel="prev",
      </users?page=3>; rel="next",
      </users?page=63>; rel="last"
```

Complements body-based pagination with standardized discovery.

#### Range Header Pagination

Use HTTP Range requests:

```
GET /users
Range: items=0-19

206 Partial Content
Content-Range: items 0-19/1250
Accept-Ranges: items
```

Pros: HTTP standard, client-controlled
Cons: Less common, limited adoption

### Filtering and Searching

#### Query Parameter Filtering

Use intuitive query parameters:

```
GET /users?role=admin&status=active
GET /products?category=electronics&minPrice=100&maxPrice=500
GET /orders?createdAfter=2024-01-01&createdBefore=2024-12-31
```

#### Complex Filtering Syntax

Support operators for advanced queries:

```
# Comparison operators
GET /products?price[gte]=100&price[lte]=500

# Multiple values (OR logic)
GET /users?status=active,pending

# Nested properties
GET /orders?customer.country=US

# Array containment
GET /posts?tags[contains]=api,rest
```

#### Full-Text Search

Dedicated search parameter:

```
GET /products?q=wireless+headphones
GET /users?search=john+doe
```

Separate from filters for clarity:

```
GET /products?q=laptop&category=electronics&minPrice=500
```

#### Field Selection (Sparse Fieldsets)

Allow clients to request specific fields:

```
GET /users?fields=id,name,email
GET /products?fields=name,price,images.thumbnail

Response:
{
  "data": [
    {
      "id": 123,
      "name": "John Doe",
      "email": "john@example.com"
    }
  ]
}
```

Reduces payload size and improves performance.

### Sorting

#### Query Parameter Syntax

Use explicit sort parameter:

```
GET /users?sort=createdAt        # Ascending
GET /users?sort=-createdAt       # Descending (minus prefix)
GET /products?sort=price,name    # Multiple fields
GET /orders?sort=-total,createdAt
```

Alternative verbose syntax:

```
GET /users?sort=createdAt:asc
GET /users?sort=createdAt:desc
```

#### Default Sorting

Document and consistently apply defaults:

```
# Default: sort by creation date descending
GET /posts

# Equivalent to:
GET /posts?sort=-createdAt
```

Include sorting metadata in responses:

```json
{
  "data": [...],
  "meta": {
    "sort": ["-createdAt"],
    "defaultSort": ["-createdAt"]
  }
}
```

### Authentication and Authorization

#### Token-Based Authentication

Use Bearer tokens in Authorization header:

```
GET /users/me
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

❌ Avoid in query parameters:
GET /users/me?token=eyJhbGciOiJ...
```

Tokens in URLs risk exposure via logs, browser history, and referrer headers.

#### API Key Authentication

Custom header for API keys:

```
GET /products
X-API-Key: sk_live_abc123xyz789
```

Never transmit API keys in URLs or JSON bodies when possible.

#### OAuth 2.0 Flows

Standard authorization framework:

```
# Authorization Code Flow
1. Redirect user to authorization server
2. User grants permission
3. Exchange code for access token

POST /oauth/token
Content-Type: application/x-www-form-urlencoded

grant_type=authorization_code&
code=AUTH_CODE&
client_id=CLIENT_ID&
client_secret=CLIENT_SECRET&
redirect_uri=REDIRECT_URI

Response:
{
  "access_token": "eyJhbGc...",
  "token_type": "Bearer",
  "expires_in": 3600,
  "refresh_token": "eyJhbGc...",
  "scope": "read write"
}
```

#### Permission-Based Authorization

Implement granular access control:

```
GET /users/123
Authorization: Bearer TOKEN

# Check permissions:
# - User owns resource (user.id === 123)
# - User has admin role
# - User has 'users:read' permission

403 Forbidden
{
  "error": {
    "code": "INSUFFICIENT_PERMISSIONS",
    "message": "You don't have permission to access this resource",
    "requiredPermissions": ["users:read"]
  }
}
```

### Rate Limiting

#### Rate Limit Headers

Communicate limits using standard headers:

```
GET /users

X-RateLimit-Limit: 1000          # Max requests per window
X-RateLimit-Remaining: 987       # Requests remaining
X-RateLimit-Reset: 1705320000    # Unix timestamp when limit resets
Retry-After: 3600                # Seconds until retry (when limited)
```

When limit exceeded:

```
429 Too Many Requests
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705320000
Retry-After: 3600

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded. Please retry after 3600 seconds"
  }
}
```

#### Tiered Rate Limiting

Different limits per authentication level:

```
# Anonymous: 100 requests/hour
# Authenticated: 1000 requests/hour
# Premium: 10000 requests/hour

GET /products
X-RateLimit-Limit: 1000
X-RateLimit-Policy: authenticated
```

#### Resource-Specific Limits

Apply different limits to different endpoints:

```
# Read endpoints: 1000/hour
GET /users
X-RateLimit-Limit: 1000

# Write endpoints: 100/hour
POST /users
X-RateLimit-Limit: 100

# Expensive operations: 10/hour
POST /reports/generate
X-RateLimit-Limit: 10
```

### HATEOAS (Hypermedia Controls)

#### Link Relations

Include navigational links in responses:

```json
GET /users/123

{
  "id": 123,
  "name": "John Doe",
  "email": "john@example.com",
  "_links": {
    "self": {
      "href": "/users/123"
    },
    "orders": {
      "href": "/users/123/orders"
    },
    "addresses": {
      "href": "/users/123/addresses"
    },
    "edit": {
      "href": "/users/123",
      "method": "PATCH"
    },
    "delete": {
      "href": "/users/123",
      "method": "DELETE"
    }
  }
}
```

#### Action Discovery

Expose available operations based on state and permissions:

```json
GET /orders/456

{
  "id": 456,
  "status": "pending",
  "total": 99.99,
  "_links": {
    "self": { "href": "/orders/456" },
    "cancel": {
      "href": "/orders/456/cancel",
      "method": "POST",
      "allowed": true
    },
    "refund": {
      "href": "/orders/456/refund",
      "method": "POST",
      "allowed": false,
      "reason": "Order not yet completed"
    }
  }
}
```

Clients discover capabilities dynamically rather than hardcoding logic.

#### Collection Navigation

Pagination and filtering links:

```json
GET /products?page=2

{
  "data": [...],
  "_links": {
    "self": { "href": "/products?page=2" },
    "first": { "href": "/products?page=1" },
    "prev": { "href": "/products?page=1" },
    "next": { "href": "/products?page=3" },
    "last": { "href": "/products?page=10" }
  }
}
```

### Caching Strategies

#### Cache-Control Headers

Control client and proxy caching:

```
# Public, cacheable for 1 hour
GET /products/123
Cache-Control: public, max-age=3600

# Private, user-specific
GET /users/me
Cache-Control: private, max-age=300

# No caching
GET /users/me/orders
Cache-Control: no-store

# Revalidate before use
GET /products/featured
Cache-Control: no-cache, must-revalidate
```

#### ETag for Conditional Requests

Validate cache freshness:

```
# Initial request
GET /users/123

200 OK
ETag: "v1-abc123"
{
  "id": 123,
  "name": "John Doe"
}

# Subsequent request with conditional header
GET /users/123
If-None-Match: "v1-abc123"

304 Not Modified
ETag: "v1-abc123"
# No body sent, client uses cached version

# If resource changed
200 OK
ETag: "v2-def456"
{
  "id": 123,
  "name": "Jane Doe"
}
```

#### Last-Modified Header

Time-based validation:

```
GET /products/123

200 OK
Last-Modified: Mon, 15 Jan 2024 10:30:00 GMT

# Conditional request
GET /products/123
If-Modified-Since: Mon, 15 Jan 2024 10:30:00 GMT

304 Not Modified
# Or 200 OK with updated content if modified
```

#### Vary Header

Indicate response variations:

```
GET /users/123
Accept: application/json
Accept-Language: en-US

200 OK
Vary: Accept, Accept-Language
# Caches should consider these headers when storing/retrieving
```

### Content Negotiation

#### Media Type Selection

Client specifies desired format:

```
GET /users/123
Accept: application/json

200 OK
Content-Type: application/json
{
  "id": 123,
  "name": "John Doe"
}
```

Support multiple formats:

```
GET /users/123
Accept: application/xml

200 OK
Content-Type: application/xml
<?xml version="1.0"?>
<user>
  <id>123</id>
  <name>John Doe</name>
</user>
```

Unsupported format handling:

```
GET /users/123
Accept: application/vnd.custom+yaml

406 Not Acceptable
{
  "error": {
    "code": "UNSUPPORTED_MEDIA_TYPE",
    "message": "Requested media type not supported",
    "supported": ["application/json", "application/xml"]
  }
}
```

#### Language Negotiation

Internationalization support:

```
GET /products/123
Accept-Language: es-MX, es;q=0.9, en;q=0.8

200 OK
Content-Language: es-MX
{
  "nombre": "Producto",
  "descripcion": "Descripción en español"
}
```

#### Compression

Request compressed responses:

```
GET /users
Accept-Encoding: gzip, deflate, br

200 OK
Content-Encoding: gzip
# Compressed response body
```

Server should compress responses over ~1KB for bandwidth efficiency.

### Bulk Operations

#### Batch Requests

Execute multiple operations in single request:

```
POST /batch

{
  "requests": [
    {
      "id": "req1",
      "method": "GET",
      "path": "/users/123"
    },
    {
      "id": "req2",
      "method": "PATCH",
      "path": "/users/123",
      "body": { "email": "newemail@example.com" }
    },
    {
      "id": "req3",
      "method": "GET",
      "path": "/users/123/orders"
    }
  ]
}

Response:
{
  "responses": [
    {
      "id": "req1",
      "status": 200,
      "body": { "id": 123, "name": "John Doe" }
    },
    {
      "id": "req2",
      "status": 200,
      "body": { "id": 123, "email": "newemail@example.com" }
    },
    {
      "id": "req3",
      "status": 200,
      "body": { "orders": [...] }
    }
  ]
}
```

#### Bulk Creation

Create multiple resources:

```
POST /users/bulk

{
  "users": [
    { "name": "Alice", "email": "alice@example.com" },
    { "name": "Bob", "email": "bob@example.com" },
    { "name": "Carol", "email": "carol@example.com" }
  ]
}

207 Multi-Status
{
  "results": [
    {
      "status": 201,
      "body": { "id": 124, "name": "Alice" }
    },
    {
      "status": 400,
      "error": { "message": "Email already exists" }
    },
    {
      "status": 201,
      "body": { "id": 125, "name": "Carol" }
    }
  ]
}
```

Use 207 Multi-Status when operations have different outcomes.

#### Bulk Updates

Update multiple resources:

```
PATCH /products/bulk

{
  "updates": [
    { "id": 1, "price": 29.99 },
    { "id": 2, "price": 39.99 },
    { "id": 3, "stock": 0 }
  ]
}
```

#### Bulk Deletion

Delete multiple resources:

```
DELETE /users
Content-Type: application/json

{
  "ids": [123, 124, 125]
}

200 OK
{
  "deleted": 3,
  "errors": []
}
```

### Asynchronous Operations

#### Long-Running Tasks

Return immediate acceptance for lengthy operations:

```
POST /reports/generate
{
  "type": "sales",
  "startDate": "2024-01-01",
  "endDate": "2024-12-31"
}

202 Accepted
Location: /reports/jobs/abc123
{
  "jobId": "abc123",
  "status": "processing",
  "estimatedCompletion": "2024-01-15T10:35:00Z"
}
```

#### Job Status Polling

Client polls for completion:

```
GET /reports/jobs/abc123

200 OK
{
  "jobId": "abc123",
  "status": "processing",
  "progress": 45,
  "estimatedCompletion": "2024-01-15T10:35:00Z"
}

# After completion
GET /reports/jobs/abc123

200 OK
{
  "jobId": "abc123",
  "status": "completed",
  "result": {
    "reportId": 789,
    "downloadUrl": "/reports/789/download"
  }
}

# If failed
200 OK
{
  "jobId": "abc123",
  "status": "failed",
  "error": {
    "code": "DATA_PROCESSING_ERROR",
    "message": "Failed to process date range"
  }
}
```

#### Webhook Callbacks

Notify clients on completion:

```
POST /reports/generate
{
  "type": "sales",
  "callbackUrl": "https://client.example.com/webhooks/reports"
}

202 Accepted
{
  "jobId": "abc123",
  "status": "processing"
}

# Server sends callback when complete
POST https://client.example.com/webhooks/reports
{
  "jobId": "abc123",
  "status": "completed",
  "result": {
    "reportId": 789
  }
}
```

### Error Handling

#### Consistent Error Format

Standardized error structure:

```json
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "details": [
      {
        "field": "email",
        "code": "INVALID_FORMAT",
        "message": "Must be a valid email address"
      }
    ],
    "requestId": "req_abc123",
    "timestamp": "2024-01-15T10:30:00Z",
    "documentation": "https://docs.example.com/errors/validation-error"
  }
}
```

#### Error Codes

Machine-readable error identifiers:

```
VALIDATION_ERROR          # 400
AUTHENTICATION_REQUIRED   # 401
INSUFFICIENT_PERMISSIONS  # 403
RESOURCE_NOT_FOUND        # 404
RESOURCE_CONFLICT         # 409
RATE_LIMIT_EXCEEDED       # 429
INTERNAL_ERROR            # 500
SERVICE_UNAVAILABLE       # 503
```

#### Validation Errors

Detailed field-level errors:

```
POST /users
{
  "name": "",
  "email": "invalid-email",
  "age": 15
}

400 Bad Request
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "details": [
      {
        "field": "name",
        "code": "REQUIRED",
        "message": "Name is required"
      },
      {
        "field": "email",
        "code": "INVALID_FORMAT",
        "message": "Must be a valid email address",
        "value": "invalid-email"
      },
      {
        "field": "age",
        "code": "MIN_VALUE",
        "message": "Must be at least 18",
        "constraint": { "min": 18 },
        "value": 15
      }
    ]
  }
}
```

#### Error Documentation

Link to detailed error explanations:

```json
{
  "error": {
    "code": "PAYMENT_FAILED",
    "message": "Payment processing failed",
    "documentation": "https://docs.example.com/errors/payment-failed",
    "supportContact": "support@example.com"
  }
}
```

### Security Best Practices

#### HTTPS Only

Enforce encrypted connections:

```
# Redirect HTTP to HTTPS
HTTP/1.1 301 Moved Permanently
Location: https://api.example.com/users

# HSTS header
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
```

#### Input Validation

Validate all input rigorously:

```
POST /users
{
  "name": "<script>alert('xss')</script>",
  "email": "user@example.com"
}

400 Bad Request
{
  "error": {
    "code": "VALIDATION_ERROR",
    "details": [
      {
        "field": "name",
        "message": "Invalid characters detected"
      }
    ]
  }
}
```

Sanitize and validate before processing.

#### CORS Configuration

Properly configure cross-origin requests:

```
# Preflight request
OPTIONS /users
Origin: https://app.example.com

# Response
Access-Control-Allow-Origin: https://app.example.com
Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE
Access-Control-Allow-Headers: Content-Type, Authorization
Access-Control-Max-Age: 86400
Access-Control-Allow-Credentials: true
```

Avoid wildcard origins with credentials:

```
❌ Insecure:
Access-Control-Allow-Origin: *
Access-Control-Allow-Credentials: true

✅ Secure:
Access-Control-Allow-Origin: https://trusted-app.example.com
Access-Control-Allow-Credentials: true
```

#### SQL Injection Prevention

Use parameterized queries, never string concatenation:

```
❌ Vulnerable:
query = "SELECT * FROM users WHERE email = '" + email + "'"

✅ Safe:
query = "SELECT * FROM users WHERE email = ?"
params = [email]
```

API layer should use ORM or prepared statements.

#### Request Size Limits

Prevent resource exhaustion:

```
POST /uploads
Content-Length: 52428800

413 Payload Too Large
{
  "error": {
    "code": "PAYLOAD_TOO_LARGE",
    "message": "Request body exceeds maximum size of 10MB",
    "maxSize": 10485760
  }
}
```

#### Security Headers

Include protective headers:

```
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Content-Security-Policy: default-src 'self'
Referrer-Policy: no-referrer
```

### Documentation Standards

#### OpenAPI Specification

Document API with standardized format:

```yaml
openapi: 3.0.0
info:
  title: User Management API
  version: 1.0.0
  description: RESTful API for managing users

paths:
  /users:
    get:
      summary: List users
      parameters:
        - name: page
          in: query
          schema:
            type: integer
            default: 1
        - name: limit
          in: query
          schema:
            type: integer
            default: 20
            maximum: 100
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/User'
                  pagination:
                    $ref: '#/components/schemas/Pagination'

components:
  schemas:
    User:
      type: object
      required:
        - id
        - name
        - email
      properties:
        id:
          type: integer
        name:
          type: string
        email:
          type: string
          format: email
```

#### Request/Response Examples

Provide concrete examples:

```yaml
paths:
  /users:
    post:
      requestBody:
        content:
          application/json:
            example:
              name: "John Doe"
              email: "john@example.com"
              role: "user"
      responses:
        '201':
          content:
            application/json:
              example:
                id: 123
                name: "John Doe"
                email: "john@example.com"
                role: "user"
                createdAt: "2024-01-15T10:30:00Z"
```

#### Error Documentation

Document all error scenarios:

```yaml
responses:
  '400':
    description: Validation error
    content:
      application/json:
        example:
          error:
            code: "VALIDATION_ERROR"
            message: "Request validation failed"
            details:
              - field: "email"
                message: "Invalid email format"
  '401':
    description: Authentication required
  '403':
    description: Insufficient permissions
```

### Health Checks and Monitoring

#### Health Endpoint

Provide service health status:

```
GET /health

200 OK
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "version": "1.2.3",
  "checks": {
    "database": {
      "status": "healthy",
      "responseTime": 12
    },
    "cache": {
      "status": "healthy",
      "responseTime": 3
    },
    "externalApi": {
      "status": "degraded",
      "responseTime": 2500,
      "message": "High latency detected"
    }
  }
}

# Unhealthy response
503 Service Unavailable
{
  "status": "unhealthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "checks": {
    "database": {
      "status": "unhealthy",
      "error": "Connection timeout"
    }
  }
}
```

#### Readiness vs Liveness

Separate endpoints for different purposes:

```
# Liveness: Is the service running?
GET /health/live
200 OK

# Readiness: Can the service accept traffic?
GET /health/ready
503 Service Unavailable
{
  "status": "not_ready",
  "reason": "Database migration in progress"
}
```

#### Metrics Endpoint

Expose operational metrics:

```
GET /metrics

{
  "requests": {
    "total": 1523890,
    "ratePerSecond": 142.3
  },
  "latency": {
    "p50": 45,
    "p95": 120,
    "p99": 350
  },
  "errors": {
    "rate": 0.02,
    "count": {
      "4xx": 125,
      "5xx": 12
    }
  },
  "uptime": 2592000
}
```

### Deprecation Strategy

#### Deprecation Headers

Warn about upcoming changes:

```
GET /v1/users

200 OK
Deprecation: true
Sunset: Sun, 31 Dec 2024 23:59:59 GMT
Link: </v2/users>; rel="successor-version"
Warning: 299 - "This endpoint is deprecated and will be removed on 2024-12-31. Please migrate to /v2/users"

{
  "data": [...]
}
```

#### Gradual Feature Deprecation

Communicate changes incrementally:

```
# Phase 1: Announce (6 months before)
GET /users?includeDeleted=true
Warning: 299 - "Parameter 'includeDeleted' is deprecated"

# Phase 2: Require opt-in (3 months before)
GET /users?includeDeleted=true
Warning: 299 - "Parameter 'includeDeleted' requires X-Enable-Deprecated: true"

# Phase 3: Remove
GET /users?includeDeleted=true
400 Bad Request
{
  "error": {
    "code": "DEPRECATED_PARAMETER",
    "message": "Parameter 'includeDeleted' has been removed. Use /users/archived instead"
  }
}
```

### Request Validation

#### Schema Validation

Validate request structure:

```
POST /users
Content-Type: application/json

{
  "name": "John Doe",
  "email": "john@example.com",
  "age": 25,
  "role": "admin"
}

# Validation rules:
# - name: required, string, 2-100 chars
# - email: required, valid email format
# - age: optional, integer, 18-120
# - role: required, enum ['user', 'admin', 'moderator']
```

#### Type Coercion

Handle type mismatches gracefully:

```
GET /users?page=abc

400 Bad Request
{
  "error": {
    "code": "VALIDATION_ERROR",
    "details": [
      {
        "field": "page",
        "message": "Must be a valid integer",
        "value": "abc",
        "type": "integer"
      }
    ]
  }
}
```

#### Required vs Optional

Clearly distinguish mandatory fields:

```
POST /products
{
  "name": "Widget"
  # Missing required fields: price, sku
}

400 Bad Request
{
  "error": {
    "code": "VALIDATION_ERROR",
    "details": [
      {
        "field": "price",
        "code": "REQUIRED",
        "message": "Price is required"
      },
      {
        "field": "sku",
        "code": "REQUIRED",
        "message": "SKU is required"
      }
    ]
  }
}
```

### Response Formatting

#### Consistent Envelope

Wrap responses uniformly:

```
# Success responses
{
  "data": {...},
  "meta": {
    "requestId": "req_abc123",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}

# Collection responses
{
  "data": [...],
  "meta": {
    "pagination": {...}
  }
}

# Error responses
{
  "error": {...},
  "meta": {
    "requestId": "req_abc123",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}
```

Alternative: No envelope for simple responses, envelope only for metadata needs.

#### Null vs Omission

Document handling of null/missing values:

```
# Option 1: Include null values
{
  "name": "John Doe",
  "middleName": null,
  "email": "john@example.com"
}

# Option 2: Omit null values (more compact)
{
  "name": "John Doe",
  "email": "john@example.com"
}
```

Choose one strategy and apply consistently.

#### Date and Time Format

Use ISO 8601 with UTC:

```
{
  "createdAt": "2024-01-15T10:30:00Z",
  "updatedAt": "2024-01-15T14:45:30.123Z",
  "scheduledFor": "2024-02-01T09:00:00Z"
}

❌ Avoid:
{
  "createdAt": "01/15/2024 10:30 AM",
  "timestamp": 1705320600
}
```

#### Boolean Representation

Use actual booleans, not strings or integers:

```
✅ Correct:
{
  "active": true,
  "verified": false
}

❌ Avoid:
{
  "active": "true",
  "verified": 0
}
```

### Testing and Quality

#### Contract Testing

Validate API behavior matches specification:

```javascript
// Example using Pact
describe('User API', () => {
  it('returns user by ID', async () => {
    await provider.addInteraction({
      state: 'user 123 exists',
      uponReceiving: 'a request for user 123',
      withRequest: {
        method: 'GET',
        path: '/users/123',
        headers: { Accept: 'application/json' }
      },
      willRespondWith: {
        status: 200,
        headers: { 'Content-Type': 'application/json' },
        body: {
          id: 123,
          name: 'John Doe',
          email: 'john@example.com'
        }
      }
    });
  });
});
```

#### Regression Testing

Maintain test suites for all endpoints:

```javascript
// Integration test example
test('GET /users/:id returns 404 for non-existent user', async () => {
  const response = await request(app)
    .get('/users/99999')
    .set('Authorization', 'Bearer token');
    
  expect(response.status).toBe(404);
  expect(response.body.error.code).toBe('RESOURCE_NOT_FOUND');
});

test('POST /users creates user with valid data', async () => {
  const response = await request(app)
    .post('/users')
    .send({
      name: 'Jane Doe',
      email: 'jane@example.com'
    });
    
  expect(response.status).toBe(201);
  expect(response.body.data).toHaveProperty('id');
  expect(response.headers.location).toMatch(/\/users\/\d+/);
});
```

#### Load Testing

Verify performance under stress:

```javascript
// Example using k6
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 }, // Ramp up
    { duration: '5m', target: 100 }, // Sustained load
    { duration: '2m', target: 0 },   // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95% under 500ms
    http_req_failed: ['rate<0.01'],   // Error rate < 1%
  },
};

export default function () {
  const res = http.get('https://api.example.com/users');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
}
```

### Logging and Observability

#### Request Logging

Log all requests with context:

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "requestId": "req_abc123",
  "method": "POST",
  "path": "/users",
  "queryParams": {},
  "statusCode": 201,
  "responseTime": 145,
  "userAgent": "Mozilla/5.0...",
  "ip": "192.168.1.100",
  "userId": "user_789"
}
```

#### Correlation IDs

Track requests across services:

```
POST /orders
X-Request-ID: req_abc123

# Propagate to downstream services
POST https://payment-service.internal/process
X-Request-ID: req_abc123
X-Parent-Request-ID: req_abc123

# Include in responses
201 Created
X-Request-ID: req_abc123
```

Clients can provide request IDs for tracing:

```
POST /users
X-Request-ID: client_generated_uuid
```

#### Structured Logging

Use structured formats for machine parsing:

```json
{
  "level": "error",
  "timestamp": "2024-01-15T10:30:00Z",
  "requestId": "req_abc123",
  "error": {
    "type": "DatabaseError",
    "message": "Connection timeout",
    "stack": "..."
  },
  "context": {
    "userId": "user_789",
    "operation": "createOrder",
    "duration": 5000
  }
}
```

### Performance Optimization

#### Response Compression

Compress large responses:

```
GET /products
Accept-Encoding: gzip

200 OK
Content-Encoding: gzip
Content-Length: 1234
# Compressed payload
```

Compression typically beneficial for responses > 1KB.

#### Conditional Requests

Minimize bandwidth with ETags:

```
GET /users/123
If-None-Match: "v1-abc123"

304 Not Modified
# No body transmitted
```

#### Partial Responses

Allow clients to request subsets:

```
GET /users/123?fields=id,name,email

{
  "id": 123,
  "name": "John Doe",
  "email": "john@example.com"
}
# Omits other fields like address, phone, etc.
```

#### Database Query Optimization

Avoid N+1 queries in list endpoints:

```
❌ Inefficient:
GET /users
# Fetches users, then makes separate query for each user's orders

✅ Optimized:
GET /users?include=orders
# Single query with JOIN or batch fetch
```

#### Connection Pooling

[Inference] Reuse database connections across requests to reduce overhead and improve response times.

### API Gateway Patterns

#### Request Routing

Gateway handles routing to services:

```
# External request
GET https://api.example.com/users/123

# Gateway routes to internal service
GET http://user-service.internal:8080/users/123
```

#### Request Transformation

Gateway modifies requests/responses:

```
# Client sends
GET /v1/users

# Gateway transforms to
GET /users
X-API-Version: 1
```

#### Rate Limiting at Gateway

Centralized rate limiting:

```
# Gateway enforces limits before reaching services
GET /users
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 999
```

#### Authentication at Gateway

Gateway validates tokens:

```
# Client request
GET /protected-resource
Authorization: Bearer token123

# Gateway validates token, forwards if valid
GET /protected-resource
X-User-ID: user_789
X-User-Roles: admin,user
```

---

## GraphQL Integration

### Basic GraphQL Requests

GraphQL queries and mutations use POST requests with a JSON body containing the query string and variables. The fetch API handles GraphQL requests identically to REST endpoints, but with a standardized request structure.

```javascript
const query = `
  query GetUser($id: ID!) {
    user(id: $id) {
      id
      name
      email
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    query,
    variables: { id: '123' }
  })
});

const { data, errors } = await response.json();
```

GraphQL responses always return HTTP 200 status codes, even for query errors. Errors appear in the `errors` array within the response body, requiring application-level error handling rather than HTTP status code checking.

### Query Structure and Variables

#### Parameterized Queries

Variables separate query structure from dynamic values, enabling query reuse and preventing injection vulnerabilities. Variables use type declarations in the query definition.

```javascript
// Query with multiple variables
const query = `
  query GetProducts($category: String!, $limit: Int, $sortBy: SortOrder) {
    products(category: $category, limit: $limit, sortBy: $sortBy) {
      id
      name
      price
      inventory {
        quantity
        warehouse
      }
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    query,
    variables: {
      category: 'electronics',
      limit: 20,
      sortBy: 'PRICE_ASC'
    }
  })
});
```

#### Fragments for Reusable Fields

Fragments define reusable field selections, reducing duplication across multiple queries. They're particularly useful when fetching the same entity type in different contexts.

```javascript
const query = `
  fragment ProductFields on Product {
    id
    name
    price
    imageUrl
    rating
  }
  
  query GetProductsAndFeatured {
    products(limit: 10) {
      ...ProductFields
      category
    }
    featuredProducts {
      ...ProductFields
      promotionText
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ query })
});
```

### Mutations

Mutations modify server-side data and follow the same request structure as queries, but use the `mutation` operation type. Mutations typically return the modified data for client-side updates.

```javascript
const mutation = `
  mutation CreateProduct($input: CreateProductInput!) {
    createProduct(input: $input) {
      id
      name
      price
      createdAt
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    query: mutation,
    variables: {
      input: {
        name: 'New Product',
        price: 29.99,
        category: 'electronics'
      }
    }
  })
});

const { data, errors } = await response.json();

if (errors) {
  console.error('Mutation failed:', errors);
} else {
  console.log('Created product:', data.createProduct);
}
```

### Batching Multiple Operations

GraphQL supports multiple queries or mutations in a single request, reducing network overhead when fetching related data. Each operation requires a unique name.

```javascript
const batchedOperations = `
  query GetUser($userId: ID!) {
    user(id: $userId) {
      id
      name
      email
    }
  }
  
  query GetUserPosts($userId: ID!) {
    posts(authorId: $userId) {
      id
      title
      createdAt
    }
  }
  
  query GetUserComments($userId: ID!) {
    comments(authorId: $userId) {
      id
      text
      createdAt
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: batchedOperations,
    variables: { userId: '123' }
  })
});

const { data } = await response.json();
// Access: data.user, data.posts, data.comments
```

Servers must explicitly support batched operations. Some implementations use array syntax for truly independent operations:

```javascript
const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify([
    {
      query: 'query { user(id: "1") { name } }',
    },
    {
      query: 'query { posts { title } }',
    }
  ])
});

const results = await response.json(); // Array of responses
```

### Error Handling

#### GraphQL Error Structure

GraphQL errors contain detailed information about what failed and where in the query structure the failure occurred. The `errors` array includes messages, paths, and extensions for debugging.

```javascript
const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: 'query { user(id: "invalid") { name email } }'
  })
});

const result = await response.json();

if (result.errors) {
  result.errors.forEach(error => {
    console.error('Message:', error.message);
    console.error('Path:', error.path); // e.g., ['user', 'name']
    console.error('Locations:', error.locations); // Query line/column
    console.error('Extensions:', error.extensions); // Additional context
  });
}

// Partial data may still exist
if (result.data) {
  console.log('Partial data:', result.data);
}
```

#### Network and HTTP Errors

Network failures and HTTP errors require separate handling from GraphQL-level errors. Check both HTTP response status and GraphQL errors.

```javascript
async function graphqlRequest(query, variables) {
  let response;
  
  try {
    response = await fetch('https://api.example.com/graphql', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, variables })
    });
  } catch (error) {
    // Network error (no connection, DNS failure, etc.)
    throw new Error(`Network error: ${error.message}`);
  }
  
  if (!response.ok) {
    // HTTP error (500, 503, etc.)
    throw new Error(`HTTP error: ${response.status} ${response.statusText}`);
  }
  
  const result = await response.json();
  
  if (result.errors) {
    // GraphQL error (query syntax, validation, resolver errors)
    throw new Error(`GraphQL errors: ${result.errors.map(e => e.message).join(', ')}`);
  }
  
  return result.data;
}
```

### Authentication and Authorization

#### Header-Based Authentication

GraphQL APIs typically use bearer tokens in the Authorization header. Some implementations also support API keys or custom authentication headers.

```javascript
const query = `
  query GetPrivateData {
    currentUser {
      id
      email
      privateNotes
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${accessToken}`
  },
  body: JSON.stringify({ query })
});
```

#### Token Refresh Handling

Long-lived sessions require token refresh logic to maintain authentication. Implement automatic retry with refreshed tokens for 401 responses.

```javascript
async function graphqlRequestWithRefresh(query, variables) {
  let token = getAccessToken();
  
  let response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({ query, variables })
  });
  
  // If unauthorized, attempt token refresh
  if (response.status === 401) {
    token = await refreshAccessToken();
    
    response = await fetch('https://api.example.com/graphql', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`
      },
      body: JSON.stringify({ query, variables })
    });
  }
  
  return response.json();
}
```

### Caching Strategies

#### Manual Cache Implementation

GraphQL's flexible query structure complicates caching compared to REST. Implement normalized caching by parsing GraphQL responses and storing entities by ID.

```javascript
class GraphQLCache {
  constructor() {
    this.entities = new Map(); // Map<entityType, Map<id, entity>>
    this.queries = new Map();  // Map<queryHash, result>
  }
  
  normalizeAndCache(data, typename) {
    if (!data) return;
    
    if (Array.isArray(data)) {
      return data.map(item => this.normalizeAndCache(item, typename));
    }
    
    if (data.__typename) {
      const type = data.__typename;
      if (!this.entities.has(type)) {
        this.entities.set(type, new Map());
      }
      
      if (data.id) {
        this.entities.get(type).set(data.id, data);
      }
    }
    
    // Recursively normalize nested objects
    Object.keys(data).forEach(key => {
      if (typeof data[key] === 'object' && data[key] !== null) {
        data[key] = this.normalizeAndCache(data[key], typename);
      }
    });
    
    return data;
  }
  
  getEntity(type, id) {
    return this.entities.get(type)?.get(id);
  }
  
  cacheQuery(query, variables, result) {
    const hash = this.hashQuery(query, variables);
    this.queries.set(hash, {
      result,
      timestamp: Date.now()
    });
  }
  
  getQuery(query, variables, maxAge = 60000) {
    const hash = this.hashQuery(query, variables);
    const cached = this.queries.get(hash);
    
    if (cached && Date.now() - cached.timestamp < maxAge) {
      return cached.result;
    }
    
    return null;
  }
  
  hashQuery(query, variables) {
    return `${query}::${JSON.stringify(variables)}`;
  }
}

// Usage
const cache = new GraphQLCache();

async function cachedGraphQLRequest(query, variables) {
  const cached = cache.getQuery(query, variables);
  if (cached) return cached;
  
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, variables })
  });
  
  const result = await response.json();
  
  if (result.data) {
    cache.normalizeAndCache(result.data);
    cache.cacheQuery(query, variables, result);
  }
  
  return result;
}
```

#### HTTP Caching with GET Requests

Some GraphQL servers support GET requests for queries, enabling standard HTTP caching mechanisms. Encode the query and variables as URL parameters.

```javascript
function buildGraphQLGetURL(endpoint, query, variables) {
  const params = new URLSearchParams({
    query: query,
    variables: JSON.stringify(variables)
  });
  
  return `${endpoint}?${params.toString()}`;
}

const url = buildGraphQLGetURL(
  'https://api.example.com/graphql',
  'query GetUser($id: ID!) { user(id: $id) { name } }',
  { id: '123' }
);

const response = await fetch(url, {
  method: 'GET',
  headers: {
    'Accept': 'application/json'
  }
});
```

This approach allows CDN and browser caching based on URL, but only works for queries (not mutations) and may hit URL length limits with complex queries.

### Persisted Queries

Persisted queries reduce bandwidth by sending only a query ID instead of the full query string. The server stores pre-registered queries and executes them by ID.

```javascript
// Client sends hash/ID instead of full query
const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    id: '9a8b7c6d5e4f3a2b1c0d9e8f7a6b5c4d', // Query hash
    variables: { userId: '123' }
  })
});
```

#### Automatic Persisted Queries (APQ)

APQ allows clients to attempt queries by hash first, falling back to full query if the server doesn't have it cached. The server automatically persists queries on first use.

```javascript
async function apqRequest(query, variables) {
  const queryHash = await sha256(query);
  
  // First attempt: send only the hash
  let response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      extensions: {
        persistedQuery: {
          version: 1,
          sha256Hash: queryHash
        }
      },
      variables
    })
  });
  
  let result = await response.json();
  
  // If query not found, send full query
  if (result.errors?.some(e => e.message.includes('PersistedQueryNotFound'))) {
    response = await fetch('https://api.example.com/graphql', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query,
        variables,
        extensions: {
          persistedQuery: {
            version: 1,
            sha256Hash: queryHash
          }
        }
      })
    });
    
    result = await response.json();
  }
  
  return result;
}

async function sha256(message) {
  const msgBuffer = new TextEncoder().encode(message);
  const hashBuffer = await crypto.subtle.digest('SHA-256', msgBuffer);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
}
```

### File Uploads

GraphQL file uploads require multipart form data rather than JSON, following the GraphQL multipart request specification.

```javascript
async function uploadFile(file, mutation, variables) {
  const operations = {
    query: mutation,
    variables: variables
  };
  
  const map = {
    '0': ['variables.file']
  };
  
  const formData = new FormData();
  formData.append('operations', JSON.stringify(operations));
  formData.append('map', JSON.stringify(map));
  formData.append('0', file);
  
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${token}`
      // Don't set Content-Type; browser sets it with boundary
    },
    body: formData
  });
  
  return response.json();
}

// Usage
const mutation = `
  mutation UploadFile($file: Upload!) {
    uploadFile(file: $file) {
      url
      filename
      mimetype
    }
  }
`;

const fileInput = document.querySelector('input[type="file"]');
const file = fileInput.files[0];

const result = await uploadFile(file, mutation, { file: null });
```

Multiple file uploads map each file to its variable path:

```javascript
const operations = {
  query: mutation,
  variables: {
    files: [null, null]
  }
};

const map = {
  '0': ['variables.files.0'],
  '1': ['variables.files.1']
};

const formData = new FormData();
formData.append('operations', JSON.stringify(operations));
formData.append('map', JSON.stringify(map));
formData.append('0', file1);
formData.append('1', file2);
```

### Subscriptions via HTTP

GraphQL subscriptions typically use WebSockets, but some implementations support HTTP-based subscriptions through polling or server-sent events.

#### Polling Implementation

Implement subscriptions by repeatedly querying for changes at regular intervals. Include a timestamp or cursor to fetch only new data.

```javascript
async function pollSubscription(query, variables, callback, interval = 5000) {
  let lastFetchTime = new Date().toISOString();
  
  const poll = async () => {
    const response = await fetch('https://api.example.com/graphql', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query,
        variables: {
          ...variables,
          since: lastFetchTime
        }
      })
    });
    
    const result = await response.json();
    
    if (result.data) {
      callback(result.data);
      lastFetchTime = new Date().toISOString();
    }
  };
  
  const intervalId = setInterval(poll, interval);
  await poll(); // Initial fetch
  
  return () => clearInterval(intervalId); // Return cleanup function
}

// Usage
const unsubscribe = await pollSubscription(
  `
    query GetNewMessages($since: DateTime!) {
      messages(since: $since) {
        id
        text
        createdAt
      }
    }
  `,
  {},
  (data) => {
    console.log('New messages:', data.messages);
  },
  3000 // Poll every 3 seconds
);

// Later: unsubscribe();
```

#### Server-Sent Events (SSE)

Some GraphQL implementations support subscriptions via SSE, providing real-time updates over HTTP without WebSocket complexity.

```javascript
function subscribeViaSSE(query, variables, callback) {
  const url = new URL('https://api.example.com/graphql/stream');
  url.searchParams.set('query', query);
  url.searchParams.set('variables', JSON.stringify(variables));
  
  const eventSource = new EventSource(url.toString());
  
  eventSource.onmessage = (event) => {
    const result = JSON.parse(event.data);
    callback(result.data);
  };
  
  eventSource.onerror = (error) => {
    console.error('SSE error:', error);
    eventSource.close();
  };
  
  return () => eventSource.close();
}

// Usage
const unsubscribe = subscribeViaSSE(
  `
    subscription OnNewMessage {
      messageAdded {
        id
        text
        author {
          name
        }
      }
    }
  `,
  {},
  (data) => {
    console.log('New message:', data.messageAdded);
  }
);
```

### Request Optimization

#### Query Complexity Analysis

Large queries with deep nesting or multiple connections can overwhelm servers. Some GraphQL servers reject queries exceeding complexity thresholds.

```javascript
// Potentially expensive query
const complexQuery = `
  query GetOrganization($id: ID!) {
    organization(id: $id) {
      name
      users(first: 100) {
        edges {
          node {
            name
            posts(first: 50) {
              edges {
                node {
                  title
                  comments(first: 100) {
                    edges {
                      node {
                        text
                        author {
                          name
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
`;
```

Mitigate complexity by:

- Limiting pagination sizes
- Reducing nesting depth
- Splitting into multiple smaller queries
- Using fragments to identify reusable patterns

#### Field Selection Optimization

Request only needed fields to reduce response payload size and server processing time. Avoid requesting large nested structures when only parent data is needed.

```javascript
// Inefficient: requesting unused fields
const bloatedQuery = `
  query GetUsers {
    users {
      id
      name
      email
      bio
      avatar
      posts {
        id
        title
        content
        createdAt
      }
      settings {
        theme
        notifications
        privacy
      }
    }
  }
`;

// Efficient: request only necessary fields
const optimizedQuery = `
  query GetUsers {
    users {
      id
      name
      avatar
    }
  }
`;
```

### Introspection Queries

GraphQL servers expose their schema through introspection, allowing clients to discover available types, queries, and mutations.

```javascript
const introspectionQuery = `
  query IntrospectionQuery {
    __schema {
      queryType {
        name
      }
      mutationType {
        name
      }
      types {
        name
        kind
        description
        fields {
          name
          type {
            name
            kind
          }
        }
      }
    }
  }
`;

const response = await fetch('https://api.example.com/graphql', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ query: introspectionQuery })
});

const { data } = await response.json();
console.log('Available types:', data.__schema.types);
```

Production servers often disable introspection for security reasons. Use introspection during development to explore the API and generate type definitions.

### Type Safety and Code Generation

#### Generated Types from Schema

Use tools like GraphQL Code Generator to create TypeScript types from the GraphQL schema, providing type safety for queries and responses.

```javascript
// Generated types (example output)
interface GetUserQuery {
  user: {
    id: string;
    name: string;
    email: string;
  } | null;
}

interface GetUserQueryVariables {
  id: string;
}

// Type-safe query function
async function getUser(
  id: string
): Promise<GetUserQuery> {
  const query = `
    query GetUser($id: ID!) {
      user(id: $id) {
        id
        name
        email
      }
    }
  `;
  
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      query,
      variables: { id }
    })
  });
  
  const { data } = await response.json();
  return data as GetUserQuery;
}
```

### Rate Limiting and Throttling

GraphQL rate limiting differs from REST due to variable query complexity. Track rate limits by query points or complexity rather than request count.

```javascript
async function graphqlRequestWithRateLimit(query, variables) {
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, variables })
  });
  
  // Check rate limit headers
  const remaining = response.headers.get('X-RateLimit-Remaining');
  const reset = response.headers.get('X-RateLimit-Reset');
  const cost = response.headers.get('X-RateLimit-Cost');
  
  console.log(`Query cost: ${cost}, Remaining: ${remaining}, Resets: ${new Date(parseInt(reset) * 1000)}`);
  
  if (remaining === '0') {
    const waitTime = parseInt(reset) * 1000 - Date.now();
    console.warn(`Rate limit exceeded. Waiting ${waitTime}ms`);
    await new Promise(resolve => setTimeout(resolve, waitTime));
    return graphqlRequestWithRateLimit(query, variables);
  }
  
  return response.json();
}
```

### Pagination Patterns

#### Cursor-Based Pagination

GraphQL commonly uses cursor-based pagination following the Relay connection specification. Cursors provide stable pagination even as data changes.

```javascript
async function fetchAllPages(query, variables = {}) {
  const allItems = [];
  let hasNextPage = true;
  let cursor = null;
  
  while (hasNextPage) {
    const response = await fetch('https://api.example.com/graphql', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        query,
        variables: {
          ...variables,
          after: cursor,
          first: 50
        }
      })
    });
    
    const { data } = await response.json();
    const connection = data.products;
    
    allItems.push(...connection.edges.map(edge => edge.node));
    
    hasNextPage = connection.pageInfo.hasNextPage;
    cursor = connection.pageInfo.endCursor;
  }
  
  return allItems;
}

// Usage
const query = `
  query GetProducts($after: String, $first: Int!) {
    products(after: $after, first: $first) {
      edges {
        node {
          id
          name
          price
        }
        cursor
      }
      pageInfo {
        hasNextPage
        endCursor
      }
    }
  }
`;

const allProducts = await fetchAllPages(query);
```

#### Offset-Based Pagination

Some GraphQL APIs use simpler offset/limit pagination. This approach is less stable when data changes but simpler to implement.

```javascript
async function fetchPage(page, pageSize = 20) {
  const query = `
    query GetProducts($offset: Int!, $limit: Int!) {
      products(offset: $offset, limit: $limit) {
        id
        name
        price
      }
      productsCount
    }
  `;
  
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      query,
      variables: {
        offset: page * pageSize,
        limit: pageSize
      }
    })
  });
  
  const { data } = await response.json();
  
  return {
    items: data.products,
    total: data.productsCount,
    totalPages: Math.ceil(data.productsCount / pageSize)
  };
}
```

### Debugging and Logging

#### Request/Response Logging

Log GraphQL requests and responses for debugging, including query complexity, execution time, and errors.

```javascript
async function graphqlRequestWithLogging(query, variables) {
  const startTime = performance.now();
  
  console.group('GraphQL Request');
  console.log('Query:', query);
  console.log('Variables:', variables);
  
  const response = await fetch('https://api.example.com/graphql', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, variables })
  });
  
  const result = await response.json();
  const endTime = performance.now();
  
  console.log('Duration:', `${(endTime - startTime).toFixed(2)}ms`);
  console.log('Status:', response.status);
  
  if (result.errors) {
    console.error('Errors:', result.errors);
  }
  
  if (result.data) {
    console.log('Data:', result.data);
  }
  
  console.groupEnd();
  
  return result;
}
```

#### Query Name Tracking

Include operation names in all queries and mutations to improve server-side logging and debugging.

```javascript
// Without operation name (harder to debug)
const query = `
  query {
    user(id: "123") {
      name
    }
  }
`;

// With operation name (easier to track in logs)
const query = `
  query GetUserProfile {
    user(id: "123") {
      name
    }
  }
`;
```

Server logs can then identify specific queries by name rather than just "anonymous query", making performance monitoring and error tracking more effective.

---

## Versioning Strategies

### URL Path Versioning

#### Version in Base Path

```javascript
const API_V1 = 'https://api.example.com/v1';
const API_V2 = 'https://api.example.com/v2';

async function getUserV1(id) {
  const response = await fetch(`${API_V1}/users/${id}`);
  return response.json();
}

async function getUserV2(id) {
  const response = await fetch(`${API_V2}/users/${id}`);
  return response.json();
}

// Client specifying version
const user = await getUserV2(123);
```

#### Version-Specific Endpoints

```javascript
class APIClient {
  constructor(version = 'v2') {
    this.baseUrl = `https://api.example.com/${version}`;
  }
  
  async fetch(endpoint, options = {}) {
    const response = await fetch(`${this.baseUrl}${endpoint}`, options);
    
    if (!response.ok) {
      throw new Error(`API ${this.version} error: ${response.status}`);
    }
    
    return response.json();
  }
  
  async getUser(id) {
    return this.fetch(`/users/${id}`);
  }
  
  async createPost(data) {
    return this.fetch('/posts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
  }
}

// Usage
const clientV1 = new APIClient('v1');
const clientV2 = new APIClient('v2');

const legacyUser = await clientV1.getUser(123);
const modernUser = await clientV2.getUser(123);
```

#### Nested Resource Versioning

```javascript
// Version applies to specific resources only
const BASE_URL = 'https://api.example.com';

async function getUsers() {
  // Unversioned endpoint
  const response = await fetch(`${BASE_URL}/users`);
  return response.json();
}

async function getAnalyticsV2(userId) {
  // Versioned nested resource
  const response = await fetch(`${BASE_URL}/users/${userId}/analytics/v2`);
  return response.json();
}

async function getReportsV3(userId) {
  // Different version for different resource
  const response = await fetch(`${BASE_URL}/users/${userId}/reports/v3`);
  return response.json();
}
```

### Header-Based Versioning

#### Accept Header Versioning

```javascript
async function fetchWithVersion(url, version) {
  const response = await fetch(url, {
    headers: {
      'Accept': `application/vnd.example.${version}+json`
    }
  });
  
  return response.json();
}

// Usage
const dataV1 = await fetchWithVersion('https://api.example.com/users', 'v1');
const dataV2 = await fetchWithVersion('https://api.example.com/users', 'v2');
```

#### Custom Version Header

```javascript
async function apiRequest(endpoint, version = '2.0') {
  const response = await fetch(`https://api.example.com${endpoint}`, {
    headers: {
      'API-Version': version,
      'Content-Type': 'application/json'
    }
  });
  
  if (!response.ok) {
    throw new Error(`Request failed: ${response.status}`);
  }
  
  // Server may return different version than requested
  const responseVersion = response.headers.get('API-Version');
  const data = await response.json();
  
  return { data, version: responseVersion };
}

// Client requesting specific version
const result = await apiRequest('/users/123', '2.1');
console.log(`Received version: ${result.version}`);
```

#### Content Negotiation

```javascript
class VersionedAPI {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
  }
  
  async request(endpoint, options = {}) {
    const { version = 'latest', acceptType = 'json', ...fetchOptions } = options;
    
    const headers = {
      'Accept': this.buildAcceptHeader(version, acceptType),
      ...fetchOptions.headers
    };
    
    const response = await fetch(`${this.baseUrl}${endpoint}`, {
      ...fetchOptions,
      headers
    });
    
    return this.parseResponse(response);
  }
  
  buildAcceptHeader(version, type) {
    const versionPart = version === 'latest' ? '' : `.${version}`;
    return `application/vnd.example${versionPart}+${type}`;
  }
  
  async parseResponse(response) {
    const contentType = response.headers.get('Content-Type');
    
    if (contentType.includes('json')) {
      return response.json();
    } else if (contentType.includes('xml')) {
      return response.text();
    }
    
    return response.blob();
  }
}

// Usage
const api = new VersionedAPI('https://api.example.com');

const v1Data = await api.request('/users', { version: 'v1' });
const v2Data = await api.request('/users', { version: 'v2' });
const latestData = await api.request('/users', { version: 'latest' });
```

### Query Parameter Versioning

#### Simple Version Parameter

```javascript
async function fetchWithQueryVersion(endpoint, version) {
  const url = new URL(`https://api.example.com${endpoint}`);
  url.searchParams.set('version', version);
  
  const response = await fetch(url);
  return response.json();
}

// Usage
const users = await fetchWithQueryVersion('/users', '2');
const posts = await fetchWithQueryVersion('/posts', '3');
```

#### API Version Parameter

```javascript
class QueryVersionAPI {
  constructor(baseUrl, defaultVersion = '1') {
    this.baseUrl = baseUrl;
    this.defaultVersion = defaultVersion;
  }
  
  async get(endpoint, params = {}, version = null) {
    const url = new URL(`${this.baseUrl}${endpoint}`);
    
    // Add version parameter
    url.searchParams.set('api_version', version || this.defaultVersion);
    
    // Add other query parameters
    Object.entries(params).forEach(([key, value]) => {
      url.searchParams.set(key, value);
    });
    
    const response = await fetch(url);
    
    if (!response.ok) {
      throw new Error(`API error: ${response.status}`);
    }
    
    return response.json();
  }
}

// Usage
const api = new QueryVersionAPI('https://api.example.com', '2');

const users = await api.get('/users', { limit: 10 });
const usersV3 = await api.get('/users', { limit: 10 }, '3');
```

#### Mixed Versioning Strategy

```javascript
async function flexibleVersionRequest(endpoint, options = {}) {
  const {
    version,
    versionMethod = 'header', // 'header', 'query', or 'path'
    ...fetchOptions
  } = options;
  
  let url = `https://api.example.com${endpoint}`;
  const headers = { ...fetchOptions.headers };
  
  switch (versionMethod) {
    case 'path':
      url = `https://api.example.com/v${version}${endpoint}`;
      break;
      
    case 'query':
      const urlObj = new URL(url);
      urlObj.searchParams.set('version', version);
      url = urlObj.toString();
      break;
      
    case 'header':
    default:
      headers['API-Version'] = version;
      break;
  }
  
  const response = await fetch(url, {
    ...fetchOptions,
    headers
  });
  
  return response.json();
}

// Usage - same interface, different versioning methods
const pathVersioned = await flexibleVersionRequest('/users', {
  version: '2',
  versionMethod: 'path'
});

const headerVersioned = await flexibleVersionRequest('/users', {
  version: '2',
  versionMethod: 'header'
});

const queryVersioned = await flexibleVersionRequest('/users', {
  version: '2',
  versionMethod: 'query'
});
```

### Version Negotiation

#### Client Version Preference

```javascript
class NegotiatingClient {
  constructor(baseUrl, supportedVersions) {
    this.baseUrl = baseUrl;
    this.supportedVersions = supportedVersions; // ['2.0', '1.5', '1.0']
  }
  
  async request(endpoint, options = {}) {
    // Request with version preference list
    const response = await fetch(`${this.baseUrl}${endpoint}`, {
      ...options,
      headers: {
        'Accept-Version': this.supportedVersions.join(', '),
        ...options.headers
      }
    });
    
    // Check which version server returned
    const serverVersion = response.headers.get('API-Version');
    
    if (!this.supportedVersions.includes(serverVersion)) {
      console.warn(`Server returned unsupported version: ${serverVersion}`);
    }
    
    const data = await response.json();
    return { data, version: serverVersion };
  }
}

// Usage
const client = new NegotiatingClient('https://api.example.com', ['2.0', '1.5']);
const result = await client.request('/users');
console.log(`Using API version: ${result.version}`);
```

### Fallback Version Handling

```javascript
async function requestWithFallback(endpoint, preferredVersion, fallbackVersions = []) {
  const versions = [preferredVersion, ...fallbackVersions];
  
  for (const version of versions) {
    try {
      const response = await fetch(`https://api.example.com/${version}${endpoint}`);
      
      if (response.ok) {
        const data = await response.json();
        return { data, version, success: true };
      }
      
      // Try next version on 404 or 410 (Gone)
      if (response.status === 404 || response.status === 410) {
        console.warn(`Version ${version} not available, trying next...`);
        continue;
      }
      
      // For other errors, throw
      throw new Error(`Request failed with status ${response.status}`);
      
    } catch (error) {
      // If this was the last version, throw the error
      if (version === versions[versions.length - 1]) {
        throw new Error(`All versions failed. Last error: ${error.message}`);
      }
      
      console.warn(`Version ${version} failed: ${error.message}`);
    }
  }
  
  // This shouldn't be reached, but just in case
  throw new Error('No versions succeeded');
}

// Usage
try {
  const result = await requestWithFallback('/users/123', 'v3', ['v2', 'v1']);
  console.log(`Successfully fetched data using version: ${result.version}`);
  console.log(result.data);
} catch (error) {
  console.error('Request failed:', error.message);
}
```

### Media Type Versioning

```javascript
async function requestWithMediaType(endpoint, version) {
  const response = await fetch(`https://api.example.com${endpoint}`, {
    headers: {
      'Accept': `application/vnd.myapi.${version}+json`,
      'Content-Type': 'application/json'
    }
  });
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  return response.json();
}

// Usage
const data = await requestWithMediaType('/users/123', 'v2');
```

### Semantic Versioning in URLs

```javascript
async function requestWithSemanticVersion(endpoint, major, minor = 0, patch = 0) {
  const version = patch > 0 ? `v${major}.${minor}.${patch}` : `v${major}.${minor}`;
  
  const response = await fetch(`https://api.example.com/${version}${endpoint}`, {
    headers: {
      'Content-Type': 'application/json'
    }
  });
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  return response.json();
}

// Usage
const data = await requestWithSemanticVersion('/users/123', 2, 1, 0);
```

### Version Deprecation Warnings

```javascript
async function requestWithDeprecationCheck(endpoint, version) {
  const response = await fetch(`https://api.example.com/${version}${endpoint}`);
  
  // Check for deprecation warnings in response headers
  const deprecationWarning = response.headers.get('Deprecation');
  const sunset = response.headers.get('Sunset');
  const link = response.headers.get('Link');
  
  if (deprecationWarning) {
    console.warn(`⚠️ API version ${version} is deprecated`);
    if (sunset) {
      console.warn(`Sunset date: ${sunset}`);
    }
    if (link) {
      console.warn(`Migration guide: ${link}`);
    }
  }
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  return response.json();
}

// Usage
const data = await requestWithDeprecationCheck('/users/123', 'v1');
```

### Version Detection from Response

```javascript
async function requestWithVersionDetection(endpoint) {
  const response = await fetch(`https://api.example.com${endpoint}`);
  
  // Detect version from response header
  const apiVersion = response.headers.get('API-Version') || 
                     response.headers.get('X-API-Version');
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  const data = await response.json();
  
  return {
    data,
    version: apiVersion,
    timestamp: new Date().toISOString()
  };
}

// Usage
const result = await requestWithVersionDetection('/users/123');
console.log(`Response from API version: ${result.version}`);
```

### Content Negotiation Based Versioning

```javascript
async function requestWithContentNegotiation(endpoint, acceptedVersions) {
  const acceptHeader = acceptedVersions
    .map(v => `application/vnd.myapi.${v}+json`)
    .join(', ');
  
  const response = await fetch(`https://api.example.com${endpoint}`, {
    headers: {
      'Accept': acceptHeader,
      'Content-Type': 'application/json'
    }
  });
  
  const contentType = response.headers.get('Content-Type');
  const versionMatch = contentType?.match(/vnd\.myapi\.([^+]+)/);
  const usedVersion = versionMatch ? versionMatch[1] : 'unknown';
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  const data = await response.json();
  
  return { data, usedVersion };
}

// Usage
const result = await requestWithContentNegotiation('/users/123', ['v3', 'v2', 'v1']);
console.log(`API responded with version: ${result.usedVersion}`);
```

### Version Range Requests

```javascript
async function requestWithVersionRange(endpoint, minVersion, maxVersion) {
  const response = await fetch(`https://api.example.com${endpoint}`, {
    headers: {
      'Accept-Version': `>=${minVersion} <=${maxVersion}`,
      'Content-Type': 'application/json'
    }
  });
  
  const actualVersion = response.headers.get('API-Version');
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  const data = await response.json();
  
  return {
    data,
    requestedRange: `${minVersion}-${maxVersion}`,
    actualVersion
  };
}

// Usage
const result = await requestWithVersionRange('/users/123', '2.0', '3.0');
console.log(`Requested: ${result.requestedRange}, Got: ${result.actualVersion}`);
```

### Default Version with Override

```javascript
const DEFAULT_API_VERSION = 'v2';

async function requestWithDefaultVersion(endpoint, versionOverride = null) {
  const version = versionOverride || DEFAULT_API_VERSION;
  
  const response = await fetch(`https://api.example.com/${version}${endpoint}`, {
    headers: {
      'Content-Type': 'application/json'
    }
  });
  
  if (!response.ok) {
    throw new Error(`Request failed with status ${response.status}`);
  }
  
  return response.json();
}

// Usage
const data1 = await requestWithDefaultVersion('/users/123'); // Uses v2
const data2 = await requestWithDefaultVersion('/users/123', 'v3'); // Uses v3
```

### Version Migration Helper

```javascript
async function migrateVersion(endpoint, fromVersion, toVersion, transformFn) {
  // Fetch from old version
  const oldResponse = await fetch(`https://api.example.com/${fromVersion}${endpoint}`);
  
  if (!oldResponse.ok) {
    throw new Error(`Failed to fetch from ${fromVersion}`);
  }
  
  const oldData = await oldResponse.json();
  
  // Transform data for new version
  const transformedData = transformFn ? transformFn(oldData) : oldData;
  
  // Verify with new version
  const newResponse = await fetch(`https://api.example.com/${toVersion}${endpoint}`);
  
  if (!newResponse.ok) {
    console.warn(`New version ${toVersion} not available, using transformed old data`);
    return { data: transformedData, migrated: true, version: toVersion };
  }
  
  const newData = await newResponse.json();
  
  return { data: newData, migrated: false, version: toVersion };
}

// Usage
const result = await migrateVersion('/users/123', 'v1', 'v2', (oldData) => ({
  ...oldData,
  // Transform old format to new format
  fullName: `${oldData.firstName} ${oldData.lastName}`
}));
```

---

## Pagination Standards

### Offset-Based Pagination

#### Page Number Strategy

Traditional page-based navigation:

```
GET /users?page=1&limit=20
GET /users?page=2&limit=20
GET /users?page=3&limit=20
```

Response structure:

```json
{
  "data": [
    { "id": 21, "name": "User 21" },
    { "id": 22, "name": "User 22" }
  ],
  "pagination": {
    "page": 2,
    "limit": 20,
    "total": 1250,
    "totalPages": 63,
    "hasNext": true,
    "hasPrevious": true
  }
}
```

#### Offset and Limit Strategy

Direct offset control:

```
GET /users?offset=40&limit=20
GET /users?offset=60&limit=20
```

Response structure:

```json
{
  "data": [...],
  "pagination": {
    "offset": 40,
    "limit": 20,
    "total": 1250,
    "hasNext": true,
    "hasPrevious": true
  }
}
```

Calculation relationship:

```
offset = (page - 1) × limit
page = (offset ÷ limit) + 1
```

#### Default Values

Establish sensible defaults:

```
GET /users
# Equivalent to: /users?page=1&limit=20

GET /users?page=1
# Uses default limit=20

GET /users?limit=50
# Uses default page=1
```

Common default limits: 10, 20, 25, 50

#### Maximum Limits

Enforce upper bounds:

```
GET /users?limit=10000

400 Bad Request
{
  "error": {
    "code": "INVALID_LIMIT",
    "message": "Limit exceeds maximum allowed value of 100",
    "maxLimit": 100,
    "requestedLimit": 10000
  }
}
```

Typical maximum limits: 100, 250, 500

#### Advantages

- Simple implementation and understanding
- Direct page access (jump to page 10)
- Easy calculation of total pages
- URL bookmarkable for specific pages
- Client can calculate progress (page 5 of 10)

#### Disadvantages

- Performance degrades with high offsets
- Inconsistent results with real-time data changes
- Skip/duplicate records when data modified during pagination
- Database query cost increases with offset size

Performance impact example:

```sql
-- Fast: Low offset
SELECT * FROM users LIMIT 20 OFFSET 0;

-- Slow: High offset (database must read and discard 100,000 rows)
SELECT * FROM users LIMIT 20 OFFSET 100000;
```

#### Deep Pagination Problem

High offsets cause performance issues:

```
GET /users?page=5000&limit=20
# offset = 99,980

# Database must:
# 1. Read 100,000 rows
# 2. Discard first 99,980 rows
# 3. Return 20 rows
```

Solutions:
- Implement cursor-based pagination for deep pages
- Limit maximum page/offset values
- Use search/filtering instead of deep pagination

#### Data Consistency Issues

Records shift between page requests:

```
# Initial state: 100 users
GET /users?page=1&limit=20
# Returns users 1-20

# 5 new users added at top
# User 16 moves to position 21

GET /users?page=2&limit=20
# Returns users 21-40
# User 16 appears again (duplicate)

# Or if 5 users deleted:
# User 21 moves to position 16
GET /users?page=2&limit=20
# Returns users 21-40
# User 16-20 skipped (missing)
```

### Cursor-Based Pagination

#### Opaque Cursor Strategy

Cursor encodes position without exposing internal structure:

```
GET /users?limit=20

Response:
{
  "data": [...],
  "pagination": {
    "nextCursor": "eyJpZCI6MjAsImNyZWF0ZWRBdCI6IjIwMjQtMDEtMTVUMTA6MzA6MDAuMDAwWiJ9",
    "prevCursor": null,
    "hasNext": true,
    "hasPrevious": false
  }
}

# Next page
GET /users?cursor=eyJpZCI6MjAsImNyZWF0ZWRBdCI6IjIwMjQtMDEtMTVUMTA6MzA6MDAuMDAwWiJ9&limit=20
```

Cursor typically base64-encoded JSON:

```javascript
// Decoded cursor
{
  "id": 20,
  "createdAt": "2024-01-15T10:30:00.000Z"
}

// Encoding cursor
const cursor = Buffer.from(JSON.stringify({ id: 20, createdAt: timestamp }))
  .toString('base64url');

// Decoding cursor
const decoded = JSON.parse(Buffer.from(cursor, 'base64url').toString());
```

#### Cursor Construction

Cursor contains values for ordering columns:

```javascript
// For: ORDER BY created_at DESC, id DESC
const cursor = {
  createdAt: "2024-01-15T10:30:00.000Z",
  id: 123
};

// Query using cursor
SELECT * FROM users
WHERE (created_at, id) < (?, ?)
ORDER BY created_at DESC, id DESC
LIMIT 20;
```

#### Bidirectional Navigation

Support forward and backward pagination:

```json
{
  "data": [...],
  "pagination": {
    "nextCursor": "eyJpZCI6NDB9",
    "prevCursor": "eyJpZCI6MjF9",
    "hasNext": true,
    "hasPrevious": true
  }
}
```

Query logic:

```sql
-- Forward pagination (after cursor)
SELECT * FROM users
WHERE id > ?
ORDER BY id ASC
LIMIT 21;

-- Backward pagination (before cursor)
SELECT * FROM users
WHERE id < ?
ORDER BY id DESC
LIMIT 21;
```

Fetch limit+1 to determine if more pages exist.

#### Parameter Naming Conventions

Common parameter names:

```
# Standard cursor
GET /users?cursor=abc123&limit=20

# Explicit direction
GET /users?after=abc123&limit=20
GET /users?before=xyz789&limit=20

# First/last terminology
GET /users?first=20&after=abc123
GET /users?last=20&before=xyz789
```

#### Advantages

- Consistent performance regardless of position
- No duplicate/missing records with real-time data
- Handles large datasets efficiently
- Database-friendly (uses indexed columns)

#### Disadvantages

- Cannot jump to arbitrary pages
- No total count or page indicators
- Cannot determine position in dataset
- More complex implementation
- Cursor invalidation on data deletion

#### Cursor Invalidation

Cursors may become invalid:

```
GET /users?cursor=eyJpZCI6MTIzfQ&limit=20

400 Bad Request
{
  "error": {
    "code": "INVALID_CURSOR",
    "message": "The provided cursor is invalid or expired",
    "suggestion": "Start pagination from the beginning"
  }
}
```

Causes:
- Referenced record deleted
- Cursor format changed (API update)
- Cursor expired (time-limited cursors)

#### Composite Cursors

Multiple fields for tie-breaking:

```javascript
// When multiple records share same timestamp
const cursor = {
  createdAt: "2024-01-15T10:30:00.000Z",
  id: 123  // Tie-breaker using unique ID
};

// SQL query
SELECT * FROM users
WHERE created_at < ?
   OR (created_at = ? AND id < ?)
ORDER BY created_at DESC, id DESC
LIMIT 20;
```

Always include unique identifier as final cursor component.

### Keyset Pagination

#### Keyset Principle

Navigate using last seen value from indexed column:

```
# First page
GET /users?limit=20
ORDER BY id ASC

Response:
{
  "data": [
    { "id": 1, "name": "User 1" },
    ...
    { "id": 20, "name": "User 20" }
  ],
  "pagination": {
    "lastId": 20
  }
}

# Next page
GET /users?lastId=20&limit=20

# SQL: WHERE id > 20 ORDER BY id ASC LIMIT 20
```

#### Multiple Column Keyset

Keyset with non-unique ordering:

```
# Order by created_at, then id
GET /users?limit=20
ORDER BY created_at DESC, id DESC

Response:
{
  "data": [...],
  "pagination": {
    "lastCreatedAt": "2024-01-15T10:30:00.000Z",
    "lastId": 20
  }
}

# Next page
GET /users?lastCreatedAt=2024-01-15T10:30:00.000Z&lastId=20&limit=20

# SQL:
WHERE (created_at, id) < (?, ?)
ORDER BY created_at DESC, id DESC
LIMIT 20
```

#### Seek Method Implementation

Database-specific syntax:

```sql
-- PostgreSQL: Row value comparison
SELECT * FROM users
WHERE (created_at, id) < (?, ?)
ORDER BY created_at DESC, id DESC
LIMIT 20;

-- MySQL: Expanded condition
SELECT * FROM users
WHERE created_at < ?
   OR (created_at = ? AND id < ?)
ORDER BY created_at DESC, id DESC
LIMIT 20;
```

#### Index Requirements

Requires composite index on ordering columns:

```sql
-- Required index for efficient keyset pagination
CREATE INDEX idx_users_created_id ON users(created_at DESC, id DESC);

-- Query uses index efficiently
EXPLAIN SELECT * FROM users
WHERE (created_at, id) < (?, ?)
ORDER BY created_at DESC, id DESC
LIMIT 20;
```

#### Advantages

- Extremely fast, constant time complexity O(1)
- No offset calculation overhead
- Works well with billions of records
- Predictable performance
- Real-time data consistency

#### Disadvantages

- Cannot skip pages or jump to arbitrary position
- Requires indexed columns for ordering
- Complex with multiple sort orders
- Client must track last seen values
- Bidirectional navigation requires extra logic

### Timestamp-Based Pagination

#### Time Range Strategy

Paginate using time windows:

```
GET /events?since=2024-01-15T10:00:00Z&until=2024-01-15T11:00:00Z&limit=100

Response:
{
  "data": [...],
  "pagination": {
    "since": "2024-01-15T10:00:00Z",
    "until": "2024-01-15T11:00:00Z",
    "nextUntil": "2024-01-15T10:30:00Z",
    "hasNext": true
  }
}

# Next page
GET /events?since=2024-01-15T10:00:00Z&until=2024-01-15T10:30:00Z&limit=100
```

#### Polling Use Case

Fetch new items since last request:

```
# Initial request
GET /notifications?since=2024-01-15T10:00:00Z

Response:
{
  "data": [...],
  "pagination": {
    "since": "2024-01-15T10:00:00Z",
    "latestTimestamp": "2024-01-15T10:30:00Z"
  }
}

# Poll for new items
GET /notifications?since=2024-01-15T10:30:00Z
```

#### Time Precision Handling

Handle records with identical timestamps:

```javascript
// Use timestamp + ID for uniqueness
const cursor = {
  timestamp: "2024-01-15T10:30:00.123Z",
  id: 456
};

// Query
SELECT * FROM events
WHERE timestamp > ?
   OR (timestamp = ? AND id > ?)
ORDER BY timestamp ASC, id ASC
LIMIT 100;
```

#### Advantages

- Natural for time-series data
- Efficient polling for updates
- Easy to implement time-range queries
- Works well with indexed timestamp columns

#### Disadvantages

- Requires reliable timestamps
- Clock skew issues in distributed systems
- Multiple records with same timestamp need tie-breaker
- Cannot determine total count easily

### Link Header Pagination (RFC 5988)

#### Standard Link Relations

Provide navigation URLs in headers:

```
GET /users?page=5&limit=20

Link: </users?page=1&limit=20>; rel="first",
      </users?page=4&limit=20>; rel="prev",
      </users?page=6&limit=20>; rel="next",
      </users?page=50&limit=20>; rel="last"
```

#### Relation Types

Standard rel values:

```
rel="first"    # First page
rel="prev"     # Previous page
rel="next"     # Next page
rel="last"     # Last page
rel="self"     # Current page
```

#### Multiple Links

Comma-separated links:

```
Link: </users?page=1>; rel="first",
      </users?page=4>; rel="prev",
      </users?page=5>; rel="self",
      </users?page=6>; rel="next",
      </users?page=50>; rel="last"
```

#### Cursor with Link Headers

Combine cursors with link headers:

```
GET /users?cursor=abc123

Link: </users?cursor=xyz789>; rel="next",
      </users?cursor=def456>; rel="prev"
```

#### Parsing Link Headers

Client-side parsing:

```javascript
// Parse Link header
function parseLinkHeader(header) {
  const links = {};
  const parts = header.split(',');
  
  parts.forEach(part => {
    const [url, rel] = part.split(';');
    const cleanUrl = url.trim().slice(1, -1); // Remove < >
    const relMatch = rel.match(/rel="(.+?)"/);
    
    if (relMatch) {
      links[relMatch[1]] = cleanUrl;
    }
  });
  
  return links;
}

// Usage
const linkHeader = response.headers.get('Link');
const links = parseLinkHeader(linkHeader);
// { first: '/users?page=1', next: '/users?page=6', ... }
```

#### Advantages

- Standards-based approach
- Keeps response body clean
- Complete URLs eliminate URL construction
- Easy discovery of available navigation

#### Disadvantages

- Less visible than body-based pagination
- Requires header parsing
- Not all HTTP clients handle headers easily
- Limited metadata capability

### Range Header Pagination (RFC 7233)

#### Range Request Syntax

Use HTTP Range header:

```
GET /users
Range: items=0-19

206 Partial Content
Content-Range: items 0-19/1250
Accept-Ranges: items

[
  { "id": 1, "name": "User 1" },
  ...
  { "id": 20, "name": "User 20" }
]
```

#### Unbounded Range

Request from offset to end:

```
GET /users
Range: items=1000-

206 Partial Content
Content-Range: items 1000-1249/1250
```

#### Suffix Range

Request last N items:

```
GET /users
Range: items=-50

206 Partial Content
Content-Range: items 1200-1249/1250
```

#### Unsatisfiable Range

Handle invalid ranges:

```
GET /users
Range: items=2000-2999

416 Range Not Satisfiable
Content-Range: items */1250

{
  "error": {
    "code": "RANGE_NOT_SATISFIABLE",
    "message": "Requested range exceeds total items",
    "totalItems": 1250
  }
}
```

#### Accept-Ranges Header

Advertise range support:

```
GET /users

200 OK
Accept-Ranges: items
Content-Range: items 0-19/1250
```

Or decline range support:

```
Accept-Ranges: none
```

#### Advantages

- HTTP standard compliance
- Semantic meaning clear from headers
- Client controls exact range
- Works with HTTP caching

#### Disadvantages

- Limited adoption in REST APIs
- Less intuitive than query parameters
- Some proxies may not handle correctly
- Complex header parsing

### GraphQL-Style Pagination

#### Relay Connection Specification

Cursor-based with standardized structure:

```graphql
query {
  users(first: 20, after: "cursor123") {
    edges {
      node {
        id
        name
        email
      }
      cursor
    }
    pageInfo {
      hasNextPage
      hasPreviousPage
      startCursor
      endCursor
    }
    totalCount
  }
}
```

REST adaptation:

```
GET /users?first=20&after=cursor123

Response:
{
  "edges": [
    {
      "node": { "id": 1, "name": "User 1" },
      "cursor": "cursor001"
    },
    ...
  ],
  "pageInfo": {
    "hasNextPage": true,
    "hasPreviousPage": false,
    "startCursor": "cursor001",
    "endCursor": "cursor020"
  },
  "totalCount": 1250
}
```

#### Forward and Backward Pagination

Explicit directional parameters:

```
# Forward pagination
GET /users?first=20&after=cursor123

# Backward pagination
GET /users?last=20&before=cursor456
```

#### Edge Metadata

Additional per-item metadata:

```json
{
  "edges": [
    {
      "node": { "id": 1, "name": "User 1" },
      "cursor": "cursor001",
      "addedAt": "2024-01-15T10:30:00Z",
      "relevanceScore": 0.95
    }
  ]
}
```

#### Advantages

- Standardized structure
- Rich metadata support
- Clear forward/backward semantics
- Per-item cursor availability

#### Disadvantages

- Verbose response structure
- Overhead for simple use cases
- Complexity for basic needs
- Primarily designed for GraphQL

### Hybrid Pagination Approaches

#### Offset with Cursor Fallback

Start with offset, switch to cursor for deep pages:

```
# Shallow pagination: offset-based
GET /users?page=1&limit=20
GET /users?page=2&limit=20

# Deep pagination: cursor-based
GET /users?cursor=abc123&limit=20

Response:
{
  "data": [...],
  "pagination": {
    "cursor": "abc123",
    "page": null,
    "hasNext": true,
    "deepPaginationThreshold": 100
  }
}
```

#### Total Count Strategy

Provide count for offset, omit for cursor:

```
# Offset pagination with count
GET /users?page=1&limit=20

Response:
{
  "data": [...],
  "pagination": {
    "page": 1,
    "total": 1250,
    "totalPages": 63
  }
}

# Cursor pagination without count
GET /users?cursor=abc123&limit=20

Response:
{
  "data": [...],
  "pagination": {
    "nextCursor": "def456",
    "hasNext": true
    # No total count for performance
  }
}
```

#### Estimated Counts

Provide fast estimates instead of exact counts:

```json
{
  "data": [...],
  "pagination": {
    "page": 1,
    "total": "~50000",
    "isEstimate": true,
    "hasNext": true
  }
}
```

Database estimation techniques:

```sql
-- PostgreSQL: Fast estimate from statistics
SELECT reltuples::bigint AS estimate
FROM pg_class
WHERE relname = 'users';

-- MySQL: Estimate from information_schema
SELECT table_rows AS estimate
FROM information_schema.tables
WHERE table_name = 'users';
```

Exact counts expensive for large tables:

```sql
-- Slow on large tables
SELECT COUNT(*) FROM users;

-- Fast estimate
SELECT reltuples FROM pg_class WHERE relname = 'users';
```

### Pagination Metadata

#### Essential Metadata Fields

Core pagination information:

```json
{
  "data": [...],
  "pagination": {
    "currentPage": 5,
    "pageSize": 20,
    "totalItems": 1250,
    "totalPages": 63,
    "hasNext": true,
    "hasPrevious": true,
    "isFirst": false,
    "isLast": false
  }
}
```

#### Navigation URLs

Pre-constructed navigation links:

```json
{
  "data": [...],
  "pagination": {
    "page": 5,
    "links": {
      "first": "/users?page=1&limit=20",
      "previous": "/users?page=4&limit=20",
      "self": "/users?page=5&limit=20",
      "next": "/users?page=6&limit=20",
      "last": "/users?page=63&limit=20"
    }
  }
}
```

#### Cursor Metadata

Cursor-specific information:

```json
{
  "data": [...],
  "pagination": {
    "cursor": {
      "next": "eyJpZCI6NDB9",
      "previous": "eyJpZCI6MjF9"
    },
    "hasNext": true,
    "hasPrevious": true,
    "pageSize": 20
  }
}
```

#### Result Statistics

Additional context about results:

```json
{
  "data": [...],
  "pagination": {
    "page": 5,
    "returned": 20,
    "total": 1250,
    "rangeStart": 81,
    "rangeEnd": 100
  }
}
```

### Performance Considerations

#### Count Query Optimization

Avoid expensive counts for large datasets:

```
# Strategy 1: Count only when needed
GET /users?page=1&includeCount=true

# Strategy 2: Estimate for display
GET /users?page=1
Response: { "total": "10000+", "isEstimate": true }

# Strategy 3: Omit count entirely
GET /users?cursor=abc123
Response: { "hasNext": true }  # No total provided
```

#### Index Optimization

Ensure proper indexing for pagination queries:

```sql
-- Offset pagination index
CREATE INDEX idx_users_id ON users(id);

-- Timestamp-based pagination index
CREATE INDEX idx_users_created ON users(created_at DESC, id DESC);

-- Filtered pagination index
CREATE INDEX idx_users_active_created 
ON users(status, created_at DESC) 
WHERE status = 'active';
```

#### Query Execution Plans

Verify efficient execution:

```sql
-- Check query plan
EXPLAIN ANALYZE
SELECT * FROM users
WHERE created_at < ?
ORDER BY created_at DESC
LIMIT 20;

-- Look for:
-- - Index usage (not Seq Scan)
-- - Low execution time
-- - Minimal rows examined
```

#### Lazy Loading Counts

Defer count calculation:

```javascript
// Don't calculate count on every request
GET /users?page=1&limit=20

// Client requests count separately if needed
GET /users/count?filters=...

Response:
{
  "count": 1250,
  "isExact": true,
  "calculatedAt": "2024-01-15T10:30:00Z"
}
```

#### Caching Strategies

Cache paginated results:

```
# Cache key includes all pagination parameters
GET /users?page=5&limit=20&sort=-createdAt

Cache-Control: public, max-age=60
ETag: "page5-20-created-v1"
```

Invalidation considerations:

```javascript
// Invalidate affected pages on mutation
POST /users
// Invalidate: page 1, counts, recent user lists

DELETE /users/123
// Invalidate: specific user, list pages, counts
```

### Error Handling

#### Invalid Page Numbers

Handle out-of-range pages:

```
GET /users?page=9999&limit=20

# Option 1: Return empty results
200 OK
{
  "data": [],
  "pagination": {
    "page": 9999,
    "total": 1250,
    "totalPages": 63,
    "hasNext": false
  }
}

# Option 2: Return error
400 Bad Request
{
  "error": {
    "code": "INVALID_PAGE",
    "message": "Page 9999 exceeds total pages (63)",
    "maxPage": 63
  }
}
```

#### Invalid Cursors

Handle malformed or expired cursors:

```
GET /users?cursor=invalid_cursor

400 Bad Request
{
  "error": {
    "code": "INVALID_CURSOR",
    "message": "The provided cursor is invalid",
    "details": "Cursor format is malformed or expired"
  }
}
```

#### Limit Validation

Enforce limit constraints:

```
GET /users?limit=-5

400 Bad Request
{
  "error": {
    "code": "INVALID_LIMIT",
    "message": "Limit must be between 1 and 100",
    "minLimit": 1,
    "maxLimit": 100,
    "requestedLimit": -5
  }
}
```

### Client Implementation Patterns

#### Infinite Scroll

Cursor-based infinite loading:

```javascript
async function loadMore() {
  const response = await fetch(
    `/users?cursor=${nextCursor}&limit=20`
  );
  const data = await response.json();
  
  users.push(...data.data);
  nextCursor = data.pagination.nextCursor;
  hasMore = data.pagination.hasNext;
}

// Trigger on scroll
window.addEventListener('scroll', () => {
  if (nearBottom() && hasMore && !loading) {
    loadMore();
  }
});
```

#### Page Navigation

Offset-based page selector:

```javascript
async function goToPage(pageNum) {
  const response = await fetch(
    `/users?page=${pageNum}&limit=20`
  );
  const data = await response.json();
  
  displayUsers(data.data);
  updatePagination(data.pagination);
}

// Render page numbers
function renderPagination(pagination) {
  const pages = [];
  for (let i = 1; i <= pagination.totalPages; i++) {
    pages.push(
      <button onClick={() => goToPage(i)}>
        {i}
      </button>
    );
  }
  return pages;
}
```

#### Load More Button

Explicit user-triggered loading:

```javascript
async function loadMore() {
  const response = await fetch(
    `/users?cursor=${nextCursor}&limit=20`
  );
  const data = await response.json();
  
  users.push(...data.data);
  nextCursor = data.pagination.nextCursor;
  showLoadMore = data.pagination.hasNext;
}

// UI
{showLoadMore && (
  <button onClick={loadMore}>
    Load More
  </button>
)}
```

### API Design Recommendations

#### Choose Pagination Type by Use Case

Selection guide:

```
Offset-based:
- Small to medium datasets (< 100k records)
- Need page numbers/total counts
- Direct page access required
- Admin interfaces, reports

Cursor-based:
- Large datasets (> 100k records)
- Real-time data (social feeds)
- Infinite scroll UIs
- Performance-critical APIs

Keyset:
- Very large datasets (millions+)
- Time-series data
- Analytics queries
- High-performance requirements

Timestamp:
- Event streams
- Activity logs
- Polling for updates
- Time-based filtering
```

#### Consistency Across Endpoints

Maintain uniform pagination:

```
✅ Consistent:
GET /users?page=1&limit=20
GET /products?page=1&limit=20
GET /orders?page=1&limit=20

❌ Inconsistent:
GET /users?page=1&limit=20
GET /products?offset=0&max=20
GET /orders?cursor=abc&size=20
```

#### Document Default Behavior

Explicitly document defaults:

```
GET /users
# Defaults: page=1, limit=20, sort=-createdAt

Response:
{
  "data": [...],
  "pagination": {
    "page": 1,
    "limit": 20,
    "defaults": {
      "limit": 20,
      "sort": "-createdAt"
    }
  }
}
```

#### Provide Configuration Options

Allow client customization:

```
# Custom page size
GET /users?limit=50

# Different sort order
GET /users?sort=name

# Combined
GET /users?page=2&limit=50&sort=name
```

Document limits and constraints:

```
Parameters:
- page: integer, min=1, default=1
- limit: integer, min=1, max=100, default=20
- sort: string, allowed=[-]createdAt,[-]name,[-]email
```

---

## Rate Limiting Responses with Fetch API

### Understanding Rate Limit Response Headers

APIs typically communicate rate limit information through standardized HTTP headers:

```javascript
async function checkRateLimitHeaders(response) {
  const headers = {
    limit: response.headers.get('X-RateLimit-Limit'),
    remaining: response.headers.get('X-RateLimit-Remaining'),
    reset: response.headers.get('X-RateLimit-Reset'),
    retryAfter: response.headers.get('Retry-After')
  };
  
  return {
    limit: parseInt(headers.limit) || null,
    remaining: parseInt(headers.remaining) || null,
    reset: parseInt(headers.reset) || null,
    retryAfter: parseInt(headers.retryAfter) || null
  };
}
```

Common header naming conventions:

- `X-RateLimit-Limit` / `X-Rate-Limit-Limit` / `RateLimit-Limit`
- `X-RateLimit-Remaining` / `X-Rate-Limit-Remaining` / `RateLimit-Remaining`
- `X-RateLimit-Reset` / `X-Rate-Limit-Reset` / `RateLimit-Reset`
- `Retry-After` (standard HTTP header)

### Detecting Rate Limit Status

Identify when rate limits are hit through status codes and headers:

```javascript
class RateLimitDetector {
  static isRateLimited(response) {
    // Check 429 status code (standard)
    if (response.status === 429) {
      return true;
    }
    
    // Check 403 with rate limit indicator
    if (response.status === 403) {
      const rateLimitRemaining = response.headers.get('X-RateLimit-Remaining');
      if (rateLimitRemaining === '0') {
        return true;
      }
    }
    
    return false;
  }
  
  static getRetryDelay(response) {
    // Check Retry-After header (seconds or HTTP date)
    const retryAfter = response.headers.get('Retry-After');
    if (retryAfter) {
      // If numeric, it's seconds
      if (/^\d+$/.test(retryAfter)) {
        return parseInt(retryAfter) * 1000;
      }
      
      // If date string, calculate milliseconds until that time
      const retryDate = new Date(retryAfter);
      return Math.max(0, retryDate.getTime() - Date.now());
    }
    
    // Check X-RateLimit-Reset (typically Unix timestamp)
    const resetTime = response.headers.get('X-RateLimit-Reset');
    if (resetTime) {
      const resetTimestamp = parseInt(resetTime) * 1000;
      return Math.max(0, resetTimestamp - Date.now());
    }
    
    // Default fallback
    return 60000; // 1 minute
  }
}
```

### Basic Retry with Exponential Backoff

Implement retry logic when rate limits are encountered:

```javascript
class RateLimitedFetch {
  constructor(maxRetries = 3) {
    this.maxRetries = maxRetries;
  }
  
  async fetch(url, options = {}, attempt = 1) {
    try {
      const response = await fetch(url, options);
      
      if (RateLimitDetector.isRateLimited(response)) {
        if (attempt >= this.maxRetries) {
          throw new RateLimitError('Max retries exceeded', response);
        }
        
        const delay = RateLimitDetector.getRetryDelay(response);
        console.log(`Rate limited. Retrying after ${delay}ms`);
        
        await this.sleep(delay);
        return this.fetch(url, options, attempt + 1);
      }
      
      return response;
    } catch (error) {
      if (error instanceof RateLimitError) {
        throw error;
      }
      throw error;
    }
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

class RateLimitError extends Error {
  constructor(message, response) {
    super(message);
    this.name = 'RateLimitError';
    this.response = response;
  }
}
```

### Request Queue Pattern

Queue requests to avoid hitting rate limits:

```javascript
class RequestQueue {
  constructor(rateLimit, interval) {
    this.queue = [];
    this.processing = false;
    this.rateLimit = rateLimit; // requests per interval
    this.interval = interval; // milliseconds
    this.requestCount = 0;
    this.windowStart = Date.now();
  }
  
  async enqueue(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.processing || this.queue.length === 0) {
      return;
    }
    
    this.processing = true;
    
    // Sort by priority
    this.queue.sort((a, b) => {
      const priorities = { high: 3, medium: 2, low: 1 };
      return priorities[b.priority] - priorities[a.priority];
    });
    
    while (this.queue.length > 0) {
      // Check circuit breaker
      if (this.enableCircuitBreaker && this.circuitBreaker.getState().state === 'OPEN') {
        await this.sleep(1000);
        continue;
      }
      
      // Wait if needed
      const waitTime = await this.getWaitTime();
      if (waitTime > 0) {
        await this.sleep(waitTime);
      }
      
      const request = this.queue.shift();
      
      try {
        // Make request
        const response = await fetch(request.url, request.options);
        
        // Update tracker
        const endpoint = new URL(request.url).pathname;
        this.tracker.updateFromResponse(endpoint, response);
        
        // Check if rate limited
        if (RateLimitDetector.isRateLimited(response)) {
          if (request.attempts < this.maxRetries) {
            request.attempts++;
            const retryDelay = RateLimitDetector.getRetryDelay(response);
            await this.sleep(retryDelay);
            this.queue.unshift(request);
            
            if (this.enableCircuitBreaker) {
              this.circuitBreaker.recordFailure();
            }
            
            continue;
          } else {
            request.reject(new RateLimitError('Max retries exceeded', response));
          }
        } else {
          this.recordRequest();
          
          if (this.enableCircuitBreaker) {
            this.circuitBreaker.recordSuccess();
          }
          
          request.resolve(response);
        }
      } catch (error) {
        if (request.attempts < this.maxRetries) {
          request.attempts++;
          this.queue.unshift(request);
        } else {
          request.reject(error);
        }
      }
    }
    
    this.processing = false;
  }
  
  recordRequest() {
    this.requests.push(Date.now());
    this.cleanOldRequests();
  }
  
  cleanOldRequests() {
    const cutoff = Date.now() - this.windowMs;
    this.requests = this.requests.filter(timestamp => timestamp > cutoff);
  }
  
  async getWaitTime() {
    this.cleanOldRequests();
    
    if (this.requests.length < this.currentRate) {
      return 0;
    }
    
    const oldestRequest = this.requests[0];
    return Math.max(0, (oldestRequest + this.windowMs) - Date.now());
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getStatus() {
    this.cleanOldRequests();
    
    return {
      queueLength: this.queue.length,
      requestsInWindow: this.requests.length,
      remainingRequests: this.currentRate - this.requests.length,
      currentRate: this.currentRate,
      circuitBreakerState: this.circuitBreaker?.getState() || null
    };
  }
  
  reset() {
    this.requests = [];
    this.queue = [];
    if (this.circuitBreaker) {
      this.circuitBreaker.reset();
    }
  }
}

// Usage example
const rateLimiter = new ComprehensiveRateLimiter({
  maxRequests: 100,
  windowMs: 60000,
  maxRetries: 3,
  enableAdaptive: true,
  enableCircuitBreaker: true
});

// Make rate-limited request
const response = await rateLimiter.fetch('/api/data', {
  method: 'GET'
}, 'high');

// Check status
console.log(rateLimiter.getStatus());;
    }
    
    this.processing = true;
    
    while (this.queue.length > 0) {
      await this.waitIfNeeded();
      
      const request = this.queue.shift();
      
      try {
        const response = await fetch(request.url, request.options);
        request.resolve(response);
      } catch (error) {
        request.reject(error);
      }
      
      this.requestCount++;
    }
    
    this.processing = false;
  }
  
  async waitIfNeeded() {
    const now = Date.now();
    const elapsed = now - this.windowStart;
    
    if (elapsed >= this.interval) {
      // Reset window
      this.windowStart = now;
      this.requestCount = 0;
      return;
    }
    
    if (this.requestCount >= this.rateLimit) {
      // Wait until window expires
      const waitTime = this.interval - elapsed;
      await this.sleep(waitTime);
      this.windowStart = Date.now();
      this.requestCount = 0;
    }
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getQueueLength() {
    return this.queue.length;
  }
}

// Usage: 10 requests per second
const queue = new RequestQueue(10, 1000);

async function makeRequest(url) {
  const response = await queue.enqueue(url);
  return response.json();
}
```

### Token Bucket Algorithm

Implement smooth rate limiting with burst capacity:

```javascript
class TokenBucket {
  constructor(capacity, refillRate, refillInterval = 1000) {
    this.capacity = capacity; // max tokens
    this.tokens = capacity; // current tokens
    this.refillRate = refillRate; // tokens added per interval
    this.refillInterval = refillInterval; // milliseconds
    this.lastRefill = Date.now();
    this.queue = [];
  }
  
  startRefilling() {
    this.refillTimer = setInterval(() => {
      this.refill();
    }, this.refillInterval);
  }
  
  stopRefilling() {
    if (this.refillTimer) {
      clearInterval(this.refillTimer);
    }
  }
  
  refill() {
    const now = Date.now();
    const elapsed = now - this.lastRefill;
    const tokensToAdd = Math.floor((elapsed / this.refillInterval) * this.refillRate);
    
    this.tokens = Math.min(this.capacity, this.tokens + tokensToAdd);
    this.lastRefill = now;
    
    this.processQueue();
  }
  
  async acquire(tokensNeeded = 1) {
    return new Promise((resolve) => {
      if (this.tokens >= tokensNeeded) {
        this.tokens -= tokensNeeded;
        resolve();
      } else {
        this.queue.push({ tokensNeeded, resolve });
      }
    });
  }
  
  processQueue() {
    while (this.queue.length > 0 && this.tokens >= this.queue[0].tokensNeeded) {
      const request = this.queue.shift();
      this.tokens -= request.tokensNeeded;
      request.resolve();
    }
  }
  
  async fetch(url, options = {}, tokensNeeded = 1) {
    await this.acquire(tokensNeeded);
    return fetch(url, options);
  }
  
  getAvailableTokens() {
    return this.tokens;
  }
}

// Usage: 10 token capacity, refill 2 tokens per second
const bucket = new TokenBucket(10, 2, 1000);
bucket.startRefilling();

async function makeRequest(url) {
  const response = await bucket.fetch(url);
  return response.json();
}
```

### Sliding Window Rate Limiter

Track requests with precise time-based windows:

```javascript
class SlidingWindowLimiter {
  constructor(maxRequests, windowMs) {
    this.maxRequests = maxRequests;
    this.windowMs = windowMs;
    this.requests = [];
  }
  
  cleanOldRequests() {
    const cutoff = Date.now() - this.windowMs;
    this.requests = this.requests.filter(timestamp => timestamp > cutoff);
  }
  
  canMakeRequest() {
    this.cleanOldRequests();
    return this.requests.length < this.maxRequests;
  }
  
  recordRequest() {
    this.requests.push(Date.now());
  }
  
  async waitForSlot() {
    this.cleanOldRequests();
    
    if (this.requests.length < this.maxRequests) {
      return 0;
    }
    
    // Calculate when oldest request expires
    const oldestRequest = this.requests[0];
    const waitTime = (oldestRequest + this.windowMs) - Date.now();
    return Math.max(0, waitTime);
  }
  
  async fetch(url, options = {}) {
    const waitTime = await this.waitForSlot();
    
    if (waitTime > 0) {
      await this.sleep(waitTime);
    }
    
    this.recordRequest();
    return fetch(url, options);
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getRemainingRequests() {
    this.cleanOldRequests();
    return this.maxRequests - this.requests.length;
  }
  
  getResetTime() {
    this.cleanOldRequests();
    if (this.requests.length === 0) {
      return 0;
    }
    return this.requests[0] + this.windowMs;
  }
}

// Usage: 100 requests per minute
const limiter = new SlidingWindowLimiter(100, 60000);

async function makeRequest(url) {
  const response = await limiter.fetch(url);
  return response.json();
}
```

### Multi-Tier Rate Limiting

Handle different rate limits for different endpoints:

```javascript
class MultiTierRateLimiter {
  constructor() {
    this.limiters = new Map();
  }
  
  addLimiter(key, limiter) {
    this.limiters.set(key, limiter);
  }
  
  getLimiterForEndpoint(url) {
    // Check for specific endpoint limiters
    for (const [pattern, limiter] of this.limiters.entries()) {
      if (url.includes(pattern)) {
        return limiter;
      }
    }
    
    // Return default limiter
    return this.limiters.get('default');
  }
  
  async fetch(url, options = {}) {
    const limiter = this.getLimiterForEndpoint(url);
    
    if (!limiter) {
      return fetch(url, options);
    }
    
    return limiter.fetch(url, options);
  }
  
  getStatus(key) {
    const limiter = this.limiters.get(key);
    if (!limiter) return null;
    
    return {
      remaining: limiter.getRemainingRequests?.() || null,
      resetTime: limiter.getResetTime?.() || null
    };
  }
}

// Usage
const rateLimiter = new MultiTierRateLimiter();

// Strict limit for search endpoint
rateLimiter.addLimiter('/api/search', new SlidingWindowLimiter(10, 60000));

// Moderate limit for user data
rateLimiter.addLimiter('/api/users', new SlidingWindowLimiter(50, 60000));

// Generous default
rateLimiter.addLimiter('default', new SlidingWindowLimiter(100, 60000));

const response = await rateLimiter.fetch('/api/search?q=test');
```

### Adaptive Rate Limiting

Dynamically adjust request rate based on responses:

```javascript
class AdaptiveRateLimiter {
  constructor(initialRate = 10, minRate = 1, maxRate = 100) {
    this.currentRate = initialRate;
    this.minRate = minRate;
    this.maxRate = maxRate;
    this.interval = 1000;
    this.successCount = 0;
    this.failureCount = 0;
    this.queue = [];
    this.processing = false;
  }
  
  async enqueue(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    if (this.processing || this.queue.length === 0) {
      return;
    }
    
    this.processing = true;
    
    while (this.queue.length > 0) {
      const delay = this.interval / this.currentRate;
      await this.sleep(delay);
      
      const request = this.queue.shift();
      
      try {
        const response = await fetch(request.url, request.options);
        
        if (RateLimitDetector.isRateLimited(response)) {
          this.handleRateLimit(response);
          // Re-queue the request
          this.queue.unshift(request);
          continue;
        }
        
        this.handleSuccess();
        request.resolve(response);
      } catch (error) {
        this.handleFailure();
        request.reject(error);
      }
    }
    
    this.processing = false;
  }
  
  handleRateLimit(response) {
    this.failureCount++;
    
    // Decrease rate by 50%
    this.currentRate = Math.max(
      this.minRate,
      Math.floor(this.currentRate * 0.5)
    );
    
    console.log(`Rate limited. Reduced rate to ${this.currentRate} req/s`);
    
    // Get delay from headers
    const delay = RateLimitDetector.getRetryDelay(response);
    return this.sleep(delay);
  }
  
  handleSuccess() {
    this.successCount++;
    
    // After 10 successful requests, try increasing rate
    if (this.successCount % 10 === 0) {
      this.currentRate = Math.min(
        this.maxRate,
        Math.floor(this.currentRate * 1.1)
      );
      console.log(`Increased rate to ${this.currentRate} req/s`);
    }
  }
  
  handleFailure() {
    this.failureCount++;
    
    // After 3 failures, decrease rate
    if (this.failureCount % 3 === 0) {
      this.currentRate = Math.max(
        this.minRate,
        Math.floor(this.currentRate * 0.9)
      );
    }
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getCurrentRate() {
    return this.currentRate;
  }
}

// Usage
const limiter = new AdaptiveRateLimiter(10, 1, 50);
const response = await limiter.enqueue('/api/data');
```

### Circuit Breaker Pattern

Prevent cascading failures when rate limits are consistently hit:

```javascript
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failureCount = 0;
    this.threshold = threshold;
    this.timeout = timeout;
    this.nextAttempt = Date.now();
  }
  
  async fetch(url, options = {}) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }
    
    try {
      const response = await fetch(url, options);
      
      if (RateLimitDetector.isRateLimited(response)) {
        this.recordFailure();
        throw new RateLimitError('Rate limit exceeded', response);
      }
      
      this.recordSuccess();
      return response;
    } catch (error) {
      this.recordFailure();
      throw error;
    }
  }
  
  recordSuccess() {
    this.failureCount = 0;
    
    if (this.state === 'HALF_OPEN') {
      this.state = 'CLOSED';
      console.log('Circuit breaker CLOSED');
    }
  }
  
  recordFailure() {
    this.failureCount++;
    
    if (this.failureCount >= this.threshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.timeout;
      console.log(`Circuit breaker OPEN until ${new Date(this.nextAttempt)}`);
    }
  }
  
  getState() {
    return {
      state: this.state,
      failureCount: this.failureCount,
      nextAttempt: this.state === 'OPEN' ? this.nextAttempt : null
    };
  }
  
  reset() {
    this.state = 'CLOSED';
    this.failureCount = 0;
  }
}

// Usage with rate limiter
class RateLimitedFetchWithCircuitBreaker {
  constructor() {
    this.circuitBreaker = new CircuitBreaker(5, 60000);
    this.rateLimiter = new SlidingWindowLimiter(100, 60000);
  }
  
  async fetch(url, options = {}) {
    try {
      return await this.circuitBreaker.fetch(url, async (url, opts) => {
        return this.rateLimiter.fetch(url, opts);
      });
    } catch (error) {
      if (error instanceof RateLimitError) {
        console.error('Rate limit hit, circuit may open');
      }
      throw error;
    }
  }
}
```

### Rate Limit State Tracker

Monitor and expose rate limit state to application:

```javascript
class RateLimitTracker {
  constructor() {
    this.limits = new Map();
    this.listeners = [];
  }
  
  updateFromResponse(endpoint, response) {
    const limit = parseInt(response.headers.get('X-RateLimit-Limit')) || null;
    const remaining = parseInt(response.headers.get('X-RateLimit-Remaining')) || null;
    const reset = parseInt(response.headers.get('X-RateLimit-Reset')) || null;
    
    const state = {
      endpoint,
      limit,
      remaining,
      reset: reset ? reset * 1000 : null,
      updatedAt: Date.now()
    };
    
    this.limits.set(endpoint, state);
    this.notifyListeners(endpoint, state);
    
    return state;
  }
  
  getState(endpoint) {
    return this.limits.get(endpoint) || null;
  }
  
  getAllStates() {
    return Array.from(this.limits.entries()).map(([endpoint, state]) => ({
      endpoint,
      ...state
    }));
  }
  
  subscribe(callback) {
    this.listeners.push(callback);
    return () => {
      this.listeners = this.listeners.filter(cb => cb !== callback);
    };
  }
  
  notifyListeners(endpoint, state) {
    this.listeners.forEach(callback => {
      try {
        callback(endpoint, state);
      } catch (error) {
        console.error('Listener error:', error);
      }
    });
  }
  
  isNearLimit(endpoint, threshold = 0.1) {
    const state = this.limits.get(endpoint);
    if (!state || !state.limit || !state.remaining) {
      return false;
    }
    
    const percentRemaining = state.remaining / state.limit;
    return percentRemaining <= threshold;
  }
  
  getTimeUntilReset(endpoint) {
    const state = this.limits.get(endpoint);
    if (!state || !state.reset) {
      return null;
    }
    
    return Math.max(0, state.reset - Date.now());
  }
}

// Usage
const tracker = new RateLimitTracker();

// Subscribe to changes
tracker.subscribe((endpoint, state) => {
  console.log(`Rate limit updated for ${endpoint}:`, state);
  
  if (state.remaining !== null && state.remaining < 10) {
    console.warn(`Low rate limit remaining for ${endpoint}`);
  }
});

// Update after each request
async function trackedFetch(url, options = {}) {
  const endpoint = new URL(url).pathname;
  const response = await fetch(url, options);
  
  tracker.updateFromResponse(endpoint, response);
  
  return response;
}
```

### Batch Request Handler

Combine multiple requests to reduce rate limit consumption:

```javascript
class BatchRequestHandler {
  constructor(batchSize = 10, batchDelay = 100) {
    this.batchSize = batchSize;
    this.batchDelay = batchDelay;
    this.pendingRequests = [];
    this.batchTimer = null;
  }
  
  async request(url, options = {}) {
    return new Promise((resolve, reject) => {
      this.pendingRequests.push({ url, options, resolve, reject });
      
      if (this.pendingRequests.length >= this.batchSize) {
        this.flush();
      } else if (!this.batchTimer) {
        this.batchTimer = setTimeout(() => this.flush(), this.batchDelay);
      }
    });
  }
  
  async flush() {
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
      this.batchTimer = null;
    }
    
    if (this.pendingRequests.length === 0) {
      return;
    }
    
    const batch = this.pendingRequests.splice(0);
    
    try {
      // Combine requests into single batch request
      const batchPayload = batch.map(req => ({
        url: req.url,
        method: req.options.method || 'GET',
        body: req.options.body
      }));
      
      const response = await fetch('/api/batch', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ requests: batchPayload })
      });
      
      const results = await response.json();
      
      // Resolve individual promises
      batch.forEach((req, index) => {
        req.resolve(results[index]);
      });
    } catch (error) {
      // Reject all promises in batch
      batch.forEach(req => req.reject(error));
    }
  }
  
  getQueueSize() {
    return this.pendingRequests.length;
  }
}

// Usage
const batcher = new BatchRequestHandler(10, 100);

async function fetchWithBatching(url) {
  return batcher.request(url);
}
```

### Priority Queue for Requests

Handle requests with different priorities:

```javascript
class PriorityRequestQueue {
  constructor(rateLimit, interval) {
    this.queues = {
      high: [],
      medium: [],
      low: []
    };
    this.processing = false;
    this.rateLimit = rateLimit;
    this.interval = interval;
    this.requestCount = 0;
    this.windowStart = Date.now();
  }
  
  async enqueue(url, options = {}, priority = 'medium') {
    return new Promise((resolve, reject) => {
      const queue = this.queues[priority] || this.queues.medium;
      queue.push({ url, options, resolve, reject, priority });
      this.process();
    });
  }
  
  async process() {
    if (this.processing) {
      return;
    }
    
    this.processing = true;
    
    while (this.hasRequests()) {
      await this.waitIfNeeded();
      
      const request = this.getNextRequest();
      if (!request) break;
      
      try {
        const response = await fetch(request.url, request.options);
        request.resolve(response);
      } catch (error) {
        request.reject(error);
      }
      
      this.requestCount++;
    }
    
    this.processing = false;
  }
  
  hasRequests() {
    return this.queues.high.length > 0 ||
           this.queues.medium.length > 0 ||
           this.queues.low.length > 0;
  }
  
  getNextRequest() {
    if (this.queues.high.length > 0) {
      return this.queues.high.shift();
    }
    if (this.queues.medium.length > 0) {
      return this.queues.medium.shift();
    }
    if (this.queues.low.length > 0) {
      return this.queues.low.shift();
    }
    return null;
  }
  
  async waitIfNeeded() {
    const now = Date.now();
    const elapsed = now - this.windowStart;
    
    if (elapsed >= this.interval) {
      this.windowStart = now;
      this.requestCount = 0;
      return;
    }
    
    if (this.requestCount >= this.rateLimit) {
      const waitTime = this.interval - elapsed;
      await this.sleep(waitTime);
      this.windowStart = Date.now();
      this.requestCount = 0;
    }
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getQueueLengths() {
    return {
      high: this.queues.high.length,
      medium: this.queues.medium.length,
      low: this.queues.low.length
    };
  }
}

// Usage
const queue = new PriorityRequestQueue(10, 1000);

// High priority request
await queue.enqueue('/api/critical', {}, 'high');

// Medium priority (default)
await queue.enqueue('/api/normal', {});

// Low priority
await queue.enqueue('/api/background', {}, 'low');
```

### Persistent Rate Limit State

Store rate limit state across page reloads:

```javascript
class PersistentRateLimiter {
  constructor(storageKey, maxRequests, windowMs) {
    this.storageKey = storageKey;
    this.maxRequests = maxRequests;
    this.windowMs = windowMs;
    this.loadState();
  }
  
  loadState() {
    try {
      const stored = localStorage.getItem(this.storageKey);
      if (stored) {
        this.requests = JSON.parse(stored);
        this.cleanOldRequests();
      } else {
        this.requests = [];
      }
    } catch (error) {
      console.error('Failed to load rate limit state:', error);
      this.requests = [];
    }
  }
  
  saveState() {
    try {
      localStorage.setItem(this.storageKey, JSON.stringify(this.requests));
    } catch (error) {
      console.error('Failed to save rate limit state:', error);
    }
  }
  
  cleanOldRequests() {
    const cutoff = Date.now() - this.windowMs;
    const initialLength = this.requests.length;
    this.requests = this.requests.filter(timestamp => timestamp > cutoff);
    
    if (this.requests.length !== initialLength) {
      this.saveState();
    }
  }
  
  canMakeRequest() {
    this.cleanOldRequests();
    return this.requests.length < this.maxRequests;
  }
  
  async waitForSlot() {
    this.cleanOldRequests();
    
    if (this.requests.length < this.maxRequests) {
      return 0;
    }
    
    const oldestRequest = this.requests[0];
    const waitTime = (oldestRequest + this.windowMs) - Date.now();
    return Math.max(0, waitTime);
  }
  
  async fetch(url, options = {}) {
    const waitTime = await this.waitForSlot();
    
    if (waitTime > 0) {
      await this.sleep(waitTime);
    }
    
    this.requests.push(Date.now());
    this.saveState();
    
    return fetch(url, options);
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  getRemainingRequests() {
    this.cleanOldRequests();
    return this.maxRequests - this.requests.length;
  }
  
  reset() {
    this.requests = [];
    this.saveState();
  }
}

// Usage
const limiter = new PersistentRateLimiter('api_rate_limit', 100, 60000);
```

### Complete Rate Limiter Implementation

```javascript
class ComprehensiveRateLimiter {
  constructor(config = {}) {
    // Configuration
    this.maxRequests = config.maxRequests || 100;
    this.windowMs = config.windowMs || 60000;
    this.maxRetries = config.maxRetries || 3;
    this.enableAdaptive = config.enableAdaptive || false;
    this.enableCircuitBreaker = config.enableCircuitBreaker || false;
    
    // State
    this.requests = [];
    this.queue = [];
    this.processing = false;
    this.currentRate = this.maxRequests;
    
    // Components
    this.tracker = new RateLimitTracker();
    
    if (this.enableCircuitBreaker) {
      this.circuitBreaker = new CircuitBreaker(5, 60000);
    }
  }
  
  async fetch(url, options = {}, priority = 'medium') {
    return new Promise((resolve, reject) => {
      this.queue.push({
        url,
        options,
        priority,
        resolve,
        reject,
        attempts: 0
      });
      
      this.process();
    });
  }
  
  async process() {
    if (this.processing || this.queue.length === 0) {
      return
```

---

## Error Response Formats with Fetch API

### Standard HTTP Error Structure

Common error response format used across REST APIs:

```javascript
// Typical error response structure
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid request parameters",
    "status": 400,
    "timestamp": "2024-12-18T10:30:00Z",
    "path": "/api/users",
    "details": [
      {
        "field": "email",
        "message": "Invalid email format"
      },
      {
        "field": "age",
        "message": "Must be at least 18"
      }
    ]
  }
}

// Parsing this format
async function handleStandardError(response) {
  const error = await response.json();
  
  return {
    code: error.error.code,
    message: error.error.message,
    status: error.error.status,
    fields: error.error.details?.map(d => ({
      field: d.field,
      message: d.message
    }))
  };
}
```

### RFC 7807 Problem Details

Standardized error format defined in RFC 7807:

```javascript
// RFC 7807 structure
{
  "type": "https://example.com/problems/validation-error",
  "title": "Validation Error",
  "status": 400,
  "detail": "The request contains invalid parameters",
  "instance": "/api/users/create",
  "invalid-params": [
    {
      "name": "email",
      "reason": "must be a valid email address"
    }
  ]
}

// Parsing RFC 7807 format
async function handleRFC7807Error(response) {
  const problem = await response.json();
  
  return {
    type: problem.type,
    title: problem.title,
    status: problem.status,
    detail: problem.detail,
    instance: problem.instance,
    extensions: Object.fromEntries(
      Object.entries(problem).filter(([key]) => 
        !['type', 'title', 'status', 'detail', 'instance'].includes(key)
      )
    )
  };
}

// Fetch with RFC 7807 handling
async function fetchWithRFC7807(url, options = {}) {
  const response = await fetch(url, {
    ...options,
    headers: {
      'Accept': 'application/problem+json',
      ...options.headers
    }
  });
  
  if (!response.ok) {
    const contentType = response.headers.get('content-type');
    if (contentType?.includes('application/problem+json')) {
      const problem = await handleRFC7807Error(response);
      throw new RFC7807Error(problem);
    }
  }
  
  return response;
}
```

### JSON:API Error Format

Errors following the JSON:API specification:

```javascript
// JSON:API error structure
{
  "errors": [
    {
      "id": "error-123",
      "status": "422",
      "code": "UNPROCESSABLE_ENTITY",
      "title": "Invalid Attribute",
      "detail": "Email must be a valid email address",
      "source": {
        "pointer": "/data/attributes/email",
        "parameter": "email"
      },
      "meta": {
        "timestamp": "2024-12-18T10:30:00Z"
      }
    },
    {
      "id": "error-124",
      "status": "422",
      "code": "UNPROCESSABLE_ENTITY",
      "title": "Invalid Attribute",
      "detail": "Age must be at least 18",
      "source": {
        "pointer": "/data/attributes/age"
      }
    }
  ]
}

// Parsing JSON:API errors
async function handleJSONAPIError(response) {
  const data = await response.json();
  
  return data.errors.map(error => ({
    id: error.id,
    status: parseInt(error.status),
    code: error.code,
    title: error.title,
    detail: error.detail,
    source: error.source,
    meta: error.meta
  }));
}

// Custom error class for JSON:API
class JSONAPIError extends Error {
  constructor(errors) {
    const messages = errors.map(e => e.detail).join('; ');
    super(messages);
    this.name = 'JSONAPIError';
    this.errors = errors;
  }
  
  getFieldErrors() {
    return this.errors
      .filter(e => e.source?.pointer)
      .map(e => ({
        field: e.source.pointer.split('/').pop(),
        message: e.detail
      }));
  }
}
```

### GraphQL Error Format

Error structure used in GraphQL responses:

```javascript
// GraphQL error response
{
  "errors": [
    {
      "message": "Field 'emaill' doesn't exist on type 'User'",
      "locations": [
        {
          "line": 2,
          "column": 3
        }
      ],
      "path": ["user", "emaill"],
      "extensions": {
        "code": "GRAPHQL_VALIDATION_FAILED",
        "typeName": "User",
        "fieldName": "emaill"
      }
    }
  ],
  "data": null
}

// Parsing GraphQL errors
async function handleGraphQLError(response) {
  const result = await response.json();
  
  if (result.errors) {
    return result.errors.map(error => ({
      message: error.message,
      locations: error.locations,
      path: error.path,
      code: error.extensions?.code,
      extensions: error.extensions
    }));
  }
  
  return null;
}

// GraphQL fetch wrapper
async function fetchGraphQL(query, variables = {}) {
  const response = await fetch('/graphql', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ query, variables })
  });
  
  const result = await response.json();
  
  if (result.errors) {
    throw new GraphQLError(result.errors, result.data);
  }
  
  return result.data;
}

class GraphQLError extends Error {
  constructor(errors, partialData = null) {
    const messages = errors.map(e => e.message).join('; ');
    super(messages);
    this.name = 'GraphQLError';
    this.errors = errors;
    this.partialData = partialData;
  }
}
```

### Simple Error Formats

Minimalist error structures used by some APIs:

```javascript
// Simple message-only format
{
  "error": "Invalid email address"
}

// Simple code and message
{
  "code": 400,
  "message": "Bad Request"
}

// Status and error array
{
  "status": "error",
  "errors": ["Email is required", "Password too short"]
}

// Parsing various simple formats
async function handleSimpleError(response) {
  const data = await response.json();
  
  // Try different structures
  if (data.error && typeof data.error === 'string') {
    return { message: data.error };
  }
  
  if (data.message) {
    return { 
      code: data.code || response.status,
      message: data.message 
    };
  }
  
  if (data.errors && Array.isArray(data.errors)) {
    return {
      messages: data.errors
    };
  }
  
  // Fallback
  return { message: 'An error occurred', raw: data };
}
```

### Nested Error Details

Deep error structures with nested validation errors:

```javascript
// Nested validation errors
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "validationErrors": {
      "user": {
        "email": ["Invalid format", "Already exists"],
        "profile": {
          "age": ["Must be at least 18"],
          "address": {
            "zipCode": ["Invalid ZIP code format"]
          }
        }
      }
    }
  }
}

// Flatten nested errors
function flattenErrors(obj, prefix = '') {
  const errors = [];
  
  for (const [key, value] of Object.entries(obj)) {
    const path = prefix ? `${prefix}.${key}` : key;
    
    if (Array.isArray(value)) {
      value.forEach(msg => {
        errors.push({ field: path, message: msg });
      });
    } else if (typeof value === 'object' && value !== null) {
      errors.push(...flattenErrors(value, path));
    }
  }
  
  return errors;
}

// Usage
async function handleNestedError(response) {
  const data = await response.json();
  const flattened = flattenErrors(data.error.validationErrors);
  
  return {
    code: data.error.code,
    message: data.error.message,
    fields: flattened
  };
}
```

### Multi-Language Error Messages

Errors with internationalization support:

```javascript
// Multi-language error format
{
  "error": {
    "code": "INVALID_EMAIL",
    "message": {
      "en": "Invalid email address",
      "es": "Dirección de correo electrónico no válida",
      "fr": "Adresse e-mail invalide"
    },
    "field": "email"
  }
}

// Request errors with Accept-Language
async function fetchWithLanguage(url, locale = 'en', options = {}) {
  const response = await fetch(url, {
    ...options,
    headers: {
      'Accept-Language': locale,
      ...options.headers
    }
  });
  
  if (!response.ok) {
    const error = await response.json();
    return {
      code: error.error.code,
      message: error.error.message[locale] || error.error.message.en,
      field: error.error.field
    };
  }
  
  return response;
}

// Alternative: server returns localized message directly
{
  "error": {
    "code": "INVALID_EMAIL",
    "message": "Dirección de correo electrónico no válida",
    "locale": "es"
  }
}
```

### Rate Limit Error Format

Specialized format for rate limiting errors:

```javascript
// Rate limit error with retry information
{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Too many requests",
    "status": 429,
    "retryAfter": 60,
    "limit": 100,
    "remaining": 0,
    "resetAt": "2024-12-18T11:00:00Z"
  }
}

// Headers-based rate limit info (alternative)
// X-RateLimit-Limit: 100
// X-RateLimit-Remaining: 0
// X-RateLimit-Reset: 1702900800
// Retry-After: 60

// Handling rate limit errors
async function handleRateLimitError(response) {
  const retryAfter = response.headers.get('Retry-After');
  const resetTime = response.headers.get('X-RateLimit-Reset');
  
  if (retryAfter) {
    return {
      code: 'RATE_LIMIT_EXCEEDED',
      message: 'Too many requests',
      retryAfter: parseInt(retryAfter),
      resetAt: resetTime ? new Date(parseInt(resetTime) * 1000) : null
    };
  }
  
  // Fallback to body
  const data = await response.json();
  return {
    code: data.error.code,
    message: data.error.message,
    retryAfter: data.error.retryAfter,
    resetAt: data.error.resetAt ? new Date(data.error.resetAt) : null
  };
}

// Automatic retry with backoff
async function fetchWithRateLimitRetry(url, options = {}, maxRetries = 3) {
  let attempts = 0;
  
  while (attempts < maxRetries) {
    const response = await fetch(url, options);
    
    if (response.status === 429) {
      const error = await handleRateLimitError(response);
      const delay = (error.retryAfter || Math.pow(2, attempts)) * 1000;
      
      attempts++;
      if (attempts < maxRetries) {
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
    }
    
    return response;
  }
  
  throw new Error('Rate limit exceeded after max retries');
}
```

### Authentication Error Formats

Errors specific to authentication and authorization:

```javascript
// Authentication error with challenge
{
  "error": {
    "code": "UNAUTHORIZED",
    "message": "Authentication required",
    "status": 401,
    "challenge": "Bearer realm=\"API\", error=\"invalid_token\"",
    "loginUrl": "https://example.com/login",
    "expiresAt": "2024-12-18T10:00:00Z"
  }
}

// OAuth2 error format
{
  "error": "invalid_token",
  "error_description": "The access token expired",
  "error_uri": "https://docs.example.com/oauth/errors/invalid_token"
}

// Authorization error with required permissions
{
  "error": {
    "code": "FORBIDDEN",
    "message": "Insufficient permissions",
    "status": 403,
    "requiredPermissions": ["users:write", "users:delete"],
    "currentPermissions": ["users:read"]
  }
}

// Handling auth errors
async function handleAuthError(response) {
  const data = await response.json();
  
  if (response.status === 401) {
    return {
      type: 'authentication',
      code: data.error.code || data.error,
      message: data.error.message || data.error_description,
      challenge: data.error.challenge,
      loginUrl: data.error.loginUrl
    };
  }
  
  if (response.status === 403) {
    return {
      type: 'authorization',
      code: data.error.code,
      message: data.error.message,
      requiredPermissions: data.error.requiredPermissions,
      currentPermissions: data.error.currentPermissions
    };
  }
}
```

### Validation Error Formats

Detailed validation error structures:

```javascript
// Field-level validation errors
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Validation failed",
    "status": 422,
    "fields": {
      "email": {
        "value": "invalid-email",
        "errors": [
          {
            "rule": "format",
            "message": "Must be a valid email address"
          }
        ]
      },
      "password": {
        "value": "123",
        "errors": [
          {
            "rule": "minLength",
            "message": "Must be at least 8 characters",
            "params": { "min": 8, "actual": 3 }
          },
          {
            "rule": "complexity",
            "message": "Must contain uppercase, lowercase, and numbers"
          }
        ]
      }
    }
  }
}

// Parse validation errors into usable format
function parseValidationErrors(errorData) {
  const fieldErrors = {};
  
  for (const [field, data] of Object.entries(errorData.error.fields)) {
    fieldErrors[field] = {
      value: data.value,
      messages: data.errors.map(e => e.message),
      rules: data.errors.map(e => ({
        name: e.rule,
        params: e.params
      }))
    };
  }
  
  return fieldErrors;
}

// Alternative: flat array format
{
  "errors": [
    {
      "field": "email",
      "code": "INVALID_FORMAT",
      "message": "Invalid email format",
      "value": "invalid-email"
    },
    {
      "field": "password",
      "code": "TOO_SHORT",
      "message": "Password must be at least 8 characters",
      "constraint": { "minLength": 8 }
    }
  ]
}
```

### Business Logic Error Formats

Errors representing business rule violations:

```javascript
// Business rule violation
{
  "error": {
    "code": "INSUFFICIENT_FUNDS",
    "message": "Cannot complete transaction",
    "status": 422,
    "context": {
      "accountBalance": 100.00,
      "requestedAmount": 150.00,
      "currency": "USD"
    },
    "suggestion": "Please reduce the amount or add funds to your account"
  }
}

// Conflict error
{
  "error": {
    "code": "RESOURCE_CONFLICT",
    "message": "Cannot delete user with active subscriptions",
    "status": 409,
    "conflicts": [
      {
        "resource": "subscription",
        "id": "sub_123",
        "reason": "Active subscription exists"
      }
    ],
    "resolution": {
      "action": "cancel_subscriptions",
      "url": "/api/users/123/subscriptions"
    }
  }
}

// Handling business errors
class BusinessError extends Error {
  constructor(errorData) {
    super(errorData.message);
    this.name = 'BusinessError';
    this.code = errorData.code;
    this.status = errorData.status;
    this.context = errorData.context;
    this.suggestion = errorData.suggestion;
    this.conflicts = errorData.conflicts;
    this.resolution = errorData.resolution;
  }
  
  isRetryable() {
    const retryableCodes = ['TEMPORARY_ERROR', 'SERVICE_UNAVAILABLE'];
    return retryableCodes.includes(this.code);
  }
  
  hasResolution() {
    return !!this.resolution;
  }
}
```

### Async Operation Error Formats

Errors from long-running or asynchronous operations:

```javascript
// Async operation error
{
  "error": {
    "code": "OPERATION_FAILED",
    "message": "Background job failed",
    "status": 500,
    "operationId": "job_123",
    "startedAt": "2024-12-18T10:00:00Z",
    "failedAt": "2024-12-18T10:05:00Z",
    "phase": "processing",
    "cause": {
      "code": "EXTERNAL_SERVICE_ERROR",
      "message": "Payment processor unavailable"
    },
    "statusUrl": "/api/operations/job_123"
  }
}

// Polling for operation status
async function pollOperationStatus(operationId, interval = 2000) {
  while (true) {
    const response = await fetch(`/api/operations/${operationId}`);
    const data = await response.json();
    
    if (data.status === 'completed') {
      return data.result;
    }
    
    if (data.status === 'failed') {
      throw new OperationError(data.error);
    }
    
    await new Promise(resolve => setTimeout(resolve, interval));
  }
}

class OperationError extends Error {
  constructor(errorData) {
    super(errorData.message);
    this.name = 'OperationError';
    this.operationId = errorData.operationId;
    this.phase = errorData.phase;
    this.cause = errorData.cause;
  }
}
```

### Batch Operation Error Formats

Errors from operations affecting multiple resources:

```javascript
// Batch operation with partial failures
{
  "status": "partial_success",
  "summary": {
    "total": 10,
    "successful": 7,
    "failed": 3
  },
  "results": [
    {
      "id": "item_1",
      "status": "success",
      "data": { "id": "123" }
    },
    {
      "id": "item_2",
      "status": "error",
      "error": {
        "code": "DUPLICATE",
        "message": "Item already exists"
      }
    },
    {
      "id": "item_3",
      "status": "error",
      "error": {
        "code": "VALIDATION_ERROR",
        "message": "Invalid email format",
        "field": "email"
      }
    }
  ]
}

// Parsing batch results
function parseBatchResults(batchResponse) {
  const successful = [];
  const failed = [];
  
  batchResponse.results.forEach(result => {
    if (result.status === 'success') {
      successful.push({
        id: result.id,
        data: result.data
      });
    } else {
      failed.push({
        id: result.id,
        error: result.error
      });
    }
  });
  
  return {
    summary: batchResponse.summary,
    successful,
    failed,
    hasErrors: failed.length > 0
  };
}

// Batch operation error class
class BatchError extends Error {
  constructor(batchResponse) {
    const failedCount = batchResponse.summary.failed;
    super(`Batch operation failed: ${failedCount} items`);
    this.name = 'BatchError';
    this.summary = batchResponse.summary;
    this.results = batchResponse.results;
    this.failed = batchResponse.results.filter(r => r.status === 'error');
  }
  
  getFailedIds() {
    return this.failed.map(r => r.id);
  }
  
  getErrorsByCode(code) {
    return this.failed.filter(r => r.error.code === code);
  }
}
```

### Error Response with Trace Information

Errors including debugging and tracing data:

```javascript
// Error with trace information
{
  "error": {
    "code": "INTERNAL_SERVER_ERROR",
    "message": "An unexpected error occurred",
    "status": 500,
    "requestId": "req_abc123",
    "timestamp": "2024-12-18T10:30:00Z",
    "trace": {
      "traceId": "trace_xyz789",
      "spanId": "span_456",
      "parentSpanId": "span_123"
    },
    "debug": {
      "service": "user-service",
      "version": "1.2.3",
      "instance": "instance-5"
    }
  }
}

// Production vs development error details
// Production response (minimal)
{
  "error": {
    "code": "INTERNAL_SERVER_ERROR",
    "message": "An unexpected error occurred",
    "requestId": "req_abc123"
  }
}

// Development response (detailed)
{
  "error": {
    "code": "INTERNAL_SERVER_ERROR",
    "message": "Database connection timeout",
    "requestId": "req_abc123",
    "stack": "Error: Connection timeout\n    at Database.connect...",
    "query": "SELECT * FROM users WHERE id = $1",
    "params": [123]
  }
}

// Handling errors with trace info
async function fetchWithTracing(url, options = {}) {
  const requestId = generateRequestId();
  
  const response = await fetch(url, {
    ...options,
    headers: {
      'X-Request-ID': requestId,
      ...options.headers
    }
  });
  
  if (!response.ok) {
    const error = await response.json();
    throw new TracedError({
      ...error.error,
      clientRequestId: requestId
    });
  }
  
  return response;
}

class TracedError extends Error {
  constructor(errorData) {
    super(errorData.message);
    this.name = 'TracedError';
    this.code = errorData.code;
    this.requestId = errorData.requestId;
    this.clientRequestId = errorData.clientRequestId;
    this.trace = errorData.trace;
  }
  
  getTraceUrl() {
    if (this.trace?.traceId) {
      return `https://trace.example.com/${this.trace.traceId}`;
    }
    return null;
  }
}
```

### Unified Error Handler

Comprehensive error handler supporting multiple formats:

```javascript
class UnifiedErrorHandler {
  constructor(options = {}) {
    this.defaultFormat = options.defaultFormat || 'standard';
    this.formats = {
      standard: this.parseStandardError,
      rfc7807: this.parseRFC7807Error,
      jsonapi: this.parseJSONAPIError,
      graphql: this.parseGraphQLError,
      simple: this.parseSimpleError
    };
  }
  
  async handle(response) {
    const contentType = response.headers.get('content-type');
    
    // Detect format from content-type
    let format = this.defaultFormat;
    if (contentType?.includes('application/problem+json')) {
      format = 'rfc7807';
    } else if (contentType?.includes('application/vnd.api+json')) {
      format = 'jsonapi';
    }
    
    try {
      const data = await response.json();
      const parser = this.formats[format] || this.parseStandardError;
      return parser.call(this, response, data);
    } catch (e) {
      // Fallback for non-JSON responses
      const text = await response.text();
      return this.parseTextError(response, text);
    }
  }
  
  parseStandardError(response, data) {
    return {
      format: 'standard',
      code: data.error?.code || 'UNKNOWN_ERROR',
      message: data.error?.message || data.message || 'An error occurred',
      status: response.status,
      details: data.error?.details || [],
      raw: data
    };
  }
  
  parseRFC7807Error(response, data) {
    return {
      format: 'rfc7807',
      code: data.type?.split('/').pop() || 'UNKNOWN_ERROR',
      message: data.detail || data.title,
      status: data.status,
      title: data.title,
      instance: data.instance,
      extensions: this.extractExtensions(data),
      raw: data
    };
  }
  
  parseJSONAPIError(response, data) {
    const errors = data.errors || [];
    return {
      format: 'jsonapi',
      code: errors[0]?.code || 'UNKNOWN_ERROR',
      message: errors.map(e => e.detail).join('; '),
      status: response.status,
      errors: errors,
      raw: data
    };
  }
  
  parseGraphQLError(response, data) {
    const errors = data.errors || [];
    return {
      format: 'graphql',
      code: errors[0]?.extensions?.code || 'UNKNOWN_ERROR',
      message: errors.map(e => e.message).join('; '),
      status: response.status,
      errors: errors,
      partialData: data.data,
      raw: data
    };
  }
  
  parseSimpleError(response, data) {
    return {
      format: 'simple',
      code: data.code || 'UNKNOWN_ERROR',
      message: data.error || data.message || 'An error occurred',
      status: response.status,
      raw: data
    };
  }
  
  parseTextError(response, text) {
    return {
      format: 'text',
      code: 'UNKNOWN_ERROR',
      message: text || response.statusText,
      status: response.status,
      raw: text
    };
  }
  
  extractExtensions(data) {
    const reserved = ['type', 'title', 'status', 'detail', 'instance'];
    return Object.fromEntries(
      Object.entries(data).filter(([key]) => !reserved.includes(key))
    );
  }
}

// Usage
const errorHandler = new UnifiedErrorHandler();

async function robustFetch(url, options = {}) {
  const response = await fetch(url, options);
  
  if (!response.ok) {
    const error = await errorHandler.handle(response);
    throw new APIError(error);
  }
  
  return response;
}

class APIError extends Error {
  constructor(errorData) {
    super(errorData.message);
    this.name = 'APIError';
    this.code = errorData.code;
    this.status = errorData.status;
    this.format = errorData.format;
    this.details = errorData.details;
    this.errors = errorData.errors;
    this.raw = errorData.raw;
  }
}
```

---

## Fetch API Documentation Consumption

### Reading API Documentation Structure

API documentation typically follows standard organizational patterns. Common sections include:

- Base URL and versioning information
- Authentication requirements
- Endpoint descriptions with HTTP methods
- Request parameters (query, path, body)
- Request headers
- Response formats and status codes
- Error codes and handling
- Rate limiting policies
- Examples and code samples

### Extracting Base URL Information

Identify the base URL from documentation:

```javascript
// Documentation states: "Base URL: https://api.example.com/v2"
const BASE_URL = 'https://api.example.com/v2';

// Make requests relative to base
const response = await fetch(`${BASE_URL}/users`);
```

Some APIs use different base URLs for different environments:

```javascript
const BASE_URLS = {
  production: 'https://api.example.com/v2',
  staging: 'https://staging-api.example.com/v2',
  development: 'https://dev-api.example.com/v2'
};

const BASE_URL = BASE_URLS[process.env.NODE_ENV] || BASE_URLS.production;
```

### Understanding Endpoint Specifications

Documentation lists endpoints with HTTP methods:

```
GET    /users          - List all users
GET    /users/:id      - Get specific user
POST   /users          - Create new user
PUT    /users/:id      - Update user
PATCH  /users/:id      - Partial update user
DELETE /users/:id      - Delete user
```

Translating to fetch calls:

```javascript
// GET /users
const response = await fetch(`${BASE_URL}/users`);

// GET /users/:id
const userId = 123;
const response = await fetch(`${BASE_URL}/users/${userId}`);

// POST /users
const response = await fetch(`${BASE_URL}/users`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'John', email: 'john@example.com' })
});

// PUT /users/:id
const response = await fetch(`${BASE_URL}/users/${userId}`, {
  method: 'PUT',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'John Updated', email: 'john@example.com' })
});

// PATCH /users/:id
const response = await fetch(`${BASE_URL}/users/${userId}`, {
  method: 'PATCH',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'John Updated' })
});

// DELETE /users/:id
const response = await fetch(`${BASE_URL}/users/${userId}`, {
  method: 'DELETE'
});
```

### Interpreting Path Parameters

Path parameters are placeholders in the URL:

```
Documentation: GET /users/:userId/posts/:postId
```

Implementation:

```javascript
function getUserPost(userId, postId) {
  return fetch(`${BASE_URL}/users/${userId}/posts/${postId}`);
}

const response = await getUserPost(123, 456);
```

### Parsing Query Parameter Documentation

Documentation formats for query parameters:

```
GET /users
Query Parameters:
  - page (integer, optional): Page number, default 1
  - limit (integer, optional): Items per page, default 20, max 100
  - sort (string, optional): Sort field, format: field or -field
  - filter (string, optional): Filter expression
  - fields (string, optional): Comma-separated field names
```

Implementation:

```javascript
function buildQueryString(params) {
  const searchParams = new URLSearchParams();
  
  for (const [key, value] of Object.entries(params)) {
    if (value !== undefined && value !== null) {
      searchParams.append(key, value);
    }
  }
  
  return searchParams.toString();
}

const params = {
  page: 2,
  limit: 50,
  sort: '-createdAt',
  filter: 'status:active',
  fields: 'id,name,email'
};

const queryString = buildQueryString(params);
const response = await fetch(`${BASE_URL}/users?${queryString}`);
```

### Understanding Request Body Schemas

Documentation provides request body structure:

```
POST /users
Request Body:
{
  "name": "string (required, max 100 chars)",
  "email": "string (required, valid email format)",
  "age": "integer (optional, min 18, max 120)",
  "roles": "array of strings (optional)",
  "address": {
    "street": "string (optional)",
    "city": "string (optional)",
    "country": "string (optional, ISO 3166-1 alpha-2)"
  }
}
```

Implementation with validation:

```javascript
function createUser(userData) {
  // Validate based on documentation
  if (!userData.name || userData.name.length > 100) {
    throw new Error('Invalid name');
  }
  
  if (!userData.email || !isValidEmail(userData.email)) {
    throw new Error('Invalid email');
  }
  
  if (userData.age !== undefined && (userData.age < 18 || userData.age > 120)) {
    throw new Error('Invalid age');
  }
  
  return fetch(`${BASE_URL}/users`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(userData)
  });
}

const response = await createUser({
  name: 'John Doe',
  email: 'john@example.com',
  age: 30,
  roles: ['user', 'moderator'],
  address: {
    city: 'New York',
    country: 'US'
  }
});
```

### Reading Authentication Documentation

Common authentication patterns in documentation:

**API Key in Header:**

```
Authentication: API Key
Header: X-API-Key: your_api_key
```

```javascript
const API_KEY = 'your_api_key_here';

const response = await fetch(`${BASE_URL}/users`, {
  headers: {
    'X-API-Key': API_KEY
  }
});
```

**Bearer Token:**

```
Authentication: Bearer Token
Header: Authorization: Bearer <token>
```

```javascript
const token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...';

const response = await fetch(`${BASE_URL}/users`, {
  headers: {
    'Authorization': `Bearer ${token}`
  }
});
```

**Basic Authentication:**

```
Authentication: Basic Auth
Header: Authorization: Basic <base64(username:password)>
```

```javascript
const username = 'user';
const password = 'pass';
const encoded = btoa(`${username}:${password}`);

const response = await fetch(`${BASE_URL}/users`, {
  headers: {
    'Authorization': `Basic ${encoded}`
  }
});
```

**OAuth 2.0:**

```
Authentication: OAuth 2.0
Header: Authorization: Bearer <access_token>
Token endpoint: POST /oauth/token
```

```javascript
// Get token first
const tokenResponse = await fetch(`${BASE_URL}/oauth/token`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
  body: new URLSearchParams({
    grant_type: 'client_credentials',
    client_id: 'your_client_id',
    client_secret: 'your_client_secret'
  })
});

const { access_token } = await tokenResponse.json();

// Use token
const response = await fetch(`${BASE_URL}/users`, {
  headers: {
    'Authorization': `Bearer ${access_token}`
  }
});
```

### Interpreting Response Documentation

Response structure documentation:

```
GET /users/:id
Response: 200 OK
{
  "id": "integer",
  "name": "string",
  "email": "string",
  "createdAt": "ISO 8601 timestamp",
  "profile": {
    "bio": "string or null",
    "avatar": "URL string or null"
  }
}
```

Handling the response:

```javascript
const response = await fetch(`${BASE_URL}/users/123`);

if (response.ok) {
  const user = await response.json();
  
  console.log(user.id);          // integer
  console.log(user.name);        // string
  console.log(user.email);       // string
  console.log(new Date(user.createdAt)); // Date object
  console.log(user.profile.bio); // string or null
  console.log(user.profile.avatar); // string or null
}
```

### Understanding Status Codes

Documentation lists possible status codes:

```
Status Codes:
  200 OK - Success
  201 Created - Resource created
  204 No Content - Success with no body
  400 Bad Request - Invalid input
  401 Unauthorized - Authentication required
  403 Forbidden - Insufficient permissions
  404 Not Found - Resource not found
  422 Unprocessable Entity - Validation error
  429 Too Many Requests - Rate limit exceeded
  500 Internal Server Error - Server error
  503 Service Unavailable - Service down
```

Implementing status code handling:

```javascript
async function handleResponse(response) {
  if (response.ok) {
    // 200-299 status codes
    if (response.status === 204) {
      return null; // No content
    }
    return response.json();
  }
  
  // Handle errors based on status code
  switch (response.status) {
    case 400:
      const badRequest = await response.json();
      throw new Error(`Bad Request: ${badRequest.message}`);
    
    case 401:
      throw new Error('Authentication required');
    
    case 403:
      throw new Error('Insufficient permissions');
    
    case 404:
      throw new Error('Resource not found');
    
    case 422:
      const validation = await response.json();
      throw new Error(`Validation error: ${JSON.stringify(validation.errors)}`);
    
    case 429:
      const retryAfter = response.headers.get('Retry-After');
      throw new Error(`Rate limit exceeded. Retry after ${retryAfter} seconds`);
    
    case 500:
      throw new Error('Internal server error');
    
    case 503:
      throw new Error('Service unavailable');
    
    default:
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
  }
}

try {
  const response = await fetch(`${BASE_URL}/users/123`);
  const data = await handleResponse(response);
  console.log(data);
} catch (error) {
  console.error(error.message);
}
```

### Parsing Error Response Format

Documentation specifies error response structure:

```
Error Response Format:
{
  "error": {
    "code": "string (error code)",
    "message": "string (human-readable)",
    "details": "array or object (optional)"
  }
}
```

Implementation:

```javascript
async function fetchWithErrorHandling(url, options) {
  const response = await fetch(url, options);
  
  if (!response.ok) {
    const errorData = await response.json();
    const error = new Error(errorData.error.message);
    error.code = errorData.error.code;
    error.details = errorData.error.details;
    error.status = response.status;
    throw error;
  }
  
  return response.json();
}

try {
  const data = await fetchWithErrorHandling(`${BASE_URL}/users/invalid`);
} catch (error) {
  console.error('Error code:', error.code);
  console.error('Error message:', error.message);
  console.error('Error details:', error.details);
  console.error('HTTP status:', error.status);
}
```

### Understanding Rate Limiting

Documentation describes rate limits:

```
Rate Limiting:
  - 1000 requests per hour per API key
  - Rate limit info in response headers:
    - X-RateLimit-Limit: Total requests allowed
    - X-RateLimit-Remaining: Requests remaining
    - X-RateLimit-Reset: Unix timestamp of reset time
  - 429 status when exceeded
  - Retry-After header indicates wait time
```

Implementation:

```javascript
class RateLimitedFetcher {
  constructor(baseUrl) {
    this.baseUrl = baseUrl;
    this.rateLimitInfo = {};
  }
  
  async fetch(endpoint, options = {}) {
    const response = await fetch(`${this.baseUrl}${endpoint}`, options);
    
    // Extract rate limit info from headers
    this.rateLimitInfo = {
      limit: parseInt(response.headers.get('X-RateLimit-Limit')),
      remaining: parseInt(response.headers.get('X-RateLimit-Remaining')),
      reset: parseInt(response.headers.get('X-RateLimit-Reset'))
    };
    
    if (response.status === 429) {
      const retryAfter = parseInt(response.headers.get('Retry-After'));
      throw new Error(`Rate limit exceeded. Retry after ${retryAfter} seconds`);
    }
    
    return response;
  }
  
  getRateLimitInfo() {
    return this.rateLimitInfo;
  }
  
  getSecondsUntilReset() {
    const now = Math.floor(Date.now() / 1000);
    return Math.max(0, this.rateLimitInfo.reset - now);
  }
}

const fetcher = new RateLimitedFetcher(BASE_URL);
const response = await fetcher.fetch('/users');
console.log('Rate limit info:', fetcher.getRateLimitInfo());
console.log('Seconds until reset:', fetcher.getSecondsUntilReset());
```

### Reading Pagination Documentation

Common pagination patterns:

**Offset-based:**

```
Pagination: Offset-based
Parameters:
  - limit: Items per page (default: 20, max: 100)
  - offset: Number of items to skip (default: 0)
Response includes:
  - total: Total number of items
  - items: Array of data
```

```javascript
async function fetchPaginated(endpoint, page = 1, limit = 20) {
  const offset = (page - 1) * limit;
  const params = new URLSearchParams({ limit, offset });
  
  const response = await fetch(`${BASE_URL}${endpoint}?${params}`);
  const data = await response.json();
  
  return {
    items: data.items,
    total: data.total,
    page,
    totalPages: Math.ceil(data.total / limit),
    hasNext: (offset + limit) < data.total,
    hasPrev: page > 1
  };
}

const result = await fetchPaginated('/users', 2, 50);
```

**Cursor-based:**

```
Pagination: Cursor-based
Parameters:
  - cursor: Opaque cursor string (optional)
  - limit: Items per page (default: 20)
Response includes:
  - items: Array of data
  - nextCursor: Cursor for next page (null if last page)
  - prevCursor: Cursor for previous page (null if first page)
```

```javascript
async function fetchCursorPaginated(endpoint, cursor = null, limit = 20) {
  const params = new URLSearchParams({ limit });
  if (cursor) {
    params.append('cursor', cursor);
  }
  
  const response = await fetch(`${BASE_URL}${endpoint}?${params}`);
  const data = await response.json();
  
  return {
    items: data.items,
    nextCursor: data.nextCursor,
    prevCursor: data.prevCursor,
    hasNext: data.nextCursor !== null,
    hasPrev: data.prevCursor !== null
  };
}

let cursor = null;
const pages = [];

// Fetch first 3 pages
for (let i = 0; i < 3; i++) {
  const result = await fetchCursorPaginated('/users', cursor);
  pages.push(result.items);
  
  if (!result.hasNext) break;
  cursor = result.nextCursor;
}
```

**Page-based:**

```
Pagination: Page-based
Parameters:
  - page: Page number (default: 1)
  - per_page: Items per page (default: 20, max: 100)
Response includes:
  - data: Array of items
  - meta: { current_page, total_pages, total_count, per_page }
```

```javascript
async function fetchPageBased(endpoint, page = 1, perPage = 20) {
  const params = new URLSearchParams({ page, per_page: perPage });
  
  const response = await fetch(`${BASE_URL}${endpoint}?${params}`);
  const json = await response.json();
  
  return {
    items: json.data,
    currentPage: json.meta.current_page,
    totalPages: json.meta.total_pages,
    totalCount: json.meta.total_count,
    perPage: json.meta.per_page,
    hasNext: json.meta.current_page < json.meta.total_pages,
    hasPrev: json.meta.current_page > 1
  };
}

const result = await fetchPageBased('/users', 3, 50);
```

### Understanding Content-Type Requirements

Documentation specifies required Content-Type headers:

```
Content-Type Requirements:
  - JSON requests: application/json
  - Form submissions: application/x-www-form-urlencoded
  - Multipart forms: multipart/form-data
  - Plain text: text/plain
```

Implementation:

```javascript
// JSON request
const jsonResponse = await fetch(`${BASE_URL}/users`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ name: 'John', email: 'john@example.com' })
});

// Form-encoded request
const formResponse = await fetch(`${BASE_URL}/login`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
  body: new URLSearchParams({
    username: 'john',
    password: 'secret123'
  })
});

// Multipart form (file upload)
const formData = new FormData();
formData.append('file', fileInput.files[0]);
formData.append('description', 'Profile photo');

const uploadResponse = await fetch(`${BASE_URL}/upload`, {
  method: 'POST',
  body: formData // Content-Type automatically set to multipart/form-data
});
```

### Parsing Filtering Documentation

Documentation describes filtering syntax:

```
Filtering:
  Format: field:operator:value
  Operators:
    - eq (equals)
    - ne (not equals)
    - gt (greater than)
    - gte (greater than or equal)
    - lt (less than)
    - lte (less than or equal)
    - in (in list)
    - like (pattern match)
  Multiple filters: Separate with comma
  Example: status:eq:active,age:gte:18,country:in:US,CA,UK
```

Implementation:

```javascript
class FilterBuilder {
  constructor() {
    this.filters = [];
  }
  
  equals(field, value) {
    this.filters.push(`${field}:eq:${value}`);
    return this;
  }
  
  notEquals(field, value) {
    this.filters.push(`${field}:ne:${value}`);
    return this;
  }
  
  greaterThan(field, value) {
    this.filters.push(`${field}:gt:${value}`);
    return this;
  }
  
  greaterThanOrEqual(field, value) {
    this.filters.push(`${field}:gte:${value}`);
    return this;
  }
  
  lessThan(field, value) {
    this.filters.push(`${field}:lt:${value}`);
    return this;
  }
  
  lessThanOrEqual(field, value) {
    this.filters.push(`${field}:lte:${value}`);
    return this;
  }
  
  in(field, values) {
    this.filters.push(`${field}:in:${values.join(',')}`);
    return this;
  }
  
  like(field, pattern) {
    this.filters.push(`${field}:like:${pattern}`);
    return this;
  }
  
  build() {
    return this.filters.join(',');
  }
}

const filter = new FilterBuilder()
  .equals('status', 'active')
  .greaterThanOrEqual('age', 18)
  .in('country', ['US', 'CA', 'UK'])
  .build();

const response = await fetch(`${BASE_URL}/users?filter=${encodeURIComponent(filter)}`);
```

### Reading Versioning Information

API versioning strategies in documentation:

**URL Path Versioning:**

```
Versioning: URL path
Format: /v{version}/resource
Current: v2
Example: https://api.example.com/v2/users
```

```javascript
const API_VERSION = 'v2';
const BASE_URL = `https://api.example.com/${API_VERSION}`;

const response = await fetch(`${BASE_URL}/users`);
```

**Header Versioning:**

```
Versioning: Accept header
Format: Accept: application/vnd.example.v{version}+json
Current: v2
Example: Accept: application/vnd.example.v2+json
```

```javascript
const API_VERSION = '2';

const response = await fetch(`${BASE_URL}/users`, {
  headers: {
    'Accept': `application/vnd.example.v${API_VERSION}+json`
  }
});
```

**Query Parameter Versioning:**

```
Versioning: Query parameter
Format: ?version={version}
Current: 2
Example: https://api.example.com/users?version=2
```

```javascript
const API_VERSION = '2';

const response = await fetch(`${BASE_URL}/users?version=${API_VERSION}`);
```

### Understanding Field Selection

Documentation for field selection:

```
Field Selection:
  Parameter: fields
  Format: Comma-separated field names
  Nested fields: Use dot notation
  Example: ?fields=id,name,email,profile.bio
```

Implementation:

```javascript
function selectFields(fields) {
  return fields.join(',');
}

const selectedFields = selectFields(['id', 'name', 'email', 'profile.bio', 'profile.avatar']);
const response = await fetch(`${BASE_URL}/users?fields=${selectedFields}`);

// Alternative: Fluent interface
class FieldSelector {
  constructor() {
    this.fields = [];
  }
  
  select(...fields) {
    this.fields.push(...fields);
    return this;
  }
  
  build() {
    return this.fields.join(',');
  }
}

const fields = new FieldSelector()
  .select('id', 'name', 'email')
  .select('profile.bio', 'profile.avatar')
  .build();

const response2 = await fetch(`${BASE_URL}/users?fields=${fields}`);
```

### Reading Webhook Documentation

Webhook configuration from documentation:

```
Webhooks:
  Endpoint: POST /webhooks
  Events: user.created, user.updated, user.deleted
  Payload: JSON with event data
  Headers: X-Webhook-Signature for verification
  Retry: 3 attempts with exponential backoff
```

Setting up webhooks:

```javascript
async function createWebhook(url, events) {
  const response = await fetch(`${BASE_URL}/webhooks`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({
      url,
      events,
      active: true
    })
  });
  
  return response.json();
}

const webhook = await createWebhook(
  'https://myapp.com/webhook/handler',
  ['user.created', 'user.updated', 'user.deleted']
);
```

### Understanding Batch Operations

Batch operation documentation:

```
Batch Operations:
  Endpoint: POST /batch
  Request Body:
    {
      "operations": [
        { "method": "POST", "path": "/users", "body": {...} },
        { "method": "GET", "path": "/users/123" },
        { "method": "DELETE", "path": "/users/456" }
      ]
    }
  Response: Array of individual responses
```

Implementation:

```javascript
async function batchOperation(operations) {
  const response = await fetch(`${BASE_URL}/batch`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({ operations })
  });
  
  return response.json();
}

const results = await batchOperation([
  {
    method: 'POST',
    path: '/users',
    body: { name: 'John', email: 'john@example.com' }
  },
  {
    method: 'GET',
    path: '/users/123'
  },
  {
    method: 'DELETE',
    path: '/users/456'
  }
]);

results.forEach((result, index) => {
  console.log(`Operation ${index}:`, result.status, result.body);
});
```

### Reading Timeout Recommendations

Documentation specifies timeout behavior:

```
Timeouts:
  - Default server timeout: 30 seconds
  - Long-running operations: Use async endpoints
  - Recommended client timeout: 60 seconds
  - Async operations return 202 Accepted with Location header
```

Implementation:

```javascript
async function fetchWithTimeout(url, options = {}, timeoutMs = 60000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    
    if (error.name === 'AbortError') {
      throw new Error(`Request timeout after ${timeoutMs}ms`);
    }
    
    throw error;
  }
}

// Regular request with timeout
const response = await fetchWithTimeout(`${BASE_URL}/users`, {}, 30000);

// Long-running async operation
const asyncResponse = await fetchWithTimeout(`${BASE_URL}/reports/generate`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ type: 'annual', year: 2024 })
});

if (asyncResponse.status === 202) {
  const location = asyncResponse.headers.get('Location');
  console.log('Check status at:', location);
  
  // Poll for completion
  let completed = false;
  while (!completed) {
    await new Promise(resolve => setTimeout(resolve, 5000)); // Wait 5s
    
    const statusResponse = await fetch(location);
    const status = await statusResponse.json();
    
    if (status.state === 'completed') {
      completed = true;
      console.log('Result:', status.result);
    } else if (status.state === 'failed') {
      throw new Error('Operation failed: ' + status.error);
    }
  }
}
```

### Building SDK from Documentation

Creating a reusable API client:

```javascript
class APIClient {
  constructor(config) {
    this.baseUrl = config.baseUrl;
    this.apiKey = config.apiKey;
    this.version = config.version || 'v2';
    this.timeout = config.timeout || 30000;
  }
  
  async request(endpoint, options = {}) {
    const url = `${this.baseUrl}/${this.version}${endpoint}`;
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);
    
    const defaultHeaders = {
      'Content-Type': 'application/json',
      'X-API-Key': this.apiKey
    };
    
    try {
      const response = await fetch(url, {
        ...options,
        headers: {
          ...defaultHeaders,
          ...options.headers
        },
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error.message);
      }
      
      if (response.status === 204) {
        return null;
      }
      
      return response.json();
    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }
  
  // User endpoints
  async listUsers(params = {}) {
    const queryString = new URLSearchParams(params).toString();
    return this.request(`/users${queryString ? '?' + queryString : ''}`);
  }
  
  async getUser(userId) {
    return this.request(`/users/${userId}`);
  }
  
  async createUser(userData) {
    return this.request('/users', {
      method: 'POST',
      body: JSON.stringify(userData)
    });
  }
  
  async updateUser(userId, userData) {
    return this.request(`/users/${userId}`, {
      method: 'PUT',
      body: JSON.stringify(userData)
    });
  }
  
  async deleteUser(userId) {
    return this.request(`/users/${userId}`, {
      method: 'DELETE'
    });
  }
}

// Usage
const client = new APIClient({
  baseUrl: 'https://api.example.com',
  apiKey: 'your_api_key',
  version: 'v2',
  timeout: 60000
});

const users = await client.listUsers({ page: 1, limit: 50 });
const user = await client.getUser(123);
const newUser = await client.createUser({ name: 'John', email: 'john@example.com' });
```

---

## OpenAPI/Swagger Integration with Fetch API

### Parsing OpenAPI Specifications

Loading and parsing OpenAPI/Swagger documents:

```javascript
class OpenAPIClient {
  constructor() {
    this.spec = null;
    this.baseUrl = '';
    this.securityHandlers = new Map();
  }

  async loadSpec(specUrl) {
    const response = await fetch(specUrl);
    
    if (!response.ok) {
      throw new Error(`Failed to load spec: ${response.status}`);
    }

    this.spec = await response.json();
    this.baseUrl = this.resolveBaseUrl();
    return this.spec;
  }

  resolveBaseUrl() {
    if (this.spec.servers && this.spec.servers.length > 0) {
      return this.spec.servers[0].url;
    }
    
    // OpenAPI 2.0 (Swagger)
    if (this.spec.host) {
      const scheme = this.spec.schemes?.[0] || 'https';
      const basePath = this.spec.basePath || '';
      return `${scheme}://${this.spec.host}${basePath}`;
    }

    return '';
  }

  getOperation(operationId) {
    for (const [path, pathItem] of Object.entries(this.spec.paths)) {
      for (const [method, operation] of Object.entries(pathItem)) {
        if (operation.operationId === operationId) {
          return { path, method: method.toUpperCase(), operation };
        }
      }
    }
    return null;
  }

  listOperations() {
    const operations = [];
    
    for (const [path, pathItem] of Object.entries(this.spec.paths)) {
      for (const [method, operation] of Object.entries(pathItem)) {
        if (operation.operationId) {
          operations.push({
            operationId: operation.operationId,
            path,
            method: method.toUpperCase(),
            summary: operation.summary,
            tags: operation.tags
          });
        }
      }
    }
    
    return operations;
  }
}
```

### Building Request URLs from Path Templates

Resolving path parameters and query strings:

```javascript
class RequestBuilder {
  constructor(baseUrl, path, method) {
    this.baseUrl = baseUrl;
    this.path = path;
    this.method = method;
    this.pathParams = {};
    this.queryParams = {};
    this.headers = {};
    this.body = null;
  }

  setPathParam(name, value) {
    this.pathParams[name] = value;
    return this;
  }

  setQueryParam(name, value) {
    if (value !== undefined && value !== null) {
      this.queryParams[name] = value;
    }
    return this;
  }

  setHeader(name, value) {
    this.headers[name] = value;
    return this;
  }

  setBody(data) {
    this.body = data;
    return this;
  }

  buildUrl() {
    // Replace path parameters
    let url = this.path;
    for (const [name, value] of Object.entries(this.pathParams)) {
      url = url.replace(`{${name}}`, encodeURIComponent(value));
    }

    // Add query parameters
    const queryString = new URLSearchParams(this.queryParams).toString();
    const fullUrl = `${this.baseUrl}${url}`;
    
    return queryString ? `${fullUrl}?${queryString}` : fullUrl;
  }

  async execute() {
    const url = this.buildUrl();
    const options = {
      method: this.method,
      headers: this.headers
    };

    if (this.body && ['POST', 'PUT', 'PATCH'].includes(this.method)) {
      options.body = JSON.stringify(this.body);
      if (!this.headers['Content-Type']) {
        options.headers['Content-Type'] = 'application/json';
      }
    }

    const response = await fetch(url, options);
    return this.handleResponse(response);
  }

  async handleResponse(response) {
    const contentType = response.headers.get('Content-Type') || '';

    if (!response.ok) {
      const error = new Error(`HTTP ${response.status}`);
      error.status = response.status;
      
      if (contentType.includes('application/json')) {
        error.details = await response.json();
      } else {
        error.details = await response.text();
      }
      
      throw error;
    }

    if (response.status === 204) {
      return null;
    }

    if (contentType.includes('application/json')) {
      return response.json();
    }

    return response.text();
  }
}
```

### Parameter Validation

Validating request parameters against OpenAPI schema:

```javascript
class ParameterValidator {
  static validate(parameters, values) {
    const errors = [];

    for (const param of parameters) {
      const value = values[param.name];

      // Required check
      if (param.required && (value === undefined || value === null)) {
        errors.push(`Missing required parameter: ${param.name}`);
        continue;
      }

      if (value === undefined || value === null) continue;

      // Type validation
      const typeError = this.validateType(param, value);
      if (typeError) {
        errors.push(typeError);
      }

      // Schema validation
      if (param.schema) {
        const schemaErrors = this.validateSchema(param.schema, value, param.name);
        errors.push(...schemaErrors);
      }
    }

    return errors;
  }

  static validateType(param, value) {
    const schema = param.schema || param;
    const type = schema.type;

    switch (type) {
      case 'integer':
        if (!Number.isInteger(Number(value))) {
          return `${param.name} must be an integer`;
        }
        break;
      case 'number':
        if (isNaN(Number(value))) {
          return `${param.name} must be a number`;
        }
        break;
      case 'boolean':
        if (typeof value !== 'boolean' && value !== 'true' && value !== 'false') {
          return `${param.name} must be a boolean`;
        }
        break;
      case 'string':
        if (typeof value !== 'string') {
          return `${param.name} must be a string`;
        }
        break;
      case 'array':
        if (!Array.isArray(value)) {
          return `${param.name} must be an array`;
        }
        break;
    }

    return null;
  }

  static validateSchema(schema, value, path) {
    const errors = [];

    // Enum validation
    if (schema.enum && !schema.enum.includes(value)) {
      errors.push(`${path} must be one of: ${schema.enum.join(', ')}`);
    }

    // String validations
    if (schema.type === 'string') {
      if (schema.minLength && value.length < schema.minLength) {
        errors.push(`${path} must be at least ${schema.minLength} characters`);
      }
      if (schema.maxLength && value.length > schema.maxLength) {
        errors.push(`${path} must be at most ${schema.maxLength} characters`);
      }
      if (schema.pattern) {
        const regex = new RegExp(schema.pattern);
        if (!regex.test(value)) {
          errors.push(`${path} must match pattern: ${schema.pattern}`);
        }
      }
    }

    // Number validations
    if (schema.type === 'number' || schema.type === 'integer') {
      const numValue = Number(value);
      if (schema.minimum !== undefined && numValue < schema.minimum) {
        errors.push(`${path} must be >= ${schema.minimum}`);
      }
      if (schema.maximum !== undefined && numValue > schema.maximum) {
        errors.push(`${path} must be <= ${schema.maximum}`);
      }
    }

    // Array validations
    if (schema.type === 'array') {
      if (schema.minItems && value.length < schema.minItems) {
        errors.push(`${path} must have at least ${schema.minItems} items`);
      }
      if (schema.maxItems && value.length > schema.maxItems) {
        errors.push(`${path} must have at most ${schema.maxItems} items`);
      }
    }

    return errors;
  }
}
```

### Dynamic Client Generation

Generating typed API clients from OpenAPI specs:

```javascript
class DynamicAPIClient extends OpenAPIClient {
  constructor() {
    super();
    this.api = {};
  }

  async loadSpec(specUrl) {
    await super.loadSpec(specUrl);
    this.generateClient();
    return this.spec;
  }

  generateClient() {
    const operations = this.listOperations();

    for (const op of operations) {
      const { operationId, path, method, operation } = op;
      
      // Create nested structure based on tags
      const tag = operation.tags?.[0] || 'default';
      if (!this.api[tag]) {
        this.api[tag] = {};
      }

      // Generate method
      this.api[tag][operationId] = this.createOperationMethod(
        path,
        method,
        operation
      );
    }
  }

  createOperationMethod(path, method, operation) {
    return async (params = {}, body = null, options = {}) => {
      const builder = new RequestBuilder(this.baseUrl, path, method);

      // Extract parameters
      const pathParams = {};
      const queryParams = {};
      const headerParams = {};

      if (operation.parameters) {
        for (const param of operation.parameters) {
          const value = params[param.name];
          
          switch (param.in) {
            case 'path':
              pathParams[param.name] = value;
              break;
            case 'query':
              queryParams[param.name] = value;
              break;
            case 'header':
              headerParams[param.name] = value;
              break;
          }
        }

        // Validate parameters
        const errors = ParameterValidator.validate(
          operation.parameters,
          params
        );
        
        if (errors.length > 0) {
          throw new Error(`Validation errors: ${errors.join(', ')}`);
        }
      }

      // Build request
      for (const [name, value] of Object.entries(pathParams)) {
        builder.setPathParam(name, value);
      }

      for (const [name, value] of Object.entries(queryParams)) {
        builder.setQueryParam(name, value);
      }

      for (const [name, value] of Object.entries(headerParams)) {
        builder.setHeader(name, value);
      }

      // Apply security
      await this.applySecurity(builder, operation.security);

      // Set body
      if (body) {
        builder.setBody(body);
      }

      // Execute
      return builder.execute();
    };
  }

  async applySecurity(builder, securityRequirements) {
    if (!securityRequirements) {
      securityRequirements = this.spec.security || [];
    }

    for (const requirement of securityRequirements) {
      for (const [schemeName, scopes] of Object.entries(requirement)) {
        const handler = this.securityHandlers.get(schemeName);
        if (handler) {
          await handler(builder, scopes);
        }
      }
    }
  }

  registerSecurityHandler(schemeName, handler) {
    this.securityHandlers.set(schemeName, handler);
  }
}
```

### Security Schemes Implementation

Handling various authentication methods:

```javascript
class SecurityHandlers {
  static apiKey(location, name, key) {
    return (builder) => {
      if (location === 'header') {
        builder.setHeader(name, key);
      } else if (location === 'query') {
        builder.setQueryParam(name, key);
      }
    };
  }

  static bearerAuth(token) {
    return (builder) => {
      builder.setHeader('Authorization', `Bearer ${token}`);
    };
  }

  static basicAuth(username, password) {
    return (builder) => {
      const credentials = btoa(`${username}:${password}`);
      builder.setHeader('Authorization', `Basic ${credentials}`);
    };
  }

  static oauth2(getAccessToken) {
    return async (builder, scopes) => {
      const token = await getAccessToken(scopes);
      builder.setHeader('Authorization', `Bearer ${token}`);
    };
  }

  static custom(applyAuth) {
    return applyAuth;
  }
}

// Usage example
const client = new DynamicAPIClient();
await client.loadSpec('https://api.example.com/openapi.json');

// Register security handlers
client.registerSecurityHandler(
  'bearerAuth',
  SecurityHandlers.bearerAuth('your-token-here')
);

client.registerSecurityHandler(
  'apiKey',
  SecurityHandlers.apiKey('header', 'X-API-Key', 'your-api-key')
);
```

### Request Body Serialization

Handling different content types:

```javascript
class BodySerializer {
  static serialize(body, contentType, schema) {
    switch (contentType) {
      case 'application/json':
        return this.serializeJSON(body, schema);
      
      case 'application/x-www-form-urlencoded':
        return this.serializeFormData(body);
      
      case 'multipart/form-data':
        return this.serializeMultipart(body);
      
      case 'text/plain':
        return String(body);
      
      default:
        return body;
    }
  }

  static serializeJSON(body, schema) {
    if (schema) {
      return JSON.stringify(this.coerceTypes(body, schema));
    }
    return JSON.stringify(body);
  }

  static serializeFormData(body) {
    const params = new URLSearchParams();
    
    for (const [key, value] of Object.entries(body)) {
      if (Array.isArray(value)) {
        value.forEach(v => params.append(key, v));
      } else {
        params.append(key, value);
      }
    }
    
    return params.toString();
  }

  static serializeMultipart(body) {
    const formData = new FormData();
    
    for (const [key, value] of Object.entries(body)) {
      if (value instanceof File || value instanceof Blob) {
        formData.append(key, value);
      } else if (Array.isArray(value)) {
        value.forEach(v => formData.append(key, v));
      } else if (typeof value === 'object') {
        formData.append(key, JSON.stringify(value));
      } else {
        formData.append(key, value);
      }
    }
    
    return formData;
  }

  static coerceTypes(data, schema) {
    if (!schema || typeof data !== 'object') return data;

    const coerced = Array.isArray(data) ? [] : {};

    for (const [key, value] of Object.entries(data)) {
      const propSchema = schema.properties?.[key];
      
      if (!propSchema) {
        coerced[key] = value;
        continue;
      }

      switch (propSchema.type) {
        case 'integer':
          coerced[key] = parseInt(value, 10);
          break;
        case 'number':
          coerced[key] = parseFloat(value);
          break;
        case 'boolean':
          coerced[key] = value === 'true' || value === true;
          break;
        case 'object':
          coerced[key] = this.coerceTypes(value, propSchema);
          break;
        case 'array':
          coerced[key] = Array.isArray(value)
            ? value.map(item => this.coerceTypes(item, propSchema.items))
            : value;
          break;
        default:
          coerced[key] = value;
      }
    }

    return coerced;
  }
}
```

### Response Deserialization

Processing and validating responses:

```javascript
class ResponseHandler {
  static async handle(response, operation) {
    const status = response.status;
    const responseSpec = operation.responses?.[status] || 
                        operation.responses?.default;

    if (!responseSpec) {
      throw new Error(`Unexpected response status: ${status}`);
    }

    const contentType = response.headers.get('Content-Type') || '';
    const content = responseSpec.content;

    if (!content) {
      return null;
    }

    // Find matching content type
    let schema = null;
    for (const [mediaType, mediaTypeObject] of Object.entries(content)) {
      if (contentType.includes(mediaType)) {
        schema = mediaTypeObject.schema;
        break;
      }
    }

    // Deserialize response
    let data;
    if (contentType.includes('application/json')) {
      data = await response.json();
    } else if (contentType.includes('text/')) {
      data = await response.text();
    } else {
      data = await response.blob();
    }

    // Validate against schema if present
    if (schema && typeof data === 'object') {
      const errors = this.validateResponse(data, schema);
      if (errors.length > 0) {
        console.warn('Response validation errors:', errors);
      }
    }

    return data;
  }

  static validateResponse(data, schema) {
    const errors = [];

    if (schema.type === 'object' && schema.properties) {
      for (const [prop, propSchema] of Object.entries(schema.properties)) {
        const value = data[prop];

        if (propSchema.required && value === undefined) {
          errors.push(`Missing required property: ${prop}`);
        }

        if (value !== undefined) {
          const propErrors = ParameterValidator.validateSchema(
            propSchema,
            value,
            prop
          );
          errors.push(...propErrors);
        }
      }
    }

    return errors;
  }
}
```

### Schema Reference Resolution

Resolving $ref pointers in OpenAPI schemas:

```javascript
class SchemaResolver {
  constructor(spec) {
    this.spec = spec;
    this.cache = new Map();
  }

  resolve(schema) {
    if (!schema) return null;

    if (schema.$ref) {
      return this.resolveRef(schema.$ref);
    }

    // Resolve nested schemas
    if (schema.properties) {
      const resolved = { ...schema, properties: {} };
      for (const [key, prop] of Object.entries(schema.properties)) {
        resolved.properties[key] = this.resolve(prop);
      }
      return resolved;
    }

    if (schema.items) {
      return { ...schema, items: this.resolve(schema.items) };
    }

    if (schema.allOf) {
      return this.resolveAllOf(schema.allOf);
    }

    if (schema.oneOf) {
      return { ...schema, oneOf: schema.oneOf.map(s => this.resolve(s)) };
    }

    if (schema.anyOf) {
      return { ...schema, anyOf: schema.anyOf.map(s => this.resolve(s)) };
    }

    return schema;
  }

  resolveRef(ref) {
    if (this.cache.has(ref)) {
      return this.cache.get(ref);
    }

    const path = ref.replace('#/', '').split('/');
    let current = this.spec;

    for (const segment of path) {
      current = current[segment];
      if (!current) {
        throw new Error(`Cannot resolve reference: ${ref}`);
      }
    }

    const resolved = this.resolve(current);
    this.cache.set(ref, resolved);
    return resolved;
  }

  resolveAllOf(allOf) {
    const schemas = allOf.map(s => this.resolve(s));
    
    // Merge all schemas
    const merged = {
      type: 'object',
      properties: {},
      required: []
    };

    for (const schema of schemas) {
      if (schema.properties) {
        Object.assign(merged.properties, schema.properties);
      }
      if (schema.required) {
        merged.required.push(...schema.required);
      }
    }

    return merged;
  }
}
```

### Mock Server Generation

Creating mock responses from OpenAPI examples:

```javascript
class MockServer {
  constructor(spec) {
    this.spec = spec;
    this.resolver = new SchemaResolver(spec);
    this.handlers = new Map();
  }

  generateMocks() {
    for (const [path, pathItem] of Object.entries(this.spec.paths)) {
      for (const [method, operation] of Object.entries(pathItem)) {
        if (['get', 'post', 'put', 'delete', 'patch'].includes(method)) {
          this.handlers.set(
            `${method.toUpperCase()} ${path}`,
            this.createMockHandler(operation)
          );
        }
      }
    }
  }

  createMockHandler(operation) {
    return (params) => {
      const successResponse = operation.responses?.['200'] ||
                            operation.responses?.['201'] ||
                            operation.responses?.default;

      if (!successResponse?.content) {
        return { status: 204, data: null };
      }

      const jsonContent = successResponse.content['application/json'];
      if (!jsonContent) {
        return { status: 200, data: {} };
      }

      // Use example if available
      if (jsonContent.example) {
        return { status: 200, data: jsonContent.example };
      }

      // Generate from schema
      const schema = this.resolver.resolve(jsonContent.schema);
      const mockData = this.generateFromSchema(schema);

      return { status: 200, data: mockData };
    };
  }

  generateFromSchema(schema) {
    if (!schema) return null;

    switch (schema.type) {
      case 'object':
        return this.generateObject(schema);
      case 'array':
        return this.generateArray(schema);
      case 'string':
        return schema.example || schema.enum?.[0] || 'string';
      case 'number':
      case 'integer':
        return schema.example || schema.minimum || 0;
      case 'boolean':
        return schema.example !== undefined ? schema.example : true;
      default:
        return null;
    }
  }

  generateObject(schema) {
    const obj = {};

    if (schema.properties) {
      for (const [key, propSchema] of Object.entries(schema.properties)) {
        obj[key] = this.generateFromSchema(
          this.resolver.resolve(propSchema)
        );
      }
    }

    return obj;
  }

  generateArray(schema) {
    const itemSchema = this.resolver.resolve(schema.items);
    const minItems = schema.minItems || 1;
    
    return Array(minItems).fill(null).map(() => 
      this.generateFromSchema(itemSchema)
    );
  }

  async intercept(url, options = {}) {
    const method = options.method || 'GET';
    const urlObj = new URL(url, this.spec.servers?.[0]?.url);
    
    // Match path
    for (const [key, handler] of this.handlers) {
      const [handlerMethod, handlerPath] = key.split(' ');
      
      if (method === handlerMethod) {
        const pathPattern = this.pathToRegex(handlerPath);
        const match = urlObj.pathname.match(pathPattern);
        
        if (match) {
          const mockResponse = handler(match.groups);
          return new Response(
            JSON.stringify(mockResponse.data),
            {
              status: mockResponse.status,
              headers: { 'Content-Type': 'application/json' }
            }
          );
        }
      }
    }

    return null;
  }

  pathToRegex(path) {
    const pattern = path.replace(/{([^}]+)}/g, '(?<$1>[^/]+)');
    return new RegExp(`^${pattern}$`);
  }
}
```

### Complete Integration Example

Putting it all together:

```javascript
// Initialize client
const client = new DynamicAPIClient();
await client.loadSpec('https://petstore3.swagger.io/api/v3/openapi.json');

// Setup authentication
client.registerSecurityHandler(
  'petstore_auth',
  SecurityHandlers.oauth2(async (scopes) => {
    // Fetch OAuth token
    return 'your-access-token';
  })
);

client.registerSecurityHandler(
  'api_key',
  SecurityHandlers.apiKey('header', 'api_key', 'special-key')
);

// Use generated API
try {
  // GET request with path and query parameters
  const pet = await client.api.pet.getPetById(
    { petId: 123 }
  );
  console.log('Pet:', pet);

  // POST request with body
  const newPet = await client.api.pet.addPet(
    {},
    {
      name: 'Doggie',
      photoUrls: ['http://example.com/photo.jpg'],
      status: 'available'
    }
  );
  console.log('Created:', newPet);

  // PUT request with path params and body
  const updated = await client.api.pet.updatePet(
    {},
    {
      id: newPet.id,
      name: 'Updated Doggie',
      status: 'sold'
    }
  );
  console.log('Updated:', updated);

} catch (error) {
  console.error('API Error:', error.message);
  if (error.details) {
    console.error('Details:', error.details);
  }
}

// Using mock server for development
const mockServer = new MockServer(client.spec);
mockServer.generateMocks();

// Override fetch for testing
const originalFetch = window.fetch;
window.fetch = async (url, options) => {
  const mockResponse = await mockServer.intercept(url, options);
  if (mockResponse) {
    return mockResponse;
  }
  return originalFetch(url, options);
};
```

### TypeScript Type Generation

[Inference] Generating TypeScript interfaces from OpenAPI schemas:

```javascript
class TypeScriptGenerator {
  constructor(spec) {
    this.spec = spec;
    this.resolver = new SchemaResolver(spec);
    this.types = new Set();
  }

  generate() {
    let output = '';

    // Generate schema types
    if (this.spec.components?.schemas) {
      for (const [name, schema] of Object.entries(this.spec.components.schemas)) {
        output += this.generateInterface(name, schema);
        output += '\n\n';
      }
    }

    // Generate operation types
    for (const [path, pathItem] of Object.entries(this.spec.paths)) {
      for (const [method, operation] of Object.entries(pathItem)) {
        if (operation.operationId) {
          output += this.generateOperationTypes(operation);
          output += '\n\n';
        }
      }
    }

    return output;
  }

  generateInterface(name, schema) {
    const resolved = this.resolver.resolve(schema);
    let output = `export interface ${name} {\n`;

    if (resolved.properties) {
      for (const [prop, propSchema] of Object.entries(resolved.properties)) {
        const optional = !resolved.required?.includes(prop) ? '?' : '';
        const type = this.getTypeScriptType(propSchema);
        const description = propSchema.description 
          ? `  /** ${propSchema.description} */\n`
          : '';
        
        output += `${description}  ${prop}${optional}: ${type};\n`;
      }
    }

    output += '}';
    return output;
  }

  getTypeScriptType(schema) {
    if (!schema) return 'any';

    if (schema.$ref) {
      const parts = schema.$ref.split('/');
      return parts[parts.length - 1];
    }

    switch (schema.type) {
      case 'string':
        if (schema.enum) {
          return schema.enum.map(v => `'${v}'`).join(' | ');
        }
        return 'string';
      case 'number':
      case 'integer':
        return 'number';
      case 'boolean':
        return 'boolean';
      case 'array':
        const itemType = this.getTypeScriptType(schema.items);
        return `Array<${itemType}>`;
      case 'object':
        if (schema.properties) {
          return this.generateInlineInterface(schema);
        }
        return 'Record<string, any>';
      default:
        return 'any';
    }
  }

  generateInlineInterface(schema) {
    let output = '{\n';
    
    for (const [prop, propSchema] of Object.entries(schema.properties || {})) {
      const optional = !schema.required?.includes(prop) ? '?' : '';
      const type = this.getTypeScriptType(propSchema);
      output += `    ${prop}${optional}: ${type};\n`;
    }
    
    output += '  }';
    return output;
  }

  generateOperationTypes(operation) {
    const opId = operation.operationId;
    let output = '';

    // Parameters type
    if (operation.parameters?.length > 0) {
      output += `export interface ${opId}Params {\n`;
      
      for (const param of operation.parameters) {
        const optional = !param.required ? '?' : '';
        const type = this.getTypeScriptType(param.schema);
        output += `  ${param.name}${optional}: ${type};\n`;
      }
      
      output += '}\n\n';
    }

    // Request body type
    if (operation.requestBody) {
      const content = operation.requestBody.content?.['application/json'];
      if (content?.schema) {
        const type = this.getTypeScriptType(content.schema);
        output += `export type ${opId}Body = ${type};\n\n`;
      }
    }

    // Response type
    const successResponse = operation.responses?.['200'] || 
                           operation.responses?.['201'];
    if (successResponse?.content?.['application/json']?.schema) {
      const type = this.getTypeScriptType(
        successResponse.content['application/json'].schema
      );
      output += `export type ${opId}Response = ${type};\n`;
    }

    return output;
  }
}

// Usage
const generator = new TypeScriptGenerator(client.spec);
const types = generator.generate();
console.log(types);
```

---

# Monitoring and Analytics

## Request Timing with Fetch API

### Performance API Integration

#### Resource Timing Entries

Access detailed timing information for fetch requests using the Performance API:

```javascript
async function fetchWithTiming(url, options = {}) {
  const startMark = `fetch-start-${Date.now()}`;
  performance.mark(startMark);

  const response = await fetch(url, options);

  const endMark = `fetch-end-${Date.now()}`;
  performance.mark(endMark);

  // Get resource timing entry
  const entries = performance.getEntriesByType('resource');
  const entry = entries.find(e => e.name === url);

  return {
    response,
    timing: entry ? extractTimingMetrics(entry) : null
  };
}

function extractTimingMetrics(entry) {
  return {
    // DNS lookup
    dnsLookup: entry.domainLookupEnd - entry.domainLookupStart,
    
    // TCP connection
    tcpConnection: entry.connectEnd - entry.connectStart,
    
    // TLS negotiation
    tlsNegotiation: entry.secureConnectionStart > 0 
      ? entry.connectEnd - entry.secureConnectionStart 
      : 0,
    
    // Request time (sending)
    requestTime: entry.responseStart - entry.requestStart,
    
    // Response time (receiving)
    responseTime: entry.responseEnd - entry.responseStart,
    
    // Total time
    totalTime: entry.responseEnd - entry.startTime,
    
    // Time to first byte
    ttfb: entry.responseStart - entry.requestStart,
    
    // Transfer size
    transferSize: entry.transferSize,
    encodedBodySize: entry.encodedBodySize,
    decodedBodySize: entry.decodedBodySize
  };
}
```

#### Performance Observer Pattern

Monitor fetch requests in real-time using PerformanceObserver:

```javascript
class FetchPerformanceMonitor {
  constructor() {
    this.metrics = new Map();
    this.observer = null;
  }

  start() {
    this.observer = new PerformanceObserver((list) => {
      for (const entry of list.getEntries()) {
        if (entry.initiatorType === 'fetch' || entry.initiatorType === 'xmlhttprequest') {
          this.recordMetric(entry);
        }
      }
    });

    this.observer.observe({ 
      entryTypes: ['resource'],
      buffered: true 
    });
  }

  recordMetric(entry) {
    const metric = {
      url: entry.name,
      duration: entry.duration,
      startTime: entry.startTime,
      dns: entry.domainLookupEnd - entry.domainLookupStart,
      tcp: entry.connectEnd - entry.connectStart,
      ttfb: entry.responseStart - entry.requestStart,
      download: entry.responseEnd - entry.responseStart,
      size: entry.transferSize,
      cached: entry.transferSize === 0 && entry.decodedBodySize > 0,
      protocol: entry.nextHopProtocol
    };

    this.metrics.set(entry.name, metric);
    this.onMetricRecorded?.(metric);
  }

  getMetrics(url) {
    return url ? this.metrics.get(url) : Array.from(this.metrics.values());
  }

  getAverageMetrics() {
    const metrics = Array.from(this.metrics.values());
    if (metrics.length === 0) return null;

    return {
      avgDuration: this.average(metrics, 'duration'),
      avgTTFB: this.average(metrics, 'ttfb'),
      avgDownload: this.average(metrics, 'download'),
      avgSize: this.average(metrics, 'size'),
      totalRequests: metrics.length,
      cachedRequests: metrics.filter(m => m.cached).length
    };
  }

  average(array, property) {
    return array.reduce((sum, item) => sum + item[property], 0) / array.length;
  }

  stop() {
    this.observer?.disconnect();
    this.observer = null;
  }

  clear() {
    this.metrics.clear();
  }
}
```

### Manual Timing Implementation

#### High-Resolution Timestamps

Use `performance.now()` for accurate timing measurements:

```javascript
class ManualTimer {
  constructor() {
    this.startTime = null;
    this.phases = [];
  }

  start() {
    this.startTime = performance.now();
    this.phases = [];
    return this;
  }

  mark(label) {
    if (!this.startTime) {
      throw new Error('Timer not started');
    }
    
    const now = performance.now();
    this.phases.push({
      label,
      timestamp: now,
      elapsed: now - this.startTime
    });
    
    return this;
  }

  stop() {
    this.mark('end');
    return this.getReport();
  }

  getReport() {
    if (this.phases.length === 0) return null;

    const report = {
      totalDuration: this.phases[this.phases.length - 1].elapsed,
      phases: []
    };

    for (let i = 0; i < this.phases.length; i++) {
      const phase = this.phases[i];
      const previousTime = i > 0 ? this.phases[i - 1].timestamp : this.startTime;
      
      report.phases.push({
        label: phase.label,
        duration: phase.timestamp - previousTime,
        elapsed: phase.elapsed
      });
    }

    return report;
  }
}

async function fetchWithManualTiming(url, options = {}) {
  const timer = new ManualTimer().start();

  timer.mark('fetch-initiated');
  
  const response = await fetch(url, options);
  timer.mark('headers-received');

  const data = await response.json();
  timer.mark('body-parsed');

  return {
    data,
    timing: timer.stop()
  };
}
```

#### Comprehensive Request Lifecycle Timing

Track all phases of a fetch request:

```javascript
class DetailedRequestTimer {
  async fetch(url, options = {}) {
    const timing = {
      queueTime: performance.now(),
      dnsStart: null,
      dnsEnd: null,
      connectStart: null,
      connectEnd: null,
      tlsStart: null,
      tlsEnd: null,
      requestStart: null,
      responseStart: null,
      responseEnd: null,
      parseStart: null,
      parseEnd: null
    };

    // Request starts
    timing.requestStart = performance.now();

    let response;
    try {
      response = await fetch(url, options);
      timing.responseStart = performance.now();
    } catch (error) {
      timing.error = error.message;
      timing.responseEnd = performance.now();
      throw error;
    }

    // Parse response
    timing.parseStart = performance.now();
    const contentType = response.headers.get('content-type');
    
    let data;
    if (contentType?.includes('application/json')) {
      data = await response.json();
    } else if (contentType?.includes('text/')) {
      data = await response.text();
    } else {
      data = await response.blob();
    }
    
    timing.parseEnd = performance.now();
    timing.responseEnd = performance.now();

    // Try to get resource timing entry
    const resourceEntry = this.getResourceTiming(url);
    if (resourceEntry) {
      timing.dnsStart = resourceEntry.domainLookupStart;
      timing.dnsEnd = resourceEntry.domainLookupEnd;
      timing.connectStart = resourceEntry.connectStart;
      timing.connectEnd = resourceEntry.connectEnd;
      timing.tlsStart = resourceEntry.secureConnectionStart;
      timing.tlsEnd = resourceEntry.connectEnd;
    }

    return {
      data,
      response,
      timing: this.calculateDurations(timing)
    };
  }

  getResourceTiming(url) {
    const entries = performance.getEntriesByType('resource');
    return entries.find(e => e.name === url);
  }

  calculateDurations(timing) {
    return {
      raw: timing,
      durations: {
        queue: timing.requestStart - timing.queueTime,
        dns: timing.dnsEnd && timing.dnsStart 
          ? timing.dnsEnd - timing.dnsStart 
          : null,
        connect: timing.connectEnd && timing.connectStart
          ? timing.connectEnd - timing.connectStart
          : null,
        tls: timing.tlsEnd && timing.tlsStart
          ? timing.tlsEnd - timing.tlsStart
          : null,
        request: timing.responseStart - timing.requestStart,
        response: timing.parseStart - timing.responseStart,
        parse: timing.parseEnd - timing.parseStart,
        total: timing.responseEnd - timing.queueTime
      }
    };
  }
}
```

### Timeout Implementation

#### Basic Timeout with AbortController

Implement request timeouts using AbortController:

```javascript
async function fetchWithTimeout(url, options = {}, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  const startTime = performance.now();

  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });

    clearTimeout(timeoutId);
    
    const duration = performance.now() - startTime;
    
    return {
      response,
      duration,
      timedOut: false
    };
  } catch (error) {
    clearTimeout(timeoutId);
    
    const duration = performance.now() - startTime;
    
    if (error.name === 'AbortError') {
      throw new Error(`Request timeout after ${duration}ms`);
    }
    
    throw error;
  }
}
```

#### Progressive Timeout Strategy

Implement different timeouts for different phases:

```javascript
class ProgressiveTimeoutFetch {
  constructor(options = {}) {
    this.timeouts = {
      connection: options.connectionTimeout || 5000,
      headers: options.headersTimeout || 10000,
      body: options.bodyTimeout || 30000,
      total: options.totalTimeout || 60000
    };
  }

  async fetch(url, options = {}) {
    const controller = new AbortController();
    const timing = {
      start: performance.now(),
      connected: null,
      headersReceived: null,
      bodyReceived: null
    };

    // Set total timeout
    const totalTimeout = setTimeout(
      () => this.abortWithReason(controller, 'total timeout'),
      this.timeouts.total
    );

    // Set connection timeout
    const connectionTimeout = setTimeout(
      () => this.abortWithReason(controller, 'connection timeout'),
      this.timeouts.connection
    );

    try {
      // Start fetch
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      timing.connected = performance.now();
      clearTimeout(connectionTimeout);

      // Set headers timeout
      const headersTimeout = setTimeout(
        () => this.abortWithReason(controller, 'headers timeout'),
        this.timeouts.headers
      );

      // Headers are already available
      timing.headersReceived = performance.now();
      clearTimeout(headersTimeout);

      // Set body timeout
      const bodyTimeout = setTimeout(
        () => this.abortWithReason(controller, 'body timeout'),
        this.timeouts.body
      );

      // Read body
      const data = await this.readBody(response);
      timing.bodyReceived = performance.now();
      
      clearTimeout(bodyTimeout);
      clearTimeout(totalTimeout);

      return {
        data,
        response,
        timing: this.calculateTimings(timing)
      };

    } catch (error) {
      clearTimeout(connectionTimeout);
      clearTimeout(totalTimeout);
      
      timing.bodyReceived = performance.now();
      
      throw {
        error,
        timing: this.calculateTimings(timing),
        phase: this.determineFailurePhase(timing)
      };
    }
  }

  abortWithReason(controller, reason) {
    controller.abort();
    controller.reason = reason;
  }

  async readBody(response) {
    const contentType = response.headers.get('content-type');
    
    if (contentType?.includes('application/json')) {
      return await response.json();
    } else if (contentType?.includes('text/')) {
      return await response.text();
    } else {
      return await response.blob();
    }
  }

  calculateTimings(timing) {
    return {
      connection: timing.connected ? timing.connected - timing.start : null,
      headers: timing.headersReceived ? timing.headersReceived - timing.connected : null,
      body: timing.bodyReceived && timing.headersReceived 
        ? timing.bodyReceived - timing.headersReceived 
        : null,
      total: timing.bodyReceived - timing.start
    };
  }

  determineFailurePhase(timing) {
    if (!timing.connected) return 'connection';
    if (!timing.headersReceived) return 'headers';
    if (!timing.bodyReceived) return 'body';
    return 'unknown';
  }
}
```

#### Adaptive Timeout

Adjust timeouts based on historical performance:

```javascript
class AdaptiveTimeoutFetch {
  constructor(options = {}) {
    this.baseTimeout = options.baseTimeout || 5000;
    this.minTimeout = options.minTimeout || 1000;
    this.maxTimeout = options.maxTimeout || 30000;
    this.history = [];
    this.maxHistorySize = options.maxHistorySize || 100;
    this.multiplier = options.multiplier || 2.5;
  }

  async fetch(url, options = {}) {
    const timeout = this.calculateTimeout();
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);

    const startTime = performance.now();

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      const duration = performance.now() - startTime;
      clearTimeout(timeoutId);

      this.recordSuccess(duration);

      return { response, duration, timeout };

    } catch (error) {
      const duration = performance.now() - startTime;
      clearTimeout(timeoutId);

      if (error.name === 'AbortError') {
        this.recordTimeout(duration);
        throw new Error(`Adaptive timeout (${timeout}ms) exceeded`);
      }

      this.recordFailure(duration);
      throw error;
    }
  }

  calculateTimeout() {
    if (this.history.length === 0) {
      return this.baseTimeout;
    }

    const successfulRequests = this.history.filter(h => h.success);
    
    if (successfulRequests.length === 0) {
      return Math.min(this.baseTimeout * 2, this.maxTimeout);
    }

    // Calculate percentile (95th)
    const durations = successfulRequests
      .map(h => h.duration)
      .sort((a, b) => a - b);
    
    const index = Math.floor(durations.length * 0.95);
    const p95 = durations[index];

    // Apply multiplier and constrain
    const calculatedTimeout = p95 * this.multiplier;
    return Math.max(
      this.minTimeout,
      Math.min(calculatedTimeout, this.maxTimeout)
    );
  }

  recordSuccess(duration) {
    this.addToHistory({ duration, success: true, timedOut: false });
  }

  recordTimeout(duration) {
    this.addToHistory({ duration, success: false, timedOut: true });
  }

  recordFailure(duration) {
    this.addToHistory({ duration, success: false, timedOut: false });
  }

  addToHistory(entry) {
    this.history.push({
      ...entry,
      timestamp: Date.now()
    });

    if (this.history.length > this.maxHistorySize) {
      this.history.shift();
    }
  }

  getStats() {
    const successful = this.history.filter(h => h.success);
    const timedOut = this.history.filter(h => h.timedOut);

    return {
      totalRequests: this.history.length,
      successfulRequests: successful.length,
      timedOutRequests: timedOut.length,
      successRate: successful.length / this.history.length,
      currentTimeout: this.calculateTimeout(),
      avgDuration: successful.length > 0
        ? successful.reduce((sum, h) => sum + h.duration, 0) / successful.length
        : 0
    };
  }

  reset() {
    this.history = [];
  }
}
```

### Request Retry with Timing

#### Exponential Backoff with Timing

Implement retry logic with exponential backoff and timing tracking:

```javascript
class RetryWithTiming {
  constructor(options = {}) {
    this.maxRetries = options.maxRetries || 3;
    this.baseDelay = options.baseDelay || 1000;
    this.maxDelay = options.maxDelay || 30000;
    this.timeout = options.timeout || 10000;
    this.retryableStatuses = options.retryableStatuses || [408, 429, 500, 502, 503, 504];
  }

  async fetch(url, options = {}) {
    const attempts = [];
    let lastError;

    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      const attemptTiming = {
        attempt: attempt + 1,
        startTime: performance.now(),
        endTime: null,
        duration: null,
        status: null,
        error: null
      };

      try {
        const result = await this.attemptFetch(url, options);
        
        attemptTiming.endTime = performance.now();
        attemptTiming.duration = attemptTiming.endTime - attemptTiming.startTime;
        attemptTiming.status = result.response.status;
        
        attempts.push(attemptTiming);

        // Success
        if (result.response.ok) {
          return {
            ...result,
            attempts,
            totalAttempts: attempts.length,
            totalDuration: attempts.reduce((sum, a) => sum + a.duration, 0)
          };
        }

        // Non-retryable status
        if (!this.retryableStatuses.includes(result.response.status)) {
          throw new Error(`Non-retryable status: ${result.response.status}`);
        }

        lastError = new Error(`HTTP ${result.response.status}`);

      } catch (error) {
        attemptTiming.endTime = performance.now();
        attemptTiming.duration = attemptTiming.endTime - attemptTiming.startTime;
        attemptTiming.error = error.message;
        
        attempts.push(attemptTiming);
        lastError = error;
      }

      // Don't wait after last attempt
      if (attempt < this.maxRetries) {
        const delay = this.calculateDelay(attempt);
        await this.sleep(delay);
      }
    }

    throw {
      error: lastError,
      attempts,
      totalAttempts: attempts.length,
      totalDuration: attempts.reduce((sum, a) => sum + a.duration, 0)
    };
  }

  async attemptFetch(url, options) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      clearTimeout(timeoutId);
      return { response };

    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }

  calculateDelay(attempt) {
    const exponentialDelay = this.baseDelay * Math.pow(2, attempt);
    const jitter = Math.random() * 0.3 * exponentialDelay;
    return Math.min(exponentialDelay + jitter, this.maxDelay);
  }

  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

#### Conditional Retry Based on Timing

Make retry decisions based on request timing patterns:

```javascript
class SmartRetryFetch {
  constructor(options = {}) {
    this.maxRetries = options.maxRetries || 3;
    this.fastFailThreshold = options.fastFailThreshold || 100;
    this.slowResponseThreshold = options.slowResponseThreshold || 5000;
    this.timeout = options.timeout || 10000;
  }

  async fetch(url, options = {}) {
    const attempts = [];
    
    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      const startTime = performance.now();
      
      try {
        const response = await this.attemptFetch(url, options);
        const duration = performance.now() - startTime;

        attempts.push({
          attempt: attempt + 1,
          duration,
          status: response.status,
          success: response.ok
        });

        if (response.ok) {
          return {
            response,
            attempts,
            strategy: this.describeStrategy(attempts)
          };
        }

        // Analyze timing to decide retry strategy
        const shouldRetry = this.analyzeAndDecideRetry(
          response,
          duration,
          attempt,
          attempts
        );

        if (!shouldRetry) {
          throw new Error(`Non-retryable failure after ${duration}ms`);
        }

        // Calculate adaptive delay
        const delay = this.calculateAdaptiveDelay(attempts);
        await this.sleep(delay);

      } catch (error) {
        const duration = performance.now() - startTime;

        attempts.push({
          attempt: attempt + 1,
          duration,
          error: error.message,
          success: false
        });

        if (attempt === this.maxRetries) {
          throw { error, attempts };
        }

        const delay = this.calculateAdaptiveDelay(attempts);
        await this.sleep(delay);
      }
    }
  }

  analyzeAndDecideRetry(response, duration, attempt, attempts) {
    // Fast failure suggests client-side or network issue
    if (duration < this.fastFailThreshold) {
      return attempt < 2; // Only retry fast failures twice
    }

    // Slow response suggests server overload
    if (duration > this.slowResponseThreshold) {
      return true; // Always retry slow responses
    }

    // Check for specific status codes
    if (response.status === 429) {
      // Rate limit - check for Retry-After header
      const retryAfter = response.headers.get('Retry-After');
      return retryAfter !== null;
    }

    if ([500, 502, 503, 504].includes(response.status)) {
      // Server errors - retry with backoff
      return true;
    }

    // Default: don't retry client errors
    return false;
  }

  calculateAdaptiveDelay(attempts) {
    const lastAttempt = attempts[attempts.length - 1];
    
    // Fast failures get shorter delays
    if (lastAttempt.duration < this.fastFailThreshold) {
      return 500 * Math.pow(1.5, attempts.length);
    }

    // Slow responses get longer delays
    if (lastAttempt.duration > this.slowResponseThreshold) {
      return 3000 * Math.pow(2, attempts.length);
    }

    // Standard exponential backoff
    return 1000 * Math.pow(2, attempts.length);
  }

  async attemptFetch(url, options) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });

      clearTimeout(timeoutId);
      return response;

    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }

  describeStrategy(attempts) {
    const durations = attempts.map(a => a.duration);
    const avgDuration = durations.reduce((sum, d) => sum + d, 0) / durations.length;

    if (avgDuration < this.fastFailThreshold) {
      return 'fast-fail-recovery';
    } else if (avgDuration > this.slowResponseThreshold) {
      return 'slow-response-backoff';
    } else {
      return 'standard-retry';
    }
  }

  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

### Performance Monitoring and Analysis

#### Request Performance Aggregator

Collect and analyze timing data across multiple requests:

```javascript
class RequestPerformanceAnalyzer {
  constructor() {
    this.requests = [];
    this.buckets = {
      fast: [], // < 100ms
      normal: [], // 100-500ms
      slow: [], // 500-2000ms
      verySlow: [] // > 2000ms
    };
  }

  recordRequest(timing) {
    const request = {
      url: timing.url,
      duration: timing.duration,
      timestamp: Date.now(),
      status: timing.status,
      size: timing.size,
      cached: timing.cached
    };

    this.requests.push(request);
    this.categorizeRequest(request);

    // Keep only last 1000 requests
    if (this.requests.length > 1000) {
      this.requests.shift();
    }
  }

  categorizeRequest(request) {
    if (request.duration < 100) {
      this.buckets.fast.push(request);
    } else if (request.duration < 500) {
      this.buckets.normal.push(request);
    } else if (request.duration < 2000) {
      this.buckets.slow.push(request);
    } else {
      this.buckets.verySlow.push(request);
    }

    // Maintain bucket sizes
    Object.keys(this.buckets).forEach(key => {
      if (this.buckets[key].length > 250) {
        this.buckets[key].shift();
      }
    });
  }

  getStatistics() {
    if (this.requests.length === 0) return null;

    const durations = this.requests.map(r => r.duration).sort((a, b) => a - b);
    const sizes = this.requests.map(r => r.size || 0).sort((a, b) => a - b);

    return {
      totalRequests: this.requests.length,
      distribution: {
        fast: this.buckets.fast.length,
        normal: this.buckets.normal.length,
        slow: this.buckets.slow.length,
        verySlow: this.buckets.verySlow.length
      },
      duration: {
        min: Math.min(...durations),
        max: Math.max(...durations),
        mean: durations.reduce((sum, d) => sum + d, 0) / durations.length,
        median: durations[Math.floor(durations.length / 2)],
        p95: durations[Math.floor(durations.length * 0.95)],
        p99: durations[Math.floor(durations.length * 0.99)]
      },
      size: {
        min: Math.min(...sizes),
        max: Math.max(...sizes),
        mean: sizes.reduce((sum, s) => sum + s, 0) / sizes.length,
        median: sizes[Math.floor(sizes.length / 2)],
        total: sizes.reduce((sum, s) => sum + s, 0)
      },
      cacheHitRate: this.requests.filter(r => r.cached).length / this.requests.length
    };
  }

  getSlowestRequests(limit = 10) {
    return [...this.requests]
      .sort((a, b) => b.duration - a.duration)
      .slice(0, limit);
  }

  getRequestsByUrl(url) {
    return this.requests.filter(r => r.url === url);
  }

  getUrlStatistics(url) {
    const urlRequests = this.getRequestsByUrl(url);
    if (urlRequests.length === 0) return null;

    const durations = urlRequests.map(r => r.duration);

    return {
      url,
      count: urlRequests.length,
      avgDuration: durations.reduce((sum, d) => sum + d, 0) / durations.length,
      minDuration: Math.min(...durations),
      maxDuration: Math.max(...durations)
    };
  }

  detectAnomalies() {
    const stats = this.getStatistics();
    if (!stats) return [];

    const anomalies = [];

    // Detect sudden performance degradation
    const recent = this.requests.slice(-50);
    const older = this.requests.slice(-100, -50);

    if (recent.length > 0 && older.length > 0) {
      const recentAvg = recent.reduce((sum, r) => sum + r.duration, 0) / recent.length;
      const olderAvg = older.reduce((sum, r) => sum + r.duration, 0) / older.length;

      if (recentAvg > olderAvg * 2) {
        anomalies.push({
          type: 'performance-degradation',
          severity: 'high',
          recentAvg,
          olderAvg,
          increase: ((recentAvg - olderAvg) / olderAvg * 100).toFixed(1) + '%'
        });
      }
    }

    // Detect unusually slow requests
    const recentSlow = recent.filter(r => r.duration > stats.duration.p95);
    if (recentSlow.length > recent.length * 0.2) {
      anomalies.push({
        type: 'high-latency-spike',
        severity: 'medium',
        affectedRequests: recentSlow.length,
        totalRecent: recent.length
      });
    }

    return anomalies;
  }

  reset() {
    this.requests = [];
    Object.keys(this.buckets).forEach(key => {
      this.buckets[key] = [];
    });
  }
}
```

#### Real-Time Performance Dashboard

Create a live monitoring system for fetch performance:

```javascript
class PerformanceDashboard {
  constructor() {
    this.analyzer = new RequestPerformanceAnalyzer();
    this.monitor = new FetchPerformanceMonitor();
    this.alerts = [];
    this.thresholds = {
      slowRequest: 1000,
      verySlowRequest: 3000,
      errorRate: 0.1,
      cacheHitRate: 0.5
    };
  }

  start() {
    this.monitor.onMetricRecorded = (metric) => {
      this.analyzer.recordRequest(metric);
      this.checkThresholds(metric);
    };

    this.monitor.start();

    // Periodic analysis
    this.analysisInterval = setInterval(() => {
      this.performPeriodicAnalysis();
    }, 30000); // Every 30 seconds
  }

  checkThresholds(metric) {
    // Check for slow requests
    if (metric.duration > this.thresholds.verySlowRequest) {
      this.addAlert({
        type: 'very-slow-request',
        severity: 'high',
        url: metric.url,
        duration: metric.duration,
        timestamp: Date.now()
      });
    } else if (metric.duration > this.thresholds.slowRequest) {
      this.addAlert({
        type: 'slow-request',
        severity: 'medium',
        url: metric.url,
        duration: metric.duration,
        timestamp: Date.now()
      });
    }

    // Check cache performance
    const stats = this.analyzer.getStatistics();
    if (stats && stats.cacheHitRate < this.thresholds.cacheHitRate) {
      this.addAlert({
        type: 'low-cache-hit-rate',
        severity: 'low',
        rate: stats.cacheHitRate,
        threshold: this.thresholds.cacheHitRate,
        timestamp: Date.now()
      });
    }
  }

  performPeriodicAnalysis() {
    const stats = this.analyzer.getStatistics();
    if (!stats) return;

    // Detect anomalies
    const anomalies = this.analyzer.detectAnomalies();
    anomalies.forEach(anomaly => this.addAlert(anomaly));

    // Emit dashboard update
    this.onDashboardUpdate?.({
      stats,
      alerts: this.getRecentAlerts(10),
      slowestRequests: this.analyzer.getSlowestRequests(5)
    });
  }

  addAlert(alert) {
    this.alerts.push({
      ...alert,
      id: `alert-${Date.now()}-${Math.random()}`
    });

    // Keep only last 100 alerts
    if (this.alerts.length > 100) {
      this.alerts.shift();
    }

    this.onAlert?.(alert);
  }

  getRecentAlerts(limit = 10) {
    return [...this.alerts]
      .sort((a, b) => b.timestamp - a.timestamp)
      .slice(0, limit);
  }

  getAlertsByType(type) {
    return this.alerts.filter(a => a.type === type);
  }

  getDashboardData() {
    const stats = this.analyzer.getStatistics();
    
    return {
      stats,
      alerts: this.getRecentAlerts(10),
      slowestRequests: this.analyzer.getSlowestRequests(5),
      recentAnomalies: this.analyzer.detectAnomalies()
    };
  }

  stop() {
    this.monitor.stop();
    clearInterval(this.analysisInterval);
  }

  reset() {
    this.analyzer.reset();
    this.alerts = [];
  }
}
```

### Network Quality Detection

#### Connection Speed Estimation

Estimate network speed based on request timing:

```javascript
class NetworkSpeedEstimator {
  constructor() {
    this.measurements = [];
    this.maxMeasurements = 50;
  }

  async measureSpeed(testUrl, testSizeBytes) {
    const startTime = performance.now();
    
    try {
      const response = await fetch(testUrl);
      const blob = await response.blob();
      
      const endTime = performance.now();
      const duration = endTime - startTime;
      const sizeBytes = blob.size || testSizeBytes;
      
      // Calculate speed in Mbps
      const speedMbps = (sizeBytes * 8) / (duration / 1000) / 1_000_000;
      
      this.recordMeasurement({
        timestamp: Date.now(),
        duration,
        sizeBytes,
        speedMbps
      });

      return {
        speedMbps,
        duration,
        sizeBytes,
        classification: this.classifySpeed(speedMbps)
      };

    } catch (error) {
      return {
        error: error.message,
        speedMbps: 0,
        classification: 'offline'
      };
    }
  }

  recordMeasurement(measurement) {
    this.measurements.push(measurement);
    
    if (this.measurements.length > this.maxMeasurements) {
      this.measurements.shift();
    }
  }

  getAverageSpeed() {
    if (this.measurements.length === 0) return null;

    const speeds = this.measurements.map(m => m.speedMbps);
    const avgSpeed = speeds.reduce((sum, s) => sum + s, 0) / speeds.length;

    return {
      avgSpeedMbps: avgSpeed,
      classification: this.classifySpeed(avgSpeed),
      measurements: this.measurements.length
    };
  }

  classifySpeed(mbps) {
    if (mbps === 0) return 'offline';
    if (mbps < 0.5) return 'slow-2g';
    if (mbps < 2) return '2g';
    if (mbps < 10) return '3g';
    if (mbps < 50) return '4g';
    return '5g';
  }

  getCurrentQuality() {
    const avg = this.getAverageSpeed();
    if (!avg) return null;

    return {
      ...avg,
      recommendation: this.getRecommendation(avg.classification)
    };
  }

  getRecommendation(classification) {
    const recommendations = {
      'offline': {
        prefetch: false,
        imageQuality: 'none',
        videoQuality: 'none',
        polling: false
      },
      'slow-2g': {
        prefetch: false,
        imageQuality: 'low',
        videoQuality: 'none',
        polling: false
      },
      '2g': {
        prefetch: false,
        imageQuality: 'low',
        videoQuality: 'low',
        polling: true
      },
      '3g': {
        prefetch: true,
        imageQuality: 'medium',
        videoQuality: 'medium',
        polling: true
      },
      '4g': {
        prefetch: true,
        imageQuality: 'high',
        videoQuality: 'high',
        polling: true
      },
      '5g': {
        prefetch: true,
        imageQuality: 'max',
        videoQuality: 'max',
        polling: true
      }
    };

    return recommendations[classification];
  }

  reset() {
    this.measurements = [];
  }
}
```

#### Network Information API Integration

Leverage the Network Information API when available:

```javascript
class NetworkConditionMonitor {
  constructor() {
    this.connection = navigator.connection || 
                     navigator.mozConnection || 
                     navigator.webkitConnection;
    this.listeners = new Set();
    this.currentConditions = this.getConditions();
  }

  start() {
    if (this.connection) {
      this.connection.addEventListener('change', () => {
        this.currentConditions = this.getConditions();
        this.notifyListeners();
      });
    }

    // Fallback: periodic manual testing
    this.fallbackInterval = setInterval(() => {
      if (!this.connection) {
        this.performFallbackDetection();
      }
    }, 30000);
  }

  getConditions() {
    if (!this.connection) {
      return {
        type: 'unknown',
        effectiveType: 'unknown',
        downlink: null,
        rtt: null,
        saveData: false
      };
    }

    return {
      type: this.connection.type || 'unknown',
      effectiveType: this.connection.effectiveType || 'unknown',
      downlink: this.connection.downlink || null,
      rtt: this.connection.rtt || null,
      saveData: this.connection.saveData || false,
      downlinkMax: this.connection.downlinkMax || null
    };
  }

  async performFallbackDetection() {
    const testImage = new Image();
    const startTime = performance.now();
    
    testImage.onload = () => {
      const duration = performance.now() - startTime;
      this.estimateConditionsFromLatency(duration);
    };

    testImage.onerror = () => {
      this.currentConditions.effectiveType = 'offline';
      this.notifyListeners();
    };

    // Small test image (1x1 pixel)
    testImage.src = `data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7?t=${Date.now()}`;
  }

  estimateConditionsFromLatency(latency) {
    let effectiveType;
    
    if (latency < 50) {
      effectiveType = '4g';
    } else if (latency < 150) {
      effectiveType = '3g';
    } else if (latency < 500) {
      effectiveType = '2g';
    } else {
      effectiveType = 'slow-2g';
    }

    this.currentConditions = {
      ...this.currentConditions,
      effectiveType,
      rtt: latency
    };

    this.notifyListeners();
  }

  onChange(callback) {
    this.listeners.add(callback);
    return () => this.listeners.delete(callback);
  }

  notifyListeners() {
    this.listeners.forEach(callback => {
      callback(this.currentConditions);
    });
  }

  shouldOptimize() {
    const { effectiveType, saveData } = this.currentConditions;
    
    return saveData || 
           effectiveType === 'slow-2g' || 
           effectiveType === '2g';
  }

  getOptimizationStrategy() {
    const { effectiveType, saveData, downlink } = this.currentConditions;

    if (saveData) {
      return {
        maxImageQuality: 'low',
        prefetchEnabled: false,
        lazyLoadThreshold: 0,
        maxConcurrentRequests: 2
      };
    }

    switch (effectiveType) {
      case 'slow-2g':
      case '2g':
        return {
          maxImageQuality: 'low',
          prefetchEnabled: false,
          lazyLoadThreshold: 100,
          maxConcurrentRequests: 2
        };
      
      case '3g':
        return {
          maxImageQuality: 'medium',
          prefetchEnabled: true,
          lazyLoadThreshold: 200,
          maxConcurrentRequests: 4
        };
      
      case '4g':
      default:
        return {
          maxImageQuality: 'high',
          prefetchEnabled: true,
          lazyLoadThreshold: 500,
          maxConcurrentRequests: 6
        };
    }
  }

  stop() {
    clearInterval(this.fallbackInterval);
  }
}
```

### Request Prioritization

#### Priority Queue Implementation

Implement a priority-based request queue:

```javascript
class PriorityRequestQueue {
  constructor(options = {}) {
    this.maxConcurrent = options.maxConcurrent || 6;
    this.queues = {
      critical: [],
      high: [],
      normal: [],
      low: []
    };
    this.active = new Set();
    this.completed = [];
  }

  async fetch(url, options = {}, priority = 'normal') {
    return new Promise((resolve, reject) => {
      const request = {
        url,
        options,
        priority,
        resolve,
        reject,
        timestamp: performance.now(),
        queueTime: null,
        startTime: null,
        endTime: null
      };

      this.enqueue(request);
      this.processQueue();
    });
  }

  enqueue(request) {
    if (!this.queues[request.priority]) {
      request.priority = 'normal';
    }

    this.queues[request.priority].push(request);
    request.queueTime = performance.now();
  }

  async processQueue() {
    if (this.active.size >= this.maxConcurrent) {
      return;
    }

    const request = this.dequeue();
    if (!request) return;

    this.active.add(request);
    request.startTime = performance.now();

    try {
      const response = await fetch(request.url, request.options);
      request.endTime = performance.now();
      
      this.recordTiming(request, response);
      request.resolve(response);

    } catch (error) {
      request.endTime = performance.now();
      request.error = error.message;
      
      this.recordTiming(request, null);
      request.reject(error);

    } finally {
      this.active.delete(request);
      this.processQueue(); // Process next
    }
  }

  dequeue() {
    // Priority order: critical > high > normal > low
    const priorities = ['critical', 'high', 'normal', 'low'];
    
    for (const priority of priorities) {
      if (this.queues[priority].length > 0) {
        return this.queues[priority].shift();
      }
    }

    return null;
  }

  recordTiming(request, response) {
    const timing = {
      url: request.url,
      priority: request.priority,
      queuedAt: request.timestamp,
      queueDuration: request.startTime - request.queueTime,
      requestDuration: request.endTime - request.startTime,
      totalDuration: request.endTime - request.timestamp,
      status: response?.status || null,
      error: request.error || null
    };

    this.completed.push(timing);

    // Keep only last 1000
    if (this.completed.length > 1000) {
      this.completed.shift();
    }
  }

  getStats() {
    const stats = {
      queued: Object.values(this.queues).reduce((sum, q) => sum + q.length, 0),
      active: this.active.size,
      completed: this.completed.length,
      byPriority: {}
    };

    Object.keys(this.queues).forEach(priority => {
      const priorityRequests = this.completed.filter(r => r.priority === priority);
      
      if (priorityRequests.length > 0) {
        const queueDurations = priorityRequests.map(r => r.queueDuration);
        const requestDurations = priorityRequests.map(r => r.requestDuration);

        stats.byPriority[priority] = {
          count: priorityRequests.length,
          avgQueueTime: queueDurations.reduce((sum, d) => sum + d, 0) / queueDurations.length,
          avgRequestTime: requestDurations.reduce((sum, d) => sum + d, 0) / requestDurations.length
        };
      }
    });

    return stats;
  }

  clear() {
    Object.keys(this.queues).forEach(key => {
      this.queues[key] = [];
    });
  }
}
```

#### Adaptive Concurrency Control

Dynamically adjust concurrent requests based on performance:

```javascript
class AdaptiveConcurrencyController {
  constructor(options = {}) {
    this.minConcurrent = options.minConcurrent || 2;
    this.maxConcurrent = options.maxConcurrent || 10;
    this.currentConcurrent = options.initialConcurrent || 4;
    this.queue = [];
    this.active = new Set();
    this.metrics = {
      successRate: 1.0,
      avgLatency: 0,
      recentLatencies: []
    };
  }

  async fetch(url, options = {}) {
    return new Promise((resolve, reject) => {
      const request = {
        url,
        options,
        resolve,
        reject,
        startTime: null,
        endTime: null
      };

      this.queue.push(request);
      this.processQueue();
    });
  }

  async processQueue() {
    while (this.active.size < this.currentConcurrent && this.queue.length > 0) {
      const request = this.queue.shift();
      this.executeRequest(request);
    }
  }

  async executeRequest(request) {
    this.active.add(request);
    request.startTime = performance.now();

    try {
      const response = await fetch(request.url, request.options);
      request.endTime = performance.now();
      
      this.recordSuccess(request);
      request.resolve(response);

    } catch (error) {
      request.endTime = performance.now();
      
      this.recordFailure(request);
      request.reject(error);

    } finally {
      this.active.delete(request);
      this.adjustConcurrency();
      this.processQueue();
    }
  }

  recordSuccess(request) {
    const latency = request.endTime - request.startTime;
    
    this.metrics.recentLatencies.push(latency);
    if (this.metrics.recentLatencies.length > 50) {
      this.metrics.recentLatencies.shift();
    }

    this.metrics.avgLatency = 
      this.metrics.recentLatencies.reduce((sum, l) => sum + l, 0) / 
      this.metrics.recentLatencies.length;

    // Update success rate (exponential moving average)
    this.metrics.successRate = this.metrics.successRate * 0.9 + 0.1;
  }

  recordFailure(request) {
    // Update success rate (exponential moving average)
    this.metrics.successRate = this.metrics.successRate * 0.9;
  }

  adjustConcurrency() {
    const { successRate, avgLatency, recentLatencies } = this.metrics;

    if (recentLatencies.length < 10) return; // Need more data

    // Calculate latency trend
    const recentAvg = recentLatencies.slice(-10).reduce((sum, l) => sum + l, 0) / 10;
    const olderAvg = recentLatencies.slice(-20, -10).reduce((sum, l) => sum + l, 0) / 10;

    // Increase concurrency if:
    // - Success rate is high (> 0.95)
    // - Latency is stable or improving
    // - Not at max
    if (successRate > 0.95 && 
        recentAvg <= olderAvg * 1.1 && 
        this.currentConcurrent < this.maxConcurrent) {
      this.currentConcurrent = Math.min(
        this.currentConcurrent + 1,
        this.maxConcurrent
      );
    }

    // Decrease concurrency if:
    // - Success rate is low (< 0.8)
    // - Latency is increasing
    // - Not at min
    if ((successRate < 0.8 || recentAvg > olderAvg * 1.5) && 
        this.currentConcurrent > this.minConcurrent) {
      this.currentConcurrent = Math.max(
        this.currentConcurrent - 1,
        this.minConcurrent
      );
    }
  }

  getStats() {
    return {
      currentConcurrency: this.currentConcurrent,
      queued: this.queue.length,
      active: this.active.size,
      metrics: {
        successRate: this.metrics.successRate,
        avgLatency: this.metrics.avgLatency
      }
    };
  }
}
```

### Server Timing API

#### Parsing Server-Timing Headers

Extract and analyze server-side timing information:

```javascript
class ServerTimingParser {
  parseResponse(response) {
    const serverTimingHeader = response.headers.get('Server-Timing');
    
    if (!serverTimingHeader) {
      return null;
    }

    const metrics = this.parseServerTimingHeader(serverTimingHeader);
    
    return {
      metrics,
      total: this.calculateTotal(metrics),
      breakdown: this.createBreakdown(metrics)
    };
  }

  parseServerTimingHeader(header) {
    const metrics = [];
    const entries = header.split(',').map(e => e.trim());

    for (const entry of entries) {
      const metric = this.parseEntry(entry);
      if (metric) {
        metrics.push(metric);
      }
    }

    return metrics;
  }

  parseEntry(entry) {
    // Format: name;dur=123;desc="Description"
    const parts = entry.split(';');
    const name = parts[0].trim();
    
    const metric = { name, duration: null, description: null };

    for (let i = 1; i < parts.length; i++) {
      const part = parts[i].trim();
      
      if (part.startsWith('dur=')) {
        metric.duration = parseFloat(part.substring(4));
      } else if (part.startsWith('desc=')) {
        metric.description = part.substring(5).replace(/^"|"$/g, '');
      }
    }

    return metric;
  }

  calculateTotal(metrics) {
    return metrics.reduce((sum, m) => sum + (m.duration || 0), 0);
  }

  createBreakdown(metrics) {
    const breakdown = {};
    
    for (const metric of metrics) {
      breakdown[metric.name] = {
        duration: metric.duration,
        description: metric.description
      };
    }

    return breakdown;
  }

  async fetchWithServerTiming(url, options = {}) {
    const clientStart = performance.now();
    const response = await fetch(url, options);
    const clientEnd = performance.now();

    const serverTiming = this.parseResponse(response);

    return {
      response,
      timing: {
        client: {
          total: clientEnd - clientStart,
          start: clientStart,
          end: clientEnd
        },
        server: serverTiming
      }
    };
  }
}
```

#### Combined Client-Server Analysis

Correlate client-side and server-side timing:

```javascript
class FullStackTimingAnalyzer {
  constructor() {
    this.parser = new ServerTimingParser();
    this.measurements = [];
  }

  async fetch(url, options = {}) {
    const measurement = {
      url,
      client: {},
      server: {},
      network: {}
    };

    // Client timing
    const clientStart = performance.now();
    measurement.client.queueStart = clientStart;

    try {
      const response = await fetch(url, options);
      const headersReceived = performance.now();
      measurement.client.headersReceived = headersReceived;

      // Parse server timing
      const serverTiming = this.parser.parseResponse(response);
      measurement.server = serverTiming;

      // Read body
      const data = await response.json();
      const clientEnd = performance.now();
      measurement.client.bodyReceived = clientEnd;

      // Calculate network overhead
      this.calculateNetworkOverhead(measurement);

      this.measurements.push(measurement);

      return {
        data,
        response,
        timing: measurement
      };

    } catch (error) {
      measurement.client.error = error.message;
      measurement.client.errorTime = performance.now();
      
      this.measurements.push(measurement);
      throw error;
    }
  }

  calculateNetworkOverhead(measurement) {
    const clientTotal = measurement.client.bodyReceived - measurement.client.queueStart;
    const serverTotal = measurement.server?.total || 0;

    measurement.network = {
      totalRoundTrip: clientTotal,
      serverProcessing: serverTotal,
      networkOverhead: clientTotal - serverTotal,
      overheadPercentage: serverTotal > 0 
        ? ((clientTotal - serverTotal) / clientTotal * 100).toFixed(2) 
        : null
    };
  }

  analyzeBottlenecks() {
    if (this.measurements.length === 0) return null;

    const analysis = {
      serverBottlenecks: [],
      networkBottlenecks: [],
      clientBottlenecks: []
    };

    for (const measurement of this.measurements) {
      const { server, network, client } = measurement;

      // Server bottleneck: server time > 50% of total
      if (server?.total && network.overheadPercentage < 50) {
        analysis.serverBottlenecks.push({
          url: measurement.url,
          serverTime: server.total,
          percentage: 100 - parseFloat(network.overheadPercentage)
        });
      }

      // Network bottleneck: network time > 70% of total
      if (network.overheadPercentage > 70) {
        analysis.networkBottlenecks.push({
          url: measurement.url,
          networkTime: network.networkOverhead,
          percentage: parseFloat(network.overheadPercentage)
        });
      }

      // Client bottleneck: body parsing takes significant time
      const parsingTime = client.bodyReceived - client.headersReceived;
      if (parsingTime > 100) {
        analysis.clientBottlenecks.push({
          url: measurement.url,
          parsingTime
        });
      }
    }

    return analysis;
  }

  getRecommendations() {
    const bottlenecks = this.analyzeBottlenecks();
    const recommendations = [];

    if (bottlenecks.serverBottlenecks.length > 0) {
      recommendations.push({
        type: 'server-optimization',
        priority: 'high',
        message: 'Server processing time is high. Consider database query optimization, caching, or scaling.',
        affectedRequests: bottlenecks.serverBottlenecks.length
      });
    }

    if (bottlenecks.networkBottlenecks.length > 0) {
      recommendations.push({
        type: 'network-optimization',
        priority: 'high',
        message: 'Network latency is high. Consider using CDN, compression, or reducing payload size.',
        affectedRequests: bottlenecks.networkBottlenecks.length
      });
    }

    if (bottlenecks.clientBottlenecks.length > 0) {
      recommendations.push({
        type: 'client-optimization',
        priority: 'medium',
        message: 'Client-side parsing is slow. Consider streaming responses or using more efficient data formats.',
        affectedRequests: bottlenecks.clientBottlenecks.length
      });
    }

    return recommendations;
  }

  reset() {
    this.measurements = [];
  }
}
```

---

## Success/Failure Tracking

### Response Status Detection

#### HTTP Status Code Analysis

```javascript
async function fetchWithStatusTracking(url) {
  try {
    const response = await fetch(url);
    
    // Track successful HTTP responses (2xx)
    if (response.ok) {
      console.log(`Success: ${response.status} ${response.statusText}`);
      return await response.json();
    }
    
    // Track client errors (4xx)
    if (response.status >= 400 && response.status < 500) {
      console.error(`Client Error: ${response.status}`);
      throw new Error(`Client error: ${response.status}`);
    }
    
    // Track server errors (5xx)
    if (response.status >= 500) {
      console.error(`Server Error: ${response.status}`);
      throw new Error(`Server error: ${response.status}`);
    }
    
    // Track other status codes
    console.warn(`Unexpected status: ${response.status}`);
    throw new Error(`Unexpected status: ${response.status}`);
  } catch (error) {
    console.error('Request failed:', error);
    throw error;
  }
}
```

#### Granular Status Code Tracking

```javascript
class StatusTracker {
  constructor() {
    this.stats = {
      '2xx': 0,
      '3xx': 0,
      '4xx': 0,
      '5xx': 0,
      specific: {}
    };
  }

  trackResponse(response) {
    const status = response.status;
    const category = `${Math.floor(status / 100)}xx`;
    
    this.stats[category]++;
    this.stats.specific[status] = (this.stats.specific[status] || 0) + 1;
    
    return {
      status,
      category,
      ok: response.ok,
      timestamp: Date.now()
    };
  }

  getStats() {
    return {
      ...this.stats,
      total: Object.values(this.stats.specific).reduce((a, b) => a + b, 0),
      successRate: this.calculateSuccessRate()
    };
  }

  calculateSuccessRate() {
    const total = this.stats['2xx'] + this.stats['3xx'] + 
                  this.stats['4xx'] + this.stats['5xx'];
    return total > 0 ? (this.stats['2xx'] / total) * 100 : 0;
  }
}

const tracker = new StatusTracker();

async function trackedFetch(url) {
  const response = await fetch(url);
  const statusInfo = tracker.trackResponse(response);
  console.log('Status tracked:', statusInfo);
  return response;
}
```

### Network Error Detection

#### Connection Failures

```javascript
async function fetchWithNetworkTracking(url) {
  const startTime = Date.now();
  
  try {
    const response = await fetch(url);
    const duration = Date.now() - startTime;
    
    console.log(`Request succeeded in ${duration}ms`);
    return response;
  } catch (error) {
    const duration = Date.now() - startTime;
    
    // Track different network error types
    if (error instanceof TypeError) {
      console.error('Network failure:', {
        type: 'NetworkError',
        message: error.message,
        duration,
        possibleCauses: ['No internet', 'DNS failure', 'CORS issue', 'Blocked request']
      });
    } else if (error.name === 'AbortError') {
      console.error('Request aborted:', { duration });
    } else {
      console.error('Unknown error:', error);
    }
    
    throw error;
  }
}
```

#### Timeout Detection

```javascript
async function fetchWithTimeout(url, timeout = 5000) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  const startTime = Date.now();
  
  try {
    const response = await fetch(url, { signal: controller.signal });
    const duration = Date.now() - startTime;
    
    clearTimeout(timeoutId);
    console.log(`Request completed in ${duration}ms`);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    const duration = Date.now() - startTime;
    
    if (error.name === 'AbortError') {
      console.error('Request timeout:', {
        url,
        timeout,
        duration
      });
      throw new Error(`Request timeout after ${timeout}ms`);
    }
    
    throw error;
  }
}
```

### Comprehensive Tracking System

#### Multi-Metric Tracker

```javascript
class RequestTracker {
  constructor() {
    this.requests = [];
    this.metrics = {
      total: 0,
      successful: 0,
      failed: 0,
      timedOut: 0,
      aborted: 0,
      networkErrors: 0,
      totalDuration: 0
    };
  }

  async track(url, options = {}) {
    const requestId = this.generateId();
    const startTime = Date.now();
    
    const request = {
      id: requestId,
      url,
      startTime,
      status: 'pending'
    };
    
    this.requests.push(request);
    this.metrics.total++;

    try {
      const response = await fetch(url, options);
      const duration = Date.now() - startTime;
      
      request.status = 'completed';
      request.httpStatus = response.status;
      request.ok = response.ok;
      request.duration = duration;
      request.endTime = Date.now();
      
      this.metrics.totalDuration += duration;
      
      if (response.ok) {
        this.metrics.successful++;
      } else {
        this.metrics.failed++;
      }
      
      return response;
    } catch (error) {
      const duration = Date.now() - startTime;
      
      request.status = 'failed';
      request.error = error.message;
      request.errorType = error.name;
      request.duration = duration;
      request.endTime = Date.now();
      
      this.metrics.totalDuration += duration;
      
      if (error.name === 'AbortError') {
        this.metrics.aborted++;
      } else if (error instanceof TypeError) {
        this.metrics.networkErrors++;
      } else {
        this.metrics.failed++;
      }
      
      throw error;
    }
  }

  generateId() {
    return `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  getMetrics() {
    const avgDuration = this.metrics.total > 0 
      ? this.metrics.totalDuration / this.metrics.total 
      : 0;
    
    return {
      ...this.metrics,
      averageDuration: Math.round(avgDuration),
      successRate: this.metrics.total > 0 
        ? (this.metrics.successful / this.metrics.total * 100).toFixed(2) 
        : 0,
      failureRate: this.metrics.total > 0 
        ? (this.metrics.failed / this.metrics.total * 100).toFixed(2) 
        : 0
    };
  }

  getRecentRequests(limit = 10) {
    return this.requests.slice(-limit);
  }

  getFailedRequests() {
    return this.requests.filter(req => req.status === 'failed');
  }

  reset() {
    this.requests = [];
    this.metrics = {
      total: 0,
      successful: 0,
      failed: 0,
      timedOut: 0,
      aborted: 0,
      networkErrors: 0,
      totalDuration: 0
    };
  }
}

// Usage
const tracker = new RequestTracker();

async function makeTrackedRequest(url) {
  try {
    const response = await tracker.track(url);
    console.log('Metrics:', tracker.getMetrics());
    return response;
  } catch (error) {
    console.error('Request failed');
    console.log('Failed requests:', tracker.getFailedRequests());
  }
}
```

### Response Validation

#### Content Type Validation

```javascript
async function fetchWithContentValidation(url, expectedType = 'application/json') {
  try {
    const response = await fetch(url);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    const contentType = response.headers.get('content-type');
    
    if (!contentType || !contentType.includes(expectedType)) {
      console.error('Content type mismatch:', {
        expected: expectedType,
        received: contentType,
        url
      });
      throw new Error(`Expected ${expectedType}, got ${contentType}`);
    }
    
    console.log('Content type validated:', contentType);
    return response;
  } catch (error) {
    console.error('Validation failed:', error);
    throw error;
  }
}
```

#### Response Body Validation

```javascript
async function fetchWithBodyValidation(url, validator) {
  try {
    const response = await fetch(url);
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    const data = await response.json();
    
    if (validator && !validator(data)) {
      console.error('Response validation failed:', {
        url,
        data
      });
      throw new Error('Response body validation failed');
    }
    
    console.log('Response validated successfully');
    return data;
  } catch (error) {
    if (error instanceof SyntaxError) {
      console.error('JSON parse error:', error);
      throw new Error('Invalid JSON response');
    }
    throw error;
  }
}

// Usage
await fetchWithBodyValidation('/api/user', (data) => {
  return data && typeof data.id === 'number' && typeof data.name === 'string';
});
```

### Retry Tracking

#### Retry Counter Implementation

```javascript
class RetryTracker {
  constructor(maxRetries = 3) {
    this.maxRetries = maxRetries;
    this.attempts = new Map();
  }

  async fetch(url, options = {}) {
    const key = `${url}:${JSON.stringify(options)}`;
    
    if (!this.attempts.has(key)) {
      this.attempts.set(key, {
        count: 0,
        failures: [],
        lastAttempt: null
      });
    }
    
    const attempt = this.attempts.get(key);
    
    for (let i = 0; i <= this.maxRetries; i++) {
      attempt.count++;
      attempt.lastAttempt = Date.now();
      
      try {
        console.log(`Attempt ${i + 1}/${this.maxRetries + 1} for ${url}`);
        const response = await fetch(url, options);
        
        if (response.ok) {
          console.log(`Success on attempt ${i + 1}`);
          this.attempts.delete(key);
          return response;
        }
        
        attempt.failures.push({
          attempt: i + 1,
          status: response.status,
          timestamp: Date.now()
        });
        
        if (i === this.maxRetries) {
          throw new Error(`Max retries (${this.maxRetries}) exceeded`);
        }
        
        await this.delay(Math.pow(2, i) * 1000);
      } catch (error) {
        attempt.failures.push({
          attempt: i + 1,
          error: error.message,
          timestamp: Date.now()
        });
        
        if (i === this.maxRetries) {
          console.error(`All ${this.maxRetries + 1} attempts failed for ${url}`);
          throw error;
        }
        
        await this.delay(Math.pow(2, i) * 1000);
      }
    }
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  getAttemptHistory() {
    return Array.from(this.attempts.entries()).map(([key, data]) => ({
      request: key,
      ...data
    }));
  }
}
```

### Success Rate Monitoring

#### Time-Window Success Rate

```javascript
class SuccessRateMonitor {
  constructor(windowSize = 60000) { // 1 minute window
    this.windowSize = windowSize;
    this.events = [];
  }

  recordSuccess(url, duration) {
    this.events.push({
      url,
      success: true,
      timestamp: Date.now(),
      duration
    });
    this.cleanup();
  }

  recordFailure(url, error) {
    this.events.push({
      url,
      success: false,
      timestamp: Date.now(),
      error: error.message
    });
    this.cleanup();
  }

  cleanup() {
    const cutoff = Date.now() - this.windowSize;
    this.events = this.events.filter(e => e.timestamp > cutoff);
  }

  getSuccessRate(url = null) {
    this.cleanup();
    
    const filtered = url 
      ? this.events.filter(e => e.url === url)
      : this.events;
    
    if (filtered.length === 0) return 100;
    
    const successful = filtered.filter(e => e.success).length;
    return (successful / filtered.length) * 100;
  }

  getStats(url = null) {
    this.cleanup();
    
    const filtered = url 
      ? this.events.filter(e => e.url === url)
      : this.events;
    
    const successful = filtered.filter(e => e.success);
    const failed = filtered.filter(e => !e.success);
    
    const durations = successful.map(e => e.duration).filter(d => d !== undefined);
    const avgDuration = durations.length > 0
      ? durations.reduce((a, b) => a + b, 0) / durations.length
      : 0;
    
    return {
      total: filtered.length,
      successful: successful.length,
      failed: failed.length,
      successRate: this.getSuccessRate(url),
      avgDuration: Math.round(avgDuration),
      timeWindow: this.windowSize
    };
  }
}

// Usage with fetch
const monitor = new SuccessRateMonitor();

async function monitoredFetch(url) {
  const startTime = Date.now();
  
  try {
    const response = await fetch(url);
    const duration = Date.now() - startTime;
    
    if (response.ok) {
      monitor.recordSuccess(url, duration);
    } else {
      monitor.recordFailure(url, new Error(`HTTP ${response.status}`));
    }
    
    return response;
  } catch (error) {
    monitor.recordFailure(url, error);
    throw error;
  }
}
```

### Error Categorization

#### Structured Error Tracking

```javascript
class ErrorCategorizer {
  constructor() {
    this.errors = {
      network: [],
      http: [],
      timeout: [],
      abort: [],
      parse: [],
      validation: [],
      unknown: []
    };
  }

  categorize(error, context = {}) {
    const errorEntry = {
      message: error.message,
      timestamp: Date.now(),
      ...context
    };

    if (error.name === 'AbortError') {
      this.errors.abort.push(errorEntry);
      return 'abort';
    }
    
    if (error.name === 'TimeoutError' || error.message.includes('timeout')) {
      this.errors.timeout.push(errorEntry);
      return 'timeout';
    }
    
    if (error instanceof TypeError) {
      this.errors.network.push(errorEntry);
      return 'network';
    }
    
    if (error instanceof SyntaxError) {
      this.errors.parse.push(errorEntry);
      return 'parse';
    }
    
    if (error.message.includes('HTTP')) {
      this.errors.http.push(errorEntry);
      return 'http';
    }
    
    if (error.message.includes('validation')) {
      this.errors.validation.push(errorEntry);
      return 'validation';
    }
    
    this.errors.unknown.push(errorEntry);
    return 'unknown';
  }

  getErrorStats() {
    return Object.entries(this.errors).map(([category, errors]) => ({
      category,
      count: errors.length,
      recent: errors.slice(-5)
    }));
  }

  getMostCommonError() {
    const counts = Object.entries(this.errors).map(([category, errors]) => ({
      category,
      count: errors.length
    }));
    
    return counts.sort((a, b) => b.count - a.count)[0];
  }
}

// Usage
const categorizer = new ErrorCategorizer();

async function categorizedFetch(url) {
  try {
    const response = await fetch(url);
    
    if (!response.ok) {
      const error = new Error(`HTTP ${response.status}`);
      categorizer.categorize(error, { url, status: response.status });
      throw error;
    }
    
    return response;
  } catch (error) {
    const category = categorizer.categorize(error, { url });
    console.error(`${category} error:`, error.message);
    throw error;
  }
}
```

### Latency Tracking

#### Performance Timing

```javascript
class LatencyTracker {
  constructor() {
    this.measurements = [];
    this.buckets = {
      fast: 0,      // < 100ms
      medium: 0,    // 100-500ms
      slow: 0,      // 500-2000ms
      verySlow: 0   // > 2000ms
    };
  }

  async trackFetch(url, options = {}) {
    const timings = {
      start: performance.now(),
      dnsStart: null,
      connectStart: null,
      requestStart: null,
      responseStart: null,
      responseEnd: null
    };
    
    try {
      const response = await fetch(url, options);
      timings.responseEnd = performance.now();
      
      const duration = timings.responseEnd - timings.start;
      
      this.recordMeasurement({
        url,
        duration,
        timestamp: Date.now()
      });
      
      this.categorizeDuration(duration);
      
      // Try to get detailed timing if available
      if (window.performance) {
        const entries = performance.getEntriesByType('resource');
        const entry = entries.find(e => e.name === url);
        
        if (entry) {
          timings.dnsStart = entry.domainLookupStart;
          timings.connectStart = entry.connectStart;
          timings.requestStart = entry.requestStart;
          timings.responseStart = entry.responseStart;
        }
      }
      
      return { response, timings, duration };
    } catch (error) {
      timings.responseEnd = performance.now();
      const duration = timings.responseEnd - timings.start;
      
      this.recordMeasurement({
        url,
        duration,
        error: error.message,
        timestamp: Date.now()
      });
      
      throw error;
    }
  }

  recordMeasurement(measurement) {
    this.measurements.push(measurement);
    if (this.measurements.length > 1000) {
      this.measurements.shift();
    }
  }

  categorizeDuration(duration) {
    if (duration < 100) {
      this.buckets.fast++;
    } else if (duration < 500) {
      this.buckets.medium++;
    } else if (duration < 2000) {
      this.buckets.slow++;
    } else {
      this.buckets.verySlow++;
    }
  }

  getStats() {
    const durations = this.measurements
      .filter(m => !m.error)
      .map(m => m.duration);
    
    if (durations.length === 0) {
      return {
        count: 0,
        avg: 0,
        min: 0,
        max: 0,
        p50: 0,
        p95: 0,
        p99: 0
      };
    }
    
    durations.sort((a, b) => a - b);
    
    return {
      count: durations.length,
      avg: durations.reduce((a, b) => a + b, 0) / durations.length,
      min: durations[0],
      max: durations[durations.length - 1],
      p50: this.percentile(durations, 50),
      p95: this.percentile(durations, 95),
      p99: this.percentile(durations, 99),
      distribution: this.buckets
    };
  }

  percentile(sorted, p) {
    const index = Math.ceil((p / 100) * sorted.length) - 1;
    return sorted[index];
  }
}
```

### Batch Request Tracking

#### Parallel Request Monitoring

```javascript
class BatchTracker {
  constructor() {
    this.batches = [];
  }

  async trackBatch(requests) {
    const batchId = this.generateBatchId();
    const startTime = Date.now();
    
    const batch = {
      id: batchId,
      startTime,
      requests: requests.map((r, i) => ({
        id: i,
        url: r.url,
        status: 'pending'
      })),
      totalRequests: requests.length,
      completed: 0,
      failed: 0
    };
    
    this.batches.push(batch);
    
    const results = await Promise.allSettled(
      requests.map(async (req, index) => {
        try {
          const response = await fetch(req.url, req.options);
          
          batch.requests[index].status = response.ok ? 'success' : 'failed';
          batch.requests[index].httpStatus = response.status;
          batch.requests[index].duration = Date.now() - startTime;
          
          if (response.ok) {
            batch.completed++;
          } else {
            batch.failed++;
          }
          
          return { index, response, success: response.ok };
        } catch (error) {
          batch.requests[index].status = 'error';
          batch.requests[index].error = error.message;
          batch.requests[index].duration = Date.now() - startTime;
          batch.failed++;
          
          return { index, error, success: false };
        }
      })
    );
    
    batch.endTime = Date.now();
    batch.totalDuration = batch.endTime - batch.startTime;
    batch.successRate = (batch.completed / batch.totalRequests) * 100;
    
    return {
      batchId,
      results,
      stats: this.getBatchStats(batchId)
    };
  }

  generateBatchId() {
    return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  getBatchStats(batchId) {
    const batch = this.batches.find(b => b.id === batchId);
    if (!batch) return null;
    
    return {
      id: batch.id,
      totalRequests: batch.totalRequests,
      completed: batch.completed,
      failed: batch.failed,
      successRate: batch.successRate,
      totalDuration: batch.totalDuration,
      requests: batch.requests
    };
  }

  getAllBatchStats() {
    return this.batches.map(batch => ({
      id: batch.id,
      totalRequests: batch.totalRequests,
      completed: batch.completed,
      failed: batch.failed,
      successRate: batch.successRate,
      totalDuration: batch.totalDuration
    }));
  }
}

// Usage
const batchTracker = new BatchTracker();

const requests = [
  { url: '/api/user/1' },
  { url: '/api/user/2' },
  { url: '/api/user/3' }
];

const { batchId, results, stats } = await batchTracker.trackBatch(requests);
console.log('Batch completed:', stats);
```

### Circuit Breaker Pattern

#### Failure Threshold Tracking

```javascript
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.threshold = threshold;
    this.timeout = timeout;
    this.failures = 0;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.nextAttempt = null;
    this.successCount = 0;
    this.failureCount = 0;
  }

  async fetch(url, options = {}) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        console.error('Circuit breaker OPEN - request blocked');
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
      console.log('Circuit breaker entering HALF_OPEN state');
    }

    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        this.onSuccess();
        return response;
      } else {
        this.onFailure();
        throw new Error(`HTTP ${response.status}`);
      }
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  onSuccess() {
    this.failures = 0;
    this.successCount++;
    
    if (this.state === 'HALF_OPEN') {
      console.log('Circuit breaker CLOSED after successful request');
      this.state = 'CLOSED';
    }
  }

  onFailure() {
    this.failures++;
    this.failureCount++;
    
    if (this.failures >= this.threshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.timeout;
      console.error(`Circuit breaker OPEN after ${this.failures} failures`);
    }
  }

  getStatus() {
    return {
      state: this.state,
      failures: this.failures,
      threshold: this.threshold,
      successCount: this.successCount,
      failureCount: this.failureCount,
      nextAttempt: this.state === 'OPEN' ? this.nextAttempt : null
    };
  }

  reset() {
    this.failures = 0;
    this.state = 'CLOSED';
    this.nextAttempt = null;
  }
}
```

### Health Check Monitoring

#### Endpoint Health Tracking

```javascript
class HealthMonitor {
  constructor(checkInterval = 30000) {
    this.checkInterval = checkInterval;
    this.endpoints = new Map();
    this.intervalId = null;
  }

  registerEndpoint(name, url, options = {}) {
    this.endpoints.set(name, {
      url,
      options,
      status: 'unknown',
      lastCheck: null,
      lastSuccess: null,
      consecutiveFailures: 0,
      totalChecks: 0,
      successfulChecks: 0,
      history: []
    });
  }

  async checkHealth(name) {
    const endpoint = this.endpoints.get(name);
    if (!endpoint) return null;

    const startTime = Date.now();
    endpoint.totalChecks++;

    try {
      const response = await fetch(endpoint.url, {
        ...endpoint.options,
        signal: AbortSignal.timeout(5000)
      });

      const duration = Date.now() - startTime;
      const isHealthy = response.ok;

      endpoint.lastCheck = Date.now();
      endpoint.status = isHealthy ? 'healthy' : 'unhealthy';
      
      if (isHealthy) {
        endpoint.lastSuccess = Date.now();
        endpoint.consecutiveFailures = 0;
        endpoint.successfulChecks++;
      } else {
        endpoint.consecutiveFailures++;
      }

      const check = {
        timestamp: Date.now(),
        healthy: isHealthy,
        status: response.status,
        duration
      };

      endpoint.history.push(check);
      if (endpoint.history.length > 100) {
        endpoint.history.shift();
      }

      return check;
    } catch (error) {
      const duration = Date.now() - startTime;
      
      endpoint.lastCheck = Date.now();
      endpoint.status = 'down';
      endpoint.consecutiveFailures++;

      const check = {
        timestamp: Date.now(),
        healthy: false,
        error: error.message,
        duration
      };

      endpoint.history.push(check);
      if (endpoint.history.length > 100) {
        endpoint.history.shift();
      }

      return check;
    }
  }

  async checkAll() {
    const results = {};
    
    for (const [name, _] of this.endpoints) {
      results[name] = await this.checkHealth(name);
    }
    
    return results;
  }

  startMonitoring() {
    if (this.intervalId) return;
    
    this.intervalId = setInterval(() => {
      this.checkAll();
    }, this.checkInterval);
    
    // Initial check
    this.checkAll();
  }

  stopMonitoring() {
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }

  getEndpointStatus(name) {
    const endpoint = this.endpoints.get(name);
    if (!endpoint) return null;

    const uptime = endpoint.totalChecks > 0
      ? (endpoint.successfulChecks / endpoint.totalChecks) * 100
      : 0;

    return {
      name,
      status: endpoint.status,
      lastCheck: endpoint.lastCheck,
      lastSuccess: endpoint.lastSuccess,
      consecutiveFailures: endpoint.consecutiveFailures,
      uptime: uptime.toFixed(2),
      totalChecks: endpoint.totalChecks,
      successfulChecks: endpoint.successfulChecks,
      recentHistory: endpoint.history.slice(-10)
    };
  }

  getAllStatuses() {
    return Array.from(this.endpoints.keys()).map(name => 
      this.getEndpointStatus(name)
    );
  }
}

// Usage
const monitor = new HealthMonitor(30000);
monitor.registerEndpoint('api', '/api/health');
monitor.registerEndpoint('auth', '/auth/health');
monitor.startMonitoring();

// Get status at any time
const apiStatus = monitor.getEndpointStatus('api');
console.log('API Health:', apiStatus);
```

### Logging Integration

#### Structured Logging

```javascript
class FetchLogger {
  constructor(logLevel = 'info') {
    this.logLevel = logLevel;
    this.levels = { debug: 0, info: 1, warn: 2, error: 3 };
    this.logs = [];
  }

  shouldLog(level) {
    return this.levels[level] >= this.levels[this.logLevel];
  }

  log(level, message, context = {}) {
    if (!this.shouldLog(level)) return;

    const entry = {
      level,
      message,
      timestamp: new Date().toISOString(),
      ...context
    };

    this.logs.push(entry);
    
    // Keep only last 1000 logs
    if (this.logs.length > 1000) {
      this.logs.shift();
    }

    const method = console[level] || console.log;
    method(`[${entry.timestamp}] ${level.toUpperCase()}: ${message}`, context);
  }

  async fetch(url, options = {}) {
    const requestId = this.generateId();
    const startTime = Date.now();

    this.log('info', 'Request started', {
      requestId,
      url,
      method: options.method || 'GET'
    });

    try {
      const response = await fetch(url, options);
      const duration = Date.now() - startTime;

      if (response.ok) {
        this.log('info', 'Request succeeded', {
          requestId,
          url,
          status: response.status,
          duration
        });
      } else {
        this.log('warn', 'Request returned error status', {
          requestId,
          url,
          status: response.status,
          statusText: response.statusText,
          duration
        });
      }

      return response;
    } catch (error) {
      const duration = Date.now() - startTime;

      this.log('error', 'Request failed', {
        requestId,
        url,
        error: error.message,
        errorType: error.name,
        duration
      });

      throw error;
    }
  }

  generateId() {
    return Math.random().toString(36).substr(2, 9);
  }

  getLogs(level = null) {
    if (level) {
      return this.logs.filter(log => log.level === level);
    }
    return this.logs;
  }

  getErrorLogs() {
    return this.logs.filter(log => log.level === 'error');
  }

  clear() {
    this.logs = [];
  }
}
```

### Real-Time Dashboard

#### Live Metrics Display

```javascript
class FetchDashboard {
  constructor() {
    this.metrics = {
      requests: {
        total: 0,
        successful: 0,
        failed: 0,
        pending: 0
      },
      latency: {
        current: 0,
        average: 0,
        min: Infinity,
        max: 0,
        history: []
      },
      errors: {
        network: 0,
        timeout: 0,
        http4xx: 0,
        http5xx: 0
      },
      successRate: 100,
      lastUpdate: null
    };
    
    this.subscribers = new Set();
  }

  subscribe(callback) {
    this.subscribers.add(callback);
    return () => this.subscribers.delete(callback);
  }

  notify() {
    this.subscribers.forEach(callback => {
      try {
        callback(this.getMetrics());
      } catch (error) {
        console.error('Dashboard subscriber error:', error);
      }
    });
  }

  async track(url, options = {}) {
    this.metrics.requests.pending++;
    this.metrics.requests.total++;
    this.notify();

    const startTime = Date.now();

    try {
      const response = await fetch(url, options);
      const latency = Date.now() - startTime;

      this.metrics.requests.pending--;
      this.updateLatency(latency);

      if (response.ok) {
        this.metrics.requests.successful++;
      } else {
        this.metrics.requests.failed++;
        
        if (response.status >= 400 && response.status < 500) {
          this.metrics.errors.http4xx++;
        } else if (response.status >= 500) {
          this.metrics.errors.http5xx++;
        }
      }

      this.updateSuccessRate();
      this.metrics.lastUpdate = Date.now();
      this.notify();

      return response;
    } catch (error) {
      const latency = Date.now() - startTime;

      this.metrics.requests.pending--;
      this.metrics.requests.failed++;
      this.updateLatency(latency);

      if (error.name === 'AbortError') {
        this.metrics.errors.timeout++;
      } else if (error instanceof TypeError) {
        this.metrics.errors.network++;
      }

      this.updateSuccessRate();
      this.metrics.lastUpdate = Date.now();
      this.notify();

      throw error;
    }
  }

  updateLatency(latency) {
    this.metrics.latency.current = latency;
    this.metrics.latency.min = Math.min(this.metrics.latency.min, latency);
    this.metrics.latency.max = Math.max(this.metrics.latency.max, latency);
    
    this.metrics.latency.history.push(latency);
    if (this.metrics.latency.history.length > 100) {
      this.metrics.latency.history.shift();
    }

    this.metrics.latency.average = 
      this.metrics.latency.history.reduce((a, b) => a + b, 0) / 
      this.metrics.latency.history.length;
  }

  updateSuccessRate() {
    const total = this.metrics.requests.successful + this.metrics.requests.failed;
    this.metrics.successRate = total > 0 
      ? (this.metrics.requests.successful / total) * 100 
      : 100;
  }

  getMetrics() {
    return JSON.parse(JSON.stringify(this.metrics));
  }

  reset() {
    this.metrics = {
      requests: { total: 0, successful: 0, failed: 0, pending: 0 },
      latency: { current: 0, average: 0, min: Infinity, max: 0, history: [] },
      errors: { network: 0, timeout: 0, http4xx: 0, http5xx: 0 },
      successRate: 100,
      lastUpdate: null
    };
    this.notify();
  }
}

// Usage
const dashboard = new FetchDashboard();

// Subscribe to updates
dashboard.subscribe((metrics) => {
  console.log('Dashboard updated:', metrics);
  // Update UI with metrics
});

// Make tracked requests
await dashboard.track('/api/data');
```

### Alerting System

#### Threshold-Based Alerts

```javascript
class FetchAlertSystem {
  constructor() {
    this.thresholds = {
      errorRate: 10,        // Percentage
      latency: 2000,        // Milliseconds
      failureStreak: 5,     // Consecutive failures
      successRate: 90       // Percentage
    };
    
    this.state = {
      errorCount: 0,
      totalRequests: 0,
      failureStreak: 0,
      recentLatencies: []
    };
    
    this.alerts = [];
    this.handlers = new Set();
  }

  onAlert(handler) {
    this.handlers.add(handler);
    return () => this.handlers.delete(handler);
  }

  triggerAlert(type, message, severity = 'warning', data = {}) {
    const alert = {
      type,
      message,
      severity,
      timestamp: Date.now(),
      data
    };
    
    this.alerts.push(alert);
    
    this.handlers.forEach(handler => {
      try {
        handler(alert);
      } catch (error) {
        console.error('Alert handler error:', error);
      }
    });
    
    return alert;
  }

  async track(url, options = {}) {
    const startTime = Date.now();
    this.state.totalRequests++;

    try {
      const response = await fetch(url, options);
      const latency = Date.now() - startTime;

      this.state.recentLatencies.push(latency);
      if (this.state.recentLatencies.length > 20) {
        this.state.recentLatencies.shift();
      }

      if (!response.ok) {
        this.state.errorCount++;
        this.state.failureStreak++;
        this.checkThresholds();
      } else {
        this.state.failureStreak = 0;
      }

      if (latency > this.thresholds.latency) {
        this.triggerAlert(
          'high_latency',
          `Request exceeded latency threshold: ${latency}ms`,
          'warning',
          { url, latency, threshold: this.thresholds.latency }
        );
      }

      return response;
    } catch (error) {
      this.state.errorCount++;
      this.state.failureStreak++;
      this.checkThresholds();

      this.triggerAlert(
        'request_failure',
        `Request failed: ${error.message}`,
        'error',
        { url, error: error.message }
      );

      throw error;
    }
  }

  checkThresholds() {
    const errorRate = (this.state.errorCount / this.state.totalRequests) * 100;
    
    if (errorRate > this.thresholds.errorRate) {
      this.triggerAlert(
        'high_error_rate',
        `Error rate exceeded threshold: ${errorRate.toFixed(2)}%`,
        'critical',
        { errorRate, threshold: this.thresholds.errorRate }
      );
    }

    if (this.state.failureStreak >= this.thresholds.failureStreak) {
      this.triggerAlert(
        'failure_streak',
        `${this.state.failureStreak} consecutive failures detected`,
        'critical',
        { streak: this.state.failureStreak }
      );
    }

    const successRate = ((this.state.totalRequests - this.state.errorCount) / 
                        this.state.totalRequests) * 100;
    
    if (successRate < this.thresholds.successRate) {
      this.triggerAlert(
        'low_success_rate',
        `Success rate below threshold: ${successRate.toFixed(2)}%`,
        'warning',
        { successRate, threshold: this.thresholds.successRate }
      );
    }
  }

  getRecentAlerts(count = 10) {
    return this.alerts.slice(-count);
  }

  getCriticalAlerts() {
    return this.alerts.filter(a => a.severity === 'critical');
  }

  clearAlerts() {
    this.alerts = [];
  }

  resetState() {
    this.state = {
      errorCount: 0,
      totalRequests: 0,
      failureStreak: 0,
      recentLatencies: []
    };
  }
}

// Usage
const alertSystem = new FetchAlertSystem();

alertSystem.onAlert((alert) => {
  console.error(`[${alert.severity.toUpperCase()}] ${alert.message}`);
  
  if (alert.severity === 'critical') {
    // Send notification, page admin, etc.
  }
});

await alertSystem.track('/api/data');
```

---

## Fetch API Performance Metrics

### Resource Timing API Integration

The Fetch API integrates with the Resource Timing API through `PerformanceResourceTiming` entries, automatically captured for every fetch request. Access these entries via:

```javascript
const entries = performance.getEntriesByType('resource');
const fetchEntries = entries.filter(e => e.initiatorType === 'fetch');
```

Alternatively, use `PerformanceObserver` for real-time monitoring:

```javascript
const observer = new PerformanceObserver((list) => {
  list.getEntries().forEach((entry) => {
    if (entry.initiatorType === 'fetch') {
      console.log(entry);
    }
  });
});
observer.observe({ entryTypes: ['resource'] });
```

### Key Timing Metrics

#### DNS Resolution Time

Time spent resolving the domain name to an IP address:

```javascript
const dnsTime = entry.domainLookupEnd - entry.domainLookupStart;
```

Zero values indicate cached DNS or same-origin requests.

#### TCP Connection Time

Time to establish TCP connection:

```javascript
const tcpTime = entry.connectEnd - entry.connectStart;
```

#### TLS Negotiation Time

For HTTPS requests, measure TLS handshake duration:

```javascript
const tlsTime = entry.connectEnd - entry.secureConnectionStart;
```

`secureConnectionStart` is zero for non-HTTPS requests.

#### Request Time

Time from request initiation to first byte received (TTFB):

```javascript
const requestTime = entry.responseStart - entry.requestStart;
```

This includes network latency and server processing time.

#### Response Time

Time to download the complete response body:

```javascript
const responseTime = entry.responseEnd - entry.responseStart;
```

#### Total Duration

End-to-end request duration:

```javascript
const totalTime = entry.responseEnd - entry.fetchStart;
```

Or use the convenience property:

```javascript
const totalTime = entry.duration;
```

### Transfer Size Metrics

#### Encoded Body Size

Compressed size of the response body (as transferred over network):

```javascript
const encodedSize = entry.encodedBodySize;
```

#### Decoded Body Size

Uncompressed size of the response body:

```javascript
const decodedSize = entry.decodedBodySize;
```

#### Transfer Size

Total bytes transferred including HTTP headers:

```javascript
const transferSize = entry.transferSize;
```

Special values:

- `0`: Resource served from cache (no network transfer)
- Non-zero but less than `encodedBodySize`: Partial response from cache with revalidation

#### Compression Ratio

Calculate compression efficiency:

```javascript
const compressionRatio = 1 - (entry.encodedBodySize / entry.decodedBodySize);
const compressionPercent = compressionRatio * 100;
```

### Cache Performance Analysis

#### Cache Hit Detection

```javascript
const isCacheHit = entry.transferSize === 0;
const isRevalidated = entry.transferSize > 0 && entry.transferSize < entry.encodedBodySize;
```

#### Cache vs Network Comparison

```javascript
function analyzeCache(entry) {
  if (entry.transferSize === 0) {
    return 'full-cache';
  } else if (entry.transferSize < entry.encodedBodySize) {
    return 'revalidated';
  } else {
    return 'network';
  }
}
```

### Protocol and Connection Analysis

#### HTTP Protocol Version

```javascript
const protocol = entry.nextHopProtocol;
// Common values: 'http/1.1', 'h2', 'h3'
```

#### Connection Reuse Detection

Check if connection was reused:

```javascript
const connectionReused = entry.connectStart === entry.connectEnd;
```

Zero duration indicates existing connection was reused.

### Server Timing API

Capture custom server-side metrics sent via `Server-Timing` header:

```javascript
const serverTimings = entry.serverTiming;
serverTimings.forEach(timing => {
  console.log(`${timing.name}: ${timing.duration}ms`);
  console.log(`Description: ${timing.description}`);
});
```

Server must send header:

```
Server-Timing: db;dur=53, app;dur=47.2;desc="Application processing"
```

### Measuring Fetch Operations Manually

For operations not captured by Resource Timing:

#### Performance.mark() and Performance.measure()

```javascript
performance.mark('fetch-start');

fetch('https://api.example.com/data')
  .then(response => response.json())
  .then(data => {
    performance.mark('fetch-end');
    performance.measure('fetch-duration', 'fetch-start', 'fetch-end');
    
    const measure = performance.getEntriesByName('fetch-duration')[0];
    console.log(`Fetch took ${measure.duration}ms`);
  });
```

#### High-Resolution Timestamps

Use `performance.now()` for microsecond precision:

```javascript
const start = performance.now();

await fetch('https://api.example.com/data');

const end = performance.now();
const duration = end - start;
```

### Response Body Processing Time

Measure deserialization overhead:

```javascript
const fetchStart = performance.now();
const response = await fetch('https://api.example.com/data');
const fetchEnd = performance.now();

const parseStart = performance.now();
const data = await response.json();
const parseEnd = performance.now();

console.log(`Network: ${fetchEnd - fetchStart}ms`);
console.log(`Parsing: ${parseEnd - parseStart}ms`);
```

### Streaming Performance Metrics

For streaming responses, track progressive data consumption:

```javascript
const response = await fetch('https://api.example.com/large-file');
const reader = response.body.getReader();

let bytesReceived = 0;
let chunks = 0;
const startTime = performance.now();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  bytesReceived += value.length;
  chunks++;
  
  const elapsed = performance.now() - startTime;
  const throughput = (bytesReceived / 1024 / 1024) / (elapsed / 1000);
  console.log(`Throughput: ${throughput.toFixed(2)} MB/s`);
}
```

### Request Timing Breakdown Visualization

Complete timing breakdown analysis:

```javascript
function analyzeRequestTiming(entry) {
  const phases = {
    redirect: entry.redirectEnd - entry.redirectStart,
    appCache: entry.domainLookupStart - entry.fetchStart,
    dns: entry.domainLookupEnd - entry.domainLookupStart,
    tcp: entry.connectEnd - entry.connectStart,
    ssl: entry.connectEnd - entry.secureConnectionStart,
    request: entry.responseStart - entry.requestStart,
    response: entry.responseEnd - entry.responseStart
  };
  
  return phases;
}
```

### Batch Request Performance

Measure parallel fetch performance:

```javascript
const urls = ['url1', 'url2', 'url3'];
const startTime = performance.now();

const results = await Promise.all(
  urls.map(url => fetch(url))
);

const endTime = performance.now();
const parallelDuration = endTime - startTime;

// Compare with sequential
const sequentialStart = performance.now();
for (const url of urls) {
  await fetch(url);
}
const sequentialDuration = performance.now() - sequentialStart;

console.log(`Parallel: ${parallelDuration}ms`);
console.log(`Sequential: ${sequentialDuration}ms`);
console.log(`Speedup: ${(sequentialDuration / parallelDuration).toFixed(2)}x`);
```

### Network Quality Estimation

[Inference] Estimate network conditions based on timing patterns:

```javascript
function estimateNetworkQuality(entry) {
  const ttfb = entry.responseStart - entry.requestStart;
  const downloadTime = entry.responseEnd - entry.responseStart;
  const throughput = entry.encodedBodySize / downloadTime;
  
  return {
    latency: ttfb,
    bandwidth: throughput * 1000 / 1024, // KB/s
    quality: ttfb < 100 ? 'excellent' : 
             ttfb < 300 ? 'good' : 
             ttfb < 1000 ? 'fair' : 'poor'
  };
}
```

### Long Task Detection During Fetch

Monitor if fetch operations cause main thread blocking:

```javascript
const longTaskObserver = new PerformanceObserver((list) => {
  list.getEntries().forEach((entry) => {
    if (entry.duration > 50) {
      console.warn(`Long task detected: ${entry.duration}ms`);
    }
  });
});
longTaskObserver.observe({ entryTypes: ['longtask'] });
```

### Memory Impact Tracking

Monitor memory consumption during large fetches:

```javascript
if (performance.memory) {
  const memBefore = performance.memory.usedJSHeapSize;
  
  const response = await fetch('https://api.example.com/large-data');
  const data = await response.json();
  
  const memAfter = performance.memory.usedJSHeapSize;
  const memDelta = (memAfter - memBefore) / 1024 / 1024;
  
  console.log(`Memory increase: ${memDelta.toFixed(2)} MB`);
}
```

Note: `performance.memory` is non-standard and only available in Chromium-based browsers.

### Request Prioritization Metrics

Track fetch priority impact:

```javascript
// High priority fetch
const highPriorityStart = performance.now();
await fetch('critical-resource', { priority: 'high' });
const highPriorityTime = performance.now() - highPriorityStart;

// Low priority fetch
const lowPriorityStart = performance.now();
await fetch('non-critical-resource', { priority: 'low' });
const lowPriorityTime = performance.now() - lowPriorityStart;
```

### Retry and Timeout Metrics

Track retry attempts and timeout occurrences:

```javascript
async function fetchWithMetrics(url, options = {}) {
  const maxRetries = 3;
  let attempt = 0;
  let timeouts = 0;
  
  while (attempt < maxRetries) {
    attempt++;
    const startTime = performance.now();
    
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
        timeouts++;
      }, 5000);
      
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      const duration = performance.now() - startTime;
      
      return {
        response,
        metrics: {
          attempts: attempt,
          timeouts,
          duration
        }
      };
    } catch (error) {
      if (attempt === maxRetries) throw error;
    }
  }
}
```

### Cross-Origin Timing Information

Timing details are restricted for cross-origin requests unless CORS headers permit:

```javascript
// Server must send: Timing-Allow-Origin: *
// Or: Timing-Allow-Origin: https://your-domain.com

const entry = performance.getEntriesByType('resource')
  .find(e => e.name === 'https://api.example.com/data');

if (entry.domainLookupStart === 0 && 
    entry.connectStart === 0 && 
    entry.requestStart === 0) {
  console.log('Detailed timing blocked by CORS');
}
```

### Performance Budget Monitoring

Set and enforce performance budgets:

```javascript
const PERFORMANCE_BUDGET = {
  maxDuration: 1000,      // ms
  maxTransferSize: 500000, // bytes
  maxTTFB: 200            // ms
};

function checkPerformanceBudget(entry) {
  const violations = [];
  
  if (entry.duration > PERFORMANCE_BUDGET.maxDuration) {
    violations.push(`Duration exceeded: ${entry.duration}ms`);
  }
  
  if (entry.transferSize > PERFORMANCE_BUDGET.maxTransferSize) {
    violations.push(`Transfer size exceeded: ${entry.transferSize} bytes`);
  }
  
  const ttfb = entry.responseStart - entry.requestStart;
  if (ttfb > PERFORMANCE_BUDGET.maxTTFB) {
    violations.push(`TTFB exceeded: ${ttfb}ms`);
  }
  
  return violations;
}
```

### User-Centric Performance Metrics

Correlate fetch operations with user experience:

```javascript
function measureUserImpact(entry) {
  // Calculate if fetch blocked user interaction
  const blockingTime = entry.duration;
  
  // [Inference] Estimate perceived performance
  const isPerceptiblyFast = entry.duration < 100;
  const causedJank = blockingTime > 50;
  
  return {
    blockingTime,
    isPerceptiblyFast,
    causedJank,
    userImpact: causedJank ? 'negative' : 'neutral'
  };
}
```

### Aggregated Performance Reporting

Collect and analyze performance across multiple requests:

```javascript
class FetchPerformanceMonitor {
  constructor() {
    this.metrics = [];
  }
  
  observe() {
    const observer = new PerformanceObserver((list) => {
      list.getEntries().forEach((entry) => {
        if (entry.initiatorType === 'fetch') {
          this.metrics.push({
            url: entry.name,
            duration: entry.duration,
            transferSize: entry.transferSize,
            protocol: entry.nextHopProtocol,
            cached: entry.transferSize === 0
          });
        }
      });
    });
    
    observer.observe({ entryTypes: ['resource'] });
    return observer;
  }
  
  getStats() {
    const durations = this.metrics.map(m => m.duration);
    const sizes = this.metrics.map(m => m.transferSize);
    
    return {
      totalRequests: this.metrics.length,
      averageDuration: durations.reduce((a, b) => a + b, 0) / durations.length,
      medianDuration: this.median(durations),
      p95Duration: this.percentile(durations, 95),
      totalTransferred: sizes.reduce((a, b) => a + b, 0),
      cacheHitRate: this.metrics.filter(m => m.cached).length / this.metrics.length
    };
  }
  
  median(arr) {
    const sorted = [...arr].sort((a, b) => a - b);
    const mid = Math.floor(sorted.length / 2);
    return sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
  }
  
  percentile(arr, p) {
    const sorted = [...arr].sort((a, b) => a - b);
    const index = Math.ceil((p / 100) * sorted.length) - 1;
    return sorted[index];
  }
}
```

### Real User Monitoring (RUM) Integration

Export metrics for analytics platforms:

```javascript
function exportFetchMetrics(entry) {
  const metrics = {
    timestamp: Date.now(),
    url: entry.name,
    duration: entry.duration,
    transferSize: entry.transferSize,
    protocol: entry.nextHopProtocol,
    cached: entry.transferSize === 0,
    ttfb: entry.responseStart - entry.requestStart,
    dns: entry.domainLookupEnd - entry.domainLookupStart,
    tcp: entry.connectEnd - entry.connectStart,
    ssl: entry.secureConnectionStart > 0 ? 
         entry.connectEnd - entry.secureConnectionStart : 0
  };
  
  // Send to analytics endpoint
  navigator.sendBeacon('/analytics/fetch-metrics', JSON.stringify(metrics));
}
```

---

## Fetch API Error Reporting

### Network vs HTTP Errors

The fetch API distinguishes between network-level failures and HTTP-level failures. A fetch promise only rejects for network errors—such as DNS resolution failures, connection timeouts, or lack of internet connectivity. HTTP error responses (4xx, 5xx) result in a resolved promise with `response.ok` set to `false`.

```javascript
fetch('https://api.example.com/data')
  .then(response => {
    if (!response.ok) {
      throw new Error(`HTTP error: ${response.status}`);
    }
    return response.json();
  })
  .catch(error => {
    // Network error or thrown HTTP error
    console.error('Fetch failed:', error);
  });
```

### Response Status Checking

#### The `ok` Property

The `response.ok` property returns `true` for status codes in the 200-299 range. This provides a convenient way to validate successful responses without manually checking status codes.

```javascript
const response = await fetch('/api/endpoint');
if (!response.ok) {
  throw new Error(`Request failed with status ${response.status}`);
}
```

#### Status Code Inspection

For granular error handling, inspect `response.status` and `response.statusText`:

```javascript
const response = await fetch('/api/resource');

switch (response.status) {
  case 200:
    return await response.json();
  case 404:
    throw new Error('Resource not found');
  case 401:
    throw new Error('Unauthorized access');
  case 500:
    throw new Error('Server error occurred');
  default:
    throw new Error(`Unexpected status: ${response.status}`);
}
```

### Network Error Detection

Network errors reject the fetch promise. These include:

- DNS lookup failures
- Connection refused or timeout
- Network disconnection
- CORS violations
- SSL/TLS certificate issues

```javascript
try {
  const response = await fetch('https://api.example.com/data');
  // Handle response
} catch (error) {
  if (error instanceof TypeError) {
    // Network error occurred
    console.error('Network failure:', error.message);
  } else {
    // Other error type
    console.error('Request error:', error);
  }
}
```

[Inference] TypeError is commonly thrown for network failures, though the specification doesn't guarantee the specific error type.

### Timeout Handling

Fetch doesn't support native timeouts. Implement timeout logic using `AbortController`:

```javascript
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 5000);

try {
  const response = await fetch('/api/data', {
    signal: controller.signal
  });
  clearTimeout(timeoutId);
  
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}`);
  }
  
  return await response.json();
} catch (error) {
  clearTimeout(timeoutId);
  
  if (error.name === 'AbortError') {
    throw new Error('Request timeout after 5 seconds');
  }
  throw error;
}
```

### Parsing Errors

JSON parsing failures occur when the response body isn't valid JSON. These throw synchronously:

```javascript
const response = await fetch('/api/data');

if (!response.ok) {
  throw new Error(`HTTP ${response.status}`);
}

try {
  const data = await response.json();
  return data;
} catch (error) {
  if (error instanceof SyntaxError) {
    throw new Error('Invalid JSON response');
  }
  throw error;
}
```

### Error Context Extraction

#### Reading Error Response Bodies

Server error responses often contain detailed error information:

```javascript
const response = await fetch('/api/submit', {
  method: 'POST',
  body: JSON.stringify(data)
});

if (!response.ok) {
  let errorMessage = `HTTP ${response.status}`;
  
  try {
    const errorData = await response.json();
    errorMessage = errorData.message || errorMessage;
  } catch {
    // Response wasn't JSON, use status text
    errorMessage = response.statusText || errorMessage;
  }
  
  throw new Error(errorMessage);
}
```

#### Preserving Response Information

Create custom error objects that retain response details:

```javascript
class FetchError extends Error {
  constructor(message, response) {
    super(message);
    this.name = 'FetchError';
    this.status = response.status;
    this.statusText = response.statusText;
    this.url = response.url;
  }
}

const response = await fetch('/api/endpoint');

if (!response.ok) {
  const body = await response.text();
  throw new FetchError(
    `Request failed: ${body || response.statusText}`,
    response
  );
}
```

### CORS Error Identification

CORS violations manifest as network errors. The browser console shows CORS-specific messages, but JavaScript only receives a generic network failure:

```javascript
try {
  const response = await fetch('https://different-origin.com/api');
  // Process response
} catch (error) {
  // Cannot definitively determine if this is CORS
  // Browser console will show CORS details
  console.error('Request failed (check console for CORS issues):', error);
}
```

[Unverified] There's no programmatic way to distinguish CORS errors from other network failures in the catch block due to security restrictions.

### Retry Logic

Implement exponential backoff for transient failures:

```javascript
async function fetchWithRetry(url, options = {}, maxRetries = 3) {
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      // Don't retry client errors (4xx)
      if (response.status >= 400 && response.status < 500) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      // Retry server errors (5xx) and network issues
      if (attempt < maxRetries) {
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }
      
      throw new Error(`HTTP ${response.status} after ${maxRetries} retries`);
      
    } catch (error) {
      if (attempt === maxRetries) {
        throw error;
      }
      
      // Exponential backoff
      const delay = Math.pow(2, attempt) * 1000;
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

### Comprehensive Error Handler Pattern

```javascript
async function safeFetch(url, options = {}) {
  const controller = new AbortController();
  const timeout = options.timeout || 10000;
  const timeoutId = setTimeout(() => controller.abort(), timeout);
  
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    // Check HTTP status
    if (!response.ok) {
      let errorBody = null;
      const contentType = response.headers.get('content-type');
      
      if (contentType?.includes('application/json')) {
        try {
          errorBody = await response.json();
        } catch {
          errorBody = await response.text();
        }
      } else {
        errorBody = await response.text();
      }
      
      throw {
        type: 'HTTP_ERROR',
        status: response.status,
        statusText: response.statusText,
        body: errorBody,
        url: response.url
      };
    }
    
    return response;
    
  } catch (error) {
    clearTimeout(timeoutId);
    
    if (error.name === 'AbortError') {
      throw {
        type: 'TIMEOUT',
        message: `Request timeout after ${timeout}ms`,
        url
      };
    }
    
    if (error instanceof TypeError) {
      throw {
        type: 'NETWORK_ERROR',
        message: error.message,
        url
      };
    }
    
    // Re-throw structured errors
    if (error.type) {
      throw error;
    }
    
    // Unknown error
    throw {
      type: 'UNKNOWN',
      message: error.message,
      originalError: error,
      url
    };
  }
}

// Usage
try {
  const response = await safeFetch('/api/data', { timeout: 5000 });
  const data = await response.json();
} catch (error) {
  switch (error.type) {
    case 'HTTP_ERROR':
      console.error(`HTTP ${error.status}:`, error.body);
      break;
    case 'TIMEOUT':
      console.error('Request timed out');
      break;
    case 'NETWORK_ERROR':
      console.error('Network failure:', error.message);
      break;
    default:
      console.error('Unknown error:', error);
  }
}
```

### Logging and Monitoring

Structure error information for observability:

```javascript
function logFetchError(error, context = {}) {
  const errorLog = {
    timestamp: new Date().toISOString(),
    url: context.url,
    method: context.method || 'GET',
    errorType: error.type || 'UNKNOWN',
    message: error.message,
    status: error.status,
    stack: error.stack,
    ...context.metadata
  };
  
  // Send to monitoring service
  console.error('Fetch error:', errorLog);
  
  // Example: Send to external service
  // analytics.track('fetch_error', errorLog);
}

// Usage
try {
  const response = await fetch('/api/endpoint', { method: 'POST' });
  if (!response.ok) throw new Error(`HTTP ${response.status}`);
} catch (error) {
  logFetchError(error, {
    url: '/api/endpoint',
    method: 'POST',
    metadata: { userId: currentUser.id }
  });
}
```

### User-Facing Error Messages

Translate technical errors into user-friendly messages:

```javascript
function getUserErrorMessage(error) {
  if (error.type === 'NETWORK_ERROR') {
    return 'Unable to connect. Please check your internet connection.';
  }
  
  if (error.type === 'TIMEOUT') {
    return 'The request is taking too long. Please try again.';
  }
  
  if (error.type === 'HTTP_ERROR') {
    switch (error.status) {
      case 400:
        return 'Invalid request. Please check your input.';
      case 401:
        return 'Please log in to continue.';
      case 403:
        return 'You don\'t have permission to access this resource.';
      case 404:
        return 'The requested resource was not found.';
      case 429:
        return 'Too many requests. Please wait a moment.';
      case 500:
      case 502:
      case 503:
        return 'Server error. Please try again later.';
      default:
        return 'An unexpected error occurred. Please try again.';
    }
  }
  
  return 'Something went wrong. Please try again.';
}
```

---

## User Analytics with Fetch API

### Tracking User Events

Event tracking forms the foundation of user analytics implementation. The fetch API enables asynchronous transmission of user interaction data to analytics endpoints without blocking the user interface.

```javascript
async function trackEvent(eventName, eventData) {
  try {
    await fetch('https://analytics.example.com/events', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: eventName,
        timestamp: Date.now(),
        ...eventData
      })
    });
  } catch (error) {
    console.error('Analytics tracking failed:', error);
  }
}

// Usage
trackEvent('button_click', {
  buttonId: 'checkout',
  pageUrl: window.location.href,
  userId: getCurrentUserId()
});
```

### Session Tracking

Session management requires consistent identification across multiple requests. Implementing session tracking involves generating unique session identifiers and persisting them throughout the user's visit.

```javascript
function getSessionId() {
  let sessionId = sessionStorage.getItem('analytics_session_id');
  
  if (!sessionId) {
    sessionId = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    sessionStorage.setItem('analytics_session_id', sessionId);
  }
  
  return sessionId;
}

async function trackPageView() {
  await fetch('https://analytics.example.com/pageviews', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      sessionId: getSessionId(),
      url: window.location.href,
      referrer: document.referrer,
      timestamp: Date.now()
    })
  });
}
```

### Batching Analytics Requests

Batching reduces server load and network overhead by accumulating multiple events before transmission. This approach optimizes performance while maintaining data accuracy.

```javascript
class AnalyticsBatcher {
  constructor(endpoint, maxBatchSize = 10, flushInterval = 5000) {
    this.endpoint = endpoint;
    this.maxBatchSize = maxBatchSize;
    this.flushInterval = flushInterval;
    this.queue = [];
    this.timer = null;
    
    this.startTimer();
  }
  
  track(event) {
    this.queue.push({
      ...event,
      timestamp: Date.now()
    });
    
    if (this.queue.length >= this.maxBatchSize) {
      this.flush();
    }
  }
  
  async flush() {
    if (this.queue.length === 0) return;
    
    const batch = [...this.queue];
    this.queue = [];
    
    try {
      await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ events: batch })
      });
    } catch (error) {
      console.error('Failed to send analytics batch:', error);
      // [Inference] Re-queuing might cause duplicate events in some implementations
      this.queue.unshift(...batch);
    }
    
    this.startTimer();
  }
  
  startTimer() {
    clearTimeout(this.timer);
    this.timer = setTimeout(() => this.flush(), this.flushInterval);
  }
}

const analytics = new AnalyticsBatcher('https://analytics.example.com/batch');
analytics.track({ event: 'page_view', page: '/home' });
analytics.track({ event: 'click', element: 'nav_menu' });
```

### Beacon API for Reliable Tracking

The Beacon API provides guaranteed delivery of analytics data during page unload events, addressing the limitation where standard fetch requests may be cancelled when users navigate away.

```javascript
function trackPageExit() {
  const data = JSON.stringify({
    event: 'page_exit',
    sessionId: getSessionId(),
    timeOnPage: performance.now(),
    url: window.location.href
  });
  
  // Beacon API ensures delivery even during page unload
  navigator.sendBeacon('https://analytics.example.com/events', data);
}

window.addEventListener('beforeunload', trackPageExit);
window.addEventListener('visibilitychange', () => {
  if (document.visibilityState === 'hidden') {
    trackPageExit();
  }
});
```

### User Identification and Attribution

Persistent user identification across sessions requires careful management of identifiers while respecting privacy considerations.

```javascript
function getUserId() {
  let userId = localStorage.getItem('analytics_user_id');
  
  if (!userId) {
    userId = `user_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    localStorage.setItem('analytics_user_id', userId);
  }
  
  return userId;
}

async function identifyUser(userAttributes) {
  await fetch('https://analytics.example.com/identify', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      userId: getUserId(),
      sessionId: getSessionId(),
      attributes: userAttributes,
      timestamp: Date.now()
    })
  });
}

// Associate user with attributes
identifyUser({
  plan: 'premium',
  signupDate: '2024-01-15',
  country: 'US'
});
```

### Custom Event Properties

Rich event metadata enables detailed behavioral analysis and segmentation capabilities.

```javascript
async function trackWithProperties(eventName, properties) {
  const enrichedData = {
    event: eventName,
    properties: {
      ...properties,
      // Automatically captured context
      screenWidth: window.innerWidth,
      screenHeight: window.innerHeight,
      userAgent: navigator.userAgent,
      language: navigator.language,
      timezone: Intl.DateTimeFormat().resolvedOptions().timeZone
    },
    userId: getUserId(),
    sessionId: getSessionId(),
    timestamp: Date.now()
  };
  
  await fetch('https://analytics.example.com/events', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(enrichedData)
  });
}

// Track purchase with detailed properties
trackWithProperties('purchase_completed', {
  productId: 'prod_123',
  productName: 'Premium Subscription',
  price: 29.99,
  currency: 'USD',
  paymentMethod: 'credit_card'
});
```

### Error and Performance Tracking

Monitoring application health through error tracking and performance metrics provides operational insights alongside user behavior data.

```javascript
// Error tracking
window.addEventListener('error', (event) => {
  fetch('https://analytics.example.com/errors', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      type: 'javascript_error',
      message: event.message,
      filename: event.filename,
      lineno: event.lineno,
      colno: event.colno,
      stack: event.error?.stack,
      userId: getUserId(),
      sessionId: getSessionId(),
      url: window.location.href,
      timestamp: Date.now()
    })
  }).catch(err => console.error('Failed to report error:', err));
});

// Performance tracking
window.addEventListener('load', () => {
  const perfData = performance.getEntriesByType('navigation')[0];
  
  fetch('https://analytics.example.com/performance', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      domContentLoaded: perfData.domContentLoadedEventEnd - perfData.domContentLoadedEventStart,
      loadComplete: perfData.loadEventEnd - perfData.loadEventStart,
      dnsLookup: perfData.domainLookupEnd - perfData.domainLookupStart,
      tcpConnection: perfData.connectEnd - perfData.connectStart,
      serverResponse: perfData.responseEnd - perfData.requestStart,
      domProcessing: perfData.domComplete - perfData.domLoading,
      userId: getUserId(),
      sessionId: getSessionId(),
      url: window.location.href,
      timestamp: Date.now()
    })
  }).catch(err => console.error('Failed to report performance:', err));
});
```

### Retry Logic and Failure Handling

Network failures require robust retry mechanisms to maintain data integrity while avoiding excessive retransmission attempts.

```javascript
async function fetchWithRetry(url, options, maxRetries = 3) {
  let lastError;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(url, options);
      
      if (response.ok) {
        return response;
      }
      
      // Don't retry client errors (4xx)
      if (response.status >= 400 && response.status < 500) {
        throw new Error(`Client error: ${response.status}`);
      }
      
      lastError = new Error(`Server error: ${response.status}`);
    } catch (error) {
      lastError = error;
      
      if (attempt < maxRetries) {
        // Exponential backoff
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}

async function trackEventWithRetry(eventName, eventData) {
  try {
    await fetchWithRetry('https://analytics.example.com/events', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: eventName,
        ...eventData
      })
    });
  } catch (error) {
    console.error('Analytics tracking failed after retries:', error);
    // Store in IndexedDB for later retry
    storeFailedEvent(eventName, eventData);
  }
}
```

### Offline Analytics Buffering

Supporting offline-first applications requires local persistence of analytics events with background synchronization when connectivity resumes.

```javascript
class OfflineAnalytics {
  constructor(endpoint) {
    this.endpoint = endpoint;
    this.dbName = 'analytics_offline';
    this.storeName = 'pending_events';
    this.db = null;
    
    this.initDB();
    this.setupSyncListener();
  }
  
  async initDB() {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, 1);
      
      request.onerror = () => reject(request.error);
      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };
      
      request.onupgradeneeded = (event) => {
        const db = event.target.result;
        if (!db.objectStoreNames.contains(this.storeName)) {
          db.createObjectStore(this.storeName, { keyPath: 'id', autoIncrement: true });
        }
      };
    });
  }
  
  async track(eventData) {
    const event = {
      ...eventData,
      timestamp: Date.now()
    };
    
    if (navigator.onLine) {
      try {
        await this.sendEvent(event);
      } catch (error) {
        await this.storeEvent(event);
      }
    } else {
      await this.storeEvent(event);
    }
  }
  
  async sendEvent(event) {
    const response = await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(event)
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
  }
  
  async storeEvent(event) {
    const transaction = this.db.transaction([this.storeName], 'readwrite');
    const store = transaction.objectStore(this.storeName);
    await store.add(event);
  }
  
  async syncPendingEvents() {
    if (!navigator.onLine) return;
    
    const transaction = this.db.transaction([this.storeName], 'readonly');
    const store = transaction.objectStore(this.storeName);
    const events = await store.getAll();
    
    for (const event of events) {
      try {
        await this.sendEvent(event);
        await this.deleteEvent(event.id);
      } catch (error) {
        console.error('Failed to sync event:', error);
        break; // Stop syncing on first failure
      }
    }
  }
  
  async deleteEvent(id) {
    const transaction = this.db.transaction([this.storeName], 'readwrite');
    const store = transaction.objectStore(this.storeName);
    await store.delete(id);
  }
  
  setupSyncListener() {
    window.addEventListener('online', () => {
      this.syncPendingEvents();
    });
  }
}

const offlineAnalytics = new OfflineAnalytics('https://analytics.example.com/events');
offlineAnalytics.track({
  event: 'page_view',
  page: '/dashboard'
});
```

### Rate Limiting Client-Side Tracking

Implementing client-side rate limits prevents excessive analytics traffic from individual users while maintaining data quality.

```javascript
class RateLimitedAnalytics {
  constructor(endpoint, maxEventsPerMinute = 60) {
    this.endpoint = endpoint;
    this.maxEventsPerMinute = maxEventsPerMinute;
    this.eventTimestamps = [];
  }
  
  async track(eventData) {
    const now = Date.now();
    const oneMinuteAgo = now - 60000;
    
    // Remove timestamps older than one minute
    this.eventTimestamps = this.eventTimestamps.filter(ts => ts > oneMinuteAgo);
    
    if (this.eventTimestamps.length >= this.maxEventsPerMinute) {
      console.warn('Rate limit exceeded, event not tracked:', eventData);
      return;
    }
    
    this.eventTimestamps.push(now);
    
    try {
      await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          ...eventData,
          timestamp: now
        })
      });
    } catch (error) {
      console.error('Failed to track event:', error);
    }
  }
}

const rateLimitedAnalytics = new RateLimitedAnalytics('https://analytics.example.com/events', 60);
```

### Privacy-Compliant Tracking

Respecting user privacy preferences requires implementing consent management and data minimization strategies.

```javascript
class PrivacyCompliantAnalytics {
  constructor(endpoint) {
    this.endpoint = endpoint;
    this.consentGiven = this.checkConsent();
  }
  
  checkConsent() {
    return localStorage.getItem('analytics_consent') === 'granted';
  }
  
  grantConsent() {
    localStorage.setItem('analytics_consent', 'granted');
    this.consentGiven = true;
  }
  
  revokeConsent() {
    localStorage.setItem('analytics_consent', 'revoked');
    this.consentGiven = false;
    // Clear existing identifiers
    localStorage.removeItem('analytics_user_id');
    sessionStorage.removeItem('analytics_session_id');
  }
  
  async track(eventData) {
    if (!this.consentGiven) {
      console.log('Analytics tracking skipped - no consent');
      return;
    }
    
    // Anonymize IP on server-side, but signal preference
    const privacySettings = {
      anonymizeIp: true,
      doNotTrack: navigator.doNotTrack === '1'
    };
    
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        ...eventData,
        privacySettings,
        timestamp: Date.now()
      })
    });
  }
}

const privacyAnalytics = new PrivacyCompliantAnalytics('https://analytics.example.com/events');

// Consent management UI
function handleConsentResponse(granted) {
  if (granted) {
    privacyAnalytics.grantConsent();
  } else {
    privacyAnalytics.revokeConsent();
  }
}
```

### A/B Testing Integration

Analytics systems frequently integrate with experimentation platforms to correlate user behavior with test variants.

```javascript
async function trackExperimentView(experimentId, variantId) {
  await fetch('https://analytics.example.com/experiments', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      event: 'experiment_view',
      experimentId,
      variantId,
      userId: getUserId(),
      sessionId: getSessionId(),
      timestamp: Date.now()
    })
  });
}

async function trackConversion(experimentId, variantId, conversionData) {
  await fetch('https://analytics.example.com/conversions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      event: 'conversion',
      experimentId,
      variantId,
      ...conversionData,
      userId: getUserId(),
      sessionId: getSessionId(),
      timestamp: Date.now()
    })
  });
}

// Usage
const variant = assignUserToVariant('homepage_redesign_2024');
trackExperimentView('homepage_redesign_2024', variant);

// Later, when conversion happens
trackConversion('homepage_redesign_2024', variant, {
  conversionType: 'signup',
  value: 29.99
});
```

### Real-Time Analytics Streaming

Server-Sent Events or WebSockets enable real-time analytics dashboards by streaming events as they occur.

```javascript
class RealtimeAnalytics {
  constructor(endpoint, streamEndpoint) {
    this.endpoint = endpoint;
    this.streamEndpoint = streamEndpoint;
    this.eventSource = null;
  }
  
  async track(eventData) {
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        ...eventData,
        timestamp: Date.now()
      })
    });
  }
  
  subscribeToRealtimeEvents(callback) {
    this.eventSource = new EventSource(this.streamEndpoint);
    
    this.eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data);
      callback(data);
    };
    
    this.eventSource.onerror = (error) => {
      console.error('EventSource error:', error);
      this.eventSource.close();
    };
  }
  
  unsubscribe() {
    if (this.eventSource) {
      this.eventSource.close();
      this.eventSource = null;
    }
  }
}

const realtimeAnalytics = new RealtimeAnalytics(
  'https://analytics.example.com/events',
  'https://analytics.example.com/stream'
);

// Subscribe to real-time updates for dashboard
realtimeAnalytics.subscribeToRealtimeEvents((event) => {
  updateDashboard(event);
});
```

### Cross-Domain Tracking

Tracking users across multiple domains requires careful coordination of identifiers while respecting same-origin policy constraints.

```javascript
async function initCrossDomainTracking(domains) {
  const userId = getUserId();
  const sessionId = getSessionId();
  
  // Add tracking parameters to cross-domain links
  document.addEventListener('click', (event) => {
    const link = event.target.closest('a');
    
    if (!link) return;
    
    const url = new URL(link.href);
    const isDifferentDomain = url.hostname !== window.location.hostname;
    const isTrackedDomain = domains.includes(url.hostname);
    
    if (isDifferentDomain && isTrackedDomain) {
      url.searchParams.set('_uid', userId);
      url.searchParams.set('_sid', sessionId);
      link.href = url.toString();
    }
  });
  
  // Check for incoming tracking parameters
  const urlParams = new URLSearchParams(window.location.search);
  const incomingUserId = urlParams.get('_uid');
  const incomingSessionId = urlParams.get('_sid');
  
  if (incomingUserId && incomingSessionId) {
    localStorage.setItem('analytics_user_id', incomingUserId);
    sessionStorage.setItem('analytics_session_id', incomingSessionId);
    
    // Track cross-domain transition
    await fetch('https://analytics.example.com/cross-domain', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: 'cross_domain_transition',
        fromDomain: document.referrer ? new URL(document.referrer).hostname : null,
        toDomain: window.location.hostname,
        userId: incomingUserId,
        sessionId: incomingSessionId,
        timestamp: Date.now()
      })
    });
    
    // Clean URL
    window.history.replaceState({}, '', window.location.pathname);
  }
}

initCrossDomainTracking(['example.com', 'shop.example.com', 'blog.example.com']);
```

### Funnel and Conversion Tracking

Multi-step conversion funnels require sequential event tracking with proper attribution and drop-off analysis.

```javascript
class FunnelTracker {
  constructor(endpoint, funnelId) {
    this.endpoint = endpoint;
    this.funnelId = funnelId;
    this.funnelSteps = [];
  }
  
  async trackStep(stepName, stepData = {}) {
    const stepInfo = {
      funnelId: this.funnelId,
      stepName,
      stepIndex: this.funnelSteps.length,
      stepData,
      userId: getUserId(),
      sessionId: getSessionId(),
      timestamp: Date.now()
    };
    
    this.funnelSteps.push(stepInfo);
    
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: 'funnel_step',
        ...stepInfo
      })
    });
  }
  
  async trackCompletion(completionData = {}) {
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: 'funnel_completion',
        funnelId: this.funnelId,
        steps: this.funnelSteps,
        completionData,
        totalDuration: Date.now() - this.funnelSteps[0].timestamp,
        userId: getUserId(),
        sessionId: getSessionId(),
        timestamp: Date.now()
      })
    });
    
    this.funnelSteps = [];
  }
  
  async trackAbandonment(abandonmentReason) {
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: 'funnel_abandonment',
        funnelId: this.funnelId,
        completedSteps: this.funnelSteps,
        lastStep: this.funnelSteps[this.funnelSteps.length - 1]?.stepName,
        abandonmentReason,
        userId: getUserId(),
        sessionId: getSessionId(),
        timestamp: Date.now()
      })
    });
  }
}

// Usage example: Checkout funnel
const checkoutFunnel = new FunnelTracker('https://analytics.example.com/events', 'checkout_v2');

checkoutFunnel.trackStep('cart_view', { itemCount: 3, cartValue: 89.97 });
checkoutFunnel.trackStep('shipping_info', { shippingMethod: 'express' });
checkoutFunnel.trackStep('payment_info', { paymentMethod: 'credit_card' });
checkoutFunnel.trackCompletion({ orderId: 'ORD-12345', totalValue: 89.97 });
```

### Custom Dimension Tracking

Enriching events with custom dimensions enables sophisticated segmentation and analysis across business-specific attributes.

```javascript
class DimensionTracker {
  constructor(endpoint) {
    this.endpoint = endpoint;
    this.customDimensions = {};
  }
  
  setDimension(key, value) {
    this.customDimensions[key] = value;
  }
  
  setDimensions(dimensions) {
    this.customDimensions = {
      ...this.customDimensions,
      ...dimensions
    };
  }
  
  clearDimension(key) {
    delete this.customDimensions[key];
  }
  
  async track(eventName, eventData = {}) {
    await fetch(this.endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        event: eventName,
        properties: eventData,
        dimensions: this.customDimensions,
        userId: getUserId(),
        sessionId: getSessionId(),
        timestamp: Date.now()
      })
    });
  }
}

const dimensionTracker = new DimensionTracker('https://analytics.example.com/events');

// Set user-level dimensions
dimensionTracker.setDimensions({
  subscriptionTier: 'premium',
  accountAge: '180_days',
  userSegment: 'power_user',
  experimentVariant: 'control'
});

// Track events with enriched dimensions
dimensionTracker.track('feature_used', {
  featureName: 'advanced_reporting',
  usageCount: 5
});
```

---

## APM Integration with Fetch API

### Instrumentation Approaches

APM (Application Performance Monitoring) systems instrument fetch requests to collect timing data, error rates, and distributed traces. Most APM agents intercept fetch by wrapping or replacing the global `fetch` function before application code executes.

```javascript
const originalFetch = window.fetch;
window.fetch = function(...args) {
  const startTime = performance.now();
  const span = apm.startSpan('HTTP Request');
  
  return originalFetch.apply(this, args)
    .then(response => {
      span.setHttpStatus(response.status);
      span.end(performance.now() - startTime);
      return response;
    })
    .catch(error => {
      span.recordError(error);
      span.end(performance.now() - startTime);
      throw error;
    });
};
```

### Trace Context Propagation

Distributed tracing requires propagating trace context across service boundaries through HTTP headers. APM agents inject trace identifiers following W3C Trace Context or vendor-specific formats.

```javascript
function instrumentedFetch(url, options = {}) {
  const traceHeaders = {
    'traceparent': `00-${traceId}-${spanId}-01`,
    'tracestate': `vendor=value`,
  };
  
  const headers = new Headers(options.headers);
  Object.entries(traceHeaders).forEach(([key, value]) => {
    headers.set(key, value);
  });
  
  return fetch(url, {
    ...options,
    headers
  });
}
```

### Performance Metrics Collection

APM systems extract multiple timing metrics from fetch requests using the Resource Timing API and internal span measurements.

```javascript
async function trackedFetch(url, options) {
  const resourceName = new URL(url, location.href).href;
  const span = {
    name: resourceName,
    startTime: performance.now(),
    attributes: {
      'http.method': options?.method || 'GET',
      'http.url': resourceName,
    }
  };
  
  try {
    const response = await fetch(url, options);
    
    span.attributes['http.status_code'] = response.status;
    span.attributes['http.response_content_length'] = 
      response.headers.get('content-length');
    
    // Extract Resource Timing entry
    const entries = performance.getEntriesByName(resourceName, 'resource');
    if (entries.length > 0) {
      const timing = entries[entries.length - 1];
      span.metrics = {
        dns: timing.domainLookupEnd - timing.domainLookupStart,
        tcp: timing.connectEnd - timing.connectStart,
        tls: timing.requestStart - timing.secureConnectionStart,
        ttfb: timing.responseStart - timing.requestStart,
        download: timing.responseEnd - timing.responseStart,
        total: timing.responseEnd - timing.fetchStart
      };
    }
    
    span.endTime = performance.now();
    apm.recordSpan(span);
    
    return response;
  } catch (error) {
    span.error = {
      message: error.message,
      type: error.name,
      stack: error.stack
    };
    span.endTime = performance.now();
    apm.recordSpan(span);
    throw error;
  }
}
```

### Request and Response Body Capture

APM agents may capture request/response bodies for debugging, typically with size limits and content-type filtering to avoid capturing binary data or sensitive information.

```javascript
function captureBody(request, options) {
  const contentType = request.headers.get('content-type') || '';
  const maxSize = 10000; // bytes
  
  if (!contentType.includes('application/json') && 
      !contentType.includes('text/')) {
    return null;
  }
  
  if (options.body) {
    if (typeof options.body === 'string') {
      return options.body.substring(0, maxSize);
    }
    if (options.body instanceof FormData) {
      const entries = {};
      for (const [key, value] of options.body.entries()) {
        entries[key] = typeof value === 'string' ? value : '[File]';
      }
      return JSON.stringify(entries).substring(0, maxSize);
    }
  }
  
  return null;
}

async function captureResponse(response) {
  const contentType = response.headers.get('content-type') || '';
  const contentLength = parseInt(response.headers.get('content-length') || '0');
  
  if (contentLength > 10000 || 
      (!contentType.includes('application/json') && 
       !contentType.includes('text/'))) {
    return null;
  }
  
  const cloned = response.clone();
  try {
    const text = await cloned.text();
    return text;
  } catch {
    return null;
  }
}
```

### Error Classification and Sampling

APM systems classify errors by status code ranges and implement sampling strategies to reduce data volume while maintaining statistical significance.

```javascript
class APMSampler {
  constructor(config) {
    this.successRate = config.successRate || 0.1;
    this.errorRate = config.errorRate || 1.0;
    this.slowThreshold = config.slowThreshold || 1000;
    this.slowRate = config.slowRate || 1.0;
  }
  
  shouldSample(span) {
    // Always sample errors
    if (span.error || span.attributes['http.status_code'] >= 400) {
      return Math.random() < this.errorRate;
    }
    
    // Always sample slow requests
    const duration = span.endTime - span.startTime;
    if (duration > this.slowThreshold) {
      return Math.random() < this.slowRate;
    }
    
    // Sample successful requests at lower rate
    return Math.random() < this.successRate;
  }
  
  classifyError(statusCode) {
    if (statusCode >= 500) return 'server_error';
    if (statusCode >= 400) return 'client_error';
    if (statusCode >= 300) return 'redirect';
    return 'success';
  }
}
```

### Correlation with User Actions

APM agents correlate fetch requests with user interactions (clicks, page loads, route changes) to understand user experience impact.

```javascript
class UserActionTracer {
  constructor() {
    this.currentAction = null;
    this.setupInteractionListeners();
  }
  
  setupInteractionListeners() {
    ['click', 'submit', 'change'].forEach(eventType => {
      document.addEventListener(eventType, (e) => {
        this.currentAction = {
          type: eventType,
          target: this.getElementIdentifier(e.target),
          timestamp: Date.now(),
          id: this.generateId()
        };
      }, true);
    });
  }
  
  getElementIdentifier(element) {
    return element.id || 
           element.name || 
           element.className || 
           element.tagName;
  }
  
  attachToSpan(span) {
    if (this.currentAction && 
        (Date.now() - this.currentAction.timestamp) < 5000) {
      span.attributes['user.action'] = this.currentAction.type;
      span.attributes['user.action.target'] = this.currentAction.target;
      span.attributes['user.action.id'] = this.currentAction.id;
    }
  }
  
  generateId() {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

### Automatic Span Naming

APM systems generate meaningful span names from URLs, removing sensitive data and applying normalization rules.

```javascript
class SpanNamer {
  constructor(config = {}) {
    this.urlPatterns = config.urlPatterns || [];
    this.stripQuery = config.stripQuery !== false;
    this.stripHash = config.stripHash !== false;
  }
  
  generateName(url, method = 'GET') {
    try {
      const parsed = new URL(url, location.href);
      let pathname = parsed.pathname;
      
      // Apply URL patterns to normalize dynamic segments
      for (const pattern of this.urlPatterns) {
        if (pattern.regex.test(pathname)) {
          pathname = pathname.replace(pattern.regex, pattern.replacement);
          break;
        }
      }
      
      // Build span name
      const parts = [method];
      
      if (parsed.hostname !== location.hostname) {
        parts.push(parsed.hostname);
      }
      
      parts.push(pathname);
      
      return parts.join(' ');
    } catch {
      return `${method} ${url}`;
    }
  }
  
  addPattern(regex, replacement) {
    this.urlPatterns.push({ regex, replacement });
  }
}

// Usage
const namer = new SpanNamer();
namer.addPattern(/\/users\/\d+/, '/users/:id');
namer.addPattern(/\/posts\/[a-f0-9-]+/, '/posts/:uuid');

// "GET /users/123" -> "GET /users/:id"
// "POST api.example.com/posts/abc-123" -> "POST api.example.com/posts/:uuid"
```

### Memory and Performance Overhead Management

APM instrumentation must minimize overhead to avoid impacting application performance. [Inference: APM vendors typically target <5% overhead]

```javascript
class LowOverheadAPM {
  constructor() {
    this.queue = [];
    this.maxQueueSize = 100;
    this.flushInterval = 10000; // 10 seconds
    this.setupPeriodicFlush();
  }
  
  recordSpan(span) {
    // Avoid blocking main thread
    if (this.queue.length >= this.maxQueueSize) {
      this.queue.shift(); // Drop oldest span
    }
    
    this.queue.push(this.serializeSpan(span));
    
    // Flush if queue is nearly full
    if (this.queue.length >= this.maxQueueSize * 0.8) {
      this.flush();
    }
  }
  
  serializeSpan(span) {
    // Minimize object size
    return {
      n: span.name,
      s: span.startTime,
      d: span.endTime - span.startTime,
      a: this.compressAttributes(span.attributes),
      e: span.error ? { m: span.error.message, t: span.error.type } : undefined
    };
  }
  
  compressAttributes(attrs) {
    const compressed = {};
    const keyMap = {
      'http.method': 'm',
      'http.status_code': 's',
      'http.url': 'u'
    };
    
    for (const [key, value] of Object.entries(attrs)) {
      compressed[keyMap[key] || key] = value;
    }
    
    return compressed;
  }
  
  setupPeriodicFlush() {
    setInterval(() => this.flush(), this.flushInterval);
  }
  
  async flush() {
    if (this.queue.length === 0) return;
    
    const batch = this.queue.splice(0, this.maxQueueSize);
    
    // Use sendBeacon for reliability during page unload
    if (navigator.sendBeacon) {
      navigator.sendBeacon('/apm/spans', JSON.stringify(batch));
    } else {
      // Fallback to fetch with keepalive
      fetch('/apm/spans', {
        method: 'POST',
        body: JSON.stringify(batch),
        headers: { 'Content-Type': 'application/json' },
        keepalive: true
      }).catch(() => {}); // Silent failure
    }
  }
}
```

### Integration with Service Workers

Fetch requests from service workers require separate instrumentation since they execute in a different context.

```javascript
// In service worker
self.addEventListener('fetch', (event) => {
  const startTime = performance.now();
  
  event.respondWith(
    (async () => {
      try {
        const response = await fetch(event.request);
        
        // Record successful fetch
        self.clients.matchAll().then(clients => {
          clients.forEach(client => {
            client.postMessage({
              type: 'apm_span',
              span: {
                name: `SW ${event.request.method} ${event.request.url}`,
                duration: performance.now() - startTime,
                status: response.status,
                context: 'service_worker'
              }
            });
          });
        });
        
        return response;
      } catch (error) {
        // Record error
        self.clients.matchAll().then(clients => {
          clients.forEach(client => {
            client.postMessage({
              type: 'apm_span',
              span: {
                name: `SW ${event.request.method} ${event.request.url}`,
                duration: performance.now() - startTime,
                error: error.message,
                context: 'service_worker'
              }
            });
          });
        });
        
        throw error;
      }
    })()
  );
});

// In main thread
navigator.serviceWorker.addEventListener('message', (event) => {
  if (event.data.type === 'apm_span') {
    apm.recordSpan(event.data.span);
  }
});
```

### Custom Attributes and Tags

APM agents allow applications to add custom metadata to spans for business-specific tracking.

```javascript
class ExtensibleAPM {
  constructor() {
    this.globalAttributes = {};
    this.attributeProcessors = [];
  }
  
  setGlobalAttribute(key, value) {
    this.globalAttributes[key] = value;
  }
  
  addAttributeProcessor(processor) {
    this.attributeProcessors.push(processor);
  }
  
  async trackedFetch(url, options = {}) {
    const span = this.createSpan(url, options);
    
    // Apply custom attributes from options
    if (options.apmAttributes) {
      Object.assign(span.attributes, options.apmAttributes);
    }
    
    // Apply global attributes
    Object.assign(span.attributes, this.globalAttributes);
    
    // Run attribute processors
    for (const processor of this.attributeProcessors) {
      await processor(span, url, options);
    }
    
    try {
      const response = await fetch(url, options);
      span.attributes['http.status_code'] = response.status;
      span.endTime = performance.now();
      this.recordSpan(span);
      return response;
    } catch (error) {
      span.error = error;
      span.endTime = performance.now();
      this.recordSpan(span);
      throw error;
    }
  }
}

// Usage
const apm = new ExtensibleAPM();

// Set global context
apm.setGlobalAttribute('user.id', currentUserId);
apm.setGlobalAttribute('app.version', '1.2.3');

// Add custom processor
apm.addAttributeProcessor((span, url, options) => {
  if (url.includes('/api/')) {
    span.attributes['api.version'] = 'v2';
  }
  
  if (options.body) {
    try {
      const body = JSON.parse(options.body);
      span.attributes['request.type'] = body.type;
    } catch {}
  }
});

// Make tracked request with custom attributes
apm.trackedFetch('/api/orders', {
  method: 'POST',
  body: JSON.stringify({ type: 'purchase' }),
  apmAttributes: {
    'business.order_type': 'premium',
    'business.customer_segment': 'enterprise'
  }
});
```

### Integration with Real User Monitoring (RUM)

APM fetch instrumentation feeds into broader RUM metrics, correlating backend performance with frontend user experience.

```javascript
class RUMIntegration {
  constructor() {
    this.pageLoadId = this.generateId();
    this.fetchCount = 0;
    this.totalFetchTime = 0;
    this.errors = [];
  }
  
  instrumentFetch() {
    const originalFetch = window.fetch;
    
    window.fetch = async (...args) => {
      const fetchId = this.fetchCount++;
      const startTime = performance.now();
      
      try {
        const response = await originalFetch(...args);
        const duration = performance.now() - startTime;
        
        this.totalFetchTime += duration;
        
        this.recordRUMMetric({
          type: 'fetch',
          pageLoadId: this.pageLoadId,
          fetchId,
          duration,
          status: response.status,
          url: args[0],
          timestamp: Date.now()
        });
        
        return response;
      } catch (error) {
        const duration = performance.now() - startTime;
        
        this.errors.push({
          fetchId,
          error: error.message,
          url: args[0]
        });
        
        this.recordRUMMetric({
          type: 'fetch_error',
          pageLoadId: this.pageLoadId,
          fetchId,
          duration,
          error: error.message,
          url: args[0],
          timestamp: Date.now()
        });
        
        throw error;
      }
    };
  }
  
  recordRUMMetric(metric) {
    // Send to RUM collector
    navigator.sendBeacon('/rum/metrics', JSON.stringify(metric));
  }
  
  getPageMetrics() {
    return {
      pageLoadId: this.pageLoadId,
      totalFetches: this.fetchCount,
      totalFetchTime: this.totalFetchTime,
      errorCount: this.errors.length,
      avgFetchTime: this.fetchCount > 0 ? 
        this.totalFetchTime / this.fetchCount : 0
    };
  }
  
  generateId() {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

### Vendor-Specific Implementations

Different APM vendors have varying instrumentation patterns, though most follow similar core concepts.

```javascript
// Example: OpenTelemetry-style instrumentation
class OTelFetchInstrumentation {
  constructor(tracer) {
    this.tracer = tracer;
  }
  
  instrument() {
    const originalFetch = window.fetch;
    const tracer = this.tracer;
    
    window.fetch = function(input, init = {}) {
      const url = typeof input === 'string' ? input : input.url;
      const method = init.method || 'GET';
      
      return tracer.startActiveSpan(`HTTP ${method}`, (span) => {
        span.setAttribute('http.method', method);
        span.setAttribute('http.url', url);
        span.setAttribute('http.target', new URL(url, location.href).pathname);
        
        // Inject trace context
        const headers = new Headers(init.headers);
        tracer.inject(span.spanContext(), headers);
        
        return originalFetch(input, { ...init, headers })
          .then(response => {
            span.setAttribute('http.status_code', response.status);
            
            if (response.status >= 400) {
              span.setStatus({ 
                code: 2, // ERROR
                message: `HTTP ${response.status}` 
              });
            }
            
            span.end();
            return response;
          })
          .catch(error => {
            span.recordException(error);
            span.setStatus({ code: 2, message: error.message });
            span.end();
            throw error;
          });
      });
    };
  }
}
```

### Performance Budget Integration

APM data can trigger alerts when fetch performance degrades beyond acceptable thresholds.

```javascript
class PerformanceBudgetMonitor {
  constructor(budgets) {
    this.budgets = budgets;
    this.violations = [];
    this.windowSize = 50; // Track last 50 requests per endpoint
    this.endpointStats = new Map();
  }
  
  recordFetch(url, duration, status) {
    const endpoint = this.normalizeEndpoint(url);
    
    if (!this.endpointStats.has(endpoint)) {
      this.endpointStats.set(endpoint, []);
    }
    
    const stats = this.endpointStats.get(endpoint);
    stats.push({ duration, status, timestamp: Date.now() });
    
    // Keep only recent requests
    if (stats.length > this.windowSize) {
      stats.shift();
    }
    
    // Check budgets
    this.checkBudgets(endpoint, stats);
  }
  
  checkBudgets(endpoint, stats) {
    const budget = this.budgets[endpoint] || this.budgets['*'];
    if (!budget) return;
    
    const recentStats = stats.slice(-20); // Last 20 requests
    const avgDuration = recentStats.reduce((sum, s) => sum + s.duration, 0) / 
                        recentStats.length;
    const errorRate = recentStats.filter(s => s.status >= 400).length / 
                      recentStats.length;
    
    if (avgDuration > budget.maxAvgDuration) {
      this.recordViolation({
        type: 'duration',
        endpoint,
        value: avgDuration,
        budget: budget.maxAvgDuration
      });
    }
    
    if (errorRate > budget.maxErrorRate) {
      this.recordViolation({
        type: 'error_rate',
        endpoint,
        value: errorRate,
        budget: budget.maxErrorRate
      });
    }
  }
  
  recordViolation(violation) {
    this.violations.push({ ...violation, timestamp: Date.now() });
    
    // Trigger alert
    this.sendAlert(violation);
  }
  
  sendAlert(violation) {
    fetch('/apm/alerts', {
      method: 'POST',
      body: JSON.stringify(violation),
      headers: { 'Content-Type': 'application/json' },
      keepalive: true
    });
  }
  
  normalizeEndpoint(url) {
    try {
      const parsed = new URL(url, location.href);
      return parsed.pathname.replace(/\/\d+/g, '/:id')
                           .replace(/\/[a-f0-9-]{36}/g, '/:uuid');
    } catch {
      return url;
    }
  }
}

// Usage
const monitor = new PerformanceBudgetMonitor({
  '/api/users/:id': {
    maxAvgDuration: 200,
    maxErrorRate: 0.01
  },
  '/api/orders': {
    maxAvgDuration: 500,
    maxErrorRate: 0.05
  },
  '*': {
    maxAvgDuration: 1000,
    maxErrorRate: 0.1
  }
});
```

---

## Fetch API Custom Metrics

### User Timing API for Fetch Operations

Create custom performance marks and measures around fetch operations:

```javascript
performance.mark('user-action-start');

const response = await fetch('/api/data');
performance.mark('fetch-complete');

const data = await response.json();
performance.mark('parsing-complete');

performance.measure('fetch-duration', 'user-action-start', 'fetch-complete');
performance.measure('parse-duration', 'fetch-complete', 'parsing-complete');
performance.measure('total-operation', 'user-action-start', 'parsing-complete');

const measures = performance.getEntriesByType('measure');
measures.forEach(measure => {
  console.log(`${measure.name}: ${measure.duration}ms`);
});
```

### Custom Metric Collection Classes

#### Basic Fetch Metrics Collector

```javascript
class FetchMetrics {
  constructor(name) {
    this.name = name;
    this.startTime = null;
    this.endTime = null;
    this.metrics = {};
  }
  
  start() {
    this.startTime = performance.now();
    this.metrics.startTimestamp = Date.now();
  }
  
  recordFetchStart() {
    this.metrics.fetchStartTime = performance.now();
  }
  
  recordFetchEnd() {
    this.metrics.fetchEndTime = performance.now();
    this.metrics.fetchDuration = this.metrics.fetchEndTime - this.metrics.fetchStartTime;
  }
  
  recordParseStart() {
    this.metrics.parseStartTime = performance.now();
  }
  
  recordParseEnd() {
    this.metrics.parseEndTime = performance.now();
    this.metrics.parseDuration = this.metrics.parseEndTime - this.metrics.parseStartTime;
  }
  
  end() {
    this.endTime = performance.now();
    this.metrics.totalDuration = this.endTime - this.startTime;
    this.metrics.endTimestamp = Date.now();
    return this.metrics;
  }
}

// Usage
const metrics = new FetchMetrics('api-call');
metrics.start();

metrics.recordFetchStart();
const response = await fetch('/api/data');
metrics.recordFetchEnd();

metrics.recordParseStart();
const data = await response.json();
metrics.recordParseEnd();

console.log(metrics.end());
```

#### Advanced Metrics with Metadata

```javascript
class DetailedFetchMetrics {
  constructor(url, options = {}) {
    this.url = url;
    this.method = options.method || 'GET';
    this.startTime = performance.now();
    this.phases = {};
    this.metadata = {};
    this.errors = [];
  }
  
  phase(name) {
    const now = performance.now();
    const previousPhase = this.currentPhase;
    
    if (previousPhase) {
      this.phases[previousPhase].end = now;
      this.phases[previousPhase].duration = now - this.phases[previousPhase].start;
    }
    
    this.phases[name] = {
      start: now,
      end: null,
      duration: null
    };
    
    this.currentPhase = name;
    return this;
  }
  
  addMetadata(key, value) {
    this.metadata[key] = value;
    return this;
  }
  
  recordError(error) {
    this.errors.push({
      message: error.message,
      timestamp: performance.now(),
      phase: this.currentPhase
    });
    return this;
  }
  
  complete() {
    if (this.currentPhase) {
      const now = performance.now();
      this.phases[this.currentPhase].end = now;
      this.phases[this.currentPhase].duration = now - this.phases[this.currentPhase].start;
    }
    
    return {
      url: this.url,
      method: this.method,
      totalDuration: performance.now() - this.startTime,
      phases: this.phases,
      metadata: this.metadata,
      errors: this.errors,
      timestamp: Date.now()
    };
  }
}

// Usage
const metrics = new DetailedFetchMetrics('/api/users', { method: 'POST' });

metrics.phase('validation').addMetadata('payloadSize', JSON.stringify(data).length);

try {
  metrics.phase('network');
  const response = await fetch('/api/users', {
    method: 'POST',
    body: JSON.stringify(data)
  });
  
  metrics.addMetadata('statusCode', response.status)
        .addMetadata('contentType', response.headers.get('content-type'));
  
  metrics.phase('deserialization');
  const result = await response.json();
  
  metrics.addMetadata('resultSize', JSON.stringify(result).length);
} catch (error) {
  metrics.recordError(error);
}

console.log(metrics.complete());
```

### Business Logic Metrics

Track custom business-relevant metrics:

```javascript
class BusinessMetrics {
  constructor() {
    this.metrics = {};
  }
  
  async trackDataFreshness(url, cacheKey) {
    const cached = localStorage.getItem(cacheKey);
    const cacheTimestamp = localStorage.getItem(`${cacheKey}_timestamp`);
    
    const startTime = performance.now();
    const response = await fetch(url);
    const data = await response.json();
    
    const freshness = cacheTimestamp ? 
      Date.now() - parseInt(cacheTimestamp) : null;
    
    return {
      fetchDuration: performance.now() - startTime,
      dataFreshness: freshness,
      cacheHit: !!cached,
      cacheAge: freshness ? `${(freshness / 1000 / 60).toFixed(2)} minutes` : 'N/A'
    };
  }
  
  async trackConversionPath(steps) {
    const metrics = {
      steps: [],
      totalDuration: 0,
      stepCount: steps.length
    };
    
    const overallStart = performance.now();
    
    for (const step of steps) {
      const stepStart = performance.now();
      
      try {
        await step.action();
        
        metrics.steps.push({
          name: step.name,
          duration: performance.now() - stepStart,
          success: true
        });
      } catch (error) {
        metrics.steps.push({
          name: step.name,
          duration: performance.now() - stepStart,
          success: false,
          error: error.message
        });
        break;
      }
    }
    
    metrics.totalDuration = performance.now() - overallStart;
    metrics.completionRate = metrics.steps.filter(s => s.success).length / steps.length;
    
    return metrics;
  }
  
  async trackSearchQuality(query, resultsUrl) {
    const startTime = performance.now();
    const response = await fetch(resultsUrl);
    const results = await response.json();
    
    return {
      query,
      responseTime: performance.now() - startTime,
      resultCount: results.length,
      emptyResults: results.length === 0,
      avgResultSize: results.reduce((sum, r) => sum + JSON.stringify(r).length, 0) / results.length
    };
  }
}
```

### Retry and Resilience Metrics

Track retry behavior and failure patterns:

```javascript
class RetryMetrics {
  constructor(maxRetries = 3) {
    this.maxRetries = maxRetries;
    this.attempts = [];
  }
  
  async fetchWithRetry(url, options = {}) {
    const startTime = performance.now();
    
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      const attemptStart = performance.now();
      
      try {
        const response = await fetch(url, options);
        
        this.attempts.push({
          attempt,
          duration: performance.now() - attemptStart,
          success: true,
          statusCode: response.status
        });
        
        return {
          response,
          metrics: this.getMetrics(performance.now() - startTime)
        };
      } catch (error) {
        this.attempts.push({
          attempt,
          duration: performance.now() - attemptStart,
          success: false,
          error: error.name,
          errorMessage: error.message
        });
        
        if (attempt === this.maxRetries) {
          return {
            response: null,
            metrics: this.getMetrics(performance.now() - startTime)
          };
        }
        
        // Exponential backoff
        await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 100));
      }
    }
  }
  
  getMetrics(totalDuration) {
    const successfulAttempts = this.attempts.filter(a => a.success).length;
    const failedAttempts = this.attempts.filter(a => !a.success).length;
    
    return {
      totalDuration,
      attemptsCount: this.attempts.length,
      successfulAttempts,
      failedAttempts,
      successRate: successfulAttempts / this.attempts.length,
      attempts: this.attempts,
      finalStatus: this.attempts[this.attempts.length - 1].success ? 'success' : 'failed'
    };
  }
}

// Usage
const retryMetrics = new RetryMetrics(3);
const result = await retryMetrics.fetchWithRetry('/api/unreliable-endpoint');
console.log(result.metrics);
```

### Request Waterfall Tracking

Track dependencies and sequential/parallel request patterns:

```javascript
class WaterfallMetrics {
  constructor() {
    this.requests = [];
    this.startTime = performance.now();
  }
  
  async trackRequest(name, fetchPromise, dependencies = []) {
    const request = {
      name,
      dependencies,
      startTime: performance.now(),
      endTime: null,
      duration: null,
      startOffset: performance.now() - this.startTime
    };
    
    try {
      const result = await fetchPromise;
      request.endTime = performance.now();
      request.duration = request.endTime - request.startTime;
      request.success = true;
      this.requests.push(request);
      return result;
    } catch (error) {
      request.endTime = performance.now();
      request.duration = request.endTime - request.startTime;
      request.success = false;
      request.error = error.message;
      this.requests.push(request);
      throw error;
    }
  }
  
  getWaterfall() {
    return {
      totalDuration: performance.now() - this.startTime,
      requests: this.requests,
      criticalPath: this.calculateCriticalPath(),
      parallelismScore: this.calculateParallelism()
    };
  }
  
  calculateCriticalPath() {
    // [Inference] Find longest dependency chain
    const paths = [];
    
    const findPath = (request, currentPath = []) => {
      const newPath = [...currentPath, request];
      
      const dependents = this.requests.filter(r => 
        r.dependencies.includes(request.name)
      );
      
      if (dependents.length === 0) {
        paths.push(newPath);
      } else {
        dependents.forEach(dep => findPath(dep, newPath));
      }
    };
    
    const roots = this.requests.filter(r => r.dependencies.length === 0);
    roots.forEach(root => findPath(root));
    
    const longestPath = paths.reduce((longest, current) => {
      const currentDuration = current.reduce((sum, r) => sum + r.duration, 0);
      const longestDuration = longest.reduce((sum, r) => sum + r.duration, 0);
      return currentDuration > longestDuration ? current : longest;
    }, []);
    
    return {
      requests: longestPath.map(r => r.name),
      duration: longestPath.reduce((sum, r) => sum + r.duration, 0)
    };
  }
  
  calculateParallelism() {
    // [Inference] Measure how parallel the execution was
    const totalRequestTime = this.requests.reduce((sum, r) => sum + r.duration, 0);
    const wallClockTime = performance.now() - this.startTime;
    return totalRequestTime / wallClockTime;
  }
}

// Usage
const waterfall = new WaterfallMetrics();

const user = await waterfall.trackRequest('user', fetch('/api/user'));
const [profile, settings] = await Promise.all([
  waterfall.trackRequest('profile', fetch('/api/profile'), ['user']),
  waterfall.trackRequest('settings', fetch('/api/settings'), ['user'])
]);
const recommendations = await waterfall.trackRequest(
  'recommendations',
  fetch('/api/recommendations'),
  ['profile']
);

console.log(waterfall.getWaterfall());
```

### Bandwidth and Throughput Metrics

Calculate custom bandwidth metrics:

```javascript
class BandwidthMetrics {
  async measureThroughput(url) {
    const startTime = performance.now();
    let bytesReceived = 0;
    let chunks = [];
    
    const response = await fetch(url);
    const reader = response.body.getReader();
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      bytesReceived += value.length;
      chunks.push({
        timestamp: performance.now(),
        size: value.length,
        totalReceived: bytesReceived
      });
    }
    
    const totalTime = performance.now() - startTime;
    
    return {
      totalBytes: bytesReceived,
      totalTime,
      averageThroughput: (bytesReceived / totalTime) * 1000, // bytes per second
      throughputMBps: ((bytesReceived / totalTime) * 1000) / (1024 * 1024),
      chunks: chunks.length,
      chunkMetrics: this.analyzeChunks(chunks)
    };
  }
  
  analyzeChunks(chunks) {
    if (chunks.length < 2) return null;
    
    const throughputs = [];
    
    for (let i = 1; i < chunks.length; i++) {
      const timeDiff = chunks[i].timestamp - chunks[i - 1].timestamp;
      const sizeDiff = chunks[i].size;
      const throughput = (sizeDiff / timeDiff) * 1000; // bytes per second
      throughputs.push(throughput);
    }
    
    throughputs.sort((a, b) => a - b);
    
    return {
      minThroughput: throughputs[0],
      maxThroughput: throughputs[throughputs.length - 1],
      medianThroughput: throughputs[Math.floor(throughputs.length / 2)],
      variability: (throughputs[throughputs.length - 1] - throughputs[0]) / throughputs[0]
    };
  }
  
  async measureLatency(url, samples = 5) {
    const latencies = [];
    
    for (let i = 0; i < samples; i++) {
      const start = performance.now();
      
      await fetch(url, { method: 'HEAD' });
      
      const latency = performance.now() - start;
      latencies.push(latency);
      
      // Small delay between samples
      if (i < samples - 1) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }
    
    latencies.sort((a, b) => a - b);
    
    return {
      samples: latencies,
      min: latencies[0],
      max: latencies[latencies.length - 1],
      average: latencies.reduce((a, b) => a + b) / latencies.length,
      median: latencies[Math.floor(latencies.length / 2)],
      jitter: latencies[latencies.length - 1] - latencies[0]
    };
  }
}
```

### Cache Effectiveness Metrics

Custom cache hit/miss tracking:

```javascript
class CacheMetrics {
  constructor() {
    this.cacheStats = {
      hits: 0,
      misses: 0,
      partialHits: 0,
      requests: []
    };
  }
  
  async fetchWithCacheTracking(url, options = {}) {
    const startTime = performance.now();
    const cacheMode = options.cache || 'default';
    
    const response = await fetch(url, options);
    const duration = performance.now() - startTime;
    
    // Check if served from cache
    const wasCached = response.headers.get('x-cache') === 'HIT' || 
                      response.headers.has('age');
    
    const requestMetric = {
      url,
      timestamp: Date.now(),
      duration,
      cached: wasCached,
      cacheMode,
      statusCode: response.status
    };
    
    if (wasCached) {
      this.cacheStats.hits++;
    } else {
      this.cacheStats.misses++;
    }
    
    this.cacheStats.requests.push(requestMetric);
    
    return { response, metrics: requestMetric };
  }
  
  getEffectiveness() {
    const total = this.cacheStats.hits + this.cacheStats.misses;
    
    return {
      hitRate: total > 0 ? this.cacheStats.hits / total : 0,
      missRate: total > 0 ? this.cacheStats.misses / total : 0,
      totalRequests: total,
      hits: this.cacheStats.hits,
      misses: this.cacheStats.misses,
      averageHitDuration: this.calculateAverageDuration(true),
      averageMissDuration: this.calculateAverageDuration(false)
    };
  }
  
  calculateAverageDuration(cached) {
    const filtered = this.cacheStats.requests.filter(r => r.cached === cached);
    if (filtered.length === 0) return 0;
    return filtered.reduce((sum, r) => sum + r.duration, 0) / filtered.length;
  }
}
```

### Error Rate and Reliability Metrics

Track error patterns and reliability:

```javascript
class ReliabilityMetrics {
  constructor(window = 100) {
    this.window = window;
    this.requests = [];
  }
  
  async trackRequest(url, options = {}) {
    const startTime = performance.now();
    const request = {
      url,
      timestamp: Date.now(),
      startTime,
      endTime: null,
      duration: null,
      success: false,
      statusCode: null,
      error: null
    };
    
    try {
      const response = await fetch(url, options);
      request.endTime = performance.now();
      request.duration = request.endTime - request.startTime;
      request.statusCode = response.status;
      request.success = response.ok;
      
      this.requests.push(request);
      this.trimWindow();
      
      return { response, metrics: this.getMetrics() };
    } catch (error) {
      request.endTime = performance.now();
      request.duration = request.endTime - request.startTime;
      request.error = error.name;
      request.success = false;
      
      this.requests.push(request);
      this.trimWindow();
      
      throw error;
    }
  }
  
  trimWindow() {
    if (this.requests.length > this.window) {
      this.requests = this.requests.slice(-this.window);
    }
  }
  
  getMetrics() {
    const successful = this.requests.filter(r => r.success);
    const failed = this.requests.filter(r => !r.success);
    
    return {
      totalRequests: this.requests.length,
      successfulRequests: successful.length,
      failedRequests: failed.length,
      successRate: successful.length / this.requests.length,
      errorRate: failed.length / this.requests.length,
      availability: this.calculateAvailability(),
      mtbf: this.calculateMTBF(),
      errorsByType: this.groupErrorsByType()
    };
  }
  
  calculateAvailability() {
    // [Inference] Calculate uptime percentage based on success rate
    const successful = this.requests.filter(r => r.success).length;
    return successful / this.requests.length;
  }
  
  calculateMTBF() {
    // [Inference] Mean time between failures
    const failures = this.requests
      .map((r, i) => ({ ...r, index: i }))
      .filter(r => !r.success);
    
    if (failures.length < 2) return null;
    
    const timeBetweenFailures = [];
    for (let i = 1; i < failures.length; i++) {
      const timeDiff = failures[i].timestamp - failures[i - 1].timestamp;
      timeBetweenFailures.push(timeDiff);
    }
    
    return timeBetweenFailures.reduce((a, b) => a + b) / timeBetweenFailures.length;
  }
  
  groupErrorsByType() {
    const errors = this.requests.filter(r => !r.success);
    const grouped = {};
    
    errors.forEach(error => {
      const key = error.error || `HTTP ${error.statusCode}`;
      grouped[key] = (grouped[key] || 0) + 1;
    });
    
    return grouped;
  }
}
```

### Custom Performance Observers

Create specialized observers for fetch events:

```javascript
class FetchObserver {
  constructor(callback) {
    this.callback = callback;
    this.metrics = [];
    this.setupObserver();
  }
  
  setupObserver() {
    const observer = new PerformanceObserver((list) => {
      list.getEntries().forEach((entry) => {
        if (entry.initiatorType === 'fetch') {
          const customMetrics = this.enrichMetrics(entry);
          this.metrics.push(customMetrics);
          this.callback(customMetrics);
        }
      });
    });
    
    observer.observe({ entryTypes: ['resource'] });
    this.observer = observer;
  }
  
  enrichMetrics(entry) {
    const dns = entry.domainLookupEnd - entry.domainLookupStart;
    const tcp = entry.connectEnd - entry.connectStart;
    const ssl = entry.secureConnectionStart > 0 ? 
                entry.connectEnd - entry.secureConnectionStart : 0;
    const ttfb = entry.responseStart - entry.requestStart;
    const download = entry.responseEnd - entry.responseStart;
    
    return {
      url: entry.name,
      timestamp: Date.now(),
      
      // Timing breakdown
      timings: {
        dns,
        tcp,
        ssl,
        ttfb,
        download,
        total: entry.duration
      },
      
      // Custom metrics
      wasRedirected: entry.redirectEnd > 0,
      redirectTime: entry.redirectEnd - entry.redirectStart,
      connectionReused: entry.connectStart === entry.connectEnd,
      fromCache: entry.transferSize === 0,
      
      // Size metrics
      transferSize: entry.transferSize,
      encodedBodySize: entry.encodedBodySize,
      decodedBodySize: entry.decodedBodySize,
      compressionRatio: entry.encodedBodySize > 0 ? 
        1 - (entry.encodedBodySize / entry.decodedBodySize) : 0,
      
      // Protocol
      protocol: entry.nextHopProtocol,
      
      // [Inference] Performance classification
      performance: this.classifyPerformance(entry.duration, ttfb),
      
      // Raw entry
      rawEntry: entry
    };
  }
  
  classifyPerformance(duration, ttfb) {
    // [Inference] Classify request performance
    if (duration < 100 && ttfb < 50) return 'excellent';
    if (duration < 300 && ttfb < 150) return 'good';
    if (duration < 1000 && ttfb < 500) return 'fair';
    return 'poor';
  }
  
  getAggregatedMetrics() {
    return {
      totalRequests: this.metrics.length,
      averageDuration: this.average(this.metrics.map(m => m.timings.total)),
      averageTTFB: this.average(this.metrics.map(m => m.timings.ttfb)),
      cacheHitRate: this.metrics.filter(m => m.fromCache).length / this.metrics.length,
      performanceDistribution: this.getPerformanceDistribution()
    };
  }
  
  average(arr) {
    return arr.reduce((a, b) => a + b, 0) / arr.length;
  }
  
  getPerformanceDistribution() {
    const dist = { excellent: 0, good: 0, fair: 0, poor: 0 };
    this.metrics.forEach(m => dist[m.performance]++);
    return dist;
  }
  
  disconnect() {
    this.observer.disconnect();
  }
}

// Usage
const observer = new FetchObserver((metrics) => {
  console.log('Fetch completed:', metrics);
  
  if (metrics.performance === 'poor') {
    console.warn('Poor performance detected:', metrics.url);
  }
});

// Later: observer.disconnect();
```

### Real-time Performance Dashboard Data

Collect metrics for live monitoring:

```javascript
class PerformanceDashboard {
  constructor() {
    this.metrics = {
      requests: [],
      current: {
        rps: 0,
        avgLatency: 0,
        errorRate: 0,
        p50: 0,
        p95: 0,
        p99: 0
      }
    };
    
    this.windowSize = 60000; // 1 minute
    this.updateInterval = 1000; // Update every second
    
    this.startUpdates();
  }
  
  recordRequest(duration, success, error = null) {
    this.metrics.requests.push({
      timestamp: Date.now(),
      duration,
      success,
      error
    });
    
    this.trimWindow();
  }
  
  trimWindow() {
    const cutoff = Date.now() - this.windowSize;
    this.metrics.requests = this.metrics.requests.filter(
      r => r.timestamp > cutoff
    );
  }
  
  startUpdates() {
    this.intervalId = setInterval(() => {
      this.updateMetrics();
    }, this.updateInterval);
  }
  
  updateMetrics() {
    this.trimWindow();
    
    const requests = this.metrics.requests;
    const windowSeconds = this.windowSize / 1000;
    
    // Requests per second
    this.metrics.current.rps = requests.length / windowSeconds;
    
    // Average latency
    const durations = requests.map(r => r.duration);
    this.metrics.current.avgLatency = durations.length > 0 ?
      durations.reduce((a, b) => a + b, 0) / durations.length : 0;
    
    // Error rate
    const errors = requests.filter(r => !r.success);
    this.metrics.current.errorRate = requests.length > 0 ?
      errors.length / requests.length : 0;
    
    // Percentiles
    if (durations.length > 0) {
      durations.sort((a, b) => a - b);
      this.metrics.current.p50 = this.percentile(durations, 50);
      this.metrics.current.p95 = this.percentile(durations, 95);
      this.metrics.current.p99 = this.percentile(durations, 99);
    }
  }
  
  percentile(sortedArray, p) {
    const index = Math.ceil((p / 100) * sortedArray.length) - 1;
    return sortedArray[Math.max(0, index)];
  }
  
  getCurrentMetrics() {
    return { ...this.metrics.current };
  }
  
  stop() {
    clearInterval(this.intervalId);
  }
}

// Usage
const dashboard = new PerformanceDashboard();

async function monitoredFetch(url) {
  const start = performance.now();
  
  try {
    const response = await fetch(url);
    const duration = performance.now() - start;
    dashboard.recordRequest(duration, response.ok);
    return response;
  } catch (error) {
    const duration = performance.now() - start;
    dashboard.recordRequest(duration, false, error.message);
    throw error;
  }
}

// Get current metrics for display
setInterval(() => {
  console.log(dashboard.getCurrentMetrics());
}, 5000);
```

### Custom Metric Export Formats

Export metrics in different formats:

```javascript
class MetricsExporter {
  constructor() {
    this.metrics = [];
  }
  
  addMetric(name, value, tags = {}) {
    this.metrics.push({
      name,
      value,
      tags,
      timestamp: Date.now()
    });
  }
  
  exportPrometheus() {
    // Prometheus exposition format
    return this.metrics.map(m => {
      const tagsStr = Object.entries(m.tags)
        .map(([k, v]) => `${k}="${v}"`)
        .join(',');
      
      return `${m.name}{${tagsStr}} ${m.value} ${m.timestamp}`;
    }).join('\n');
  }
  
  exportStatsd() {
    // StatsD format
    return this.metrics.map(m => {
      const tagsStr = Object.entries(m.tags)
        .map(([k, v]) => `${k}:${v}`)
        .join(',');
      
      return `${m.name}:${m.value}|ms|#${tagsStr}`;
    }).join('\n');
  }
  
  exportJSON() {
    return JSON.stringify(this.metrics, null, 2);
  }
  
  exportCSV() {
    if (this.metrics.length === 0) return '';
    
    const headers = ['timestamp', 'name', 'value', ...Object.keys(this.metrics[0].tags)];
    const rows = this.metrics.map(m => [
      m.timestamp,
      m.name,
      m.value,
      ...Object.values(m.tags)
    ]);
    
    return [
      headers.join(','),
      ...rows.map(r => r.join(','))
    ].join('\n');
  }
}

// Usage
const exporter = new MetricsExporter();

exporter.addMetric('fetch_duration', 245, {
  endpoint: '/api/users',
  method: 'GET',
  status: 200
});

exporter.addMetric('fetch_size', 1024, {
  endpoint: '/api/users',
  type: 'response'
});
```

---

## Fetch API Logging Strategies

### Structured Logging

Structure logs as JSON objects for easier parsing and analysis:

```javascript
function logFetchRequest(url, options, metadata = {}) {
  const log = {
    timestamp: new Date().toISOString(),
    type: 'fetch_request',
    url: url,
    method: options.method || 'GET',
    headers: options.headers ? Object.keys(options.headers) : [],
    hasBody: !!options.body,
    ...metadata
  };
  
  console.log(JSON.stringify(log));
  return log;
}

function logFetchResponse(url, response, duration, metadata = {}) {
  const log = {
    timestamp: new Date().toISOString(),
    type: 'fetch_response',
    url: url,
    status: response.status,
    statusText: response.statusText,
    ok: response.ok,
    duration: duration,
    contentType: response.headers.get('content-type'),
    contentLength: response.headers.get('content-length'),
    ...metadata
  };
  
  console.log(JSON.stringify(log));
  return log;
}
```

### Request/Response Correlation

Associate requests with their responses using correlation IDs:

```javascript
function generateCorrelationId() {
  return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
}

async function fetchWithCorrelation(url, options = {}) {
  const correlationId = generateCorrelationId();
  const startTime = performance.now();
  
  console.log({
    correlationId,
    type: 'request_start',
    url,
    method: options.method || 'GET',
    timestamp: new Date().toISOString()
  });
  
  try {
    const response = await fetch(url, options);
    const duration = performance.now() - startTime;
    
    console.log({
      correlationId,
      type: 'request_complete',
      url,
      status: response.status,
      duration: `${duration.toFixed(2)}ms`,
      timestamp: new Date().toISOString()
    });
    
    return response;
  } catch (error) {
    const duration = performance.now() - startTime;
    
    console.error({
      correlationId,
      type: 'request_failed',
      url,
      error: error.message,
      duration: `${duration.toFixed(2)}ms`,
      timestamp: new Date().toISOString()
    });
    
    throw error;
  }
}
```

### Log Levels

Implement different severity levels for appropriate filtering:

```javascript
const LogLevel = {
  DEBUG: 0,
  INFO: 1,
  WARN: 2,
  ERROR: 3
};

class FetchLogger {
  constructor(minLevel = LogLevel.INFO) {
    this.minLevel = minLevel;
  }
  
  log(level, message, data = {}) {
    if (level < this.minLevel) return;
    
    const levelNames = ['DEBUG', 'INFO', 'WARN', 'ERROR'];
    const logEntry = {
      level: levelNames[level],
      message,
      timestamp: new Date().toISOString(),
      ...data
    };
    
    switch (level) {
      case LogLevel.DEBUG:
      case LogLevel.INFO:
        console.log(logEntry);
        break;
      case LogLevel.WARN:
        console.warn(logEntry);
        break;
      case LogLevel.ERROR:
        console.error(logEntry);
        break;
    }
  }
  
  debug(message, data) {
    this.log(LogLevel.DEBUG, message, data);
  }
  
  info(message, data) {
    this.log(LogLevel.INFO, message, data);
  }
  
  warn(message, data) {
    this.log(LogLevel.WARN, message, data);
  }
  
  error(message, data) {
    this.log(LogLevel.ERROR, message, data);
  }
}

// Usage
const logger = new FetchLogger(LogLevel.INFO);

async function fetchData(url) {
  logger.debug('Initiating request', { url });
  
  try {
    const response = await fetch(url);
    
    if (!response.ok) {
      logger.warn('Non-OK response', { url, status: response.status });
    } else {
      logger.info('Request successful', { url, status: response.status });
    }
    
    return response;
  } catch (error) {
    logger.error('Request failed', { url, error: error.message });
    throw error;
  }
}
```

### Performance Metrics

Track detailed timing information:

```javascript
async function fetchWithMetrics(url, options = {}) {
  const metrics = {
    url,
    method: options.method || 'GET',
    startTime: performance.now(),
    dnsLookup: null,
    tcpConnection: null,
    tlsHandshake: null,
    requestSent: null,
    firstByte: null,
    contentDownload: null,
    totalDuration: null
  };
  
  try {
    const response = await fetch(url, options);
    
    // Get performance entry
    const perfEntries = performance.getEntriesByType('resource');
    const entry = perfEntries.find(e => e.name === url);
    
    if (entry) {
      metrics.dnsLookup = entry.domainLookupEnd - entry.domainLookupStart;
      metrics.tcpConnection = entry.connectEnd - entry.connectStart;
      metrics.tlsHandshake = entry.secureConnectionStart > 0 
        ? entry.connectEnd - entry.secureConnectionStart 
        : 0;
      metrics.requestSent = entry.responseStart - entry.requestStart;
      metrics.firstByte = entry.responseStart - entry.fetchStart;
      metrics.contentDownload = entry.responseEnd - entry.responseStart;
      metrics.totalDuration = entry.responseEnd - entry.fetchStart;
    } else {
      metrics.totalDuration = performance.now() - metrics.startTime;
    }
    
    console.log({
      type: 'performance_metrics',
      ...metrics,
      status: response.status
    });
    
    return response;
  } catch (error) {
    metrics.totalDuration = performance.now() - metrics.startTime;
    
    console.error({
      type: 'performance_metrics',
      ...metrics,
      error: error.message
    });
    
    throw error;
  }
}
```

### Request/Response Body Logging

Log payloads with size limits and sanitization:

```javascript
class BodyLogger {
  constructor(maxBodySize = 1000, sanitize = true) {
    this.maxBodySize = maxBodySize;
    this.sanitize = sanitize;
  }
  
  logRequestBody(body) {
    if (!body) return null;
    
    if (typeof body === 'string') {
      return this.truncate(body);
    }
    
    if (body instanceof FormData) {
      const entries = {};
      for (const [key, value] of body.entries()) {
        entries[key] = value instanceof File 
          ? `[File: ${value.name}]` 
          : this.truncate(String(value));
      }
      return entries;
    }
    
    if (body instanceof Blob) {
      return `[Blob: ${body.size} bytes, type: ${body.type}]`;
    }
    
    return '[Unknown body type]';
  }
  
  async logResponseBody(response) {
    const clonedResponse = response.clone();
    const contentType = response.headers.get('content-type') || '';
    
    if (contentType.includes('application/json')) {
      try {
        const json = await clonedResponse.json();
        return this.sanitize 
          ? this.sanitizeData(json) 
          : this.truncate(JSON.stringify(json));
      } catch {
        return '[Invalid JSON]';
      }
    }
    
    if (contentType.includes('text/')) {
      const text = await clonedResponse.text();
      return this.truncate(text);
    }
    
    return `[Binary content: ${contentType}]`;
  }
  
  truncate(str) {
    if (str.length <= this.maxBodySize) return str;
    return str.substring(0, this.maxBodySize) + '... [truncated]';
  }
  
  sanitizeData(data) {
    const sensitiveKeys = ['password', 'token', 'secret', 'apiKey', 'authorization'];
    
    if (typeof data !== 'object' || data === null) {
      return data;
    }
    
    if (Array.isArray(data)) {
      return data.map(item => this.sanitizeData(item));
    }
    
    const sanitized = {};
    for (const [key, value] of Object.entries(data)) {
      if (sensitiveKeys.some(sk => key.toLowerCase().includes(sk))) {
        sanitized[key] = '[REDACTED]';
      } else if (typeof value === 'object') {
        sanitized[key] = this.sanitizeData(value);
      } else {
        sanitized[key] = value;
      }
    }
    
    return sanitized;
  }
}

// Usage
const bodyLogger = new BodyLogger(500, true);

async function fetchWithBodyLogging(url, options = {}) {
  console.log({
    type: 'request',
    url,
    method: options.method || 'GET',
    body: bodyLogger.logRequestBody(options.body)
  });
  
  const response = await fetch(url, options);
  
  const responseBody = await bodyLogger.logResponseBody(response);
  
  console.log({
    type: 'response',
    url,
    status: response.status,
    body: responseBody
  });
  
  return response;
}
```

### Header Logging

Log headers with security considerations:

```javascript
function logHeaders(headers, direction = 'request') {
  const sensitiveHeaders = [
    'authorization',
    'cookie',
    'set-cookie',
    'x-api-key',
    'x-auth-token'
  ];
  
  const logged = {};
  
  if (headers instanceof Headers) {
    for (const [key, value] of headers.entries()) {
      if (sensitiveHeaders.includes(key.toLowerCase())) {
        logged[key] = '[REDACTED]';
      } else {
        logged[key] = value;
      }
    }
  } else if (typeof headers === 'object') {
    for (const [key, value] of Object.entries(headers)) {
      if (sensitiveHeaders.includes(key.toLowerCase())) {
        logged[key] = '[REDACTED]';
      } else {
        logged[key] = value;
      }
    }
  }
  
  console.log({
    type: `${direction}_headers`,
    headers: logged
  });
  
  return logged;
}

async function fetchWithHeaderLogging(url, options = {}) {
  logHeaders(options.headers, 'request');
  
  const response = await fetch(url, options);
  
  logHeaders(response.headers, 'response');
  
  return response;
}
```

### Batched Logging

Buffer logs and send them in batches to reduce overhead:

```javascript
class BatchLogger {
  constructor(batchSize = 10, flushInterval = 5000, endpoint = null) {
    this.batchSize = batchSize;
    this.flushInterval = flushInterval;
    this.endpoint = endpoint;
    this.buffer = [];
    this.timer = null;
    
    this.startTimer();
  }
  
  log(entry) {
    this.buffer.push({
      ...entry,
      timestamp: new Date().toISOString()
    });
    
    if (this.buffer.length >= this.batchSize) {
      this.flush();
    }
  }
  
  async flush() {
    if (this.buffer.length === 0) return;
    
    const batch = [...this.buffer];
    this.buffer = [];
    
    console.log(`[BatchLogger] Flushing ${batch.length} entries`);
    
    if (this.endpoint) {
      try {
        await fetch(this.endpoint, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ logs: batch })
        });
      } catch (error) {
        console.error('[BatchLogger] Failed to send batch:', error);
        // Could re-add to buffer or store locally
      }
    } else {
      // Local logging
      console.log('[BatchLogger] Batch:', batch);
    }
    
    this.startTimer();
  }
  
  startTimer() {
    if (this.timer) clearTimeout(this.timer);
    this.timer = setTimeout(() => this.flush(), this.flushInterval);
  }
  
  destroy() {
    if (this.timer) clearTimeout(this.timer);
    this.flush();
  }
}

// Usage
const batchLogger = new BatchLogger(20, 10000, '/api/logs');

async function fetchWithBatchLogging(url, options = {}) {
  const startTime = performance.now();
  
  batchLogger.log({
    type: 'request_start',
    url,
    method: options.method || 'GET'
  });
  
  try {
    const response = await fetch(url, options);
    const duration = performance.now() - startTime;
    
    batchLogger.log({
      type: 'request_complete',
      url,
      status: response.status,
      duration
    });
    
    return response;
  } catch (error) {
    const duration = performance.now() - startTime;
    
    batchLogger.log({
      type: 'request_error',
      url,
      error: error.message,
      duration
    });
    
    throw error;
  }
}

// Clean up before page unload
window.addEventListener('beforeunload', () => {
  batchLogger.destroy();
});
```

### Context Enrichment

Add contextual information to every log:

```javascript
class ContextualLogger {
  constructor() {
    this.context = {
      sessionId: this.generateSessionId(),
      userId: null,
      environment: this.detectEnvironment(),
      userAgent: navigator.userAgent,
      url: window.location.href
    };
  }
  
  generateSessionId() {
    return `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
  
  detectEnvironment() {
    const hostname = window.location.hostname;
    if (hostname === 'localhost' || hostname === '127.0.0.1') {
      return 'development';
    }
    if (hostname.includes('staging')) {
      return 'staging';
    }
    return 'production';
  }
  
  setUserId(userId) {
    this.context.userId = userId;
  }
  
  addContext(key, value) {
    this.context[key] = value;
  }
  
  log(entry) {
    const enriched = {
      ...this.context,
      ...entry,
      timestamp: new Date().toISOString()
    };
    
    console.log(enriched);
    return enriched;
  }
}

// Global logger instance
const contextLogger = new ContextualLogger();

// Set user context after login
function onUserLogin(user) {
  contextLogger.setUserId(user.id);
  contextLogger.addContext('userRole', user.role);
}

// Use in fetch
async function fetchWithContext(url, options = {}) {
  contextLogger.log({
    type: 'fetch_request',
    url,
    method: options.method || 'GET'
  });
  
  const response = await fetch(url, options);
  
  contextLogger.log({
    type: 'fetch_response',
    url,
    status: response.status
  });
  
  return response;
}
```

### Error Stack Traces

Capture and log detailed error information:

```javascript
function logErrorWithStack(error, context = {}) {
  const errorLog = {
    type: 'error',
    message: error.message,
    name: error.name,
    stack: error.stack,
    timestamp: new Date().toISOString(),
    ...context
  };
  
  // Parse stack trace for better readability
  if (error.stack) {
    const stackLines = error.stack.split('\n');
    errorLog.parsedStack = stackLines.slice(1).map(line => {
      const match = line.match(/at\s+(.+?)\s+\((.+?):(\d+):(\d+)\)/);
      if (match) {
        return {
          function: match[1],
          file: match[2],
          line: parseInt(match[3]),
          column: parseInt(match[4])
        };
      }
      return line.trim();
    });
  }
  
  console.error(errorLog);
  return errorLog;
}

async function fetchWithStackTrace(url, options = {}) {
  try {
    const response = await fetch(url, options);
    
    if (!response.ok) {
      const error = new Error(`HTTP ${response.status}: ${response.statusText}`);
      throw error;
    }
    
    return response;
  } catch (error) {
    logErrorWithStack(error, {
      url,
      method: options.method || 'GET',
      fetchContext: 'api_call'
    });
    
    throw error;
  }
}
```

### Sampling for High-Traffic Scenarios

Log only a percentage of requests in production:

```javascript
class SamplingLogger {
  constructor(sampleRate = 0.1) {
    this.sampleRate = sampleRate; // 0.1 = 10%
    this.alwaysLogErrors = true;
  }
  
  shouldLog() {
    return Math.random() < this.sampleRate;
  }
  
  log(entry, forceLog = false) {
    if (forceLog || this.shouldLog()) {
      console.log({
        ...entry,
        sampled: !forceLog,
        sampleRate: this.sampleRate,
        timestamp: new Date().toISOString()
      });
    }
  }
  
  logError(entry) {
    // Always log errors regardless of sample rate
    console.error({
      ...entry,
      sampled: false,
      timestamp: new Date().toISOString()
    });
  }
}

// Production: log 5% of requests, all errors
const samplingLogger = new SamplingLogger(0.05);

async function fetchWithSampling(url, options = {}) {
  const startTime = performance.now();
  
  samplingLogger.log({
    type: 'request',
    url,
    method: options.method || 'GET'
  });
  
  try {
    const response = await fetch(url, options);
    const duration = performance.now() - startTime;
    
    if (!response.ok) {
      samplingLogger.logError({
        type: 'http_error',
        url,
        status: response.status,
        duration
      });
    } else {
      samplingLogger.log({
        type: 'response',
        url,
        status: response.status,
        duration
      });
    }
    
    return response;
  } catch (error) {
    samplingLogger.logError({
      type: 'network_error',
      url,
      error: error.message
    });
    
    throw error;
  }
}
```

### Integration with External Services

Send logs to third-party monitoring services:

```javascript
class ExternalLogger {
  constructor(config = {}) {
    this.serviceName = config.serviceName;
    this.apiKey = config.apiKey;
    this.endpoint = config.endpoint;
    this.enabled = config.enabled !== false;
  }
  
  async sendLog(log) {
    if (!this.enabled) return;
    
    try {
      // Use sendBeacon for reliability during page unload
      if (navigator.sendBeacon && log.type === 'critical') {
        const blob = new Blob(
          [JSON.stringify(log)],
          { type: 'application/json' }
        );
        navigator.sendBeacon(this.endpoint, blob);
      } else {
        await fetch(this.endpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-API-Key': this.apiKey
          },
          body: JSON.stringify(log),
          keepalive: true
        });
      }
    } catch (error) {
      // Fallback to console if external logging fails
      console.error('[ExternalLogger] Failed to send log:', error);
      console.log('[ExternalLogger] Original log:', log);
    }
  }
  
  logFetchRequest(url, options, result) {
    this.sendLog({
      service: this.serviceName,
      type: 'fetch_request',
      url,
      method: options.method || 'GET',
      status: result.status,
      duration: result.duration,
      timestamp: new Date().toISOString()
    });
  }
  
  logError(url, error) {
    this.sendLog({
      service: this.serviceName,
      type: 'fetch_error',
      url,
      error: {
        message: error.message,
        name: error.name,
        stack: error.stack
      },
      severity: 'error',
      timestamp: new Date().toISOString()
    });
  }
}

// Initialize with your monitoring service
const externalLogger = new ExternalLogger({
  serviceName: 'my-app',
  apiKey: 'your-api-key',
  endpoint: 'https://logs.yourservice.com/v1/logs',
  enabled: true
});
```

### Development vs Production Logging

Adjust logging verbosity based on environment:

```javascript
class EnvironmentLogger {
  constructor() {
    this.isDevelopment = this.detectDevelopment();
  }
  
  detectDevelopment() {
    return (
      window.location.hostname === 'localhost' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname.includes('.local') ||
      process.env.NODE_ENV === 'development'
    );
  }
  
  log(level, message, data = {}) {
    const entry = {
      level,
      message,
      ...data,
      timestamp: new Date().toISOString()
    };
    
    if (this.isDevelopment) {
      // Verbose logging in development
      console.group(`[${level}] ${message}`);
      console.log('Details:', data);
      console.trace();
      console.groupEnd();
    } else {
      // Structured logging in production
      const method = level === 'error' ? 'error' : 'log';
      console[method](JSON.stringify(entry));
    }
  }
  
  debug(message, data) {
    if (this.isDevelopment) {
      this.log('DEBUG', message, data);
    }
  }
  
  info(message, data) {
    this.log('INFO', message, data);
  }
  
  error(message, data) {
    this.log('ERROR', message, data);
  }
}

const envLogger = new EnvironmentLogger();

async function fetchWithEnvironmentLogging(url, options = {}) {
  envLogger.debug('Fetch request initiated', { url, options });
  
  try {
    const response = await fetch(url, options);
    
    envLogger.info('Fetch completed', {
      url,
      status: response.status
    });
    
    return response;
  } catch (error) {
    envLogger.error('Fetch failed', {
      url,
      error: error.message,
      stack: error.stack
    });
    
    throw error;
  }
}
```

---

# Advanced Security

## Token Refresh Flows

### Basic Token Refresh Pattern

Token refresh mechanisms maintain authenticated sessions by obtaining new access tokens before expiration. The fetch API handles authentication headers and token exchange requests with the authorization server.

```javascript
class TokenManager {
  constructor(tokenEndpoint, clientId) {
    this.tokenEndpoint = tokenEndpoint;
    this.clientId = clientId;
    this.accessToken = null;
    this.refreshToken = null;
    this.expiresAt = null;
  }
  
  setTokens(accessToken, refreshToken, expiresIn) {
    this.accessToken = accessToken;
    this.refreshToken = refreshToken;
    // Set expiry slightly before actual expiration (buffer of 60 seconds)
    this.expiresAt = Date.now() + (expiresIn * 1000) - 60000;
  }
  
  isTokenExpired() {
    return !this.accessToken || Date.now() >= this.expiresAt;
  }
  
  async refreshAccessToken() {
    if (!this.refreshToken) {
      throw new Error('No refresh token available');
    }
    
    const response = await fetch(this.tokenEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        grant_type: 'refresh_token',
        refresh_token: this.refreshToken,
        client_id: this.clientId
      })
    });
    
    if (!response.ok) {
      throw new Error(`Token refresh failed: ${response.status}`);
    }
    
    const data = await response.json();
    this.setTokens(data.access_token, data.refresh_token, data.expires_in);
    
    return this.accessToken;
  }
  
  async getValidToken() {
    if (this.isTokenExpired()) {
      await this.refreshAccessToken();
    }
    return this.accessToken;
  }
}

const tokenManager = new TokenManager('https://auth.example.com/oauth/token', 'client_123');
```

### Automatic Token Refresh Interceptor

Request interceptors automatically refresh tokens before making API calls, ensuring seamless authentication without manual intervention.

```javascript
class AuthenticatedFetch {
  constructor(tokenManager) {
    this.tokenManager = tokenManager;
  }
  
  async fetch(url, options = {}) {
    const token = await this.tokenManager.getValidToken();
    
    const authOptions = {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    };
    
    let response = await fetch(url, authOptions);
    
    // Handle token expiration during request
    if (response.status === 401) {
      await this.tokenManager.refreshAccessToken();
      const newToken = this.tokenManager.accessToken;
      
      authOptions.headers['Authorization'] = `Bearer ${newToken}`;
      response = await fetch(url, authOptions);
    }
    
    return response;
  }
}

const authenticatedFetch = new AuthenticatedFetch(tokenManager);

// Usage
const response = await authenticatedFetch.fetch('https://api.example.com/user/profile');
const data = await response.json();
```

### Proactive Token Refresh

Proactive refresh strategies renew tokens before expiration, preventing interruptions during critical operations.

```javascript
class ProactiveTokenManager extends TokenManager {
  constructor(tokenEndpoint, clientId, refreshThreshold = 300000) {
    super(tokenEndpoint, clientId);
    this.refreshThreshold = refreshThreshold; // 5 minutes default
    this.refreshTimer = null;
  }
  
  setTokens(accessToken, refreshToken, expiresIn) {
    super.setTokens(accessToken, refreshToken, expiresIn);
    this.scheduleProactiveRefresh();
  }
  
  scheduleProactiveRefresh() {
    if (this.refreshTimer) {
      clearTimeout(this.refreshTimer);
    }
    
    const timeUntilRefresh = Math.max(
      0,
      this.expiresAt - Date.now() - this.refreshThreshold
    );
    
    this.refreshTimer = setTimeout(async () => {
      try {
        await this.refreshAccessToken();
      } catch (error) {
        console.error('Proactive token refresh failed:', error);
        // Retry with exponential backoff
        setTimeout(() => this.refreshAccessToken(), 5000);
      }
    }, timeUntilRefresh);
  }
  
  clearSchedule() {
    if (this.refreshTimer) {
      clearTimeout(this.refreshTimer);
      this.refreshTimer = null;
    }
  }
}

const proactiveTokenManager = new ProactiveTokenManager(
  'https://auth.example.com/oauth/token',
  'client_123',
  300000 // Refresh 5 minutes before expiration
);
```

### Concurrent Request Deduplication

Multiple simultaneous requests should not trigger duplicate token refresh attempts. Request deduplication ensures a single refresh operation serves all pending requests.

```javascript
class DedupedTokenManager extends TokenManager {
  constructor(tokenEndpoint, clientId) {
    super(tokenEndpoint, clientId);
    this.refreshPromise = null;
  }
  
  async refreshAccessToken() {
    // Return existing refresh promise if refresh is already in progress
    if (this.refreshPromise) {
      return this.refreshPromise;
    }
    
    this.refreshPromise = (async () => {
      try {
        if (!this.refreshToken) {
          throw new Error('No refresh token available');
        }
        
        const response = await fetch(this.tokenEndpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/x-www-form-urlencoded',
          },
          body: new URLSearchParams({
            grant_type: 'refresh_token',
            refresh_token: this.refreshToken,
            client_id: this.clientId
          })
        });
        
        if (!response.ok) {
          throw new Error(`Token refresh failed: ${response.status}`);
        }
        
        const data = await response.json();
        this.setTokens(data.access_token, data.refresh_token, data.expires_in);
        
        return this.accessToken;
      } finally {
        this.refreshPromise = null;
      }
    })();
    
    return this.refreshPromise;
  }
}

// Multiple concurrent requests will share the same refresh operation
const dedupedManager = new DedupedTokenManager('https://auth.example.com/oauth/token', 'client_123');

// These will trigger only one refresh
Promise.all([
  authenticatedFetch.fetch('https://api.example.com/endpoint1'),
  authenticatedFetch.fetch('https://api.example.com/endpoint2'),
  authenticatedFetch.fetch('https://api.example.com/endpoint3')
]);
```

### Token Persistence and Restoration

Persisting tokens across browser sessions requires secure storage mechanisms while managing the refresh lifecycle.

```javascript
class PersistentTokenManager extends DedupedTokenManager {
  constructor(tokenEndpoint, clientId, storageKey = 'auth_tokens') {
    super(tokenEndpoint, clientId);
    this.storageKey = storageKey;
    this.restoreTokens();
  }
  
  setTokens(accessToken, refreshToken, expiresIn) {
    super.setTokens(accessToken, refreshToken, expiresIn);
    this.persistTokens();
  }
  
  persistTokens() {
    const tokenData = {
      accessToken: this.accessToken,
      refreshToken: this.refreshToken,
      expiresAt: this.expiresAt
    };
    
    try {
      localStorage.setItem(this.storageKey, JSON.stringify(tokenData));
    } catch (error) {
      console.error('Failed to persist tokens:', error);
    }
  }
  
  restoreTokens() {
    try {
      const stored = localStorage.getItem(this.storageKey);
      if (!stored) return;
      
      const tokenData = JSON.parse(stored);
      this.accessToken = tokenData.accessToken;
      this.refreshToken = tokenData.refreshToken;
      this.expiresAt = tokenData.expiresAt;
      
      // Immediately refresh if expired
      if (this.isTokenExpired() && this.refreshToken) {
        this.refreshAccessToken().catch(error => {
          console.error('Failed to restore session:', error);
          this.clearTokens();
        });
      }
    } catch (error) {
      console.error('Failed to restore tokens:', error);
      this.clearTokens();
    }
  }
  
  clearTokens() {
    this.accessToken = null;
    this.refreshToken = null;
    this.expiresAt = null;
    
    try {
      localStorage.removeItem(this.storageKey);
    } catch (error) {
      console.error('Failed to clear tokens:', error);
    }
  }
}

const persistentManager = new PersistentTokenManager(
  'https://auth.example.com/oauth/token',
  'client_123'
);
```

### Refresh Token Rotation

Token rotation enhances security by issuing new refresh tokens with each access token refresh, invalidating previous refresh tokens.

```javascript
class RotatingTokenManager extends PersistentTokenManager {
  async refreshAccessToken() {
    if (this.refreshPromise) {
      return this.refreshPromise;
    }
    
    this.refreshPromise = (async () => {
      try {
        if (!this.refreshToken) {
          throw new Error('No refresh token available');
        }
        
        const oldRefreshToken = this.refreshToken;
        
        const response = await fetch(this.tokenEndpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/x-www-form-urlencoded',
          },
          body: new URLSearchParams({
            grant_type: 'refresh_token',
            refresh_token: oldRefreshToken,
            client_id: this.clientId
          })
        });
        
        if (!response.ok) {
          // [Inference] Refresh token might be invalidated
          if (response.status === 401) {
            this.clearTokens();
            throw new Error('Refresh token invalid or expired');
          }
          throw new Error(`Token refresh failed: ${response.status}`);
        }
        
        const data = await response.json();
        
        // Server provides new refresh token with each refresh
        this.setTokens(
          data.access_token,
          data.refresh_token || oldRefreshToken, // Fallback if not rotated
          data.expires_in
        );
        
        return this.accessToken;
      } finally {
        this.refreshPromise = null;
      }
    })();
    
    return this.refreshPromise;
  }
}
```

### Silent Token Refresh with Hidden Iframe

Single Page Applications can leverage hidden iframes for silent token refresh using authorization server session cookies.

```javascript
class SilentTokenRefresh {
  constructor(authEndpoint, clientId, redirectUri) {
    this.authEndpoint = authEndpoint;
    this.clientId = clientId;
    this.redirectUri = redirectUri;
    this.iframe = null;
    this.refreshPromise = null;
  }
  
  async refreshToken() {
    if (this.refreshPromise) {
      return this.refreshPromise;
    }
    
    this.refreshPromise = new Promise((resolve, reject) => {
      // Create hidden iframe
      this.iframe = document.createElement('iframe');
      this.iframe.style.display = 'none';
      this.iframe.sandbox = 'allow-same-origin allow-scripts allow-forms';
      
      const timeoutId = setTimeout(() => {
        this.cleanup();
        reject(new Error('Silent refresh timeout'));
      }, 10000);
      
      // Listen for token response
      const messageHandler = (event) => {
        if (event.origin !== new URL(this.authEndpoint).origin) {
          return;
        }
        
        clearTimeout(timeoutId);
        window.removeEventListener('message', messageHandler);
        this.cleanup();
        
        if (event.data.error) {
          reject(new Error(event.data.error));
        } else {
          resolve(event.data);
        }
        
        this.refreshPromise = null;
      };
      
      window.addEventListener('message', messageHandler);
      
      // Build authorization URL with prompt=none
      const params = new URLSearchParams({
        client_id: this.clientId,
        redirect_uri: this.redirectUri,
        response_type: 'token',
        scope: 'openid profile email',
        prompt: 'none'
      });
      
      this.iframe.src = `${this.authEndpoint}?${params.toString()}`;
      document.body.appendChild(this.iframe);
    });
    
    return this.refreshPromise;
  }
  
  cleanup() {
    if (this.iframe && this.iframe.parentNode) {
      this.iframe.parentNode.removeChild(this.iframe);
      this.iframe = null;
    }
  }
}

const silentRefresh = new SilentTokenRefresh(
  'https://auth.example.com/authorize',
  'client_123',
  'https://app.example.com/callback'
);
```

### Refresh Failure Handling

Graceful degradation when refresh operations fail requires clear user communication and session recovery strategies.

```javascript
class RobustTokenManager extends RotatingTokenManager {
  constructor(tokenEndpoint, clientId, onRefreshFailure) {
    super(tokenEndpoint, clientId);
    this.onRefreshFailure = onRefreshFailure;
    this.refreshAttempts = 0;
    this.maxRetries = 3;
  }
  
  async refreshAccessToken() {
    try {
      const token = await super.refreshAccessToken();
      this.refreshAttempts = 0; // Reset on success
      return token;
    } catch (error) {
      this.refreshAttempts++;
      
      if (this.refreshAttempts >= this.maxRetries) {
        this.handleRefreshFailure(error);
        throw error;
      }
      
      // Exponential backoff retry
      const delay = Math.pow(2, this.refreshAttempts) * 1000;
      await new Promise(resolve => setTimeout(resolve, delay));
      
      return this.refreshAccessToken();
    }
  }
  
  handleRefreshFailure(error) {
    console.error('Token refresh failed after retries:', error);
    this.clearTokens();
    
    if (this.onRefreshFailure) {
      this.onRefreshFailure(error);
    }
  }
}

const robustManager = new RobustTokenManager(
  'https://auth.example.com/oauth/token',
  'client_123',
  (error) => {
    // Redirect to login or show session expired modal
    window.location.href = '/login?session_expired=true';
  }
);
```

### Multi-Tab Token Synchronization

Coordinating token refresh across multiple browser tabs prevents race conditions and ensures consistent authentication state.

```javascript
class MultiTabTokenManager extends RobustTokenManager {
  constructor(tokenEndpoint, clientId, onRefreshFailure) {
    super(tokenEndpoint, clientId, onRefreshFailure);
    this.broadcastChannel = new BroadcastChannel('token_sync');
    this.setupSyncListeners();
  }
  
  setupSyncListeners() {
    // Listen for storage changes from other tabs
    window.addEventListener('storage', (event) => {
      if (event.key === this.storageKey && event.newValue) {
        try {
          const tokenData = JSON.parse(event.newValue);
          this.accessToken = tokenData.accessToken;
          this.refreshToken = tokenData.refreshToken;
          this.expiresAt = tokenData.expiresAt;
        } catch (error) {
          console.error('Failed to sync tokens from storage:', error);
        }
      }
    });
    
    // Listen for broadcast messages from other tabs
    this.broadcastChannel.onmessage = (event) => {
      if (event.data.type === 'TOKEN_REFRESHED') {
        this.accessToken = event.data.accessToken;
        this.refreshToken = event.data.refreshToken;
        this.expiresAt = event.data.expiresAt;
      } else if (event.data.type === 'TOKENS_CLEARED') {
        this.clearTokens();
      }
    };
  }
  
  async refreshAccessToken() {
    // Acquire lock to prevent simultaneous refreshes across tabs
    if (navigator.locks) {
      return navigator.locks.request('token_refresh_lock', async () => {
        // Check if another tab already refreshed
        this.restoreTokens();
        if (!this.isTokenExpired()) {
          return this.accessToken;
        }
        
        const token = await super.refreshAccessToken();
        this.broadcastTokenRefresh();
        return token;
      });
    }
    
    // Fallback for browsers without Web Locks API
    const token = await super.refreshAccessToken();
    this.broadcastTokenRefresh();
    return token;
  }
  
  broadcastTokenRefresh() {
    this.broadcastChannel.postMessage({
      type: 'TOKEN_REFRESHED',
      accessToken: this.accessToken,
      refreshToken: this.refreshToken,
      expiresAt: this.expiresAt
    });
  }
  
  clearTokens() {
    super.clearTokens();
    this.broadcastChannel.postMessage({
      type: 'TOKENS_CLEARED'
    });
  }
}

const multiTabManager = new MultiTabTokenManager(
  'https://auth.example.com/oauth/token',
  'client_123',
  (error) => {
    window.location.href = '/login?session_expired=true';
  }
);
```

### Request Queue During Refresh

Queuing API requests during token refresh prevents request failures and maintains operation order.

```javascript
class QueuedAuthenticatedFetch extends AuthenticatedFetch {
  constructor(tokenManager) {
    super(tokenManager);
    this.requestQueue = [];
    this.isRefreshing = false;
  }
  
  async fetch(url, options = {}) {
    // Check if refresh is needed
    if (this.tokenManager.isTokenExpired() && !this.isRefreshing) {
      this.isRefreshing = true;
      
      try {
        await this.tokenManager.refreshAccessToken();
      } catch (error) {
        this.isRefreshing = false;
        this.requestQueue = [];
        throw error;
      }
      
      this.isRefreshing = false;
      this.processQueue();
    }
    
    // Queue request if refresh is in progress
    if (this.isRefreshing) {
      return new Promise((resolve, reject) => {
        this.requestQueue.push({ url, options, resolve, reject });
      });
    }
    
    // Execute request with current token
    const token = this.tokenManager.accessToken;
    const authOptions = {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    };
    
    const response = await fetch(url, authOptions);
    
    // Handle unexpected expiration
    if (response.status === 401 && !this.isRefreshing) {
      this.isRefreshing = true;
      
      try {
        await this.tokenManager.refreshAccessToken();
        this.isRefreshing = false;
        this.processQueue();
        
        // Retry current request
        authOptions.headers['Authorization'] = `Bearer ${this.tokenManager.accessToken}`;
        return fetch(url, authOptions);
      } catch (error) {
        this.isRefreshing = false;
        this.requestQueue = [];
        throw error;
      }
    }
    
    return response;
  }
  
  async processQueue() {
    const queue = [...this.requestQueue];
    this.requestQueue = [];
    
    for (const { url, options, resolve, reject } of queue) {
      try {
        const response = await this.fetch(url, options);
        resolve(response);
      } catch (error) {
        reject(error);
      }
    }
  }
}

const queuedFetch = new QueuedAuthenticatedFetch(multiTabManager);

// Multiple requests during refresh are queued
Promise.all([
  queuedFetch.fetch('https://api.example.com/endpoint1'),
  queuedFetch.fetch('https://api.example.com/endpoint2'),
  queuedFetch.fetch('https://api.example.com/endpoint3')
]);
```

### Refresh Token Expiration Handling

Managing refresh token expiration requires detecting terminal authentication failures and initiating re-authentication flows.

```javascript
class TokenManagerWithReauth extends MultiTabTokenManager {
  constructor(tokenEndpoint, clientId, loginUrl) {
    super(tokenEndpoint, clientId);
    this.loginUrl = loginUrl;
    this.reauthInProgress = false;
  }
  
  async refreshAccessToken() {
    try {
      return await super.refreshAccessToken();
    } catch (error) {
      // Check if refresh token is expired or invalid
      if (this.isRefreshTokenInvalid(error)) {
        this.initiateReauthentication();
        throw new Error('Refresh token expired, reauthentication required');
      }
      throw error;
    }
  }
  
  isRefreshTokenInvalid(error) {
    // [Inference] Error messages vary by authorization server implementation
    return error.message.includes('invalid') || 
           error.message.includes('expired') ||
           error.message.includes('401');
  }
  
  initiateReauthentication() {
    if (this.reauthInProgress) return;
    
    this.reauthInProgress = true;
    this.clearTokens();
    
    // Save current location for post-login redirect
    sessionStorage.setItem('post_login_redirect', window.location.href);
    
    // Redirect to login
    window.location.href = this.loginUrl;
  }
}

const reauthManager = new TokenManagerWithReauth(
  'https://auth.example.com/oauth/token',
  'client_123',
  '/login'
);
```

### Background Token Refresh with Service Workers

Service workers enable background token refresh even when application tabs are closed, maintaining active sessions.

```javascript
// service-worker.js
let tokenManager = null;

self.addEventListener('message', (event) => {
  if (event.data.type === 'INIT_TOKEN_MANAGER') {
    tokenManager = {
      tokenEndpoint: event.data.tokenEndpoint,
      clientId: event.data.clientId,
      refreshToken: event.data.refreshToken,
      expiresAt: event.data.expiresAt
    };
    
    scheduleBackgroundRefresh();
  }
});

async function refreshToken() {
  if (!tokenManager || !tokenManager.refreshToken) return;
  
  try {
    const response = await fetch(tokenManager.tokenEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        grant_type: 'refresh_token',
        refresh_token: tokenManager.refreshToken,
        client_id: tokenManager.clientId
      })
    });
    
    if (response.ok) {
      const data = await response.json();
      tokenManager.refreshToken = data.refresh_token;
      tokenManager.expiresAt = Date.now() + (data.expires_in * 1000);
      
      // Notify all clients
      const clients = await self.clients.matchAll();
      clients.forEach(client => {
        client.postMessage({
          type: 'TOKEN_REFRESHED',
          accessToken: data.access_token,
          refreshToken: data.refresh_token,
          expiresIn: data.expires_in
        });
      });
      
      scheduleBackgroundRefresh();
    }
  } catch (error) {
    console.error('Background token refresh failed:', error);
  }
}

function scheduleBackgroundRefresh() {
  if (!tokenManager) return;
  
  const timeUntilRefresh = Math.max(
    0,
    tokenManager.expiresAt - Date.now() - 300000 // 5 minutes before expiry
  );
  
  setTimeout(refreshToken, timeUntilRefresh);
}

// Client-side initialization
// main.js
if ('serviceWorker' in navigator) {
  navigator.serviceWorker.register('/service-worker.js').then(registration => {
    navigator.serviceWorker.controller?.postMessage({
      type: 'INIT_TOKEN_MANAGER',
      tokenEndpoint: 'https://auth.example.com/oauth/token',
      clientId: 'client_123',
      refreshToken: persistentManager.refreshToken,
      expiresAt: persistentManager.expiresAt
    });
  });
  
  navigator.serviceWorker.addEventListener('message', (event) => {
    if (event.data.type === 'TOKEN_REFRESHED') {
      persistentManager.setTokens(
        event.data.accessToken,
        event.data.refreshToken,
        event.data.expiresIn
      );
    }
  });
}
```

### Token Refresh with PKCE

Proof Key for Code Exchange adds security to token refresh flows by preventing authorization code interception attacks.

```javascript
class PKCETokenManager extends TokenManager {
  constructor(authEndpoint, tokenEndpoint, clientId) {
    super(tokenEndpoint, clientId);
    this.authEndpoint = authEndpoint;
    this.codeVerifier = null;
  }
  
  async generatePKCE() {
    // Generate code verifier
    const array = new Uint8Array(32);
    crypto.getRandomValues(array);
    this.codeVerifier = this.base64URLEncode(array);
    
    // Generate code challenge
    const encoder = new TextEncoder();
    const data = encoder.encode(this.codeVerifier);
    const hash = await crypto.subtle.digest('SHA-256', data);
    const codeChallenge = this.base64URLEncode(new Uint8Array(hash));
    
    return { codeVerifier: this.codeVerifier, codeChallenge };
  }
  
  base64URLEncode(buffer) {
    const base64 = btoa(String.fromCharCode(...buffer));
    return base64
      .replace(/\+/g, '-')
      .replace(/\//g, '_')
      .replace(/=/g, '');
  }
  
  async exchangeCodeForToken(authorizationCode) {
    if (!this.codeVerifier) {
      throw new Error('Code verifier not found');
    }
    
    const response = await fetch(this.tokenEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        grant_type: 'authorization_code',
        code: authorizationCode,
        client_id: this.clientId,
        code_verifier: this.codeVerifier
      })
    });
    
    if (!response.ok) {
      throw new Error(`Token exchange failed: ${response.status}`);
    }
    
    const data = await response.json();
    this.setTokens(data.access_token, data.refresh_token, data.expires_in);
    this.codeVerifier = null; // Clear after use
    
    return data;
  }
}

const pkceManager = new PKCETokenManager(
  'https://auth.example.com/authorize',
  'https://auth.example.com/oauth/token',
  'client_123'
);

// Generate PKCE parameters for authorization request
const { codeChallenge } = await pkceManager.generatePKCE();
```

### Device Flow Token Refresh

Device flow implementations for limited-input devices require specialized token refresh handling with device-specific grant types.

```javascript
class DeviceFlowTokenManager extends TokenManager {
  constructor(tokenEndpoint, clientId, deviceCode) {
    super(tokenEndpoint, clientId);
    this.deviceCode = deviceCode;
  }
  
  async pollForToken(interval = 5000) {
    const pollPromise = new Promise((resolve, reject) => {
      const poll = async () => {
        try {
          const response = await fetch(this.tokenEndpoint, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/x-www-form-urlencoded',
            },
            body: new URLSearchParams({
              grant_type: 'urn:ietf:params:oauth:grant-type:device_code',
              device_code: this.deviceCode,
              client_id: this.clientId
            })
          });
          
          const data = await response.json();
          
          if (response.ok) {
            this.setTokens(data.access_token, data.refresh_token, data.expires_in);
            resolve(data);
          } else if (data.error === 'authorization_pending') {
            setTimeout(poll, interval);
          } else if (data.error === 'slow_down') {
            setTimeout(poll, interval + 5000);
          } else {
            reject(new Error(data.error));
          }
        } catch (error) {
          reject(error);
        }
      };
      
      poll();
    });
    
    return pollPromise;
  }
}

const deviceManager = new DeviceFlowTokenManager(
  'https://auth.example.com/oauth/token',
  'device_client_123',
  'DEVICE_CODE_ABC123'
);

// Start polling for user authorization
await deviceManager.pollForToken();
```

---

## Secure Token Storage with Fetch API

### Storage Location Considerations

Tokens (authentication tokens, API keys, session identifiers) require careful storage to balance security and usability. Each storage mechanism presents distinct security trade-offs.

**localStorage/sessionStorage vulnerabilities:**

- Accessible to any JavaScript code including third-party scripts
- Vulnerable to XSS attacks
- Persist across page reloads (localStorage) or browser session (sessionStorage)
- Not sent automatically with requests
- Domain-scoped but accessible to all scripts on that domain

**Cookie-based storage:**

- Can be configured with HttpOnly flag (inaccessible to JavaScript)
- Automatically sent with requests to matching domains
- Vulnerable to CSRF if not properly protected
- Can use Secure flag for HTTPS-only transmission
- Supports SameSite attribute for CSRF protection

**In-memory storage:**

- Lost on page reload/navigation
- Not vulnerable to XSS persistence
- Requires re-authentication more frequently
- Best security profile for sensitive tokens

```javascript
class TokenStore {
  constructor() {
    // In-memory storage - most secure but not persistent
    this.memoryStore = new Map();
  }
  
  // Store in memory only
  setInMemory(key, token) {
    this.memoryStore.set(key, {
      token,
      timestamp: Date.now()
    });
  }
  
  getInMemory(key) {
    const stored = this.memoryStore.get(key);
    return stored ? stored.token : null;
  }
  
  // Clear all tokens
  clearAll() {
    this.memoryStore.clear();
  }
  
  // Check if token exists
  has(key) {
    return this.memoryStore.has(key);
  }
}

// Usage with fetch
const tokenStore = new TokenStore();

// Store token after authentication
async function login(credentials) {
  const response = await fetch('/auth/login', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(credentials)
  });
  
  const data = await response.json();
  tokenStore.setInMemory('accessToken', data.accessToken);
  tokenStore.setInMemory('refreshToken', data.refreshToken);
}

// Use token in requests
async function authenticatedFetch(url, options = {}) {
  const token = tokenStore.getInMemory('accessToken');
  
  if (!token) {
    throw new Error('No authentication token available');
  }
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`
    }
  });
}
```

### Token Encryption in Storage

When persistent storage is required, encrypting tokens adds a layer of defense. [Inference: This approach reduces but does not eliminate XSS risk, as the encryption key must also be stored]

```javascript
class EncryptedTokenStore {
  constructor(encryptionKey) {
    this.key = encryptionKey;
  }
  
  async deriveKey(password) {
    const encoder = new TextEncoder();
    const keyMaterial = await crypto.subtle.importKey(
      'raw',
      encoder.encode(password),
      { name: 'PBKDF2' },
      false,
      ['deriveKey']
    );
    
    return crypto.subtle.deriveKey(
      {
        name: 'PBKDF2',
        salt: encoder.encode('static-salt'), // [Unverified: Production should use dynamic salt]
        iterations: 100000,
        hash: 'SHA-256'
      },
      keyMaterial,
      { name: 'AES-GCM', length: 256 },
      false,
      ['encrypt', 'decrypt']
    );
  }
  
  async encrypt(text, key) {
    const encoder = new TextEncoder();
    const data = encoder.encode(text);
    const iv = crypto.getRandomValues(new Uint8Array(12));
    
    const encrypted = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv },
      key,
      data
    );
    
    // Combine IV and encrypted data
    const combined = new Uint8Array(iv.length + encrypted.byteLength);
    combined.set(iv, 0);
    combined.set(new Uint8Array(encrypted), iv.length);
    
    return btoa(String.fromCharCode(...combined));
  }
  
  async decrypt(encryptedText, key) {
    const combined = Uint8Array.from(atob(encryptedText), c => c.charCodeAt(0));
    const iv = combined.slice(0, 12);
    const data = combined.slice(12);
    
    const decrypted = await crypto.subtle.decrypt(
      { name: 'AES-GCM', iv },
      key,
      data
    );
    
    return new TextDecoder().decode(decrypted);
  }
  
  async setToken(tokenName, token, password) {
    const key = await this.deriveKey(password);
    const encrypted = await this.encrypt(token, key);
    sessionStorage.setItem(tokenName, encrypted);
  }
  
  async getToken(tokenName, password) {
    const encrypted = sessionStorage.getItem(tokenName);
    if (!encrypted) return null;
    
    try {
      const key = await this.deriveKey(password);
      return await this.decrypt(encrypted, key);
    } catch {
      return null;
    }
  }
}
```

### Token Expiration and Refresh Flow

Implementing token expiration checking and automatic refresh prevents using expired tokens and reduces exposure window.

```javascript
class TokenManager {
  constructor() {
    this.tokens = new Map();
    this.refreshPromise = null;
  }
  
  setTokens(accessToken, refreshToken, expiresIn) {
    const expiresAt = Date.now() + (expiresIn * 1000);
    
    this.tokens.set('access', {
      token: accessToken,
      expiresAt
    });
    
    if (refreshToken) {
      this.tokens.set('refresh', {
        token: refreshToken,
        expiresAt: null // Refresh tokens typically have longer/no expiration
      });
    }
  }
  
  getAccessToken() {
    const stored = this.tokens.get('access');
    if (!stored) return null;
    
    // Check if expired
    if (Date.now() >= stored.expiresAt) {
      return null;
    }
    
    return stored.token;
  }
  
  isAccessTokenExpired() {
    const stored = this.tokens.get('access');
    if (!stored) return true;
    
    return Date.now() >= stored.expiresAt;
  }
  
  shouldRefresh() {
    const stored = this.tokens.get('access');
    if (!stored) return false;
    
    // Refresh when 5 minutes remain
    const fiveMinutes = 5 * 60 * 1000;
    return Date.now() >= (stored.expiresAt - fiveMinutes);
  }
  
  async refreshAccessToken() {
    // Prevent multiple simultaneous refresh requests
    if (this.refreshPromise) {
      return this.refreshPromise;
    }
    
    const refreshToken = this.tokens.get('refresh')?.token;
    if (!refreshToken) {
      throw new Error('No refresh token available');
    }
    
    this.refreshPromise = (async () => {
      try {
        const response = await fetch('/auth/refresh', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${refreshToken}`
          }
        });
        
        if (!response.ok) {
          throw new Error('Token refresh failed');
        }
        
        const data = await response.json();
        this.setTokens(data.accessToken, data.refreshToken, data.expiresIn);
        
        return data.accessToken;
      } finally {
        this.refreshPromise = null;
      }
    })();
    
    return this.refreshPromise;
  }
  
  clearTokens() {
    this.tokens.clear();
  }
}

// Automatic refresh interceptor
async function fetchWithTokenRefresh(url, options = {}) {
  const tokenManager = window.tokenManager;
  
  // Check if token needs refresh
  if (tokenManager.shouldRefresh()) {
    try {
      await tokenManager.refreshAccessToken();
    } catch (error) {
      // Refresh failed, clear tokens and redirect to login
      tokenManager.clearTokens();
      window.location.href = '/login';
      throw error;
    }
  }
  
  const token = tokenManager.getAccessToken();
  if (!token) {
    throw new Error('No valid access token');
  }
  
  const response = await fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${token}`
    }
  });
  
  // Handle 401 by attempting refresh once
  if (response.status === 401) {
    try {
      await tokenManager.refreshAccessToken();
      const newToken = tokenManager.getAccessToken();
      
      // Retry original request with new token
      return fetch(url, {
        ...options,
        headers: {
          ...options.headers,
          'Authorization': `Bearer ${newToken}`
        }
      });
    } catch {
      tokenManager.clearTokens();
      window.location.href = '/login';
      throw new Error('Authentication failed');
    }
  }
  
  return response;
}
```

### Content Security Policy Integration

CSP headers restrict where scripts can be loaded from and what operations they can perform, reducing XSS risk.

```javascript
// Server sends CSP header:
// Content-Security-Policy: 
//   default-src 'self'; 
//   script-src 'self' 'nonce-{random}'; 
//   connect-src 'self' https://api.example.com;
//   style-src 'self' 'unsafe-inline'

// Client-side token handling remains the same
// but inline scripts and eval are blocked, reducing XSS vectors

// Check CSP support and configuration
function checkCSPSupport() {
  const meta = document.querySelector('meta[http-equiv="Content-Security-Policy"]');
  const hasCSP = meta || 
                 document.securityPolicy || 
                 !!window.SecurityPolicyViolationEvent;
  
  return hasCSP;
}

// Listen for CSP violations
document.addEventListener('securitypolicyviolation', (e) => {
  // Log violation for security monitoring
  fetch('/security/csp-violation', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      blockedURI: e.blockedURI,
      violatedDirective: e.violatedDirective,
      originalPolicy: e.originalPolicy,
      sourceFile: e.sourceFile,
      lineNumber: e.lineNumber
    }),
    keepalive: true
  });
});
```

### Subresource Integrity for Token Scripts

When loading token management libraries from CDNs, SRI prevents tampering.

```html
<script 
  src="https://cdn.example.com/auth-lib.js"
  integrity="sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxQ"
  crossorigin="anonymous">
</script>
```

```javascript
// Verify dynamically loaded scripts
async function loadSecureScript(url, expectedHash) {
  const response = await fetch(url);
  const content = await response.text();
  
  // Calculate hash
  const encoder = new TextEncoder();
  const data = encoder.encode(content);
  const hashBuffer = await crypto.subtle.digest('SHA-384', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashBase64 = btoa(String.fromCharCode(...hashArray));
  
  if (hashBase64 !== expectedHash) {
    throw new Error('Script integrity check failed');
  }
  
  // Execute script
  const script = document.createElement('script');
  script.textContent = content;
  document.head.appendChild(script);
}
```

### Token Scope Limitation

Limiting token permissions reduces impact if compromised.

```javascript
class ScopedTokenManager {
  constructor() {
    this.tokens = new Map();
  }
  
  // Store multiple tokens with different scopes
  setToken(scope, token, expiresIn) {
    this.tokens.set(scope, {
      token,
      expiresAt: Date.now() + (expiresIn * 1000),
      scope
    });
  }
  
  getToken(requiredScope) {
    const stored = this.tokens.get(requiredScope);
    
    if (!stored || Date.now() >= stored.expiresAt) {
      return null;
    }
    
    return stored.token;
  }
  
  // Request token with minimal required scope
  async requestScopedToken(scope) {
    const response = await fetch('/auth/token', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ scope })
    });
    
    const data = await response.json();
    this.setToken(scope, data.token, data.expiresIn);
    return data.token;
  }
}

// Usage
const scopedManager = new ScopedTokenManager();

// Get read-only token for fetching data
async function fetchUserData() {
  const token = scopedManager.getToken('read:user') || 
                await scopedManager.requestScopedToken('read:user');
  
  return fetch('/api/user', {
    headers: { 'Authorization': `Bearer ${token}` }
  });
}

// Get write token only when needed
async function updateUserData(updates) {
  const token = scopedManager.getToken('write:user') || 
                await scopedManager.requestScopedToken('write:user');
  
  return fetch('/api/user', {
    method: 'PATCH',
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(updates)
  });
}
```

### Fingerprinting and Device Binding

Binding tokens to device characteristics makes stolen tokens harder to use on different devices. [Inference: This adds friction and may not prevent sophisticated attacks]

```javascript
class DeviceBoundTokenManager {
  async generateDeviceFingerprint() {
    const components = [];
    
    // Screen properties
    components.push(`${screen.width}x${screen.height}x${screen.colorDepth}`);
    
    // Timezone
    components.push(Intl.DateTimeFormat().resolvedOptions().timeZone);
    
    // Language
    components.push(navigator.language);
    
    // Hardware concurrency
    components.push(navigator.hardwareConcurrency);
    
    // Canvas fingerprint
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    ctx.textBaseline = 'top';
    ctx.font = '14px Arial';
    ctx.fillText('fingerprint', 2, 2);
    components.push(canvas.toDataURL().slice(-50));
    
    // Hash all components
    const fingerprint = components.join('|');
    const encoder = new TextEncoder();
    const data = encoder.encode(fingerprint);
    const hashBuffer = await crypto.subtle.digest('SHA-256', data);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  }
  
  async storeTokenWithFingerprint(token, expiresIn) {
    const fingerprint = await this.generateDeviceFingerprint();
    
    sessionStorage.setItem('token', JSON.stringify({
      token,
      fingerprint,
      expiresAt: Date.now() + (expiresIn * 1000)
    }));
  }
  
  async getTokenIfValid() {
    const stored = sessionStorage.getItem('token');
    if (!stored) return null;
    
    try {
      const data = JSON.parse(stored);
      
      // Check expiration
      if (Date.now() >= data.expiresAt) {
        return null;
      }
      
      // Verify fingerprint matches
      const currentFingerprint = await this.generateDeviceFingerprint();
      if (currentFingerprint !== data.fingerprint) {
        // Fingerprint mismatch - possible token theft
        sessionStorage.removeItem('token');
        return null;
      }
      
      return data.token;
    } catch {
      return null;
    }
  }
}
```

### Rate Limiting Token Usage

Implementing client-side rate limiting reduces impact of compromised tokens.

```javascript
class RateLimitedTokenManager {
  constructor(maxRequestsPerMinute = 60) {
    this.maxRequests = maxRequestsPerMinute;
    this.requests = [];
    this.token = null;
  }
  
  setToken(token) {
    this.token = token;
  }
  
  canMakeRequest() {
    const now = Date.now();
    const oneMinuteAgo = now - 60000;
    
    // Remove requests older than 1 minute
    this.requests = this.requests.filter(time => time > oneMinuteAgo);
    
    return this.requests.length < this.maxRequests;
  }
  
  recordRequest() {
    this.requests.push(Date.now());
  }
  
  async fetchWithRateLimit(url, options = {}) {
    if (!this.canMakeRequest()) {
      throw new Error('Rate limit exceeded');
    }
    
    if (!this.token) {
      throw new Error('No token available');
    }
    
    this.recordRequest();
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${this.token}`
      }
    });
  }
  
  getRemainingRequests() {
    const now = Date.now();
    const oneMinuteAgo = now - 60000;
    const recentRequests = this.requests.filter(time => time > oneMinuteAgo);
    
    return this.maxRequests - recentRequests.length;
  }
  
  getResetTime() {
    if (this.requests.length === 0) return 0;
    
    const oldestRequest = Math.min(...this.requests);
    const resetTime = oldestRequest + 60000;
    
    return Math.max(0, resetTime - Date.now());
  }
}
```

### Secure Token Transmission

Ensuring tokens are only sent over secure channels and not logged or exposed.

```javascript
class SecureTokenFetcher {
  constructor(token) {
    this.token = token;
  }
  
  async secureFetch(url, options = {}) {
    // Verify HTTPS
    const urlObj = new URL(url, location.href);
    if (urlObj.protocol !== 'https:' && location.protocol === 'https:') {
      throw new Error('Cannot send token over insecure connection');
    }
    
    // Clone options to avoid mutating original
    const secureOptions = { ...options };
    
    // Ensure headers object exists
    secureOptions.headers = new Headers(secureOptions.headers || {});
    
    // Add authorization header
    secureOptions.headers.set('Authorization', `Bearer ${this.token}`);
    
    // Prevent credentials from being cached in browser history
    secureOptions.cache = 'no-store';
    
    try {
      const response = await fetch(url, secureOptions);
      return response;
    } catch (error) {
      // Don't expose token in error messages
      const sanitizedError = new Error(
        `Fetch failed: ${error.message.replace(this.token, '[REDACTED]')}`
      );
      throw sanitizedError;
    }
  }
  
  // Clear token from memory
  destroy() {
    this.token = null;
  }
}

// Prevent token exposure in browser dev tools
Object.defineProperty(window, 'sensitiveToken', {
  get() {
    console.warn('Access to token detected');
    return '[PROTECTED]';
  },
  set(value) {
    // Store in closure, not directly on window
    this._token = value;
  },
  configurable: false,
  enumerable: false
});
```

### Token Rotation Strategy

Regularly rotating tokens limits exposure window.

```javascript
class RotatingTokenManager {
  constructor(rotationInterval = 15 * 60 * 1000) { // 15 minutes
    this.rotationInterval = rotationInterval;
    this.currentToken = null;
    this.nextToken = null;
    this.rotationTimer = null;
    this.lastRotation = null;
  }
  
  async initialize(initialToken) {
    this.currentToken = initialToken;
    this.lastRotation = Date.now();
    this.scheduleRotation();
    
    // Pre-fetch next token
    await this.prefetchNextToken();
  }
  
  scheduleRotation() {
    if (this.rotationTimer) {
      clearTimeout(this.rotationTimer);
    }
    
    this.rotationTimer = setTimeout(
      () => this.rotateToken(),
      this.rotationInterval
    );
  }
  
  async prefetchNextToken() {
    try {
      const response = await fetch('/auth/rotate', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.currentToken}`,
          'Content-Type': 'application/json'
        }
      });
      
      const data = await response.json();
      this.nextToken = data.nextToken;
    } catch (error) {
      console.error('Failed to prefetch next token:', error);
    }
  }
  
  async rotateToken() {
    if (this.nextToken) {
      // Swap to pre-fetched token
      this.currentToken = this.nextToken;
      this.nextToken = null;
      this.lastRotation = Date.now();
    } else {
      // Fallback: fetch new token immediately
      try {
        const response = await fetch('/auth/rotate', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.currentToken}`,
            'Content-Type': 'application/json'
          }
        });
        
        const data = await response.json();
        this.currentToken = data.nextToken;
        this.lastRotation = Date.now();
      } catch (error) {
        console.error('Token rotation failed:', error);
        return;
      }
    }
    
    // Schedule next rotation and prefetch
    this.scheduleRotation();
    await this.prefetchNextToken();
  }
  
  getCurrentToken() {
    // Check if rotation is overdue
    if (Date.now() - this.lastRotation > this.rotationInterval * 1.5) {
      console.warn('Token rotation overdue');
    }
    
    return this.currentToken;
  }
  
  async fetchWithRotation(url, options = {}) {
    const token = this.getCurrentToken();
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      }
    });
  }
  
  destroy() {
    if (this.rotationTimer) {
      clearTimeout(this.rotationTimer);
    }
    this.currentToken = null;
    this.nextToken = null;
  }
}
```

### Secure Token Deletion

Properly clearing tokens from all storage locations when logging out.

```javascript
class SecureTokenCleanup {
  static clearAllTokenStorage() {
    // Clear localStorage
    const localStorageKeys = Object.keys(localStorage);
    localStorageKeys.forEach(key => {
      if (key.includes('token') || key.includes('auth') || key.includes('session')) {
        localStorage.removeItem(key);
      }
    });
    
    // Clear sessionStorage
    const sessionStorageKeys = Object.keys(sessionStorage);
    sessionStorageKeys.forEach(key => {
      if (key.includes('token') || key.includes('auth') || key.includes('session')) {
        sessionStorage.removeItem(key);
      }
    });
    
    // Clear cookies
    document.cookie.split(';').forEach(cookie => {
      const name = cookie.split('=')[0].trim();
      if (name.includes('token') || name.includes('auth') || name.includes('session')) {
        document.cookie = `${name}=; expires=Thu, 01 Jan 1970 00:00:00 UTC; path=/;`;
      }
    });
    
    // Clear any in-memory references
    if (window.tokenManager) {
      window.tokenManager.clearTokens();
      window.tokenManager = null;
    }
  }
  
  static async invalidateOnServer(token) {
    try {
      await fetch('/auth/logout', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/json'
        }
      });
    } catch (error) {
      console.error('Server-side logout failed:', error);
    }
  }
  
  static async secureLogout() {
    // Get current token before clearing
    const token = window.tokenManager?.getAccessToken();
    
    // Invalidate on server first
    if (token) {
      await this.invalidateOnServer(token);
    }
    
    // Clear all client-side storage
    this.clearAllTokenStorage();
    
    // Redirect to login
    window.location.href = '/login';
  }
}

// Usage
document.getElementById('logoutBtn')?.addEventListener('click', () => {
  SecureTokenCleanup.secureLogout();
});

// Also handle browser close/navigation
window.addEventListener('beforeunload', () => {
  const token = window.tokenManager?.getAccessToken();
  if (token) {
    // Use sendBeacon for reliable logout during navigation
    navigator.sendBeacon('/auth/logout', JSON.stringify({ token }));
  }
});
```

### Cross-Origin Token Handling

Managing tokens when making requests to different origins.

```javascript
class CrossOriginTokenManager {
  constructor() {
    this.tokens = new Map();
    this.allowedOrigins = new Set();
  }
  
  addAllowedOrigin(origin) {
    this.allowedOrigins.add(origin);
  }
  
  setTokenForOrigin(origin, token) {
    if (!this.allowedOrigins.has(origin)) {
      throw new Error(`Origin ${origin} not in allowlist`);
    }
    this.tokens.set(origin, token);
  }
  
  getTokenForOrigin(origin) {
    if (!this.allowedOrigins.has(origin)) {
      return null;
    }
    return this.tokens.get(origin);
  }
  
  async fetchCrossOrigin(url, options = {}) {
    const urlObj = new URL(url);
    const origin = urlObj.origin;
    
    // Check if origin is allowed
    if (!this.allowedOrigins.has(origin)) {
      throw new Error(`Requests to ${origin} are not permitted`);
    }
    
    const token = this.tokens.get(origin);
    if (!token) {
      throw new Error(`No token available for ${origin}`);
    }
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'Authorization': `Bearer ${token}`
      },
      // Explicitly set credentials mode
      credentials: 'omit' // Don't send cookies cross-origin
    });
  }
}

// Usage
const crossOriginManager = new CrossOriginTokenManager();
crossOriginManager.addAllowedOrigin('https://api.example.com');
crossOriginManager.addAllowedOrigin('https://cdn.example.com');

// Set different tokens for different services
crossOriginManager.setTokenForOrigin('https://api.example.com', apiToken);
crossOriginManager.setTokenForOrigin('https://cdn.example.com', cdnToken);

// Make cross-origin request
await crossOriginManager.fetchCrossOrigin('https://api.example.com/data');
```

---

## Fetch API Certificate Pinning

### Browser Limitations

Certificate pinning is **not directly supported** in the Fetch API or in web browsers for JavaScript applications. Browsers handle TLS/SSL certificate validation automatically at the network layer, and web applications cannot access or override this validation process.

The browser's built-in certificate validation:

- Checks certificate chain of trust
- Verifies certificate hasn't expired
- Validates certificate revocation status
- Ensures hostname matches certificate

Web applications cannot:

- Access raw certificate data during fetch requests
- Implement custom certificate validation logic
- Pin specific certificates or public keys
- Override browser certificate decisions

### Why Certificate Pinning is Unavailable

#### Security Architecture

Browsers intentionally prevent certificate pinning in web contexts to:

- Prevent malicious sites from bypassing security warnings
- Maintain user control over trusted certificate authorities
- Avoid breaking legitimate traffic through corporate proxies
- Protect users from outdated or compromised pins

#### Network Layer Abstraction

The Fetch API operates at the application layer and has no access to:

- TLS handshake details
- Certificate chain information
- Raw certificate bytes
- Connection security parameters

### Alternative Security Measures

#### Subresource Integrity (SRI)

While not certificate pinning, SRI provides integrity verification for fetched resources:

```javascript
// For <script> and <link> tags (not fetch)
<script 
  src="https://cdn.example.com/library.js"
  integrity="sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/ux..."
  crossorigin="anonymous">
</script>
```

**Important**: SRI only works with `<script>`, `<link>`, and `<style>` tags, not with the Fetch API directly.

#### Content Security Policy (CSP)

Restrict which domains can be contacted:

```javascript
// Set via HTTP header (server-side)
Content-Security-Policy: connect-src 'self' https://api.example.com;

// Or via meta tag
<meta http-equiv="Content-Security-Policy" 
      content="connect-src 'self' https://api.example.com;">
```

This limits fetch requests to specific origins but doesn't validate certificates.

#### HTTPS Enforcement

Always use HTTPS and enable HSTS:

```javascript
// Server sends header
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
```

This ensures browsers always use HTTPS but doesn't pin certificates.

### Detecting Certificate Issues

While you cannot implement pinning, you can detect when certificate validation fails:

```javascript
async function fetchWithCertificateDetection(url) {
  try {
    const response = await fetch(url);
    return { success: true, response };
  } catch (error) {
    // [Unverified] Certificate errors may appear as network errors
    // Browsers don't expose specific certificate failure reasons
    
    if (error.name === 'TypeError' && error.message.includes('Failed to fetch')) {
      // Could be certificate error, network error, or CORS issue
      return {
        success: false,
        possibleCertificateIssue: true,
        error: error.message
      };
    }
    
    return { success: false, error: error.message };
  }
}
```

**Note**: Browsers do not expose specific certificate validation failure reasons to JavaScript for security reasons.

### Public Key Pinning (Deprecated)

HTTP Public Key Pinning (HPKP) was a mechanism for certificate pinning but has been **deprecated and removed** from browsers:

```javascript
// DEPRECATED - Do not use
Public-Key-Pins: pin-sha256="base64=="; max-age=expireTime
```

HPKP was removed due to:

- Risk of site lockout with misconfiguration
- Potential for ransom attacks
- Complexity in key rotation
- Better alternatives available

### Certificate Transparency

Modern browsers support Certificate Transparency (CT) automatically:

```javascript
// Browsers verify CT logs automatically
// No JavaScript API available to check CT status
```

Certificate Transparency helps detect:

- Mis-issued certificates
- Compromised certificate authorities
- Unauthorized certificate issuance

### Native Mobile App Pinning

Certificate pinning **is available** in native mobile applications but not in web browsers:

#### iOS Example (Swift)

```swift
// Native iOS - NOT available in web browsers
func urlSession(_ session: URLSession, 
                didReceive challenge: URLAuthenticationChallenge,
                completionHandler: @escaping (URLSession.AuthChallengeDisposition, URLCredential?) -> Void) {
    // Custom certificate validation
    let serverTrust = challenge.protectionSpace.serverTrust
    // Validate against pinned certificate
}
```

#### Android Example (Kotlin)

```kotlin
// Native Android - NOT available in web browsers
val certificatePinner = CertificatePinner.Builder()
    .add("example.com", "sha256/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=")
    .build()

val client = OkHttpClient.Builder()
    .certificatePinner(certificatePinner)
    .build()
```

### Service Worker Considerations

Service Workers can intercept fetch requests but still cannot validate certificates:

```javascript
// Service Worker - certificate validation NOT available
self.addEventListener('fetch', (event) => {
  event.respondWith(
    fetch(event.request)
      .then(response => {
        // Cannot access certificate information here
        // Cannot perform custom certificate validation
        return response;
      })
      .catch(error => {
        // Cannot determine if error was certificate-related
        console.log('Fetch failed:', error);
        throw error;
      })
  );
});
```

### Security Headers for Enhanced Protection

While not certificate pinning, these headers improve security:

#### Expect-CT Header (Deprecated)

```javascript
// Server sends (now deprecated)
Expect-CT: max-age=86400, enforce, report-uri="https://example.com/report"
```

Modern browsers enforce CT by default without this header.

#### Certificate Authority Authorization (CAA)

DNS-level control over certificate issuance (configured at DNS level, not in JavaScript):

```
example.com. CAA 0 issue "letsencrypt.org"
example.com. CAA 0 issuewild "letsencrypt.org"
```

### Verifying HTTPS Connection

You can verify a connection uses HTTPS but cannot inspect the certificate:

```javascript
function isSecureConnection(url) {
  const urlObj = new URL(url);
  return urlObj.protocol === 'https:';
}

async function fetchSecure(url) {
  if (!isSecureConnection(url)) {
    throw new Error('Insecure connection: HTTPS required');
  }
  
  return await fetch(url);
}
```

### Mixed Content Detection

Detect and prevent mixed content issues:

```javascript
function detectMixedContent(url) {
  const isPageSecure = window.location.protocol === 'https:';
  const isResourceSecure = new URL(url).protocol === 'https:';
  
  if (isPageSecure && !isResourceSecure) {
    console.warn('Mixed content detected:', url);
    return true;
  }
  
  return false;
}

async function fetchWithMixedContentCheck(url) {
  if (detectMixedContent(url)) {
    throw new Error('Mixed content: Cannot fetch HTTP resource from HTTPS page');
  }
  
  return await fetch(url);
}
```

### Monitoring Certificate Expiration

Certificate expiration monitoring must be done server-side or via external monitoring tools. JavaScript cannot access certificate expiration dates.

### Proxy and Corporate Certificate Issues

Users behind corporate proxies with custom certificates will experience different certificate chains:

```javascript
async function fetchWithProxyAwareness(url) {
  try {
    const response = await fetch(url);
    return response;
  } catch (error) {
    // [Unverified] Could be corporate proxy certificate
    console.log('Fetch failed - possible proxy certificate issue:', error);
    
    // Cannot distinguish between:
    // - Invalid certificate
    // - Corporate proxy certificate
    // - Self-signed certificate
    // - Network error
    
    throw error;
  }
}
```

### Best Practices Without Pinning

#### 1. Use HTTPS Exclusively

```javascript
const API_BASE = 'https://api.example.com'; // Always HTTPS

async function apiRequest(endpoint) {
  return await fetch(`${API_BASE}${endpoint}`);
}
```

#### 2. Validate Response Integrity

```javascript
async function fetchWithIntegrityCheck(url, expectedHash) {
  const response = await fetch(url);
  const data = await response.arrayBuffer();
  
  // Calculate hash
  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  
  if (hashHex !== expectedHash) {
    throw new Error('Integrity check failed');
  }
  
  return data;
}
```

#### 3. Monitor for Certificate Warnings

```javascript
// Log all fetch failures for analysis
async function fetchWithLogging(url) {
  try {
    return await fetch(url);
  } catch (error) {
    // Send to monitoring service
    sendToMonitoring({
      type: 'fetch_failure',
      url,
      error: error.message,
      timestamp: Date.now(),
      userAgent: navigator.userAgent
    });
    throw error;
  }
}
```

#### 4. Implement Content Security Policy

```javascript
// Server-side header configuration
const cspHeader = [
  "default-src 'self'",
  "connect-src 'self' https://api.example.com https://cdn.example.com",
  "script-src 'self' 'unsafe-inline'",
  "style-src 'self' 'unsafe-inline'",
  "img-src 'self' data: https:",
  "font-src 'self' data:",
  "upgrade-insecure-requests"
].join('; ');

// Set via server response headers
```

#### 5. Use Trusted CDNs

```javascript
// Use well-known CDNs with good security practices
const TRUSTED_SOURCES = [
  'https://cdn.jsdelivr.net',
  'https://cdnjs.cloudflare.com',
  'https://unpkg.com'
];

function isTrustedSource(url) {
  return TRUSTED_SOURCES.some(trusted => url.startsWith(trusted));
}
```

### Feature Detection

Check what security features are available:

```javascript
function detectSecurityFeatures() {
  return {
    https: window.location.protocol === 'https:',
    crypto: typeof crypto !== 'undefined' && typeof crypto.subtle !== 'undefined',
    csp: typeof SecurityPolicyViolationEvent !== 'undefined',
    hsts: document.location.protocol === 'https:', // [Inference] Likely has HSTS if on HTTPS
    sri: 'integrity' in document.createElement('script'),
    
    // Certificate pinning: NOT available in browsers
    certificatePinning: false,
    
    // Direct certificate access: NOT available
    certificateAccess: false
  };
}

console.log(detectSecurityFeatures());
```

### Server-Side Certificate Validation

For scenarios requiring certificate pinning, implement server-side proxy:

```javascript
// Client-side: fetch through your secure backend
async function fetchViaPinnedProxy(externalUrl, data) {
  // Your backend validates certificates and pins them
  const response = await fetch('https://your-backend.com/api/proxy', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      targetUrl: externalUrl,
      data: data
    })
  });
  
  return response;
}
```

Server-side (Node.js example):

```javascript
// Backend with certificate pinning (Node.js)
const https = require('https');
const crypto = require('crypto');

const PINNED_FINGERPRINT = 'AA:BB:CC:DD:EE:FF:...';

const agent = new https.Agent({
  checkServerIdentity: (host, cert) => {
    const fingerprint = crypto
      .createHash('sha256')
      .update(cert.raw)
      .digest('hex')
      .toUpperCase()
      .match(/.{2}/g)
      .join(':');
    
    if (fingerprint !== PINNED_FINGERPRINT) {
      throw new Error('Certificate pinning failed');
    }
  }
});
```

### Browser Extension Limitations

Even browser extensions cannot implement certificate pinning for web content due to security architecture restrictions.

### Summary

Certificate pinning in the Fetch API:

- ❌ Not available in web browsers
- ❌ No JavaScript API for certificate validation
- ❌ Cannot access certificate data
- ❌ Cannot override browser certificate decisions
- ✅ Available in native mobile apps
- ✅ Can be implemented server-side
- ✅ Alternative security measures available (HTTPS, CSP, SRI)

For applications requiring certificate pinning, implement the validation in:

1. Native mobile applications
2. Server-side proxy layer
3. Desktop applications with system-level access

Web browsers intentionally prevent certificate pinning to maintain security, user control, and compatibility with legitimate network configurations like corporate proxies.

---

## Request Signing

### HMAC-based Signing

Generate signatures using HMAC (Hash-based Message Authentication Code) to verify request authenticity:

```javascript
async function generateHMAC(message, secret) {
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secret);
  const messageData = encoder.encode(message);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  
  // Convert to hex string
  return Array.from(new Uint8Array(signature))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
}

async function signRequest(url, method, body, secret) {
  const timestamp = Date.now().toString();
  const message = `${method}:${url}:${body || ''}:${timestamp}`;
  const signature = await generateHMAC(message, secret);
  
  return {
    signature,
    timestamp
  };
}

// Usage
async function fetchWithHMAC(url, options = {}, secret) {
  const method = options.method || 'GET';
  const body = options.body || '';
  
  const { signature, timestamp } = await signRequest(url, method, body, secret);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Timestamp': timestamp
    }
  });
}
```

### AWS Signature V4

Implement AWS-style request signing for API authentication:

```javascript
class AWSSignatureV4 {
  constructor(accessKeyId, secretAccessKey, region, service) {
    this.accessKeyId = accessKeyId;
    this.secretAccessKey = secretAccessKey;
    this.region = region;
    this.service = service;
  }
  
  async sign(request) {
    const url = new URL(request.url);
    const method = request.method || 'GET';
    const timestamp = new Date().toISOString().replace(/[:\-]|\.\d{3}/g, '');
    const date = timestamp.slice(0, 8);
    
    // Canonical request
    const canonicalUri = url.pathname || '/';
    const canonicalQueryString = this.getCanonicalQueryString(url.searchParams);
    const canonicalHeaders = this.getCanonicalHeaders(request.headers, url.host);
    const signedHeaders = this.getSignedHeaders(request.headers);
    const payloadHash = await this.hashPayload(request.body);
    
    const canonicalRequest = [
      method,
      canonicalUri,
      canonicalQueryString,
      canonicalHeaders,
      signedHeaders,
      payloadHash
    ].join('\n');
    
    // String to sign
    const credentialScope = `${date}/${this.region}/${this.service}/aws4_request`;
    const canonicalRequestHash = await this.sha256(canonicalRequest);
    const stringToSign = [
      'AWS4-HMAC-SHA256',
      timestamp,
      credentialScope,
      canonicalRequestHash
    ].join('\n');
    
    // Calculate signature
    const signature = await this.calculateSignature(stringToSign, date);
    
    // Authorization header
    const authorization = [
      `AWS4-HMAC-SHA256 Credential=${this.accessKeyId}/${credentialScope}`,
      `SignedHeaders=${signedHeaders}`,
      `Signature=${signature}`
    ].join(', ');
    
    return {
      'Authorization': authorization,
      'X-Amz-Date': timestamp,
      'X-Amz-Content-Sha256': payloadHash
    };
  }
  
  getCanonicalQueryString(params) {
    const sorted = Array.from(params.entries())
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([key, value]) => `${encodeURIComponent(key)}=${encodeURIComponent(value)}`)
      .join('&');
    return sorted;
  }
  
  getCanonicalHeaders(headers, host) {
    const canonical = { host };
    
    if (headers) {
      for (const [key, value] of Object.entries(headers)) {
        const lowerKey = key.toLowerCase();
        if (lowerKey.startsWith('x-amz-') || lowerKey === 'content-type') {
          canonical[lowerKey] = value.trim();
        }
      }
    }
    
    return Object.entries(canonical)
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([key, value]) => `${key}:${value}`)
      .join('\n') + '\n';
  }
  
  getSignedHeaders(headers) {
    const headerNames = ['host'];
    
    if (headers) {
      for (const key of Object.keys(headers)) {
        const lowerKey = key.toLowerCase();
        if (lowerKey.startsWith('x-amz-') || lowerKey === 'content-type') {
          headerNames.push(lowerKey);
        }
      }
    }
    
    return headerNames.sort().join(';');
  }
  
  async hashPayload(body) {
    if (!body) return await this.sha256('');
    
    if (typeof body === 'string') {
      return await this.sha256(body);
    }
    
    // For other body types, convert to string
    return await this.sha256(JSON.stringify(body));
  }
  
  async sha256(message) {
    const encoder = new TextEncoder();
    const data = encoder.encode(message);
    const hash = await crypto.subtle.digest('SHA-256', data);
    return Array.from(new Uint8Array(hash))
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  async hmac(key, message) {
    const encoder = new TextEncoder();
    const keyData = typeof key === 'string' ? encoder.encode(key) : key;
    const messageData = encoder.encode(message);
    
    const cryptoKey = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['sign']
    );
    
    return await crypto.subtle.sign('HMAC', cryptoKey, messageData);
  }
  
  async calculateSignature(stringToSign, date) {
    const kDate = await this.hmac(`AWS4${this.secretAccessKey}`, date);
    const kRegion = await this.hmac(kDate, this.region);
    const kService = await this.hmac(kRegion, this.service);
    const kSigning = await this.hmac(kService, 'aws4_request');
    const signature = await this.hmac(kSigning, stringToSign);
    
    return Array.from(new Uint8Array(signature))
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
}

// Usage
const signer = new AWSSignatureV4(
  'AKIAIOSFODNN7EXAMPLE',
  'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY',
  'us-east-1',
  's3'
);

async function fetchWithAWSSignature(url, options = {}) {
  const signatureHeaders = await signer.sign({
    url,
    method: options.method || 'GET',
    headers: options.headers || {},
    body: options.body
  });
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      ...signatureHeaders
    }
  });
}
```

### JWT-based Request Signing

Sign requests using JSON Web Tokens:

```javascript
async function createJWT(payload, secret, expiresIn = 3600) {
  const header = {
    alg: 'HS256',
    typ: 'JWT'
  };
  
  const now = Math.floor(Date.now() / 1000);
  const claims = {
    ...payload,
    iat: now,
    exp: now + expiresIn
  };
  
  // Base64URL encode
  const base64UrlEncode = (obj) => {
    const json = JSON.stringify(obj);
    const base64 = btoa(json);
    return base64.replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');
  };
  
  const encodedHeader = base64UrlEncode(header);
  const encodedPayload = base64UrlEncode(claims);
  const message = `${encodedHeader}.${encodedPayload}`;
  
  // Sign
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secret);
  const messageData = encoder.encode(message);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  const encodedSignature = btoa(String.fromCharCode(...new Uint8Array(signature)))
    .replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=+$/, '');
  
  return `${message}.${encodedSignature}`;
}

async function fetchWithJWT(url, options = {}, secret, payload = {}) {
  const jwt = await createJWT(payload, secret);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': `Bearer ${jwt}`
    }
  });
}
```

### OAuth 1.0a Signature

Implement OAuth 1.0a request signing:

```javascript
class OAuth1Signer {
  constructor(consumerKey, consumerSecret, tokenKey = null, tokenSecret = null) {
    this.consumerKey = consumerKey;
    this.consumerSecret = consumerSecret;
    this.tokenKey = tokenKey;
    this.tokenSecret = tokenSecret;
  }
  
  generateNonce() {
    return Math.random().toString(36).substring(2, 15) +
           Math.random().toString(36).substring(2, 15);
  }
  
  async sign(method, url, params = {}) {
    const oauthParams = {
      oauth_consumer_key: this.consumerKey,
      oauth_nonce: this.generateNonce(),
      oauth_signature_method: 'HMAC-SHA1',
      oauth_timestamp: Math.floor(Date.now() / 1000).toString(),
      oauth_version: '1.0'
    };
    
    if (this.tokenKey) {
      oauthParams.oauth_token = this.tokenKey;
    }
    
    // Combine all parameters
    const allParams = { ...params, ...oauthParams };
    
    // Create parameter string
    const sortedParams = Object.keys(allParams)
      .sort()
      .map(key => `${this.percentEncode(key)}=${this.percentEncode(allParams[key])}`)
      .join('&');
    
    // Create signature base string
    const baseUrl = url.split('?')[0];
    const signatureBase = [
      method.toUpperCase(),
      this.percentEncode(baseUrl),
      this.percentEncode(sortedParams)
    ].join('&');
    
    // Create signing key
    const signingKey = `${this.percentEncode(this.consumerSecret)}&${
      this.tokenSecret ? this.percentEncode(this.tokenSecret) : ''
    }`;
    
    // Generate signature
    const signature = await this.hmacSha1(signatureBase, signingKey);
    oauthParams.oauth_signature = signature;
    
    return oauthParams;
  }
  
  percentEncode(str) {
    return encodeURIComponent(str)
      .replace(/!/g, '%21')
      .replace(/'/g, '%27')
      .replace(/\(/g, '%28')
      .replace(/\)/g, '%29')
      .replace(/\*/g, '%2A');
  }
  
  async hmacSha1(message, key) {
    const encoder = new TextEncoder();
    const keyData = encoder.encode(key);
    const messageData = encoder.encode(message);
    
    const cryptoKey = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-1' },
      false,
      ['sign']
    );
    
    const signature = await crypto.subtle.sign('HMAC', cryptoKey, messageData);
    return btoa(String.fromCharCode(...new Uint8Array(signature)));
  }
  
  buildAuthorizationHeader(oauthParams) {
    const parts = Object.keys(oauthParams)
      .sort()
      .map(key => `${this.percentEncode(key)}="${this.percentEncode(oauthParams[key])}"`)
      .join(', ');
    
    return `OAuth ${parts}`;
  }
}

// Usage
const oauth = new OAuth1Signer(
  'consumer-key',
  'consumer-secret',
  'token-key',
  'token-secret'
);

async function fetchWithOAuth1(url, options = {}, queryParams = {}) {
  const method = options.method || 'GET';
  const oauthParams = await oauth.sign(method, url, queryParams);
  const authHeader = oauth.buildAuthorizationHeader(oauthParams);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'Authorization': authHeader
    }
  });
}
```

### Request Body Hash Verification

Include body hash in signature to prevent tampering:

```javascript
async function signRequestWithBodyHash(url, method, body, secret) {
  const encoder = new TextEncoder();
  
  // Hash the body
  const bodyData = encoder.encode(body || '');
  const bodyHashBuffer = await crypto.subtle.digest('SHA-256', bodyData);
  const bodyHash = Array.from(new Uint8Array(bodyHashBuffer))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  // Create signature with body hash
  const timestamp = Date.now().toString();
  const message = `${method}:${url}:${bodyHash}:${timestamp}`;
  
  const keyData = encoder.encode(secret);
  const messageData = encoder.encode(message);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signatureBuffer = await crypto.subtle.sign('HMAC', key, messageData);
  const signature = Array.from(new Uint8Array(signatureBuffer))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
  
  return {
    signature,
    bodyHash,
    timestamp
  };
}

async function fetchWithBodyHashSignature(url, options = {}, secret) {
  const method = options.method || 'GET';
  const body = options.body || '';
  
  const { signature, bodyHash, timestamp } = await signRequestWithBodyHash(
    url,
    method,
    body,
    secret
  );
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Body-Hash': bodyHash,
      'X-Timestamp': timestamp
    }
  });
}
```

### Timestamp-based Replay Protection

Prevent replay attacks using timestamp validation:

```javascript
class ReplayProtectedSigner {
  constructor(secret, maxAge = 300000) { // 5 minutes default
    this.secret = secret;
    this.maxAge = maxAge;
  }
  
  async sign(url, method, body) {
    const timestamp = Date.now();
    const nonce = this.generateNonce();
    const message = `${method}:${url}:${body || ''}:${timestamp}:${nonce}`;
    
    const signature = await this.generateHMAC(message);
    
    return {
      signature,
      timestamp: timestamp.toString(),
      nonce
    };
  }
  
  generateNonce() {
    const array = new Uint8Array(16);
    crypto.getRandomValues(array);
    return Array.from(array)
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  async generateHMAC(message) {
    const encoder = new TextEncoder();
    const keyData = encoder.encode(this.secret);
    const messageData = encoder.encode(message);
    
    const key = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['sign']
    );
    
    const signature = await crypto.subtle.sign('HMAC', key, messageData);
    return Array.from(new Uint8Array(signature))
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  async verify(signature, timestamp, nonce, url, method, body) {
    const now = Date.now();
    const requestTime = parseInt(timestamp);
    
    // Check timestamp is within acceptable range
    if (now - requestTime > this.maxAge) {
      throw new Error('Request timestamp expired');
    }
    
    if (requestTime > now + 60000) { // Allow 1 minute clock skew
      throw new Error('Request timestamp is in the future');
    }
    
    // Recalculate signature
    const message = `${method}:${url}:${body || ''}:${timestamp}:${nonce}`;
    const expectedSignature = await this.generateHMAC(message);
    
    // Constant-time comparison
    if (signature !== expectedSignature) {
      throw new Error('Invalid signature');
    }
    
    return true;
  }
}

// Usage
const signer = new ReplayProtectedSigner('secret-key', 300000);

async function fetchWithReplayProtection(url, options = {}) {
  const method = options.method || 'GET';
  const body = options.body || '';
  
  const { signature, timestamp, nonce } = await signer.sign(url, method, body);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Timestamp': timestamp,
      'X-Nonce': nonce
    }
  });
}
```

### Public Key Signature (RSA)

Sign requests using RSA public/private key pairs:

```javascript
class RSASigner {
  constructor() {
    this.privateKey = null;
    this.publicKey = null;
  }
  
  async generateKeyPair() {
    const keyPair = await crypto.subtle.generateKey(
      {
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: 2048,
        publicExponent: new Uint8Array([1, 0, 1]),
        hash: 'SHA-256'
      },
      true,
      ['sign', 'verify']
    );
    
    this.privateKey = keyPair.privateKey;
    this.publicKey = keyPair.publicKey;
    
    return keyPair;
  }
  
  async importPrivateKey(pemKey) {
    const pemContents = pemKey
      .replace('-----BEGIN PRIVATE KEY-----', '')
      .replace('-----END PRIVATE KEY-----', '')
      .replace(/\s/g, '');
    
    const binaryDer = Uint8Array.from(atob(pemContents), c => c.charCodeAt(0));
    
    this.privateKey = await crypto.subtle.importKey(
      'pkcs8',
      binaryDer,
      {
        name: 'RSASSA-PKCS1-v1_5',
        hash: 'SHA-256'
      },
      true,
      ['sign']
    );
  }
  
  async sign(message) {
    if (!this.privateKey) {
      throw new Error('Private key not loaded');
    }
    
    const encoder = new TextEncoder();
    const data = encoder.encode(message);
    
    const signature = await crypto.subtle.sign(
      'RSASSA-PKCS1-v1_5',
      this.privateKey,
      data
    );
    
    return btoa(String.fromCharCode(...new Uint8Array(signature)));
  }
  
  async signRequest(url, method, body) {
    const timestamp = Date.now().toString();
    const message = `${method}:${url}:${body || ''}:${timestamp}`;
    const signature = await this.sign(message);
    
    return {
      signature,
      timestamp
    };
  }
}

// Usage
const rsaSigner = new RSASigner();
await rsaSigner.generateKeyPair();

async function fetchWithRSASignature(url, options = {}) {
  const method = options.method || 'GET';
  const body = options.body || '';
  
  const { signature, timestamp } = await rsaSigner.signRequest(url, method, body);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      'X-Signature': signature,
      'X-Timestamp': timestamp,
      'X-Signature-Algorithm': 'RSA-SHA256'
    }
  });
}
```

### Custom Header Signature

Sign specific headers to verify their integrity:

```javascript
async function signHeaders(headers, secret) {
  const headerString = Object.entries(headers)
    .sort(([a], [b]) => a.localeCompare(b))
    .map(([key, value]) => `${key.toLowerCase()}:${value}`)
    .join('\n');
  
  const encoder = new TextEncoder();
  const keyData = encoder.encode(secret);
  const messageData = encoder.encode(headerString);
  
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );
  
  const signature = await crypto.subtle.sign('HMAC', key, messageData);
  
  return Array.from(new Uint8Array(signature))
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');
}

async function fetchWithHeaderSignature(url, options = {}, secret) {
  const headersToSign = {
    'Content-Type': options.headers?.['Content-Type'] || 'application/json',
    'X-Request-ID': crypto.randomUUID(),
    'X-Timestamp': new Date().toISOString()
  };
  
  const signature = await signHeaders(headersToSign, secret);
  
  return fetch(url, {
    ...options,
    headers: {
      ...options.headers,
      ...headersToSign,
      'X-Signature': signature,
      'X-Signed-Headers': Object.keys(headersToSign).sort().join(',')
    }
  });
}
```

### Signature Verification Middleware

Create reusable signing wrapper:

```javascript
class RequestSigner {
  constructor(config) {
    this.secret = config.secret;
    this.algorithm = config.algorithm || 'HMAC-SHA256';
    this.includeBody = config.includeBody !== false;
    this.includeTimestamp = config.includeTimestamp !== false;
    this.includeNonce = config.includeNonce !== false;
  }
  
  async signRequest(url, options = {}) {
    const method = options.method || 'GET';
    const components = [method, url];
    
    const headers = { ...options.headers };
    
    if (this.includeTimestamp) {
      headers['X-Timestamp'] = Date.now().toString();
      components.push(headers['X-Timestamp']);
    }
    
    if (this.includeNonce) {
      headers['X-Nonce'] = this.generateNonce();
      components.push(headers['X-Nonce']);
    }
    
    if (this.includeBody && options.body) {
      const bodyHash = await this.hashBody(options.body);
      headers['X-Body-Hash'] = bodyHash;
      components.push(bodyHash);
    }
    
    const message = components.join(':');
    const signature = await this.sign(message);
    
    headers['X-Signature'] = signature;
    headers['X-Signature-Algorithm'] = this.algorithm;
    
    return {
      ...options,
      headers
    };
  }
  
  async sign(message) {
    const encoder = new TextEncoder();
    const keyData = encoder.encode(this.secret);
    const messageData = encoder.encode(message);
    
    const key = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['sign']
    );
    
    const signature = await crypto.subtle.sign('HMAC', key, messageData);
    return Array.from(new Uint8Array(signature))
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  async hashBody(body) {
    const encoder = new TextEncoder();
    const data = encoder.encode(typeof body === 'string' ? body : JSON.stringify(body));
    const hash = await crypto.subtle.digest('SHA-256', data);
    return Array.from(new Uint8Array(hash))
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  generateNonce() {
    const array = new Uint8Array(16);
    crypto.getRandomValues(array);
    return Array.from(array)
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
}

// Usage
const signer = new RequestSigner({
  secret: 'your-secret-key',
  algorithm: 'HMAC-SHA256',
  includeBody: true,
  includeTimestamp: true,
  includeNonce: true
});

async function signedFetch(url, options = {}) {
  const signedOptions = await signer.signRequest(url, options);
  return fetch(url, signedOptions);
}

// Example request
const response = await signedFetch('https://api.example.com/data', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({ key: 'value' })
});
```

---

## Encryption in Transit

### TLS/HTTPS Enforcement

The fetch API automatically uses the HTTPS protocol when specified in URLs, establishing encrypted connections through TLS handshakes. All modern browsers enforce strict transport security for sensitive operations.

```javascript
// Fetch automatically uses HTTPS encryption
async function secureRequest(endpoint, data) {
  const response = await fetch(`https://api.example.com/${endpoint}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(data)
  });
  
  return response.json();
}

// Protocol validation
function ensureHttps(url) {
  const parsedUrl = new URL(url);
  
  if (parsedUrl.protocol !== 'https:') {
    throw new Error('Insecure protocol detected. HTTPS required.');
  }
  
  return url;
}

async function secureOnlyFetch(url, options) {
  const validatedUrl = ensureHttps(url);
  return fetch(validatedUrl, options);
}
```

### Strict Transport Security (HSTS)

HSTS headers force browsers to use HTTPS for all subsequent connections, preventing protocol downgrade attacks.

```javascript
// Server response includes HSTS header:
// Strict-Transport-Security: max-age=31536000; includeSubDomains; preload

class HSTSAwareFetch {
  constructor() {
    this.hstsCache = new Map();
  }
  
  recordHSTS(hostname, maxAge) {
    this.hstsCache.set(hostname, {
      enforceUntil: Date.now() + (maxAge * 1000)
    });
  }
  
  isHSTSEnforced(hostname) {
    const entry = this.hstsCache.get(hostname);
    
    if (!entry) return false;
    
    if (Date.now() > entry.enforceUntil) {
      this.hstsCache.delete(hostname);
      return false;
    }
    
    return true;
  }
  
  async fetch(url, options = {}) {
    const parsedUrl = new URL(url);
    
    // Upgrade to HTTPS if HSTS is enforced
    if (this.isHSTSEnforced(parsedUrl.hostname) && parsedUrl.protocol === 'http:') {
      parsedUrl.protocol = 'https:';
      url = parsedUrl.toString();
    }
    
    const response = await fetch(url, options);
    
    // Parse HSTS header from response
    const hstsHeader = response.headers.get('strict-transport-security');
    if (hstsHeader) {
      const maxAgeMatch = hstsHeader.match(/max-age=(\d+)/);
      if (maxAgeMatch) {
        this.recordHSTS(parsedUrl.hostname, parseInt(maxAgeMatch[1]));
      }
    }
    
    return response;
  }
}

const hstsFetch = new HSTSAwareFetch();
```

### Certificate Pinning Validation

Certificate pinning prevents man-in-the-middle attacks by validating server certificates against known good values. Browser fetch API does not expose certificate details directly, but pinning can be enforced through service workers and Content Security Policy.

```javascript
// Service Worker for certificate pinning
// service-worker.js
const EXPECTED_CERT_HASHES = [
  'sha256/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=',
  'sha256/BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB=' // Backup pin
];

self.addEventListener('fetch', (event) => {
  const url = new URL(event.request.url);
  
  if (url.hostname === 'api.example.com') {
    event.respondWith(
      fetch(event.request)
        .then(response => {
          // [Unverified] Browser fetch API does not expose certificate information
          // Certificate validation happens at browser TLS layer
          // Additional validation requires server-side verification
          return response;
        })
        .catch(error => {
          console.error('Certificate validation failed:', error);
          return new Response('Certificate validation failed', { status: 526 });
        })
    );
  }
});

// Client-side CSP header enforcement
// Content-Security-Policy: require-sri-for script style;
```

### Perfect Forward Secrecy

Perfect forward secrecy ensures past communications remain secure even if private keys are compromised. Modern TLS cipher suites automatically provide this protection.

```javascript
// Browser automatically negotiates PFS-enabled cipher suites
// Verification through SecurityInfo (not directly accessible in fetch)

class SecureConnectionValidator {
  async validateConnection(url) {
    try {
      const response = await fetch(url, {
        method: 'HEAD'
      });
      
      // [Unverified] Fetch API does not expose TLS negotiation details
      // Browsers automatically prefer strong cipher suites with PFS
      // Server must support modern TLS 1.2+ with ECDHE/DHE key exchange
      
      return {
        secure: response.url.startsWith('https://'),
        // [Inference] Modern browsers enforce minimum TLS versions
        tlsVersion: 'TLS 1.2+',
        // [Inference] Cipher suite selection happens transparently
        forwardSecrecy: true
      };
    } catch (error) {
      throw new Error(`Connection validation failed: ${error.message}`);
    }
  }
}

const validator = new SecureConnectionValidator();
```

### End-to-End Payload Encryption

Application-layer encryption provides defense-in-depth by encrypting sensitive data before transmission, independent of transport security.

```javascript
class E2EEncryptedFetch {
  constructor(publicKey) {
    this.publicKey = publicKey;
  }
  
  async encryptPayload(data) {
    const jsonData = JSON.stringify(data);
    const encodedData = new TextEncoder().encode(jsonData);
    
    // Import public key for encryption
    const cryptoKey = await crypto.subtle.importKey(
      'spki',
      this.base64ToArrayBuffer(this.publicKey),
      {
        name: 'RSA-OAEP',
        hash: 'SHA-256'
      },
      false,
      ['encrypt']
    );
    
    // Encrypt data
    const encryptedData = await crypto.subtle.encrypt(
      { name: 'RSA-OAEP' },
      cryptoKey,
      encodedData
    );
    
    return this.arrayBufferToBase64(encryptedData);
  }
  
  async decryptPayload(encryptedData, privateKey) {
    const cryptoKey = await crypto.subtle.importKey(
      'pkcs8',
      this.base64ToArrayBuffer(privateKey),
      {
        name: 'RSA-OAEP',
        hash: 'SHA-256'
      },
      false,
      ['decrypt']
    );
    
    const decryptedData = await crypto.subtle.decrypt(
      { name: 'RSA-OAEP' },
      cryptoKey,
      this.base64ToArrayBuffer(encryptedData)
    );
    
    const decodedData = new TextDecoder().decode(decryptedData);
    return JSON.parse(decodedData);
  }
  
  base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
  
  async fetch(url, data, options = {}) {
    const encryptedPayload = await this.encryptPayload(data);
    
    return fetch(url, {
      ...options,
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      },
      body: JSON.stringify({
        encrypted: encryptedPayload
      })
    });
  }
}

const e2eFetch = new E2EEncryptedFetch('PUBLIC_KEY_BASE64');

await e2eFetch.fetch('https://api.example.com/sensitive', {
  ssn: '123-45-6789',
  creditCard: '4111111111111111'
});
```

### Symmetric Encryption for Large Payloads

Hybrid encryption combines symmetric and asymmetric algorithms for efficient encryption of large data transfers.

```javascript
class HybridEncryptionFetch {
  async generateSessionKey() {
    return crypto.subtle.generateKey(
      {
        name: 'AES-GCM',
        length: 256
      },
      true,
      ['encrypt', 'decrypt']
    );
  }
  
  async encryptWithSessionKey(data, sessionKey) {
    const encodedData = new TextEncoder().encode(JSON.stringify(data));
    const iv = crypto.getRandomValues(new Uint8Array(12));
    
    const encryptedData = await crypto.subtle.encrypt(
      {
        name: 'AES-GCM',
        iv: iv
      },
      sessionKey,
      encodedData
    );
    
    return {
      encryptedData: this.arrayBufferToBase64(encryptedData),
      iv: this.arrayBufferToBase64(iv)
    };
  }
  
  async encryptSessionKey(sessionKey, recipientPublicKey) {
    const exportedKey = await crypto.subtle.exportKey('raw', sessionKey);
    
    const cryptoKey = await crypto.subtle.importKey(
      'spki',
      this.base64ToArrayBuffer(recipientPublicKey),
      {
        name: 'RSA-OAEP',
        hash: 'SHA-256'
      },
      false,
      ['encrypt']
    );
    
    const encryptedKey = await crypto.subtle.encrypt(
      { name: 'RSA-OAEP' },
      cryptoKey,
      exportedKey
    );
    
    return this.arrayBufferToBase64(encryptedKey);
  }
  
  async fetch(url, data, recipientPublicKey, options = {}) {
    // Generate ephemeral session key
    const sessionKey = await this.generateSessionKey();
    
    // Encrypt payload with session key (fast symmetric encryption)
    const { encryptedData, iv } = await this.encryptWithSessionKey(data, sessionKey);
    
    // Encrypt session key with recipient's public key
    const encryptedSessionKey = await this.encryptSessionKey(sessionKey, recipientPublicKey);
    
    return fetch(url, {
      ...options,
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...options.headers
      },
      body: JSON.stringify({
        encryptedData,
        encryptedKey: encryptedSessionKey,
        iv
      })
    });
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
  
  base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }
}

const hybridFetch = new HybridEncryptionFetch();

await hybridFetch.fetch(
  'https://api.example.com/upload',
  { largeDocument: '...' },
  'RECIPIENT_PUBLIC_KEY_BASE64'
);
```

### Encrypted Headers and Metadata

Protecting request metadata prevents information leakage through HTTP headers and query parameters.

```javascript
class EncryptedHeaderFetch {
  constructor(sharedSecret) {
    this.sharedSecret = sharedSecret;
  }
  
  async deriveKey(salt) {
    const encoder = new TextEncoder();
    const keyMaterial = await crypto.subtle.importKey(
      'raw',
      encoder.encode(this.sharedSecret),
      { name: 'PBKDF2' },
      false,
      ['deriveBits', 'deriveKey']
    );
    
    return crypto.subtle.deriveKey(
      {
        name: 'PBKDF2',
        salt: encoder.encode(salt),
        iterations: 100000,
        hash: 'SHA-256'
      },
      keyMaterial,
      { name: 'AES-GCM', length: 256 },
      false,
      ['encrypt', 'decrypt']
    );
  }
  
  async encryptHeader(value, salt) {
    const key = await this.deriveKey(salt);
    const iv = crypto.getRandomValues(new Uint8Array(12));
    const encodedValue = new TextEncoder().encode(value);
    
    const encrypted = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv },
      key,
      encodedValue
    );
    
    return {
      encrypted: this.arrayBufferToBase64(encrypted),
      iv: this.arrayBufferToBase64(iv)
    };
  }
  
  async fetch(url, options = {}) {
    const salt = crypto.getRandomValues(new Uint8Array(16));
    const saltBase64 = this.arrayBufferToBase64(salt);
    
    // Encrypt sensitive headers
    const encryptedHeaders = {};
    const sensitiveHeaders = ['X-User-ID', 'X-Session-Token', 'X-API-Key'];
    
    for (const [key, value] of Object.entries(options.headers || {})) {
      if (sensitiveHeaders.includes(key)) {
        const { encrypted, iv } = await this.encryptHeader(value, salt);
        encryptedHeaders[`X-Encrypted-${key}`] = `${encrypted}:${iv}`;
      } else {
        encryptedHeaders[key] = value;
      }
    }
    
    encryptedHeaders['X-Encryption-Salt'] = saltBase64;
    
    return fetch(url, {
      ...options,
      headers: encryptedHeaders
    });
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

const encryptedHeaderFetch = new EncryptedHeaderFetch('SHARED_SECRET_KEY');

await encryptedHeaderFetch.fetch('https://api.example.com/data', {
  headers: {
    'X-User-ID': 'user_123456',
    'X-Session-Token': 'session_abc789',
    'Content-Type': 'application/json'
  }
});
```

### Request Signing and Integrity Verification

HMAC signatures ensure request integrity and authenticity, preventing tampering during transit.

```javascript
class SignedRequestFetch {
  constructor(secretKey) {
    this.secretKey = secretKey;
  }
  
  async importKey() {
    const encoder = new TextEncoder();
    return crypto.subtle.importKey(
      'raw',
      encoder.encode(this.secretKey),
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['sign', 'verify']
    );
  }
  
  async signRequest(method, url, body, timestamp) {
    const key = await this.importKey();
    
    // Create canonical string
    const canonicalString = `${method}\n${url}\n${timestamp}\n${body || ''}`;
    const encoder = new TextEncoder();
    const data = encoder.encode(canonicalString);
    
    const signature = await crypto.subtle.sign('HMAC', key, data);
    
    return this.arrayBufferToHex(signature);
  }
  
  async verifySignature(signature, method, url, body, timestamp) {
    const key = await this.importKey();
    
    const canonicalString = `${method}\n${url}\n${timestamp}\n${body || ''}`;
    const encoder = new TextEncoder();
    const data = encoder.encode(canonicalString);
    
    const signatureBuffer = this.hexToArrayBuffer(signature);
    
    return crypto.subtle.verify('HMAC', key, signatureBuffer, data);
  }
  
  async fetch(url, options = {}) {
    const method = options.method || 'GET';
    const body = options.body || '';
    const timestamp = Date.now().toString();
    
    const signature = await this.signRequest(method, url, body, timestamp);
    
    return fetch(url, {
      ...options,
      headers: {
        ...options.headers,
        'X-Signature': signature,
        'X-Timestamp': timestamp,
        'X-Signature-Algorithm': 'HMAC-SHA256'
      }
    });
  }
  
  arrayBufferToHex(buffer) {
    const bytes = new Uint8Array(buffer);
    return Array.from(bytes)
      .map(b => b.toString(16).padStart(2, '0'))
      .join('');
  }
  
  hexToArrayBuffer(hex) {
    const bytes = new Uint8Array(hex.length / 2);
    for (let i = 0; i < hex.length; i += 2) {
      bytes[i / 2] = parseInt(hex.substr(i, 2), 16);
    }
    return bytes.buffer;
  }
}

const signedFetch = new SignedRequestFetch('SECRET_SIGNING_KEY');

await signedFetch.fetch('https://api.example.com/transaction', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    amount: 100.00,
    recipient: 'user_456'
  })
});
```

### Encrypted WebSocket Connections

WebSocket security requires WSS protocol (WebSockets over TLS) for encrypted bidirectional communication.

```javascript
class SecureWebSocketClient {
  constructor(url, protocols = []) {
    // Enforce WSS protocol
    if (!url.startsWith('wss://')) {
      throw new Error('WebSocket URL must use wss:// protocol');
    }
    
    this.url = url;
    this.protocols = protocols;
    this.ws = null;
    this.reconnectAttempts = 0;
    this.maxReconnectAttempts = 5;
  }
  
  connect() {
    return new Promise((resolve, reject) => {
      this.ws = new WebSocket(this.url, this.protocols);
      
      this.ws.onopen = () => {
        this.reconnectAttempts = 0;
        resolve();
      };
      
      this.ws.onerror = (error) => {
        reject(error);
      };
      
      this.ws.onclose = () => {
        this.handleReconnection();
      };
    });
  }
  
  async sendEncrypted(data, encryptionKey) {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      throw new Error('WebSocket not connected');
    }
    
    // Additional application-layer encryption
    const iv = crypto.getRandomValues(new Uint8Array(12));
    const encodedData = new TextEncoder().encode(JSON.stringify(data));
    
    const encrypted = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv },
      encryptionKey,
      encodedData
    );
    
    const payload = {
      encrypted: this.arrayBufferToBase64(encrypted),
      iv: this.arrayBufferToBase64(iv)
    };
    
    this.ws.send(JSON.stringify(payload));
  }
  
  async handleReconnection() {
    if (this.reconnectAttempts >= this.maxReconnectAttempts) {
      console.error('Max reconnection attempts reached');
      return;
    }
    
    this.reconnectAttempts++;
    const delay = Math.pow(2, this.reconnectAttempts) * 1000;
    
    setTimeout(() => {
      this.connect().catch(error => {
        console.error('Reconnection failed:', error);
      });
    }, delay);
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

const secureWs = new SecureWebSocketClient('wss://realtime.example.com/stream');
await secureWs.connect();
```

### Encrypted File Upload

Large file uploads require streaming encryption to manage memory efficiently while maintaining security.

```javascript
class EncryptedFileUpload {
  async encryptFile(file, password) {
    const salt = crypto.getRandomValues(new Uint8Array(16));
    const iv = crypto.getRandomValues(new Uint8Array(12));
    
    // Derive key from password
    const keyMaterial = await this.deriveKeyMaterial(password);
    const key = await this.deriveKey(keyMaterial, salt);
    
    // Read file as array buffer
    const fileBuffer = await file.arrayBuffer();
    
    // Encrypt file content
    const encryptedContent = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv },
      key,
      fileBuffer
    );
    
    // Create encrypted file with metadata
    const metadata = {
      originalName: file.name,
      originalSize: file.size,
      mimeType: file.type,
      salt: this.arrayBufferToBase64(salt),
      iv: this.arrayBufferToBase64(iv)
    };
    
    return {
      encryptedContent,
      metadata
    };
  }
  
  async deriveKeyMaterial(password) {
    const encoder = new TextEncoder();
    return crypto.subtle.importKey(
      'raw',
      encoder.encode(password),
      { name: 'PBKDF2' },
      false,
      ['deriveBits', 'deriveKey']
    );
  }
  
  async deriveKey(keyMaterial, salt) {
    return crypto.subtle.deriveKey(
      {
        name: 'PBKDF2',
        salt: salt,
        iterations: 100000,
        hash: 'SHA-256'
      },
      keyMaterial,
      { name: 'AES-GCM', length: 256 },
      false,
      ['encrypt', 'decrypt']
    );
  }
  
  async upload(file, password, uploadUrl) {
    const { encryptedContent, metadata } = await this.encryptFile(file, password);
    
    // Create form data
    const formData = new FormData();
    const encryptedBlob = new Blob([encryptedContent], { type: 'application/octet-stream' });
    formData.append('file', encryptedBlob, `${file.name}.encrypted`);
    formData.append('metadata', JSON.stringify(metadata));
    
    const response = await fetch(uploadUrl, {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Upload failed: ${response.status}`);
    }
    
    return response.json();
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

const encryptedUpload = new EncryptedFileUpload();

const fileInput = document.querySelector('input[type="file"]');
const file = fileInput.files[0];

await encryptedUpload.upload(
  file,
  'user_password_123',
  'https://api.example.com/upload'
);
```

### Chunked Encrypted Streaming

Streaming encryption for large files reduces memory consumption by processing data in chunks.

```javascript
class StreamingEncryptedUpload {
  constructor(chunkSize = 1024 * 1024) { // 1MB chunks
    this.chunkSize = chunkSize;
  }
  
  async uploadEncrypted(file, password, uploadUrl) {
    const salt = crypto.getRandomValues(new Uint8Array(16));
    const keyMaterial = await this.deriveKeyMaterial(password);
    const key = await this.deriveKey(keyMaterial, salt);
    
    // Initialize upload session
    const sessionResponse = await fetch(`${uploadUrl}/init`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        fileName: file.name,
        fileSize: file.size,
        salt: this.arrayBufferToBase64(salt)
      })
    });
    
    const { uploadId } = await sessionResponse.json();
    
    // Upload encrypted chunks
    const totalChunks = Math.ceil(file.size / this.chunkSize);
    
    for (let chunkIndex = 0; chunkIndex < totalChunks; chunkIndex++) {
      const start = chunkIndex * this.chunkSize;
      const end = Math.min(start + this.chunkSize, file.size);
      const chunk = file.slice(start, end);
      
      await this.uploadChunk(chunk, chunkIndex, uploadId, key, uploadUrl);
    }
    
    // Finalize upload
    const finalizeResponse = await fetch(`${uploadUrl}/finalize`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        uploadId,
        totalChunks
      })
    });
    
    return finalizeResponse.json();
  }
  
  async uploadChunk(chunk, chunkIndex, uploadId, key, uploadUrl) {
    const iv = crypto.getRandomValues(new Uint8Array(12));
    const chunkBuffer = await chunk.arrayBuffer();
    
    const encryptedChunk = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv },
      key,
      chunkBuffer
    );
    
    const formData = new FormData();
    formData.append('uploadId', uploadId);
    formData.append('chunkIndex', chunkIndex.toString());
    formData.append('iv', this.arrayBufferToBase64(iv));
    formData.append('chunk', new Blob([encryptedChunk]));
    
    const response = await fetch(`${uploadUrl}/chunk`, {
      method: 'POST',
      body: formData
    });
    
    if (!response.ok) {
      throw new Error(`Chunk upload failed: ${response.status}`);
    }
  }
  
  async deriveKeyMaterial(password) {
    const encoder = new TextEncoder();
    return crypto.subtle.importKey(
      'raw',
      encoder.encode(password),
      { name: 'PBKDF2' },
      false,
      ['deriveBits', 'deriveKey']
    );
  }
  
  async deriveKey(keyMaterial, salt) {
    return crypto.subtle.deriveKey(
      {
        name: 'PBKDF2',
        salt: salt,
        iterations: 100000,
        hash: 'SHA-256'
      },
      keyMaterial,
      { name: 'AES-GCM', length: 256 },
      false,
      ['encrypt', 'decrypt']
    );
  }
  
  arrayBufferToBase64(buffer) {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

const streamingUpload = new StreamingEncryptedUpload();

await streamingUpload.uploadEncrypted(
  largeFile,
  'encryption_password',
  'https://api.example.com/upload'
);
```

### Mutual TLS Authentication

Mutual TLS (mTLS) requires both client and server to present certificates, providing bidirectional authentication. The fetch API relies on browser certificate management for client certificates.

```javascript
// Browser prompts for client certificate when server requests it
// Certificates managed through browser settings or OS keychain

class MTLSFetch {
  async fetch(url, options = {}) {
    // [Unverified] Browser automatically presents client certificate if configured
    // Server must be configured to request and validate client certificates
    
    try {
      const response = await fetch(url, {
        ...options,
        credentials: 'include', // Include certificates
        mode: 'cors'
      });
      
      if (response.status === 495) {
        // [Inference] Server rejected client certificate
        throw new Error('Client certificate validation failed');
      }
      
      return response;
    } catch (error) {
      if (error.message.includes('certificate')) {
        throw new Error('mTLS authentication failed: ' + error.message);
      }
      throw error;
    }
  }
  
  async validateServerCertificate(url) {
    // [Unverified] Fetch API does not expose server certificate details
    // Certificate validation occurs at browser TLS layer
    // Additional validation requires server-side implementation
    
    try {
      const response = await fetch(url, {
        method: 'HEAD'
      });
      
      return {
        valid: response.ok,
        url: response.url
      };
    } catch (error) {
      return {
        valid: false,
        error: error.message
      };
    }
  }
}

const mtlsFetch = new MTLSFetch();

await mtlsFetch.fetch('https://secure-api.example.com/data', {
  method: 'GET',
  headers: {
    'Content-Type': 'application/json'
  }
});
```

### DNS over HTTPS (DoH)

DNS over HTTPS encrypts DNS queries, preventing DNS-based surveillance and man-in-the-middle attacks. Browser implementations handle DoH transparently.

```javascript
// Modern browsers support DoH configuration
// Queries encrypted automatically when DoH is enabled

class SecureDNSValidator {
  constructor() {
    this.dohProviders = [
      'https://cloudflare-dns.com/dns-query',
      'https://dns.google/dns-query'
    ];
  }
  
  async queryDNS(domain, recordType = 'A') {
    const dohUrl = this.dohProviders[0];
    
    const response = await fetch(`${dohUrl}?name=${domain}&type=${recordType}`, {
      headers: {
        'Accept': 'application/dns-json'
      }
    });
    
    if (!response.ok) {
      throw new Error(`DNS query failed: ${response.status}`);
    }
    
    return response.json();
}

async validateDomain(domain) { 
		try {
		 const result = await this.queryDNS(domain);
	  return {
	    domain,
	    valid: result.Status === 0,
	    answers: result.Answer || [],
	    secure: true // Query performed over HTTPS
	  };
	} catch (error) {
	  return {
	    domain,
	    valid: false,
	    error: error.message,
	    secure: false
	  };
	}
  }
}

const dnsValidator = new SecureDNSValidator(); const validation = await dnsValidator.validateDomain('example.com');
````

### Content Security Policy Integration

CSP headers restrict resource loading to trusted sources, preventing injection attacks that could compromise encrypted communications.

```javascript
class CSPAwareFetch {
  constructor() {
    this.trustedDomains = new Set([
      'https://api.example.com',
      'https://cdn.example.com'
    ]);
  }
  
  validateURL(url) {
    const parsedUrl = new URL(url);
    const origin = `${parsedUrl.protocol}//${parsedUrl.hostname}`;
    
    if (!this.trustedDomains.has(origin)) {
      throw new Error(`URL ${origin} not in trusted domains list`);
    }
    
    if (parsedUrl.protocol !== 'https:') {
      throw new Error('Only HTTPS URLs are allowed');
    }
    
    return true;
  }
  
  async fetch(url, options = {}) {
    this.validateURL(url);
    
    const response = await fetch(url, options);
    
    // Verify CSP headers in response
    const csp = response.headers.get('content-security-policy');
    if (!csp) {
      console.warn('Response missing Content-Security-Policy header');
    }
    
    return response;
  }
  
  addTrustedDomain(domain) {
    if (!domain.startsWith('https://')) {
      throw new Error('Only HTTPS domains can be added');
    }
    this.trustedDomains.add(domain);
  }
}

const cspFetch = new CSPAwareFetch();

await cspFetch.fetch('https://api.example.com/data', {
  method: 'GET'
});
````

---



---


# Progressive Web Apps



---

# Modern Alternatives



---

# TypeScript Integration



---

# Production Best Practices



---

# Accessibility



---

# Standards and Specifications



---